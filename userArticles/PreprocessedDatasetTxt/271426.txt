parallel cluster identification multidimensional lattices abstractthe cluster identification problem variant connected component labeling arises cluster algorithms spin models statistical physics present multidimensional version belkhale banerjees quad algorithm connected component labeling distributed memory parallel computers extension abstracts away extraneous spatial connectivity information two dimensions simplifying implementation higher dimensionality identify two types locality present cluster configurations present optimizations exploit locality better performance performance results 2d 3d 4d ising model simulations swendsonwang dynamics show optimizations improve performance 2080 percent b introduction cluster identification problem variant connected component labeling arises cluster algorithms spin models statistical mechanics applications graph labeled ddimensional hypercubic lattice variables called spins edges bonds may exist nearestneighbor spins cluster spins set spins defined transitive closure relation bond cluster algorithms require lattice labeled two spins label belong cluster since cluster identification step often bottleneck cluster spin model applica tions candidate parallelization however implementation distributed memory parallel computer problematic since clusters may span entire spatial domain requiring global information propagation furthermore cluster configurations may highly irregular preventing priori analysis communication computation patterns parallel algorithms cluster identification must overcome difficulties achieve good performance developed multidimensional extension belkhale banerjees quad algorithm 1 2 2d connected component labeling algorithm developed vlsi circuit extraction hypercube multiprocessor paper presents performance results applying algorithm ising model simulations swendsonwang dynamics 3 2d 3d 4d extension abstracts away extraneous spatial information distributed data structures managed dimensionindependent manner strategy considerably simplifies implementation two dimensions knowledge implementation first parallelization cluster identification 4d improve performance identify two types locality present swendsonwang cluster configurations present optimizations exploit type locality optimizations work abstract representation spatial connectivity information complicated implement 2 dimensions 2d performance results show optimizations effectively exploit cluster locality improve performance 2080 multidimensional quad algorithm remainder paper proceeds follows section 2 discusses previous approaches cluster identification problem parallel computers section 3 describes ising model swendsonwang dynamics section 4 reviews belkhale banerjees quad algorithm presents extensions two dimensions section 5 presents two optimizations exploit cluster locality section 6 gives performance results 2d 3d 4d related work several algorithms 2d cluster identification distributed memory mimd computers presented recent years flanigan tamayo present relaxation algorithm block domain decomposition 4 method neighboring processors compare cluster labels iterate steady state reached baillie coddington consider similar approach self labeling algorithm 5 relaxation methods demonstrate reasonable scaleup 2d problems critical cluster configurations number relaxation iterations grows distance furthest two processors 2 p block decompositions p processors approaches similar relaxation presented strip decompositions 6 7 strip decompositions result two external surfaces per processor however distance two processors large p increases number stages reach steady state multigrid methods accelerate relaxation algorithm large clusters presented simd architectures 8 9 hostnode algorithms involve communicating global connectivity information single processor host processor labels global graph communicates results processors hostnode algorithms 10 11 5 scale processors since serialized host process becomes bottleneck hierarchical methods connected component labeling characterized spatial domain decomposition propagation global information log p stages approach based hierarchical quad algorithm vlsi circuit extraction hypercube multiprocessor 1 hierarchical methods distributed memory computers used image component labeling 12 13 baillie coddington consider mimd hierarchical algorithm ising model achieve good parallel efficiency 5 mino presents hierarchical labeling algorithm vector architectures 14 comparably little work evaluating mimd cluster identification algorithms two dimensions bauernfeind et al consider relaxation host node approaches 3d problem 15 introduce channel reduction net list optimizations reduce communication computation requirements 3d conclude hostnode approach inappropriate 3d due increased memory requirements host node fink et al present 2d 3d results preliminary implementation multidimensional quad algorithm 2 paper includes 4d results introduces issues pertaining dimensionindependent implementation ising model many physical systems binary fluids liquid gas systems magnets exhibit phase transitions order understand critical phenomena simple effective models constructed statistical mechanics simplest model ising model gives qualitative insights properties phase transitions sometimes even provide quantitative predictions measurable physical quantities 16 ising model solved exactly 2d 17 two dimensions exact solutions known numerical simulations often used obtain approximate results example numerical simulations 3d ising model used determine properties phase transitions systems like binary liquids 18 4d ising model prototype relativistic field theory used learn nonperturbative aspects particular phase transitions theories 19 dimensions ising model consists ddimensional lattice variables called spins take discrete values sigma1 neighboring spins coupled coupling strength inversely proportional temperature monte carlo simulations ising model generate sequence spin configurations traditional localupdate monte carlo ising model simulations spins value may may change depending values neighbors random variable 5 since spin update depends solely local information algorithms map naturally onto distributed memory architecture interesting physics arises spin configurations critical region phase transitions occur configurations neighboring spins form large clusters spins value unfortunately length spins correlated correlation length number iterations required reach statistically independent configuration grows z local update schemes value z dynamical critical exponent z 2 thus even correlation lengths small 10 100 critical slowingdown severely limits effectiveness localupdate algorithms ising model 20 order avoid critical slowingdown swendson wangs cluster algorithm updates whole regions spins simultaneously 3 nonlocal update scheme generates independent configurations fewer iterations conventional algorithms cluster algorithm much smaller value z often approaching 0 therefore eliminates critical slowingdown completely swendsonwang cluster algorithm proceeds follows 1 compute bonds spins bond exists probability adjacent spins value 2 label clusters spins clusters defined transitive closure relation bond 3 randomly assign spins cluster common spin value sigma1 steps repeated iteration distributed memory computer large spin lattice must partitioned spatially across processors block decomposition step 1 simple parallelize since compute bonds neighboring spins processor must communicate spins boundaries neighboring processors work step 3 proportional number clusters typically much less number lattice sites step 2 bottleneck computation single cluster may span entire lattice thus entire processor array label cluster requires global propagation information thus labeling step ideally matched distributed memory architecture requires efficient parallel algorithm 41 2d quad algorithm cluster identification method based belkhale banerjees quad algorithm geometric connected component labeling 1 developed label connected sets rectangles represent vlsi circuits plane straightforward apply algorithm label clusters 2d lattice spin values brief description quad algorithm applied 2d lattice spins presented complete description quad algorithm see 1 cluster labeling algorithm consists local labeling phase global combining phase first global 2d lattice partitioned blockwise across processor array processor labels clusters local partition plane sequential labeling algorithm quad algorithm merges local labels across processors assign correct global label spin site processor p processors quad algorithm takes log p stages processor determines correct global labels spins partition plane stage processor knowledge rectangular information region spans evergrowing section plane intuitively processor qs information region represents portion global domain q already collected information necessary label qs local spins data associated information region consists ffl list labels clusters touch least one border information region clusters called ccomp sets ffl four borders information region list representing processor bonds touch border bond border list connects spin site current information region spin site outside region bond associated ccomp set containing local spin site border list data structure list offsets list ccomp set labels offset represents one bond border indirect representation facilitates unionfind cluster mergers described see figure 1 l 1 l l l l l ccomp labels border bond lists figure 1 fields information region data structure initial information region processor consists ccomp set labels border lists local partition plane stage processor q 1 exchanges messages processor q 2 q 1 q 2 information regions adjacent messages contain ccomp set labels border lists current information region processor merges ccomp sets common border two information regions using unionfind data structure 21 border lists two information regions concatenated form information region processor q 1 next stage manner size processors information region doubles stage log p stages processors information region spans entire plane figure 2 illustrates information region grows span entire global domain planar topology processors global combining complete information region spans entire plane global domain toroidal topology clusters opposite borders last information region merged postprocessing step current information region stage 1 stage 2 stage 4 stage 3 partner information region done figure 2 information regions stage quad algorithm sixteen processors stage information region processor top left corner current information region partner processor information region also shown stage two information regions merged forming information region subsequent stage 42 extending quad algorithm higher dimensions straightforward extension quad algorithm two dimensions results fairly complex multidimensional information region data structures simplify implemen tation present multidimensional extension using abstract dimensionindependent information region representation divideandconquer quad algorithm strategy naturally extended 2 dimensions partitioning global domain ddimensional blocks assigning one processor processor performs sequential labeling method local domain domains translated information regions global combining step information region represents ddimensional subset ddimensional global domain ddimensional information regions merged stage algorithm log p stages information region spans entire global domain two dimensions list bonds border 1d list corresponding 1d border two 2d information regions since bonds exist every lattice site border lists sparse 3d lattice border lists must represent sparse 2d borders general border two ddimensional information regions gamma 1 dimensional hyperplane thus straightforward 3d 4d implementation would much complex two dimensions sparse multidimensional hyperplanes must communicated traversed order merge clusters avoid complication note impose order bonds touching information region border actual spatial location bond within border needed merge sets across processors long processor stores border bonds order store bonds 1d list merge clusters different processors traversing corresponding border lists order figure 3 illustrates 3d lattices concept first applied fink et al 3d quad algorithm 2 figure 3 2d borders 3d information region linearized enumerating border bonds order processor similar optimization applied 3d lattices bauernfeind et al15 define order border bonds considering gamma 1dimensional border subset ddimensional global lattice enumerate bonds touching dimensional border columnmajor order relative ddimensional global lattice since processor enumerates sites relative global indices processor stores sets border order without regard orientation border space ordering linearizes gamma 1dimensional borders resulting abstract information region whose border representations independent problem dimensionality two information regions merged order bonds new border lists consistent different processors therefore logic merging clusters border two information regions change multidimensional lattices sparse hyperplane data structures required 2d cluster implementation extended 3d 4d modifications 43 performance analysis belkhale banerjee show 2d quad algorithm vlsi circuit extraction runs number processors ff inverse ackermans function message startup time b communication time per byte b number border rectangles along cross section global domain 1 number border rectangles vlsi circuit extraction applications corresponds number border bonds cluster identification applications cluster identification lattice let n lattice size p probability bond two adjacent lattice points giving running time olog p n ddimensional problem define n p assume global domain ddimensional hypercube sides n 1d partitioned onto ddimensional logical hypercube processors sides p 1d suppose stage processors information region hypercube sides length stage information region hypercube sides length 2a thus surface area information region increases factor 2 dgamma1 every stages let bi surface area information region stage bi e 1 easy see total number bonds border information region proportional surface area summing log p stages find total number bytes processor communicates algorithm o2dpn log p message starts total time spent communication olog total number unionfind operations performed processor stage equal number bonds border information region using path compression union rank optimizations unionfind operations 21 total work spent merging clusters opdn ffpdn implementation uses path compression heuristic unionbyrank adding together communication computation running time global combining olog ffpdn breadthfirst searchbfs shown efficient algorithm perform sequential local labeling step 5 since bfs runs ojv jjej 21 local labeling phase runs n thus dimension lattice time local phase dominate time global phase long n large however increases global time increases relative local time fixed problem size must therefore scale problem size along problem dimensionality order realize equivalent parallel efficiency higher dimensional lattices optimizations one limitation quad algorithm surface area information region grows stage last stage processor must handle crosssection entire global domain many processors large problem sizes degrade algorithms performance 1 mitigate effect developed optimizations exploit properties cluster configuration better performance monte carlo ising model simulations cluster configuration structure depends heavily coupling constant recall probability bond exists two adjacent samevalued spins subcritical low bonds relative sparse clusters small supercritical high bonds relatively dense one large cluster tends permeate entire lattice criticality system transition two cases cluster configurations combinations small large clusters particular spin affects labels spins depends cluster configuration properties identify following two types locality may exist cluster configuration clusters affect cluster labels limited area ffl type 2 adjacent lattice points likely belong cluster subcritical configurations exhibit type 1 locality supercritical configurations exhibit type 2 locality configurations criticality show aspects types belkhale banerjee exploit type 1 locality two dimensions overlap quad algorithm 1 algorithm information regions overlap clusters span overlap region must merged intuitively small clusters eliminated early stages algorithm leaving large clusters merge later stages overlap quad algorithm requires positions bonds within borders maintained precluding use abstract dimensionindependent information region data structure instead present two simpler optimizations bubble elimination border compression optimizations work abstract border representations complicated implement 2 dimensions 2d 51 bubble elimination bubble elimination exploits type 1 locality eliminating small clusters preprocessing phase quad algorithm local cluster touches one border information region called bubble immediately initializing information region processor identifies bubbles along border information exchanged neighbor clusters marked bubbles sides border merged deleted borders thus small clusters eliminated information regions performing basic quad algorithm course quad algorithm communication computation reduced since bubble clusters considered bubble elimination incurs communication overhead 3 gamma1 messages ddimensional problem communicate manhattan neighbors communication overhead drops 2d messages although bubbles corners edges information region eliminated effect insignificant granularity problem sufficiently large 52 border compression border compression exploits type 2 locality changing representation border lists compress representation list using runlength encoding 22 border list set labels replaced sequence pairs l sl number times value l appears succession border list type 2 locality prevalent border compression aids performance two ways reduces length messages exploit compressed representation reduce number unionfind operations performed two compressed borders merged decompressed form two corresponding lists cluster labels combine compressed representation simple determine two clusters merged together several times succession decompression simple filter redundant mergers lists reducing number unionfind mergers performed thus border compression reduces communication volume computation cluster configurations bubble elimination increases effectiveness border compression suppose global cluster configuration resembles swiss cheese many small clusters interspersed one large cluster phenomenon occurs ising model cluster configurations criticality bubble elimination removes small clusters preprocessing leaving active clusters belonging one large cluster case long runs identical labels along border information region border compression collapses runs leaving small effective information region borders 6 performance results 61 implementation implemented cluster algorithm ising model simulation 2d 3d 4d c global lattice toroidal topology directions using bubble elimination manhattan neighbors considered local labeling method breadthfirst search 21 according swendsonwang algorithm clusters must flipped randomly cluster identification step spatially decomposed parallel implementation necessary processors obtain consistent pseudorandom numbers generating new spins clusters span one processor implementation generate new random spins local cluster prior global cluster merging store new spin highorder bit cluster label thus cluster merging spins cluster guaranteed consistent simplify implementation 2 dimensions use lparx programming library version 11 23 lparx manages data distribution communication cartesian lattices greatly simplifies sections code manages regular spin lattice kernel cluster algorithm written messagepassing style using messagepassing layer lparx24 generic messagepassing system resembling message passing interface25 since cluster algorithm largely dimensionindependent messagepassing code almost identical problem dimensionality fact code generates 2d3d 4d versions compiletime macros determine problem dimensionality code developed debugged sun workstation using lparx mechanisms simulate parallel processes messagepassing performance results obtained runs intel paragon osf1 r12 32mbnode code compiled gcc v257 optimization level 2 62 performance total cluster identification time consists local stage perform local labeling sequential algorithm global stage combine labels across processors using multidimensional quad algorithm times reported wall clock times obtained paragon dclock system call accuracy 100 nanoseconds intuitively expect benefits bubble elimination border compression vary coupling constant figures 4 5 6 show global stage running times varying values problem sizes shown critical region occurs c 0221 2d c 0111 3d c 008 4d since surface areatovolume ratio larger 3d 4d 2d optimizations important problems expected figures 5 6 show bubble elimination effective subcritical region border compression effective supercritical region critical region two optimizations together effective either optimization alone presumably due swiss cheese effect discussed section 5 together optimizations improve performance 3585 depending 3d 4d kappa10305070 global combining time per 4d global combining time nodes 68x68x34x34 lattice bubble elimination border compression 2d optimizations improve performance 2070 show intuitive dependence 3d 4d suspect due cache effects increases number global clusters decreases thus cluster merging unionfind data structure accesses cache hits higher since greater portion union find data structure fits cache 2d surface areatovolume ratio low unionfind accesses become dominant factor algorithms performance 3d 4d information region borders much larger overflowing cache causing many cache misses traversing borders information region since borders larger unionfind data structures unionfind data structure memory accesses less critical figure 7 shows relative costs local stage global stages without optimizations breakdown shows 2d local labeling time dominates global time benefit optimizations limited amdahls law 26 however 3d 4d global stage bottleneck computation two optimizations significant impact performance timing results instructive depend implementation details machine ar chitecture evaluate optimizations objective measure table 1 shows total number bytes transmitted course quad algorithm since amount work merge clusters directly proportional length messages numbers give good indication successfully optimizations exploit various cluster configu rations communication volume reduction varies depending cluster configuration structure ranging factor twenty one since physicists interested using parallel processing capability run larger problems possible single workstation appropriate examine algorithms performance problem size number processors grow ideal linear parallel time per site ns normalized labeling perfomance local labeling global labeling optimization optimizations subcritical critical supercritical figure 7 breakdown algorithm costs normalized per spin site runs 64 processors intel paragon lattice sizes 4680x4680 2d 280x280x280 3d 68x68x34x34 4d subcritical runs 3d 004 4d critical runs 2d 0111 3d 008 4d supercritical runs 2d 02 3d 02 4d opt elim compress 2d 4680x4680 lattice 3d 280x280x280 lattice 4d 68x68x34x34 lattice table 1 total number bytes transmitted global combining runs 64 processors algorithm problem size number processors scaled together asymptotically running time remains constant due global nature cluster identification problem basic quad algorithm cannot achieve ideal scaled speedup practice since quad algorithm takes log p stages global work increase least log p difficulty dimensions work last stage algorithm doubles every stages however bubble elimination border compression optimizations vastly reduce work later stages algorithm thus optimizations get closer achieving ideal scaled speedup table 2 shows scaled speedup results fixed number spins sites per processor critical cluster configurations results show number processors problem size scaled together performance benefit optimizations increases 2d scaled speedup optimizations nearly ideal 3d especially 4d versions scale well although figure 7 shows better performance achieved away criticality although optimizations developed multidimensional quad algorithm mind conjecture would also effective cluster identification algorithms relaxation methods 4 6 7 multidimensional quad algorithm optimizations may also appropriate variants connected component labeling one open question whether border compression bubble elimination optimizations would effectively exploit graph structure applications image component labeling applications 7 conclusion presented efficient multidimensional extension belkhale banerjees quad algorithm connected component labeling since extension deals abstract spatial number optimizations optimizations processors 2d 3d 4d 2d 3d 4d table 2 global combining time seconds lattice size number processors scaled together processors partition 585x585 2d 70x70x70 3d 17x17x17x17 4d runs c connectivity information distributed data structures managed dimensionindependent manner technique considerably simplifies implementations two dimen sions introduced two optimizations basic algorithm effectively exploit locality ising model cluster configurations depending structure cluster configurations optimizations improve performance 2080 intel paragon opti mizations large lattices labeled many processors good parallel efficiency optimizations especially important two dimensions surface areatovolume ratio high r parallel algorithms geometric connected component labeling hypercube multiprocessor cluster identification distributed memory multiprocessor nonuniversal critical dynamics monte carlo simu lations parallel cluster labeling method monte carlo dy namics cluster identification algorithms spin models sequential parallel parallelization ising model performance evaluation swendsonwang dynamics large 2d critical ising models multigrid cluster labeling scheme parallel multigrid algorithm percolation clusters parallel simulation ising model paralleliza tion 2d swendsonwang algorithm evaluation connected component labeling algorithms shared distributed memory multiprocessors component labeling algorithms intel ipsc2 hypercube vectorized algorithm cluster formation swendsonwang dynam ics 3d ising model swendsonwang dynamics parallel approach statistical field theory crystal statistics twodimensional model orderdisorder tran sition numerical investigation interface tension threedimensional ising model broken phase 4dimensional ising model finite volume computer simulation methods theoretical physics introduction algorithms robust parallel programming model dynamic nonuniform scientific computation lparx users guide v20 message passing interface forum computer architecture quantitative approach tr ctr scott b baden software infrastructure nonuniform scientific computations parallel processors acm sigapp applied computing review v4 n1 p710 spring 1996