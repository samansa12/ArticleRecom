parallel mining outliers large database data mining new important fast growing database application outlier exception detection one kind data mining applied variety areas like monitoring credit card fraud criminal activities electronic commerce everincreasing size attributes dimensions database previously proposed detection methods two dimensions longer applicable time complexity nestedloop nl algorithm knorr ng proc 24th vldb 1998 linear dimensionality quadratic dataset size inducing unacceptable cost large dataseta efficient version enl parallel version penl introduced theory improvement performance penl linear number processors shown performance comparison enl penl using bulk synchronization parallel bsp model great improvement verified experiments parallel computer system ibm 9076 sp2 results show good choice mine outliers cluster workstations lowcost interconnected commodity communication network b introduction data mining knowledge discovery tasks classified four general categories dependency detection eg association rules 1 b class identification eg classification data clustering 6 14 17 c class description eg concept generalization 7 11 excep tionoutlier detection 12 13 research concentrated first three categories existing work outliers detection lied field statistics 2 8 although author currently department computer science university maryland college park work paper done university hong kong hung cheung outliers also considered existing algorithms main target algorithms try remove tolerate 6 14 17 fact identification outliers applied areas electronic commerce credit card fraud detection analysis performance statistic professional athletes 10 even exploration satellite medical images 12 example database transactions containing sales information transactions would involve small amount money items thus typical fault detection discover exceptions amount money spent type items purchased time location second example satellite nowadays used take images earth using visible lights well electromagnetic waves detect targets potential oil fields suspicious military bases detection exceptional high energy temperature reflection certain electromagnetic waves used locate possible targets simple algorithm called nestedloop algorithm nl proposed 13 however complexity okn 2 k number dimensions n number data objects number passes dataset linear n real implementation performance studies find major cost calculation distances objects though nl good choice dataset high dimensionality large number calculations makes unfavorable cellbased algorithm proposed 13 needs three dataset passes however suitable high dimensions time complexity exponential number dimensions nl always outperforms cellbased algorithm four dimensions 13 paper improve nl high dimensional dataset common data warehouse one approach improve nl algorithm parallelize paper definition outliers original nl described next subsections introduction nl improved reduce number calculations resulted algorithm enl given section 2 section 3 enl parallelized reduce execution time sharednothing system section 4 performance improvement analyzed using bulk synchronization parallel bsp model performance studies given section 5 finally give discussion related works section 6 paper mainly focuses identification distancebased outliers although parallel algorithm also modified perform expensive step finding densitybased outliers 4 related works densitybased outliers described section 6 11 distancebased outliers given 13 definition outlier following given parameter p object dataset dbp doutlier least fraction p objects lies greater distance definition maximum number objects within distance outlier number objects let f underlying distance function gives distance pair objects object parallel mining outliers large database 3 neighbourhood contains set objects q 2 within distance ie notion outliers suitable situation observed distribution fit standard distribution readers referred 12 generalization notions distancebased outliers supported statistical tests standard distributions works densitybased outliers described section 6 12 assumption notation nl algorithm algorithm nl 13 blockoriented nestedloop design block involve one disk io ie may necessary take one disk io read block paper page needs one disk io access thus total number pages particular dataset constant total number blocks dataset change size block nl algorithm designed uniprocessor system one local memory one local disk effect cache insignificant make assumptions generally acceptable real systems additional disk buffer operating system beside buffer use algorithm disk access sequential let n number blocks dataset k dimensionality n number objects dataset p number pages contained block number objects page let time accessing page disk io time computing distance 2 objects comp linear dimensionality 13 original nl original nl algorithm 13 clarification described assume buffer size storing dataset b dataset size buffer first divided 2 equal halves called first second arrays dataset read first second array predefined order object first array distance objects arrays directly computed count objects dneighbourhood maintained algorithm nl 1 fill first array size b dataset block objects 2 object first array count number objects first array close distance count nonoutlier 3 repeat blocks compared first array fill second array another block save block never served first array last 4 hung cheung b unmarked object first array increase count number objects second array close distance count mark nonoutlier 4 report unmarked objects first array outliers 5 second array served first array stop otherwise swap names first second arrays repeat step 2 time complexity stated okn 2 13 k dimensionality n number objects dataset disk io time considered briefly 13 fact cpu time io time considered detailed analysis computation time disk io time given computation time total time calculation distance pairs objects upper bound n 2 comp ie number calculations distance quadratic number objects dataset actual number calculations depends distribution data location data blocks distance number turn depends fraction p since usual case number outliers small small calculation particular object done count exceeds result actual number calculations much less n 2 usually within half shown section 5 disk io time since dataset divided blocks total number block reads nngamma2ngamma1 number passes dataset n total number page reads np 1p noted p directly proportional buffer size fixed buffer size n directly proportional n complexity 2 example 1 following example consider 50 buffering 4 blocks dataset denoted b c ie block contains4 dataset order filling arrays comparing following 1 b c total 4 blocks reads 2 read required read b c total 2 blocks reads 3 c c b total 2 blocks reads 4 b b c total 2 blocks reads table shows order blocks loaded blocks staying two arrays buffer row shows snapshot step 1 step 3 parallel mining outliers large database 5 block buffer disk io order b c array 1 array 2 6 l c 9 buffer unchanged total number disk io n blocks total number dataset passes is4 25 enhanced nl nl redundant block reading comparison section new order proposed results reduced computation time disk io time arrangement turn blocks read second array predefined order end series ready blocks reached block first array marked done names two arrays swapped order reversed repeated blocks done resultant enhanced nl enl algorithm described object dataset count algorithm enl 1 label blocks ready block either ready done state 2 fill first array size b dataset block objects 3 object first array increase count number objects first array close distance count mark nonoutlier 4 set blockreading order forward 5 repeat ready blocks without marked done compared first array specified blockreading order fill second array next block b object first array object j second array object j unmarked 6 hung cheung increase count count j 1 count mark nonoutlier proceed next nonoutlier 6 report unmarked objects first array outliers 7 second array marked done stop otherwise mark block first array done reverse blockreading order swap names first second arrays repeat step 3 although time complexity enl still okn 2 k dimensionality n number objects dataset cost computation disk io reduced compared nl computation time upper bound total time calculation distance pairs objects still linear dimensionality original nl algorithm count object first array updated however enl counts objects updated comparison thus upper bound number calculations distances reduced almost half compared nl actual reduction number calculations depends distribution data locations data blocks distance number turn depends fraction p comparions performance nl enl shown section 5 simplicity upper bound number distance calculations objects block said np p 2 fact needs np p np times disk io time dataset divided blocks total number block reads number passes dataset n total number page reads fixed buffer size n directly proportional n disk io time complexity nearly half nl example 2 example 1 extended illustrate enl consider 50 buffering 4 blocks dataset denoted b c ie block contains4 dataset order filling arrays comparing following 1 b c total 4 blocks reads 2 read required c b total 2 blocks reads parallel mining outliers large database 7 3 b b c total 1 blocks reads 4 c c total 0 blocks reads table shows order blocks loaded blocks staying two arrays buffer row shows snapshot step 2 step 5 block buffer disk io order b c array 1 array 2 buffer unchanged total number disk io 1 blocks total number dataset passes is4 175 3 parallel enl penl parallel enl parallel version enl running sharednothing system actually running processor penl almost reduced enl block reading enl replaced transfer blocks among processors communication network major advantage distributing costly computations nearly evenly among processors 31 assumptions notation extend enl penl assumptions notations extended simplicity assumed sharednothing system node one processor node memory local disk dataset distributed equally size local disk node without overlapping communication done message passing network architecture designed node send message receive message time simplicity analysis later section make previous assumption requirement strict least required internode communication possible among nodes besides nodes arranged logical ring node two neighbour nodes logical arrangement means physically network architecture eg bus affect effectiveness algorithm performance let n number blocks dataset np total number pages dataset k dimensionality n number objects dataset p number pages contained block number objects page number 8 hung cheung objects block n let time computing distance 2 objects comp time internode communication 2 nodes transfer page data comm time accessing page local disk io let p number processors nodes size local memory used disk buffer simplify algorithm analysis assumed local memory buffers size nodes data local disk number data blocks local disk integer ie number pages dataset np multiple product number processors number pages contained block pp 32 algorithm node part dataset local disk number pages local data np number objects local data n node local memory size divided 3 arrays array contain block size p pages first second arrays function similarly enl third array used temp buffer store data received neighboring node besides count objects dneighbors object maintained penl modified enl basic principle node time block read nodes local disk distance calculations done block transferred nodes neighbor node distance calculations done using block received nodes another neighbour node repeated block passed neighbors node reads another block local disk repeats disk io operations replaced relatively fast internode communication huge number calculations distributed nodes greatly reduces execution time ie response time algorithm penlnode id x 1 label blocks ready block either ready done state 2 fill first array block objects 3 set blockreading order forward 4 set counter b 0 set counter 0 5 repeat ready blocks compared first array specified blockreading order set counter c 0 object first array increase count number objects first array close distance count mark nonoutlier c set b 1 go step f parallel mining outliers large database 9 b 6 0 fill second array next block object first array object j second array object j unmarked distt increase count 1 otherwise increase count count j 1 count nonoutlier reverse order execution steps g h send data first array neighbor node send data second array neighbor node receive data neighbor node store temp buffer third array increment counter c 1 swap names second array third array counter continue iteration step 5 otherwise go step 5e 6 second array marked done report unmarked objects first array outliers otherwise mark block first array done reverse blockreading order swap names first second arrays repeat step 4 time analysis penl given briefly later detailed analysis given using bulk synchronous parallel bsp model node operations similar enl except block transferred nodes computations done thus brief upper bound computation time node node n blocks local data local disk io time enl executing n blocks data disk io time node internode communication time node obvious upper bound computation time linear reciprocal number processors internode communication time decreases increasing number hung cheung processors disk io time quadratic reciprocal number processors please note p changes size buffer total size local memory fixed ie pp constant internode communication time node varies dataset size number processors computation time local disk io time node linear reciprocal number processors although upper bound computation time shown actually calculations distributed quite evenly among nodes nearly linear reciprocal number processors shown performance studies section 5 33 example following gives example execution penl dataset 16 blocks using four nodes node four local blocks 16 blocks evenly distributed four nodes four local blocks node x denoted ax bx cx dx order filling arrays disk io internode communication comparing node 0 following 1 a0 a0 io 3 communications total 4 blocks reads 12 communications 2 d0 d0 read required nications b0 io b1 b2 b3 3 communications total 2 blocks reads 9 communications 3 b0 b0 read required b1 nications total 1 blocks reads 6 communications 4 c0 c0 read required c1 c2 c3 3 communications total 0 blocks reads 3 communications node number disk io 1 blocks number dataset passes is4 175 internode communication 34 times table appendix shows details order blocks loaded node 0 blocks transferred node 0 blocks staying two arrays buffer node 0 run enl using single node amount memory node penl total number disk io blocks total number dataset passes 121 75625 ratio disk io enl penl using 4 nodes 75625 432 improvement significant however give enl amount memory total sum memory nodes gain benefit disk io size block larger total number blocks much less 16 nevertheless still significant improvement performance computation time major cost nearly evenly distributed nodes penl shown section 5 parallel mining outliers large database 11 34 optimization following optimization penl outer iterations step 5 5a 5i 1 approximately first half inner iterations 5e 5i reduce redundancy block transmission computation example section 33 inner iterations computations blocks 0 3 0 3 c 3 skipped upper bound cost computation outer iteration reduced pnp p therefore upper bound total computation cost reduced therefore computationcostreductionratio ratio reduction upper bound computation cost optimization penl pgamma1k2 n number blocks node example section 33 reduction 01 practice large number local blocks reduction significant paper refer original penl algorithm unless specified simplicity implementation analysis parallel algorithm theoretical analysis using bsp model studying performance real execution algorithms theoretical analysis given bsp bulk synchronous parallel model 3 used analyze penl algorithm hardware software characteristics model match penls platform requirement working principle bsp computer consists set processormemory pairs communication network delivers messages pointtopoint manner mechanism efficient barrier synchronization processors bsp computer twolevel memory model ie processor physically local memory module memory nonlocal accessible uniformly efficient way penl requires node local memory buffer accesses blocks buffers nodes done synchronous communication block transfers done nodetonode manner bsp computer operates following way computation consists sequence parallel supersteps superstep sequence steps followed barrier synchronization point nonlocal memory accesses take effect penl requires barrier synchronization block transfers 12 hung cheung superstep processor carry set programs threads following perform number computation steps set threads values held locally start superstep ii send receive number messages corresponding nonlocal read write requests superstep penl performs computations items one two blocks accesses disk loading new block executes block transmissions simple model bridges hardware software bsp model provides portability across diverse platforms predictable efficiency seen model suitable penl penl coarse granularity superstep consists lot distance calculations followed message passing 41 cost analysis define following variables l barrier synchronization cost ratio time cost local disk io accessing object ie time local disk io accessing page time computation distance two objects g ratio time internode communication transferring object ie time internode communication transferring page time computation distance two objects costs barriers added penl algorithm shown algorithm penlnode id x 1 label blocks ready block either ready done state 2 fill first array block objects pages block np objects page 3 set blockreading order forward 4 set counter b 0 5 repeat ready blocks compared first array specified blockreading order set counter c 0 set counter 0 object first array increase count number objects first array close distance count mark nonoutlier parallel mining outliers large database 13 c set b 1 go step f b 6 0 fill second array next block object first array object j second array object j unmarked distt increase count 1 otherwise increase count count j 1 count nonoutlier f set barrier reverse order execution steps g h send data first array neighbor node send data second array neighbor node receive data neighbor node store temp buffer third array set barrier increment counter c 1 swap names second array third continue iteration step 5 otherwise go step 6 second array marked done report unmarked objects first array outliers otherwise mark block first array done reverse blockreading order swap names first second arrays repeat step 4 therefore total costs algorithm derivation found appendix b first term computation second one disk io third one communication last one synchronization please notice time computation upper bound therefore theoretical analysis give reliable value actual execution time still acts good reference comparison enl later block size page size object size constant found dataset size large n ae pnp ie local block number large ffl computation cost quadratic dataset size linear reciprocal number processors ffl disk io cost quadratic dataset size quadratic reciprocal number processors 14 hung cheung ffl communication cost quadratic dataset size linear reciprocal number processors ffl synchronization cost quadratic dataset size linear reciprocal number processors please note p changes size buffer total size local memories fixed ie pp constant costs still quadratic dataset size dataset size large n ae pnp ie local block number large besides ffl computation cost still linear reciprocal number processors ffl disk io cost linear reciprocal number processors ffl synchronization cost linear number processors analysis tells us total memory fixed still beneficial increase number processors shown major cost computation linear reciprocal number processors hand number processors kept unchanged buffer size node ie block size p varies computation cost linear proportional number pages block p thus smaller block size fewer computations necessary besides local block number increases makes computationcostreductionratio optimization algorithm section 34 become smaller however recommended use small buffer p small n ae pnp p effect reduction computation cost small p small besides smaller block size also increases cost disk io communication synchronization 42 comparision penl enl comparing penl enl given amount memory enl corresponding cost ii number pages block enl enl buffer divided two arrays total amount memory 2p 1 penl local buffer divided three arrays total amount memory 3pp giving amount memory penl enl better implementation made sufficient divide local buffer two arrays however later sections still choose three arrays order give advantage sequential algorithms comparisons still show parallel algorithm outperforms parallel mining outliers large database 15 assume worse case ratio number calculations actually done enl total sum number calculations actually done nodes penl 2 let f fraction number calculations actually done enl fraction penl 2f enl computation cost penl computation cost cpenlcomp linear number processors thus always better choice use penl even total buffer size fixed performance studies 51 experimental setup implementation experiments base dataset 248object dataset consisting trade index numbers hksar 1992 1999 march 5 object one four categories imports domestic exports reexports total exports four categories equal number objects object six attributes index value yearonchange percentage change index value index unit value yearonchange percentage change index unit value index quantum yearonchange percentage change index quantum since reallife dataset quite small want test algorithms large diskresident dataset generate large number objects simulating distribution orginal dataset testing distance defined number outliers restricted within percents objects simulate real situation programs run ibm 9076 sp2 system installed university hong kong system consists three frames frame consists 16 160 mhz ibm p2sc risc processors individual node local ram 128 mb 256 mb local disk storage 2 gb system files local scratch spaces node frame interconnected high performance switches three frames also linked interframe high performance switch theroretical peak performance processor 640 mflops tests sequential programs parallel programs run dedicated mode using loadleveler batch job scheduler section 52 nl enl run another system sp2 system time limit 10 hours running sun enterprise ultra 450 4 ultrasparcii cpu running 250mhz 1gb ram four 41gb hard disks sp2 order make comparison fair fix total amount memory nodes penl nl enl able hold 75000 objects number objects chosen number blocks test reasonable hung cheung result number objects block np p nl penl 2 4 8 processors 37500 12500 6250 3125 1563 respectively number objects 50000 100000 200000 400000 800000 implies number blocks 2 4 8 16 32 penl 2 3 6 11 22 nl implemented three algorithms nl enl penl using c mpi message passing interface library used penl message passing among multiple processors 15 penl better implementation made sufficient divide local buffer two arrays rather three arrays however still chose three arrays simplicity order give advantage sequential algorithms comparisons still show parallel algorithm penl outperforms noted penl node part memory needed act counts objects decrease memory act counts decrease p number pages block increase total cost however addition cost small compared improvement nl object database usually contains tens even hundreds attributes may integers floating points even strings size count small compared size object p decrease bit total number objects huge undesirable hold counts memory counts stored local disks total size counts small compared size datasets thus extra disk io time accessing counts affects performance bit implementation enl penl counts resident disk load required method good induces extra disk io experiments decide define object six dimensions long integer data type order make effect reading writing counts significant however results show effect minor compared reduction computation cost besides needs extra communication transfer counts objects node containing objects disk outliers reported soon possible better way end counts gathered node outliers reported combining counts extra communication cost little compared computation cost chose second method implementation final point note computer architecture processor cache processors larger total cache capacity thus hit ratio larger performance enhanced besides existing workstations cluster formed low cost perform penl rather installing new advanced costly supercomputer although experiments conducted supercomputer results show commuication cost minor thus communication network low cost sufficient 52 nl vs enl section compare performance nl enl parallel mining outliers large database 17 object number 2000 8000 execution time computation time disk io time calculation number 974467 618697 23095637 17763925 enl execution time nl execution time 07459 08487 figure 1 table comparisons nl enl object number 32000 128000 execution time computation time disk io time calculation number enl execution time nl execution time 08636 08743 figure 2 table comparisons nl enl cont figure 3 see enl better nl although improvement great moreover tables figure 1 2 found major cost computation distance greatly reduced penl show later besides see increase execution time approximately quadratic increase objects ie execution time complexity 2 indicating unlikely use nl enl deal large number objects however penl help reduce time 53 sequential vs parallel compare performance sequential program nl parallel program penl figure 4 5 show penl various number processors outperforms nl whatever number objects even number processor two performance improved 100 percents said total amount memory given penl nl clear penl always better choice multiprocessor system cluster workstations available result nl 400000 800000 objects penl 2 processors 800000 objects available execution time exceeds time limit job sp2 system hung cheung0750852000 8000 32000 128000 object number figure 3 comparison execution time nl enl processor number number objects 50000 100000 200000 400000 800000 figure 4 table comparisons execution time nl penl seconds100100001nl 2 4 8 processor number execution time sec 50000 objects 333100000 objects 200000 objects 222400000 objects theta theta theta theta theta 800000 objects 44 figure 5 execution time number processors parallel mining outliers large database 19 processor number execution cpu io communication synchronization figure table comparisons different costs nl penl 100000 objects seconds 54 variation processor number section see performance penl related number processors figure 4 5 see nearly straight lines dropping steadily almost parallel indicating scalability stable cases execution time almost halved number processors doubled near theoretical analysis predicts ie execution time approximately linear reciprocal number processors increase execution time approximately quadratic number objects ie execution time complexity 2 noted execution time linear dimensionality thus still preferable database high dimensionality 55 comparison computation disk io communication time synchronization time section look clearly contribution execution time com putation disk io communication synchronization time penl figure 6 shows 99 percents execution cost comes computation time since penl distributes computation operations among processors nearly evenly execution time reduced greatly improvement considered focus reduce computation operations hand disk io communication synchronization time much minor trends theoretical analysis disk io time increases slowly number processors reading writing counts block size smaller number blocks loaded transfered larger new block comes counts old block written counts new block read sum number pages accessed processors close matter many processors used total number pages accessed counts increases number processors counts read written times thus disk time increases bit communication time synchronization time depend much system moment execution eg bandwidth condition communication network 20 hung cheung 6 discussion related works nl algorithm straight forward method mine outliers database enl proposed reduces computation disk io costs furthermore algorithm penl proposed parallelize enl analysis shows total buffer size system fixed computation cost linear reciprocal number processors verified performance studies great improvement caused nearly even distribution computation operations among processors performance studies indicate 99 percents execution time comes computation execution time also linear reciprocal number processors results show penl efficient comparing nl enl improvement focused reduce computation operations since costs like communication time minor lowcost cluster workstations commodity processors interconnected lowcost communication network chosen platform running penl rather much expensive supercomputer cluster also much cheaper easier build maintain upgrade achieve similar performance nl single high performance processor system breunig et al introduced definition new kind outliers densitybased outliers investigates applicability 4 heuristic identify meaningful local outliers notion distancebased outliers cannot find first step computation lof local outlier factor materialization minptsubnearest neighborhoods pages 102103 4 modification made parallel algorithm perform step also expensive step computation lof instead updating count objects dneighborhood object node stores temporary minptsubnearest neighborhood object final minptsubnearest neighborhood object obtained combining temporary minptsubnearest neighborhoods object calculated nodes choose parallelize nl algorithm instead using penl algorithm simplifying implementation reducing disk storage space temporary minptsubnearest neighborhoods case node stores minptsubnearest neighborhoods objects block stays first array difference reading order blocks increase number blocks io computation amost doubling similarity search highdimensional vector space using vafile method outperforms methods known 16 detection outliers based vafile approach different approaches nestedloop cellstructure take using vafile consideration future works r mining association rules sets items large databases outliers statistical data scientific computing bulk synchronous parallel architetures lof identifying densitybased local outliers trade index numbers densitybased algorithm discovering clusters large spatial databases noise knowledge discovery databases attributeoriented approach outliers parallel algorithm mining outliers large database digital money card technologies finding aggregate proximity relationships commonalities spatial data mining unified notion outliers properties computation algorithms mining distancebased outliers large datasets efficient effective clustering methods spatial data mining quantitative analysis performance study similaritysearch methods hifhdimensional spaces birch efficient data clustering method large databases tr mining association rules sets items large databases finding aggregate proximity relationships commonalities spatial data mining quantitative analysis performance study similaritysearch methods highdimensional spaces algorithms mining distancebased outliers large datasets knowledge discovery databases efficient effective clustering methods spatial data mining unified approach mining outliers digital money card technologies