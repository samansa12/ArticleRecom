3d scene data recovery using omnidirectional multibaseline stereo traditional approach extracting geometric information large scene compute multiple 3d depth maps stereo pairs direct range finders merge 3d data however resulting merged depth maps may subject merging errors relative poses depth maps known exactly addition 3d data may also resampled merging adds additional complexity potential sources errorsthis paper provides means directly extracting 3d data covering wide field view thus bypassing need numerous depth map merging work cylindrical images first composited sequences images taken camera rotated 360 vertical axis taking image panoramas different camera locations recover 3d data scene using set simple techniques feature tracking 8point structure motion algorithm multibaseline stereo also investigate effect median filtering recovered 3d point distributions show results approach applied synthetic real scenes b introduction traditional approach extracting geometric information large scene compute multiple possibly numerous 3d depth maps stereo pairs merge 3d data ferrie levine 1987 higuchi et al 1993 parvin medioni 1992 shum et al 1994 computationally intensive resulting merged depth maps may subject merging er rors especially relative poses depth maps known exactly 3d data may also resampled merging adds additional complexity potential sources errors paper provides means directly extracting 3d data covering wide field view thus bypassing need numerous depth map merging work cylindrical images first composited sequences images taken camera rotated 360 ffi vertical axis taking image panoramas different camera locations recover 3d data scene using set simple techniques feature tracking 8point direct iterative structure motion algorithms multibaseline stereo several advantages approach first cylindrical image mosaics built quite accurately since camera motion restricted second relative pose various camera locations determined much greater accuracy regular structure motion applied images narrower fields view third need build purchase specialized stereo camera whose calibration may sensitive drift timeany conventional video camera tripod suffice approach used construct models building interiors virtual reality applications games home sales architectural remodeling robotics applications navigation paper describe approach generate 3d data corresponding wide field view specifically 360 ffi show results approach synthetic real scenes first review relevant work section 2 delineating basic approach section 3 method extract wideangle images ie panoramic images described section 4 section 5 reviews 8point algorithm shows applied cylindrical panoramic images section 6 describes two methods extracting 3d point data first relies unconstrained tracking using 8point data input second constrains search feature correspondences epipolar lines briefly outline approach modeling data section 7details given elsewhere kang et al 1995a finally show results approach section 8 close discussion conclusions relevant work significant body work range image recovery using stereo comprehensive survey given barnard fischler 1982 work stereo uses images limited fields view one earliest work use panoramic images omnidirectional stereo system ishigura ishigura et al 1992 uses two panoramic views panoramic view created one two vertical slits camera image sweeping around 360 ffi cameras displaced front rotation center rotated small angles typically 04 ffi one disadvantages method slow data accumulation takes 10 mins camera angular increments must approximately 1f radians assumed known priori murray murray 1995 generalizes ishigura et als approach using vertical slits image except paper uses single image raster would equivalent structure known motion motion stereo advantage efficient data acquisition done lower angular resolution analysis involved work similar bolles et als bolles et al 1987 spatiotemporal epipolar analysis except temporal dimension replaced angular displacement another related work plenoptic modeling mcmillan bishop 1995 idea composite rotated camera views panoramas based two cylindrical panoramas project disparity values locations given viewing position however explicit 3d reconstruction approach similar mcmillan bishop 1995 composite rotated camera views panoramas well however going step reconstructing 3d feature points modeling scene based upon recovered points use multiple panoramas accurate 3d reconstruction 3 overview approach 3 omnidirectional multibaseline stereo recovered 3d scene points modeled scene figure 1 generating scene model multiple 360 ffi panoramic views 3 overview approach ultimate goal generate photorealistic model used variety scenarios interested providing simple means generating models also wish minimize use cad packages means 3d model generation since effort laborintensive addition impose requirement means generating models real scene done using commercially available equipment case use workstation framegrabber realtime image digitizer commercially available 8mm camcorder approach straightforward camera location scene capture sequences images rotating camera vertical axis passing camera optical center composite set images produce panoramas camera location use stereo extract 3d data scene finally model scene using 3d data input render texture provided input 2d image approach summarized figure 1 using panoramic images extract 3d data covering wide field view thus bypassing need numerous depth map merging multiple depth map merging computationally intensive resulting merged depth maps may subject merging errors especially relative poses depth maps known exactly 3d data may also resampled merging adds additional complexity potential sources figure 2 compositing multiple rotated camera views panorama theta marks indicate locations camera optical rotation center errors using multiple camera locations stereo analysis significantly reduces number ambiguous matches also effect reducing errors averaging okutomi kanade 1993 kang et al 1995b especially important images wide fields view depth recovery unreliable near epipoles 1 looming effect takes place resulting poor depth cues 4 extraction panoramic images panoramic image created compositing series rotated camera image images shown figure 2 order create panoramic image first ensure camera rotating axis passing optical center ie must eliminate motion parallax panning camera around achieve manually adjust position camera relative xy precision stage mounted tripod motion parallax effect disappears camera rotated back forth vertical axis stein 1995 prior image capture scene calibrate camera compute intrinsic camera parameters specifically focal length f aspect ratio r radial distortion coefficient camera calibrated taking multiple snapshots planar dot pattern grid known depth separation successive snapshots use iterative leastsquares algorithm levenberg 1 pair images taken two different locations epipoles location image planes intersection image planes line joining two camera optical centers excellent description stereo vision given faugeras 1993 image 1 image 2 image n1 image n figure 3 example undistorted image sequence office marquardt estimate camera intrinsic extrinsic parameters except szeliski kang 1994 determined using 1d search brents parabolic interpolation 1d press et al 1992 leastsquares algorithm black box steps involved extracting panoramic scene follow ffl camera location capture sequence panning camera around 360 ffi ffl using intrinsic camera parameters correct image sequence r aspect ratio radial distortion coefficient ffl convert r corrected 2d flat image sequence cylindrical coordinates focal length f crosssectional radius example sequence corrected images office shown figure 3 ffl composite images xdirectional dof equivalent motion angular dimension cylindrical image space yield desired panorama szeliski 1994 relative displacement one frame next coarsely determined using phase correlation kuglin hines 1975 technique estimates 2d translation pair images taking 2d fourier transforms images computing phase difference frequency performing inverse fourier transform searching peak magnitude image subsequently image translation refined using local image registration directly comparing overlapped regions two images szeliski 1994 ffl correct slight errors resulting length theory equals 2f propagating residual displacement error equally across images recompositing error length usually within percent expected length 6 5 recovery epipolar geometry figure 4 panorama office scene compositing example panoramic image created office scene figure 3 shown figure 4 5 recovery epipolar geometry order extract 3d data given set panoramic images first know relative positions camera corresponding panoramic images calibrated camera equivalent determining epipolar geometry reference panoramic image every panoramic image epipolar geometry dictates epipolar constraint refers locus possible image projections one image given image point another image planar image planes epipolar constraint form straight lines interested reader referred faugeras 1993 details use 8point algorithm longuethiggins 1981 hartley 1995 extract called essential matrix yields relative camera placement epipolar geometry done pairwise namely reference panoramic image another panoramic image however four possible solutions hartley 1995 solution yields positive projections ie projections away camera optical centers chosen 51 8point algorithm basics briefly review 8point algorithm camera calibrated ie intrinsic parameters known two corresponding image points two different camera placements 3d 51 8point algorithm basics 7 matrix e called essential matrix form r r rotation matrix translation vectors respectively theta matrix form cross product camera calibrated general relation two corresponding image points image plane u v 1 namely f called fundamental matrix also rank 2 arbitrary 3 theta 3 matrix fundamental matrix generalization essential matrix e usually employed establish epipolar geometry recover projective depth faugeras 1992 shashua 1994 case since know camera parameters recover e let e vector comprising ijth element e point matches 1 get set linear equations form number input points small output algorithm sensitive noise hand turns normalizing 3d point location vector cylindrical image reduces sensitivity 8point algorithm noise similar spirit hartleys application isotropic scaling hartley 1995 prior using 8point algorithm 3d cylindrical points normalized according relation n panoramic images solve sets linear equations form 4 kth set corresponds panoramic image pair 1 1 notice solution e defined unknown scale work measure distance camera positions enable us recover scale however relax assumption carrying following steps recovery epipolar geometry ffl fix camera distance first pair pair 1 say unit distance assign camera distances pairs first ffl calculate essential matrices pairs panoramic images assuming unit camera distances ffl pair compute 3d points ffl estimate relative distances camera positions pair j 6 1 ie first pair find scale 3d points corresponding pair j minimizes distance error corresponding pair 1 robust statistics used reject outliers specifically best 50 used 52 tracking features 8point algorithm 8point algorithm assumes feature point correspondences available feature tracking challenge purely local tracking fails displacement large order 100 pixels direction camera motion approach adopted comprises splinebased tracking attempts globally minimize image intensity differences yields estimates optic flow turn used local tracker refine amount feature displacement optic flow pair cylindrical panoramic images first estimated using splinebased image registration pair szeliski coughlan 1994 szeliski et al 1995 image registration approach displacement fields ux vx ie displacements x directions functions pixel location represented twodimensional splines controlled smaller number displacement estimates lie coarser spline control grid initial optic flow found best candidates tracking chosen choice based minimum eigenvalue local hessian indication local image texturedness subsequently using initial optic flow estimate displacement field use shitomasi tracker shi tomasi 1994 window size 25 pixels theta 25 pixels refine displacements chosen point features use approach applying splinebased tracker using shitomasi tracker approach used take advantage complementary characteristics two trackers namely 1 splinebased image registration technique capable tracking features larger dis placements done coarsetofine image registration work use 6 levels resolution technique generally results good tracks subpixel accu racy szeliski et al 1995 poor tracks may result areas vicinity object occlu sionsdisocclusions 2 shitomasi tracker local tracker fails large displacements performs better small number frames relatively small displacements deteriorates large numbers frames presence rotation image plane szeliski et al 1995 considering small number frames time image warping due local image plane rotation expected shitomasi tracker also capable subpixel accuracy approach undertaken object tracking thought finetofiner tracking approach addition feature displacements measure reliability tracks available according match errors local texturedness latter indicated minimum eigenvalue local hessian shi tomasi 1994 szeliski et al 1995 well see later section 81 used cull possibly bad tracks improve 3d estimates extracted point feature tracks proceed recover 3d positions corresponding feature tracks 3d data recovery based simple notion stereo 6 omnidirectional multibaseline stereo idea extracting 3d data simultaneously theoretically sufficient number two camera views founded two simple tenets statistical robustness redundancy disambiguation matches due overconstraints okutomi kanade 1993 kang et al 1995b notion using multiple camera views even critical using panoramic images taken vertical height results epipoles falling within images two panoramic images used points close epipoles reliable also important note problem persist multiple panoramic images taken camera positions collinear experiments described section 8 camera positions deliberately arranged positions collinear addition images taken vertical height maximize view overlap panoramic images use three related approaches reconstruct 3d multiple panoramic images 3d data recovery done either 1 using 8point algorithm tracks directly recovering 3d points 2 proceeding iterative leastsquares method refine camera pose 3d feature location 3 going step impose epipolar constraints performing full multiframe stereo reconstruction first approach termed unconstrained tracking 3d data merging second approach iterative structure motion third approach named constrained depth recovery using epipolar geometry 61 reconstruction method 1 unconstrained feature tracking 3d data merging approach use tracked feature points across panoramic images apply 8 point algorithm extracted essential matrix camera relative poses directly estimate 3d positions sets 2d image data used determine pairwise essential matrix recovery essential matrix turns reasonably stable due large 360 ffi field view problem 8point algorithm optimization occurs function space image space ie minimizing error distance 2d image point corresponding epipolar line deriche et al deriche et al 1994 use robust regression method called leastmedian ofsquares minimize distance error expected estimated fundamental matrix given 2d image points found extracting essential matrix using 8point algorithm relatively stable long 1 number points large least hundreds 2 points well distributed field view approach use set data recover euclidean shape theory recovered positions true scale since distance camera locations known measured able get true scale recovered shape note however approach critical upon knowing camera distances indicated section 51 let u ik ith point image k v ik unit vector optical center panoramic image point 3d space ik corresponding line passing optical center panoramic image point space k camera translation associated kth panoramic image note 0 equation line ik r thus point 62 reconstruction method 2 iterative panoramic structure motion 11 constrained lie line i1 minimize error function n number panoramic images taking partial derivatives e respect equating zero solving get reconstructed 3d point calculated using relation p v i1 note optimal manner estimating 3d point minimize expression detailed derivation involving 8 given appendix however due practical consideration texturemapping recovered 3d mesh estimated point distribution projection estimated 3d point coincide 2d image location reference image justified saying since feature tracks originate reference image reasonable assume uncertainty feature location reference image immediate problem approach feature tracking data merging reliance tracking makes relatively sensitive tracking errors inherits problems associated tracking aperture problem sensitivity changing amounts object distortion different viewpoints however problem mitigated number sampled points large addition advantage need specify minimum maximum depths resolution associated multibaseline stereo depth search eg see okutomi kanade 1993 kang et al 1995b points extracted directly analytically correspondence established 62 reconstruction method 2 iterative panoramic structure motion 8point algorithm recovers camera motion parameters directly panoramic tracks corresponding 3d points computed however camera motion parameters may optimally recovered even though experiments hartley using narrow view images indicate motion parameters close optimal hartley 1995 using output omnidirectional multibaseline stereo 8point algorithm recovered 3d data apply iterative leastsquares minimization refine camera motion 3d positions simultaneously similar work done szeliski kang structure motion using multiple narrow camera views szeliski kang 1994 input reconstruction method use 3d normalized locations cylindrical image point equation linking 3d normalized cylindrical image position u ij frame j 3d position track index r k p projection transformation r k k rotation matrix translation vector respectively associated relative pose jth camera represent rotation quaternion corresponding rotation matrix alternative representations rotations discussed ayache 1991 projection equation given simply x x words 3d points projected onto surface 3d unit sphere solve structure motion parameters simultaneously use iterative levenbergmarquardt algorithm levenbergmarquardt method standard nonlinear least squares technique press et al 1992 works well wide range situations provides way vary smoothly inversehessian method steepest descent method merit objective function minimize f given 9 63 reconstruction method 3 constrained depth recovery using epipolar geometry 13 vector structure motion parameters determine image point frame j weight c ij 12 describes confidence measurement u ij normally set inverse variance oe gamma2 ij set levenbergmarquardt algorithm first forms approximate hessian matrix weighted gradient vector image plane error point frame j given current estimate computes increment ffia towards local minimum solving stabilizing factor varies time press et al 1992 note matrix approximation hessian matrix secondderivative terms left mentioned press et al 1992 inclusion terms destabilizing model fits badly contaminated outlier points compute required derivatives 14 15 compute derivatives respect fundamental operations perspective projection rotation translation apply chain rule equations basic derivatives given appendix b derivation exactly szeliski kang 1994 except projection equation 63 reconstruction method 3 constrained depth recovery using epipolar ge ometry result first reconstruction methods reliance tracking suffers aperture problem hence limited number reliable points approach using epipolar geometry limit search designed reduce severity problem given epipolar geometry 14 8 experimental results image point reference panoramic image constrained search performed along line sight image point subsequently position along line results minimum match error projected image coordinates corresponding viewpoints chosen using approach results denser depth map due epipolar constraint constrain reduces aperture problem search theoretically occurs direction ambiguity along epipolar line interest principle described kang et al 1995b approach mitigates problem aperture problem suffers much higher computational demand addition recovered epipolar geometry still dependent output quality 8point algorithm turn depends quality tracking user also specify minimum maximum depths well resolution depth search alternative working cylindrical coordinates project sections cylinder tangential rectilinear image plane rectify use rectified planes multibaseline stereo mitigates computational demand search restricted horizontal scanlines rectified images however major problem scheme reprojecting rectilinear coordinates rectifying problematical due increasing distortion away new center projection creates problem matching using window fixed size result scheme reprojecting rectilinear coordinates rectifying used 7 stereo data segmentation modeling 3d stereo data extracted model 3d mesh texturemap face associated part 2d image panorama done work reduce complexity resulting 3d mesh planar patch fitting boundary simplification displayed models shown paper rendered using modeling system detailed description model extraction range data given kang et al 1995a 8 experimental results section present results applying approach recover 3d data multiple panoramic images used synthetic real images test approach mentioned 81 synthetic scene 15 figure 5 panorama synthetic room compositing earlier experiments described section camera positions deliberately arranged positions collinear addition images taken vertical height maximize overlap panoramic images 81 synthetic scene synthetic scene room comprising objects tables tori cylinders vases one half room textured mandrill image textured regular brodatz pat tern synthetic objects images created using rayshade program creating raytraced color images kolb 1994 synthetic images created free radial distor tion since rayshade currently unable model camera characteristic omnidirectional synthetic depth map entire room created merging depth maps associated multiple views taken around inside room composite panoramic view synthetic room center shown figure 5 left right observe vases resting table vertical cylinders torus resting table larger torus results applying reconstruction methods ie unconstrained search 8point constrained search using epipolar geometry seen figure 6 get many points using constrained search 3 times quality 3d reconstruction appears degraded compare figure 6b c part due matching occurring integral values pixel positions limiting depth resolution dimensions synthetic room 10length theta 8width theta 6height specified resolution 001 quality recovered 3d data appears enhanced applying 3d median filter 2 however median 2 median filter works following manner feature point cylindrical panoramic image find feature points within certain neighborhood radius 20 case sort 3d depths associated neighborhood feature points find median depth rescale depth associated current feature point new depth median depth illustration suppose original 3d feature location v original depth v 3d unit vector camera center direction image point med results correct distribution b unconstrained 8point c iterative constrained search medianfiltered f medianfiltered g medianfiltered h top view 8point iterative constrained 3d mesh e figure comparison 3d points recovered synthetic room filter also effect rounding corners mesh figure 6f three views figure 7 generated 3d modeling system described kang et al 1995a seen figures 3d recovered points subsequent model based points basically preserved shape synthetic room addition performed series experiments examine effect bad track removal median filtering quality recovered depth information synthetic room feature tracks sorted increasing order according error matching 3 continually median depth within neighborhood filtered 3d feature location given v 0 med v 3 note general worse track sense need necessarily translate worse 3d estimate high 81 synthetic scene 17 view 1 b view 2 b view 3 figure 7 three views modeled synthetic room figure 6h remove tracks worst amount match error recovering 3d point distribution instant graph figure 8 see interesting result tracks taken retaining better ones quality 3d point recovery improvesup point improvement accuracy surprising since worse tracks likely result worse 3d esti mates removed however tracks removed gap amount accuracy demanded tracks given increasingly smaller number available tracks track accuracy available grows results generally worse estimates epipolar ge ometry hence 3d data concomitant reduction number points sensitivity recovery epipolar geometry form essential matrix 3d data evidenced fluctuation curves lower end graph another interesting result observed 3d point distribution median filtered lower errors especially higher numbers recovered 3d points indicated graph figure 8 accuracy point distribution derived 8point algorithm almost equivalent using iterative leastsquares levenberg marquardt minimization statistically optimal near true solution result agreement hartleys application 8point algorithm narrowangle images hartley 1995 also worth noting accuracy iterative algorithm best smaller numbers input points suggesting stable given smaller number input data table 1 lists 3d errors constrained unconstrained 8point methods synthetic scenes appears result constrained method yields better results match error may due apparent object distortion different viewpoints percent total points030040 rms error 8point known camera distance 8point unknown camera distance iterative medianfiltered 8point known camera distance medianfiltered 8point unknown camera distance medianfiltered iterative figure 8 3d rms error vs number points original number points corresponding 100 3057 dimensions synthetic room 10length theta 8width theta 6height original 0315039 0393777 0302287 medianfiltered 0266600 0364889 0288079 table 1 comparison 3d rms error unconstrained constrained stereo results n number points 82 real scenes 19 median filtered points result reducing aperture problem practice shall see next section problems due misestimation camera intrinsic parameters specifically focal length aspect ratio radial distortion coefficient causes 3d reconstruction real images worse subject ongoing research 82 real scenes setup used record image sequences consists dec alpha workstation j300 framegrabber camcorder sony handycam ccdtr81 mounted xy position stage affixed tripod stand camcorder settings made field view maximized 43 ffi reiterate method generating panoramic images follows ffl calibrate camcorder using iterative levenbergmarquardt leastsquares algorithm szeliski kang 1994 ffl adjust xy position stage panning camera left right remove effect motion parallax ensures camera rotated optical center ffl camera location record onto tape image sequence rotating camera digitize image sequence using framegrabber ffl using recovered camera intrinsic parameters focal length aspect ratio radial distortion undistort image ffl project image rectilinear image coordinates cylindrical coordinates whose crosssectional radius camera focal length ffl composite frames panoramic image number frames used extract panoramic image experiments typically 50 recorded image sequences two scenes namely office scene lab scene panoramic image office scene shown figure 4 extracted four panoramic images corresponding four different locations office spacing locations 6 inches locations roughly corners square size office 10 feet 15 feet results 3d point recovery office scene shown figure 9 three sample experimental results views model shown figure 10 seen figure 9 results due constrained search approach looks much worse may directly attributed inaccuracy extracted intrinsic camera parameters consequence composited panoramas may actually exactly physically correct fact matching epipolar constraint progress observed actual correct matches exactly along epipolar lines slight vertical drifts generally order one two pixels another example real scene shown figure 11 total eight panoramas eight different locations 3 inches apart ordered roughly zigzag fashion lab extracted longest dimensions lshaped lab 15 feet 225 feet 3d point distribution shown figure 12 figure 13 shows three views recovered model lab seen shape lab reasonably well recovered noise points bottom figure 12a corresponds positions outside laboratory since parts transparent laboratory window covered reveals one weaknesses correlationbased algorithm namely stereo algorithms work well image reflections transparent material observe points recovered using constrained search worse errors observed real scene images especially constrained search due following practical problems ffl autoiris feature camcorder used cannot deactivated even though focal length kept constant result may fact slight variations focal length camera rotated ffl camera may rotating exactly optical center since adjustment xy position stage done manually may human error judging absence motion parallax ffl camera may rotating unique axis way around assumed ver tical due play unevenness tripod ffl digitization problems images digitized tape ie camcorder playing tape contain scan lines occasionally horizontally shifted probably caused degraded blanking signal properly detected framegrabber ever compositing many images averages artifacts 82 real scenes 21 unconstrained 8point b medianfiltered version c iterative medianfiltered version c constrained search f medianfiltered version e g 3d mesh b figure 9 extracted 3d points mesh office scene notice recovered distributions shown c appear rectangular shown b view 1 b view 2 b view 3 figure 10 three views modeled office scene figure 9g figure 11 panorama laboratory compositing ffl extracted camera intrinsic parameters may precise result problems encountered resulting composited panorama may physically correct especially causes problems constrained search given estimated epipolar geometry essential matrix actually widened search little allowing search much couple pixels away epipolar line however significantly increases computational demand effect loosening constraints making approach less attractive 9 discussion conclusions shown omnidirectional depth data whose denseness depends amount local texture extracted using set simple techniques camera calibration image compositing feature tracking 8point algorithm constrained search using recovered epipolar geom etry advantage work able extract depth data within wide field view simultaneously removes many traditional problems associated recovering camera pose narrowbaseline stereo despite practical problems caused using unsophisticated equipment result slightly incorrect panoramas still able extract reasonable 3d data thus far best real data results come using unconstrained tracking 8point al unconstrained b medianfiltered c iterative 8point version medianfiltered e constrained f medianfiltered version c search version e g 3d mesh b figure 12 extracted 3d points mesh laboratory scene view 1 b view 2 b view 3 figure 13 three views modeled laboratory scene figure 12g gorithm direct iterative structure motion results also indicate application 3d median filtering improves accuracy appearance stereocomputed 3d point distribution expedite panorama image production critical applications require close realtime modeling special camera equipment may called one possible specialized equipment ahujas camera system reported freedman 1995 lens rotated relative imaging plane however currently putting emphasis use commercially available equipment cheap camcorder even practical problems associated imperfect data acquisition solved still fundamental problem stereothat inability match extract 3d data textureless regions scenes involve mostly textureless components bare walls objects special pattern projectors may need used conjunction camera kang et al 1995b currently omnidirectional data obtained 360 ffi view limited vertical view plan extend work merging multiple omnidirectional data obtained different heights different locations also look possibility extracting panoramas larger height extents incorporating tilted ie rotated horizontal axis camera views would enable scene reconstruction building floor involving multiple rooms good vertical view currently characterizing effects misestimated intrinsic camera parameters focal length aspect ratio radial distortion factor accuracy recovered 3d data optimal point intersection 25 summary set methods reconstructing 3d scene points within wide field view shown quite robust accurate wideangle reconstruction 3d scenes conventionally achieved merging multiple range images methods demonstrated attractive alternative wideangle 3d scene model recovery addition methods require specialized camera equipment thus making commercialization technology easier direct strongly feel development significant one toward attaining goal creating photorealistic 3d scenes minimum human intervention acknowledgments would like thank andrew johnson use 3d modeling rendering program richard weiss helpful discussions optimal point intersection order find point closest rays whose line equations form minimize expression p optimal point intersection determined taking partials e respect k p equating zero solving k 18 noting substituting k 19 yields perpendicular projection operator ray point along viewing ray closest origin thus optimal intersection point bundle rays computed weighted sum adjusted camera centers indicated k weighting direction perpendicular viewing ray optimal estimate found minimizing formula respect p k weighting squared perpendicular distance gamma2 k downweighting points away camera justification formula uncertainty direction defines conical region uncertainty space centered cam era ie uncertainty point location hence inverse weight grows linearly k however implementing minimization requires interative nonlinear solver elemental transform derivatives derivative projection function 11 respect 3d arguments internal parameters straightforward x gammaxy gammaxz gammayz 3the derivatives elemental rigid transformation x z 0 gammax gammay x 0c c c see shabana 1989 derivatives screen coordinate respect motion structure parameter computed applying chain rule set equations r artificial vision mobile robots stereo vision multisensory perception computational stereo robust recovery epipolar geometry uncalibrated stereo rig seen three dimensions uncalibrated stereo rig integrating information multiple views camera near defence 8point algorithm building 3d models unregistered range images extraction concise realistic 3d models real data multibaseline stereo system active illumination realtime image acquisition rayshade users guide reference manual phase correlation image alignment method computer algorithm reconstructing scene two projections plenoptic modeling imagebased rendering system recovering range using virtual multicamera stereo multiple baseline stereo numerical recipes c art scientific computing dynamics multibody systems projective structure uncalibrated images structure motion recognition good features track principal component analysis missing data application object modeling accurate internal camera calibration using rotation image mosaicing telereality applications hierarchical splinebased image reg istration recovering 3d shape motion image streams using nonlinear least squares parallel feature tracker extended image sequences tr ctr yin li heungyeung shum chikeung tang richard szeliski stereo reconstruction multiperspective panoramas ieee transactions pattern analysis machine intelligence v26 n1 p4562 january 2004 r hicks pettey k daniilidis r bajcsy closed form solutions reconstruction via complex analysis journal mathematical imaging vision v13 n1 p5770 august 2000 srikumar ramalingam suresh k lodha peter sturm generic structurefrommotion framework computer vision image understanding v103 n3 p218228 september 2006 nelson l chang avideh zakhor constructing multivalued representation view synthesis international journal computer vision v45 n2 p157190 november 2001