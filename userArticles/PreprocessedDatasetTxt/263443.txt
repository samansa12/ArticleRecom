bias robust estimation caused discontinuities multiple structures abstractwhen fitting models data containing multiple structures fitting surface patches data taken neighborhood includes range discontinuity robust estimators must tolerate gross outliers pseudo outliers pseudo outliers outliers structure interest inliers different structure differ gross outliers coherence data occurs frequently computer vision problems including motion estimation model fitting range data analysis focus paper problem fitting surfaces near discontinuities range datato characterize performance least median squares least trimmed squares mestimators hough transforms ransac minpran type data pseudo outlier bias metric developed using techniques robust statistics literature used study error robust fits caused distributions modeling various types discontinuities results show robust estimator biased small substantial discontinuities also show circumstances different estimators effective importantly results imply present estimators used care new estimators developed b introduction robust estimation techniques used increasing frequency computer vision applications proven effective tolerating gross errors outliers characteristic sensors lowlevel vision algorithms often robust estimators used fitting model parameters eg coefficients either polynomial surface affine motion model pose estimate fundamental matrix data set applications robust estimators work reliably data contain measurements single structure single surface plus gross errors sometimes however data complicated presenting challenge robust estimators anticipated robust statistics literature complication occurs data measurements multiple structures still corrupted gross outliers structures may different surfaces depth measurements multiple moving objects motion estimation difficulty arises robust estimators designed extract single fit thus estimate accurate parameters modeling one structures one important must treat points structures outliers successfully estimating fit parameters one structure robust estimator may reapplied desired estimate subsequent fits removing first fits inliers data example using synthetic range data illustrates potential problems caused multiple structures figure 1 shows nonrobust linear leastsquares fits data single surface data pair surfaces forming step discontinuity single surface example leastsquares fit skewed slightly gross outliers points surface still generally closer fit outliers thus fit estimated robust version leastsquares significantly corrupted outliers multiple surface example leastsquares fit skewed much crosses bridges point sets surfaces placing fit close proximity point sets since robust estimators use fit proximity distinguish inliers outliers downgrade influence outliers raises two concerns accuracy robust fits first estimator iteratively refines initial least squares fit local potentially b figure 1 examples demonstrating effects gross outliers b gross outliers data multiple structures linear leastsquares fits global minimum fit far initial skewed fit points surfaces small large residuals making difficult estimator pull away one surfaces second important robust estimate correct fit thereby treating points one surface inliers points outliers estimators objective function must lower smaller inlier set correct fit larger inlier set bridging fit varying proximity two surfaces relative sizes point sets robust estimators studied made fail data producing fits heavily skewed motivated foregoing discussion goal paper study effectively robust estimators estimate fit parameters given mixture data multiple struc tures stating pseudo outliers problem abstractly obtain accurate fit robust technique must tolerate two different types outliers gross outliers pseudo outliers gross outliers bad measurements may arise specularities boundary effects physical imperfections sensors errors lowlevel vision computations edge detection matching algorithms pseudo outliers measurements one additional structures without losing generality inliers pseudo outliers distinguished assuming inliers points structure contributing points pseudo outliers points structures coherence pseudo outliers distinguishes gross outliers data multiple structures common vision ap plications robust estimators performance type data must understood use effectively prove ineffective new perhaps complicated robust techniques needed 1 study pseudo outliers problem paper develops measure pseudo outlier bias using tools robust statistics literature 10 pages 8195 12 page 11 pseudo outlier bias measure distance robust estimators fit target distribution fit outlier corrupted distribution target distribution model distribution points drawn single structure without outliers outlier corrupted mixture distribution 27 combine distributions modeling different structures gross outlier distribution optimal fit found applying functional form estimator distributions rather applying estimators standard form particular sets points generated distributions gives theoretical mea sure avoids need extensive simulations importantly shows inherent limitations robust estimators studying objective functions independent search techniques bias number estimators mestimators 12 chapter 7 least median squares lms 16 21 least trimmed squares lts 21 hough transforms 13 ransac 7 minpran 26 studied target mixture distributions vary application studying pseudo outliers problem fitting surfaces range data taken neighborhood surface discontinuity simple application studying pseudo outliers problem problem certainly arises applications well essentially application data could contain multiple structures results obtained used qualitative predictions potential difficulties applications context range data application three idealized discontinuity models used develop mixture distributions step edges crease edges parallel surfaces step edges model depth discontinuities points upper surface step pseudo outliers lower surface crease edges model surface orientation discontinuities points one side crease pseudo outliers versions techniques actually exist fitting surfaces range data effectiveness however depends part accuracy initial set robust fits finally parallel surfaces model transparent semitransparent surfaces background surface appears breaks foreground surface data background pseudo outliers foreground final introductory comment important assist reading paper paper defines notion pseudo outlier bias using techniques common mathematical statistics computer vision importantly functional form robust estimator intuitive meaning functional forms use pseudo outlier bias discussed start section 4 proceeds main derivations readers uninterested mathematical details able skip sections 42 46 still follow analysis results robust estimators section defines robust estimators studied definitions converted functional forms suitable analysis section 4 goal paper expose inherent limitations robust estimators focus defining estimators objective functions rather optimization techniques special cases iterative optimization techniques local minima potentially problematic discussed appropriate data x image coordinate vector independent vari ables z range value dependent variable fit function z x often restricted class linear quadratic polynomials notation x indicates fit minimizes estimators objective function called estimate esti mators objective function evaluates hypothesized fits x via residuals r 21 mestimators regression mestimate 12 chapter 7 aer oe 1 oe estimate true scale noise term oe aeu robust loss function grows subquadratically large juj reduce effect outliers often discussed oe estimated jointly mestimators categorized three types 11 behavior one estimator type studied monotone mestimators figure 2a hubers 12 chapter 7 nondecreasing bounded u functions hard redescenders figure 2b hampels 9 10 page 150 force hence c rejection point beyond residual influence soft redescenders figure 2c maximum likelihood estimator students tdistribution 5 finite rejection point force u 0 juj 1 three robust loss functions shown figure 2 order 2 ae h ae ae functions constants usually set optimize asymptotic efficiency relative given target distribution 11 eg gaussian residuals mestimators typically minimize using iterative techniques 11 12 chapter 7 objective functions hard soft redescending mestimators nonconvex may multiple local minima general oe must estimated data hardredescending mestimators often use median absolute deviation mad 11 computed residuals initial fit monotone hard soft aeu b c figure 2 aeu u functions three mestimators consistency normal distribution students tdistribution mestimators jointly estimate oe oe aer particular huber 12 chapter 7 uses oe equation 2 tuning parameter mirza boyer 5 use ae r oe equation 4 fitting surfaces range data different option obtaining oe often used 3 oe depends properties sensor oe may estimated fixed data sets theoretically oe fixed mestimators described equation 1 longer true mestimators since scale equivariant 10 page 259 reflect oe fixed priori called fixedscale mestimators standard mestimators fixedscale mestimators studied 22 fixedband techniques hough transforms ransac hough transforms 13 ransac 4 7 roths primitive extractor 20 examples fixedband techniques 20 techniques fit maximizing number points within sigma r b r b inlier bound generally depends oe ie r constant c equivalently viewing fixedband techniques minimizing number outliers become special case fixedscale mestimators simple discontinuous loss function ae f fixedband techniques search using either random sampling voting techniques 23 lms lts least median squares lms introduced rousseeuw 21 finds fit minimizing median squared residuals see 16 review specifically lms estimate fmedian implementations lms use random sampling techniques find approximate minimum related lms also introduced rousseeuw 21 least trimmed squares estimator lts lts estimate r 2 nondecreasing ordered squared residuals fit usually implementations also use random sampling 24 minpran minpran searches fit minimizing probability fit collection inliers fit could due gross outliers 24 26 derived assuming relative hypothesized fit x residuals gross outliers uniformly distributed 2 range sigmaz 0 based assumption probability particular gross outlier could within x furthermore n points gross outliers probability k could within x sigma r given n data points containing unknown number gross outliers minpran evaluates hypothesized fits x finding inlier bound r associated number points inliers k r within sigmar x minimizing probability inliers could actually gross outliers thus minprans objective function evaluating particular fit min r minprans estimate min r minpran implemented using random sampling techniques see 26 modeling discontinuities important first step developing pseudo outlier bias analysis technique model data taken near discontinuity probability distribution attention restricted discontinuities onedimensional structures since sufficient demonstrate limitations robust estimators 31 outlier distributions set context developing distributions modeling discontinuities consider one dimensional outlier corrupted distributions used statistics literature study robust location estimators 10 page 97 12 page 11 2 minpran generalized known outlier distribution 26 z x x figure 3 example data set points near step discontinuity f 1 inlier distribution also called target distribution unit variance gaussian g outlier distribution large variance gaussian uniform distribution large interval parameter outlier proportion set n points sampled distribution contain average n outliers robust location estimators analyzed using distribution f rather using series point sets sampled f 32 mixture distributions modeling discontinuities present paper analyzes robust regression estimators examining behavior distributions modeling discontinuities mixture distributions 27 form inlier pseudo outlier gross outlier distributions respectively control proportion points drawn three distributions set data points taken vicinity discontinuity example might points figure 3 whose x coordinate falls interval x modeled twodimensional distribution points x z x values interval x losing generality points left side discontinuity location right using twodimensional distribution could counterintuitive since x values may thought image positions depth measurements made usually fixed x treated uniform interval x modeling uniform spacing image positions 3 depth measurement inlier z fi 1 xe e independent noise controlled gaussian density ge oe 2 mean 0 variance oe 2 fi 1 x models ideal curve inliers measured pseudo outlier distribution h 2 defined similarly x values uniform x distributions h 1 h 2 densities x z combined give joint density 0 otherwise bound uniform distribution x interval distribution gross outliers x values uniformly distributed time entire interval x z values governed density g z uniform large range gives joint density gross outlier 0 otherwise mixture proportions 14 easily specified fraction gross outliers relative fraction inliers ie fraction points gross outliers inlier side discontinuity assuming density x values change across discontinuity determined x equivalently inliers pseudo outliers notice actual fraction inliers depending estimator analyzed either relative actual fraction important 3 point set sampled distribution x values uniformly spaced general expected values expected behavior captured using distribution analysis rather points sets sampled distribution using mixture proportions densities combined single mixed twodimensional density observe target density h 1 x z target distribution h 1 x z mixture distribution hx z target distribution h 1 x z calculated hx z h 1 x z respectively using mixture density hx z data generated form step edges crease edges appropriate model determined two curve functions fi 1 fi 2 example step edge height deltaz modeled setting fi 1 c crease edge modeled fi 1 fi 2 linear functions lines overlapping x domains created using fi 1 fi 2 step edges setting x proportion points lower line case mixture proportions divorced location discontinuity meaning thus three desired discontinuities modeled 4 functional forms mixture models analyze estimators distributions h estimator must rewritten functional mapping space probability distributions space possible estimates section derives functional forms robust estimators defined section 2 starts section 41 giving intuitive insight section 42 introduces functional forms empirical distributions technical level using univariate leastsquares location estimates example next section 43 derives several important distributions needed functionals remaining sections derive required functionals readers uninterested technical details read section 41 skip ahead section 5 41 intuition illustrate means functional applied distribution h consider leastsquares regression applied set containing points objective function proportional second moment residuals conditioned least squares estimate fit minimizing conditional second moment similar second moment conditioned may calculated distribution hx z fit minimizing conditional second moment may found leastsquares regression functional functional form mestimator analogy returns fit minimizing robust version second moment conditional residual distribution calculated h intuitions functional forms estimators similar estimate h used represent characterize estimators performance point sets sampled h although robust fit particular point set may differ h h skewed pseudo gross outliers fit point set likely skewed well indeed estimators minimization technique iterative search skew may worse h may stop local minimum 42 onedimensional location estimators introduce functional forms technical level section examines leastsquares location estimate univariate data finite sample fx g location estimate n sample mean expected value functional form location estimate distribution f x drawn z z z population mean expected value functional form location estimate derived sample location estimate writing latter terms empirical distribution data denoted f n replacing f n f actual distribution empirical density fx ffidelta dirac delta function empirical distribution udelta unit step function x independent identically dis converges f n 1 least squares location estimate written terms empirical density using sifting property delta function 8 page 56 argmin n n z z z replacing f n population density yields functional form location estimate desired 20 43 residual distributions empirical distributions deriving functional forms robust regression estimators mixture distribution hx z must rewritten terms distribution residuals relative hypothesized fit estimators objective functions depend directly residuals r indirectly points x z addition several empirical versions residual distribution needed two different residual distributions required one signed residuals one absolute values let distribution density signed residuals f rj h including h notation make explicit dependence mixture distribution easily seen figure 4a f z xr b figure 4 cumulative distribution residual r relative fit x integral point densities h 1 h 2 curves gross outlier density h region bounded x bounded sides unbounded signed residuals b bounded x gamma r absolute residuals figures show region integration functions fi x boundaries modeling step edge let distribution density absolute residuals f rj h f rj h r 0 figure 4b f z xr f appendix evaluates integrals replacing h h 1 equations yields residual distributions densities target inlier distribution several empirical distributions needed first given n points sampled hx z empirical density data simply confused h equation 15 next empirical density signed residuals follows h n x z using sifting property ffi function 8 page 56 gamma1n n finally empirical distribution absolute residuals f z r gammar 44 mestimators fixedband techniques functionals robust regression estimators derived starting fixedscale mestimators first step write equation 1 slightly modified form change estimate n aer oe next writing terms empirical distribution produces argmin n aer n n zz zz replacing empirical density h n x z mixture density hx z yields ae zz change variables simplifies things ae z aeroe z z fixedscale mestimator functional substituting equations 2 3 4 gives respectively mestimators studied mestimators jointly estimate oe see equations 7 8 functional obtained replacing aeroe aer oe equation 27 producing aes z finally recalling fixedband techniques special cases fixedscale mestimators functional obtained substituting equation 9 equation 27 yielding b observe 1 gamma f r b j h expected fraction outliers 45 lms lts deriving functional equivalent lms requires first deriving cumulative distribution squared residuals writing median terms inverse distribution defining empirical distribution squared residuals f ny since simply percentage points whose absolute residuals relative fit less ny 12j h 30 words median inverse cumulative evaluated 12 4 standard functional form median 10 page 89 substituting equation 4 lms implemented using random sampling p points chosen instantiate fit median residual taken among remaining points reflect 12 equation could replaced n replacing empirical distribution f ny f produces lms turning lts normalizing objective function writing terms empirical density residuals yieldsn z rm ny 12j h n empirical median square residual functional form lts easily written gammaf 46 minpran minprans functional derived first rewriting minprans objective function replacing binomial distribution incomplete beta function 19 page 229 min r gammavgammaw z pt gammadelta gamma function done iv w p requires v w 2 binomial distribution requires integer values k r n since f empirical distribution absolute residuals see equation 26 k objective function rewritten equivalently min r delta f replacing f n f substituting equation 13 gives functional min r observe n number points still required tm h considered functional 10 page 40 5 pseudo outlier bias functional forms robust estimators derived pseudo outlier bias metric defined given particular mixture distribution hx z target distribution fits assumed minimize estimators objective functional globally pseudo outlier bias defined normalized l 2 distance fits oe 12 easily shown metric invariant translation independent scaling x z fixedscale mestimators oe provided priori must scaled well minpran outlier distribution must scaled appropriately set possible curves x includes fi 1 x shown functionals derived section 4 words estimators objective function minimized fi 1 5 pseudo outlier bias metric becomes oe 12 intuitively pseudo outlier bias measures l 2 norm distance two estimates h h 1 normalized length x interval hx z nonzero standard deviation noise z values since h 1 cases studied metric value 0 implies corrupted presence either gross pseudo outliers metric value 1 implies average x domain h one standard deviation away fi 1 5 analysis results given section 6 set curves linear functions form also linear curves continuous infinite extent x unlike densities modeling data drawn z z step creaseb x zx parallel figure 5 parameters controlling curve models step edges crease edges parallel lines case fi 1 x desired correct fit points fi 2 x pseudo outliers deltazoe scaled discontinuity magnitude controls percentage points 6 bias caused surface discontinuities pseudo outlier bias bias short used analyze robust estimators accuracy fitting surfaces data three different types discontinuities step edges crease edges parallel lines overlapping x domains section 61 parameterizes mixture density outlines technique find h discusses relationship results presented results higher dimensions analysis results specific estimators presented fixedscale mestimators fixedband techniques sec tion 62 require prior estimate oe standard mestimators section 63 estimate oe lms lts minpran section 64 independent oe case bias examined discontinuity magnitude mixture inliers pseudo outliers gross outliers vary 5 figure surface plot objective functional ae h h ie r hard redescending fixedscale mestimator step edge fits form b plot shows negation objective functional local minima functional appear local maxima plot three local optimal one second third heavily biased fit 191 biased fit global optimum 61 discontinuity models search figure 5 shows models step edges crease edges parallel lines translation scale invariance estimators pseudo outlier bias along several realistic assumptions allow discontinuities described parameters refer back section 3 exact parameter definitions models x interval 0 1 step edges fi 1 retaining oe parameter make clear scale invariance x values move step crease edges curves fi 1 x fi 2 x must changed referring figure 5b functions explicit role scale invariant parallel lines figure 5c fi 1 x fi 2 x step edges x parameter x plays role finally outlier distribution g z uniform z within sigmaz 0 2 deltaz2 0 otherwise foregoing shows parameters deltazoe z 0 completely specify two surface discontinuity model resulting mixture density hx z therefore distri bution hx z hence specifying class functions linear hypothesized fits given robust estimators pseudo outlier bias calculated function parameters calculation requires iterative numerical search minimize h may require several starting points avoid local minima see figure 6 example plot ae h objective functional thus particular type discontinuity particular robust estimator parameters may varied study effect estimators pseudo outlier bias thereby characterizing accurately estimator fit surfaces near discontinuities final observation although results presented onedimensional image domains immediate extension two dimensions example twodimensional analog step edge presented fi 1 x straightforward show model results exactly pseudo outlier bias onedimensional step model mixture parameters gross outlier distribution similar results obtained natural extensions crease edge parallel lines models thus onedimensional discontinuities sufficient establish limitations effectiveness robust estimators 62 fixedscale mestimators fixedband techniques first analysis results fixedband techniques fixedscale mestimators techniques represent ideal case noise parameter oe oe known fixed advance figure 7 shows bias fixedband techniques f three fixedscale mestimators function deltazoe 08 bias leastsquares estimator calculated substituting included comparison ae function tuning parameters values directly literature page 167 interestingly proportion gross outliers effect results fraction outlier distribution within r fit fits r except x sigma r extreme enough cross outside bounds gross outlier distribution sharp drops bias shown figure 7 b fixedband techniques hard redescending mestimator extent soft redescending mestimator b correspond shifting local minimum associated heavily biased fit local minimum near fi 1 x optimum fit target distribution plotting step height drop occurs function gives good summary estimators bias step edges figure 8 referring height small bias height quantifying step height bias drops 10 plots figures 7 8a show fixedband techniques fixedscale mestimators biased nearly much leastsquares significant step edge crease edge discontinuity magnitudes estimators fare much better parallel lines figure 7e f apparently asymmetric positioning pseudo outliers causes bias give intuitive feel significance bias figure 9 shows step edge data generated using model parameters robust estimators strongly biased overall hard redescending fixedscale mestimator least biased techniques studied thus far compared fixedscale mestimators finite rejection point point outliers longer influence fit makes less biased pseudo outliers monotone soft redescending fixedscale mestimators hand less biased fixedband techniques retains statistical efficiency leastsquares small residuals hard redescending fixedscale mestimator made less biased reducing values tuning parameters shown figure 8b effectively narrowing ae h reducing finite rejection point parameter set 10 20 comes 2 set 10 chosen intermediate set values using small parameter values two disadvantages however optimum statistical efficiency standard parameters lost giving less accurate fits target distribution good data may rejected outliers despite disadvantages lower tuning parameters used since avoiding heavily biased fits important objective finally practice nonconvex objective functions hard soft redescending bias step height leastsquares fixedband bias step height leastsquares monotone fixedband hard b crease bias crease height leastsquares monotone fixedband hard020611418 bias crease height leastsquares monotone fixedband hard c parallel bias relative height leastsquares monotone fixedband bias relative height leastsquares monotone fixedband hard figure 7 bias fixedband techniques fixedscale mestimators leastsquares step edges b crease edges c parallel lines e f function height 08 horizontal axis relative discontinuity magnitude height deltazoe vertical axis bias see equation 35 plots shown essentially equivalent leastsquares plots small bias cutoff height fraction points lower half step fixedband small bias cutoff height fraction points lower half step 131 204 40 10 20 30 10 10 20 b figure 8 small bias cutoff heights function relative fraction points lower half step plots show heights fixedband techniques two fixedscale mestimators plots b show heights different tuning parameters hard redescending fixedscale mestimator heights plotted small height plotted large bias never greater 10 fixedscale mestimators lead biased results indicated iterative search techniques especially started nonrobust fit may stop local minimum corresponding biased fit fit target distribution global minimum objective function therefore avoid local minima fixedscale mestimators use either random sampling search technique hough transform 63 mestimators next consider standard mestimators estimate oe data calculate h monotone soft redescending mestimators simply calculate mixture distribution using equation 7 8 objective functional hard redescending mestimator estimates oe initial fit optimum fit mixture distribution found three stages first find optimum lms fit calculate median absolute deviation mad 10 page 107 fit scaling estimate oe finally calculate oe fixed two different scale factors estimating oe considered first 14826 ensures consistency normal distribution second 114601 ensures consistency students tdistribution 15 using latter allows accurate comparison hard soft redescending mestimators since figure 9 example step edge data generated objective function robust estimator except lts minimized biased fit example fit shown x hard redescending fixedscale mestimator latter maximum likelihood estimate students distribution 5 figure shows bias plots soft redescending mestimator hard descending mestimator using two different scale factors plot hardn normal distribution plot hardt tdistribution results monotone mestimator shown since bias matches leastsquares almost exactly overall results substantially worse fixedscale mestimators especially direct result oe substantial overestimate oe example oeoe 24 estimates see 22 analysis bias estimating oe overestimates allow large portion residual distribution fall region ae quadratic causing estimator act like leastsquares mestimators heavily biased discontinuities must estimate oe data 64 lms lts minpran last estimators examined lms lts minpran methods neither require oe priori need estimate finding x figure shows bias plots estimators step edges crease edges parallel lines using figure shows small bias cutoff heights step edges lms lts minpran demonstrates effects changes mixture proportions lms lts lms lts work well technique studied long actual fraction bias step height leastsquares hardn bias step height leastsquares hardn hardt b crease bias crease height leastsquares hardn hardt020611418 bias crease height leastsquares hardn hardt c parallel bias relative height leastsquares hardn bias relative height leastsquares hardn hardt figure 10 bias mestimators leastsquares step edges b crease edges bias step height leastsquares minpran lms bias step height leastsquares minpran lms b crease bias crease height leastsquares minpran lms bias crease height leastsquares minpran lms c parallel bias relative height leastsquares minpran lms bias relative height leastsquares minpran lms figure 11 bias minpran lms lts leastsquares step edges b crease small bias cutoff height relative fraction lower half step minpran lms small bias cutoff height relative fraction lower half step01a b261014 small bias cutoff height actual fraction lower half step010481205 055 06 065 07 075 small bias cutoff height actual fraction lower half step01c figure 12 small bias cutoff heights plot shows lms lts minpran modified minpran optimization criteria minpran2 function relative fraction inliers plot b shows lts function different gross outlier percentages plots c show lts lms respectively function actual fraction inliers heights plotted small height plotted large never greater oe inliers data fi 1 x 05 since fraction bias lms lts unlike mestimators depends heavily sampling implementations lms lts p points instantiate hypothesized fit objective function evaluated remaining points bias curves figure 11 steep drop cutoff heights figure 12 shift right marginally since usually n ae p figures 12b c demonstrate dependence two ways lts figure shows small bias cutoffs function relative fraction inliers points lower half step bias cutoffs lower lower simply fewer gross outliers imply actual inliers remains fixed figure 12c shows small bias cutoffs function actual fraction inliers context varying fixed changes fraction gross outliers versus pseudo outliers plot shows coherent structure pseudo outliers causes bias random structure gross outliers effect shown lms figure 12d finally magnitude z 0 controls gross outlier distribution little effect bias results except unrealistic case approaches discontinuity magnitude lts less biased lms especially actual fraction inliers slightly 05 seen easily comparing low bias cutoff plots figure 12c like advantage hard redescending mestimators fixedband techniques section 62 occurs lts statistically efficient lms 21 objective function depends smallest 50 residuals rather median residual important note although lmss efficiency improved application onestep mestimator starting lms estimate improve substantially heavily biased fit since local minimum mestimator objective function near fit minor modification optimization criteria minpran made much less sensitive pseudo outliers improving dramatically poor performance shown figures 11 12 idea find two disjoint fits shared inliers inlier bounds r r b inlier counts k r k minimizing fr r b k 1 r 23 26 single fit minimizing criterion function inlier bound r inlier count k r two fits b chosen instead single fit r thus modified optimization criteria tests whether one two inlier distributions likely data 27 figure 12 shows step edge small bias cutoff heights new objective function denoted minpran2 substantially lower techniques including lts results unlike minpran marginally affected parameters unfortunately search b computationally expensive present implementation minpran2 uses simple search heuristic yields 23 26 biased results optimum shown however effective fixedscale hard redescending mestimator unlike lms lts fail dramatically inliers 65 discussion recommendations overall results show robust estimators studied estimate biased fits small substantial discontinuity magnitudes bias relative bias leastsquares greater crease step edges less parallel lines occurs even oe distribution gross outliers known priori must emphasized bias artifact search process functional form estimator returns fit corresponding global minimum estimators objective function reason bias seen examining cumulative distribution functions cdfs absolute residuals figure 13 plots cdf f rj h target fit leastsquares fit h h modeling crease step discontinuities cdf biased fit almost always greater target fit meaning discrete set samples biased fit crosses point sets average yield smaller magnitude residuals target fit close target point set situation somewhat better deltazoe 90 therefore robust estimators ones studied whose objective functions based solely residuals unlikely estimate unbiased fits small magnitude discontinuities cdf absolute residual biased fit target fit02061 cdf absolute residual biased fit target fit b crease cdf absolute residual biased fit target fit02061 cdf absolute residual biased fit target fit c figure 13 figure plots cumulative distribution functions cdf absolute residuals target fit biased leastsquares fit b relative step discontinuity c relative crease discontinuity plots mixture fractions fixed robust estimators substantially biased step crease discontinuities none estimators works well desired following recommendations choosing among based results presented oe known priori one use hard redescending mestimator objective function hampels reduced tuning parameter values either randomsampling search technique weighted hough transform ensure inliers found obtain greater statistical efficiency onestep mestimator larger tuning parameters run initial optimum fit technique preferable lts lms less sensitive number gross outliers oe known priori distribution gross outliers known one use modified minpran algorithm minpran2 23 26 ffl neither oe distribution gross outliers known lts used although performance degrades quickly inliers lts preferable lms statistical efficiency 7 summary conclusions paper developed pseudo outlier bias metric using techniques mathematical statistics study fitting accuracy robust estimators data taken multiple structures surface discontinuities particular pseudo outlier bias measures distance robust estimators optimum fit target distribution optimum fit outlier corrupted mixture distribution target distribution models points single surface mixture distribution models points multiple surfaces plus gross outliers estimators optimum fit found applying functional form one model distributions thus like analysis tools robust statistics literature pseudo outlier bias depends point distributions rather particular point sets drawn distributions limitations actual fitting error particular points sets may less pseudo outlier bias ignores problems may arise multiple local minima objective function represents simple efficient elegant method analyzing robust estimators pseudo outlier bias used analyze performance mestimators fixedband techniques hough transforms ransac least median squares lms least trimmed squares lts minpran fitting surfaces three different discontinuity models step edges crease edges parallel lines discontinuities two surfaces generate data larger set surface data forming inliers smaller set forming pseudo outliers characterizing discontinuity models using small number parameters formulating models mixture distributions studying bias robust estimators parameters varied shown robust estimator biased substantial discontinuity magnitudes effect relative leastsquares strongest step edges crease edges persists even noise data gross outlier distribution known advance disappointing vision data range data multiple structures pseudo outliers prevalent gross outliers spite disappointment however specific recommendations depend known data made choosing current techniques 6 negative results indicate care used robustly estimating surface parameters range data either obtain local loworder surface approximations initialize fits surface growing algorithms 3 5 6 15 similar problems may occur layers techniques applied motion analysis 1 6 28 robust estimates accurate large scale depth discontinuties sharp corners skewed small magnitude discontinuites near boundary slightly raised depressed area surface obtaining accurate estimates near discontinuities require new perhaps sophisticated robust estimators acknowledgements author would like acknowledge financial support national science foundation grants iri9217195 iri9408700 assistance james miller various aspects work insight offered anonymous reviewers led sub 6 see 14 17 new related techniques stantial improvements presentation appendix evaluating f appendix shows evaluate conditional cumulative distribution conditional density signed residuals f 22 distribution density absolute residuals obtained easily expanding expression equation 21 f rj h using equation h gives f z xr cumulative distribution gross outliers z xr simplify evaluating f variables change order integration starting change variables make substitutions intuitively v fit residual x define integral becomes z oexr since integrand independent x rewriting integral integrate strips parallel x axis produce single integral consider strip bounded v v deltav figure 14 integral strip approximately gvwvdeltav wv width integration region v limit deltav 0 becomes exact integral entire region becomes maximum oex r f x figure 14 calculating f requires integrating point density curve strips width deltav parallel x axis density gv oe 2 constant strips evaluating wv depends oex paper studies linear fits linear curve models oex linear case let figure 14 using g denote cdf gaussian similar result obtained 0 compute density f rj h start mixture density equation 22 integrate component density separately straightforward density g uniform x fi x linear r layered representation motion video using robust maximum likelihood estimation mixture models mdl encoding robust window operators segmentation variableorder surface fitting ransacbased approach model fitting application finding cylinders range data robust sequential estimator general approach application surface organization range data cooperative robust estimation using layers support random sample consensus paradigm model fitting applications image analysis automated cartography linear systems changeofvariance curve optimal redescending mestimators robust statistics approach based influence functions robust regression using iteratively reweighted least squares robust statistics survey hough transform robust adaptive segmentation range images segmentation range images search geometric parametric models robust regression methods computer vision review muse robust surface fitting using unbiased scale esti mates performance evaluation class mestimators surface parameter estimation noisy range data numerical recipes c art scientific computing extracting geometric primitives least median squares regression alternatives median absolute deviation new robust operator computer vision application range images new robust operator computer vision theoretical analysis expected performance robust estimators near discontinuities minpran new robust estimator computer vision statistical analysis finite mixture distri butions layered representation motion analysis tr ctr cesare alippi randomized algorithms systemlevel polytime analysis robust computation ieee transactions computers v51 n7 p740749 july 2002 alireza babhadiashar david suter robust segmentation visual data using ranked unbiased scale estimate robotica v17 n6 p649660 november 1999 ulrich hillenbrand consistent parameter clustering definition analysis pattern recognition letters v28 n9 p11121122 july 2007 klaus kster michael spann mir approach robust clusteringapplication range image segmentation ieee transactions pattern analysis machine intelligence v22 n5 p430444 may 2000 thomas kmpke matthias strobel polygonal model fitting journal intelligent robotic systems v30 n3 p279310 march 2001 christine h mller tim garlipp simple consistent cluster methods based redescending mestimators application edge identification images journal multivariate analysis v92 n2 p359385 february 2005 hanzi wang david suter robust adaptivescale parametric model estimation computer vision ieee transactions pattern analysis machine intelligence v26 n11 p14591474 november 2004 hanzi wang david suter mdpe robust estimator model fitting range image segmentation international journal computer vision v59 n2 p139166 september 2004 philip h torr colin davidson impsac synthesis importance sampling random sample consensus ieee transactions pattern analysis machine intelligence v25 n3 p354364 march vieville lingrand f gaspard implementing multimodel estimation method international journal computer vision v44 n1 p4164 august 2001 p h torr bayesian model estimation selection epipolar geometry generic manifold fitting international journal computer vision v50 n1 p3561 october 2002 myron z brown darius burschka gregory hager advances computational stereo ieee transactions pattern analysis machine intelligence v25 n8 p9931008 august