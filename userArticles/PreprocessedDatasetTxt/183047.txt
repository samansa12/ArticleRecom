cache interference phenomena impact cache interferences program performance particularly numerical codes heavily use memory hierarchy remains unknown general knowledge cache interferences highly irregular terms occurrence intensity paper different types cache interferences occur numerical loop nests identified analytical method developed detecting occurrence interferences important computing number cache misses due interferences simulations experiments real machines show model generally accurate interference phenomena captured experiments also show cache interferences intense frequent certain parameters array base addresses dimensions strong impact occurrence interferences modifying parameters induce global execution time variations 30 applications modeling techniques numerous range performance evaluation prediction enhancement data locality optimizations techniques b introduction three types cache misses distinguished 6 7 coldstart misses compulsory capacity misses interference conflict misses capacity occur cache space unsufficient store data reused interference misses occur two data mapped cache location typi cally fullyassociative caches exhibit interference misses work supportedby esprit agency dg xiii grant apparc 6634 bra iiicapacity misses numerical codes studied great extent 2 9 16 relatively easily predicted estimated studies also attempt take account impact cache line size studies interference misses though several casestudies report cache interferences severely affect cache behavior 6 8 also 3 suggestions provided consider interferences cache performance evaluation optimization cache interferences difficult predict esti mate necessary know data mapped cache data referenced stance consider addresses b mapped cache location reused 3 times whether reference sequence aaabbb ababab interference equal respectively 0 4 nevertheless several reasons press study cache interferences first cache tends performance bottleneck high network memory latencies significant performance improvements obtained slight reduction cache misses besides several onchip data caches directmapped order achieve low hit time caches considered sensitive interferences 8 especially small currently case onchip space constraints kbytes dec alpha 11 mips r4000 5 moreover large cache line sizes induce high interferences 12 one reasons cache line size currently kept small capable detect avoid cache interferences could allow increases cache line size important cache interferences make program performance unpredictable understanding workings cache phenomena would allow precise performance analysis prediction application codes paper particularly targeted towards numerical codes characterized large working sets performance highly dependent memory hierarchy behavior goal paper threefold first illustrate fact cache interferences occur frequently significant impact program performance section 2 3 second goal introduce methodology predicting estimating cache interferences directmapped caches frequently occurring numerical loop nests section 3 third goal illustrate model accuracy several examples sections 3 4 first version framework computing cache interferences presented 14 15 model applied drive data copying strategies present paper provides details computations illustrates model accuracy experiments examples three types statistics provided simulated execution time whole loop array estimated execution time obtained model global execution time loop timed hpparisc workstation 1 execution time curves corresponding simulations modeling obtained following technique since purpose model predict variations rather absolute execution time starting point picked real execution time graph x parameter varied graph execution time let x number simulated estimated cache misses parameter lat 2 purpose statistics twofold first show impact cache interferences global performance second verify execution time variations correspond miss ratio variations 2 notion cache interferences cache interferences operate disrupting reuse data several types reuse distinguished spatial temporal reuse type self dependence reuse one reference reuses data groupdependence reuse one reference uses data another reference also distinguished see 16 characteristics hpparisc cache array elements directmapped cache bytes whole paper 1 array floatingpoint data dimensions given array elements experiments 1 array 1 experiments hp array base addresses varied using one large single array arrays point array modifying pointed location relative base address two arrays varied 2 hp system miss penalty experimentally timed 8e gamma 7 seconds loop 2a iju1 ku700 ju500290310330350500 0 500 1000 1500 2000 execution time 100 runs seconds real 33333333 estimated 2222222222222figure 2bexecution time oe oe oe cache arrays oe ku figure 2clayout cache figure 2 influence cache interferences frequency interferences notion cache interferences conveys rare intense phenomena like pingpong two references references ai bi doloop index start cache location translate cache constantly compete cache line therefore preventing spatial reuse however cache interferences much diverse frequent type reuse dis rupted general larger reuse distance given datum higher probability flushed cache data loaded reuse oc curs consider loop 2a modified version loop arc2d perfect club benchmark 1 reuse distance associated spatial reuse ldak equal 1 iteration loop k unlikely disrupted reuse distance associated temporal reuse ldak equal ku iterations loop k likely disrupted depending value ku irregularity interferences whether two data sets intersect cache determined cache position sets position generally depends two types parameters arrays base address leading di mensions since parameters arbitrarily ie cacheconsciously determined compiler programmer cache interferences occur apparently random manner consider loop 2a 3 cache distance arrays lda ldb smaller base addresses arrays lda ldb two data sets intersect assuming directmapped cache data belonging intersection cannot reused importance cache interferences loop 2a distance arrays characterized one parameter effects shown varying single parameter ldb lds figure 2b ffi varied gammak u 4 theta ku performance variations 20 500 case pingpong observed match estimated real execution time graphs strongly suggests variations due interference phenomena note value ffi exact number references performed arrays base address modified experiments conducted paper see sections 35 361 362 37 show frequent significant performance losses due cache interferences examples illustrate type interference phenomenon case shown section 3 evaluate corresponding number cache misses section 4 synthesizes results showing compute number cache misses loop 2a modeling cache behavior section techniques used estimate number interference misses presented though method applies types reuse method illustrated selfdependence temporal reuse frequent type reuse often likely victim interferences extensions groupdependence reuse explained 3 example analyzed detail section 4 4 figure 2c illustrates respective cache positions different arrays one iteration loop j paper length constraints extension spatial reuse discussed paper see 13 though primary goal methodology applied compute capacity misses well interference misses though interference misses far complex evaluate consequently analytical expression total miss ratio given loop derived illustrated section 4 compulsory misses easily estimated 31 basic concepts evaluating miss ratio loop nest amounts counting reference number cache misses due disruption locality exploitation reference necessary determine reuse occurs ie loop level reuse occurs first time consider loop 35a reuse reference j3 j2 occurs loop j 1 reuse reference zj3 j1 occurs loop j 2 reuse loop defines set data reused reference j3 j2 set equal fy 0 equal reference zj 3 cache arrays j 3 reuse set j 3 interference set interference set interference set interference set reuse set figure 31 notion interferencereuse sets similarly loop level also defines sets data references interfere reuse set reference j3 j2 terference sets fz0 j 1 cache reused see figure 31 reference interference sets fy 0 consider reference iteration reuse loop number cache misses due disruption reuse reference equal size intersection cache lines reuse set interference sets considering problem way implicitly makes abstraction time considerations ie interferences occur problem equivalent computing intersection size several sets summing intersections iterations reuse loop provides total number cache interference misses given reference next sections provide formal treatment method 311 reuse set definition 31 assuming loops perfectly nested j n innermost loop reuse loop level l reference defined example consider loop 35a reuse loop level 32 reuse set within set array elements reused possible two elements map cache location elements alternately flush cache reused therefore counted within set elements effectively reused necessary distinguish theoretical reuse set actual reuse set definition 32 array reference reuse loop l theoretical reuse set equal 0 g definition 33 actual reuse set arsr cache footprint theoretical reuse set trsr excluding cache lines mapping conflicts occur definition 34 ktrsrk size theoretical reuse set r expressed array lines ie number cache lines used trsr assuming infinite cache size definition 35 karsrk size actual reuse set r expressed cache lines example consider loop 35a reuse set z 0 base address array z leading dimension arrays xy z case array elements n array lines 6 actual reuse set equal cache lines corresponding cache locations 1g assuming cache size 4 array elements 1element 2 words cache line actual reuse set z equal n cache lines n 4 equal 8 gamma n cache lines 4 empty 8 n 5 note simple dependences considered instance reuse associated reference sidered frequently found dependences simple ones mentioned 17 6 floor ceiling functions often omitted paper experiments showed generally dont significant impact precision 33 interference set definition set array elements interfere reuse set similar definition reuse set definition 36 array reference interfere reuse set defined loop level l theoretical interference set equal 0 g opposition actual reuse set two elements theoretical interference set map cache line line still counted actual interference set definition 37 actual interference set aisr exactly cache footprint theoretical interference set tisr definition 38 reuse set ktisrk kaisrk denote respectively size theoretical actual interference set r example consider loop 35a reuse j 3 occurs loop j 1 corresponding interference set defined loop j 1 interference set 1g case array elements n ls array lines assuming cache size 4 array elements words 1element 2 words cache line actual interference set z equal n cache lines n 4 equal 4 cache lines 4 n 34 evaluating actual sets 7 consider reference want compute cache footprint loop level l ie footprint defined loops observation 31 iterating loop data layout cache assumed set intervals cache locations characterized average size interval average distance oe two consecutive intervals assertion approximationwhich aims simplifying evaluation process using observation recursive process applied loop level problem 31 assuming initial regular 8 data layout intervals size separated distance oe cache locations layout obtained iterating loops 1 problem determine final layout ie average size 0 average distance iterating loop 7 section skipped indepth comprehension computations sought 8 ie distance two consecutive intervals approximately constant 341 actual interference set problem 31 recursive process also ap plied let oe number iterations intervals wrap around cache area size oe 0 within area oe 1 cache locations layout intervals identical study restricted one area within one area spacing two consecutive intervals equal oe us consider recursive application process observation 32 recursion level k size area considered equal oe kgamma1 spacing two consecutive intervals one area equal oe k recursion process stops level iterations loop considered overlapping occurs ie oe starting point possible determine footprint within area size oe sgamma1 assuming layout across areas footprint within whole cache proposition 31 let oe oe c b oe 0 oe areas size oe sgamma1 n intervals size brought remaining r areas n brought proposition 32 let f x cache footprint size intervals equal ii oe layout intervals average size interval equal ii oe oe spacing intervals equal oe remark oe oe k computed priori cost one application euclide algorithm 10 practice fact also makes process nonrecursive since level recursion stops determined beforehand process applied loops resulting layout cache actual interference set reference defined loop l 342 actual reuse set reasoning nearly identical actual reuse set except cache lines overlapping occurs must excluded proposition 33 number elements reused equal ii oe 0 oe example application whole process found section 35 note process inaccurate mentioned several approximations made error become significant multiple applications ie multiple loop levels fortunately reuse set defined two loop levels corresponds 3deep loop nest reuse occurs third loop reuse set algorithm needs applied except access stride equal one reuse sets defined three loops less common primitives real codes 17 less likely exploited instance loop blocking rarely performed two innermost loops assume reuse loop level l reference r proposition 34 number cache misses due selfinterferences r equal intuitively cache line excluded actual reuse set conflicts generates one cache miss time reuse set referenced hence proposition example consider loop 35a corresponding multiplication two n theta n submatrices theta matrices enddo enddo enddo loop 35a n100 execution time 100 runs seconds matrix dimension real est 2222 222222222 figure 35bexecution time cache array oe oe oe figure 35clayout cache figure 35 selfinterferences since arrays reused amount compulsory misses negligible spatial interference misses negligible small spatial reuse distance spatial reuse distance large since reference accounts small share memory accesses impact spatial interference misses significant references memory accesses temporal reuse distance j 3 one order magnitude larger intuitively j 3 likely responsible temporal interference misses case loop misses since theoretical interference set size zj 3 equal n elements theoretical reuse set size j 3 equal n 2 elements effect self interferences much significant cross interferences ie crossinterferences prevent reuse n elements selfinterferences prevent reuse n 2 elements reuse set j 3 set n intervals relative distance oe spread within interval oe cations oe k values obtained oe oe kgamma2 mod oe kgamma1 using technique section 34 n computed table 35 shows values main variables different values figure 35b illustrates model precision impact selfinterferences global performance seen interferences nearly total temporal reuse cannot exploited spatial reuse still exploited miss ratio close theoretical minimum 1 0125 crossinterferences yield even lower miss ratio ns szars 0 oe 0 miss table 35 examples values obtained 36 crossinterferences consider reuse set reference r reuse occurs loop l corresponding interference set reference r 0 definition 39 reuse interference set defined loop l cache position defined 9 lemma 31 relative cache position interference set r 0 respect reuse set r equal relative distance two sets equal example consider loop 35a reuse j 3 occurs loop j 1 corresponding interference set zj 3 defined loop j 1 position actual reuse set j 3 oearsy j 3 position actual interference set zj 3 361 internal crossinterferences definition 310 ffi independent l crossinterferences r r 0 called internal crossinterferences proposition 35 crossinterferences r r 0 internal crossinterferences size intersection aisr 0 constant iterations loops 9 note actually corresponds cache position first element set number cache misses due crossinterferences equal proposition 36 intersection two intervals size 1 2 separated distance locations equal instance sets correspond collection intervals stead one single interval interval reuse set compared interval interference set size intersection obtained summing subcases example enddo enddo loop 361a n1000m2509111350 200 400 600 800 1000 1200 execution time 100 runs seconds figure 361b execution time cache arrays oe oe figure 361clayout cache figure 361 internal crossinterferences consider loop 361a temporal interferences xa xb likely account interferences c breeds compulsory misses role arrays symmetric consider array xa reuse set interval locations well corresponding interference set xb relative cache distance two sets according proposition total number internal crossinterference misses xa equal figure 361 illustrates model precision impact internal crossinterferences global performance seen execution time decreases ffi decreases two sets overlap 362 external crossinterferences external crossinterferences accurate approximate evaluation used tradeoffs accuracy complexity approximate evaluation described accurate evaluation described 13 see also 4 example considered approximation let us assume ffi distance reuse set r interference set variable uniform distribution interferences averaged values ffi hence proposition proposition 37 approximate number cache misses due external crossinterferences r r 0 execution loop nest equal theta function defined section 361 example consider loop 362a corresponds multiplication n theta n matrix vector x reg aj2j1 xj2 enddo enddo loop 362a 10000 20000 30000 40000 50000 average execution time per reference figure 362bexecution time cache arrays oe oe figure 362clayout cache figure 362 external crossinterferences assuming n c ie capacity miss oc approximate number external crossinterference misses x due equal n theta 1 theta seen figure 362 time per reference increases n mostly temporal reuse array x disrupted array threshold value reached temporal reuse cannot exploited 37 extension groupdependence reuse techniques sections 32 36 extended groupdependence reuse opposition self dependences reuse set defined two references reusing data r 1 reuse loop level simply loop level reuse occurs reuse set defined set elements referenced r 1 reused r 2 consequently reuse set interference set defined whole execution one several loops subset iterations one several loops main difference selfdependences reuse set well interference set moving iteration reuse loop consequently formal definition interference set quired element theoretical reuse set theoretical interference set equal elements loaded cache two references element definition apparently dependent element reuse set generally elements within reuse set behave way surprising consequence internalcross interferences disrupt group dependence reuse boolean way either element reuse set elements reuse set flushed cache 10 external crossinterferences accurate evaluation difficult derive approximate evaluation still used computed one element reuse set extended elements reuse set notions illustrated example example consider loop 37a group dependence xj disrupted xy j assumed leading dimen sion references translation cross interferences internal crossinterferences reuse set defined loop j 2 corresponds 1g element 1 interference set equal 1g ie relative distance interference set internal cross interferences occur condition selfdependence reuse intuitively interference set located reuse set going sweep away elements reuse set reused see figure 37c case internal crossinterferences occur group dependence reuse achieved phenomenon illustrated figure 37 n varied gamma500 1000 enddo enddo loop 37a n1n2500 exactly elements reuse set flushed interference set cache locations used reuse set may never used interference set even though sets moving cache execution time 100 runs seconds figure 37bexecution time cache arrays oe oe figure 37clayout cache figure 37 disruption groupdependence reuse 38 computing total number misses previous sections shown predict compute number cache misses due given type interference though major issue another difficult problem combine results several references occurring loop 381 cumulating interference sets possible simply add number cache misses corresponding reference type interferences interferences redun dant consider example enddo enddo arrays b induce external cross interferences array relative cache distance actual interference sets two arrays equal ffi ie two actual interference sets lap time overlap reuse set b redundant impact cache misses counted twice order avoid redundancy references considered individually definition 311 two references r r 0 belong translation group relative cache distance r r 0 constant actual interference set translation group union actual interference sets references within translation group interferences due single reference considered anymore instead interferences due translation group consid ered notion useful avoid redundant estimates crossinterferences note general translation groups within loop body 382 selecting proper dependence consider following example enddo enddo selfdependence xj 2 group dependence xj 2 1 reuse distance groupdependence 1 iteration j 2 much shorter selfdependence n 2 iterations j 2 elements excluding x0 reference exploits groupdependence reuse rather selfdependence therefore interferences groupdependence instead selfdependence must considered interferences evaluated dependence corresponds smallest dependence distance gen eral array subscripts simple enough make task tractable redundancies globally redundancies avoided following reasons determining crossinterferences actual reuse set instead theoretical reuse set avoids redundant evaluation selfinterferences cross interferences ffl determining internal crossinterferences evaluating external crossinterferences updating actual reuse set avoids redundant evaluation internal crossinterferences external cross interferences ffl redundancies within external crossinterferences ignored proved negligible cases 11 assertion illustrated section 4 391 global algorithm global algorithm computing number cache interference misses following cache misses due selfinterferences compute number set r removing elements victim crossinterferences update actual reuse compute number cache misses due external crossinterferences cache misses due internal crossinterferences compute number oe oe oe oe loop body oe dependence distance determine shortest determine reuse set translation group actual reuse set reference r determine interference set actual interference set translation group determine interference set actual interference set total number cumulate derive cache misses reference r 4 putting together section number cache misses loop 2a computed based techniques presented section 3 leading dimension arrays f u ku mentioned section 2 one parameter ffi used characterize distance different arrays 12 seen figure 2 four intervals dis tinguished paper length constraints interval 0 ku gamma 1 considered interval corresponds complex case many interference phenomena occur time compulsory misses ffl number compulsory misses due array ldaldblds equal ku ls references u k u k j belong translation group potential reuse two references ignored therefore considered references breed compulsory misses ku ls u k ju thetaku ls u k j f k f k j ffl consequently total number compulsory misses equal internal crossinterferences selfdependence reuse 11 possible though come examples redundancies external crossinterferences significant assumption influence complexity computations ffl actual reuse set ldak set ku ls consecutive cache lines references ldbk ldsk u k f k belong translation group ldak actual interference sets u k f k overlap actual reuse set ldak 13 actual interference sets ldbk overlap actual reuse set ldak impact ldsk redundant ldbk see figure 2c actual interference set size ldbk ldsk combined equal minkuffi2thetaku ls overlaps ku gammaffi ls actual reuse set ldak therefore internal crossinterferences ldak induce cache misses ffl ldak internal crossinterferences ls cache misses ffl ldbk actual interference set size combined equal minku2ffi2thetaku ls overlaps 2thetaku gammaffi ls actual reuse set ldbk therefore internal crossinterferences ldbk induce ju ls cache misses ffl actual interference set f k overlaps ffi cache lines actual reuse set u k ju thetaku gammaffi ls cache misses due internal cross interferences u k role u k f k symmetric therefore ju thetaku gammaffi ls cache misses due internal crossinterferences f k total number internal crossinterferences corresponding selfdependence reuse disruption equal internal crossinterferences groupdependence reuse consider groupdependence u k j u 1 actual reuse set u location u leading dimension u ku actual interference set corresponding f k j starts f 0 f k inequation equivalent 0 satisfied hypotheses internal crossinterferences groupdependence reuse u k 1 mentioned section 37 interferences boolean none 13 sake clarity relative distance u 0 lda 0 chosen internal crossinterference occurs uk f k ldak ldbkldsk however crossinterferences would difficult compute ones studied paragraph ku gamma1 elements reuse set reused condition interferences occur satisfied groupdependence u consequently number cache misses due internal crossinterferences groupdependence reuse equal external crossinterferences ffl external cross interferences groupdependence reuse u due ldak ldbk ldsk f k u k negligible ignored ffl external crossinterferences ldak ldbk ldsk f k u k due u k j f k estimated updated actual reuse sets actual interference set size corresponding translation group u k j u k j1 u k j2 f k j equal 3 theta ku impact f k j redundant using function f defined section 362 total number external crossinterferences equal 4 theta f total number cache misses precision evaluation illustrated figure 2b 14 5 conclusions future directions main outcome work show computing number cache misses due interference phenomena tractable task methodology presented perform outcome paper show interference phenomena occur frequently intense compilers need address issue cache interferences optimizing codes reducing capacity misses sufficient first application work integration miss ratio evaluation techniques compiler performance evaluation prediction purposes implementation would fully validate possibility automatically computing number cache misses would also enhance model unveiling potential issues would show theoretical study second application refinement data locality optimization techniques mainly accurate evaluation optimal block sizes 14 peaks occurring correspond pingpong phenomena spatial reuse disruption see section 2 discussed simply identified checking relative position different arrays r supercomputing performance evaluation perfect benchmarks strategy array management local memory estimating enhancing cache effectiveness extended ab stract accurate evaluation blocked algorithms cache interferences computer ar chitecture quantitative approach aspects cache memory instruction buffer performance cache performance blocked algorithms automatic interactive paral lelization sites editor alpha architecture reference man ual cache memories cache interference phenomena impact cache interferences usual numerical dense loop nests copy copy compiletime technique assessing data copying used eliminate cache conflicts data locality optimizing algorithm empirical study array subscripts data dependendencies tr computer architecture quantitative approach data locality optimizing algorithm mips risc architectures alpha architecture reference manual automatic interactive parallelization copy copy supercomputer performance evaluation perfect benchmarks cache memories concrete math estimating enhancing cache effectiveness aspects cache memory instruction buffer performance ctr b b fraguela r doallo j tourio e l zapata compiler tool predict memory hierarchy performance scientific codes parallel computing v30 n2 p225248 february 2004 basilio b fraguela ramn doallo emilio l zapata probabilistic miss equations evaluating memory hierarchy performance ieee transactions computers v52 n3 p321336 march van der deijl gerco kanbier olivier temam elena granston cache visualization tool computer v30 n7 p7178 july 1997 basilio b fraguela ramn doallo emilio l zapata modeling set associative caches behavior irregular computations acm sigmetrics performance evaluation review v26 n1 p192201 june 1998 andrade b b fraguela r doallo analytical modeling codes arbitrary datadependent conditional structures journal systems architecture euromicro journal v52 n7 p394410 july 2006 j hu kandemir n vijaykrishnan j irwin h saputra w zhang compilerdirected cache polymorphism acm sigplan notices v37 n7 july 2002 christine fricker olivier temam william jalby influence crossinterferences blocked loops case study matrixvector multiply acm transactions programming languages systems toplas v17 n4 p561575 july 1995 john harper darren j kerbyson graham r nudd analytical modeling setassociative cache behavior ieee transactions computers v48 n10 p10091024 october 1999 somnath ghosh margaret martonosi sharad malik cache miss equations analytical representation cache misses proceedings 11th international conference supercomputing p317324 july 0711 1997 vienna austria min zhao bruce childers mary lou soffa predicting impact optimizations embedded systems acm sigplan notices v38 n7 july richard e ladner james fix anthony lamarca cache performance analysis traversals random accesses proceedings tenth annual acmsiam symposium discrete algorithms p613622 january 1719 1999 baltimore maryland united states apan qasem ken kennedy profitable loop fusion tiling using modeldriven empirical search proceedings 20th annual international conference supercomputing june 28july 01 2006 cairns queensland australia gabriel rivera chauwen tseng data transformations eliminating conflict misses acm sigplan notices v33 n5 p3849 may 1998 j hu kandemir n vijaykrishnan j irwin analyzing data reuse cache reconfiguration acm transactions embedded computing systems tecs v4 n4 p851876 november 2005 somnath ghosh margaret martonosi sharad malik automated cache optimizations using cme driven diagnosis proceedings 14th international conference supercomputing p316326 may 0811 2000 santa fe new mexico united states somnath ghosh margaret martonosi sharad malik precise miss analysis program transformations caches arbitrary associativity acm sigops operating systems review v32 n5 p228239 dec 1998 gayathri venkataraman sartaj sahni srabani mukhopadhyaya blocked allpairs shortestpaths algorithm journal experimental algorithmics jea 8 gabriel rivera chauwen tseng eliminating conflict misses high performance architectures proceedings 12th international conference supercomputing p353360 july 1998 melbourne australia kadayif kandemir n vijaykrishnan j irwin j ramanujam morphable cache architectures potential benefits acm sigplan notices v36 n8 p128137 aug 2001 gabriel rivera chauwen tseng locality optimizations multilevel caches proceedings 1999 acmieee conference supercomputing cdrom p2es november 1419 1999 portland oregon united states ya kalinov l lastovetsky n ledovskikh posypkin compilation vector statements c language architectures multilevel memory hierarchy programming computing software v27 n3 p111122 mayjune 2001 alexandre farcy olivier temam improving singleprocess performance multithreaded processors proceedings 10th international conference supercomputing p350357 may 2528 1996 philadelphia pennsylvania united states gabriel rivera chauwen tseng tiling optimizations 3d scientific computations proceedings 2000 acmieee conference supercomputing cdrom p32es november 0410 2000 dallas texas united states lakshminarayanan renganarayana sanjay rajopadhye geometric programming framework optimal multilevel tiling proceedings 2004 acmieee conference supercomputing p18 november 0612 2004 somnath ghosh margaret martonosi sharad malik cache miss equations compiler framework analyzing tuning memory behavior acm transactions programming languages systems toplas v21 n4 p703746 july 1999 chunghsing hsu ulrich kremer quantitative analysis tile size selection algorithms journal supercomputing v27 n3 p279294 march 2004 anthony lamarca richard ladner influence caches performance heaps journal experimental algorithmics jea 1 p4es 1996 kathryn mckinley olivier temam quantitative analysis loop nest locality acm sigplan notices v31 n9 p94104 sept 1996 hans vandierendonck koen de bosschere highly accurate efficient evaluation randomising set index functions journal systems architecture euromicro journal v48 n1315 p429452 may xavier vera nerina bermudo josep llosa antonio gonzlez fast accurate framework analyze optimize cache memory behavior acm transactions programming languages systems toplas v26 n2 p263300 march 2004 johann blieberger thomas fahringer bernhard scholz symbolic cache analysis realtime systems realtime systems v18 n23 p181215 may 2000 jingling xue xavier vera efficient accurate analytical modeling wholeprogram data cache behavior ieee transactions computers v53 n5 p547566 may 2004 ismail kadayif mahmut kandemir quasidynamic layout optimizations improving data locality ieee transactions parallel distributed systems v15 n11 p9961011 november 2004 zhiyuan li yonghong song automatic tiling iterative stencil loops acm transactions programming languages systems toplas v26 n6 p9751028 november 2004