cumulated gainbased evaluation ir techniques modern large retrieval environments tend overwhelm users large output since documents equal relevance users highly relevant documents identified ranked first presentation order develop ir techniques direction necessary develop evaluation approaches methods credit ir methods ability retrieve highly relevant documents done extending traditional evaluation methods recall precision based binary relevance judgments graded relevance judgments alternatively novel measures based graded relevance judgments may developed article proposes several novel measures compute cumulative gain user obtains examining retrieval result given ranked position first one accumulates relevance scores retrieved documents along ranked result list second one similar applies discount factor relevance scores order devaluate lateretrieved documents third one computes relativetotheideal performance ir techniques based cumulative gain able yield novel measures defined discussed use demonstrated case study using trec data sample system run results 20 queries trec7 relevance base used novel graded relevance judgments fourpoint scale test results indicate proposed measures credit ir methods ability retrieve highly relevant documents allow testing statistical significance effectiveness differences graphs based measures also provide insight performance ir techniques allow interpretation example user point view b 2 cumulated gain based measurements 21 direct cumulated gain examining ranked result list query obvious highly relevant documents valuable marginally relevant documents greater ranked position relevant document less valuable user less likely user ever examine document first point leads comparison ir techniques test queries cumulated gain document rank evaluation relevance score document somehow used gained value measure ranked position result gain 1 discussion degree relevance probability relevance see robertson belkin 1978 summed progressively ranked position 1 n thus ranked document lists determined length turned gained value lists replacing document ids relevance scores assume relevance scores 0 3 used 3 denoting high value 0 value turning document lists rank 200 corresponding value lists gives vectors 200 components value 0 1 2 3 example cumulated gain ranked position computed summing position 1 ranges 1 200 formally let us denote position gain vector g gi cumulated gain vector cg defined recursively vector cg cgigcg1i1gioifthierw1ise 1 example g obtain cumulated gain rank may read directly example rank 7 11 22 discounted cumulated gain second point stated greater ranked position relevant document less valuable user less likely user ever examine document due time effort cumulated information documents already seen leads comparison ir techniques test queries cumulated gain based document rank rankbased discount factor greater rank smaller share document score added cumulated gain discounting function needed progressively reduces document score rank increases steeply eg division rank allow user persistence examining documents simple way discounting requirement divide document score log rank example thus document position 1024 would still get one tenth face value selecting base logarithm sharper smoother discounts computed model varying user behavior formally b denotes base logarithm cumulated gain vector discount dcg defined recursively vector dcg note must apply logarithmbased discount rank 1 blog moreover apply discount case ranks less logarithm base would give boost also realistic since higher base lower discount likely searcher examine results least base rank say 10 example let 2 g given preceding section obtain 5 689 689 689 728 799 866 961 961 lack ability query rank highly relevant documents toward top result list show cumulated gain document rank cg cumulated gain discount document rank dcg vectors averaging set test queries average performance particular ir technique analyzed averaged vectors length individual ones component gives average ith component individual vectors averaged vectors directly visualized gainbyrank graphs section 3 compute averaged vectors need vector sum operation vector multiplication constant let two vectors sum vector v wk set vectors v1 v2 vn k components sum vector generalised vn multiplication vector constant r vector rvk average vector av based vectors v v1 v2 vn given function avgvectv average cg dcg vectors vector sets cg dcg set test queries computed avgvectcg avgvectdcg actual cg dcg vectors particular ir method may also compared theoretically best possible latter vectors constructed follows let k l relevant documents relevance levels 1 2 3 respectively given request first fill vector positions 1 values 3 positions m1 ml values 2 positions ml1 ml k values 1 finally remaining positions values 0 formally theoretically best possible score vector bv request k l relevant documents relevance levels 1 2 3 constructed follows 0 otherwise sample ideal gain vector could ideal cg dcg vectors well average ideal cg dcg vectors curves computed note curves turn horizontal relevant documents level found section 3 gives examples unrealistically assume baseline retrieved documents could maximally rele vant vertical distance actual average dcg curve theoretically best possible average curve shows effort wasted lessthanperfect documents due particular ir method based sample ideal gain vector obtain ideal cg dcg b 2 vectors note ideal vector based recall base search topic rather result ir technique important difference respect related measures eg sliding ratio satisfaction measure korfhage 1997 23 relative ideal measure normalized dcgmeasure two ir techniques significantly different effectiveness evaluated dcg curves case pr performance may use average interpolated precision figures standard points operation eg eleven recall levels dcv points perform statistical significance test practical significance may judged sparck jones 1974 criteria example differences less 5 marginal differences 10 essential pr performance also relative ideal performance 100 precision recall levels dcg curves relative ideal therefore difficult assess magnitude difference two dcg curves obvious significance test difference two ir techniques either one needs constructed dcg vectors ir technique normalized dividing corresponding ideal dcg vectors component component way vector position normalized value 1 represents ideal performance values range 0 1 share ideal performance cumulated technique given average dcg vector ir technique average dcg vector i1 i2 ik ideal performance normalized performance vector ndcg obtained function example based cg cgi obtain normalized cg vector normalized dcg vector ndcg obtained similar way dcg dcgi note special case normalized ideal dcg vector always norm ideal vector area normalized ideal dcg vector normalized dcg vector represents quality ir technique normalized dcg vectors two techniques also normalized difference compared way pr curves ir techniques average dcg vector normalized varia tion given ranked position summarizes vector performance analogous noninterpolated average precision dcv curve given ranked position average ndcg vector v position k given vector averages used statistical significance tests way average precision standard points operation example eleven recall levels points 24 comparison earlier measures novel measures several advantages compared several previous related measures average search length asl measure losee 1998 estimates average position relevant document retrieved list expected search length esl measure korfhage 1997 cooper 1968 average number documents must examined retrieve given number relevant documents dichotomi cal take degree document relevance account former also heavily dependent outliers relevant documents found late ranked order normalized recall measure nr short rocchio 1966 salton mcgill 1983 sliding ratio measure sr short pollack 1968 korfhage 1997 satisfaction frustration total measure sft short myaeng korfhage 1990 korfhage 1997 seek take account order documents presented user nr measure compares actual performance ir technique ideal one relevant documents retrieved first basically measures area ideal actual curves nr take degree document relevance account highly sensitive last relevant document found late ranked order sr measure takes degree document relevance account actually computes cumulated gain normalizes ideal cumulated gain retrieval result result thus quite similar ncg vectors however sr heavily dependent retrieved list size longer list ideal cumulated gain may change essentially affects normalized sr ratios rank one onwards ncg based recall base search topic first ranks ideal vector affected extension evaluation ranks improving normalized recall sr dependent outliers sensitive actual retrieved set size sr discount feature ndcg measure sft measure consists three components similar sr measure satisfaction measure considers retrieved relevant documents frustration measure irrelevant documents total measure weighted combination two like sr also sft assumes retrieved list documents obtained different orders ir techniques compared unrealistic assumption comparison since retrieved list size n n n database size different techniques may retrieve quite different documents whole idea strong feature sft comes capability punishing ir technique retrieving irrelevant documents rewarding relevant ones sft discount feature ndcg measure relative relevance ranked half life measures borlund ingwersen 1998 borlund 2000 developed interactive ir evaluation relative relevance rr short measure based comparing match systemdependent probability relevance userassessed degree relevance latter real per soninneed panel assessors match computed cosine coefficient borlund 2000 ranked ir technique output considered vectors relevance weights estimated technique user panel rr tended association measure types relevance judgments directly performance measure course cosine ir technique scores user relevance judgments low technique cannot perform well user point view ranked order documents taken account ranked half life rhl short measure gives median point accumulated relevance given query result thus improves asl taking degree document relevance account like asl rhl dependent outliers rhl may also quite differently performing queries rhl discount feature dcg strengths proposed cg dcg ncg ndcg measures summarized follows combine degree relevance documents rank affected probability relevance coherent way number retrieved documents examined rank cg dcg give estimate cumulated gain single measure matter recall base size heavily dependent outliers relevant documents found late ranked order since focus gain cumulated beginning result point interest obvious interpret direct pr curves explicitly giving number documents ndcg value holds pr curves make number documents explicit given performance may therefore mask bad performance losee 1998 addition dcg measure following advantages realistically weights gain received documents found later ranked results allows modeling user persistence examining long ranked result lists adjusting discounting factor furthermore normalized ncg ndcg measures support evaluation represent performance relative ideal based known possibly large recall base graded relevance judgments performance differences ir techniques also normalized relation ideal thereby supporting analysis performance differences jrvelin keklinen earlier proposed recall precision based evaluation measures work graded relevance judgments jrvelin keklinen 2000 keklinen jrvelin 2002a first propose use relevance level separately recall precision calculation thus different pr curves drawn level performance differences different relevance levels ir techniques may thus analyzed furthermore generalize recall precision calculation directly utilize graded document relevance scores consider precision function recall demonstrate relative effectiveness ir techniques statistical significance performance differences may vary according relevance scales used proposed measures similar standard ir measures taking document relevance scores account discount feature ndcg measure measures proposed article directly useroriented calculating gain cumulated consulting explicit number documents pr curves tend hide information generalized pr approach extends dcv document cutoff value based recall precision well however limitations measures considered chapter 4 3 case study comparison trec7 results different demonstrate use proposed measures case study testing runs trec7 ad hoc track binary nonbinary relevance judgments give results cg dcg curves exploit degrees relevance show results normalized ncg ndcg curves present results statistical test based averages ndcg vectors 31 trec7 data seventh text retrieval conference trec7 ad hoc track participants produced queries topic statements altogether 50 run queries trec text document collection collection includes 528000 documents 19 gb data participants returned lists best 1000 documents retrieved topic lists evaluated binary relevance judgments provided trec organizers national institute standards technology nist participants allowed submit three different runs could based different queries different retrieval methods voorhees harman 1999 ad hoc task two subtracks automatic manual different query construction techniques automatic technique means deriving query topic statement without manual intervention manual technique anything else voorhees harman 1999 case study used result lists 20 topics five participants trec7 ad hoc manual track topics selected availability nonbinary relevance judgments see sormunen 20022 32 relevance judgments nonbinary relevance judgments obtained rejudging documents judged relevant nist assessors 5 irrelevant documents topic new judgments made six masters students information studies fluent english though native speakers relevant irrelevant documents pooled judges know number documents previously judged relevant irrelevant pool sormunen 2002 assumption relevance rejudgment process topicality agrees trec judgments ad hoc track documents judged one one general information limitations given topics narrative searched details sense question answering new judgments done fourpoint scale 1 irrelevant document document contain information topic 2 numbers topics 351 353 355 358 360 362 364 365 372 373 377 378 384 385 387 392 393 396 399 400 details see httptrecnistgovdatatopicsengtopics351400gz 2 marginally relevant document document points topic contain information topic statement 3 fairly relevant document document contains information topic statement presentation exhaustive case multifaceted topic subthemes covered 4 highly relevant document document discusses themes topic exhaus tively case multifaceted topics subthemes covered altogether 20 topics trec7 topics trec8 reassessed table 1 results rejudgment shown respect original trec judg ments obvious almost originally irrelevant documents also assessed irrelevant rejudgment 938 trec relevant documents 75 judged relevant level 25 irrelevant seems indicate reassessors somewhat stricter original judges great overlap irrelevant documents proves new judgments reliable however case study interested compare results based different judgments show effects utilizing nonbinary relevance judgments evaluation thus use original trec judgments phase case study levels relevance trec relevant trec irrelevant total docs docs docs 691 250 2780 938 3471 605 1004 362 134 45 1138 198 total 2772 1000 2965 1000 5737 1000 table 1 distribution new relevance judgments relation original trec judgments subset 20 topics among relevant documents share highly relevant documents 201 share fairly relevant documents 305 marginal documents 494 33 application evaluation measures run trec7 result lists five participating groups new graded relevance judgments cumulated gain evaluations tested logarithm bases handling relevance levels varied parameters follows 1 tested different relevance weights different relevance levels first replaced document relevance levels 0 1 2 3 binary weights ie gave documents level 0 weight 0 documents levels 13 weight 1 weighting scheme 0111 four point scale replaced relevance levels weights 0 0 0 1 test extreme highly relevant documents valued last weighting scheme 0 1 10 100 extremes highly relevant documents valued hundred times marginally relevant documents ten times fairly relevant ones different weighting highly relevant documents may affect relative effectiveness ir techniques also pointed voorhees 2001 first last weighting schemes shown graphs 0001 scheme similar last one appearance 2 logarithm bases 2 10 tested dcg vectors base 2 models impatient users base 10 persistent ones differences results vary markedly logarithm base show results logarithm base 2 also prefer stricter test condition smaller logarithm base provides 3 average actual cg dcg vectors compared ideal average vectors 4 average actual cg dcg vectors normalized dividing ideal average vectors 34 cumulated gain figures 1a 1b present cg vector curves five runs ranks 1 100 ideal curves figure 1a shows weighting scheme 0111 1b scheme 01 10100 ranked result list highly relevant documents add either 1 100 points cumulated gain fairly relevant documents add either 1 10 points marginally relevant documents add 1 point irrelevant documents add 0 points gain 011150cg200 ideal rank figure 1a cumulated gain cg curves binary weighting b 011010014001000 cg600200a ideal rank figure 1b cumulated gain cg curves nonbinary weighting different weighting schemes change position curves compared example figure 1a binary weighting scheme performance run close c highly relevant documents given weight similar b c e close performance note graphs different scales weighting schemes figure 1a best possible curve starts level rank 100 reflecting fact rank 100 practically relevant documents found figure 1b observed ideal curve already found fairly highly relevant documents rank 50 course reflects sizes recall bases average number documents relevance levels 2 3 per topic 299 best system hangs ideal 0 39 points binary weights 1a 70 894 points nonbinary weights 1b note differences greatest rank 100 often earlier runs remain 0 6 points binary weights 1a 0 197 points nonbinary weights 1b differences ideal actual curves bound diminish ideal curve levels curves also interpreted another way figure 1a one retrieve documents best run 90 worst run order gain benefit could theoretically gained retrieving 10 documents ideal curve respect best run three times effective worst run figure 1b one retrieve documents best run get benefit theoretically obtainable rank 5 worst run provide benefit even rank 100 discounted cumulated gain figures 2a 2b show dcg vector curves five runs ranks 1 100 ideal curve log2 document rank used discounting factor discounting alone seems narrow differences systems 1a compared 2a 1b 2b discounting nonbinary weighting changes performance order systems figure 2b run seems lose run c benefit figure 2a ideal curve levels upon rank 100 best run hangs points runs remain 025 1 points thus discounting factor binary weighting runs seem perform equally figure 2b ideal curve levels upon rank 50 best run hangs 71 408 points runs remain 13 40 points actual curves still grow rank 100 beyond differences best possible curves gradually become stable 01111410 ideal rank figure 2a discounted cumulated gain dcg curves binary weighting b 0110100500dcg2000 ideal rank figure 2b discounted cumulated gain dcg curves nonbinary weighting graphs also interpreted another way figure 2a one expect user examine 40 documents best run order gain discounted benefit could theoretically gained retrieving 5 documents worst run reaches gain round rank 95 figure 2b none runs gives gain would theoretically 7be obtainable rank 5 given worst run user examine 50 documents order get discounted benefit obtained best run rank 10 respect difference effectiveness runs essential one might argue user goes say 50 documents gets real value discounted one therefore dcg data used effectiveness comparison although may hold user situation dcgbased comparison valuable system designer user less less likely scan thus documents placed real relevance value retrieval technique placing relevant documents later ranked results credited much another technique ranking earlier 36 normalized dcg vectors statistical testing figures 3a 3b show curves cg vectors normalized ideal vectors curve normalized ideal cg vector value 1 ranks actual normalized cg vectors reach due course relevant documents found differences early ranks easier observe figure 1 ncg curves readily show differences methods compared scale lack straightforward interpretation gain rank given cg curves figure 3b curves start lower figure 3a obvious highly relevant documents difficult retrieve 0111 06 04 03 01a rank figure 3a normalized cumulated gain ncg curves binary weighting 06 04 03 01a rank figure 3b normalized cumulated gain ncg curves nonbinary weighting figures 4a 4b display normalized curves dcg vectors curve normalized ideal dcg vector value 1 ranks actual normalized dcg vectors never reach start level upon rank 100 effect discounting seen comparing figures 3 4 eg order runs changes effect normalization detected comparing figure 2 figure 4 differences ir techniques easier detect comparable 0111 06 04 03 01a rank figure 4a normalized discounted cumulated gain ndcg curves binary weighting 06 04 03 01a rank figure 4b normalized discounted cumulated gain ndcg curves nonbinary weighting ndcg 0001 statistical testing differences query types based normalized average ndcg vectors vector averages used statistical significance tests way average precision document cutoff values classification used label relevance levels numbers 0 3 ordinal scale holding ordinal scale suggests nonparametric statistical tests friedman test see conover 1980 however based calculations class weights represent relative differences weights 0 1 10 100 denote differences ratio scale suggests use parametric tests anova provided assumptions sampling measurement distributions met next give grand averages vectors length 200 results friedman test anova prove differences significant table 2 ndcg averages topics statistical significance results five trec7 runs legend friedman test table 2 average first calculated topic average taken topics average would taken vectors different length results statistical tests might changed also number topics 20 rather small provide reliable results however even data illuminate behavior ndcg measures 4 discussion proposed measures based several parameters last rank considered gain values employ discounting factors apply experimenter needs know parameter values combinations use practice evaluation context scenario suggest values alternatively several values andor combinations may used obtain richer picture ir system effectiveness different condi tions consider effects parameters thereafter discuss statistical testing relevance judgments limitations measures last rank considered gain vectors various length 1 n may used computing proposed measures curves one analyzes curves alone last rank matter eventual differences ir methods observable rank region gain difference point region curves may measured directly one interested differences average gain given last rank last rank matters particularly ncg measurements suppose ir method somewhat better method b early ranks say rank 10 beyond methods starts catching en par rank 50 relevant documents found one evaluates methods ncg might statistically significantly different ranks 1 10 probably would significant difference ranks 1 100 lower positions one uses ndcg previous case difference earned method would preserved due discounting low ranked relevant documents case difference methods may statistically significant also ranks 1 100 lower positions measures cannot tell applied rank depends evaluation scenario sizes recall bases makes sense produce ndcg curves liberally ie quite low ranks significance differences ir methods present tested selected regions top n justified scenario also test data demonstrate one run may significantly better another top ranks considered similarly effective another low ranks included also say 100 see eg runs c figure 3 gain values justifying different gain values documents relevant different degrees inherently quite arbitrary often easy say one document relevant another quantification difference still remains arbitrary however determining documents equally relevant another arbitrary decision less justified light evidence relevance studies tang shaw vevea 1999 sormunen 2002 since graded relevance judgments provided reliably sensitivity evaluation results different gain quantifications easily tested sensitivity testing also typical costbenefit studies new idea even evaluation scenario would advice us gain quantifications evaluation several flat steep quantifications informs us relative performance ir methods better single one voorhees 2001 used approach trec web track evaluation weighted highly relevant documents factors 11000 relation marginal docu ments varying weighting affected relative effectiveness order ir systems test present illustrative findings based trec data also show weighting affects relative effectiveness order ir systems observe figures 4a b sec tion 36 changing weighting 0111 flat trectype weights weights 0110100 irrelevant highly relevant documents run appears effective others tang shaw vevea 1999 proposed seven optimal number relevance levels relevance judgments although findings four levels proposed measures tightly coupled particular number levels discounting factor choice ncg ndcg measures evaluation essential discounting gain documents retrieved late affects order effectiveness runs saw sections 34 35 figures 1b 2b however somewhat arbitrary apply specific form discounting consider discounting case dcg function df discounting factor current ranked position three cases interest discounting performed documents whatever rank retrieved retain relevance score sharp discount first documents would really matter hardly desirable realistic evaluation smooth discounting factor smoothness adjusted choice base b relatively small base b 2 models impatient searcher value late documents drops rapidly relatively high base b 10 models patient searcher even late documents valu able high base b 100 yields marginal discount practical ir evaluation point view propose use logarithmic discounting factor however choice base somewhat arbitrary either evaluation scenario advice evaluator base range bases could tried note dcg function case choice base would affect order effectiveness ir methods blog pair bases b since blog constant reason applying discounting case dcg rank indicated logarithm base also point discounting begins blog 1 rank region 2 b discounting would replaced boosting two borderline cases logarithm base base b b 1 approaches discounting becomes aggressive finally first document would matter hardly realistic hand b approaches infinity dcg approaches cg neither realistic believe base range 2 10 serves evaluation scenarios well practical methodological problems discussion leaves open proper parameter combinations use evalua tion unfortunate also unavoidable mathematics work whatever parameter combinations cannot advice us choose advice must come evaluation context form realistic evaluation scenarios research campaigns trec scenarios selected one evaluating ir methods busy users willing examine best answers queries makes sense evaluate shallow ranks say 30 use fairly sharp gain quantifications say 0110100 low base discounting factor say 2 hand one evaluating ir methods patient users willing dig low ranked marginal answers que ries makes sense evaluate deep ranks say 200 use moderate gain quantifications say 0123 high base discounting factor say 10 makes sense try scenarios order see whether ir methods superior one scenario scenarios argued critically assessed defended choices involved done arbitrary choice committed perhaps uncon sciously example precision averages 11 recall points binary relevance gains models well patient users willing dig deep low ranked swers matter relevant vs marginal answers clearly scenario one look normalized measures ncg ndcg propose normalized best possible behavior query rankbyrank basis therefore averages normalized vectors also less prone problems recall base size variation plague precisionrecall measurements whether based dcvs precision function recall cumulated gain curves illustrate value user actually gets discounted cumulative gain curves used forecast system performance regard users patience examining result list example cg dcg curves analyzed horizontally case study may conclude system designer would expect users examine 100 500 documents worse query types collect gain collected best query types possible persistent users go way result list eg 30 60 documents often unlikely happen system requiring behavior practice much worse system yielding gain within 50 documents relevance judgments keklinen jrvelin 2002a argue basis several theoretical laboratory field studies degree document relevance varies document users distinguish documents far relevant others furthermore many studies information seeking retrieval multiple degree relevance scales found pertinent number degrees employed varies difficult determine many degrees general depends study setting user scenarios multiple degree approaches justified evaluation methods utilize support trec based binary relevance judgments low threshold accepting document relevant topical request document needs least one sentence pertaining request count relevant trec 2001 special evaluation scenario obvious alternatives many scenarios level contribution one would count document marginal unless request factual case short factual response regarded highly relevant another giving facts marginal irrelevant completely compatible proposed measures share marginal documents high test collection utilizing treclike liberal binary relevance judgments would lead difficulties identifying better techniques data sample 50 relevant documents marginally relevant possible differences ir techniques retrieving highly relevant documents might evened possible indifference retrieving marginal documents net differences might seem practically marginal statistically insignificant statistical testing holding ordinal scale relevance judgments suggests nonparametric statistical tests wilcoxon test friedman test however weights used scale measurement becomes one interval ratio scale suggests use parametric tests anova ttest provided assumptions sampling measurement distributions met example zobel 1998 used parametric tests analyzing reliability ir experiment results also hull 1993 argues sufficient data parametric tests may used test case anova gave result different friedman effect magnitude differences ir runs considered however data set used demonstration fairly small empirical findings based proposed measures dcg measure applied trec web track 2001 voorhees 2001 text summarization experiment sakai sparck jones 2001 voorhees findings based threepoint relevance scale examined effect incorporating highly relevant documents hrds ir system evaluation weighting less sharply dcgbased evaluation found relative effectiveness ir systems affected evaluated hrds voorhees pointed moderately sharp weighting hrds dcg measurement supports evaluation hrds avoids problems caused instability due small recall bases hrds test collections sakai sparck jones first assigned weight 2 highly relevant document weight 1 partially relevant document also experimented valuations eg zero partially relevant documents sakai sparck jones used log base 2 discounting factor model users lack persistence dcg measure served test hypotheses summarization study present demonstrative findings based trec7 data also show weighting affects relative effectiveness order ir systems results exemplify usability cumulated gainbased approach ir evaluation limitations measures considered paper old new ones weaknesses three areas firstly none take account order effects relevance judg ments document overlap redundancy trec interactive track 1999 instance recall employed handle usersystem pairs rewarded retrieving distinct instances answers rather multiple overlapping documents princi ple ndcg measures may used evaluation secondly measures considered section 24 deal relevance single dimension really multidimensional vakkari hakala 2000 principle multidimensionality may accounted construction recall bases search topics leads complexity recall bases evaluation measures nevertheless added complexity may worth pursuing much effort invested ir evaluation thirdly measure based static relevance judgments unable handle dynamic changes real relevance judgments however changes users relevance criteria lead reformulated query ir system retrieve best documents reformulated query keklinen jrvelin 2002b argue complex dynamic interaction sequence simple topical interactions thus good oneshot performance retrieval system rewarded evaluation changes users information need relevance criteria affect consequent requests queries likely happen shown affect design retrieval techniques neither shown would invalidate proposed traditional evaluation measures may argued ir systems rank highly relevant documents top ranks consequently rewarded evaluation spink greisdorf bateman 1998 argued partially relevant documents important users early stages information seeking process therefore one might require ir systems rewarded retrieving partially relevant documents top ranks 40 years ir systems compared basis ability provide relevant useful documents users us seems plausible highly relevant documents people find useful findings spink greisdorf bateman really disqualify belief rather state students early states information seeking tend change relevance criteria problem definition number partially relevant documents correlate changes however turn purposes ir systems rank partially relevant documents higher say highly relevant documents measures suit perfectly comparisons basis documents weighted accordingly intend say criteria relevance judgments made propose measures take account differences relevance limitations proposed measures similar traditional meas ures proposed measures offer benefits taking degree document relevance account modeling user persistence 5 conclusions argued modern large database environments development evaluation ir methods based ability retrieve highly relevant documents often desirable user viewpoint presents liberal test ir techniques developed novel methods ir technique evaluation aim taking document relevance degrees account cg dcg measures give discounted cumulated gain given document rank retrieval results normalized variants ncg ndcg based ideal retrieval performance related traditional measures like average search length asl losee 1998 expected search length esl cooper 1968 normalized recall nr rocchio 1966 salton mcgill 1983 sliding ratio sr pollack 1968 korfhage 1997 satisfaction frustration total measure sft myaeng korfhage 1990 ranked halflife rhl borlund ingwersen1998 benefits proposed novel measures many systematically combine document rank degree relevance number retrieved documents examined rank cg dcg give estimate cumulated gain single measure matter recall base size performance determined basis recall bases search topics thus vary uncontrollable way true measures based retrieved lists novel measures heavily dependent outliers since focus gain cumulated beginning result point interest obvious interpret mask bad performance directly useroriented calculating gain cumulated consulting explicit number documents pr curves tend hide information addition dcg measure realistically weights gain received documents found later ranked results allows modeling user persistence examining long ranked result lists adjusting discounting factor furthermore normalized ncg ndcg measures support evaluation representing performance relative ideal based known possibly large recall base graded relevance judgments performance differences ir techniques also normalized relation ideal thereby supporting analysis performance differences essential feature proposed measures weighting documents different levels relevance value highly relevant document compared value fairly marginally relevant documents absolute value subjective matter also depends information seeking situation may difficult justify particular weighting scheme evaluation scenario suggest otherwise several weight values may used obtain richer picture ir system effectiveness different conditions regarding least somewhat relevant documents equally relevant also arbitrary albeit traditional decision also counterintuitive may argued ir systems rank highly relevant documents top ranks one might require ir systems rewarded retrieving partially relevant documents top ranks however measures suit perfectly comparisons basis documents weighted accordingly traditional measures allow cg dcg measures complement pr based measures jrvelin keklinen 2000 keklinen jrvelin 2002a precision fixed recall levels hides users effort given recall level dcvbased precision recall graphs better still make value gained ranked position explicit cg dcg graphs provide directly distance theoretically best possible curve shows effort wasted lessthanperfect useless documents normalized cg dcg graphs show explicitly share ideal performance given ir technique make statistical comparisons possible advantage pr based measures treat requests different number relevant documents equally systems point view precision recall level comparable contrast cg dcg curves show users point view number documents needed achieve certain gain together theoretically best possible curve also provide stopping rule best possible curve turns horizontal nothing gained retrieving examining documents generally proposed evaluation measures case demonstrate graded relevance judgments applicable ir experiments dichotomous liberal relevance judgments generally applied may permissive consequently easily give credit ir system performance believe modern large environ 9ments proposed novel measures used whenever possible provide richer information evaluation acknowledgements thank fire group university tampere helpful comments ir lab programming r evaluation retrieval effectiveness fulltext documentretrieval system evaluation interactive information retrieval systems measures relative relevance ranked halflife performance indicators interactive ir wilkinson practical nonparametric statistics 2nd expected search length single measure retrieval effectiveness based weak ordering action retrieval systems evaluation interactive boolean natural language searching online medical textbook using statistical testing evaluation retrieval experiments journal american society information science technology 53 libraries unlimited greenwood village information storage retrieval text retrieval filtering analytic models performance integration user profiles models experiments information retrieval measures comparison information retrieval systems ranking principle document retrieval systems optimization evaluation introduction modern information retrieval method measuring wide range performance boolean queries fulltext databases online extensions stairs study empirical evidence hypothesised ineffectiveness boolean queries large fulltext databases liberal relevance criteria trec counting negligible documents proceedingsin proceedings 25th annual international acm sigir conference research development information retrievalproceedings automatic indexing highly relevant non relevant examining different regions relevance changes relevance criteria problem stages task performance evaluation highly relevant documents overview seventh text retrieval conference trec7 online reliable results largescale information retrieval experiments proceedingsin proceedings 21st annual international acm sigir conference research development information trievalproceedings revised july tr evaluation retrieval effectiveness fulltext documentretrieval system integration user profiles models experiments information retrieval using statistical testing evaluation retrieval experiments evaluation interactive boolean natural language searching online medical textbook information storage retrieval impact query structure query expansion retrieval performance reliable results largescale information retrieval experiments measures relative relevance ranked halflife text retrieval filtering towards identification optimal number relevance categories highly relevant relevant evaluation methods retrieving highly relevant documents evaluation highly relevant documents generic summaries indexing information retrieval liberal relevance criteria trec introduction modern information retrieval coeffects query structure expansion retrieval performance probabilistic text retrieval extensions stairs studymyampersandmdashempirical evidence hypothesised ineffectiveness boolean queries large fulltext databases using graded relevance assessments ir evaluation ctr mounia lalmas gabriella kazai report adhoc track inex 2005 workshop acm sigir forum v40 n1 june 2006 paul ogilvie mounia lalmas investigating exhaustivity dimension contentoriented xml element retrieval evaluation proceedings 15th acm international conference information knowledge management november 0611 2006 arlington virginia usa mette skov birger larsen peter ingwersen inter intradocument contexts applied polyrepresentation proceedings 1st international conference information interaction context october 1820 2006 copenhagen denmark tetsuya sakai reliability factoid question answering evaluation acm transactions asian language information processing talip v6 n1 p3es april 2007 crestan claude de loupy natural language processing browse help proceedings 27th annual international acm sigir conference research development information retrieval july 2529 2004 sheffield united kingdom tetsuya sakai evaluating evaluation metrics based bootstrap proceedings 29th annual international acm sigir conference research development information retrieval august 0611 2006 seattle washington usa crestan claude de loupy browsing help faster document retrieval proceedings 20th international conference computational linguistics p576es august 2327 2004 geneva switzerland tetsuya sakai reliability information retrieval metrics based graded relevance information processing management international journal v43 n2 p531548 march 2007 egidio terra robert warren poison pills harmful relevant documents feedback proceedings 14th acm international conference information knowledge management october 31november 05 2005 bremen germany gabriella kazai mounia lalmas arjen p de vries overlap problem contentoriented xml retrieval evaluation proceedings 27th annual international acm sigir conference research development information retrieval july 2529 2004 sheffield united kingdom robert losee percent perfect performance ppp information processing management international journal v43 n4 p10201029 july 2007 charles l clarke controlling overlap contentoriented xml retrieval proceedings 28th annual international acm sigir conference research development information retrieval august 1519 2005 salvador brazil mounia lalmas anastasios tombros evaluating xml retrieval effectiveness inex acm sigir forum v41 n1 p4057 june 2007 jaana keklinen binary graded relevance ir evaluations comparison effects ranking ir systems information processing management international journal v41 n5 p10191033 september 2005 per ahlgren jaana keklinen indexing strategies swedish full text retrieval different user scenarios information processing management international journal v43 n1 p81102 january 2007 jorge r herskovic sriram iyengar elmer v bernstam using hit curves compare search algorithm performance journal biomedical informatics v40 n2 p9399 april 2007 yuting liu tieyan liu tao qin zhiming hang li supervised rank aggregation proceedings 16th international conference world wide web may 0812 2007 banff alberta canada thanh tin tang nick craswell david hawking kathy griffiths helen christensen quality relevance domainspecific search case study mental health information retrieval v9 n2 p207225 march 2006 ryen w white using searcher simulations redesign polyrepresentative implicit feedback interface information processing management international journal v42 n5 p11851202 september 2006 hongyuan zha zhaohui zheng haoying fu gordon sun incorporating query difference learning retrieval functions world wide web search proceedings 15th acm international conference information knowledge management november 0611 2006 arlington virginia usa vincenzo della mea stefano mizzaro measuring retrieval effectiveness new proposal first experimental validation journal american society information science technology v55 n6 p530543 april 2004 gabriella kazai mounia lalmas extended cumulated gain measures evaluation contentoriented xml retrieval acm transactions information systems tois v24 n4 p503542 october 2006