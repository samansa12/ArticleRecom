modifying sparse cholesky factorization given sparse symmetric positive definite matrix bf aasf associated sparse cholesky factorization bf ldlsf bf llsf develop sparse techniques obtaining new factorization associated either adding column bf deleting column bf techniques based analysis manipulation underlying graph structure ideas gill et al math comp 28 1974 pp 505535 modifying dense cholesky factorization show methods extend general case arbitrary sparse symmetric positive definite matrix modified methods optimal sense take time proportional number nonzero entries bf l bf change b introduction paper presents method updating downdating sparse cholesky factorization matrix aa n precisely evaluate cholesky factorization aa either oe 1 corresponding update w arbitrary oe gamma1 corresponding downdate w column aa aa must symmetric positive definite techniques develop matrix aa extended determine effects cholesky factors general symmetric positive definite matrix symmetric change form preserves positive definiteness methods optimal sense take time proportional number nonzero entries l change many applications techniques presented paper linear program dual active set algorithm lp dasa 19 matrix corresponds basic variables current basis linear program successive iterations bring variables basis leading changes form aa application areas techniques developed paper applicable include leastsquares problems statistics analysis electrical circuits structural mechanics sensitivity analysis linear programming boundary condition changes partial differential equations domain decomposition methods boundary element methods discussion application areas others see 18 section 2 introduces notation introduction sparse matrix techniques see 4 8 x3 discuss structure nonzero elements cholesky factorization aa x4 discuss structure associated cholesky factors aa symbolic update downdate methods provide framework sparse version method c5 gill golub murray saunders 15 modifying dense cholesky factorization discuss sparse algorithm x5 section 6 presents general algorithm modifying sparse cholesky factorization sparse symmetric positive definite matrix implementation details modification algorithm associated aa summarized x7 results numerical experiment large optimization problem netlib 3 presented x8 section 9 concludes discussion future work notation throughout paper matrices capital bold letters like l vectors lower case bold letters like x v sets multisets calligraphic style like l p scalars either lower case greek letters italic style like oe k given location nonzero elements aa perform symbolic factorization terminology introduced george liu 8 matrix predict location nonzero elements cholesky factor l actuality predicted nonzeros may zero due numerical cancellation factorization process statement l ij 6 0 mean l ij symbolically nonzero diagonal l always nonzero since matrices factor positive definite see 24 p 253 nonzero pattern column j l denoted l denotes collection patterns similarly j denotes nonzero pattern column j collection patterns elimination tree defined terms parent map see 20 gives row index associated given node j first nonzero element column j l beneath diagonal element denotes smallest element convention min empty set zero note j j except case diagonal element column j nonzero element parent map children multifunction children node k set defined ancestors node j denoted pj set successive parents powers map defined usual way 0 identity ifold composition sequence nodes j j forming pk called path j associated tree root collection paths leading root form elimination tree set trees elimination forest typically single tree whose root however column j aa one nonzero element diagonal element j root separate tree number elements size set x denoted jx j jaj jlj denote sum sizes sets contain define directed graph gm matrix nonzero pattern vertex edge sets vertex set directed edge set 3 symbolic factorization approach generating pattern set l called 23 symbolic factorization matrix form aa given algorithm 1 see 9 20 algorithm 1 symbolic factorization aa min k j ka end algorithm 1 basically says pattern column j l expressed union patterns column l whose parent j patterns columns whose first nonzero element j elimination tree connecting child parent easily formed symbolic factorization algorithm 1 done ojlj 1 asymptotic complexity notation defined 2 write exist positive constants c n 0 0 fn cgn n n 0 observe pattern parent node j contains entries pattern column j except j 22 proceeding induction k ancestor j leads following relation l j path pj first part proposition proof given 22 proof differs slightly one 22 include since proof technique exploited later proposition 31 j l j pj furthermore k j 2 proof obviously given element l j 6 j since see following relation holds suppose 2 holds integer l 0 let k denote l j 1 fact k implies hence either 2 holds l replaced l 1 since 2 violated l sufficiently large conclude exists l consequently element l j contained pj ancestor k pj pk since already shown l j pj proof complete see symbolic factorization aa obtained updating symbolic factorization aa using algorithm structure algorithm 1 new pattern l j equal old pattern l j union entries arise new children pattern new column put bar matrix set multiset denote value update downdate complete downdating easy set union computed cannot undone without knowledge entries entered set keep track information storing elements l multisets rather sets multiset associated column j form multiplicity mi j number children j contain row index pattern plus number columns whose smallest entry j contain row index equivalently definition undo set union subtracting multiplicities define operations involving multisets first x multiset consisting pairs mi mi multiplicity associated x set obtained removing multiplicities words multiset x associated base set x satisfy relation define addition multiset x set following way similarly subtraction set multiset x defined multiset subtraction x undoes prior addition multiset x set contrast x n equal x x disjoint sets algorithm 2 performs symbolic factorization aa set union operation replaced multiset addition algorithm identical algorithm 1 except bookkeeping associated multiplicities algorithm 2 symbolic factorization aa using multisets c 2 gamma1 j end k min end end conclude section result concerning relation patterns aa patterns aa ww proposition 32 let c patterns associated symmetric positive definite matrices c respectively neglecting numerical cancellation c j j j implies l c j l c ld patterns associated cholesky factors c respectively proof 8 21 shown edge j contained graph cholesky factor symmetric positive definite matrix c path j graph c intermediate vertex path 1 min fi jg c j j j paths associated graph c subset paths associated graph follows l c j ignoring numerical cancellation edges graph aa subset edges graph aa ww proposition 32 conclude edges graphs associated cholesky factors satisfy inclusion result columns vectors w used update aa ww chosen columns fixed matrix b fillreducing permutation p found cholesky factors pbb p sparse 1 example proposition 32 cholesky factors paa p paa ww p least sparse pbb p 4 modifying symbolic factors let modified version put bar matrix set multiset denote value update downdate complete update obtained appending column w right downdate obtained deleting column w hence oe either 1 w last column update oe gamma1 w column downdate since differ single column follows proposition 32 l j l j j update l j l j downdate moreover multisets associated cholesky factor either updated downdated matrix structure described following theorem theorem 41 let k index associated first nonzero component w update pk pk l complement pk l except k one new ancestors k downdate pk pk l l except k one old ancestors k proof begin let us consider update show element pk member pk well clearly k lies pk pk proceeding induction suppose 0 k need show complete induction pk induction step complete j1 l 6 l proposition 32 l l following relation holds suppose 3 holds integer p 1 let q denote p l proposition 32 l 2 l l l l combining 3 follows 1 l 2 l q l definition parent hence either p1 holds p replaced p 1 since 3 violated p sufficiently large conclude exists integer p l follows pk induction step complete pk pk suppose l 2 pk c important recall k index first nonzero component w vector appearing update observe l cannot equal k since l 2 pk c k 2 pk proof l l induction depth defined l children child loop algorithm 2 skipped either l l l l evaluated since l 6 k pattern associated w cannot added l l hence l trivial assuming p 0 l l whenever l 2 pk c dl p let us suppose induction assumption since l 6 k pattern w added l l consequently algorithm 2 executed l l completes induction step consider downdate part theorem rearranging downdate relation aa hence downdate think updated version consequently second part theorem follows directly first part 41 symbolic update algorithm present algorithm evaluating new pattern l associated update based theorem 41 sets l j change associated pk k index first nonzero component w referring algorithm 2 set marching path j evaluate changes induced additional column order bookkeeping four cases consider case 1 start new path need add pattern w l case 2 c 2 pk case c child j new old elimination tree since pattern l c may differ l c need add difference l j since j unique child path pk one node c satisfies conditions also note theorem 41 l hence node lead adjustment l algorithm 2 case 3 case c child j new elimination tree old tree entire set l c added l since included l theorem 41 hence c 62 pk c equivalently c 2 pk since node path pk k one child path one node c satisfying conditions lies path pk case 4 case c child j old elimination tree new tree set l c subtracted l since previously added l fact implies c 2 pk algorithm follows refer nodes c satisfy conditions lost children cases every node c led adjustments pattern located path pk detailed algorithm appears simply march path k root making adjustments enumerated algorithm 3 symbolic update add new column w case 1 first node path j 6 0 case 2 c old child j possibly changed else case 3 c new child j lost child c place c lostchildqueue c case 4 consider lost child j c lostchildqueue j end time taken algorithm given following lemma lemma 42 time execute algorithm 3 bounded constant times number entries associated patterns nodes new path pk time ob proof algorithm 3 simply march path pk making adjustments j proceed node j take time proportional jl j j plus time taken process children j node visited child c twice since falls one two four cases enumerated node c new child one node lost child another work proportional jl c j jl c j accounted step c instead j time make adjustment pattern bounded constant times either jl j j jl j j since jl theorem 41 proof complete practice reduce execution time algorithm 3 skipping nodes l current node j lost children child c falls case 2 l j update skipped execution time modified algorithm one implement 42 symbolic downdate algorithm let us consider removal column w let k index first nonzero entry w symbolic downdate algorithm analogous symbolic update algorithm roles pk pk interchanged accordance theorem 41 instead adding entries l j subtract entries instead lost child queues new child queues instead walking path pk walk path pk pk algorithm 4 symbolic downdate remove column w case 1 first node path j 6 0 case 2 c old child j possibly changed else case 3 c lost child j new child c place c newchildqueue c case 4 consider new child j c newchildqueue j end algorithm 4 similar algorithm 3 execution time obeys following estimate lemma 43 time execute algorithm 4 bounded constant times number entries associated patterns nodes old path pk time achieve practice speedup check whether l changes given node j 2 pk time taken modified algorithm 4 5 numerical factors add delete column update downdate symbolic factorization order determine location cholesky factor either new nonzero entries nonzero entries zero knowing location nonzero entries update numerical value entries first consider case l dense draw ideas 15 show method extends sparse case 51 dense matrices algorithm implement numerical update downdate based method c5 15 dense matrices summarize approach start writing positive account assumption aa aa positive definite since matrices aa congruent sylvesters law inertia see 24 number positive negative zero eigenvalues eigenvalues one multiplicity corresponding eigenvectors orthogonal v 1 corresponding eigenvector v since aa positive definite eigenvalues positive implies 1 combining 4 5 sequence givens rotations product denoted g 1 chosen 1 e 1 vector every entry zero except first entry matrix lower hessenberg structure second sequence givens rotations product denoted g 2 chosen lower triangular matrix denoted g following form ffi fl vectors computed algorithm 5 diagonal elements g given g elements diagonal algorithm 5 compute g dense case else find g 1 zero first entry v 1 end find g 2 combine obtain g end algorithm 5 algorithm 6 evaluate new cholesky factor forming g explicitly 15 taking advantage special structure g product computed column column moving right left practice l overwritten l algorithm 6 compute 1 end end algorithm 6 observe 13 multiplies eliminated l stored product ld diagonal matrix components ffi absorbed fl adjusted accordingly ffi algorithm 6 eliminated exploit simplification numerical results reported x8 52 sparsity pattern v sparse case sparse nonzero pattern crucial since elements g satisfy j conclude columns l associated nonzero components v enter computation l nonzero pattern v found using following lemma lemma 51 nodes reachable given node k paths directed graph gl coincide path pk proof pk single element lemma holds proceeding induction suppose lemma holds k jpkj j pk elements induction hypothesis nodes reachable k paths directed graph gl coincide path pk nodes reachable one step k consist elements l k proposition 31 elements l k contained path pk induction hypothesis nodes reachable coincide pi pk nodes reachable k consist fkg union nodes reachable l k since nodes reachable k contained pk hand p element l row p k column p1 k nonzero hence elements pk reachable k since nodes coincide nodes reachable k paths directed graph gl induction step complete theorem 52 symbolic downdate aa w column nonzero pattern equal path pk old elimination tree l proof let 0g theorem 51 gilbert 10 11 14 states nonzero pattern v set nodes reachable nodes w paths directed graph gl algorithm 1 w l k hence element w reachable k path length one nodes reachable w subset nodes reachable k conversely since k 2 w nodes reachable k subset nodes reachable w combining inclusions nodes reachable k w lemma 51 nodes reachable k coincide path pk corollary 53 symbolic update aa nonzero pattern equal path pk new elimination tree l k defined 6 proof since view l cholesky factor downdate hence apply theorem 52 effect replacing p p 53 sparse matrices dense algorithm presented start section write specific let us consider case 7 corresponds update nonzero elements lie along diagonal intersection rows 2 pk columns j 2 pk k defined 6 essence extract submatrix corresponding rows columns apply algorithm 5 dense submatrix modify submatrix l consisting rows columns associated pk reinsert dense submatrix sparse matrix l algebraic level think process following way p permutation matrix property columns associated pk moved first jpkj columns multiplication right matrix p diagonal identity lower right corner dense upper left corner v elements l 21 correspond elements l ij l 2 pk c follows 2 l c note general algorithm 6 columnoriented 8 multiplied givens rotations computed algorithm 5 obtain apply p left p right 9 obtain l neither l 12 l 22 modified 7 corresponds downdate discussion update except pk replaces pk role l j l j interchanged summary sparse update downdate cholesky factorization accomplished first evaluating nonzero entries contained path pk pk k defined 6 apply dense algorithm 5 vector symbolically nonzero entries v update entries l rows columns associated indices pk pk using algorithm 6 following result indicates algorithm 6 applied l 11 specific structure proposition 54 symbolic downdate l 11 lower triangular matrix dense profile row 1 integer proof rows columns columns l 11 correspond nodes path pk assume nodes relabeled follows l 11 1 consequently l letting p smallest index p proof complete corollary 55 symbolic update l 11 lower triangular matrix dense profile row 1 integer proof follows immediately proposition 54 replacing pk pk consequence proposition 54 corollary 55 proposition 32 skip index algorithm 6 algorithm 6 applied sparse l opposed dense submatrix indices j take values pk l j respectively downdate take values pk l j respectively update 6 arbitrary symbolic numerical factors methods developed computing modification cholesky factors aa corresponding addition deletion columns used determine effect cholesky factors general symmetric positive definite matrix symmetric change form preserves positive definiteness briefly describe algorithms 1 6 modified general case let j denote nonzero pattern lower triangular part symbolic factorization 5 6 7 8 23 obtained replacing union k terms algorithm 1 set j change l j algorithm 1 given leads change algorithm 2 computing multiplicities multiplicity index l j becomes loop involving k terms algorithm 2 replaced single statement precisely k min end entries removed added symbolically aa deletion addition columns numerical cancellation ignored numerical cancellation entries ignored however way entries dropped numerical cancellation taken account neither inclusions may hold resolve problem using symbolic modification scheme two steps symbolic update phase new nonzero entries taken account followed separate downdate phase handle entries become numerically zero since modification step involves update phase followed downdate phase attach section overbar quantities associated update underbar quantities associated downdate let w nonzero pattern w namely 0g first phase entries w symbolically added j j 2 w second symbolic phase entries w symbolically deleted j 2 w practice need introduce drop tolerance replace equality 10 inequality general matrix analogue theorem 41 following theorem 61 ff first index ff 6 ff pff pff l 2 pff c fi first index fi 6 fi evaluating modification symbolic factorization associated start first index ff ff 6 ff march path pff making changes l j second phase start first index fi 6 fi march path pfi making changes analogue algorithm 3 general case differs starting index ff addition sets j n j pass jloop algorithm 7a symbolic update phase general matrix case 1 first node path j 6 0 case 2 c old child j possibly changed else case 3 c new child j lost child c place c lostchildqueue c case 4 consider lost child j c lostchildqueue j end algorithm 7a similarly analogue algorithm 4 general case differs starting index fi subtraction sets j n j pass jloop algorithm 7b symbolic downdate phase general matrix case 1 first node path j 6 0 case 2 c old child j possibly changed else case 3 c lost child j new child c place c newchildqueue c case 4 consider new child j c newchildqueue j end algorithm 7b algorithms 5 6 completely unchanged general case applied completion algorithm 7b know location new nonzero entries cholesky factor process submatrix associated rows columns pk k index first nonzero element w form aa gotten either adding deleting column assuming numerical cancellations algorithm 7b skipped add column since j similarly column removed algorithm 7a skipped since j hence algorithm 7a followed algorithm 7b applied matrix form aa algorithm 7a takes effect update algorithm 7b takes effect downdate thus approach presented section arbitrary symmetric positive definite matrix generalizes earlier approach focus matrices form aa 7 implementation issues section discuss implementation issues context updates downdates matrix form aa similar discussion applies general symmetric positive definite matrix assume columns matrix product aa chosen among columns fixed matrix b update downdate algorithms used compute modification cholesky factor corresponding additions deletions columns cholesky factorization initial aa columns added deleted often preceded fill reducing permutation p rows columns example could compute permutation reduce fill bb since cholesky factors aa least sparse bb proposition 32 regardless columns chosen columns b based number nonzeros column cholesky factors bb could allocate static storage structure always contain cholesky factors aa hand could lead wasted space number nonzeros cholesky factors aa far less number nonzeros cholesky factors bb alternatively could store cholesky factor current aa smaller space reallocate storage updates downdates based changes nonzero patterns time initial cholesky factorization aa given see 8 following om 3 l dense update downdate proceeds first finding new symbolic factors required path pk updating pk downdating using algorithm 3 4 modified skip constant time column j change algorithms 5 6 applied columns path lower triangular solve system algorithm 5 done time downdating ob updating 14 remainder algorithm 5 takes time ojpkj downdating ojpkj updating sparse form algorithm 6 discussed x53 computes product downdating ob updating since l j l j update follows asymptotic time entire downdate update symbolic numeric equal asymptotic time algorithm 6 much less om 2 algorithms 5 6 dense case 8 experimental results developed matlab codes experiment algorithms presented paper including algorithms x6 general symmetric positive definite matrix section present results numerical experiment large sparse optimization problem netlib 3 computer used experiment model 170 ultrasparc equipped 256mb memory matlab version 42c 81 experimental design selected optimization problem airline scheduling dfl001 constraint matrix b 6071by12230 35632 nonzeros matrix bb 37923 nonzeros strictly lower triangular part cholesky factor lb 149 million nonzeros fillminimizing permutation pb rows b described requires 112 billion floatingpoint operations 115 seconds compute lp dual active set algorithm require matrix however noted earlier upper bound number nonzeros occur execution lp dasa high level fillin lb result highly irregular nonzero pattern b basis matrix 0 corresponding optimal solution linear programming problem 5446 columns wrote set matlab scripts implements complete cholesky updatedowndate algorithm discussed x7 first found pb using 101 trials matlabs column multiple minimum degree ordering algorithm colmmd 12 100 different random permutation rows b took best permutation found permutation pb factor l 0 0 831 thousand nonzeros took 481 million floatingpoint operations 51 seconds compute using matlabs chol following method used lp dasa added gamma12 diagonal ensure positive definiteness used permutation pb entire experiment initial symbolic factorization took 15 seconds algorithm 2 matrix factor required lp dasa use matlabs sparse matrix data structure since matlab removes explicit zeros changing nonzero pattern single entry cause matlab make new copy entire matrix would defeat asymptotic performance algorithms instead columnoriented data structure use l l l consists three arrays length jl b j array length contains indices first entry column array length holding number nonzeros column columns allocated column hold many nonzeros corresponding column lb without reallocation starting optimal basis 5446 columns added one column time basis included 12230 columns removed one time obtain optimal basis total time work required modify factors 76598 seconds 615 billion floating point operations divides 441 seconds bookkeeping keep track basis set b 6051 seconds symbolic updates downdates algorithms 3 4 c 21167 seconds solve 4977 seconds remainder algorithm 5 43962 seconds algorithm 6 algorithm 6 clearly dominates modification algorithm symbolic updates downdates took little time even though algorithms 3 4 well suited implementation matlab comparison using cholesky factorization solve linear system dense righthandside b using column oriented data structure l step took total 93418 seconds 677 billion floating point operations solve takes ojlj time note much higher time taken solve algorithm 5 v w sparse time taken entire updatedowndate computation would much smaller code written compiled language solving one system dense right hand side using factorization optimal basis takes 553 seconds using columnoriented data structure 126 seconds using matlab sparse matrix l 0215 seconds fortran 77 82 numerical accuracy order measure error computed cholesky factorization evaluated difference kaa computed cholesky factorization airline scheduling matrix x8 l 149 million nonzeros impractical compute product update obtain quick accurate estimate kek 1 applied strategy presented 16 see 17 p 139 symbolic statement algorithm estimate 1norm inverse matrix used gradient accent approach compute local maximum following problem l used multiple times following algorithm copied data structure l matlab sparse matrix algorithm 8 estimate 1norm matrix e ae current estimate kek end algorithm 8 improve accuracy 1norm estimate used algorithm 8 three times second third trials different starting vector x used described 16 observe algorithm 8 makes use product matrix e vector feature important context sparse matrices since e contains term impractical compute product practical multiply vector airline scheduling matrix x8 values kek 1 initially step 6784 end 249 154theta10 gamma10 respectively estimates obtained using algorithm 8 identical three steps hand times compute kek 1 initial step step 6784 1379 2795 seconds times three trials algorithm 8 87 147 seconds respectively excluding time construct matlab sparse matrix l methods quite accurate problem 6784 updates 6784 downdates 13568 changes 1norm e increased factor 618 figure 1 shows estimated value kek 1 computed every steps using algorithm 8 1norm matrix aa increases 4580 initially 11070 iteration 6784 returns 4580 iteration 13568 hence product computed cholesky factors agrees product aa 15 significant digits initially products agree 12 significant digits 13568 modifications step norm estimated algorithm figure 1 estimated 1norm error cholesky factorization 83 alternative permutations methods optimal sense take time proportional number nonzero entries l change step however optimal respect fillin since assume single initial permutation subsequent permutations fillreducing ordering bb might best ordering use basis matrices simple pathological example mbyn matrix b nonzero pattern column b unique pair integers set f1 2 mg case every element bb nonzero nonzero pattern aa arbitrary matrix changes might advantageous compute fillreducing ordering aa size factors grow large refactorization new permutation would required found fillreducing permutation pa optimal basis 0 best 101 trials colmmd results factor l 381 thousand nonzeros requiring 169 million floating point operations compute significantly less number nonzeros 831 thousand floating point operations 481 million associated fill reducing permutation bb also computed ordering aa step using colmmd computed number nonzeros factor factorize using permutation although takes 1 second compute ordering 12 symbolic step nonzeros l three different permutations figure 2 nonzeros l using three different permutations factorization 13 practical use 101 random trials step figure 2 depicts nonzero counts l three different permutations 13568 steps fixed permutation pb results smooth curve starting 831 thousand peaking 149 million fixed permutation pa results number nonzeros l starts 381 thousand rises quickly leaving figure step 1206 peaking 74 million middle surpasses pb step 267 using permutation p computed step gives erratic line figure starting 390 thousand peaking 19 million middle results indicate might advantageous start fixed permutation pa use 267 steps refactorize permutation p computed step 267 results new factor 463 thousand nonzeros near center figure however basis includes columns b case pb permutation used 9 summary presented new method updating downdating factorization sparse symmetric positive definite matrix aa experimental results show method fast accurate practice extensions arbitrary sparse symmetric positive definite matrix discussed mention additional extension work would useful make use supernodal form factorization use related compressed pattern l 8 method used numerical factorization first basis matrix course factor would copied simple columnoriented data structure keeping supernodal form potential reducing time taken symbolic factorization algorithm 2 symbolic update downdate algorithms 3 4 numerical update downdate dense matrix kernels could used algorithms 5 6 however supernodes would merge update split downdate complicating supernodal form factorization r approximate minimum degree ordering algorithm introduction algorithms distribution mathematical software via electronic mail direct methods sparse matrices yale sparse matrix package design user interface sparse matrix package data structure sparse qr lu factorizations predicting structure sparse matrix computations sparse matrices matlab design implementation efficient algorithm compute row column counts sparse cholesky factorization sparse partial pivoting time proportional arithmetic operations methods modifying matrix factorizations active set strategies lp dual active set algorithm role elimination trees sparse factorization algorithmic aspects vertex elimination graphs new implementation sparse gaussian elimination efficient solution sparse systems linear nonlinear equations new york tr ctr w hager dual active set algorithm application linear programming computational optimization applications v21 n3 p263275 march 2002 ove edlund software package sparse orthogonal factorization updating acm transactions mathematical software toms v28 n4 p448482 december 2002 matine bergounioux karl kunisch primaldual strategy stateconstrained optimal control problems computational optimization applications v22 n2 p193224 july 2002 frank dellaert michael kaess square root sam simultaneous localization mapping via square root information smoothing international journal robotics research v25 n12 p11811203 december 2006 nicholas gould jennifer scott yifan hu numerical evaluation sparse direct solvers solution large sparse symmetric linear systems equations acm transactions mathematical software toms v33 n2 p10es june 2007 olga sorkine daniel cohenor dror irony sivan toledo geometryaware bases shape approximation ieee transactions visualization computer graphics v11 n2 p171180 march 2005