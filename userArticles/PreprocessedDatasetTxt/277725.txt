implementation cilk5 multithreaded language fifth release multithreaded language cilk uses provably good workstealing scheduling algorithm similar first system language completely redesigned runtime system completely reengineered efficiency new implementation aided clear strategy arose theoretical analysis scheduling algorithm concentrate minimizing overheads contribute work even expense overheads contribute critical path although may seem counterintuitive move overheads onto critical path workfirst principle led portable cilk5 implementation typical cost spawning parallel thread 2 6 times cost c function call variety contemporary machines many cilk programs run one processor virtually degradation compared equivalent c programs paper describes workfirst principle exploited design cilk5s compiler runtime system particular present cilk5s novel twoclone compilation strategy dijkstralike mutualexclusion protocol implementing ready deque workstealing scheduler b introduction cilk multithreaded language parallel programming generalizes semantics c introducing linguistic constructs parallel control original cilk1 release 3 4 18 featured provably efficient randomized work stealing scheduler 3 5 language clumsy parallelism exposed hand using explicit continuation passing cilk language implemented research supported part defense advanced research projects agency darpa grant n000149410985 computing facilities provided mit xolas project thanks generous equipment donation sun microsystems appear proceedings 1998 acm sigplan conference programming language design implementation pldi montreal canada june 1998 latest cilk5 release 8 still uses theoretically efficient scheduler language simplified considerably employs callreturn semantics parallelism features linguistically simple inlet mechanism nondeterministic control cilk5 designed run efficiently contemporary symmetric multiprocessors smps feature hardware support shared memory coded many applications cilk including socrates cilkchess chessplaying programs prizes international competitions philosophy behind cilk development make cilk language true parallel extension c semantically respect performance parallel computer cilk control constructs allow program execute parallel cilk keywords parallel control elided cilk program however syntactically semantically correct c program results call c elision generally serial elision cilk program cilk faithful extension c c elision cilk program correct implementation semantics program moreover one processor parallel cilk program scales run nearly fast c elision unlike cilk1 cilk scheduler identifiable piece code cilk5 compiler runtime system bear responsibility scheduling obtain ef ficiency course attempted reduce scheduling overheads overheads larger impact execution time others however theoretical understanding cilks scheduling algorithm 3 5 allowed us identify optimize common cases according abstract theory performance cilk computation characterized two quantities work total time needed execute computation serially criticalpath length execution time infinite number processors cilk provides instrumentation allows user measure two quantities within cilks scheduler identify given cost contributing either work overhead criticalpath overhead much efficiency cilk derives following principle shall justify section 3 workfirst principle minimize scheduling overhead borne work computation specifically move overheads work onto critical path workfirst principle played important role design earlier cilk systems cilk5 exploits principle extensively workfirst principle inspired twoclone strategy compiling cilk programs cilk2c compiler 23 sourcetosource translator transforms cilk source c postsource makes calls cilks runtime library c postsource run gcc compiler produce object code cilk2c compiler produces two clones every cilk procedurea fast clone slow clone fast clone identical respects c elision cilk program executes common case serial semantics suffice slow clone executed infrequent case parallel semantics concomitant bookkeeping required communication due scheduling occurs slow clone contributes criticalpath overhead work overhead workfirst principle also inspired dijkstralike 11 sharedmemory mutualexclusion protocol part runtime loadbalancing scheduler cilks scheduler uses workstealing algorithm idle processors called thieves steal threads busy processors called vic tims cilks scheduler guarantees cost stealing contributes criticalpath overhead work overhead nevertheless hard avoid mutualexclusion costs incurred potential victim contribute work minimize work overhead instead using locking cilks runtime system uses dijkstralike protocol call protocol manage runtime deque ready threads workstealing algorithm added advantage protocol allows exception signaled working processor additional work overhead feature used cilks abort mechanism remainder paper organized follows section 2 overviews basic features cilk language section 3 justifies workfirst principle section 4 describes twoclone strategy implemented section 5 presents protocol section 6 gives empirical evidence cilk5 scheduler efficient finally section 7 presents related work offers conclusions 2 cilk language section presents brief overview cilk extensions c supported cilk5 complete description consult cilk5 manual 8 key features language specification parallelism synchroniza tion spawn sync keywords specification nondeterminism using inlet abort include stdlibh include stdioh include cilkh cilk int fib int n n2 return n else int x return cilk int main int argc char argv int n result printf result dn result return 0 figure 1 simple cilk program compute nth fibonacci number parallel using bad algorithm basic cilk language understood example figure 1 shows cilk program computes nth fibonacci number 1 observe program would ordinary c program three keywords cilk spawn sync elided keyword cilk identifies fib cilk procedure parallel analog c function parallelism created keyword spawn precedes invocation procedure semantics spawn differs c function call parent continue execute parallel child instead waiting child complete done c cilks scheduler takes responsibility scheduling spawned procedures processors parallel computer cilk procedure cannot safely use values returned children executes sync statement sync statement local barrier global one ex ample used messagepassing programming fibonacci example sync statement required statement return xy avoid anomaly would occur x summed computed addition explicit synchronization provided sync statement every cilk procedure syncs implicitly returns thus ensuring children terminate ordinarily spawned procedure returns returned value simply stored variable parents frame program uses inefficient algorithm runs exponential time although logarithmictime methods known 9 p 850 program nevertheless provides good didactic example cilk int fib int n int inlet void summer int result x result return n2 return n else summerspawn fib n1 summerspawn fib n2 return figure 2 using inlet compute nth fibonnaci number occasionally one would like incorporate returned value parents frame complex way cilk provides inlet feature purpose inspired part inlet feature tam 10 inlet essentially c function internal cilk pro cedure normal syntax cilk spawning procedure must occur separate statement expression exception made rule spawn performed argument inlet call case procedure spawned returns inlet invoked meantime control parent procedure proceeds statement following inlet call princi ple inlets take multiple spawned arguments cilk5 restriction exactly one argument inlet may spawned argument must first argument necessary restriction easy program around figure illustrates fib function might coded using inlets inlet summer defined take returned value result add variable x frame procedure spawning variables fib available within summer since internal function fib 2 lock required around accesses x summer cilk provides atomicity implicitly concern two updates might occur parallel atomicity imposed update might lost cilk provides implicit atomicity among threads procedure stance thread maximal sequence instructions ending spawn sync return either explicit implicit statement inlet precluded containing spawn sync statements thus operates atomically single thread implicit atomicity simplifies reasoning 2 c elision cilk program inlets ansi c ansi c support internal c functions cilk based gnu c technology however provide support concurrency nondeterminism without requiring locking declaration critical regions like cilk provides syntactic sugar produce certain commonly used inlets implicitly example statement x spawn fibn1 conceptually generates inlet similar one figure 2 sometimes procedure spawns parallel work later discovers unnecessary speculative work aborted cilk using abort primitive inside let common use abort occurs parallel search many possibilities searched parallel soon solution found one searches one wishes abort currently executing searches soon possible waste processor resources abort statement executed inside inlet causes alreadyspawned children procedure terminate considered using futures 19 implicit synchro nization well synchronizing specific variables instead using simple spawn sync statements realized workfirst principle however different synchronization mechanisms could impact criticalpath computation issue secondary concern consequently opted implementation simplicity also systems support relaxed memoryconsistency models explicit sync statement used ensure sideeffects previously spawned subprocedures occurred addition control synchronization provided sync cilk programmers use explicit locking synchronize accesses data providing mutual exclusion atomicity data synchronization overhead borne work however although striven minimize overheads finegrain locking contemporary processors expensive currently investigating incorporate atomicity cilk language protocol issues involved locking avoided user level aid debugging cilk programs use locks developing tool called nonde 7 13 detects common synchronization bugs called data races 3 workfirst principle section justifies workfirst principle stated section 1 showing follows three assumptions first assume cilks scheduler operates practice according theoretical analysis presented 3 5 sec ond assume common case ample parallel slackness 28 exists average parallelism cilk program exceeds number processors run sufficient margin third assume indeed case every cilk program c elision oneprocessor performance measured theoretical analysis presented 3 5 cites two fundamental lower bounds fast cilk program run let us denote tp execution time given computation p processors work computation criticalpath length computation work lower bound tp t1p must hold p units work executed single step addition lower bound tp must hold since finite number processors cannot execute faster infinite cilks randomized workstealing scheduler 3 5 executes cilk computation p processors expected time assuming ideal parallel computer equation resembles brents theorem 6 15 optimal within constant factor since t1p lower bounds call first term righthand side equation 1 work term second term criticalpath term importantly communication costs due cilks scheduler borne criticalpath term scheduling costs make overheads explicit define criticalpath overhead smallest constant c1 second assumption needed justify workfirst principle focuses commoncase regime parallel program operates define average parallelism corresponds maximum possible speedup application obtain define also parallel slackness 28 ratio pp assumption parallel slackness pp ae c1 means number p processors much smaller average parallelism p assumption follows t1p ae c1t1 hence inequality 2 obtain linear speedup criticalpath overhead c1 little effect performance sufficient slackness exists although determines much slackness must exist ensure linear speedup whether substantial slackness exists common applications matter opinion empiricism suggest slackness common case expressiveness cilk makes easy code applications large amounts parallelism modestsized problems many applications exhibit average parallelism 200 yielding substantial slackness contemporary smps even sandia national laboratorys intel paragon contains 1824 nodes socrates chess program coded cilk1 ran linearspeedup regime 1995 icca world computer chess championship placed second field 24 section 6 describes dozen diverse applications run 8processor smp 3 abstract model execution time ignores reallife details memoryhierarchy effects nonetheless quite accurate 4 considerable parallel slackness parallelisim applications increases problem size thereby ensuring run well large machines third assumption behind workfirst principle every cilk program c elision oneprocessor performance measured let us denote ts running time c elision define work overhead incorporating criticalpath work overheads inequality 2 yields since assume parallel slackness restate workfirst principle precisely minimize c1 even expense larger c1 c1 direct impact performance adopting workfirst principle may adversely affect ability application scale however criticalpath overhead c1 large shall see section 6 criticalpath overhead reasonably small cilk5 many applications coded large amounts parallelism workfirst principle pervades cilk5 implementa tion workstealing scheduler guarantees high probability opt1 steal migration attempts occur ot1 average per processor costs borne critical path consequently scheduler cilk5 postpones much scheduling cost possible work stolen thereby removing contributor work overhead strategy amortizing costs steal attempts permeates virtually every decision made design scheduler 4 cilks compilation strategy section describes cilk2c compiler generates c postsource cilk program dictated work first principle compiler scheduler designed reduce work overhead much possible strategy generate two clones procedurea fast clone slow clone fast clone operates much c elision little support parallelism slow clone full support parallelism along concomitant overhead first describe cilk scheduling algorithm describe compiler translates cilk language constructs code fast slow clones procedure lastly describe runtime system links together actions fast slow clones produce complete cilk implementation lazy task creation 24 cilk5 proces sor called worker maintains ready deque doubly ended queue ready procedures technically procedure instances deque two ends head tail procedures added removed worker operates locally tail deque treating much int fib int n 3 fibframe f frame pointer 8 return n int x live vars c call return 0 frame stolen 22 return xy figure 3 fast clone generated cilk2c fib procedure figure 1 code second spawn omitted functions alloc free inlined calls runtime systems fast memory allocator signature fib sig contains description fib procedure including pointer slow clone push pop calls operations scheduling deque described detail section 5 c treats call stack pushing popping spawned activation frames worker runs work becomes thief attempts steal procedure another worker called victim thief steals procedure head victims deque opposite end victim working procedure spawned fast clone runs whenever thief steals procedure however procedure converted slow clone cilk scheduler guarantees number steals small sufficient slackness exists expect fast clones executed time thus workfirst principle reduces minimizing costs fast clone contribute heavily work overhead minimizing costs slow clone although desirable goal less important since costs contribute less heavily work overhead criticalpath overhead minimize costs fast clone exploiting structure cilk scheduler convert procedure slow clone stolen maintain invariant fast clone never stolen none descendants fast clone stolen either since strategy stealing heads ready deques guarantees parents stolen children shall see simple fact allows many optimizations performed fast clone describe cilk2c compiler generates post source c code fib procedure figure 1 example postsource fast clone fib given figure 3 generated c code general structure c elision additional statements lines 45 activation frame allocated fib initialized cilk runtime system uses activation frames represent procedure instances using techniques similar 16 17 inlined allocator typically takes cycles frame initialized line 5 storing pointer static structure called signature describing fib first spawn fib translated lines 1218 lines 1213 state fib procedure saved activation frame saved state includes program counter encoded entry number live dirty vari ables frame pushed runtime deque lines 1415 4 next call fib routine would c spawn statement compiles directly c elision postsource exploit optimization capabilities c compiler including ability pass arguments receive return values registers rather memory fib returns lines 1718 check see whether parent procedure stolen return immediately dummy value since ancestors stolen well c stack quickly unwinds control returned runtime system 5 protocol check whether parent procedure stolen quite subtlewe postpone discussion implementation section 5 parent procedure stolen continues execute line 19 performing second spawn shown fast clone sync statements compile noops fast clone never children exe cuting know compile time previously spawned procedures completed thus operations required sync statement always succeeds exam ple line 20 figure 3 translation sync statement empty statement finally lines 2122 fib deallocates activation frame returns computed result parent procedure slow clone similar fast clone except provides support parallel execution procedure stolen control suspended two procedures threads spawn sync point slow clone resumed uses goto statement restore program counter restores local variable state activation frame spawn statement translated slow clone fast clone sync statement cilk2c inserts call runtime system checks see whether procedure spawned children returned although parallel book 4 shared memory sequentially consistent memory fence must inserted lines 14 15 ensure surrounding writes executed proper order 5 setjmplongjmp facility c could used well unwinding strategy simpler keeping slow clone substantial contributes little work overhead since slow clones rarely executed separation fast clones slow clones also allows us compile inlets abort statements efficiently fast clone inlet call compiles efficiently ordinary spawn example code inlet call figure compiles similarly following cilk code implicit inlet calls x spawn fibn1 compile directly c elisions abort statement compiles noop sync statement executing fast clone children abort runtime system provides glue fast slow clones makes whole system work includes protocols stealing procedures returning values processors executing inlets aborting computation subtrees like costs protocols amortized critical path overhead significantly affect running time sufficient parallel slackness exists portion stealing protocol executed worker contributes work overhead however thereby warranting careful implementation discuss protocol detail section 5 work overhead spawn cilk5 reads writes fast clone3 reads 5 writes fib example experimentally quantify work overhead section 6 work overheads still remain im plementation however including allocation freeing activation frames saving state spawn pushing popping frame deque checking procedure stolen portion work overhead due fact cilk5 duplicating work c compiler performs section 6 shows overhead small although production cilk compiler might able eliminate unnecessary work would likely compromise portability cilk4 precursor cilk5 took workfirst principle extreme cilk4 performed stackbased allocation activation frames since work overhead stack allocation smaller overhead heap alloca tion cactus stack 25 semantics cilk stack 6 however cilk4 manage virtualmemory map processor explicitly done 27 work overhead cilk4 frame allocation little incrementing stack pointer whenever stack pointer overflowed page expensive userlevel ensued cilk4 would modify memory map unfortunately operatingsystem mechanisms supporting operations slow un predictable possibility page fault critical sec 6 suppose procedure spawns two children b c two children reference objects activation frame b c see others frame tions led complicated protocols even though overheads could charged criticalpath term practice became large criticalpath term contributed significantly running time thereby violating assumption parallel slackness oneprocessor execution program indeed fast insufficient slackness sometimes resulted poor parallel performance cilk5 simplified allocation activation frames simply using heap common case frame allocated removing free list deallocation performed inserting frame management virtual memory required except initial setup shared memory heap allocation contributes slightly stack allocation work overhead saves substantially critical path term downside heap allocation potentially waste memory stack allocation due fragmentation careful analysis relative merits stack heap based allocation supports heap allocation see paper appel shao 1 equally careful analysis supports stack allocation see 22 thus although workfirst principle gives general understanding overheads borne experience cilk4 showed large enough criticalpath overheads tip scales point assumptions underlying principle longer hold believe cilk5 work overhead nearly low possible given goal generating portable c output compiler 7 researchers able reduce overheads even however expense portability example lazy threads 14 obtains efficiency expense implementing calling conventions stack layouts etc although could principle incorporate machinedependent techniques compiler feel cilk5 strikes good balance performance portability also feel current overheads sufficiently low problems notably minimizing overheads data synchronization deserve attention 5 implemention workstealing section describe cilk5s workstealing mecha nism based dijkstralike 11 sharedmemory mutualexclusion protocol called protocol accordance workfirst principle protocol designed minimize work overhead example 167megahertz ultrasparc fib program protocol runs 25 faster hardware locking primitives first present simplified version protocol discuss actual implementation allows exceptions signaled additional overhead 7 although runtime system requires effort port architectures compiler requires changes whatsoever different platforms several straightforward mechanisms might considered implement workstealing protocol example thief might interrupt worker demand attention victim strategy presents problems two reasons first mechanisms signaling interrupts slow although interrupt would borne critical path large cost could threaten assumption parallel slack ness second worker would necessarily incur overhead work term ensure could safely interrupted critical section alternative sending interrupts thieves could post steal requests workers could periodically poll however cost accrues work overhead time polling techniques known limit overhead polling 12 require support sophisticated compiler workfirst principle suggests reasonable put substantial effort minimizing work overhead workstealing protocol since cilk5 designed sharedmemory machines chose implement workstealing sharedmemory rather messagepassing might otherwise appropriate distributedmemory implementation implementation victim operate directly shared memory victims ready deque crucial issue resolve race condition arises thief tries steal frame victim attempting pop one simple solution add lock deque using relatively heavyweight hardware primitives like compareandswap testand set whenever thief worker wishes remove frame deque first grabs lock solution fundamental problem interrupt polling mechanisms described however whenever worker pops frame pays heavy price grab lock contributes work overhead consequently adopted solution employs di jkstras protocol mutual exclusion 11 assumes reads writes atomic protocol uses three atomic shared variables h e call protocol key idea actions worker tail queue contribute work overhead actions thieves head queue contribute criticalpath overhead therefore accordance workfirst principle attempt move costs worker thief arbitrate among different thieves attempting steal victim use hardware lock since overhead amortized critical path resolve conflicts worker sole thief holding lock however use lightweight dijkstralike protocol contributes minimally work overhead worker resorts heavyweight hardware lock encounters actual conflict thief case charge overhead victim incurs critical path rest section describe protocol 9 return failure return success thief 7 return failure 9 unlockl return success figure 4 pseudocode simplified version protocol left part figure shows actions performed victim right part shows actions thief none actions besides reads writes assumed atomic example implemented detail first present simplified protocol uses two shared variables h designating tail head deque respectively later extend protocol third variable e allows exceptions signaled worker exception mechanism used implement cilks abort statement interestingly extension introduce additional work overhead pseudocode simplified protocol shown figure 4 assume shared memory sequentially consistent 20 8 code assumes ready deque implemented array frames head tail deque determined two indices h stored shared memory visible processors index points first unused element array h points first frame deque indices grow head towards tail normal con ditions h moreover deque lock l implemented atomic hardware primitives os calls worker uses deque stack see section 4 spawn pushes frame onto tail deque spawn pops frame unless frame stolen thief attempts steal frame head deque one thief time may steal deque since thief grabs l first action seen code worker alters h whereas thief increments h alter possible interaction thief vic 8 shared memory sequentially consistent memory fence must inserted lines 5 6 workervictim code lines 3 4 thief code ensure instructions executed proper order b000000000000000111111111111111000000000000111111111111111 h24a c thief figure 5 three cases ready deque simplified protocol shaded entry indicates presence frame certain position deque head tail marked h occurs thief incrementing h victim decrementing consequently always safe worker append new frame end deque worrying actions thief pop operations three cases shown figure 5 case thief victim get frame deque case b deque contains one frame victim decrements without interference thieves gets frame similarly thief steal frame long victim trying obtain thief victim try grab frame however protocol guarantees least one discovers h thief discovers h restores h original value retreats victim discovers h restores original value restarts protocol acquired l l acquired thief steal deque victim pop frame without interference frame still finally case c deque empty thief tries steal always fail victim tries pop attempt fails control returns cilk runtime system protocol cannot deadlock process holds one lock time argue protocol contributes little work overhead pushing frame involves overhead beyond updating common case worker succesfully pop frame pop protocol performs 6 operations2 memory loads 1 memory store 1 decre ment 1 comparison 1 predictable conditional branch moreover common case thief operates deque h cached exclusively worker expensive operation worker grabbing lock l occurs thief simultaneously trying steal frame popped since number steal attempts depends t1 t1 relatively heavy cost victim grabbing l considered part criticalpath overhead c1 influence work overhead c1 ran experiments determine relative performance protocol versus straightforward protocol pop locks deque accessing 167megahertz ultrasparc protocol 25 faster simple locking protocol machines memory model requires memory fence instruction membar inserted lines 5 6 pop pseudocode tried quantify performance impact membar instruction experiments execution times code without membar 200megahertz pentium pro running linux gcc 271 protocol 5 faster locking protocol processor protocol spends half time memory fence replaces locks memory synchronization protocol nonblocking straightforward locking protocol consequently protocol less prone problems arise spin locks used extensively example even worker suspended operating system execution pop infrequency locking protocol means usually complete steal operation workers deque recent work arora et al 2 shown completely nonblocking workstealing scheduler im plemented using ideas lisiecki medina 21 modified cilk5 scheduler make completely non blocking experience protocol greatly simplifies nonblocking implementation simplified protocol extended support signaling exceptions worker figure 4 index h plays two roles marks head deque marks point worker cannot cross pops places deque need full protocol separate two functions h two variables h marks head deque e marks point victim cannot cross exceptional condition occurred includes frame stolen also used exceptions example setting causes worker discover exception next pop new protocol e replaces h line 6 workervictim moreover lines 715 workervictim replaced call exception handler determine type exception stolen frame otherwise proper action perform thief code also modified trying program size fib blockedmul 1024 299 00044 6730 105 43 70 66 notempmul 1024 297 0015 1970 105 39 76 72 strassen 1024 202 058 35 101 354 57 56 cilksort 4 100 000 54 00049 1108 121 090 60 50 yqueens 22 150 00015 96898 099 188 80 80 yknapsack heat 4096 theta 512 623 016 384 108 94 66 61 43 00020 2145 093 077 56 60 figure performance example cilk programs times seconds accurate within 10 serial programs c elisions cilk programs except programs starred parallel program implements different algorithm serial program programs labeled dagger nondeterministic thus running time one processor work performed computation programs value 1 indicates actual work computation 8 processors running time one processor steal thief increments e nothing steal restores e original value otherwise thief steals frame h increments h point view worker common case simplified protocol compares two pointers e rather h exception mechanism used implement abort cilk procedure executes abort instruction runtime system serially walks tree outstanding descendants procedure marks descendants aborted signals abort exception processor working descendant next pop aborted procedure discover exception notice aborted return immediately conceivable procedure could run long time without executing pop discovering aborted made design decision accept possibility unlikely scenario figuring cycles likely lost work overhead abandoned protocol mechanism solves minor problem 6 benchmarks section evaluate performance cilk5 show 12 applications work overhead c1 close 1 indicates cilk5 implementation exploits workfirst principle effectively present breakdown cilks work overhead c1 four machines finally present experiments showing criticalpath overhead c1 reasonably small well figure 6 shows table performance measurements taken 12 cilk programs sun enterprise 5000 smp 8 167megahertz ultrasparc processors 512 kilobytes l2 cache 16 kilobytes l1 data instruction caches running solaris 25 compiled programs gcc 272 optimization level o3 full description programs see cilk 51 manual 8 table shows work cilk program t1 critical path two derived quantities p c1 table also lists running time t8 8 processors speedup t1t8 relative oneprocessor execution time speedup tst8 relative serial execution time 12 programs average parallelism p cases quite large relative number processors typical smp measurements validate assumption parallel slackness implies work term dominates inequality 4 instance 1024 theta 1024 matri ces notempmul runs average parallelism 1970 yielding adequate parallel slackness several hundred processors even larger machines one normally would run small problem notempmul well 11 applications average parallelism grows problem size thus sufficient parallel slackness likely exist even much larger machines long problem sizes scaled appropriately work overhead c1 percent larger 1 programs shows design cilk5 faithfully implements workfirst principle two cases work overhead larger cilksort cholesky due fact change serial algorithm obtain parallel algorithm thus comparison c elision example serial c algorithm sorting inplace quicksort parallel algorithm cilksort requires additional temporary array adds overhead beyond overhead cilk self similarly parallel cholesky factorization uses quadtree representation sparse matrix induces work linkedlist representation used serial c algorithm finally work overhead fib large fib essentially work besides spawning procedures thus overhead good estimate cost cilk spawn versus traditional c function call small overhead spawning one understand applications perform significant work spawn overhead cilk5s scheduling barely noticeable compared 10 noise measurements 195 mhz mips r10000 ultra sparc 200 mhz pentium pro alpha 21164 overheads protocol frame allocation state saving 115ns 113ns 78ns 27ns figure 7 breakdown overheads fib running one processor various architectures overheads normalized running time serial c elision three overheads saving state procedure spawn allocation activation frames procedures protocol absolute times given perspawn running time c elision present breakdown cilks serial overhead c1 components scheduling overheads small programs perform analysis fib program figure 1 program unusually sensitive scheduling overheads contains little actual computation give breakdown serial overhead three components overhead saving state spawning overhead allocating activation frames overhead protocol figure 7 shows breakdown cilks serial overhead fib four machines methodology obtaining numbers follows first take serial c fib program time execution individually add code generates overheads time execution resulting program attribute additional time required modified program scheduling code added order verify numbers timed fib code cilk overheads added code shown figure 3 compared resulting time sum individual overheads cases two times differed less 10 overheads vary across architectures overhead cilk typically times c running time spawnintensive program overheads alpha machine particularly large native c function calls fast compared architectures statesaving costs small fib four architectures write buffers hide latency writes required also attempted measure criticalpath overhead c1 used synthetic knary benchmark 4 synthesize computations artificially wide range work criticalpath lengths figure 8 shows outcome many experiments figure plots measured01001 normalized normalized machine size experimental data model work bound critical path bound figure 8 normalized speedup curve cilk5 horizontal axis number p processors vertical axis speedup t1tp data point normalized dividing t1t1 graph also shows speedup predicted formula speedup t1tp run machine size p run order plot different computations graph normalized machine size speedup dividing values average parallelism done 4 run horizontal position plotted datum inverse slackness pp thus normalized machine size 10 number processors equal average parallelism vertical position plotted datum t1tp measures fraction maximum obtainable speedup seen chart almost runs bench mark observed tp t1p 10t1 one exceptional data point satisfies tp t1p workfirst principle caused us move overheads critical path ability cilk applications scale significantly compromised 7 conclusion conclude paper examining related work mohr et al 24 introduced lazy task creation implementation mult language lazy task creation similar many ways lazy scheduling techniques mohr et al report work overhead around 2 comparing serial scheme dialect mult based research confirms intuition behind methods shows work overheads close 1 achievable cid language 26 like cilk uses c base language simple preprocessing compiler convert parallel cid constructs c cid designed work distributed memory environment employs latencyhiding mechanisms cilk5 could avoid working distributed version cilk however cilk cid recognize attractiveness basing parallel language c leverage c compiler technology highperformance codes cilk faithful extension c however supporting simplifying notion c elision allowing cilk exploit c compiler technology readily tam 10 lazy threads 14 also analyze many overhead issues general nonstrict language setting individual performances whole host mechanisms required applications obtain good overall performance contrast cilks multithreaded language provides execution model based work criticalpath length allows us focus implementation efforts using workfirst principle using principle guide concentrated optimizing effort commoncase protocol code develop efficient portable implementation cilk language acknowledgments gratefully thank contributed cilk development including bobby blumofe ien cheng dailey mingdong feng chris joerg bradley kuszmaul phil lisiecki alberto medina rob miller aske plaat bin song andy stark volker strumpen yuli zhou many thanks users provided us feedback suggestions improvements martin rinard suggested term workfirst r empirical analytic study stack versus heap cost languages closures thread scheduling multiprogrammed multiprocessors executing multithreaded programs ef ficiently scheduling multithreaded computations work stealing parallel evaluation general arithmetic expressions detecting data races cilk programs use locks introduction algorithms solution problem concurrent programming control polling efficiently stock hardware efficient detection determinacy races cilk programs lazy threads implementing fast parallel call bounds multiprocessing timing anoma lies heaps stacks time space efficient threads without operating system support cilk system parallel multithreaded computing jr make multiprocessor computer correctly executes multiprocess programs personal communication garbage collection fast function function lisp funarg problem called environment prob lem parallel symbolic computing cid vlsi support cactus stack oriented memory organization bridging model parallel computation tr multilisp language concurrent symbolic computation vlsi support cactus stack oriented memory organization bridging model parallel computation introduction algorithms finegrain parallelism minimal hardware support compilercontrolled threaded abstract machine polling efficiently stock hardware wholeprogram optimization time space efficient threads cilk system parallel multithreaded computing lazy threads cilk executing multithreaded programs efficiently efficient detection determinacy races cilk programs thread scheduling multiprogrammed multiprocessors detecting data races cilk programs use locks parallel evaluation general arithmetic expressions solution problem concurrent programming control lazy task creation parallel symbolic computing cid garbage collection fast stack faster function function lisp funarg problem called environment problem ctr liang peng wengfai wong chungkwong yuen silkroad ii mixed paradigm cluster computing rcdag consistency parallel computing v29 n8 p10911115 1 august matteo frigo fast fourier transform compiler acm sigplan notices v39 n4 april 2004 kalyan perumalla richard fujimoto efficient largescale processoriented parallel simulations proceedings 30th conference winter simulation p459466 december 1316 1998 washington dc united states doug lea java forkjoin framework proceedings acm 2000 conference java grande p3643 june 0304 2000 san francisco california united states christopher j hughes radek grzeszczuk eftychios sifakis daehyun kim sanjeev kumar andrew p selle jatin chhugani matthew holliman yenkuang chen physical simulation animation visual effects parallelization characterization chip multiprocessors acm sigarch computer architecture news v35 n2 may 2007 yaron shoham sivan toledo parallel randomized bestfirst minimax search artificial intelligence v137 n12 p165196 may 2002 philip cox simon gauvin andrew rauchaplin adding parallelism visual data flow programs proceedings 2005 acm symposium software visualization may 1415 2005 st louis missouri voonyee vee wenjing hsu localitypreserving loadbalancing mechanisms synchronous simulations sharedmemory multiprocessors proceedings fourteenth workshop parallel distributed simulation p131138 may 2831 2000 bologna italy marcel van lohuizen generic approach parallel chart parsing application lingo proceedings 39th annual meeting association computational linguistics p507514 july 0611 2001 toulouse france bryan chan tarek abdelrahman runtime support automatic parallelization java programs journal supercomputing v28 n1 p91117 april 2004 madanlal musuvathi shaz qadeer iterative context bounding systematic testing multithreaded programs acm sigplan notices v42 n6 june 2007 gregory w price david k lowenthal comparative analysis finegrain threads packages journal parallel distributed computing v63 n11 p10501063 november kenjiro taura kunio tabata akinori yonezawa stackthreadsmp integrating futures calling standards acm sigplan notices v34 n8 p6071 aug 1999 dorit naishlos joseph nuzman chauwen tseng uzi vishkin towards first vertical prototyping extremely finegrained parallel programming approach proceedings thirteenth annual acm symposium parallel algorithms architectures p93102 july 2001 crete island greece robert ennals simon peyton jones optimistic evaluation adaptive evaluation strategy nonstrict programs acm sigplan notices v38 n9 p287298 september radu rugina martin rinard pointer analysis multithreaded programs acm sigplan notices v34 n5 p7790 may 1999 john danaher iting angelina lee charles e leiserson programming exceptions jcilk science computer programming v63 n2 p147171 1 december 2006 matteo frigo fast fourier transform compiler acm sigplan notices v34 n5 p169180 may 1999 rezaul alam chowdhury vijaya ramachandran cacheoblivious gaussian elimination paradigm theoretical framework parallelization experimental evaluation proceedings nineteenth annual acm symposium parallel algorithms architectures june 0911 2007 san diego california usa kenjiro taura kenji kaneda toshio endo akinori yonezawa phoenix parallel programming model accommodating dynamically joiningleaving resources acm sigplan notices v38 n10 october sanjeev kumar christopher j hughes anthony nguyen carbon architectural support finegrained parallelism chip multiprocessors acm sigarch computer architecture news v35 n2 may 2007 lawrence rauchwerger nancy amato smartapps middleware adaptive applications reconfigurable platforms acm sigops operating systems review v40 n2 april 2006 v vasenin n vodomerov formal model system automated program parallelization programming computing software v33 n4 p181194 july 2007 radu rugina martin rinard symbolic bounds analysis pointers array indices accessed memory regions acm sigplan notices v35 n5 p182195 may 2000 matteo frigo volker strumpen cache complexity multithreaded cache oblivious algorithms proceedings eighteenth annual acm symposium parallelism algorithms architectures july 30august 02 2006 cambridge massachusetts usa guangien cheng mingdong feng charles e leiserson keith h randall andrew f stark detecting data races cilk programs use locks proceedings tenth annual acm symposium parallel algorithms architectures p298309 june 28july 02 1998 puerto vallarta mexico polyvios pratikakis jaime spacco michael hicks transparent proxies java futures acm sigplan notices v39 n10 october 2004 nimar arora robert blumofe c greg plaxton thread scheduling multiprogrammed multiprocessors proceedings tenth annual acm symposium parallel algorithms architectures p119129 june 28july 02 1998 puerto vallarta mexico michael bender cynthia phillips scheduling dags asynchronous processors proceedings nineteenth annual acm symposium parallel algorithms architectures june 0911 2007 san diego california usa matteo frigo fast fourier transform compiler acm sigplan notices v39 n4 april 2004 girija j narlikar scheduling threads low space requirement good locality proceedings eleventh annual acm symposium parallel algorithms architectures p8395 june 2730 1999 saint malo france michael bender jeremy fineman seth gilbert charles e leiserson onthefly maintenance seriesparallel relationships forkjoin multithreaded programs proceedings sixteenth annual acm symposium parallelism algorithms architectures june 2730 2004 barcelona spain dror irony gil shklarski sivan toledo parallel fully recursive multifrontal sparse cholesky future generation computer systems v20 n3 p425440 april 2004 charles r tolle timothy r mcjunkin david j gorisch suboptimal minimum cluster volume coverbased method measuring fractal dimension ieee transactions pattern analysis machine intelligence v25 n1 p3241 january robert blumofe charles e leiserson scheduling multithreaded computations work stealing journal acm jacm v46 n5 p720748 sept 1999 kunal agrawal yuxiong wen jing hsu charles e leiserson adaptive scheduling parallelism feedback proceedings eleventh acm sigplan symposium principles practice parallel programming march 2931 2006 new york new york usa radu rugina martin c rinard symbolic bounds analysis pointers array indices accessed memory regions acm transactions programming languages systems toplas v27 n2 p185235 march 2005 kunal agrawal yuxiong charles e leiserson adaptive work stealing parallelism feedback proceedings 12th acm sigplan symposium principles practice parallel programming march 1417 2007 san jose california usa radu rugina martin c rinard pointer analysis structured parallel programs acm transactions programming languages systems toplas v25 n1 p70116 january girija j narlikar guy e blelloch pthreads dynamic irregular parallelism proceedings 1998 acmieee conference supercomputing cdrom p116 november 0713 1998 san jose ca