constraint preconditioning indefinite linear systems problem finding good preconditioners numerical solution indefinite linear systems considered special emphasis put preconditioners 2 2 block structure incorporate 12 21 blocks original matrix results concerning spectrum form eigenvectors preconditioned matrix minimum polynomial given consequences results considered variety krylov subspace methods numerical experiments validate conclusions b introduction paper concerned investigating new class preconditioners indefinite systems linear equations sort arise constrained optimization well leastsquares saddlepoint stokes problems attempt solve indefinite linear system 2 ir nthetan symmetric b 2 ir mthetan throughout paper shall assume n nonsingular case b must full rank example 1 consider problem minimizing function n variables subject linear equality constraints variables ie minimize subject finite solution 12 stationary point lagrangian function referred lagrangian multipliers differentiating l respect x solution 12 readily seen satisfy linear equations form 11 x application known karushkuhntucker kkt conditions 2 example 2 stokes problem stokes equations compact form defined div discretising equations 13 together boundary conditions defines linear system equations form 11 b carsten keller nick gould andy wathen among important iterative methods currently available krylov subspace methods apply techniques involve orthogonal projections onto subspaces form common schemes use idea method conjugate gradients cg symmetric positive definite matrices method minimum residuals minres symmetric possibly indefinite matrices generalised minimum residual method gmres unsymmetric matrices although many methods availablesee example greenbaum 12 one common feature methods solution linear system 11 found within n iterations exact arithmeticsee joubert manteuffel 14 p 152 large possibly sparse linear systems upper limit number iterations often practical idea preconditioning attempts improve spectral properties ie clustering eigenvalues total number iterations required solve system within tolerance decreased substantially paper specifically concerned nonsingular preconditioners form nthetan approximates inclusion exact representation 1 2 2 1 matrix blocks preconditioner often associated constraints see example 1 leads one hope favourable distribution eigenvalues leftpreconditioned linear system since blocks unchanged original system shall call g constraint preconditioner preconditioner form g recently used luksan vlcek 16 context constrained nonlinear programming problemssee also coleman 4 polyak 18 gould et al 11 derive arguments confirm extend results 16 highlight favourable features preconditioner form g note golub wathen 10 recently considered symmetric preconditioner form 14 problems form 11 nonsymmetric section 2 determine eigensolution distribution preconditioned system give lower upper bounds eigenvalues g gamma1 constraint preconditioning 3 case submatrix g positive definite section 3 describes convergence behaviour krylov subspace method gmres section 4 investigates possible implementation strategies section 5 give numerical results support theory developed paper preconditioning symmetric general normal matrix systems convergence applicable iterative method determined distribution eigenvalues coefficient matrix particular desirable number distinct eigenvalues least number clusters small case convergence rapid precise distinct eigenvalues optimal methods like cg minres gmres terminate exact arithmetic small precisely defined number steps prove result type nonnormal systems convergence opposed termination readily describedsee greenbaum 12 p 5 21 eigenvalue distribution eigenvalues preconditioned coefficient matrix g gamma1 may derived considering general eigenvalue problem x x z orthogonal factorisation b nthetam z 2 ir nthetangammam basis nullspace b premultiplying 26 nonsingular square matrix6 6 4 postmultiplying transpose gives6 6 4 x z x x z x made use equalities performing simultaneous sequence row column inter 4 carsten keller nick gould andy wathen changes matrices 27 reveals two lower blocktriangular matrices thus preconditioned coefficient matrix g gamma1 similar theta z gz precise forms theta upsilon gamma irrelevant argument general nonzero proved following theorem theorem 21 let 2 ir nmthetanm symmetric indefinite matrix form 2 ir nthetan symmetric b 2 ir mthetan full rank assume z n theta n gamma basis nullspace b preconditioning matrix form nthetan symmetric g 6 b 2 ir mthetan implies matrix g gamma1 1 eigenvalue 1 multiplicity 2m eigenvalues defined generalised eigenvalue problem z azx note indefinite constrained preconditioner applied indefinite linear system 11 yields preconditioned matrix p real eigenvalues remark 1 argument assumed b full row rank consequently applied orthogonal factorisation b resulted constraint preconditioning 5 upper triangular matrix r 2 ir mthetam b full row rank ie rows columns deleted matrices 27 thus giving reduced system dimension removal redundant information impose restriction proposed preconditioner since mathematical arguments equivalently apply reduced system equations 22 eigenvector distribution mentioned termination krylov subspace method related location eigenvalues number corresponding linearly independent eigenvectors order establish association eigenvectors eigenvalues expand general eigenvalue problem 27 yielding 211 may deduced either former case equations 29 210 simplify consequently written z z since q orthogonal general eigenvalue problem 212 equivalent considering w 6 0 oe 1 linearly independent eigenvectors corresponding linearly independent eigenvectors corresponding eigenvalues suppose 6 1 case x equations 29 210 yield 6 carsten keller nick gould andy wathen general eigenvalue problem 214 defines equal 1 two cases distinguished x z 6 0 must satisfy follows corresponding eigenvectors defined x deduce 215 hence z x 0 case extra eigenvectors arise summarising evident p show realistic assumptions eigenvectors fact linearly independent theorem 22 let 2 ir nmthetanm symmetric indefinite matrix form 2 ir nthetan symmetric b 2 ir mthetan full rank assume preconditioner g defined matrix form nthetan symmetric g 6 b 2 ir mthetan let z denote n theta n gamma basis nullspace b suppose z gz positive definite preconditioned matrix g gamma1 nm eigenvalues defined theorem 21 linearly independent eigenvectors eigenvectors form correspond case constraint preconditioning 7 eigenvectors form z x arising z linearly independent eigenvectors form correspond case 6 1 proof prove eigenvectors p linearly independent need show 1 1a 1 x z 2 2 x 2 2 2 2a 2 x z 3 3a 3 implies vectors zero vectors multiplying g gamma1 recalling previous equation first matrix arises case second matrix case last matrix arises k 1 1a 1 x z 2 2 x 2 2 2 2a 2 x z 3 3a 3 subtracting equation 216 217 obtain6 6 4 x z 3 3a 3 8 carsten keller nick gould andy wathen simplifies to6 6 4 x z 3 3a 3 since k assumption z gz positive definite implies x z 218 linearly independent thus 3 similarly 2 follows linear independence x z 2 x 2 thus 216 simplifies to6 6 4 1 1a 1 1 linearly independent thus 1 remark 2 note result theorem 22 remains true z fla positive definite scalars fl oesee parlett 17 p 343 details show eigenvector bounds theorem 22 fact attained consider following two examples example 3 minimum bound consider matrices 2 preconditioned matrix p eigenvalue 1 multiplicity 3 one eigenvector arising case 1 theorem 22 eigenvector may taken 2 example 4 maximum bound let 2 ir 3theta3 defined example 3 assume preconditioned matrix p eigenvalue 1 multiplicity 3 clearly complete set eigenvectors may taken constraint preconditioning 9 23 eigenvalue bounds apparent calculations previous section eigenvalue 1 multiplicity 2m independent choice g preconditioner contrary eigenvalues defined 214 highly sensitive choice g g close approximation expect favourable distribution eigenvalues consequently may expect faster convergence appropriate iterative method order determine good factorisation helpful find intervals located g positive definite matrix one possible approach provided cauchys interlace theorem theorem 23 cauchys interlace theorem see 17 theorem 1011 suppose nthetan symmetric label eigenpairs h proof see parlett 17 p 203 2 applicability theorem 23 verified recalling definitions q z given previous section considering generalised eigenvalue problems carsten keller nick gould andy wathen since g positive definite q gq may therefore write rr rewriting 220 gives since matrix gamma1 q aqm gammat similar g defines eigenvalues ff may therefore apply theorem 23 directly result particular bounded extreme eigenvalues g gamma1 necessarily clustered g good approximation furthermore good preconditioner g implies z gz least good preconditioner z az show preconditioner z gz fact much better consider following example taken cute collection 3 example 5 consider convex quadratic programming problem bloweyc may formulated subject z selecting size parameter 500 discretisation intervals defines set linear equations form 11 letting g diagonal may deduce theory extreme eigenvalues g gamma1 give lower upper bound defined general eigenvalue problem 214 figure 21 1002 eigenvalues g gamma1 drawn vertical lines whereas figure 21 b displays 500 eigenvalues z gz spectrum figure 21 equivalent graph entire spectrum p eigenvalue 1 multiplicity 502 removed rounded two decimal places numerical values two extreme eigenvalues g gamma1 constraint preconditioning 11 04 size eigenvalue eigenvalues g gamma1 04 size eigenvalue b eigenvalues z gz figure 21 continuous vertical lines represent eigenvalues g gamma1 002 198 whereas extreme eigenvalues z gz given 071 1 note example large number eigenvalues clustered approximate intervals 002 038 165 197 eigenvalue distribution figure 21 b reveals one eigenvalue near 071 group eigenvalues near 1 follows appropriate iterative method solves 15 expected converge small number steps verified numerical results presented section 5it readily seen example 5 case bounds provided theorem 23 descriptive significantly clustering eigenvalues implied theorem convergence context paper convergence iterative method preconditioning influenced spectral properties coefficient matrix also relationship dimensions n par ticular follows theorem 21 special case preconditioned linear system 15 one eigenvalue 1 multiplicity 2n gives eigenvalue 1 multiplicity 2m generally distinct eigenvalues whose value may may equal 1 examine results determine upper bounds number 12 carsten keller nick gould andy wathen iterations appropriate krylov subspace method recall definition minimum polynomial matrix definition 1 let 2 ir nmthetanm monic polynomial f minimum degree called minimum polynomial importance definition becomes apparent considering subsequent results recalling similar matrices minimum polynomial krylov subspace theory states iteration method optimality property gmres terminate degree minimum polynomial attainedsee axelsson 1 p 463 precise number may less special cases b combination eigenvectors affect grade respect b particular degree minimum polynomial equal dimension corresponding krylov subspace general b following theorems relevant theorem 31 let 2 ir nmthetanm symmetric indefinite matrix form 2 ir nthetan symmetric b 2 ir mthetan full rank let preconditioned matrix form g 2 ir nthetan g 6 b 2 ir mthetan krylov subspace kp b dimension 2 b proof writing preconditioned system 28 explicit form observe p fact given 0 upsilon upsilon nonzero 6 g show dimension corresponding krylov subspace 2 need determine minimum polynomial system evident 323 constraint preconditioning 13 eigenvalues p 1 minimum polynomial order 2 2 remark 3 course possible case solve square constrained equation bx obtain x gives motivation result theorem 31 independent g remark 4 important consequence theorem 31 termination iteration method gmres occur 2 steps choice b even though preconditioned matrix diagonalisable unless theorem 32 let 2 ir nmthetanm symmetric indefinite matrix form 2 ir nthetan symmetric b 2 ir mthetan full rank assume n nonsingular furthermore assume preconditioned matrix form nthetan symmetric g 6 b 2 ir mthetan z gz positive definite z n theta n gamma basis nullspace b dimension krylov subspace kp b n gamma 2 proof eigenvalue derivation section 21 evident characteristic polynomial preconditioned linear system 15 prove upper bound dimension krylov subspace need show order minimum polynomial less equal 2 14 carsten keller nick gould andy wathen expanding polynomial obtain matrix form6 6 4 psi ngammam defined recursive formula theta base cases psi note 2 1 2 2 3 2 entries matrix 324 fact zero since eigenvalues similar symmetric matrix thus diagonalisable thus 324 may written 2 remains distinguish two different cases value phi ngammam phi former case order minimum polynomial p less equal thus dimension krylov subspace kp b order latter case dimension kp b less equal n gamma 2 since multiplication 325 another factor p gamma gives zero matrix upper bound dimension krylov subspace stated theorem 32 reduced special case z repeated eigenvalues result stated theorem 33 following ran domly generated example shows bound theorem 32 attainable example 6 let 2 ir 6theta6 b 2 ir 6theta2 given 269 162 116 160 081 gamma197 162 623 gamma190 189 090 005 081 090 gamma016 001 194 038 constraint preconditioning 15 assume diaga matrices 3 1 entry 325 gamma022 gamma002 follows minimum polynomial order 6 thus bound given theorem 32 sharp 2 theorem 33 let 2 ir nmthetanm symmetric indefinite matrix form 2 ir nthetan symmetric b 2 ir mthetan full rank assume nonsingular preconditioned matrix nthetan symmetric g 6 b 2 ir mthetan furthermore let z n theta n gamma basis nullspace b assume z gz distinct eigenvalues respective multiplicity dimension krylov subspace kp b k 2 proof proof similar one theorem 32 case z distinct eigenvalues multiplicity may without loss generality write characteristic polynomial p expanding obtain matrix6 6 4 carsten keller nick gould andy wathen psi k given recursive formula theta base cases psi note 2 1 2 2 3 2 blocks matrix 326 fact zero follows phi k 6 0 multiplication 326 zero matrix thus dimension krylov subspace kp b less equal k 2 2 verify bound theorem 33 attainable consider following example example 7 let 2 ir 4theta4 g 2 ir 4theta4 b 2 ir 4theta1 given two eigenvalues defined generalised eigenvalue problem 214 distinct given 2 4 follows 3 1 entry 326 nonzero minimum polynomial order 4 2 implementation various strategies used implement proposed pre conditioner two used numerical results section 5 first strategy applies standard preconditioned gmres algorithm 20 preconditioner step implemented means symmetric indefinite factorisation 14 factorisation preconditioner may much less demanding factorisation initial coefficient matrix g considerably simpler matrix second approach discussed next section based algorithm solves reduced linear system constraint preconditioning 17 41 conjugate gradients reduced linear system 11 gould et al propose conjugate gradient like algorithm solve equality constrained quadratic programming problems one described example 1 algorithm based idea computing implicit basis z spans nullspace b nullspace basis used remove constraints system equations thus allowing application conjugate gradients method positive definite reduced system assume w gz symmetric positive definite preconditioner matrix dimension n gamma theta n gamma z n theta n gamma matrix algorithm stated follows algorithm 41 preconditioned cg reduced system 1 choose initial point x satisfying 2 compute gammag 3 repeat following steps x computation preconditioned residual 429 often expensive computational factor algorithm gould et al suggest avoiding explicit use nullspace z instead compute g applying carsten keller nick gould andy wathen symmetric indefinite factorisation r practice 430 often factored efficiently using ma27 package harwell subroutine library g simple matrix block whereas direct application ma27 original system 11 limited space requirements well time large enough systems 6 context factorisation consists three separate routines first two analyse factorise matrix 430 need executed step 1 algorithm 41 repeated calls third routine within ma27 apply forward backwardsubstitutions find initial point x step 1 solve g 427 also find g 429 remark 5 computation projected residual g often accompanied significant roundoff errors vector much smaller residual iterative refinement used 428 redefine r norm closer g result dramatic reduction roundoff errors projection operationsee gould et al 11 5 numerical results present results numerical experiments reinforce analysis given previous sections test problems use partly randomised sparse matrices table 51 partly matrices arise linear nonlinear optimization table 52see bongartz et al 3 indicated matrices form 2 ir nthetan symmetric b 2 ir mthetan full rank n four different approaches finding solutions 11 comparedthree iterative algorithms based krylov subspaces direct solver ma27 applies sparse variant gaussian eliminationsee duff reid 6 investigate possible favourable aspects preconditioning makes sense compare unpreconditioned preconditioned solution strategies indefinite nature matrix 531 suggests use minres unpreconditioned case outlined section 4 employ two slightly different strategies order implement preconditioner g first method applies standard full gmresa code pgmres tables 51 52 constraint preconditioning 19 mathematically equivalent minresa symmetric matrices whereas second approach implements algorithm 41 rcg tables 51 52 low choice preconditioner made pgmres rcg random random ii random iii random iv nonzero entries 2316 9740 39948 39948 nonzero entries b 427 1871 3600 686 minres iterations 174 387 639 515 time seconds 04 31 175 131 pgmres iterations 46 87 228 242 time seconds 02 39 960 1089 rcg iterations 36 67 197 216 time seconds 01 10 59 59 time seconds 01 09 54 29 table 51 random test problems tests performed sun ultra sparcii300mhz ultra30 workstation 245 mb physical ram running sunos release 551 programs written standard fortran 77 using sun workshop f77 compiler version 42 0 optimization flag set order deal large sparse matrices implemented index storage format stores nonzero matrix elementssee press et al 19 termination criterion iterative methods taken residual vector order less 10 gamma6 2norm part analysis procedure ma27 accepts pattern coefficient matrix chooses pivots factorisation solution phases subsequent routines amount pivoting controlled special parameter modifying u within positive range influences accuracy resulting solution whereas negative value prevents pivotingsee duff reid 6 context early construction test examples default value accompanied difficulties form memory limitations met tradeoff less use memory solutions high enough accuracy choosing parameter value tables 51 52 time measurements eight test examples indicate itera carsten keller nick gould andy wathen nonzero entries 3004 672 1020 13525 nonzero entries b 2503 295 148 50284 minres iterations 363 convergence 51 180 time seconds 18 convergence 01 142 pmgrem iterations time seconds 06 01 02 132 rcg iterations time seconds 06 01 02 162 time seconds 05 01 01 156 table 52 cute test problems tion counts three proposed iterative methods comparable far operation counts ie work concerned numerical results suggest inclusion 1 2 2 1 block preconditioner together results considerable reduction iterations appropriate bounds theorems 31 32 33 attained cases specifically theorem 31 applies context problem cvxqp1 test problems random iii random iv table 51 emphasise storage problems associated use long recurrences pgmres algorithm time required find solution random iii random iv via pgmres algorithm comparable methods due increased storage requirements data trafficking involved solution memory problems restart pgmres prescribed number iterations iteration counts restarts would comparable full pgmres relevance time measurements ma27 commented next section 6 conclusion paper investigated new class preconditioner indefinite linear systems incorporate 2 1 2 2 blocks original matrix blocks often associated constraints numerical results used simple diagonal matrix g approximate 1 1 block constraint preconditioning 21 even though approximations incomplete factorisation possible first showed inclusion constraints preconditioner clusters least 2m eigenvalues 1 regardless structure g however unless g represents exactly p complete set linearly independent eigenvectors thus standard convergence theory krylov subspace methods readily applicable find upper bound number iterations required solve linear system form 11 means appropriate subspace methods used minimum polynomial argument theorem 31 considers special condition case termination guaranteed two iterations theorem 32 gives general sharp upper bound dimension krylov subspace whereas theorem 33 defines considerably stronger result defined z gz repeated special case g positive definite matrix block able apply cauchys interlacing theorem order give upper lower bound eigenvalues defined 2 2 block matrix 28 confirm analytical results paper used three different subspace methods minres paige saunders unpreconditioned matrix system rcg gould et al also pgmres saad schultz preconditioned case overall results show number iterations decreased substantially preconditioning applied krylov subspaces built execution two preconditoned implementations theory equal dimension eight test examples thus pgmres rcg expected terminate number steps however convergence prescribed tolerance may occur different number steps since pgmres rcg minimize different quantities seen examples nevertheless note convergence methods attained much earlier suggested bounds theorems 31 32 33 time measurements ma27 last section suggest preconditioned conjugate gradients algorithm discussed section 41 suitable alternative direct solver whereas minres especially pgm res considerably slower ma27 timings rcg virtually cases comparable problems large enough dimension bandwidth resources required ma27 must become prohibitive case rcg becomes even competitive 22 carsten keller nick gould andy wathen acknowledgments authors would like thank gene h golub insightful comments process work r cambridge university press cute constrained unconstrained testing environment linearly constrained optimization projected preconditioned conjugate gradients direct methods sparse matrices multifrontal solution indefinite sparse symmetric linear equations perturbation eigenvalues preconditioned navierstokes operators polynomial based iteration methods symmetric linear systems matrix computations iteration indefinite system application navierstokes equations solution equality constrained quadratic programming problems arising optimiza tion iterative methods solving linear systems iterative methods nonsymmetric linear systems iterative methods linear nonlinear equations symmetric eigenvalue problem numerical recipes fortran art scientific computing gmres generalised minimal residual algorithm solving nonsymmetric linear systems tr ctr joosiong chai kimchuan toh preconditioning iterative solution symmetric indefinite linear systems arising interior point methods linear programming computational optimization applications v36 n23 p221247 april 2007 luca bergamaschi jacek gondzio manolo venturin giovanni zilli inexact constraint preconditioners linear systems arising interior point methods computational optimization applications v36 n23 p137147 april 2007 z dostl optimal algorithm class equality constrained quadratic programming problems bounded spectrum computational optimization applications v38 n1 p4759 september 2007 h dollar n gould w h schilders j wathen using constraint preconditioners regularized saddlepoint problems computational optimization applications v36 n23 p249270 april 2007 luca bergamaschi jacek gondzio giovanni zilli preconditioning indefinite systems interior point methods optimization computational optimization applications v28 n2 p149171 july 2004 cafieri dapuzzo v simone serafino stopping criteria inner iterations inexact potential reduction methods computational study computational optimization applications v36 n23 p165193 april 2007 bocanegra f f campos r oliveira using hybrid preconditioner solving largescale linear systems arising interior point methods computational optimization applications v36 n23 p149164 april 2007 cafieri dapuzzo v simone serafino iterative solution kkt systems potential reduction software largescale quadratic problems computational optimization applications v38 n1 p2745 september 2007 silvia bonettini emanuele galligani valeria ruggiero inner solvers interior point methods large scale nonlinear programming computational optimization applications v37 n1 p134 may 2007