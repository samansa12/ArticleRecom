block stationary methods nonsymmetric cyclically reduced systems arising threedimensional elliptic equations consider threedimensional convectiondiffusion model problem examine systems equations arising performing one step cyclic reduction equally spaced mesh discretized using sevenpoint operator present two ordering strategies analyze block splittings resulting matrices matrices consistently ordered relative given partitioning youngs analysis block gaussseidel block sor methods applied compare partitionings property holds ones matrices property yet still give rise efficient solution process bounds convergence rates derived work involved solving systems estimated b introduction consider threedimensional 3d convectiondiusion equation constant coecients z unit subject dirichlettype boundary con ditions focus applying sevenpoint finite dierence discretizations example centered dierences diusive terms centered dierences firstorder upwind approximations convective terms let us define n h n 3 number unknowns mesh size let f denote corresponding dierence operator scaling h 2 gridpoint u ijk next boundary f denote mesh reynolds numbers h values components computational molecule given received editors march 3 1997 accepted publication revised form z strakos february 27 1998 published electronically july 9 1999 httpwwwsiamorgjournalssimax20431771html gates building stanford university stanford ca 94305 greif sccmstanfordedu department computer science university british columbia vancouver bc v6t 1z4 canada varahcsubcca lexicographic ordering b redblack ordering fig 11 sparsity patterns matrices corresponding two possible orderings unknown centered dierence approximations first derivatives used backward firstorder accurate schemes used sparsity pattern underlying matrix depends ordering unknowns fig 11 sparsity patterns associated two possible ordering strategies illustrated natural lexicographic ordering one unknowns numbered rowwise planewise redblack ordering b means color gridpoints using two colors checkerboard fashion number points correspond one colors first evident fig 11b split matrix four blocks size see two diagonal blocks diagonal matrices means matrix property 24 cheap relatively simple process elimination points correspond one color say red leads smaller system equations whose associated matrix schur complement original matrix still fairly sparse procedure amounts performing one step cyclic reduction notice general original reduced matrices nonsymmetric cyclic reduction step repeated small system equations obtained solved directly procedure called complete cyclic reduction studied several papers mainly symmetric systems arising twodimensional 2d selfadjoint elliptic problems general overview algorithm list references found 12 early papers present analyze algorithm hockney 17 buneman 2 buzbee golub nielson 4 buzbee et al 3 use cyclic reduction solving poisson equation irregular regions concus golub 6 discuss 2d nonseparable cases application cyclic reduction matrices arbitrary dimensions done sweet 20 21 presents fast 2 algorithm discusses stability eciency one step cyclic reduction symmetric positive definite systems analyzed hageman varga 16 later hageman luk young 15 shown reduced solver generally converges faster unreduced solver 1 axelsson gustafsson use cyclic reduction conjunction conjugate gradient method elman golub conducted extensive investigation 2d elliptic nonselfadjoint problems 8 9 10 shown one step cyclic reduction leads systems several valuable properties symmetrizability large set underlying pde coecients eectively used derive bounds convergence rates iterative solvers fast convergence preliminary analysis nonselfadjoint 3d model problem 11 done authors 14 one step 3d cyclic reduction described detail block jacobi solver analyzed based certain block splitting referred 1d splitting throughout paper conjunction called twoplane ordering strategy computational molecule reduced operator consists 19 points located 5 parallel planes let r denote reduced dierence operator scaling ah 2 interior gridpoint u ijk r u 2cf following results hold ordering strategy see 14 proofs obtained using techniques elman golub 8 9 theorem 11 reduced matrix symmetrized real diagonal similarity transformation products bcde befg cdfg positive theorem 12 cd fg 0 reduced matrix symmetrized reduced matrix diagonally dominant mmatrices paper purpose extend analysis initiated 14 examine block stationary methods solvers reduced system section 2 present ordering strategies examined section 3 two block splittings presented bounds convergence rates derived section 4 analyze reduced system context consistently ordered matrices section 5 amount computational work involved solving linear systems estimated comparison reduced system unreduced system conducted numerical results validate analysis illustrate fast convergence reduced system given finally section 6 conclude 2 orderings reduced system consider two ordering strategies reduced grid twoplane ordering described detail 14 corresponds ordering unknowns gathering blocks 2n gridpoints two horizontal lines two adjacent planes ordering strategy depicted fig 21a figure numbers indices gridpoints expressed 21 215 connection index gridpoint coordinate values j h given term fix borrowed matlab means rounding nearest integer toward zero x 17 192123252729316a twoplane b twoline fig 21 two suggested ordering strategies reduced grid figure unreduced grid size 4 4 4 21c see 14 specification matrix entries alternative twoplane ordering straightforward generalization three dimensions twoline ordering used elman golub 9 illustrated fig 21b reduced matrix ordering strategy block pentadiagonal ij n 2 2 n 2 2 combination n uncoupled matrices size n n diagonal matrices jj block tridiagonal submatrix size n n diagonal block stands value along main diagonal matrix given 2 gridpoints next boundary see 14 specification main diagonals values associated gridpoints next boundary superdiagonal subdiagonal blocks matrices jj following irregular tridiagonal structure depends whether j even odd superdiagonal matrices given 2de 2ce e 2 2de 2ce e 2 2de 1042 chen greif james varah j odd 2ce e 2 2de 2ce e 2 j even subdiagonal matrices 2bd j odd 2bd 2bd 2bd j even superdiagonal subdiagonal blocks jj1 block tridiagonal twoplane b twoline fig 22 sparsity patterns reduced matrices associated two ordering strategies matrices correspond 6 6 6 grids square corresponds n 2 gridpoints form two coupled planes reduced grid finally matrices jj2 jj2 diagonal 2 connection gridpoints index coordinate values given 215c sparsity patterns matrices corresponding twoplane ordering twoline ordering depicted fig 22 1d splitting b 2d splitting fig 31 sparsity patterns block diagonal matrices associated block jacobi split ting two suggested block splittings using twoplane ordering strategy 3 block splittings bounds convergence rate two ordering strategies presented section 2 matrices expressed block tridiagonal form n 3 2 n 3 2 matrix case twoplane ordering block ij size n 2 block tridiagonal respect 2n 2n blocks case twoline ordering block ij size n 2 2 n 2 2 block tridiagonal respect n n blocks solving reduced system using stationary method various splittings possible consider two obvious ones based dimension use term 1d splitting splitting based partitioning matrix blocks 2n2n blocks twoplane ordering nn blocks twoline ordering 2d splitting one based partitioning matrix 2 blocks blocks twoplane ordering n 2 2 n 2 2 blocks twoline ordering notice 1d splitting ordering strategies essentially associated blocks gridpoints xoriented however 2d splitting twoline ordering corresponds xy oriented planes gridpoints whereas twoplane ordering corresponds xz oriented planes gridpoints observations deduced referring fig 21 dierent orientations obtained simply reordering unknowns roles x z interchanged sparsity patterns block diagonal parts splittings associated block jacobi scheme depicted fig 31 compare orderings following useful result theorem 31 cd fg 0 1d splitting spectral radius jacobi iteration matrix associated twoplane ordering smaller spectral radius iteration matrix associated twoline ordering proof theorem 12 matrices mmatrices ordering strategy produces matrix merely symmetric permutation matrix associated ordering suppose splitting twoplane ordering matrix 1d splitting twoline order ing exists permutation matrix p p consider splitting p straightforward show examining matrix entries p latter nonnegative matrices therefore 23 thm 315 follows 0 result applies 2d splitting provided orientation planes gridpoints identical ordering strategies proof identical proof theorem 31 results indicated theorem 31 observed fig 32 interesting observe superiority twoplane ordering carries case cd fg 0 corresponds region mesh reynolds numbers larger 1 pde considered convectiondominated remark however amount computational work per iteration somewhat higher system corresponds twoplane ordering fig 32 cross sections mesh reynolds numbers examined example graph corresponds flow velocity x z directions graph b corresponds flow x directions convection z direction see 13 definitions derive bounds convergence rates shall attach subscripts 1 2 matrices associated 1d splitting 2d splitting respectively since twoplane ordering gives rise moreecient solution procedure twoline ordering focus denote two splittings block jacobi scheme 14 shown cd fg sign real diagonal nonsingular symmetrizer found thus since symmetrizer diagonal sparsity patterns original nonsymmetric matrix symmetrized matrix identical let us attach hat sign matrix denote application similarity transformation symmetrizes given matrix x diagonal symmetrizer q q 1 xq denoted x matrices similar original iteration matrices respectively thus spectral radii following elman golubs strategy 8 9 symmetric matrix handled easily far computing spectral radius concerned since use following 2 results presented case cd fg 0 using twoplane ordering conditions equivalent 1 centered dierences used discretize convective terms restriction magnitude mesh reynolds numbers imposed upwind dierences used values tight bounds spectral radius iteration matrix obtained 1 minimal eigenvalue found 14 thm 38 relevant part theorem quoted proposition 32 minimal eigenvalue 1 lower bound 1 given following proposition fig 32 spectral radii iteration matrices versus mesh reynolds numbers block jacobi scheme using 1d splitting centered dierence discretization broken lines correspond twoplane ordering solid lines correspond twoline ordering proposition 33 minimal eigenvalue 1 bounded table comparison computed spectral radius bound 2d splitting scheme upwind centered n bound ratio bound ratio proof part follows 14 lem 310 shown spectral radius 1 bounded combining propositions 32 33 applying rayleigh quotients matrices obtain following lemma lemma 34 minimal eigenvalue 2 bounded expressions given 33 34 bound c 2 obtained combining 14 lems 311313 follows lemma 35 spectral radius matrix c 2 bounded finally lemmas 34 35 lead following theorem theorem 36 spectral radii iteration matrices bounded respectively defined 33 34 35 respectively corollary 37 cd fg 0 block jacobi iteration converges 1d 2d splittings proof use vargas result mmatrices 23 thm 313 alter natively taylor expansions bounds given theorem 36 given thus smaller 1 table 31 give indication quality bound 2d splitting results similar level accuracy obtained presented 14 1d splitting observed bounds tight become tighter n increases suggests asymptotic spectral radii discuss stationary methods namely gaussseidel sor relative given partitioning reduced matrix consistently ordered straightforward apply youngs analysis bounds theorem 36 used estimating rate convergence gaussseidel sor schemes reader referred 19 defs 43 44 definitions property consistent ordering stated 19 matrix consistently ordered property 1048 chen greif james varah conversely matrix property permuted consistently ordered mentioned introduction matrix unreduced system property reduced system following observations proposition 38 reduced matrix associated twoline ordering sl property relative 1d 2d partitionings proof let ij denote jth nn block sl let q n 2 2n 2 2 matrix whose entries satisfy q jth n 2 2 n 2 2 block submatrix nonzero pentadiagonal matrix thus property since q referred partitioning also property proposition 39 reduced matrix associated twoplane ordering sp property relative 1d partitioning proof let ij denote jth 2n 2n block sp let q n 2 whose entries satisfy q otherwise straightforward see nonzero pattern q identical matrix associated using ninepoint operator 2d grid since latter property relative partitioning 1 1 matrices result follows hand following proposition proposition 310 reduced matrix associated twoplane ordering sp property moreover consistently ordered relative 2d partitioning proof matrix block tridiagonal relative partitioning 24 sor scheme following result completely analogous elman golubs result 2d problem 9 thm 4 theorem 311 let l denote block sor operator associated 2d splitting using twoplane ordering either cd fg 0 0 choice minimizes l respect l 1 proof theorem essentially identical proof elman golub 9 thm 4 follows young 24 chap 14 sects 52 143 algebraic details pick signs diagonal symmetrizer symmetrized block diagonal part splitting diagonally dominant mmatrix omitted 1 known corollary 37 reduced matrix consistently ordered proposition 310 way approximately determine optimal relaxation parameter case cd fg 0 replace bound given theorem 36 expression theorem 311 bound block jacobi scheme tight estimate fairly accurate proposition 312 suppose cd fg 0 system associated 2d splitting h suciently small choice approximately minimizes l spectral radius iteration matrix approximately 1 taylor expansion estimate optimal relaxation parameter given fig 41 sparsity pattern matrix c 39 follows estimated asymptotic rate convergence block sor scheme approximately second term 39 negative sign moved thus oh 4 nearproperty 1d splitting twoplane matrix although matrix associated twoplane ordering property relative 1d partitioning interesting observations made let ij denote n 2 blocks reduced matrix block ij block tridiagonal matrix relative 2n 2n blocks attach superscripts mark far block diagonal main block diagonal define see 14 specification entries matrices section 3 slight change notation let c 1d splitting matrix define c c matrix c property sp let us examine matrix prevents sp property namely c extremely sparse matrix magnitude nonzero values matrix bounded 2 cd fg 0 nonzero pattern c depicted fig 41 wish estimate far reduced matrix sp block property relative 1d partitioning let us denote upper part lower part c u l respectively let u l upper part lower part c respectively spectral radius block gaussseidel matrix satisfies significantly larger norms inequality means spectral radius gaussseidel iteration matrix associated twoplane ordering estimated replacing twoplane matrix c property thus easier analyze alternatively following observation obtained numerical experiments gs vs 2 centered b gs vs 2 fig 42 near property 1d splitting youngs analysis applied directly c c property thus approximate relationship eigenvalues block jacobi iteration matrix eigenvalues block gaussseidel iteration matrix obtained cd fg 0 observed spectral radius block jacobi iteration matrix satisfies j gs first two graphs fig 42 illustrate phenomenon numerically broken lines graphs b correspond square spectral radius iteration matrix associated block jacobi 256 256 matrix solid lines correspond spectral radius block gaussseidel iteration matrix seen curves almost indistinguishable phenomenon becomes dramatic systems become larger analysis done using vargas work extensions theory p cyclic matrices 22 23 sect 44 paper concerned recall 23 def 42 defines set matrices follows square matrix satisfies following properties diagonal entries 2 b irreducible convergent ie 0 b 1 3 b symmetric cd fg 0 reduced matrix sp diagonally dominant mmatrix symmetrized 12 well defined define 12 applying block jacobi original reduced system analogous applying point jacobi sense spectra iteration matrices associated systems identical iteration matrix associated 12 showing matrix b belongs set defined easy omitted let l lower part b define mb l mb mb let b 12 23 thm 47 slight modification match terminology used paper follows theorem 41 let b hb 1 b consistently ordered sense hb ln measures departure matrix b block property matrices consistently ordered following result applies 23 thm 46 theorem 42 b either hb 1 real hb strictly increasing 0 moreover 0 figure 42c demonstrates close function hb 1 reduced matrix 1d partitioning used provides another way illustrate near property matrix figure function hb computed symmetrized block jacobi 256 256 matrix analyze gaussseidel sor schemes recall 23 thm 48 slightly modified follows theorem 43 let lb denote sor iteration matrix b gaussseidel iteration matrix corresponds case equality possible b consistently ordered sharpened form steinrosenberg theorem 23 applying theorem reduced matrix following theorem theorem 44 bound block jacobi iteration matrix tends actual spectral radius h 0 spectral radius block gaussseidel iteration matrix coincides square bound spectral radius block jacobi iteration matrix oh 2 terms proof since iteration matrix b spectral radius 1 c dc use bound 1d iteration matrix presented theorem 36 simplicity notation denote bound clearly since 1052 chen greif james varah 20103050709fig 43 spectral radius sor iteration matrix versus relaxation parameter uppermost curve corresponds 1d splitting unreduced system order 2d splitting unreduced system 1d splitting reduced system 2d splitting reduced system since taylor expansion form 1 ch 2 2 2 taylor expansion oh 2 terms form terms pde coecients 2 shown bound b extremely tight replace spectral radii bounds spectral radii theorem 43 obtain desired result actual meaning result systems equations large enough matrix nearly property relative 1d partitioning least far convergence properties block gaussseidel scheme concerned since solution process small mesh reynolds numbers ecient 1d splitting compared 2d splitting shall see section 5 aim overcome diculty able apply youngs analysis directly block sor scheme upper bound spectral radius given 23 thm 49 1 tight however numerically evident bound jacobi iteration matrix eectively used estimate optimal sor parameter fig 43 observe behavior 1d splitting qualitatively identical behavior twocyclic consistently ordered matrices present results centered dierence discretization problem 05 reduced matrix 256 256 figure also present behavior sor iteration matrix unreduced system 5 computational work numerical experiments done analysis section examine 1d 2d solvers ecient overall show reduced system superior unreduced system 51 aspects computational work cd fg 0 23 thm 315 36 37 evident spectral radius iteration matrix associated 2d splitting smaller 1d iteration matrix however inverting 1 involves less computational work inverting 2 compare two solution procedures begin block jacobi scheme asymptotically fixed ratio 18 rate convergence two splittings see 36 37 rough terms number characterizes ratio number iterations convergence two solvers far computational work per iteration concerned lu decompositions matrices systems solved iteration assume number operations per iteration approximately number nonzeros l u plus number nonzeros part splitting order avoid costly fillin using gaussian elimination whose band sparse use instead technique innerouter iterations denote number iterations schemes associated 1d splitting 2d splitting respectively let us also define cost functions follows c 1 n c 2 n represent overall number floating point operations solvers c n represents cost inner solve 51a term nzx stands number nonzeros matrix x stands reduced matrix proposition 51 n large enough scheme associated 2d splitting cheaper one associated 1d splitting c n 15n 3 proof n large enough use relation k1 refer leading power n expressions c 1 n c 2 n follows c n result stated proposition readily follows left examine amount work involved solving inner system equations natural choice splitting system straightforward show following propositions 32 33 proposition 52 block jacobi based splitting used spectral radius inner iteration matrix namely bounded defined 33 34 considering methods faster block jacobi inner system following useful result proposition 53 inner matrix block consistently ordered relative 1d partitioning proof inner matrix block tridiagonal relative partitioning ready prove main result subsection proposition 54 cd fg 0 1d splitting used solving inner system cost solving higher 15n 3 floating point operations block jacobi well block gaussseidel block sor thus n large enough methods considered paper 1d solver faster 2d solver 1054 chen greif james varah proof taylor expansion bound proposition 52 h small enough simply examine leading term bound approximately9 block jacobi used since proposition 53 matrix consistently ordered youngs analysis shows spectral radius approximately 81 block gaussseidel used approximately 0055 block sor optimal relaxation parameter used schemes iteration costs 7n 3 floating point operations since reducing inital error factor 10 takes roughly spectral radius associated iteration matrix follows even block sor scheme optimal relaxation parameter fastest scheme considered two iterations error reduced factor approximately 10 25 obviously far satis factory thus iteration count larger 2 cost inner solve larger 15n 3 floating point operations remark inexact inner solve also considered see example elman golubs paper inexact uzawa algorithms 11 beyond scope work conclusion solver associated 1d splitting ecient one associated 2d splitting upwind dierences used centered dierences mesh reynolds numbers smaller 1 magnitude used 52 comparison unreduced system one step cyclic reduction results complicated dierence operator compared original unreduced system grid dicult handle far ordering unknowns concerned moreover unreduced matrix block consistently ordered relative 1d 2d splittings refer straightforward oneline oneplane partitionings basis 1d 2d splittings case unreduced system thus youngs analysis easily applied one could ask therefore advantages using cyclic reduction subsection illustrate superiority reduced system unreduced system start block jacobi scheme unreduced system shall refer natural lexicographic ordering unknowns lines gridpoints xoriented planes xy oriented start quoting following result given 14 sects 2 4 lemma 55 spectral radius block jacobi scheme associated 1d splitting unreduced system taylor expansion 54 14 shown spectrum iteration matrix unreduced system found sequence diagonalizations permutations form similarity transformation matrix matrix whose associated iteration matrix easy analyze far spectrum concerned reader referred proof 14 thm 21 full details 2d splitting similar procedure applied technique used similar one presented 14 algebraic details omitted lemma 56 spectral radius block jacobi iteration matrix associated 2d splitting given taylor expansion type analysis done previous section comparing 1d splitting 2d splitting reduced system possible unreduced system sketch main details suppose innerouter iterations used solving scheme associated 2d splitting denote splitting inner system dierent ones defined section 3 following proposition proposition 57 consider unreduced system suppose cd fg 0 n suciently large 1d splitting used solving inner system stationary methods considered paper 1d solver faster 2d solver proof ratio asymptotic rate convergence 1d solver 2d solver 2 number nonzeros whole matrix approximately 7n 3 number nonzeros 1 approximately 3n 3 number nonzeros 2 approximately 5n 3 since spectral radii two splittings available find spectral radius iteration matrix inner system taylor expansion given 1 cost functions analogous ones defined section 3 reduced system using line argument c n follows c n 12n 3 2d solver ecient however proposition 54 means two iterations inner solve performed enough required accuracy since 1d splitting reduced unreduced systems gives rise ecient solve compare two systems focusing splitting see also 14 sect 4 lu decomposition solution system iteration done see 12 operation count cost negligible comparison amount work done iterative process iteration reduced system costs 10n 3 floating point operations whereas iterate unreduced system costs approximately 7n 3 floating point operations per iteration hence amount computational work per iteration cheaper unreduced system factor 107 however using asymptotic formulas 36 55 evident number iterations required unreduced system larger required reduced system gs centered b gs upwind fig 51 comparison spectral radii gaussseidel iteration matrices reduced unreduced systems uppermost curve corresponds 1d splitting unreduced system order 2d splitting unreduced system 1d splitting reduced system 2d splitting reduced system worst case ratio work required solving reduced system versus unreduced system roughly 107 2740 2728 still smaller 1 thus reduced solver ecient convective terms nonzero ratio becomes smaller practice observed substantial savings illustrated test problem discussed section 53 moving comparing block jacobi scheme reduced unreduced systems comparing gaussseidel sor straightforward youngs analysis used section 4 showed even though reduced matrix consistently ordered relative 1d partitioning nearly consistently ordered general convergence analysis jacobi scheme always indicate behavior gaussseidel sor schemes nevertheless twocyclic consistently ordered matrices matrices nearly strong connections spectra jacobi iteration matrix gaussseidel sor iteration matrices 24 allow us conclude superiority reduced system unreduced system shown jacobi superiority carried stationary schemes indeed numerical experiments verify observation illustrated section 53 fig 51 superiority reduced system unreduced system gaussseidel scheme illustrated numerically graphs created small 512point grid interesting notice reduced 1d gaussseidel iteration matrix well behaved ie spectral radius significantly smaller 1 even convectiondominated case centered dierences used convergence occur block jacobi scheme values mesh reynolds numbers used bounds convergence rates range mesh reynolds numbers thus cannot explain phenomenon analytically superiority reduced system evident also sor scheme see fig 43 notice sor scheme dicult determine optimal relaxation parameter cd fg negative end subsection remark regarding case convectiondominated equations convergence analysis cover case mesh reynolds num table comparison iteration counts reduced unreduced system dierent values mesh reynolds numbers nc marks convergence 2000 iterations system reduced unreduced centered 393 173 53 nc 1030 444 nc nc gs centered 188 77 14 322 492 198 nc nc centered 36 gs upwind 219 bers greater 1 magnitude conjunction centered dierence discretization since numerical solution might oscillatory centered difference scheme used 18 analysis case less interest nevertheless fourier analysis based chan elmans technique 5 shows one mesh reynolds numbers tends scheme still converges presented 13 53 test problem consider 11 righthand side solution continuous problem ux sinz domain unit cube dirichlet boundary conditions case zero performance solvers specific problem well represents performance test problems examined taken zero vector initial guess used r stopping criterion r denotes residual ith iterate program stopped stopping criterion satisfied 2000 iterations numerical experiments executed sgi origin 2000 four parallel 195 mhz processors 512 mb ram 4mb cache program written matlab 5 experiments presented 1d solver used table 51 grid size 32 matrix underlying system equations size 32 768 32 768 table iteration counts jacobi scheme gaussseidel scheme presented four values pde coecients two discretization schemes pde coecients referred table 51 specified 11 values coecients table namely 10 20 100 1000 corresponding values mesh reynolds numbers 01515 03030 1515 1515 notice last two larger 1 values analytical way knowing optimal relaxation parameter experiments values performed following observations made 1 overall reduced solver substantially faster unreduced solver cases reduced solver converges whereas unreduced solver remark cases examined cpu time reduced solver less much less cases cpu time unreduced system 2 convergence faster illustrates phe nomenon supported analysis holds also twodimensional case 9 smallenough mesh reynolds numbers 1058 chen greif james varah nonsymmetric systems converge faster close symmet ric ones close sense pde coecients close zero 3 upwind dierence scheme converges slowly centered dier ence scheme mesh reynolds numbers small magnitude convergence extremely fast large mesh reynolds numbers applies reduced unreduced systems follows fact pde coecients grow larger underlying matrix diagonally dominant upwind schemes used 6 concluding remarks presented ordering strategies cyclically reduced matrix arising discretizing 3d model problem constant coe cients derived bounds convergence rates block stationary schemes associated called 1d splitting 2d splitting compared amount work involved solving system suggested splittings gen eral 1d splitting gives rise moreecient solvers since matrices associated splitting consistently ordered analyzed departure block property shown fact matrices nearly block consistently ordered shown analytically numerically one step cyclic reduction results system easier solve compared original unreduced system acknowledgments would like thank referees helpful com ments substantially improved manuscript r use preconditioned conjugate gradient methods redblack order fivepoint dierence schemes compact noniterative poisson solver direct solution discrete poisson equation irregular regions direct methods solving poissons equations fourier analysis iterative methods elliptic problems use fast direct methods e point cyclic reductions elliptic boundaryvalue problems constant coefficient case iterative methods cyclically reduced nonselfadjoint linear systems iterative methods cyclically reduced nonselfadjoint linear systems ii line iterative methods cyclically reduced discrete convectiondiusion problems inexact preconditioned uzawa algorithms saddle point problems matrix computations analysis cyclic reduction numerical solution threedimensional convectiondiusion equations iterative solution cyclically reduced systems arising discretization threedimensional convection diusion equation equivalence certain iterative acceleration methods block iterative methods cyclically reduced matrix equa tions fast direct solution poissons equation using fourier analysis numerical solution convectiondiusion problems iterative methods sparse linear systems generalized cyclic reduction algorithm cyclic reduction algorithm solving block tridiagonal systems arbitrary dimension generalization youngfrankel successive overrelaxation scheme matrix iterative analysis iterative solution large linear systems tr ctr cheung michael k ng blockcirculant preconditioners systems arising discretization threedimensional convectiondiffusion equation journal computational applied mathematics v140 n12 p143158 1 march 2002 liang li tingzhu huang xingping liu asymmetric hermitian skewhermitian splitting methods positive definite linear systems computers mathematics applications v54 n1 p147159 july 2007