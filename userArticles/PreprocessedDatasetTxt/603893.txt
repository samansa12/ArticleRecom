bayesian likelihood methods fitting multilevel models complex level1 variation multilevel modelling common practice assume constant variance level 1 across individuals paper consider situations level1 variance depends predictor variables examine two cases using dataset educational research first case variance level 1 test score depends continuous intake score predictor second case variance assumed differ according gender contrast two maximumlikelihood methods based iterative generalised least squares two markov chain monte carlo mcmc methods based adaptive hybrid versions metropolishastings mh algorithm use two simulation experiments compare four methods find four approaches good repeatedsampling behaviour classes models simulate conclude contrasting raw logscale formulations level1 variance function find adaptive mh sampling considerably efficient adaptive rejection sampling heteroscedasticity modelled polynomially log scale b introduction past 15 years tting multilevel models data hierarchical nested structure become increasingly common statisticians many application areas eg goldstein 1986 1995 bryk raudenbush 1992 draper 2000 main purpose tting models partition variation response variable function levels hierarchy relate variability descriptions data structure education example multilevel modelling used calculate proportion variation observation explained variability students classes schools 3level nested structure randomeects modelling kind generally combined xedeects modelling predictors additionally related response variable covariates generally models assume constant level1 variance error residual term observations notation students level 1 3level structure reason true applications alternative allow heteroscedasticityin words models relate amount level1 variability predictor variables refer complex level1 variation heteroscedasticity common modelling concern standard tting institute education university london 20 bedford way london wc1h 0al uk email bwjsmsrioeacuk wjb hgoldsteinioeacuk hg teuejraioeacuk jr department mathematical sciences university bath claverton bath ba2 7ay uk email ddrapermathsbathacuk web httpwwwbathacukmasdd w j browne draper h goldstein j rasbash table 1 comparison means variances normalised exam scores various partitions gcse dataset partition size mean variance whole dataset 4059 0000 1000 boys 1623 0140 1052 girls 2436 0093 0940 standardised lrt 1 612 0887 0731 05 standardised lrt 01 619 0191 0650 01 standardised lrt 03 710 0044 0658 03 standardised lrt 07 547 0279 0659 07 standardised lrt 11 428 0571 0678 11 standardised lrt 549 0963 0703 linear models data lacking hierarchical multilevel structure eg weisberg 1985 far less attention paid topic multilevel data main motivating example consider dataset studied rasbash et al 2000 originally analysed goldstein et al 1993 dataset contains exam results 4059 pupils schools sampled six inner london education author ities response variable interest total score achieved gcse examinations standardised test taken age 16 pupils variable already normalised transformed replacing value standard normal score dataset consider table contains mean variance estimates response variable various partitions dataset one main predictors interest score reading test lrt pupils took age 11 purposes partitioning divided pupils 7 groups roughly equal sample size based standardised version lrt score mean column table clear girls generally bit better boys lrt score positively correlated exam score also seen boys exam scores slightly variable girls scores variance exam score bears roughly quadratic relationship lrt score conclusions mean tting multilevel model dataset worth considering need complex variation level 1 plan paper follows section 2 describe two variations maximumlikelihood approach tting multilevel models complex level1 variation examine several examples complex variance structures sections 3 4 present markov chain monte carlo mcmc method bayesian tting models based adaptive metropolishastings sampling using two dierent proposal distribu tions section 5 give results two simulation studies investigating bias interval coverage properties repeated sampling four tting methods described previous three sections section 6 examines alternatives mcmc methods b formulation complex variance structures section 7 discusses conclusions suggests extensions work presented fitting multilevel models complex level1 variation 3 maximumlikelihoodbased methods complex variance structures begin describing general 2level model complex variation later sections examine methods alternatives general model additional constraints added basic structure general gaussian multilevel model n n x v n 1 vector responses necessarily independently distributed p f 1 vector xedeect coecients predictors n n total number level1 observations data set 4059 students example section 1 p f number xed eects model n n covariance matrix v responses contains random structure model twolevel case write variance term v level2 unit j expression variance partitioned separate terms two levels e u denoting random eects levels 1 2 respectively covariances responses form v iji two observations level2 unit v iji means vector ordered observations level2 unit grouped together v block diagonal form general formulation level1 level2 variances covariances potentially dierent pair observations important special cases exist simpler structure eg variancecomponents models level1 level 2 variances constant across observations covariates x may make appearance random structure model leading partition uij example randomslopes regression model single predictor x 1ij uij u11 u consists variance covariance terms level 2 expressed matrix structural zeroes neces sary using notation general withinblock covariance term written vector predictors language section referred earlier complex variation level 1 simply means partitioning level1 variance depends natural way predictor variables figure 1 presents several potential variance structures tted gcse dataset described earlier corresponding models eij uij eij uij eij 4 w j browne draper h goldstein j rasbash standardised lrt score levelvariance model 2 standardised lrt score variance level 1 variance level 2 variance standardised lrt score variance level 1 variance level 2 variance standardised lrt score variance model 5 level 1 variance boys level 1 variance girls level 2 variance figure 1 four dierent variance structures tted gcse dataset uij eij models x 1 refers standardised lrt score x 2 refers gender coded 0 boys 1 girls equation 2 simple onelevel regression model quadratic variance relationship lrt models involve tting increasingly complex variance structures data twolevel framework one approach tting models 25 via maximum likelihood ml based iterative generalised least squares igls restricted variant rigls also known reml corrects bias basic idea similar em algorithm estimate 1 obtained using current estimate v b estimate v obtained using iglsrigls estimation fitting multilevel models complex level1 variation 5 table 2 igls estimates models 25 tted gcse dataset standard errors ses parentheses model parameter 2 3 4 5 u00 0094 0018 0091 0018 0086 0017 u01 0019 0007 0020 0007 u11 0014 0004 0015 0004 e12 0032 0013 e22 0058 0026 covariance matrix v recast regression problem weighted least squares used steps see goldstein 1986 1989 details table estimates obtained models 25 applied gcse data gender lrt score evidently useful predicting gcse score model 2 naively ignores hierarchical nature data hints heteroscedasticity ml estimate e11 big standard error se estimates u00 equations 35 clear need twolevel modelling full complexity required describe data comes focus model 5 every estimate least 22 times large se 3 mcmc method general 2level gaussian model complex level1 variation browne draper 2000a 2000b gave gibbssampling algorithms bayesian tting 2level variancecomponents randomslopesregression models respectively section consider general 2level model complex variation level 1 easily generalised nlevel model via approach similar method detailed browne 1998 mcmc tting model 1 useful rewrite follows ij denoting scalar outcome level1 observation level2 unit 0 0 e p f 1 p 2 1 p 1 1 vectors xedeects parameters level2 level1 residuals vectors predictor values p 1 p 2 numbers parameters specifying random eects levels 1 2 respectively iglsrigls methods directly estimate estimated tting model using method given 6 w j browne draper h goldstein j rasbash goldstein 1995 equation 6 e u variance terms level 1 level gibbs sampling procedures tting multilevel models 6 proceed smoothly treating level2 residuals latent variables forming full conditional posterior distributions multilevel model simple homoscedastic variation level 1 level1 residuals may calculated iteration subtraction model cannot explicitly compute individual level1 residuals instead deal composite residuals x c calculated subtraction important part algorithm follows store composite level1 variance function individual parameters depend level1 covariance matrix e individual variances means algorithm follows apart updating step e almost identical algorithm model without complex variation browne 1998 31 inversewishart proposals level1 covariance matrix rst mcmc method examined paper collect together terms variance equation level 1 eij covariance matrix e updating e using metropolishastings mh algorithm therefore requires proposal distribution generates positivedenite matrices later relax restriction use inversewishart proposal distribution expectation current estimate e iteration generate e parameterisation used example gelman carlin et al 1995 inversewishart distribution w 1 expectation e w positive integer degrees freedom parameter produce distribution expectation e parameter w tuning constant may set integer value gives desired mh acceptance rate prior distributions parameters model 6 make following choices algorithm generic prior e specied section 42 level1 covariance matrix inversewishart prior level2 covariance matrix multivariate normal prior n p f xed eects parameter vector algorithm detailed appendix hybrid gibbs mh steps divides parameters latent variables 6 four blocks uses multivariate normal gibbs updates u j inversewishart gibbs updates u inversewishart mh proposals e 32 adaptive method choosing tuning constant w browne draper 2000b describe adaptive hybrid metropolisgibbs sampler tting randomeects logistic regression models gibbs sampling may used models variance parameters metropolis updates needed xed eects latent residuals browne draper employ series univariate normal proposal distributions pds quantities give procedure adaptive choice appropriate fitting multilevel models complex level1 variation 7 table 3 illustration adaptive mh procedure model 4 applied gcse data acceptance within iterations rate w tolerance 100 20 138 0 200 19 195 0 300 30 208 1 500 30 229 3 values variances pds achieve ecient mh acceptance rates provide modication procedure case inversewishart proposals set tuning parameter w described arbitrary starting value example follows 100 run algorithm batches 100 iterations goal achieve acceptance rate level1 covariance matrix lies within specied tolerance interval r compare empirical acceptance rate r current batch 100 iterations tolerance interval modify proposal distribution appropriately proceeding next batch 100 modication performed end batch follows r r integer part w used 8 amount w altered iteration procedure increasing function distance r r adaptive procedure ends three successive r values lie within tolerance interval value w xed proceed usual burnin monitoring periods 33 example consider model section 2 quadratic relationship variance lrt predictor model 4 adaptive procedure run model target acceptance rate based recommendation gelman roberts gilks 1995 tolerance summarises progress adaptive method example 500 iterations required adjust proposal distribution give desired acceptance rate 5002000 iterations typically needed applications examined table 4 compares estimates produced mcmc method model 4 igls rigls procedures b another mcmc method described next section throughout paper mcmc point estimates posterior means used slightly informative inversewishart prior level2 covariance matrix mcmc methods based rigls estimate uniform prior level1 covariance matrix case results methods fairly similar one exception parameter e11 noticeably larger using mcmc 8 w j browne draper h goldstein j rasbash table 4 parameter estimates four methods tting model 4 london schools dataset sesposterior standard deviations parentheses mcmc methods monitored 50000 iterations adaptive procedure burnin 500 iterations mcmc method parameter igls rigls 1 2 method 1 dierence highlights fact rst mcmc approach actually ts model extra positivedenite constraint forcing e11 positive ates point estimate second mcmc method consider based dierent constraints examined chain values produced e11 found nearly 40 values negative inconsistency result model examined next section e11 variance 4 truncated normal proposals level1 variance func tion inversewishart updating method assumes variance function level 1 arises positivedenite covariance matrix consider alternative method manner similar igls rigls requires variance level 1 linear function parameters mcmc solution still constraints igls solution still considering level1 level2 variances separately quantities must positive constraint used mcmc method 1 covariance matrix level 1 positivedenite actually stronger necessary positivedenite matrices guarantee vector x c ij produce positive variance equation 6 milder still scientically reasonable constraint allow values e j restriction appears complicated work consider parameters e separately assume variables xed constraint becomes manageable useful rewrite model 1 time follows e 0 e eij given equation 7 composite level1 residuals e normally distributed variances depend predictors consequently fitting multilevel models complex level1 variation 9 constraint level1 variance always positive still satised e need positivedenite 41 mh updating method 2 second method identical rst u j appendix involves hastings update dierent proposal distribution e update parameter level1 variance equation turn always requiring j every iteration markov chain 0 10 considering rst diagonal terms ekk c x c kth element vector x c ij equivalent requiring c use normal proposal distribution variance 2 kk reject generated values fail satisfy 12 amounts using truncated normal proposal shown figure 2i hastings ratio r calculated ratio two truncated normal distributions shown figure 2i ii letting value ekk time proposed value time kk kk update step follows ekk probability min4 ekk otherwise corresponding density denominator 14 given 28 diagonal terms special case always multiplied positive quantity variance equation proposal distribution needs one truncation point generally nondiagonal terms ekl get following time j constraint 10 must satised 1 k l p 1 rewritten ekl c c ekl w j browne draper h goldstein j rasbash iv figure 2 plots truncated univariate normal proposal distributions parameter current value c b proposed new value max min truncation points distributions iii mean c distributions ii iv mean equivalent two constraints j x c ekl min ekl min ij j x c use normal proposal distribution time variance 2 kl values failing satisfy 16 rejected leads truncated normal proposal shown figure 2iii hastings ratio r simply ratio two truncated normal distributions shown figure 2iii iv letting value ekl time fitting multilevel models complex level1 variation 11 proposed value time kl kl min ekl kl kl update step similar 14 subscripts kl place kk e terms 42 proposal distribution variances prior distributions method outlined consider parameter e separately means use separate truncated univariate normal proposal distribution parameter subject constraints value generated produce positive level1 variance eij j therefore need choose proposal distribution variance parameter two possible solutions use variance parameter estimate rigls procedure multiplied suitable positive scale factor use adaptive approach burnin monitoring run simulation see browne draper 2000a description methods case random eects logistic regression models prior distributions using method must take account constraints imposed parameters analyses perform paper method use series marginal uniform priors level1 variance terms subject constraints words valid combinations parameter estimates e priori equally likely prior distributions may problematic 43 examples model 4 tted gcse data section 33 estimates produced mcmc methods shown table 4 truncated normal method used adaptive mh procedure case desired acceptance rate 50 parameters updated separately advantage truncated normal method handle variance functions would necessarily positivedenite matrix form illustration consider simple case inversewishart method cannot model follows model includes variance boys term represents dierence variance boys girls results tting model given table 5 methods give roughly estimates level1 variance terms total variances produced model similar values given part table 1 variance response calculated boys girls separately 12 w j browne draper h goldstein j rasbash table 5 parameter estimates three methods tted model 18 gcse dataset method 2 using truncated normal proposals monitored 50000 iterations following adapting period burnin 500 iterations mcmc parameter igls rigls method 2 5 simulation studies section examine bias intervalcoverage properties repeated sampling four methods described two sets simulated models complex level variation based gcse example rst consider model 4 features quadratic variance relationship input reading test lrt predictor true population parameters simulation used values close estimates obtained actual data one exception increased e11 correlation random eects level 1 reduced sample datasets drawn multilevel models high correlation cause convergence problems igls rigls methods browne draper 2000b one thousand datasets generated randomly according model 4with numbers level1 level2 units 4069 65 respectively original gcse data set distribution level1 observations within level2 unitsand tted using four methods results presented table 6 mcmc methods simulation studies posterior distribution dataset monitored 10000 iterations adapting period burnin 500 igls starting values uniform priors used level1 variances xed eects slightly informative inversewishart prior used level2 covariance matrix line results browne draper 2000b interval estimates nominal level 1001 igls rigls approaches form based largesample normal approximation users multilevel packages mlwin rasbash et al 2000 hlm bryk et al 1988 would report report interval estimates since packages routinely report estimates standard errors maximumlikelihood methods bayesian mcmc methods give results based posterior means point estimates 9095 central posterior intervals second simulation study table 7 based model 18 section 43 male female subsamples dierent level1 variances mcmc method 1 available model created 1000 simulation datasets population values similar estimates obtained gcse dataset bayesian approach tting uniform priors used level1 variances xed eects fitting multilevel models complex level1 variation 13 table summary results rst simulation study lrt score random levels 1 2 bias results relative except brackets absolute true value cases zero monte carlo standard errors ses given parentheses monte carlo ses estimated interval coverages b range 07 10 relative bias point estimates parameter mcmc mcmc ftrue valueg igls rigls method 1 method 2 u00 f01g 181 059 008 060 279 062 279 062 b interval coverage probabilities nominal levels 9095 mcmc mcmc parameter igls rigls method 1 method 2 u00 894931 907936 911960 911960 u01 900944 903946 887941 888941 e00 907941 907941 902941 909948 e11 906951 907951 900950 909954 c mean interval widths nominal levels 9095 mcmc mcmc parameter igls rigls method 1 method 2 14 w j browne draper h goldstein j rasbash table 7 summary results second simulation study separate variances level 1 boys girls monte carlo standard errors ses given parentheses monte carlo ses estimated interval coverages b range 07 10 relative bias point estimates parameter mcmc ftrue valueg igls rigls method 2 b interval coverage probabilities nominal levels 9095 mcmc parameter igls rigls method 2 u00 883925 892934 900953 c mean interval widths nominal levels 9095 mcmc parameter igls rigls method 2 fitting multilevel models complex level1 variation 15 1 prior used level2 variance parameter line results browne draper 2000a evident tables 6 7 four methods performed reasonably well models rigls succeeded reducing already small biases arising igls estimation cases relative biases mcmc methods also small ranging 0 48 median absolute value 15 interval coverages four methods close nominal actual coverages ranging 86 91 9196 nominal 90 95 respectively four methods achieved level coverage intervals comparable length ratios 95 90 interval lengths method close value 1 0975 expected normality ml methods clear advantage speed original gcse data set iglsrigls mcmc methods 1 2 took 2 168 248 seconds 500mhz pentium pc respectively mcmc methods based 10000 monitoring iterations ml approach two potential disadvantages data sets small numbers level1 level2 units requires sophisticated methods constructing interval estimates variance parameters achieve good coverage properties largesample normal approximation used browne draper 2000ab may fail converge e andor matrices exhibit high degree correlation parameters quantifying random eects bayesian methods considerably slower additional advantage inferences arbitrary functions model parameters automatic model parameters monitored 6 mcmc methods 61 gibbs sampling special cases problem complex level1 variation tted using standard gibbs sampler model equation 18 used second simulation use dierent level1 variance term gender one example could reparameterise model two variances one boys 2 b one girls rather boys variance plus dierence scaledinverse 2 priors see eg gelman et al 1995 used two variances parameters respectively divide children boys girls subgroups b g size n b n g step 3 algorithm given appendix rewritten two gibbs sampling steps follows full conditional 2 b full conditional 2 g exactly analogous level1 variance steps algorithm 62 modelling variance log scale developers software package bugs spiegelhalter et al 1997 use dierent approach tting complex level1 variation one examples schools data w j browne draper h goldstein j rasbash set example 9 volume 2 spiegelhalter et al 1996 model logarithm level1 precision function predictors parameters 0 results multiplicative rather additive variance function exp advantages approach parameters unconstrained level variance never negative easier specify prior method disadvantages interpretation individual coecients easy computation models slower interpretation diculty apparent mainly x variables categorical model 20 tted bugs using adaptive rejection ar sampling gilks wild 1992 alternatively adaptive mh method used truncated normal algorithm section 41 used time parameter constraints hence truncation normal proposal distributions goldstein 1995 appendix 51 shows obtain ml estimates model see yang et al 2000 set mlwin macros explore dierences logvariance modelling earlier approach tted four dierent level1 variance functions gcse dataset model eect lrt score x 1 level1 variance considered quadratic relationship examined earlier model 4 simpler linear relationship eij also considered two exponential relationships four models level2 variance structure xed eects equation 4 figure 3 plots resulting level1 estimated variances function lrt score case majority data variance estimates produced four models fairly similar discrepancies models occurring extremes lrt range relatively observations table presents estimates four models using mh method 2 together rafterylewis 1992 default diagnostics mh ar sampling exponential models 23 comparative timings part b table evident parameter worst mcmc mixing intercept 0 means although mh method requires longer monitoring runs ar approach fitting multilevel models complex level1 variation 17 standardised lrt score levelvariance quadratic exp linear exp quadratic figure 3 four ways model eect standardised lrt score level1 variance gcse dataset level1 variance parameters run lengths required ensure parameter estimates specied accuracy respect 95 interval estimation roughly equal part c table seen mh approach 49 times faster realtime execution speed example results table 8 based single data set typical ndings obtained similar models 7 conclusions extensions paper presented several methods modelling nonconstant level1 variance functions multilevel data introduced two new adaptive metropolishastings sampling methods tting functions subject dierent constraints two methods give similar estimates models true parameter values aected constraints true values satisfy additional positive denite matrix constraint inversewishart proposal method estimates two methods dier main advantage inversewishart method models level1 variance function matrix manner analogous usual treatment level2 variance function meaning among things informative inversewishart priors level 1 used approach main advantage truncated normal proposal method general deal variance function level w j browne draper h goldstein j rasbash table 8 parameter estimates four dierent level1 variance functions applied gcse dataset mcmc methods used monitoring period 50000 iterations burnin 500 iterations methods adaptive mh step level run using development version mlwin adaptive rejection ar step level 1 run winbugs posterior standard deviations given parentheses parameter estimates exponential exponential parameter linear quadratic linear quadratic e11 0003 0009 00005 0016 b rafterylewis values thousands iterations main entries apply mh method 2 corresponding values ar parentheses exponential exponential n linear quadratic linear quadratic u00 43 43 44 43 43 41 e11 169 156 46 c timings minutes 500 pentium mhz exponential exponential method linear quadratic linear quadratic metropolishastings 19 20 23 25 adaptive rejection 95 227 fitting multilevel models complex level1 variation 19 1 methods bias interval coverage properties similar maximumlikelihood igls rigls approaches four methods perform satisfactorily repeated sampling regard section 62 considered alternative formulation level1 variance function terms log precision level 1 method two advantages need impose constraints terms resulting variance function therefore easier contemplate variety prior distributions resulting variance parameters main disadvantage approach individual terms variance function may easily interpreted making potentially dicult construct sensible informative priors table 8 shows clearly however adaptive rejection sampling much less ecient adaptive metropolishastings sampling achieve default mcmc accuracy standards variance precision functions exponential parameters two obvious extensions work arbitrary variance structures higher levels multivariate normal responses two approaches tting random eects level 2 appear common current applied work modelling random eects independently tting fully dependent random eects complete covariance matrix level see birats example spiegelhalter et al 1996 illustration formulations fairly easy blockdiagonal covariance structure higher level using gibbs sampling straightforward extension approach given section 61 adaptive mh sampler truncated normal proposal method 2 section 41 used dependence structure among random eects higher levels including non blockdiagonal covariance matrices multivariate normal response models variance function lowest level includes variances response plus covariances responses variance function could also extended include predictors may uence variance individual responses analogous way univariate model intend report mcmc sampling algorithms general multivariateresponse multilevel models elsewhere acknowledgements grateful epsrc esrc european commission nancial support david spiegelhalter nicky best participants bugs project references comments set multilevel modelling papers based rst authors phd dissertation membership list imply agreement ideas expressed people responsible errors may present appendix details mcmc method 1 step 1 algorithm described section 31 full conditional distribution gibbs update xed eects parameter vector multivariate normal p f w j browne draper h goldstein j rasbash number xed eects eij eij involves gibbs update level2 residuals u j also multivariate normal full conditional distribution p 2 number parameters describing random eects level2 n j number level1 units level2 unit j pn eij pn eij step 3 employs hastings update using inversewishart proposal distribution level1 covariance matrix e specically markov chain moves e time e follows e probability min e e e otherwise e w 1 e w chosen section 32 p 1 number rows columns b hastings ratio r 26 exp tr e e tr e c full conditional distribution e 26 1eij exp expressed righthand side 28 convenience terms eij equation 7 finally step 4 involves gibbs update level2 covariance matrix expressed ofu full conditional e number rows columns u j number level2 units data set improper uniform prior u corresponds choice fitting multilevel models complex level1 variation 21 r applying mcmc methods multilevel models bryk bryk bayesian hierarchical modeling bayesian data analysis adaptive rejection sampling gibbs sampling multilevel mixed linear model analysis using iterative generalised least squares restricted unbiased iterative generalised least squares estimation multilevel statistical models second edition multilevel analysis school examination results many iterations gibbs sampler users guide mlwin version 21 bugs 05 examples version ii cambridge medical research council biostatistics unit bugs bayesian inference using gibbs sampling version 060 applied linear regression mlwin macros advanced multilevel modelling version 20 tr