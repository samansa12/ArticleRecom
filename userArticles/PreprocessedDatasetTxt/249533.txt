empirical evaluation performancememory tradeoffs time warp abstractthe performance time warp mechanism experimentally evaluated limited amount memory available parallel computation implementation cancelback protocol used memory management shared memory architecture viz ksr evaluate performance vs memory tradeoff implementation cancelback protocol supports canceling back one memory object memory exhausted precise number referred salvage parameter incorporates nonworkconserving processor scheduling technique prevent starvationseveral synthetic benchmark programs used provide interesting stress cases evaluating limited memory behavior experiments extensively monitored determine extent various factors may affect performance several observations made analyzing behavior time warp limited memory 1 depending available memory asymmetry workload canceling back several memory objects one time ie salvage parameter value one improves performance significantly reducing certain overheads however performance relatively insensitive salvage parameter except extreme values 2 speedup vs memory curve time warp programs welldefined knee speedup increases rapidly memory beyond little performance gain increased memory performance nearly equivalent large amounts memory achieved modest amount additional memory beyond required sequential execution memory management overheads small compared event granularity results indicate contrary common belief memory usage time warp controlled within reasonable limits without significant loss performance b common belief memory usage time warp controlled within reasonable limits without significant loss performance work also suggests limiting memory act effective throttling mechanism time warp executions tion protocols time warp offers potential greater exploitation parallelism perhaps importantly greater transparency synchronization mechanism simulation programmer time warp demonstrated fair amount success speeding simulations combat models 31 communication networks 3 26 queueing networks 8 digital logic circuits 2 among many others one major critique time warp apparent large inefficient use memory time warp uses checkpointing technique implement rollback mechanism past states processes need saved enable rollback addition time warp system may hold large amount incorrect computations rolled back canceled future thus time warp may inefficient memory usage large simulations may cause severe performance degradations due overheads virtual memory system underlying architecture memory utilization time warp unbounded principle even though garbage collection mechanism called fossil collection reclaiming memory alone may enough complete time warp execution reasonable amount memory makes imperative study techniques limit memory usage time warp execution performance impacts number memory management schemes proposed reduce space usage time warp classify approaches two categories passive active passive schemes reduce average space utilization must abort program execution actually runs memory infrequent state saving 20 incremental state saving 4 strategies type contrast active schemes able run simulation within available memory long minimal amount memory available able recover memory demand intuitively latter schemes attempt retract possibly correct computations andor states ahead virtual time make room recent computation proceed lin 19 18 made comprehensive study space usage memory management schemes many approaches proposed modest amount work investigating performance passive memory management schemes see example 7 even less evaluating active mechanisms two studies evaluating performance active mechanisms 1 analytic model specific class homogeneous synthetic simulation models developed ii recently work reported scheme reclaims state memory demand performance evaluated homogeneous queueing network model 25 paper present comprehensive empirical evaluation rollback based active memory management protocol called cancelback 15 context also describe efficient implementation cancelback protocol existing multiprocessor time warp kernel cancelback protocol attractive storage optimal property 18 storage optimal property states cancelback protocol able complete time warp computation within amount memory required equivalent sequential computation however memory usually gives better performance storage optimal property says nothing concerning performance one expect different amounts memory factors affect performance performance depends heavily implementational overheads experimental evaluation performance vs memory tradeoff required one goal study determine minimum amount memory required efficient execution practical implementations remainder paper organized follows section 2 briefly describe time warp protocol define terminology used throughout section 3 describe cancelback protocol active memory management schemes time warp section 4 discuss specific problems related efficiently implementing cancelback multiprocessor architecture solutions adopted section 5 discusses results synthetic simulation workloads evaluate performance cancelback protocol section 6 extends results specific benchmark models section 7 analyze various factors controlling limited memory behavior time warp properties application simulation execution system determine factors also indicate view limiting available memory way throttle time warp execution conclusions presented section 8 2 time warp protocol time warp program consists collection logical processes lps execute possi bly different physical processors lps execute timestamped events interact exchanging events also called messages use terms event message synonymously timestamp indicates events virtual time occurrence assumed specified application program discrete event simulation programs virtual time identical simulation time events simulation events event two timestamps associated timestamp occurs called receive timestamp ii timestamp sending lp event scheduled called send timestamp shall use term timestamp indicate receive timestamp unless specified otherwise lp time warp system must process messages scheduled timestamp order order guarantee correctness lp processes events timestamp order eg receives message called straggler timestamp smaller already processed lp rolls back corresponding event computations processed sequence reexecutes including newly arrived stragglers timestamp order rollback entails undoing event computations computation event modify state 1 lp ii send messages possibly lps thus undoing event computation entails restoring state lp existed prior processing event ii unsending messages sent course processing event enable rollbacks state lp periodically saved ii negative copy outgoing message saved sending lp negative copy called antimessage differs sign field original positive message event computation undone upon rollback state lp restored past correct copy unsending previously sent message accomplished sending corresponding antimessage cancels annihilates previously sent positive message cancelled message already processed another lp antimessage received receiver first rolled back possibly generating additional antimessages prior message cancellation order reclaim memory eg processed messages snapshots lps state allow operations cannot rolled back eg io global virtual time gvt defined 1 note time warp lps share states though extensions time warp implement state sharing proposed9 gvt future present past send time receive time send time receive time receive time send time fossil collect optimistically generated required figure 1 time warp objects gvt lower bound timestamp rollback might later occur guarantee progress time warp system always ensure eventual increase gvt normally gvt defined operationally smallest receive timestamp unprocessed partially processed message antimessage system however memory management schemes may require different operational definition later discuss question gvt defines commitment horizon simulation events timestamp less gvt referred committed events never rolled back irrevocable operations invoked committed events performed generally speaking storage occupied states reclaimed latter operations called fossil collection 3 active memory management schemes time warp time warp consumes memory storing three types objects viz copies state vectors positive messages negative messages objects receive time 2 earlier gvt called past objects objects send time earlier equal gvt receive time later equal gvt called present objects objects send time therefore receive time later gvt called future objects see figure 1 apparent present messages states ones required corresponding sequential simulation simulation time equal current value gvt parallel simulation past objects committed fossil collected present future objects also called uncommitted objects 3 2 state vector virtual send time time created virtual receive time time used read 3 except present antimessages also committed fossil collected several techniques proposed reclaim memory removing future objects thereby causing rollback sender corresponding object message sendback proposed jefferson original work time warp 14 flow control scheme message arrives receiving processs input queue room store receiving process makes room sending back message possibly different one received original sender sender must roll back 4 state sent message resend message executes forward natural choice 14 message sent back one largest send time gafnis protocol 11 generalizes message sendback removing stored object input message state vector output message process p runs memory discarded object input message returned sender message sendback output message transmitted receiver cancel corresponding positive message p rolls back state sent original positive message stored object state discarded p rolls back previous state typically stored object highest send time selected sent back message sendback gafnis protocol storage optimal property may able complete simulation within sequential amount memory 5 cancelback protocol 15 however storage optimal unlike message sendback gafnis protocol cancelback targeted shared memory architecture single shared pool memory processes allocate objects shared pool return free objects pool reclama tion protocol process p needs storage object u assumed u always allocated allocation may remaining free memory case protocol invokes fossil collection fossil collection fails reclaim storage protocol discards stored object process exactly gafnis protocol free memory discarded object may may u object sendtime greater current gvt 6 ie future object discarded lin described similar protocol called artificial rollback 19 18 process runs 4 accommodate sendbacks operational definition gvt must modified ensure sendback cause rollback beyond gvt message sendback gvt minimum local clocks ii send times messages transit 18 definition also used twos 16 implements message sendback flow control 5 fact shown worst case space usage protocols number processors times sequential amount memory 25 6 cancelback protocol uses original definition gvt memory fossil collection fails reclaim enough storage process farthest ahead virtual time rolled back resulting cancellations free storage rollback distance considered design parameter efficiency reasons lin recommends rolling back process latest local clock second latest local clock process continues certain amount storage reclaimed minimum amount storage reclaimed parameter lin also suggests integration nonwork conserving processor scheduling policy artificial rollback limit number active processors memory consumption rate matches amount available memory 18 artificial rollback similar cancelback thus shares storage optimality property implemented shared memory system however may easier implement many systems example need distinguish messages forward reverse transit similarly possibility positive message reverse transit negative message forward transit miss fail annihilate however differences expected create significant performance differential thus even though study investigates performance time warp cancelback protocol similar results expected artificial rollback protocol recently preiss loucks suggested active protocol reclaim memory demand involve rollback 25 protocol called pruneback reclaims uncommitted state objects primarily targeted distributed memory systems pruneback shown outperform artificial rollback certain homogeneous queueing network models 25 efficient implementation cancelback protocol efficient implementation cancelback nontrivial practice following briefly discuss performance issues associated implementing cancelback 41 instantaneous message delivery one important problem implementing cancelback assumption zero message delivery time 15 real architectures message sends instantaneous processes ask memory rate faster freed cancelback later rate determined speed rollback message send annihilation must fairness scheme ensure process asked memory would eventually receive without provision possible process furthest behind gvt 7 regulator starves forever simulation cannot progress starvation easily avoided invoking cancelback atomically 8 low level synchronization protocol records memory requests guarantees eventually served serving requests firstcomefirstserve order one way ensure although approach avoids starvation may necessarily lead good performance process furthest behind computation gvt regulator must wait turn allocate memory computation likely critical path may unnecessarily delayed implementation starvation avoided another approach gvt regulator given priority allocate event buffer reclaimed cancelback 9 evident simulation always progress gvt regulator starved memory lps may allocate reclaimed memory gvt regulator successfully allocates memory makes progress scheme also eliminates busy cancelback 15 message repeatedly canceled back regenerated large number times 42 n event cancelback invocation cancelback expensive global computation involved includes gvt computation fossil collection efficient recover one buffer though one buffer sufficient buffers equal size implementation single invocation cancelback reduce frequency time warp system runs memory thus global computation cost reduced thus allow one message buffer reclaimed one invocation cancelback protocol call number buffers reclaimed salvage parameter parameter similar parameter used lin artificial rollback protocol 18 assuming salvage value n failed fossil collection invokes cancelback send back n highest send timestamped future events entire system note correctness standpoint n future events may 7 cancelback nonzero message delivery times new operational definition gvt required gvt minimum local simulation times ii receive timestamps messages forward transit iii send timestamps messages backward transit ie discarded way sender 18 8 performance overhead may excessive 9 nonwork conserving processor scheduling scheme processor may block even lps mapped onto may messages process similar scheme also suggested connection artificial rollback protocol 19 18 sent back n highest send timestamped events chosen optimistic among future events thus expected bear greater chance incorrect others number future messages less n future messages sent back shall see later choice salvage parameter significantly affects time warp performance 43 georgia tech time warp system use georgia tech time warp gtwsm sm stands shared memory system evaluate performance cancelback protocol time warp 5 gtwsm system portable across shared memory multiprocessors ported bbn butterfly sequent symmetry sun sparc kendall square research ksrseries multiprocessors versions gtwsm system used study time warp university calgary canada university waikato new zealand saic washington dc experiments reported paper performed ksr1 processing node ksr1 twoway superscalar processor 25 mhz clock processing node cache processor caches connected highspeed slotted ring interconnect interconnect routes data among caches implement data sharing consistency invalidation based hardware cache coherence protocol implements shared virtual address space amongst processing nodes memory system architecture known allcache tm memory system physical main memory traditional sense architecture effect disk serves main memory thus architecture often referred coma cache memory architecture location system virtual address space reside possibly one cache cache coherence protocol ensures consistency respecting locality reference makes machine appear least approximately uniform memory access uma system application sufficient locality access certain advantage approximate uma behavior context cancelback protocol protocol requires use single shared pool memory objects thus object allocated lp irrespective physical location object even though object located remote cache time allocation object automatically brought local cache allocation accessed locally object deallocated returned free pool one interesting design choices gtwsm system use causality pointers implement antimessages message positive sent pointer left sending receive time sending lp receiving lp message data copy state causality record figure 2 structure memory buffer message new message essentially serves antimessage thus message cancellation entails traversing pointer annihilating appropriate rollback necessary message addition space saving saves message copying time match messages antimessages technique called direct cancellation 8 even though direct cancellation possible shared memory systems appropriate hashing technique devised distributed memory systems emulate causality pointers since causality structure system represented tree two pointers per event sufficient implement causality record use single logical shared free pool fixed number memory buffers memory buffer includes storage event message one copy state vector two pointers used implement causality record see figure 2 state saved processing event though gtwsm system support different state sizes different lps different message sizes ease experimentation analysis shall assume states messages size thus unit memory allocation single buffer constant size size may vary application includes necessary data specific kernel eg pointers implementing antimessages application eg message data state vector lp sends message another lp sending lp allocates one buffer fills data portion enqueues receiving queue destination processor state causality portions buffer filled message actually processed single shared free list may potential bottleneck memory allocations deallocations utilize single shared lock reduce contention processor maintains free pool processor fails fossil collect remaining free buffers system processors redistributed equally among processors number free buffers less number processors could happen severe memory limitation processors requested memory allocated buffers free buffer processor cancelback invoked note still logically shared free pool however scheme eliminates contention shared pool sufficient memory system application simulation program partitioned several logical processes lps execute events events readwrite lps state send events lps message send kernel allocates memory buffer shared pool application memory buffers deallocated returned shared free pool events cancelled fossil collected rollbacks normally nonpreemptive 10 however rollback induced cancelback made preemptive otherwise system deadlock operated memory constraints evaluation global predicates gvt computation choosing one suitable events cancelback implemented stopping processors using barrier synchronization locks efficient scalable barrier synchronization algorithm called tournament barrier used fast synchronization processors resume barrier computations completed global computation within pair barriers optimized much possible computation invoked system runs memory trying send event synchronizing barrier processors compute local virtual time lvt parallel taking account messages transit gvt computed minimum lvts processors try fossil collect parallel fossil collection fails reclaim storage one future events highest send timestamps canceled back accordingly corresponding source processes rolled back processors perform barrier synchronization complete global computation phase resume normal time warp operation 5 experimental results discussed memory consumed sequential simulation forms lower bound memory required time warp 11 thus experiments measure memory usage known nonpreemptive rollbacks cause deadlocks certain pathological situations eg incorrect event computation may enter infinite loop however avoid issue system favor simpler implementation 11 lower bound achieved practice assumed lp state saved processing pair consecutive events following fossil collected positive messages receive timestamp less gvt ii negative messages send timestamp less equal gvt iii copies state send timestamp time generation less gvt receive timestamp less equal gvt thus additional memory beyond seq memory required sequential execution additional memory must consumed future objects assuming past objects present antimessages immediately fossil collected thus evaluating performancememory tradeoff essentially evaluating performance time warp placing limit number future objects exist system note experimental testbed one type object memory buffer infrequent incremental state saving used 12 instructive note number future objects dependent degree optimism ie variations lvts time warp system optimism depends several factors physical parallelism execution system homogeneity behavior lps load balance amount asynchrony simulated system etc constructed set experiments synthetic workloads vary degree optimism different ways also report experiments real simulation models two different communication networks corroborate behavior observed synthetic workload experiments 51 symmetric phold workload phold workload originally described 10 parameterized synthetic workload model performance evaluation parallel simulation systems workload constant number messages called message population circulate among lps timestamp increments selected stochastic distribution messages equally likely forwarded lp lp mapped onto distinct processor computation grain per event selected exponential distribution mean 5 millisecond several experiments performed measure speedup message density defined message population divided number lps varied speedup measured relative performance sequential event list simulator event set implemented splay tree respect time warp simulations behavior similar simulations symmetric closed queueing networks experiments benchmark 8 lps used mapped onto one ksr1 processor message population 256 used gvt regulator lp fossil collect states sendtimes less gvt lps must copy state sendtime less gvt however special handling gvt regulator lp fossil collection may possible practice situation lower bound time warp memory usage sequential amount memory plus space hold one state object per lp additional space constant brevity shall ignore additional space discussions memory buffers unit memory allocation deallocation use techniques change total number objects use though may reduce size individual objects exec time sec additional memory buffers execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation salvage parameter exec time sec additional memory buffers execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation b salvage parameter figure 3 execution time profile two different salvage parameters phold model 8 processors performance time warp monitored obtain detailed accounting execution time processor spends time performing memory management activities including gvt computation fossil collection invocation cancelback necessary within barrier synchronization locks ii executing code time warp overheads rollbacks message cancellation message delivery etc iii busy waiting memory reclaimed enable progress 13 iv computing events performance results follow indicate time spent functions 511 varying amount memory figure 3a shows result first set experiments graphically demonstrates spacetime tradeoff time warp execution instance phold workload model amount time spent four activities mentioned earlier shown figure salvage parameter set 1 set experiments categorization execution time typical processor see start increasing memory minimum amount required sequential simulation execution time falls rapidly quickly stabilizes demonstrates time warp achieve much speedup four eight buffers per processor unlimited memory execution profile reveals memory management overheads high low amounts memory fall rapidly memory added low values system runs memory frequently time warp overheads also large low memory increase number rollbacks arising invocations cancelback cancellations however decline overheads increasing memory less dramatic memory management increasing memory system operates optimism cancelback rollbacks replaced straggler induced rollbacks busy wait time memory reduced amount memory increased computation time events almost independent memory also observe distinct knee execution time vs memory curve approximately additional memory equal 60 beyond improvement execution time minimal increased memory knee important characteristics performancememory curve 13 recall gvt regulator priority allocate memory reclaimed cancelback processes wait gvt regulator makes progress 512 effect salvage parameter figure 3b shows effect increasing value salvage parameter n figure shows execution profile n set 20 modest decrease total execution time increased value n nature profile respect event computation time busy wait time also different low amounts memory time spent event computations less time spent waiting memory computations execute forward rolled back via rollbacks due cancelback rather block waiting memory become available salvage parameter increased one interesting aspect curve increase subsequent reduction event computation time decreasing memory seen low values memory increase due rollbacks cancelback however subsequent reduction decrease effective value salvage parameter turn causes fewer rollbacks due cancelback effective value salvage parameter bounded number additional buffers available maximum number future events system thus additional memory falls specified value salvage parameter latters effective value becomes equal memory decreases memory reduced increased value memory 20 buffers efficiency still lower high salvage parameter marginal improvement memory management overhead reduces execution time small amount effect due less frequent calls fossil collectioncancelback figure 4 shows variation execution time salvage parameter memory fixed near knee execution time vs memory curve 40 memory buffers steady increase event processing time salvage parameter increasing number reexecution rolled back events however expected marginal drop idle time memory management overheads increases salvage value explains shape curve figure 4 curve shows exists optimal value salvage parameter maximizes performance given amount memory 513 effect message density physical parallelism conducted two sets experiments examine limited memory behavior problem size number processors change one set experiments message density varied keeping number processors fixed equal 8 number processors varied message density fixed equal 32 single lp per processor salvage parameter value fixed 1 see exec time sec salvage parameter execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation figure 4 execution time profile varying salvage parameter phold workload memory fixed 40 extra buffers1350 20 40 additional memory buffers figure 5 performance phold workload varying memory different message densities 8 processors additional memory buffers figure performance phold workload varying memory different number processors fixed message density 32 figures 5 6 respectively performancememory curves speedup shown instead absolute execution time increase message density without change timestamp increment behavior reduces rollbacks 14 however increases message density without change timestamp increment distribution physical parallelism affect rate forward computation events computed per unit real time rate event commitment events committed per unit real time thus increase message density increases number future events turn increases frequency fossil collectioncancelback invocations hence knee curve occurs progressively higher memory values figure 5 behavior also observed figure 6 number processors increased fixed message density processors generate larger number future events fact increases physical parallelism contribute pool future events directly proportionate increase increase message density set curves higher overheads per invocation fossil collectioncancelback larger number processors due longer barrier synchronization times also responsible shift knee towards larger amounts memory increasing number processors 14 rate progress simulator virtual time per unit real time becomes slower increase message density messages need processed make similar progress virtual time hand timestamp increment change newly generated messages tend fall increasingly virtual future destination lps thus reducing rollbacks additional memory buffers symmetric figure 7 speedup curves varying memory asymmetric phold workload symmetric speedup data shown comparison 52 asymmetric phold workload introducing asymmetry phold workload making processes faster changing event granularity increases average number future events faster processes become overly optimistic equivalent processors different speed time warp system simulation workload otherwise remains identical additional future messages however generated overoptimistically faster processors would eventually rolled back thus knee performance memory curve expected occur position regardless asymmetry figure 7 shows speedup data phold workload symmetric asymmetric cases message population 256 8 processors two asymmetric cases shown half processors 20 slower rest asymmetric 12 ii half processors twice asymmetric 20 slow rest data correspond salvage value 1 figure 7 demonstrates three curves knees approximately memory value two asymmetric curves knee marginally shifted towards right higher memory management overheads cancelback needs called frequently overly optimistic behavior set curves demonstrate number future events unlimited memory execution sole determinant limited memory performance asymmetric models average number future events larger many especially larger virtual timestamp incorrect liable retracted degrade performance limiting number cancelback thus symmetric asymmetric phold workloads behave similarly compared corresponding unlimited memory execution except higher memory management overheads asymmetric workloads observe achieve good performance sufficient provide enough extra space sequential memory requirement hold correct future events future events may eliminated cancelback without affecting performance however relying hypothesis events larger timestamps higher probability incorrect 53 asymmetry arbitrary flow network model model based simulation power distribution grid model source nodes generate events receive nodes sink nodes receive events send application nodes model actual network simulated node modeled lp application nodes communicate sending timestamped messages two types propagating nonpropagating messages processing propagating message results one additional messages sent lp messages sent lps based communication probability matrix nonpropagating messages intended model data transfers result additional communication new messages generated one propagating rest nonpropagating propagating message processed timestamp increment computed based probability distribution addition granularity event computed based another probability distribution number source sink application nodes communication probability matrix timestamp increment granularity distribution node parameters model model used 22 evaluating performance probabilistic synchronization scheme conjunction time warp chosen instance model one source one sink eight application nodes granularity events normally distributed mean 10ms per event eight application nodes six fast rest slow fast nodes send messages average timestamp increment 100 slow nodes send messages average timestamp increment 1 timestamp increments exponentially distributed fast slow node exec time sec additional memory buffers execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation salvage parameter 12006001000 exec time sec additional memory buffers execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation b salvage parameter 202006001000 exec time sec additional memory buffers execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation c salvage parameter 100 figure 8 execution time profile three different salvage parameters arbitrary flow network model 10 processors probability communicating group 02 probability communicating group parameters provide significant amount asymmetry simulation model 15 number unprocessed messages system continuously grows progress simulation existence unthrottled source lp continues generate messages lps never rolls back time warp system provide finite amount memory simulation cancelback protocol needs invoked memory management whenever system runs memory cancelback automatically reclaims memory undoing computations high timestamps thus making room creating memory lower timestamped computations progress vary events set sizes different lps simply varying amount memory measured terms number event buffers available simulation arbitrary flow network model provides challenging test case experimenting limited memory behavior time warp source process never rolls back quickly consumes available memory even though processes remain far behind virtual time 22 observed time warp without throttling cannot simulate model real machine memory requirements unbounded without flow control mechanism figure 8 shows execution profiles workload 10 processors different values salvage parameter unthrottled nature source process severe asymmetry system model large number future events generated need rolled back cancelback ensure limited memory execution workload puts pressure memory management system compared previous workloads thus knee performance memory curve occurs somewhat larger memory value compared phold salvage parameter values initial decrease continues memory value approximately 300 extra buffers reached easy see dominant portion execution time goes memory management overheads especially small memory low salvage parameter one interesting aspect set curves large amount memory modest rise execution time attributed severe loss locality program using large amount memory results cache misses 15 asymmetry controlled varying number slow fast processors timestamp increments communication probabilities chosen parameters data presented representatives asymmetric behavior exec time sec salvage parameter execution time breakdown shown following order top bottom memory management overhead tw overhead busy wait memory event computation figure 9 effect varying salvage parameter constant amount memory arbitrary flow network additional memory 600 buffers frequent need page allocation servicing cache misses 16 however behavior specific ksr architecture reduced using certain buffer management techniques improve locality reference transparent application program 24 let us examine execution time varies salvage parameter setting figure 8 see execution time improves significant amount salvage parameter increased low value 1 moderate value 20 large average fanout events model largely responsible behavior salvage parameter 1 cancelback reclaims memory one buffer time gvt regulator needs send k events k 1 fossil collection cancelback invoked k sends hand salvage parameter set value larger maximum fanout worst case one cancelback invocation per event necessary thus workload see faster improvement memory management overhead little effect efficiency increase salvage parameter see figure 9 behavior different paging disk ksrs cache protocol valid cache block exist local cache corresponding page also exist cache cache blocks page need valid state page exist cache needs allocated less locality program cache block miss greater probability seeing corresponding page miss subsequent page allocation speed eventssec memory homo 14 hot 18 hot figure 10 performancememory curve hypercube network without hotspots 6 experiments benchmark simulation applications though many real simulations properties exhibited synthetic workloads described set benchmark applications studied validate behaviors observed synthetic workloads two benchmarks selected simulations store forward communication network hypercube configuration without hotspot traffic ii personal communication service pcs network simulating mobile communication system benchmarks properties observed many real simulation models large number simulation objects modeled lps large event population possibly time varying ii small grain computation often 100s per event less ksr1 61 store forward communication network simulation network configured hypercube fixed size message population network messages routed randomly selected destination nodes using ecube routing algorithm 13 message lengths selected uniform distribution transmission time proportional message length assumed two unidirectional links one direction neighboring nodes hypercube addition transmission latency may queueing delays links one message transmitted link one time queuing fcfs infinite buffer capacity assumed simulation model message reached destination node another destination picked random message reinserted network simulation model network queueing server associated link service time server equivalent message transmission latency simulation model service times precomputed messages forwarded immediately next server suggested 23 improves lookahead hence performance one set experiments destination nodes selected using uniform distribution two sets experiments hot spots introduced nodes within designated subcube 50 probability destination nodes introduction hotspots increases rollbacks load imbalance time warp system reported set experiments 128 lps 128 node hypercube used 8 processors message population 2048 see figure 10 salvage parameter value 100 chosen note message population plus one memory required sequential simulation forms lower bound memory required time warp better locality communication subcubes hypercube mapped onto individual processors three different experiments performed first set experiments message destinations chosen random using uniform distribution second third 14th 18th nodes chosen hotspots 50 message traffic directed towards note severe hotspots load imbalance hence rollbacks also progress simulation controlled hotspot nodes accounts loss simulation speed concentrated hotspots note knee occurs approximately memory value irrespective hotspot though hotspot reduces number correct future messages simulation cancelback force simulation execute smaller amount memory without loss performance increases memory management overheads due overoptimism thus requiring memory equivalent performance balancing effect two opposite forces places knee value three curves 62 pcs network simulation pcs personal communication services network wireless communication network provides communication services mobile units simulation model service area network partitioned checkerboardlike subareas cells simulation model consists cells portables portables model mobile units cell represents cellular 0speed eventssec memory figure performancememory curve pcs network different numbers processors ceivertransmitter fixed number channels allocated portable represents mobile phone unit resides within cell period time moves one four neighboring cells behavior portable modeled different types events portable move call arrival call completion detailed description application presented 3 pcs model views portable receiver calls concerned originator call new call arrives cell cell first determines status destination portable destination portable busy another call call counts busy line portable busy cell determines channel availability channels busy call counted block channel available allocated destination portables use call allowed connect portable moves another cell call progress handoff takes place ie channel currently use released new channel must allocated cell entering channels available call dropped cut simulation used extensively engineer pcs systems call blocking dropping probabilities small cell modeled lp lp also models behavior portables presently grid cell one interesting aspect pcs simulation model selfinitiating behavior lps ie lp often sends messages advance simulation time pcs model portables generate incoming calls imparts selfinitiating behavior lps 3 another interesting aspect pcs model high degree locality normally large number grid cells simulation modeled many lps since neighboring lps mapped onto single processor much local communication remote messages selfinitiating behavior coupled remote communications makes simulation extremely asynchronous thus possibility overoptimistic behavior gives rise large memory usage without form throttling however rollbacks thus great majority future events correct figure 11 shows performancememory curves pcs network model 8 16 processors ksr1 salvage parameter set 100 problem size proportional number processors set experiments 16 lps modeling grid cells per processor used note increase problem size proportionately increases sequential amount memory lower bound time warp memory increasing number processors scaled problem size increases size future message set proportion proportionately increases number additional memory buffers knee little memory detrimental performance primarily two reasons high memory management overheads ii loss physical parallelism lack adequate memory force final execution many simulation events timestamp order rather parallel timestamp order 17 loss parallelism represented performance curves larger event execution time cancellations correct events rollbacks followed reexecutions corresponding sender events b busy wait time memory allow gvt regulator progress force final committed event executions happen timestamp order sequential execution experimental results give us certain insights limited memory behavior time warp described 17 note often executing two events outoftimestamp order efficient executing timestamp order even though either case processed sequentially events may generated outoftimestamp order generated may cpu cycles immediately available process 71 knee performancememory curve performance data collected study indicate welldefined knee performancememory curve regardless symmetry model system architecture physical model parallelism problem size intuitive reason follows suppose amount memory increased seq k extra buffers k future events generated event fanout k allows one event gvt event complete processing optimistically become candidate commitment memory close seq much optimism system thus rollbacks unlikely additional k events one event potentially complete execution different processor commit thus memory increased steps k buffers step one additional processor become busy useful work means parallelism ii one event potentially fossil collected fossil collection invocation means less cancelbacks less overheads thus performance increases rapidly additional buffers however soon point reached processors become busy fossil collection invocations able collect sufficient number fossils system runs memory infrequently knee point beyond point performance almost independent amount memory knee performancememory curve good operating point time warp rise performance beyond knee value marginal possibility performance decrease larger values memory lack locality observed arbitrary flow workload experiments indicate two major factors determine location knee 1 size future event pool size future event pool affected following rates rate generation new messages ii rate message cancellations iii rate event commitment responsible growth future event pool ii iii responsible shrinkage given amount memory size determines frequency fossil collectioncancelback calls thus controls memory management overheads event grain small memory management overheads may dominate execution time limited memory pushes knee towards large memory values note experimental data change location knee consistent change event granularity communication network simulators grain size order magnitude smaller synthetic workloads former knees located within 150 buffers per processor compared within 15 latter 2 number correct future events source events critical path simulation computation salvaging storage occupied future events rollback one source uncommitted events future events correct events source events recomputed regenerate events source events critical path parallel computation recomputation critical path slow progress simula tion hand rolling back ie incorrect correct critical path uncommitted events cancelback little effect performance thus case logical processes systematically ahead virtual time others asymmetry marginally affect location knee seen phold asymmetry processor speed hypercube asymmetry simulation model examples exact location knee cannot however predicted statically without knowledge applications behavior also location shift dynamically change simulation model runtime however possible predict approximate location knee observing behavior time warp runtime rate generation new events rate rollbacks rate progress gvt monitored predict size future event pool initial ideas regarding accomplished found 6 72 effect salvage parameter experimental data suggests optimal value salvage parameter small value causes cancelback called often causing poor performance due associated overheads large value may cause correct computation critical path rolled back thus affecting performance suggests optimal value somewhere explanation see profile figure 3a event grain becomes smaller lower portion profile event computation time smaller without affecting part profile increase fractional change total execution time per unit change memory thus fractional change memory required 1 amount surplus memory amount available minus amount needed run sequential simulation latter term upper bound salvage parameter larger values affect performance also observed performance relatively insensitive actual value parameter away two extremes indicates may crucial determine exact optimal value practice currently general method choosing appropriate value salvage parameter given simulation application depends runtime characteristics application cannot predicted statically however adaptive mechanism selecting salvage value automatically devised studying many events canceled cancelback actually regenerated 6 fewer events indicate increase salvage value possibly harmless detailed description adaptive mechanism beyond scope paper however sake completeness mention ground rules help selecting reasonable value parameter statically certain information application behavior known optimal value salvage parameter generally increases smaller event grain overheads become proportionately larger ii larger available memory optimism system may critical performance iii overoptimism workload may lps operating much higher virtual time others rolled back free memory without affecting performance ground rules help experimenter choose good static value parameter 73 memory control effective throttling mechanism limited memory execution cancelback viewed throttling scheme artificially limits optimism execution time warp programs amount throttling depends number future objects generated turn depends amount available memory throttling schemes suggested literature different controls eg width time window window based schemes 21 27 28 29 resynchronization intervals probabilistic synchronization 22 bound value bounded time warp algorithm among others developed primarily limit amount rolled back computation time warp however controls used mechanisms limit optimism indirect relationship amount optimism provided system hence may difficult choose appropriate values example optimal size time window optimal bound value depends density events virtual time depends timestamps events simulation application readily clear users particularly intimately familiar details underlying simulation protocol set control particular application similarly without elaborate experimentation knowledge application impossible set appropriate resynchronization interval hand amount memory provided time warp system straightforward throttling mechanism overoptimistic execution study adaptive memory control mechanism based principle presented elsewhere 6 concluding remarks cancelback protocol used empirical evaluation performance time warp programs amount memory allocated program limited predetermined value efficient implementation cancelback protocol nontrivial real architecture instantaneous message send assumption ii high cost necessary memory management related computations gvt computation fossil collection selection messages canceled back developed reasonably efficient solutions problems summarized nonatomic message delivery may cause starvation additional synchronization required eliminate possibility efficient synchronizing scheme always gives priority process furthest behind virtual time allocating memory proposed implemented ii reduce frequency cancelback calls expensive cancelback protocol parameterized salvage parameter indicates number future events canceled invocation cancelback different simulation models different degrees asymmetry used evaluate performance vs memory tradeoff across workloads used study experimental data indicate performancememory curve always welldefined knee performance drops rapidly reduction amount memory beyond significant improvement performance increases amount memory performance decrease small amounts memory attributed large memory management overheads ii loss physical parallelism due excessive throttling observed large memory may also lead poor performance due poor locality reference virtual memory system thus amount memory beyond knee good operating point time warp programs value salvage parameter also affects performance observed intermediate value salvage parameter usually best small value increases memory management overheads large value may cause correct events critical path computation rolled back cancelback performance relatively insensitive salvage value long set away two extreme values location knee appropriate value salvage parameter properties application program dependent event granularity physical parallelism overoptimism time warp system latter depends many factors including load balance behavior simulation model large grain simulations least milliseconds per events cancelback appropriately chosen value salvage parameter good performance even modest amount memory synthetic simulation workloads considered performance found within 10 maximum possible performance amount memory 15 fewer additional message buffers per processor however many real simulations much less computation within event thus memory management overheads may dominate number additional buffers required similarly good performance also increases proportionately thus conclusion possible derive good performance time warp execution modest amount additional memory compared amount required sequential execution however requires computation global predicates eg gvt selection events cancelback takes little time compared average event granularity acknowledgment acknowledge encouragement professor ian akyildiz initial phase work discussions helpful christopher carothers developed pcs simulation program gtw r effect memory capacity time warp performance distributed simulation large scale pcs networks cost state saving rollback gtw time warp system shared memory multiprocessors adaptive memory management protocol time warp parallel simulation comparative analysis periodic state saving techniques time warp simulators time warp shared memory multiprocessor virtual time machine performance time warp synthetic workloads rollback mechanisms optimistic distributed simulation systems advanced computer architecture parallelism virtual time virtual time ii cancelback protocol storage management distributed simulation distributed simulation time warp operating system time warp mechanism database concurrency control memory management algorithms optimistic parallel simulation optimal memory management time warp parallel simulation selecting checkpoint interval time warp simulation rollback sometimes works mimdix operating system parallel simulation supercomputing parallel discreteevent simulation fcfs stochastic queueing networks buffer management shared memory time warp systems memory management techniques time warp distributed memory machine benchmarking time warp operating system computer network simulation limitation optimism time warp operating system mtw strategy scheduling discrete simulation events concurrent execution mtw experimental results constrained optimistic scheduling paradigm performance evaluation bounded time warp algorithm tr ctr hironori hibino yoshiyuki yura yoshiro fukuda keiji mitsuyuki kiyoshi kaneda manufacturing modeling architectures manufacturing adapter distributed simulation systems using hla proceedings 34th conference winter simulation exploring new frontiers december 0811 2002 san diego california francesco quaglia andrea santoro nonblocking checkpointing optimistic parallel simulation description implementation ieee transactions parallel distributed systems v14 n6 p593610 june francesco quaglia vittorio cortellessa processor scheduling problem time warp synchronization acm transactions modeling computer simulation tomacs v12 n3 p143175 july 2002 kevin jones samir r das combining optimism limiting schemes time warp based parallel simulations proceedings 30th conference winter simulation p499506 december 1316 1998 washington dc united states samir r das richard fujimoto adaptive memory management optimism control time warp acm transactions modeling computer simulation tomacs v7 n2 p239271 april 1997 yarong tang kalyan perumalla richard fujimoto homa karimabadi jonathan driscoll yuri omelchenko optimistic parallel discrete event simulations physical systems using reverse computation proceedings 19th workshop principles advanced distributed simulation p2635 june 0103 2005 yarong tang kalyan perumalla richard fujimoto homa karimabadi jonathan driscoll yuri omelchenko optimistic simulations physical systems using reverse computation simulation v82 n1 p6173 january 2006