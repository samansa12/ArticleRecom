high performance presenceaccelerated ray casting present novel presence acceleration volumetric ray casting highly accurate estimation object presence obtained projecting grid cells associated object boundary image plane memory space access time reduced runlength encoding boundary cells boundary cell projection time reduced exploiting projection templates multiresolution volumes efforts also made towards fast perspective projection well interactive classification present task partitioning schemes effective parallelization boundary cell projection ray traversal procedures good load balancing reached taking full advantage optimizations serial rendering algorithm sharedmemory architecture experimental results 16processor sgi power challenge shown interactive rendering rates 2563 volumetric data sets paper describes theory implementation algorithm shows superiority shearwarp factorization approach b introduction effective approach achieve high frame rates volume rendering parallelize fast rendering algorithm relies algorithmic optimizations 1 2 3 4 two requirements must met approach achieve interactive rendering first serial volume rendering algorithm must fast enough second parallel version serial algorithm must scale well number processors increases many parallel volume rendering algorithms developed optimizing serial volume renderers among efficient ones lacroutes 3 realtime parallel volume rendering algorithm multiprocessor sgi challenge using shearwarp factorization 5 could render 256 3 volume data set hz dynamic task stealing scheme borrowed 1 load balancing parker et al 4 proposed another interactive parallel ray casting algorithm sgi workstations using 128 pro cessors algorithm rendered 1gbyte full resolution visible woman data set 10 hz one optimizations ray casting using multilevel spatial hierarchy space leaping paper explore effective parallelization boundary cellbased ray casting acceleration algorithm multipro cessors serial algorithm derived acceleration technique boundingboxes technique consists three steps emailbrysonnasnasagov first object surrounded tightly fit boxes easy tointersect geometric primitives spheres intersection rays bounding object calculated finally actual volume traversal along ray commencesfrom first intersection point opposed starting volume bound ary unlike kinds presence acceleration techniques traverse hierarchical data structure octrees 4 6 k trees 7 skip empty regions approach directly hence quickly traverses original regular grid obviously effectiveness boundingboxes approach depends ability accurately calculate intersection distance viable ray minimal computational overhead fore previously proposed boundarycell based ray casting method 8 accurately detected object boundary grid cell volumetric data set cell volume contained within rectangular box bounded eight neighboring grid vertices voxels distance information object boundary image plane obtained projecting boundary cells cells pierced object boundary onto image plane projection procedure accelerated exploiting coherence adjacent cells employing generic projection template experimental results showed projection time faster parc polygon assisted ray casting algorithm 9 accelerated graphics hardware however previously proposed method 8 limi tations first effective small volume data less 128 3 voxels second supported fast ray casting parallel projection paper present improved version solve problems propose runlength encode detected boundary cells data compression reduces memory space access time multiresolution volumes exploited reduce number boundary cells method capable rendering larger volumes interactive rates efforts also made towards fast perspective projection well interactive classification based improved serial rendering algorithm developed parallel rendering algorithm using effective task partitioning schemes boundary cell projection subsequent ray traversal procedures good load balancing reached taking full advantage optimizations rendering algorithm sharedmemory architecture parallel algorithm implemented silicon graphics power challenge busbased sharedmemory mimd multiple instruction multiple data machine processors rendering rates 256 3 volumetric data sets fast among fastest reported detailed comparison algorithm shearwarp factorization approach 3 given section 5 difficult compare performances method 4 since former used much larger data set eight times processors yet two methods similarities essentially ray casting algorithms running multiprocessors interested object boundary one significant difference lies method could display boundary surface object also visualize interior structures translucency description serial algorithm parallel version given sections 2 3 respectively performance results reported section 4 2 serial algorithm serial rendering algorithm completed three steps 1 runlength encode boundary cells preprocessing stage 2 project runlength encoded boundary cells onto image plane produce intersection distance values pixel 3 viable ray intersects object volume start sam pling shading compositing intersection discussion support interactive volume classification renderings given end section 21 boundary cell encoding since boundary cell information viewpointindependent obtain scanning volume offline preprocessing stage essentially scanlinebased runlength encoding scheme exploits 1d spatial coherence exists along selected axis direction 10 gives kn 2 compressed representation data n 3 grid factor k mean number runs run maximal set adjacent voxels property scalar field value associated classified material see section 24 interactive classification obviously k low scheme efficient tunately true classified volume volume opacity transfer function applied 5 use scheme encode boundary cells volume algorithm run maximal set adjacent boundary cells grid cell scanline aligned selected axis x axis selected runlength encoding paper specific data structure use runlength encoding boundary cells includes linear run list l 2d table see figure 1 list l contains runs boundary cells element lt l represents run including location first boundary cell ci j k run run length position cell ci j k determined one eight voxels lowest xy z coordinate value accordingly cell ci j ith cell scanline j k table records distribution information boundary cells among volume scanlines element j k holds number boundary cells located scanline j k according information table list l quickly skip empty scanlines empty runs order reach high data compression suggest first run list l x coordinate starting cell needs stored lt instead three coordinates easily infer two coordinates second boundary cells 6 faceconnected boundary cells ignored nonboundary cells data structure contribution object boundary estimation third table also runlength encoded run maximal set adjacent elements number space complexity runlength encoding data structure sum space complexities list l table k mean number runs per scanline two fields needed element lt one j k fields scanline j cell jk list l0 t1 m1 z table boundary cell nonboundary cell figure 1 data structure runlength encoding boundary cells represented integer numbers 4 bytes sgi work stations 1 byte character n 256 fore equation 1 written 22 boundary cell projection skipping runs nonboundary cells runlength encoding scheme provides high data compression also leads fast 3d scan volume boundary cell projection procedure parallel perspective projections supported algorithm 221 parallel projection parallel projection projected area every cell shape size image plane projected position distance cell center image plane different cell cell based projection property employ generic projection template speed boundary cell projection establish projection template algorithm generic projection template size bounding box projected area cell image plane element template templatepixel two respective components recording near far distances calculate distance values template first choose arbitrary cell volume place center template center point cell ensure template parallel image plane also aligned primary axes image plane origin defined center template three different levelsofaccuracy templates selected algorithm low levelofaccuracy template far distance value templatepixel distance farthest voxel cell template near distance value templatepixel middle levelofaccuracy template distance values templatepixels covered projected cell set infinity remaining templatepixels values low level template high levelofaccuracy template near far distance values templatepixels accurately calculated scanconverting front facing back facing surfaces cell obviously different levelofaccuracy templates provide different accuracy distance information note high resolution volume data set cells small densely overlapped viewing direction therefore rough approximation based low levelofaccuracy template often good enough support efficient skipping empty space evidenced experimental results determine projection position parallel projection first cell c0 0 0 projected onto image plane position remaining cells quickly calculated incremental vectors addition operations specifically assume center point first cell c0 0 projected position x0 y0 image plane depth z0 deltax deltay deltaz respectively vector directions volume axis xyz image space volume size nx theta ny theta nz unit spacing voxels position x1 y1 depth z1 center point cells adjacent cell c0 0 along volume axes xyz respectively calculated following equations runlength encoding used algorithm relationship two adjacent boundary cells list l compli cated two adjacent cells could located run two adjacent runs scanline two runs different scanlines assume projection information two adjacent boundary cells c c i1 respectively x x two cells located run x found x single vector addition operation using equation 3 otherwise c c i1 located different runs scanline x calculated x two vector addition operations one vector multiplication operation case cell c i1 located new scanline slice new slice projection information similarly calculated first cell previous scanline slice respectively using equations 4 5 using incremental method timeconsuming 4 theta 4 matrix multiplications projection applied solely cell rather boundary cells thus projection procedure greatly accelerated fill projection buffer utilize two projection buffers zn zf size resultant image respectively record nearest farthest intersection distances object boundary along rays cast image pixels projected position boundary cell determined specific projection template m1 cell quickly generated adding distance cell center image plane near far distance values viable element template manner straightforward using current template m1 update distance values two projection buffers first place template m1 image plane center templatepixel image position cell center projected imagepixel covered template compare nearest farthest intersection distances ie zn zf corresponding bufferpixels noninfinity near far distances ie dn df corresponding element template m1 specifically zn greater dn zn replaced dn near zbuffer meanwhile zf less df zf replaced df far zbuffer situation center point cell exactly projected image pixel one image pixel covered template may surrounded two four templatepixels thus nearest distance dn farthest distance df surrounding templatepixels taken give conservative distance estimation 222 perspective projection perspective projection particular importance viewing point getting close data located inside volume interactive navigation inside human colon 3d virtual colonoscopy 11 implemented perspective projection procedure algorithm similar parallel projection still adopt projection templates fast projection however since different cells different perspective projection shapes sizes due different distances directions view point generic projection template cells furthermore incremental method finding projection information adjacent boundary cell work perspective projection cells aligned volume axis longer fixed spacing screen implementation low levelofaccuracy template turned competitive candidate among three low template essentially degenerated template including height width near far distances projected boundary cell whenever one cell cover many screen pixels object boundary estimation based low templates satisfactory perspective projection template specific boundary cell quickly generated done projecting eight vertices cell onto image plane find bounding box projected area cell well minimal maximal distances screen template directly used update near far projection buffers furthermore since four vertices shared two adjacent boundary cells run projection information four shared vertices one boundary cell reused neighboring boundary cell speedup result although perspective projection involves computation parallel projection still done rapidly specifics projection time experiments various data sets reported section 4 23 ray traversal depending intersection distance information projection buffers zn zf ray casting procedure accelerated casting rays viable pixels image plane traversing ray closest depth farthest depth effective ray casting optimizations adaptive image sampling 12 early ray termination 6 conveniently incorporated speedup ray traversal procedure example employing early ray termination traversal along viable ray stops farthest intersection reached accumulated opacity reached unit exceeded userselected threshold opacity ray traversal procedure algorithm often rapidly completed overall complexity ray casting algorithm greatly reduced assume volume size n 3 image size n 2 generate ray casting image parallel projection rendering complexity bruteforce ray caster would 3 algorithm rendering complexity reduced okn 2 although value k data dependent often quite small compared n especially early ray termination employed unless substantial fraction classified volume low nontransparent opacity note however classification functions considered less useful 5 fact accelerated ray traversal speed sometimes becomes fast may approach boundary cell projection speed especially larger data sets happens pleased reduce projection time decreasing resolution boundary cells since accuracy current object boundary estimation unnecessarily high one solution reduce volume resolution merging 3 neighboring cells macrocell cells macrocell nonboundary cells macrocell nonboundary macrocell otherwise boundary macrocell experiment 256 theta 256 theta 124 mri data set human brain even merging eight neighboring cells original volume leads threefold decrease cell projection time nearly ray traversal time another approach use lower levelsofdetail lod volume fast object boundary estimation use original high resolution volume accurate ray traversal approach may produce accurate estimation especially selected value large yet user make sure object represented lower lod volume thinner original size guaranteed either modeling algorithm lod adjusting projection templates 24 interactive classification practical application user may want change opacity transfer function renderings exploring new data set existing algorithms employ spatial data structures require expensive preprocessing step transfer function changes therefore support interactive volume classifi cation although algorithm presented thus far works classified volume fixed transfer function easily support interactive classification minor constraint modification transfer function algorithm define opacity threshold transfer function minimal scalar field value volumetric data set associated nonzero opacity opacity threshold given transfer function boundary cells determined eight vertices possess field values less opacity threshold transfer function changes previous runlength encoding boundary cells based previous opacity threshold may appropriate data structure new object yet note increase opacity threshold shrinks object volume coverage object higher opacity threshold always enclosed object lower opacity threshold consequently runlength encoding object boundary low opacity threshold used overestimate another object boundary higher opacity threshold follows start object lowest opacity threshold create runlength encoding boundary cells according opacity threshold avoid repeating preprocessing step boundary cell detection runlength en coding opacity transfer function changesbetween render ings always using runlength encoding data structure overestimate new object boundary specified modified transfer function higher opacity threshold although correctly render images interactively classified volume rendering rates may slow greatly radical changesof transfer function two reasons first number boundary cells fixed runlength encoding data structure larger shrunken object specified higher opacity threshold may lead longer projection time sec ond overestimation shrunken object boundary may cause longer ray traversal time due unnecessary samplings outside shrunken object fortunately typical classified volume 70 gamma 95 voxels transparent 7 5 know total number boundary cells object small compared volume size projection time boundary cells shortened employing runlength encoding templateassisted projection accordingly difference projection time different objects often minor also since possible objects crowded small part volume boundaries objects often close overestimation cause much extra ray traversal time brief algorithm allows interactive classification moderate performance penalty experimental results different data sets interactive classification fixed preclassification given section 4 3 parallel algorithm general two types task partitionings parallel volume rendering algorithms objectbased 2 imagebased partitionings 1 3 4 respectively working volume image domains order take full advantage optimizations serial algorithm designed objectbased task partitioning scheme boundary cell projection imagebased partitioning scheme ray traversal procedure sharedmemory architecture sgi power challenge fully supports implementation parallel algorithm 31 objectbased partitioning boundary cell projection achieve high processor utilization boundary cell projection procedure volume carefully divided assigned processors processor possesses subset volume equal number boundary cells based runlength encoding data structure able precisely divide volume subvolumes contiguous grid cells containing roughly equal number boundary cells convenience implementation used run instead cell fundamental unit work compared options static interleaved partitionings dynamic partitionings static contiguous partitioning several advantages maximizes spatial locality runlength encoding data structure therefore minimizes memory stall time caused cache misses addi tion static scheme less synchronization required task redistribution overhead also avoided volume distributed available processors processor works concurrently independently subvolume scanning projecting related boundary cells onto image plane since image plane shared processors processor establishes separate pair near far projection buffers size resultant image order avoid memory access conflict processor finishes work supplies pair partial projection buffers within span time complete unified projection buffers whole volume obtained combining partial projection buffers combination procedure also parallelized dividing partial projection buffer subbuffers equal number contiguous buffer scanlines one subbuffer per processor processor respectively combines near far subbuffers assigned forming pair complete subbuffers end process obtain pair complete projection buffers zn zf since comparison assignment operations performed process fast computation overhead combination algorithm low evidently another solution avoid memory access conflict without creating combining pair partial projection buffers processors simultaneously access shared projection buffers zn zf parallelized projection procedure exclusive mode although implementation simpler buffer access time may slightly increase due exclusive access mode 32 imagebased partitioning ray traversal algorithm projection buffers provide closer bounds intervals ray integrals need calcu lated also viewdependent information image complexity static imagebased contiguous partitioning therefore natural choice note amount computation involved specific image section calculated following formula number viable pixels image section length bounded ray interval associated ith viable pixel g function length value gd depends length transparency property object rendered generally speaking transparent object greater value larger value gd value adjusted rendering suitable object according load balancing feedback function g equation 7 determined image divided large image blocks contiguous image scanlines block contains roughly equal amount work see figure 2 fundamental unit work algorithm image pixel rather image scanline supports accurate partitioning hence better load balancing processor takes one image block casts rays viable pixels block performs ray integrals within bounded interval along ray parallel ray traversal procedure accelerated existing ray casting optimizations fall two classes according whether computational dependenciesbetween rays non raydependent optimizations early ray ter mination directly applied imagebased partitioning however incorporating adaptive image sampling belongs raydependent class caution must taken avoid cost replicated ray casting pixels shared different processors serial ray casting algorithm adaptive image sampling optimization 12 performed dividing image plane fixed size square image tiles theta pixels casting rays four corner pixels tile additional rays cast image tiles high image complexity measured color difference corner pixels image tiles non raycasting pixels bilinearly interpolated raycasting pixels nieh levoy 1 proposed dynamic imagebased partitioning scheme reduces cost associated pixel sharing delaying evaluation image tiles whose pixel values computed processors paper propose effective solution based static imagebased contiguous partitioning compared previous dynamic image partitioning scheme 1 method task redistribution overhead thus fewer synchronization quirements method described follows 1 small fixed size square image tile theta pixels defined fundamental unit work 2 p processors image split p large image blocks contiguous scanlines tiles block may contain number tiles contains roughly equal amount work 3 processor takes one image block performs adaptive image sampling tile block top scanline order note shared pixels bottom image block processor directly gets values shared memory computed processors regular tile bottom tile top tile image tile pixels x figure 2 static imagebased contiguous partitioning example figure 2 illustrates fourprocessor example image partitioned algorithm fundamental unit work becomes square image tile square image tiles contain shared pixels different processors marked dark shad ing gathered top bottom image block therefore tiles image block classified regular tiles white tiles figure top tiles tiles dark shading bottom tiles light shading parallel algorithm processor p starts work top tiles image tile scanline order top regular tiles normal adaptive image sampling performed however bottom tile read values directly shared mem ory therefore replicated ray casting interpolation operations shared pixels avoided evidently algorithm works based premise processor approximately equal amount work guarantee test computation shared pixels missed processors set alarm signal shared pixel top tiles initial values 1 shared pixel evaluated signal set 0 processor reaches shared pixel value 1 bottom tiles alarm sounds notify user stop rendering experimental results shown algorithm works well alarm sounded far possible processors used day hear alarm happens would like employ dynamic task stealing based contiguous image partitioning scheme dynamic scheme would produce better load balancing also increase synchronization overhead implementation complexity realize however processors available trend render much larger volume data sets larger images number processors would still significantly lower number pixels thus algorithm would remain competitive 4 experimental results algorithm implemented sgi power challenge processors performance results classified volume data sets given table 1 2 brain data set table 1 256 theta 256 theta 124 mri scan human brain figure 3 head data set table 2 256 theta 256 theta 225 ct scan human head figure 4 rendering times include boundary cell projection time subsequent ray traversal time offline preprocessing time boundary cell detection runlength encoding preprocessing times respectively 99 seconds 183 secondson single processor two data sets would like point projection procedure parallelized multiprocessor extra time needed combine partial buffers generated different processors however experiments shown combination times buffer size negligible less minimum measurable time 001 seconds preprocessing stage merged every eight neighboring grid cells one macrocell reduce amount boundary cells boundary cell projection procedure used low levelofaccuracy projection templates runlength encoding data structure parallel perspective projections subsequent ray traversal procedure performed resampling using trilinear interpolation shading using phong model one light source compositing within bounded ray interval original volume data resultant images contain 256 theta 256 pixels selected earlyraytermination opacity cutoff 95 ray traversal time adaptive nonadaptive normal image sampling measured adaptive image sampling used square image tiles 3 theta 3 pixels along minimum color difference 25 measured euclidean distance rgb 256 theta 256 theta 256 space fastest rendering rates data sets 20 hz among fastest reported table 1 volume rendering times sec 256 theta 256 theta 124 mri brain data set processors parallel projection 016 004 002 001 001 perspective projection 049 012 006 004 003 nonadaptive traversal 132 034 017 012 009 adaptive ray traversal 053 014 007 005 003 best frame rate hz 14 55 111 166 250 table 2 volume rendering times sec 256 theta 256 theta 225 ct head data set processors parallel projection 020 005 002 001 001 perspective projection 086 022 011 007 005 nonadaptive traversal 051 014 007 005 004 adaptive ray traversal 027 007 004 003 002 best frame rate hz 21 83 166 250 333 experimental results shown perspective boundary cell projection times three five times longer parallel boundary cell projection times depending number boundary cells projected however subsequent ray traversal times perspective parallel views volumetric object close projected object similar sizes projection plane therefore resultant perspective rendering times including projection ray traversal times less three times longer corresponding parallel rendering times figure 5 shows speedup curves nonadaptive adaptive renderings including boundary cell projection time mri brain data set parallel projection speedup results ct head data set similar two observations speedup curves first parallel program scales well multiprocessor near linear speedups ascribed effective contiguous object imagebased partitioning schemes lead spatial locality good load balancing boundary cell projection procedure computation work assigned processor subvolume contiguous runlength encoded scanlines boundary cells therefore provides good spatial lo cality good spatial locality effectively make use prefetching effect long cache lines challenge helps mask latency main memory accesses fact two medical data sets tables 1 2 significant coher ence opacity transfer functions used 31 32 grid cells mri ct data sets boundary cells ac cordingly runlength encodings boundary cells small compared original volume short runlength encodings split assigned multiprocessors easily fixed inside local caches processors minimal cache misses evidently ray traversal procedure also benefits spatial locality provided contiguous imagebased par titioning since adjacent rays access data cache line number processors nonadaptive rendering adaptive rendering figure 5 speedupsof rendering mri brain data set challenge second observation speedups adaptive rendering nearly good nonadaptive rendering unlike results reported nieh levoy 1 adaptive rendering always exhibits worse speedups nonadaptive rendering due extra memory synchronization overhead parallel algorithm shows efficient adaptive rendering algo rithm memory overhead larger adaptive rendering access additional shared writable data structures local wait queue needed nonadaptive rendering additional synchronization time also required adaptive case due waiting processors complete ray casting non raycasting pixels interpolated raycasting pixels ever algorithm neither additional shared writable data structure additional synchronization time needed adaptive rendering cost replicated ray casting avoided load balancing image partitioning scheme without dynamic task redistribution show performance load balancing schemes collected times parallel projection subsequentnonadap tive adaptive ray traversal procedures processor rendering mri brain data set using twelve processors ta table 3 computation distribution sec mri brain data set 12 processors procedures projection nonadaptive rt adaptive rt variation 000 001 000 ble 3 shows variations rendering times among processors adaptive nonadaptive ray traversal respectively zero 001 seconds good load balancing also reached boundary cell projection measurable variation projection times among processors note present load balancing performance 12 rather 16 processors challenge processors used projection times short often less 001 seconds purposes compar ison also tables 46 present rendering rates several data sets 12 processors proc table 4 volume rendering times sec positive potential high potential iron protein data set proj projection time ray ray traversal time l overview lower opacity threshold 10 h interior higher opacity threshold 120 interactive classification fixed classification proc projl rayl rayh projh rayh table 4 commonly used 66 3 voxel positive potential high potential iron protein rendered using modified opacity transfer functions different opacity thresholds frames slow preprocessing stage runlength encoding avoided algorithm provided new opacity thresholds never less initially specified opacity threshold set initial opacity threshold 10 figure 6a modified threshold 120 figure 6b ray traversal times increase modification projection times change since change view therefore interactive rendering rates maintained rendering interactive classification similar results shown table 5 320 theta 320 theta 34 ct scan lobster rendered interactive classification initial opacity threshold set 30 display semitransparent shell 7a new opacity threshold set 90 display meat without shell figure 7b table 5 volume rendering times sec lobster data set proj projection time ray ray traversal time l shell low opacity threshold 30 h meat high opacity threshold 90 interactive classification fixed classification proc projl rayl rayh projh rayh comparison purposes also rendered two data sets fixed classification data set first recreated runlength encoding data structure new boundary cells according modified opacity threshold rendered data set view using modified transfer function new runlength encoding data structure tables 4 5 show rendering times interactive classification almost twice long fixed classification also measured different number boundary cells different opacity thresh olds found number boundary cells corresponding modified opacity thresholds two thirds corresponding initial opacity thresholds two data sets follows performance penalty rendering rate memory space moderate interactive classification table volume rendering times sec voxelized f15 aircraft data set using different kinds multiresolution volumes object boundary estimation para parallel projection time pers perspective projection time ray ray traversal time shrunken volume low lod volume proc para pers ray para pers ray 4 004 011 006 002 004 004 order speedup boundary cell projection time larger data sets used lower resolution volume procedures boundary cell detection runlength encoding pro jection still used original high resolution volume accurate rendering lower resolution volume either shrunken volume generated original volume merging every 3 neighboring cells macrocell low lod volume conducted experiments rendering 186 theta 256 theta 76 voxelized f15 aircraft data set figure 8a separately used two runlength encodings created shrunken volume m2 low lod volume low lod volume 93 theta 128 theta 41 voxels see figure 8b object modeling algorithm 14 used guaranteed shape aircraft low lod volume thinner original high resolution volume shown figure 8 table 6 shows projection ray traversal times using runlength encoding low lod volume faster shrunken volume discovered even though fewer boundary cells contained low lod vol ume led accurate object boundary estimation therefore time savings projection ray traversal procedures also note although employed lighting model 3d texture mappings implemented software rendering time ray traversal speeds fast binary classification aircraft decreased rendering complexity nearly 2 image size n 2 5 comparison shearwarp shearwarp factorization technique 5 another fast volume rendering method several similarities algorithm comparison two helpful evaluating first methods high speed volume rendering algorithms without graphics hardware acceleration high performances reached combining advantages image objectorder approaches therefore scalable rendering rates fast 1030hz reported methods render volume data set 16processor sgi challenge method inherits high image quality accurate ray casting shearwarp method suffers image quality problems due twopass resampling 2d rather 3d interpolation filter reported 5 second theoretical fundamentals methods directly indirectly based normal ray casting algorithm 13 method directly speeds ray casting algorithm efficiently skipping empty space outside classified object without affecting image quality thus existing ray casting optimiza tions early ray termination adaptive image sampling conveniently incorporated algorithm shearwarp method also viewed special form ray casting sheared rays cast voxels principal face volume bilinear rather trilinear interpolation operations used voxel slice resample volume data shortens rendering time also reduces image quality effect ray termination also achieved third methods employ scanlinebased runlength encoding data structure encode spatial coherence volume high data compression low access time algorithm small number boundary cells compared volume size leads minimal extra memory space runlength encoding obvi ously still need original volume ray traversal procedure shearwarp method although three encoded volumes required along three volume axes total memory occupation reported much smaller original volume fourth methods support interactive classification similar moderate performance penalties method interactive classification performs without extra programming efforts providing modified opacity threshold never less initial opacity threshold shearwarp method sophisticated solution presented restrictions fifth methods parallelized shared memory multiprocessors show good load balancing dynamic interleaved partitioning scheme employed parallel shearwarp algorithm 3 static contiguous partitioning schemes used method methods exploit spatial locality runlength encoding data structure general contiguous partitioning volume provides higher spatial locality interleaved parti tioning also compared dynamic partitioning static scheme economical due simplified controlling mechanism lower synchronization overhead compared performance parallelized shearwarp algorithm reported lacroute 3 experimental results 256 theta 256 theta 225 voxel ct head data set achieved challenge processors fastest shearwarp rendering rate 13 hz 256 theta 256 grey scale image parallel pro jection rendering time doubles color image additional resampling two extra color channels reached rendering rate 20 hz 33 hz adopting adaptive image sampling color images size shown figure 4 6 conclusions proposed interactive parallel volume rendering algorithm without using graphics hardware accelerators capable rendering per second 16processor sgi power challenge 256 3 volume data sets achieved speeds using accelerated ray casting algorithm effective space leaping available optimizations contiguous task partitioning schemeswhich take full advantage optimizations serial algorithm high load balancing low synchronization head compared shearwarp approach method shown faster rendering speed higher image quality following encouragingexperimental results currently investigating interactive ray casting large data sets algorithm runlength encoding lower levelsofdetail volume data studied create near accurate object boundary estimation much fewer boundary cells original full resolution data set utilized ray traversal procedure highquality ray casting images acknowledgments work partially supported nasa grant ncc25231 nsf grant mip9527694 onr grant n000149710402 nrl grant n00014961g015 nih grant ca79180 thanks huamin qu kevin kreeger lichan hong shigeru muraki constructive suggestions kathleen mcconnell comments special thanks milos sramek providing multiresolution volumes f15 aircraft mri data set courtesy electrotechnical laboratory etl japan r volume rendering scalable sharedmemory mimd architectures parallel performance measures volume ray casting realtime volume rendering shared memory multiprocessors using shearwarp factorization interac tive ray tracing isosurface rendering fast volume rendering using shearwarp factorization viewing transformation efficient ray tracing volume data applying space subdivision techniques volume rendering boundary cellbased acceleration volume ray casting towards comprehensive volume visualization system rendering volumetric data using stick representation scheme vol ume rendering based interactive navigation within human colon volume rendering adaptive refinement display surface volume data object voxelization filtering tr display surfaces volume data efficient ray tracing volume data volume rendering adaptive refinement rendering volumetric data using sticks representation scheme volume rendering scalable sharedmemory mimd architectures fast volume rendering using shearwarp factorization viewing transformation realtime volume rendering shared memory multiprocessors using shearwarp factorization object voxeliztion filtering interactive ray tracing isosurface rendering volume rendering based interactive navigation within human colon case study applying space subdivision techniques volume rendering towards comprehensive volume visualization system parallel performance measures volume ray casting ctr lukas mroz rainer wegenkittl eduard grller mastering interactive surface rendering javabased diagnostic applications proceedings conference visualization 00 p437440 october 2000 salt lake city utah united states anna vilanova balint hegeds eduard grller daniel wagner rainer wegenkittl martin c freund mastering interactive virtual bronchioscopy lowend pc proceedings conference visualization 00 p461464 october 2000 salt lake city utah united states ming wan qingyu tang arie kaufman zhengrong liang mark wax volume rendering based interactive navigation within human colon case study proceedings conference visualization 99 celebrating ten years p397400 october 1999 san francisco california united states gunter knittel ultravis system proceedings 2000 ieee symposium volume visualization p7179 october 0910 2000 salt lake city utah united states benjamin mora jeanpierre jessel ren caubet accelerating volume rendering quantized voxels proceedings 2000 ieee symposium volume visualization p6370 october 0910 2000 salt lake city utah united states feng dong gordon j clapworthy mel krokos volume rendering fine details within medical data proceedings conference visualization 01 october 2126 2001 san diego california ming wan aamir sadiq arie kaufman fast reliable space leaping interactive volume rendering proceedings conference visualization 02 october 27november 01 2002 boston massachusetts ming wan nan zhang huamin qu arie e kaufman interactive stereoscopic rendering volumetric environments ieee transactions visualization computer graphics v10 n1 p1528 january 2004 rdiger westermann bernd sevenich accelerated volume raycasting using texture mapping proceedings conference visualization 01 october 2126 2001 san diego california benjamin mora jean pierre jessel ren caubet new objectorder raycasting algorithm proceedings conference visualization 02 october 27november 01 2002 boston massachusetts