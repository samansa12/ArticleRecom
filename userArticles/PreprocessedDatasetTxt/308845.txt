reducing processing cost ondemand qos path computation quality service qos routing algorithms become focus recent research due potential increasing utilization integrated services packet network ispn serving requests qos requirements heuristics determining paths requests formulated variety qos models little attention given overall processing complexity qos routing protocol paper deals processing complexity determining qos paths link state based routing architectures although ondemand path computation attractive due simplicity many believe processing cost prohibitive environments high request rates work first characterize processing cost qos routing algorithms use widestshortest path heuristic study alternatives ondemand path computation reduce processing overhead addition well known solution path precomputation introduce study path caching incremental modification ondemand path computation simulating realistic topologies traffic conditions investigate performance alternatives results show caching effective alternative path precomputation path caching precomputation achieve significant processing cost savings without severely compromising routing performance b introduction although considerable amount work done problem supporting qos network recently role routing play integrated services network came attention main body qos routing work far focuses path finding problem given qos metrics network state qos requirements request find path maximizes chances request successful resource reservation minimum negative impact networks ability accept future requests variety heuristics unicast version problem different qos models discussed literature 1 3 4 5 6 7 8 1 3 7 8 operate bandwidth based qos model requests express qos requirements terms desired bandwidth model advantage simplicity basis controlled load service model proposed working group path finding heuristics assume paths calculated per request ba sis resulting ondemand mode operation calculating paths ondemand leads simple implementation reduces storage requirements many believe may practical environments high rates qos requests high processing overhead although claim hard verify due limited experience realistic qos aware network environments alternatives ondemand routing already proposed 1 7 9 10 alternatives based path precomputation principle paths destinations computed asynchronously request arrivals used route multiple requests reducing way per request processing overhead aforementioned path precomputation propos als paths precomputed possible paths destinations computed stored qos routing table may prove inefficient terms processing storage precomputed paths used addition path precomputation proposals far set precomputed paths updated precomputations possible allowing addition new good paths set precomputed paths improve routing performance without incurring cost precomputing completely new set paths work propose caching architecture flexible far proposed path precomputation approaches caching architecture paths computed ondemand stored path cache reused future requests request routed using cached path ondemand computation used determine qos path new path added path cache updating way contents best knowledge previous work path caching appeared 17 although approach similar work considerably different become apparent present caching scheme detail ad dition major goal work compare routing performance processing cost path caching path precomputation architecture investigate overall cost effectiveness path caching method reducing processing cost determining qos paths paper organized follows section 2 algorithms used discussed path caching introduced section 3 introduces simulation environment section 4 different approaches compared based simulation results last section summarize findings algorithms path computation consider link state routing protocols paths calculated source requests routed using source routing evidence architecture choice standard qos routing algorithms private network network interface pnni 14 already standardized qos routing protocol based architecture moreover qos routing proposals ietfs ospf working group based link state architecture operate source routing hop byhop mode link state routing protocol node maintains link state database contains description network state known node link state database updated link state reports generated nodes link state updates distributed nodes using flood ing contrast previous studies 1 use link update generation model proposed 7 initiates new link state update available bandwidth link changes significantly since last time advertised link state update threshold determines percentage change necessary readvertising value available link bandwidth b last recently advertised available bandwidth value b cur current value update originated jb cur gamma b last jb last th th link state update trigger threshold recent simulation studies 1 showed among heuristics proposed routing requests bandwidth requirements shortest path heuristics 1 7 8 perform better widest path heuristic 3 prefers widest shortest paths width path also called bottleneck capacity defined minimum available bandwidth links path use widest shortest path heuristic 7 basis path computing algorithms ondemand widestshortest paths computed fol lows links insufficient available bandwidth request routed pruned network topology path calculated minimum hop count paths source destination discovered widest one used route request one widestshortest paths one must chosen among multiple path precomputation propos als chose use work approach described mainly path precomputation solution proposed ietfs ospf working group uses modified bellmanford algorithm precompute widest bottleneck capacity minimum hop path destination addition paths longer minimum hop path alternate paths larger bottleneck capacity shorter paths recorded destination also stored multiple paths equal bottleneck capacity minimum hop alternate paths stored request arrives path selected among precomputed paths follows paths checked feasibility order increasing length shortest feasible one selected ondemand case path feasible bottleneck capacity calculated time path precomputation larger equal request requirements multiple feasible paths hop count path selected using technique discussed ondemand path computation feasible paths request routed longest available path destination comparison purposes also use static path computation algorithm operates exactly way ondemand algorithm except link capacity used value available bandwidth making path selection insensitive variations resource availability network multiple minimum hop paths static bottleneck capacity one selected random using load balancing technique previous two cases link capacity first hop path used instead available bandwidth interface first hop path 21 path caching path caching attempts reduce processing complexity ondemand path computation without compromising ondemand nature ability compute paths individual requests necessary path caching reduces number path computations reusing already calculated paths already discovered paths particular destination stored path cache associated destination future requests routed ondemand routed using contents path cache different path cache associated destination node clearly path cache needs flushed repopulated case topology changes ie change link status path cache implemented variety ways chose simple implementation path repre link state database records path cache destination 8 network topology figure 1 example path cache organization sented list node structures node structure essentially pointer corresponding entry link state database figure 1 organization allows simple traversal link state database easy reconstruction path needed routing request optimize storage cached path hop length bottleneck bandwidth capacity maintained cache along sequence nodes path value bottleneck capacity necessarily reflect recent information link state database since recomputed time link state update received feasible cached paths considered routing requests cached path feasible bottleneck capacity larger bandwidth requirements request cache contain feasible path request routed using cache contents routed ondemand 22 operation new request arrives cache containing paths destination node searched feasible path path selected using cache selection policy path exists used route request feasible path request routed ondemand ondemand computation may fail discover appropriate path case request rejected path found though added cache destination cache full cache replacement policy determines cached path replaced new path order make sure cached paths reflect reasonable degree current network state cache update policy determines cached paths updated rest section discuss cache managements policies detail 221 cache selection policy accordance previous studies order minimize consumption network resources shortest feasible cached paths used routing request choosing longer path results using resources links potentially penalizes ability network accept future requests still depending topology network may exist multiple paths hop length case tiebreaking mechanism needed work explore three mechanisms ffl roundrobin path counter times path used maintained multiple feasible paths hop count least used paths chosen attempts distribute load among multiple paths request basis usage counter reset time path added removed cache information bottleneck capacity path updated describe next section ffl widest path path largest bottleneck capacity among feasible equal hop length paths chosen implements worsefit policy attempt reduce bandwidth fragmentation see 16 discussion bandwidth fragmentation tightest path feasible path smallest bottleneck bandwidth chosen policy contrast previous one attempts pack requests leave large chunks bandwidth available future larger requests cases occasion also tie amount available bandwidth path selected among ones hop length bottleneck capacity random uniform distribution 222 cache replacement policy result successful ondemand path computations performed requests could routed using cached path new information needs added cache path discovered already cache bottleneck capacity updated otherwise path added cache cache full another path replaced choice path replaced path low chances used later replaced note since new path result ondemand computation performed feasible path cache follows newly discovered path bottleneck capacity larger currently cached paths search path suitable replacement first considers paths longer path added cache longer paths exist ideal candidates replacement since never selected new path added cache indeed cache selection policy always prefer new path longer less wide path next step paths length equal new one considered paths exist one selected replacement agreement cache selection policy ie widest cached path selection policy used narrowest paths hop length equal new path selected tightest policy used widest path chosen roundrobin policy used path replaced last case cache contain paths shorter new path case obvious path one less chances used routing future request heuristic choose path among cached paths accordance cached path selection policy 223 cache update policy clearly network conditions case available bandwidth interface change continuously resulting new feasible paths destinations need discovered added path cache new values bottleneck bandwidth capacity already cached paths contents path cache updated either invalidating cached paths accessing link state database recomputing updated values bottleneck bandwidth capacity cached paths note link state updates generated nodes used update local link state database information cached paths modified receipt link state update cached paths invalidated future requests forced routed ondemand discovering way new network state result path invalidation expected result larger overall number ondemand path computations hand recomputing bottleneck capacity cached paths lead fewer ondemand computations since paths still cache used routing future requests still updating cached paths discovery new paths may delayed resulting suboptimal routes investigate performance two alternatives using three different cache update policies ffl periodic invalidation cached paths destinations periodically invalidated forcing future requests routed ondemand repopulate path caches ffl periodic update cached paths destinations updated periodically accessing link state topology database recomputing bottleneck bandwidth values ffl individual invalidation cached path lifetime associated paths lifetime expired invalidated cache update policies require performing operations periodically case individual invalidation setting lifetime cache entry collectively refer update period policies cache update period term also include lifetime cache entry individual invalidation policy used path precomputation period paths precomputed presenting details path caching architecture contrast previous work caching presented 17 main difference 17 allowed single path cached per destination allow caching multiple paths per destination achieving flexibility routing requests also attempt exploit topology characteristics like availability multiple equal hop paths sourcesdestinations paths result caching multiple paths per destination cache management form cache selection cache replacement important component caching archi tecture addition investigate effects cache size performance caching scheme finally cached paths 17 invalidated sufficiently large number link state updates received links belonging cached path believe implementation policy nontrivial terms processing performed receipt new link state update chose investigate different lower cost mechanisms keeping cached paths date 3 simulation environment performance metrics developed simulator based maryland routing simulator mars 13 mars extended perform source routing link state update generation mechanism modified support triggered dates simple resource reservation protocol implemented unicast connections traffic load expressed terms connection requests request established actual packet traffic path isp b mesh figure 2 topologies used experiments current load network links determined list reservations maintained interface reservation protocol effectively connections assumed constant bit rate conform stated bandwidth requirements clearly simplification issues like traffic policing shaping modeling orthogonal issues study topologies used experiments shown figure 2 isp typical topology fairly large isp provider 1 mesh topology compact expect differences running time computing path destinations single destination small addition contrast isp mesh topology larger number equal hop multipaths propagation delay links set 1 millisecond assumed links never fail believe qos routing beneficial cases temporary mismatches traffic pattern network topology create increased loads parts network conditions occur either result network failure link failure simply changing traffic patterns order recreate conditions simulations determine link capacities topology dimensioned uniform traffic dimensioning results link capacities mbitssec isp topology 100 140 mbitssec mesh create conditions nonuniform traffic establishing two sets nonuniform traffic nodes nodes belong one sets request connections nodes set mean request arrival rate different nodes belong sets destination set contains one node destination chosen randomly among nodes destination set uniformly distributed probability nodes belonging set topologies shown figure marked b correspondingly case nonuniform traffic two request arrival rates background rate traffic nodes belong sets nonuniform traffic nodes foreground rate nodes sets background rate chosen background traffic levels large enough limit routing options available primary traffic ie reducing levels background traffic reduce overall blocking ratio basic dimension comparison different routing architectures behavior different workloads capture effects call duration requested bandwidth use two different workloads combine different duration request size parameters workloads summarized table 1 bandwidth requirements uniformly distributed minimum value 64 kbitsec maximum value shown call duration exponentially distributed mean 3 minutes mit stands mean interarrival time traffic loads chosen way blocking ratios kept 230 range arrival rates poisson distributed mean shown figure 1 experiments performed link state update triggering threshold 10 number results frequent link state updates ensuring link state information accurate also performed experiments larger threshold values resulted link state information inac curacy although report detailed results due space limitations overall behavior different alternatives similar described section 4 even link state information inaccurate node network individual request arrival process independent ones nodes network simulated 100000 connections requested first 30000 connection requests used warm network ignored calculating routing performance processing cost 31 higher level admission control well known 11 12 excessive alternate routing actually reduce routing performance conditions foreground mit 25 sec 20 sec background mit 5 sec 40 sec foreground mit 65 sec 5 sec background mit 13 sec 75 sec table 1 workload parameters high load since traffic following alternate routes interfere minimum hop traffic competing links order address problem investigate high level admission control policies similar trunk reservation assuming explicit routing used propose trunk reservation approach may result rejecting requests routed alternate paths resource reservation phase even sufficient resources satisfy request local per node check determines request allowed continue reserving resources path depending resources remain available link reservation relative length path ie much longer compared minimum hop path information easy compute topology change minimum hop destination computed reservation attempted node quantity b avail capacity calculated outgoing link b avail amount available bandwidth link b capacity capacity link resource reservation request allowed continue fraction larger trunk reservation level depends length path request fails test rejected computing trunk reservation level based requests requirements residual capacity link allows us reject requests really would resulted overloading link different trunk reservation levels increasingly longer paths allows us penalize longer paths control alternate routing better experiments paper trunk reservation levels set 2 one hop longer paths 5 two three four hops longer 10 longer paths 32 performance measures circuit switched routing performance studies connection blocking ratio used measure routing performance connection blocking ratio defined percentage connection requests rejected total number requests mentioned 1 necessarily accurate measure since connections different bandwidth requirements thus mainly report bandwidth acceptance ratio sum bandwidths connection requests accepted sum bandwidths connection requests compare processing cost alternative routing architectures use processing cost model described 2 model routing algorithm broken number elementary operations cost operations measured carefully designed benchmark experiments operations initialization b accessing link state database c data structure opera tions actual simulations number times elementary operation executed determined aggregate cost routing algorithm computed summing products counts cost elementary operation number computed way corresponds total time spent routing protocol processing given simulation run path caching need accommodate new elementary operations unique path caching operations updating cache b adding path cache c cache lookup invalidating cached path derive cost individual operations profiling execution benchmark experiments using pixie profiler available digital unix platform used simulations profiler gives total real time spent function simulation associating total time spent operations particular category number operations derive approximate cost per operation details benchmark experiments described 2 cost cache operations measured conjuction many iterations main loop operations required number iterations depends number cached paths results summarized table 2 numbers derived architecture used simulations alphaserver servers 4 alpha 21064a cpus 275 mhz 256 mbytes real memory digital unix operating system cache related costs depend cache size way computed cost initialization large since part initialization spent releasing memory data structures paths used since last path precomputation cost clearly depends size network cost operations relatively independent size network topology size numbers reported 95 confidence interval 3 isp 1 mesh topology bandwidth acceptance ratio 5 processing cost values topologies confidence intervals calculated using students distribution operation isp mesh iteration avground 2 15 data structure avgoperation 4 4 initialization avgpath computation 120 47 cache update maxpath 5 caching path maxpath cached 15 cache lookup maxcached path 3 path selection maxpath 3 table 2 cost operations performed routing algorithms sec performance comparison first determine appropriate values path precomputation period particular topologies workloads used values chosen routing performance various alternatives measured using bandwidth acceptance ratio better similar performance static path computation values update period calculated way used experiments 5 10 30 60 120 180 220 280 seconds larger values update period routing performance actually worse static path computation combinations topology workload nevertheless use comparison purposes disadvantage fixed update periods varying effects different workloads example network topology used requests belonging workload requests large amount bandwidths must slower arrival rate since want keep rejection rate low requests workload smaller request sizes slow arrival rates path precomputation performed often terms number requests successive path pre computations still fixed period probably simplest alternative real network addition even simplified environment experiments obvious choose equivalent precomputation periods different workloads since due nonuniform traffic different nodes different request rates cache size path caching experiments set four paths choosing small cache size important since desirable minimize storage overhead path caches nevertheless verified traffic workloads topologies used experiments increasing cache size effect routing performance processing cost path caching alterna tives indication small caches paths sufficient effective operation path caching schemes compare different approaches evaluating performancecost tradeoffs accomplish plotting bandwidth acceptance ratio processing cost different values cache update path precomputation period results curve different alternative points curve larger costs xaxis coordinate correspond small periods ondemand path computation single point since routing performance cost dependent update period processing cost static computation negligible graphs plot line instead single point yaxis make comparisons routing performance alternatives easier figure 3 show performance path precomputation caching topologies requests 1 mbitsec widest path cache selection pol icy figure see larger update periods alternatives achieve significant processing cost savings compared ondemand routing small update periods alternatives routing performance similar ondemand routing cost similar even exceed cost ondemand routing indeed path precomputation periodic cache update incur processing cost time paths recomputed cache dated update period sufficiently small cost exceed ondemand path computation hand cache invalidation policies involve processing cost cache management result processing cost smaller ondemand computation path precomputation periodic cache update achieve better processing cost savings similar values update period visible part b figure 3 isp topology large values update period cost precomputation periodic update levels reflects processing due path computation small path selection cost becomes dominant cost component contrary cost two cache policies continues decrease update period increases cost decrease due fact larger update periods cached paths updated less often tend used reducing way number ondemand path computations path precomputation processing cost similar periodic cache update mesh topology larger difference favor periodic cache update exists isp topology due fact larger isp topology cost computing path single destination much lower cost computing paths destinations cost difference pronounced mesh topology note also mesh topology routing performance alternatives appears deteriorate quickly become worse acceptance processing cost total simulation time perupd indivinv perinv ondemand mesh089091093095097 acceptance processing cost total simulation time perupd indivinv perinv ondemand b isp figure 3 performance comparison 1 mbitsec static routing even moderately small values update period case isp topol ogy mainly result fact mesh topology calls especially source destination hotspot traffic routed equal hop case also minimum hop multipaths favor static routing algorithm also use available minimum hop multipaths isp topol ogy existence alternate paths results significantly improved routing performance alternatives static routing results 6 mbitsec requests similar 1 mbitsec case shown 41 effects cache selection policy figure 4 show effects cache selection policy topologies requests 1 mbitsec turns type cache selection policy affects observed behavior cache based alternative when07808208609094098 acceptance processing cost total simulation time rr perupd widest perupd tightest perupd widest perinv widest indivinv mesh0890910930950 05 1 acceptance processing cost total simulation time rr perupd widest perupd tightest perupd widest perinv widest indivinv b isp figure 4 effects cache selection policy 1 mbitsec periodic update used using periodic update policy results average number cached paths larger invalidation based policies used intuitive since periodic update policy never invalidates paths contrast two policies periodically invalidate individual cached paths paths cache effects cache selection policy become pronounced periodic cache update policy widest path cache selection policy results better routing performance smaller update period values topologies narrowest path policy always results worse routing performance cache policies type cache selection policy significant effect since cache occupancy hit ratios lower policies show curve widest cache selection policy overall observe widest cached path selection policy achieves good performance periodic update cache update policy used intuitive since increasing cache update periods bottleneck bandwidths cached paths become increasingly less accu rate choosing tightest path soon result overflowing chosen path since reduction paths available bandwidth discovered later cache updated roundrobin cache selection policy ignores completely available bandwidth capacity fails achieve good performance caches updated ten choosing widest cached path combines protection infrequent updating cached paths good routing performance smaller update periods 5 considerations 51 cache size figure 5 show cache size affects routing performance different cache based alterna tives part figure show data mesh topology b isp requests 1 mbitssec link state update threshold set 10 update period set 5 seconds invalidation based policies show important dependence cache size mainly since cache occupancy low times nevertheless interesting variations behavior periodic cache update policy mesh topology widest cached path selection used performance increases increasing cache size reasonable since topology multiple equal hop paths cache achieve good performance paths exist cache information available network time cached paths updated load balancing performed choosing widest performs bet ter indication types topologies caching multiple paths per destination advantageous single path cache architecture similar 17 performance choosing round robin cached paths really depend cache size due high degree link sharing minimum hop multipaths even rotating multipaths achieve link load rotating multiple paths selecting tightest cached path performs bad cache size 1 showing policy appropriate topology isp case less equal hop multipaths caches due topology result variations routing performance due varying cache size much less pronounced periodic cache update policy routing performance widest cached path selection policy independent cache size tightest cached path selection policy performs bad isp topology routing performance roundrobin cached path selection policy seems also slightly08609094098 acceptance cache size rr perupd widest perupd tightest perupd widest indivinv widest perinv acceptance cache size rr perupd widest perupd tightest perupd widest indivinv widest perinv b isp figure 5 effects cache size decreasing cache larger 1 path indicating selection policy perform well invalidation based cache update policies type cached path selection policy affect performance result figure 5 invalidation based policies show curve widest cached path selection policy 6 conclusions experiments turns ffl path caching viable method reducing processing cost ondemand qos path computation least widestshortest path selection criterion used ffl periodic cache update policy coupled widest cached path selection policy achieves best processing costrouting performance tradeoff many cases significantly better path precomputation ffl tightest cached path selection policy performs bad cases considered ffl invalidation based cache update policies achieve significant processing cost savings general less path precomputation periodic cache update ffl topology play important role processing cost routing performance different caching policies particular amount equal hop multipaths density diameter topology determine relative costs singledestination alldestination path computations routing performance different cached path selection policies ffl small cache sizes sufficient achieving good routing performance processing savings always though dependence network topol ogy cases cache large enough hold specific number minimum length equal hop paths case mesh topology r path selection traffic bandwidth guarantees qos routing performance perspective quality service routing supporting multimedia applications routing subject quality service constraints integrated communication networks design evaluation routing algorithms realtime channels two distributed algorithms constrained steiner tree problem routing highbandwidth traffic maxmin fair share networks route precomputation algorithm integrated services networks efficient precomputation qualityofservice routes stabilization alternate routing net works dynamic alternate routing modeling behaviour private network network interface specification adaptive source routing real time traffic integrated service networks performance modeling management highspeed networks tr ctr matthew stafford xiangying yang gustavo de veciana connection caching reduce signaling loads applications softswitch telephony computer networks international journal computer telecommunications networking v42 n2 p211229 5 june