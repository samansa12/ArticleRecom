parallel mining association rules abstractwe consider problem mining association rules sharednothing multiprocessor present three algorithms explore spectrum tradeoffs computation communication memory usage synchronization use problemspecific information best algorithm exhibits near perfect scaleup behavior yet requires minimal overhead compared current best serial algorithm b introduction availability inexpensive storage progress data capture technology many organizations created ultralarge databases business scientific data trend expected grow complementary technology trend progress networking memory processor technologies opened possibility accessing manipulating massive databases reasonable amount time data mining also called knowledge discovery databases efficient discovery previously unknown patterns large databases promise data mining deliver technology enable development new breed decisionsupport applications discovering association rules important data mining problem 1 recently considerable research designing fast algorithms task 1 3 5 6 8 12 9 11 however exception 10 work far concentrated designing serial algorithms since databases mined often large measured gigabytes even terabytes parallel algorithms required present paper three parallel algorithms mining association rules order determine best method mining rules parallel explore spectrum tradeoffs computation communication memory usage synchronization use problemspecific information parallel data mining specifically 1 focus count distribution algorithm minimizing communication even expense carrying redundant duplicate computations parallel 2 data distribution algorithm attempts utilize aggregate main memory system effectively communicationhappy algorithm requires nodes broadcast local data nodes also department computer science university wisconsin madison 3 candidate distribution algorithm exploits semantics particular problem hand reduce synchronization processors segment database based upon patterns different transactions support algorithm also incorporates load balancing algorithms based upon serial algorithm apriori first presented 3 chose apriori algorithm superior performance earlier algorithms 1 6 shown 3 preferred apriori apriorihybrid somewhat faster algorithm 3 apriorihybrid harder parallelize performance apriorihybrid sensitive heuristically determined parameters furthermore performance apriori made approximate apriorihybrid combining small workloads several apriori cycles single workload requiring one cycle algorithm 8 quite similar apriori parallelization techniques directly apply algorithm well algorithm 11 perform well apriori large datasets large number items algorithm 9 attempts improve performance apriori using hash filter however see section 43 optimization actually slows apriori algorithm concurrent work algorithm parallelized recently presented simulation study 10 suffers use hashfilter despite use special communication operator build discuss section 43 three parallel algorithms implemented ibm powerparallel system sp2 henceforth referred simply sp2 sharednothing machine7 present measurements implementation evaluate effectiveness design tradeoffs winning algorithm part ibm datamining product used field organization rest paper follows section 2 gives brief review problem mining association rules1 apriori algorithm3 proposed parallel algorithms based section 3 gives description parallel algorithms section 4 presents results performance measurements algorithms section 5 contains conclusions detailed version paper found 2 2 overview serial algorithm 21 association rules basic problem finding association rules introduced 1 follows let set literals called items let set transactions transaction itemset say transaction contains x set items x association rule implication form x rule x holds transaction set confidence c c transactions contain x also contain rule x support transaction set transactions contain x given set transactions problem mining association rules generate association rules certain userspecified minimum support called minsup confidence called minconf problem decomposition problem mining association rules decomposed two subproblems 1 1 find sets items itemsets whose support greater userspecified minimumsupport itemsets minimum support called frequent itemsets kitemset itemset k items lk set frequent kitemsets minimum support member set two fields itemset ii support count ck set candidate kitemsets potentially frequent itemsets member set two fields itemset ii support count dataset local processor p dr dataset local processor p repartitioning candidate set maintained processor p kth pass k items candidate figure 1 notation l1 ffrequent 1itemsetsg represents pass number begin ck new candidates size k generated transactions 2 increment count candidates ck contained lk candidates ck minimum support answer figure 2 apriori algorithm 2 use frequent itemsets generate desired rules general idea say abcd ab frequent itemsets determine rule ab cd holds computing ratio supportabcdsupportab conf minimum confidence rule holds rule minimum support abcd frequent much research focussed first subproblem database accessed part computation several algorithms proposed 1 3 6 8 9 11 review section 22 apriori algorithm 3 parallel algorithms based 22 apriori algorithm figure 2 gives overview apriori algorithm finding frequent itemsets using notation given figure 1 first pass algorithm simply counts item occurrences determine frequent 1itemsets subsequent pass say pass k consists two phases first frequent itemsets l kgamma1 found pass used generate candidate itemsets c k using apriori candidate generation procedure described next database scanned support candidates c k counted fast counting need efficiently determine candidates c k contained given transaction hashtree data structure 3 used purpose candidate generation given l kgamma1 set frequent 1itemsets want generate superset set frequent kitemsets intuition behind apriori candidate generation procedure itemset x minimum support subsets x simplicity assume items itemset lexicographic order candidate generation takes two steps first join step join l kgamma1 l insert ck select pitem1 pitem2 next prune step delete itemsets c 2 c k k gamma 1subset c l kgamma1 example let l 3 ff1 2 3g f1 2 4g f1 3 4g f1 3 5g f2 3 4gg join step c 4 ff1 2 3 g prune step delete itemset f1 3 4 5g itemset f1 4 5g l 3 left f1 2 3 4g c 4 3 parallel algorithms first present three parallel algorithms first subproblem problem finding frequent itemsets give parallel algorithm second subproblem problem generating rules frequent itemsets refer figure 1 summary notation used algorithm descriptions use superscripts indicate processor id subscripts indicate pass number also size itemset algorithms assume sharednothing architecture n processors private memory private disk processors connected communication network communicate passing messages communication primitives used algorithms part mpi message passing communication library supported sp2 candidates messagepassing communication standard currently discussion 4 data evenly distributed disks attached processors ie processors disk roughly equal number transactions require transactions placed disks special way 31 algorithm 1 count distribution algorithm uses simple principle allowing redundant computations parallel otherwise idle processors avoid communication first pass special passes k 1 algorithm works follows 1 processor p generates complete c k using complete frequent itemset l kgamma1 created end pass k gamma 1 observe since processor identical l kgamma1 generating identical 2 processor p makes pass data partition develops local support counts candidates 3 processor p exchanges local c k counts processors develop global c k counts processors forced synchronize step 4 processor p computes l k c k 5 processor p independently makes decision terminate continue next pass decision identical processors identical l k first pass processor p dynamically generates local candidate itemset c 1 depending items actually present local data partition hence candidates counted different processors may identical care must taken exchanging local counts determine global c 1 thus every pass processors scan local data asynchronously parallel however must synchronize end pass develop global counts performance considerations steps 12 45 similar serial algorithm nonobvious step processors exchange local counts arrive global c k counts since processor exact c k processor puts count values common order count array needed perform parallel vector sum arrays requires communicating count values done ologn communication steps also avoids timeconsuming logic would otherwise needed assure combine counts belong candidate full details process including mpi communication primitives used described 2 32 algorithm 2 data distribution attractive feature count distribution algorithm data tuples exchanged processors counts exchanged thus processors operate independently asynchronously reading data however disadvantage algorithm exploit aggregate memory system effectively suppose processor memory size jm j number candidates counted one pass determined jm j increase number processors 1 n system n theta jm j total memory still count number candidates one pass processor counting identical candidates count distribution algorithm counts candidates per pass serial algorithm data distribution algorithm designed exploit better total systems memory number processors increased algorithm processor counts mutually exclusive candidates thus number processors increased larger number candidates counted pass nprocessor configuration data able count single pass candidate set would require n passes count downside algorithm every processor must broadcast local data processors every pass therefore algorithm become viable machine fast communication pass 1 count distribution algorithm 1 processor p generates c k l kgamma1 retains 1nth itemsets forming candidates subset k count 1n itemsets retained determined processor id computed without communicating processors implementation itemsets assigned roundrobin fashion c k sets disjoint union c k sets original c k 2 processor p develops support counts itemsets local candidate set c using local data pages data pages received processors 3 end pass data processor p calculates l k using local c k l sets disjoint union l k sets l k 4 processors exchange l k every processor complete l k generating c k1 next pass step requires processors synchronize obtained complete l k processor independently identically decide whether terminate continue next pass interesting step step 2 processors develop support counts local candidates c chronously step processors broadcasting local data well receiving local data processors must careful avoid network congestion use asynchronous communication overlap communication time counting support see 2 full details 33 algorithm 3 candidate distribution one limitation count data distribution algorithms since database transaction could support candidate itemset transaction must compared entire candidate set requires count duplicate candidate set every processor data broadcast every database transaction additionally count data distribution algorithms require processors synchronize end pass exchange counts frequent itemsets respectively workload perfectly balanced cause processors wait whichever processor finishes last every pass problems due fact neither count data exploit problemspecific knowledge data tuples candidate itemsets partitioned merely equally divide work processors must consulted information gathered proceed onto next pass candidate distribution algorithm attempts away dependencies partitioning data candidates way processor may proceed independently pass l l heuristically determined algorithm divides frequent itemsets l lgamma1 processors way processor p generate unique c independent processors c time data repartitioned processor count candidates c independent processors note depending upon quality itemset partitioning parts database may replicated several processors itemset partitioning algorithm considers aspect identifying segments l lgamma1 likely supported different database transactions choice redistribution pass tradeoff decoupling processor dependence soon possible waiting itemsets become easily equitably partitionable partitioning algorithm exploits semantics apriori candidate generation procedure described section 22 candidate distribution processor proceeds independently counting portion global candidate set using local data communication counts data tuples ever required dependence processor processors pruning local candidate set prune step candidate generation however information sent asynchronously processors wait complete pruning information arrive processors prune step candidate generation prunes candidate set much possible using whatever information arrived opportunistically starts counting candidates late arriving pruning information instead used subsequent passes algorithm described use either count data distribution algorithm pass 1 partition l kgamma1 among n processors l kgamma1 sets well balanced discuss partitioning done record frequent itemset l kgamma1 processor assigned itemset partitioning identically done parallel processor 2 processor p generates c logically using l kgamma1 partition assigned note p still access complete l kgamma1 hence use standard pruning generating c k pass 3 p develops global counts candidates c k database repartitioned dr time 4 p processed local data data received processors posts asynchronous receive buffers receive l j k processors l j needed pruning c prune step candidate generation 5 processor p computes l k c k asynchronously broadcasts processors using sends 1 processor p collects frequent itemsets sent processors used pruning step candidate generation join step itemsets received processor j could length greater keeps track processor p j largest size frequent itemsets sent receive buffers frequent itemsets reposted processing 2 k using local l happen p received l j kgamma1 processors p needs careful time pruning needs distinguish itemset long subset candidate itemset present l j itemset present set yet received processor p probing l remember repartitioning took place pass l using l gamma 1 long prefix itemset question finding processor responsible checking l j received processor 3 p makes pass dr counts c k computes l k c k asynchronously broadcasts k every processor using sends data distribution algorithm step 3 pass communicating local data support counts developed one difference local data need broadcast every processor candidate partitioning processors information transactions useful developing support counts processors allows processors send less data network full details filtering described 2 partitioning l k motivate algorithm partitioning l k example let l 3 fabc abd abe acd ace bcd bce bde cdeg l fabcdeg l whose members common prefix ab note candidates abcd abce abde abcde also prefix ab apriori candidate generation procedure section 22 generates candidates joining items e therefore assuming items itemsets lexicographically ordered partition itemsets l k based common long prefixes ensuring partition assigned one processor ensured processor generate candidates independently ignoring prune step suppose also repartition database way tuple supports itemset contained l k partitions assigned processor copied local disk processor processors proceed completely asynchronously actual algorithm involved two reasons processor may obtain frequent itemsets computed processors prune step candidate generation example processor assigned set e know whether bcde frequent able decide whether prune candidate abcde set prefix bc may assigned different processor problem need balance load across processors details full partitioning algorithm given 2 34 parallel rule generation present parallel implementation second subproblem problem generating rules frequent itemsets generating rules much less expensive discovering frequent itemsets require examination data given frequent itemset l rule generation examines nonempty subset generates rule lgammaa computation efficiently done examining largest subsets l first proceeding smaller subsets generated rules required minimum confidence 3 example given frequent itemset abcd rule abc minimum confidence neither ab cd need consider generating rules parallel simply involves partitioning set frequent itemsets among processors processor generates rules partition using algorithm since number rules generated itemset sensitive itemsets size attempt equitable balancing partitioning itemsets length equally across processors note calculation confidence rule processor may need examine support itemset responsible reason processor must access frequent itemsets rule generation begin problem count data distribution algorithms end last pass processors frequent itemsets candidate distribution algorithm fast processors may need wait slower processors discovered transmitted frequent itemsets reason rule generation step relatively cheap may better candidate distribution algorithm simply discover frequent itemsets generate rules offline possibly serial processor would allow processors freed run jobs soon done finding frequent itemsets even processors system still working 35 discussion tradeoffs initially clear us three algorithms would win would even single overall winner count minimizes communication expense ignoring aggregate memory workstationcluster environment approach probably ideal may however sp2 data distribution fully exploits aggregate memory cost heavy communication help us explore issue also datas ability count single pass n times many candidates count could make algorithm strong contender third algorithm candidate distribution see incorporating detailed problemknowledge yield benefits count data distribution algorithms also see beneficial removing processor dependence synchronous communication performance evaluation ran experiments 32node ibm sp2 model 302 node multiprocessor thin consisting power2 processor running 667mhz 256mb real memory attached node 2gb disk less 500mb available tests processors run aix level 325 communicate highperformance switch hps2 adaptors combined communication hardware rated peak bandwidth 80 megabytes per second latency less 40 microseconds tests base communication routines actual pointtopoint bandwidth reached 20mbs experiments run otherwise idle system see 7 details sp2 architecture name 1 average transaction length average size frequent itemsets average number transactions table 1 data parameters used synthetic datasets varying complexity generated using procedure described 3 characteristics six datasets used shown table 1 datasets vary many short transactions frequent itemsets fewer larger transactions many frequent itemsets datasets 100mb per processor size could use larger datasets due constraints amount storage available local disks candidate algorithm writes redistributed database local disks candidate partitioning run disk space larger datasets however include results experiments 400 mb per processor count distribution algorithm show trends larger amounts data per processor experiments repeated multiple times obtain stable values data point 41 relative performance tradeoffs figure 3 shows response times three parallel algorithms six datasets 16 node configuration total database size approximately 16gb response time measured time elapsed initiation execution end time last processor finishing computation response times serial version run one nodes worth data 116th total database run serial algorithm entire data enough disk space available obtained similar results node configurations dataset sizes experiments candidate distribution repartitioning done fourth pass tests choice yielded best performance results encouraging count candidate distribution algorithms response times close serial algorithm especially true count overhead count less 75 compared serial version run 1n data one third overhead 25 spend waiting processors synchronize among parallel algorithms data distribution fare well two expected data indeed able better exploit aggregate memory multiprocessor make fewer passes case datasets large average transaction frequent itemset lengths see table 2 however response time candidate data count serial 1n data figure 3 relative performance algorithms20006000100001400018000 response time normal communication figure 4 communication costs data distribution name serial count data candidate table 2 number data passes required performance turned markedly lower two reasons extra communication fact every node system must process every single database transaction communication worst two problems show figure 4 even machine sp2 fast communication points labeled normal correspond response times normal data distribution algorithm 16node configuration 100mb data replicated node points labeled communication correspond modified version data distribution algorithm instead receiving data nodes node simply processed local data 15 times since node exact data yielded exact results difference time spent communication management three six datasets discovered fully half time taken data distribution communication algorithm also almost entirely cpubound making io savings due data making fewer passes practically negligible hoped better results candidate distribution algorithm considering one exploits problemspecific semantics since candidate algorithm must also communicate entire dataset redistribution pass suffers problems data candidate however performs redistribution also unlike data processors may selectively filter transactions sends processors depending upon dependency graph partitioned greatly reduce amount data traveling network unfortunately even single pass filtered data redistribution costly question whether subsequent passes processor run completely independently smaller candidate sets compensate cost performance results show redistribution simply costs much also unlike data distribution candidate algorithm unable capitalize optimal use aggregate memory large candidate sets force count multiple subpasses occur candidate takes redistribution pass candidate thus makes many data passes count insufficient gains coupled high redistribution cost allow count small overhead emerge overall winner although experiments show counts overhead fairly small synchronization costs become quite large data distributions skewed nodes equally capable different memory sizes processor speeds io bandwidths capacities investigation issues broad topic future plans however one think several alternatives adding load balancing count distribution algorithm require redistribution complete database case candidate distribution algorithm extrapolating results study sense count distribution algorithm embellished appropriate load balancing strategy likely continue dominate 42 sensitivity analysis examine scaleup sizeup speedup characteristics count distribution algorithm report results data candidate distribution algorithms inferior performance scaleup see well count distribution algorithm handles larger problem sets processors available performed scaleup experiments increased size database direct proportion number nodes system used datasets d2016kt10i2 d1456kt15i4 d1140kt20i6 previous experiments except number transactions increased decreased depending upon multiprocessor size database sizes single 32 node configurations shown table 1 100mb per node three datasets range 100mb single node case almost 32gb node case figure 5 shows performance results three datasets addition absolute response times number processors increased also plotted scaleup response time normalized respect response time single processor clearly count algorithm scales well able keep response time almost constant database multiprocessor sizes increase slight increases response times due entirely processors involved communication since itemsets found algorithm change database size increased number candidates whose support must summed communication phase remains constant sizeup experiments fixed size multiprocessor nodes growing database 25 mb per node 400 mb per node plotted response times sizeup figure 5 sizeup response time normalized respect response time 25mb per node results show sublinear performance count algorithm program actually efficient database size increased since results change database size increases neither amount cost communication increasing size database simply makes noncommunication portion code take time due io transaction processing result reducing percentage overall time spent communication since io cpu processing scale perfectly sizeup get sublinear performance scaleup relative scaleup5001500250035004500 response time number processors scaleup number processors sizeup relative sizeup200060001000014000 response time amount data per node mb sizeup amount data per node mb speedup relative speedup200060001000014000 response time number processors number processors figure 5 performance count distribution response time hash filter count figure effect hash filtering speedup last set experiments kept database constant varied number processors constraint available disk space size three databases fixed 400mb figure 5 shows results running count algorithm configurations 16 processors run larger configurations amount data node becomes small speedup figure response time normalized respect response time single processor graphs show count good speedup performance performance however begin fall short ideal 8 processors artifact small amount data node processing 25mb per node communication times become significant percentage overall response time easily predicted sizeup experiments noticed data node processes less significant becomes communication time giving us better performance simply seeing opposite effect larger datasets would shown even better speedup characteristics 43 effect hash filtering recently park chen yu 9 proposed use hash filter reduce cost apriori particularly second pass reducing size c 2 basic idea build hash filter tuples read first pass every 2itemset present tuple count incremented corresponding hash bucket thus end pass upperbound support count every 2itemset present database generating c 2 using l 1 candidate itemsets hashed candidate whose support count hash table less minimum support deleted figure 6 compares combined response times pass 1 2 count algorithm hash filter algorithm times remaining passes identical count algorithm beats hash filter count never explicitly forms c 2 rather uses specialized version hashtree done 3 since nothing c 2 pruned apriori candidate generation algorithm equal l 1 theta l 1 c 2 thus represented simple twodimensional count array drastically reducing memory requirements function call overhead savings using hash filter prune c 2 lost due cost constructing hash filter use regular hashtree storing counting c 2 parallel version hash filter algorithm called pdm presented 10 along performance results simulation study uses parallelization technique similar count except entire candidate sets exchanged rather candidate counts expensive communication cpu costs focus pdm efficient construction hashfilter used serial algorithm speed pass two however serial algorithm hashfilter actually hurts performance resulting double performance hit pdm conclusions considered problem mining association rules sharednothing multiprocessor data partitioned across nodes presented three parallel algorithms task based upon apriori best serial algorithms mining association rules designs algorithms represent spectrum tradeoffs computation communication memory usage synchronization use problemspecific information count distribution algorithms attempts minimize communication replicating candidate sets processors memory processors work local data communicate counts data distribution algorithm takes counter approach processor works entire dataset portion candidate set maximizes use aggregate memory requires high communication broadcast data minimizing communication may best approach workstation cluster environment necessarily true sp2 lastly candidate algorithm incorporates domainknowledge partition data candidates allowing processor work unique set candidates without repeatedly broadcast entire dataset maximizes use aggregate memory limiting heavy communication single redistribution pass also completely eliminates synchronization costs count data must pay end every pass studied tradeoffs evaluated relative performance three algorithms implementing 32node sp2 parallel machine count distribution emerged algorithm choice exhibited linear scaleup excellent speedup sizeup behavior using n processors overhead less 75 compared response time serial algorithm executing 1n amount data data distribution algorithm lost cost broadcasting local data processor every processor results show even highbandwidthlowlatency system sp2 data redistribution still costly candidate distribution algorithm similarly edged cost data redistribution gains processor work independently different subset problem could make single pass redistribution may disheartening learn carefully designed algorithm candidate beaten relatively simpler algorithm like count least illuminate fact problems require intricate parallelization exploring various possibilities shown true mining association rules acknowledgments maurice houtsma implemented parallel version associationrule mining algorithm presented 1 earlier version ibm powerparallel system called sp1 nodes diskless data funneled master node although could use implementation changes architecture communication library basic algorithm benefited experience howard ho provided us early prototype implementation mpi communication library get us going ramakrishnan srikant patiently explained many nuances serial apriori implementation discussions mike carey influential initial stages work finally several sp organization particularly hieronymous sharon selzo bob walkup wonderful help arranging sp cycles tests r mining association rules sets items large databases parallel mining association rules design fast algorithms mining association rules message passing interface forum discovery multiplelevel association rules large databases scalable powerparallel systems efficient algorithms discovering association rules effective hash based algorithm mining association rules efficient parallel data mining association rules efficient algorithm mining association rules large databases mining generalized association rules tr ctr hongjun lu ling feng jiawei han beyond intratransaction association analysis mining multidimensional intertransaction association rules acm transactions information systems tois v18 n4 p423454 oct 2000 mohammed j zaki neal lesh mitsunori ogihara planmine predicting plan failures using sequence mining artificial intelligence review v14 n6 p421446 december 1 2000 canasai kruengkrai chuleerat jaruskulchai parallel learning algorithm text classification proceedings eighth acm sigkdd international conference knowledge discovery data mining july 2326 2002 edmonton alberta canada takahiko shintani masaru kitsuregawa parallel mining algorithms generalized association rules classification hierarchy acm sigmod record v27 n2 p2536 june 1998 robert grossman yike guo data mining tasks methods parallel methods scaling data mining algorithms large data sets handbook data mining knowledge discovery oxford university press inc new york ny 2002 assaf schuster ran wolff communicationefficient distributed mining association rules data mining knowledge discovery v8 n2 p171196 march 2004 dora souliou aris pagourtzis nikolaos drosinos panayiotis tsanakas computing frequent itemsets parallel using partial support trees journal systems software v79 n12 p17351743 december 2006 min song ilyeol song xiaohua hu robert b allen integration association rules ontologies semantic query expansion data knowledge engineering v63 n1 p6375 october 2007 assaf schuster ran wolff communicationefficient distributed mining association rules acm sigmod record v30 n2 p473484 june 2001 mohammed j zaki srinivasan parthasarathy mitsunori ogihara wei li parallel algorithms discovery association rules data mining knowledge discovery v1 n4 p343373 december 1997 valerie guralnik george karypis parallel treeprojectionbased sequence mining algorithms parallel computing v30 n4 p443472 april 2004 riedel christos faloutsos gregory r ganger david f nagle data mining oltp system nearly free acm sigmod record v29 n2 p1321 june 2000 raymond ng laks v lakshmanan jiawei han alex pang exploratory mining pruning optimizations constrained associations rules acm sigmod record v27 n2 p1324 june 1998 masaru kitsuregawa masashi toyoda iko pramudiono web community mining web log mining commodity cluster based execution australian computer science communications v24 n2 p310 januaryfebruary 2002 massimo coppola marco vanneschi parallel distributed data mining parallel skeletons distributed objects data mining opportunities challenges idea group publishing hershey pa steve c chiu weikeng liao alok n choudhary mahmut kandemir processorembedded distributed smart disks iointensive workloads architectures performance models evaluation journal parallel distributed computing v64 n3 p427446 march 2004 shichao zhang chengqi zhang jeffrey xu yu efficient strategy mining exceptions multidatabases information sciences international journal v165 n12 p120 3 september 2004 asif javed ashfaq khokhar frequent pattern mining message passing multiprocessor systems distributed parallel databases v16 n3 p321334 november 2004 wenchih peng mingsyan chen developing data allocation schemes incremental mining user moving patterns mobile computing system ieee transactions knowledge data engineering v15 n1 p7085 january ning x sean wang sushil jajodia discovering calendarbased temporal association rules data knowledge engineering v44 n2 p193218 february ruoming jin ge yang gagan agrawal shared memory parallelization data mining algorithms techniques programming interface performance ieee transactions knowledge data engineering v17 n1 p7189 january 2005 jiawei han yongjian fu mining multiplelevel association rules large databases ieee transactions knowledge data engineering v11 n5 p798805 september 1999 steve c chiu weikeng liao alok n choudhary mahmut kandemir processorembedded distributed smart disks iointensive workloads architectures performance models evaluation journal parallel distributed computing v65 n4 p532551 april 2005 shengnan cong jiawei han jay hoeflinger david padua samplingbased framework parallel data mining proceedings tenth acm sigplan symposium principles practice parallel programming june 1517 2005 chicago il usa steve c chiu weikeng liao alok n choudhary distributed smart disks iointensive workloads switched interconnects future generation computer systems v22 n5 p643656 april 2006 gregory buehrer yenkuang chen srinivasan parthasarathy anthony nguyen amol ghoting daehyun kim efficient pattern mining shared memory systems implications chip multiprocessor architectures proceedings 2006 workshop memory system performance correctness october 2222 2006 san jose california gregory buehrer srinivasan parthasarathy shirish tatikonda tahsin kurc joel saltz toward terabyte pattern mining architectureconscious solution proceedings 12th acm sigplan symposium principles practice parallel programming march 1417 2007 san jose california usa assaf schuster ran wolff dan trock highperformance distributed algorithm mining association rules knowledge information systems v7 n4 p458475 may 2005 christopher r lumb jiri schindler gregory r ganger david f nagle erik riedel towards higher disk head utilization extracting free bandwidth busy disk drives proceedings 4th conference symposium operating system design implementation p77 october 2225 2000 san diego california wei li ari mozes computing frequent itemsets inside oracle 10g proceedings thirtieth international conference large data bases p12531256 august 31september 03 2004 toronto canada laks v lakshmanan carson kaisang leung raymond ng segment support map scalable mining frequent itemsets acm sigkdd explorations newsletter v2 n2 p2127 dec 2000 amol ghoting gregory buehrer srinivasan parthasarathy daehyun kim anthony nguyen yenkuang chen pradeep dubey cacheconscious frequent pattern mining modern emerging processors vldb journal international journal large data bases v16 n1 p7796 january 2007 frans coenen paul leng partitioning strategies distributed association rule mining knowledge engineering review v21 n1 p2547 march 2006 carson kaisang leung quamrul khan boyu hao distributed mining constrained patterns wireless sensor data proceedings 2006 ieeewicacm international conference web intelligence intelligent agent technology p248251 december 1822 2006 masahisa tamura masaru kitsuregawa dynamic load balancing parallel association rule mining heterogenous pc cluster systems proceedings 25th international conference large data bases p162173 september 0710 1999 david w cheung yongqiao xiao effect data distribution parallel mining associations data mining knowledge discovery v3 n3 p291314 september 1999 euihong han george karypis vipin kumar scalable parallel data mining association rules acm sigmod record v26 n2 p277288 june 1997 riedel garth gibson christos faloutsos active storage largescale data mining multimedia proceedings 24rd international conference large data bases p6273 august 2427 1998 flip korn alexandros labrinidis yannis kotidis christos faloutsos ratio rules new paradigm fast quantifiable data mining proceedings 24rd international conference large data bases p582593 august 2427 1998 ling feng jeffrey xu yu hongjun lu jiawei han template model multidimensional intertransactional association rules vldb journal international journal large data bases v11 n2 p153175 october 2002 h ravi sankar naidu innovative algorithm mining multilevel association rules proceedings 25th conference proceedings 25th iasted international multiconference artificial intelligence applications p307310 february 1214 2007 innsbruck austria john holt soon chung parallel mining association rules text databases journal supercomputing v39 n3 p273299 march 2007 congnan luo anil l pereira soon chung distributed mining maximal frequent itemsets data grid system journal supercomputing v37 n1 p7190 july 2006 r j kuo lin c w shih mining association rules integration clustering analysis ant colony system health insurance database taiwan expert systems applications international journal v33 n3 p794808 october 2007 distributed higher order association rule mining using information extracted textual data acm sigkdd explorations newsletter v7 n1 p2635 june 2005 mohammed j zaki scalable algorithms association mining ieee transactions knowledge data engineering v12 n3 p372390 may 2000 tahsin kurc mustafa uysal hyeonsang eom jeff hollingsworth joel saltz alan sussman efficient performance prediction largescale dataintensive applications international journal high performance computing applications v14 n3 p216227 august 2000 david w cheung kan hu shaowei xia adaptive algorithm mining association rules sharedmemory parallel machines distributed parallel databases v9 n2 p99132 march 2001 mohammed javeed zaki srinivasan parthasarathy wei li localized algorithm parallel association mining proceedings ninth annual acm symposium parallel algorithms architectures p321330 june 2325 1997 newport rhode island united states yenliang chen shihsheng chen pingyu hsu mining hybrid sequential patterns sequential rules information systems v27 n5 p345362 july 2002 david w cheung kan hu shaowei xia asynchronous parallel algorithm mining association rules sharedmemory multiprocessors proceedings tenth annual acm symposium parallel algorithms architectures p279288 june 28july 02 1998 puerto vallarta mexico jian tang using incremental pruning increase efficiency dynamic itemset counting mining association rules proceedings seventh international conference information knowledge management p273280 november 0207 1998 bethesda maryland united states sung zhao li chew l tan peter ng forecasting association rules using existing data sets ieee transactions knowledge data engineering v15 n6 p14481459 november sunita sarawagi shiby thomas rakesh agrawal integrating association rule mining relational database systems alternatives implications acm sigmod record v27 n2 p343354 june 1998 qing li ling feng allan wong intratransaction generalized intertransaction landscaping multidimensional contexts association rule mining information sciencesinformatics computer science international journal v172 n34 p361395 9 june 2005 jianchao han nick cercone xiaohua hu interactive visualization system mining association rules data mining rough sets granular computing physicaverlag gmbh heidelberg germany 2002 antonin rozsypal miroslav kubat association mining timevarying domains intelligent data analysis v9 n3 p273288 may 2005 ferenc kovcs sndor juhsz performance evaluation distributed association rule mining algorithms proceedings 4th wseas international conference software engineering parallel distributed systems p16 february 1315 2005 salzburg austria xindong wu shichao zhang synthesizing highfrequency rules different data sources ieee transactions knowledge data engineering v15 n2 p353367 february sunita sarawagi shiby thomas rakesh agrawal integrating association rule mining relational database systems alternatives implications data mining knowledge discovery v4 n23 p89125 july 2000 lin z kedem efficient algorithm discovering maximum frequent set ieee transactions knowledge data engineering v14 n3 p553566 may 2002 edward r omiecinski alternative interest measures mining associations databases ieee transactions knowledge data engineering v15 n1 p5769 january ron kohavi llew mason rajesh parekh zijian zheng lessons challenges mining retail ecommerce data machine learning v57 n12 p83113 octobernovember 2004 ruoming jin gagan agrawal methodology detailed performance modeling reduction computations smp machines performance evaluation v60 n14 p73105 may 2005 kubat searching highsupport itemsets itemset trees intelligent data analysis v10 n2 p105120 march 2006 caiyan jia xieping gao multiscaling sampling adaptive sampling method discovering approximate association rules journal computer science technology v20 n3 p309318 may 2005 laks v lakshmanan carson kaisang leung raymond ng efficient dynamic mining constrained frequent sets acm transactions database systems tods v28 n4 p337389 december miroslav kubat alaaeldin hafez vijay v raghavan jayakrishna r lekkala wei kian chen itemset trees targeted association querying ieee transactions knowledge data engineering v15 n6 p15221534 november euihong sam han george karypis vipin kumar scalable parallel data mining association rules ieee transactions knowledge data engineering v12 n3 p337352 may 2000 mara c fernndezbaizn ernestina menasalvas ruiz juan fransisco martnez sarras reduction discriminant rules based frequent item set calculation new learning paradigms soft computing physicaverlag gmbh heidelberg germany 2002 maniatty mohammed j zaki systems support scalable data mining acm sigkdd explorations newsletter v2 n2 p5665 dec 2000 peiyi tang li ning ningning wu domain data partitioning parallel mining frequent closed itemsets proceedings 43rd annual southeast regional conference march 1820 2005 kennesaw georgia mohammed j zaki parallel distributed association mining survey ieee concurrency v7 n4 p1425 october 1999 dejiang jin sotirios g ziavras superprogramming approach mining association rules parallel pc clusters ieee transactions parallel distributed systems v15 n9 p783794 september 2004 jihye kim sihui zhao steffen heber finding association rules cisregulatory elements involved alternative splicing proceedings 45th annual southeast regional conference march 2324 2007 winstonsalem north carolina jack dongarra ian foster geoffrey fox william gropp ken kennedy linda torczon andy white references sourcebook parallel computing morgan kaufmann publishers inc san francisco ca p deepa shenoy k g srinivasa k r venugopal lalit patnaik dynamic association rule mining using genetic algorithms intelligent data analysis v9 n5 p439453 september 2005 claudio silvestri salvatore orlando distributed approximate mining frequent patterns proceedings 2005 acm symposium applied computing march 1317 2005 santa fe new mexico massimo coppola marco vanneschi highperformance data mining skeletonbased structured parallel programming parallel computing v28 n5 p793813 may 2002 mohammad elhajj osmar r zaane parallel bifold largescale parallel pattern mining constraints distributed parallel databases v20 n3 p225243 november 2006 vipin kumar mohammed zaki high performance data mining tutorial pm3 tutorial notes sixth acm sigkdd international conference knowledge discovery data mining p309425 august 2023 2000 boston massachusetts united states xun yi yanchun zhang privacypreserving distributed association rule mining via semitrusted mixer data knowledge engineering v63 n2 p550567 november 2007