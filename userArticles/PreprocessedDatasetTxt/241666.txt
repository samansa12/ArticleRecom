parallel divide conquer meshes abstractwe address problem mapping divideandconquer programs mesh connected multicomputers wormhole storeandforward routing propose binomial tree efficient model parallel divideandconquer present two mappings binomial tree 2d mesh mappings exploit regularity communication structure divideandconquer computation also sensitive underlying flow control scheme target architecture evaluate mappings using new metrics extensions classical notions dilation contention introduce notion communication slowdown measure total communication overhead incurred parallel computation conclude significant performance gains realized mapping sensitive flow control scheme target architecture b introduction wellknown problemsolving paradigm occurs many computations divideand conquer subproblems independent may executed parallel makes useful paradigm designing large scale parallel programs divideandconquer studied many researchers 7 2 3 13 14 applicable wide range applications paper address problem mapping degree two divide conquer computations twodimensional meshes represent computations binomial tree show runs phase phase manner regular pattern times messages sent addition message volumes also exhibit regularity one goals exploit aspects regularity topological temporal message volume still develop parameterized mappings family graphs rather single graph present two mappings called reflecting mapping growing mapping embedding divideandconquer binomial tree mesh addition exploiting regularity binomial tree mappings sensitive flowcontrol technology target machine furthermore evaluate mappings using new cost functions extensions standard contention dilation metrics used embedding literature consider four pragmatic caseswhether communication volumes significantly larger smaller startup overhead whether routing mechanism wormhole storeandforward remainder paper organized follows section 2 discusses related work section 3 describes regular structure divideandconquer computations present mappings section 4 describe new performance metrics section 5 section 6 presents analysis conclude discussion indication future work related work divide conquer model widely recognized effective parallel programming paradigm 14 7 recently algebraic theory developed provide general framework describe class computations mapping class algorithms hypercubelike architectures also discussed mou hudak 13 keep half send half strategy improve efficiency divide conquer algorithm observed 7 2 however model formalized underlying binomial tree structure recognized papers 11 spanning binomial tree hypercube used achieve efficient broadcasting 17 htree embedding proposed embed complete binary tree mesh embedding requires slightly larger mesh graph embedding techniques usually used emulate machine one topology machine different topology 15 17 maximum dilation contention used two major metrics measure embedding context mapping parallel program modeled static task graph 16 4 approach usually used assign tasks processors 4 however argued paper approach ignores temporal aspect computation underlying communication technique example well recognized wormholerouted circuit switching multicomputer network distance effect compared effect message collision negligible message latency 10 8 5 much work done analytically model network different routing schemes 12 8 1 however models based assumptions message distribution thus accurate specific application work complements studies gives important metrics developing mapping onto network storeandforward wormhole communication technology 3 divide conquer binomial trees traditional task graph structure degree2 divide conquer algorithm complete binary tree cbt n 2 leaves however cbt efficient since computation proceeds root leaves back tree level level manner time nodes given level active well known folklore noted many authors 2 7 obvious way improve performance use keep half send half strategy outlined parameter ff used step 2 assume 0 ff 1 denotes message size phase fraction incoming message node tree performs following computation 1 receive problem size x parent host node root 2 solve problem locally small enough divide problem two parts size ffx spawn child process solve one parallel start solving one repeating step 2 3 get results children combine repeat childrens results combined 4 send results parent host node root two stages computationdivide step 2 combine step 3 note divide stage node receives message parent exactly may send messages multiple times child process spawned combine stage message traffic opposite directiona node may receive many times sends exactly patterns data flow two stages identical except direction therefore restrict analysis divide stage without loss generality also normalize analysis volume message sent root initial problem size unity figure 1 binomial tree definition example b 4 parameter ff described serve completely define communication volumes occur divide conquer paradigm edge weights expressed terms ff phase moreover ff natural parameter users point view two common values corresponds uniform traffic occurs leader election broadcasting data value combine stage associativecommutative operation message volume halved phase occurs mergesort data distribution etc also many problems different value may occur common example solving graph problem decomposing graph two graphs half number vertices assuming messages passed children consist adjacency matrix 1note even single algorithm message volumes may different divide stage combine stage multiplying sequence n theta n matrices example ff 1in divide mode 1 combine mode show graph corresponding keep half send half strategy binomial tree 1 binomial tree bn defined inductively follows 18 see fig 1 ffl b0 single node edges ffl bn consists two copies bn gamma 1 together edge connecting roots one designated root bn note subtree rooted node binomial tree moreover root bn n children turn roots see fig 1 use convention children node arranged decreasing order size thus ith child root node root bn gamma adopt postorder labelling tree shown fig 1 lemma 1 computation graph keep half send half paradigm divide conquer n divide phases binomial tree bn proof let cn graph corresponding keep half send half c0 b0 onenode graphs hence identical establish lemma showing cn bn equivalent iterative definitions definition cn obtained taking cn gamma 1 nodes creating new node adjacent show induction bn constructed way since b0 single node b1 consists two nodes single edge base case holds assume inductively bn constructed adding leaf every node bn gamma 1 definition bn consists two copies bn gamma 1 edge e connecting roots adding leaf every node bn thus amounts adding leaf every node copies bn gamma 1 inductive assumption creates two copies bn roots still connected edge e resulting graph corresponds definition addition topological properties communication divide conquer algorithms described important accurately determine varies time particular would like specify exactly given edge active weight using binomial tree bn model computation total n communication phases numbered 1 n mentioned restrict attention divide stage computation every node receives message exactly say node activated receiving message say phase remaining phases node activate new child initially root receives message size 1 host constituting entire problem solved phase 1 root sends message volume ff first child thereby activating phase active nodes sending message volume ff child 4 mappings binomial tree 2d mesh present two mappings bn mesh size 2 b nc theta 2 ne mesh either square aspect ratio two mappings 11 mappings ie node binomial tree mapped distinct node mesh 1 first mapping uses definition 1 bn called reflecting mapping second mapping uses definition bn arises lemma 1 called growing mapping mappings adjacent binomial tree nodes mapped mesh nodes row column thus edges mapped shortest path connecting endpoints mappings completely specified node mapping definition 2 reflecting mapping mr defined inductively followssee figure 2 ffl b0 single node binomial tree mapped single node mesh ffl constructed taking two copies mr b2k placing second copy reflected vertical axis right first one roots two copies b2k must lie row connected root new reflected copy root bn ffl constructed taking two copies mr b2k gamma 1 placing second copy reflected horizontal axis first one roots two copies b2k gamma 1 must lie column connected root reflected copy root bn see reflecting mapping excellent performance machines wormhole routing storeandforward networks reason develop growing mapping mg uses fact shown lemma 1 binomial tree also viewed copy bn gamma 1 every node new leaf node added definition 3 growing mapping mg defined inductively follows see figure 3 restriction justified since size binomial tree controlled adjusting amount work performed leaf nodes figure 2 reflecting mapping mr square node root ffl b0 b1 b2 mg mr ffl mapped bn gamma 1 leaf nodes grown horizontally parent uniform dilation thus node eastern western half bn gamma 1 gets leaf placed row distance 2 kgamma2 east west ffl nodes mapped bn gamma 1 leaves grown vertically parent uniform dilation thus node northern southern half bn gamma 1 gets leaf placed column distance 2 kgamma2 north south figure 3 growing mapping mg square node root 5 new metrics performance evaluation section develop new metrics evaluating mapped parallel computation metrics extensions classic graph theoretic metrics congestion dilation taking account 1 distinct message passing phases 2 volume communication associated message also define notion communication slowdown measures amount communication overhead incurred specific mapping relative incurred perfect mapping derive formulae communication slowdown two flow control schemes wormhole storeandforward two ranges message volumes startup costs dominate message volumes dominate formulae developed contention free mappings new metrics assume two edges contend active phase realistic view classic graph theoretic notion contention shall show holds growing mapping storeand forward routing reflecting mapping flow control schemes general formulae arbitrary mappings subject ongoing work beyond scope paper mapping problem typically uses well known static task graph model stone 16 bokhari 4 parallel computation viewed weighted graph target machine graph mapping formally specified two functions n e asterisk denotes kleene star provided e ha bi 2 ec e e path n n b typically one seeks mapping minimizes communication overhead maintaining balanced load past metrics used evaluate mappings use following traditional notions dilation contention 15 17 definition 4 dilation de edge e 2 ec jm e ej ie length path e mapped dilation dec mapping given de definition 5 contention cl link l 2 ea jfe 2 ec jl 2 e egj ie number edges gc mapped paths containing l contention cec mapping given l2ea cl dilation reflects communication overhead caused messages traverse multiple links contention reflects communication overhead arises two messages require link mentioned interested phased computations operate fol lows ith phase nodes subset v vc perform computation messages sent edges belong e ec assume loosely synchronous model tasks assumed synchronize phase call phased computation graph special case uniform phased graph edge weights uniform refine definitions dilation realistically reflect 1 phasewise behavior 2 nonuniform edge weights define functions either individual edge e active ith phase edges ith guide notation function set edges maximum value elements set example w e weight single edge weight heaviest edge ith phase definition 6 ith phase interference set ie edge e consists edges e also use link used e ie e g path level contention introduced chittor 6 similar notion except deal phased computations definition 7 edge e weighted dilation dw e product weight length path mapped ie dw mapping ith phase weighted dilation defined maximum weighted dilation edges phase dw dw e edge e ith phase weighted contention cw e sum weights edges ith phase interference set cw mapping ith phase weighted contention cw defined maximum ith phase weighted contention edges phase cw cw e special case arises computation uniform ie w dw de also cw jiej indicate uniform metrics dropping subscript w denote communication time edge e accounting delays due path length congestion communication time ith phase largest time edges phase remember model assumes synchronization phases ie total communication time computation ec sum phases ie ec definition 9 mapping p said perfect minimum dilation minimum contention note dilation contention minimized task graph gc subgraph target ga gives us lower bound optimal cost mapping define notion communication slowdown normalizing total communication time mapping respect total communication time perfect mapping given mapping communication slowdown sm defined ratio total communication cost cost perfect mapping 51 formulae communication slowdown derive formulae total communication time ec mapped compu tation recall paper make simplifying assumption contention show section 6 assumption valid analysis mentioned earlier consider two different flow control schemes target machine namely wormhole routing storeandforward routing also consider two cases message traffic large volume message size dominant factor small volume startup costs dominate 511 wormhole routing consider single edge e 2 ec isolation wormhole routing message consists stream flits routed network minimal buffering pipelined fashion thus absence contention time message takes travel one processor another path length given 11 c startup cost 1b bandwidth h flit size usually 1 2 bytes large messages w e ae dh bw e ae c hand small messages bw bdh case also reasonable assume c ae bdh note term corresponds additional volume dh order tens bytes order magnitude smallest messages system note distance longer relevant observed 9 estimated communication time ith phase c small volume weight heaviest edge phase thus total communication time mapping k phases assuming contention follows ck small volume note formula applies contention free mapping including perfect mapping thus communication slowdown contention free mapping target machine wormhole routing 512 store forward routing storeandforward routing message decomposed sequence messages one hop along path thus absence contention communication time single message traverse distance c per node overhead cost 1b bandwidth following extreme cases small volume bdew e large volume small volume bdw e large volume obtain communication time mapping follows small volume dw e large volume c note conventional dilation metrics used phasewise additive sense perfect mapping dilation always 1 ck small volume thus communication slowdown large volume contention free mapping target machine storeandforward routing 6 performance analysis analyze two mappings presented sec 4 respect new metrics first show reflecting mapping optimal wormhole routing true mapping contention free sense two edges phase simultaneously active also show growing mapping also contention routing case contention communication pipelined lockstep manner hence formulae applicable compare communication slowdown metrics mappings storeandforward routing show growing mapping superior performance 61 reflecting mapping wormhole routing lemma 2 reflecting mapping mr bn edges using link never active phase thus cw contention free proof prove showing induction n edges using link never active phase b0 communication assume claim holds bn consists two copies bn gamma 1 edge e connecting roots two copies mr two edges separate copies bn gamma 1 share links hence inductive assumption claim holds edges copies edge e active first phase active edge phase hence claim holds bn theorem 1 reflecting mapping wormhole routing mr bn communication 1 thus reflecting mapping optimal proof fact follows directly lemma 2 equation 5 communication slowdown contention free mapping wormhole machine 62 reflecting mapping storeandforward routing section next omit two constants c b formulas total communication time mapping see equation 8 multiplicative constants ultimately cancel formulas communication slowdown first establish maximum weighted dilation dw lemma 3 maximum weighted dilation reflecting mapping phase ff proof already argued weights edges phase ff note regularity mapping implies de represents dilation edge phase consider fig 4 shows reflecting mapping b2k 2 k theta 2 k mesh b2k rooted largest subtree rooted f note alternate horizontal vertical reflections give de 2k intermediate goal show recurrence figure 4 mapping corresponds remains show easily shown root b2k always mapped main diagonal mesh topleft bottomright root b2k gamma 1 diagonal bottomleft topright thus symmetry reflection ef last equality together easy geometrical argument solution recurrence 11 using standard textbook techniques multiplied ff establishes lemma even odd already argued de lemma 4 communication time perfect mapping tp ec follows directly fact edge weights binomial tree constitute geometric series also sum geometric series whose solution summarized following lemma focus common cases 5 total communication time reflecting mapping b2k store andforward machines given tmr ec b tmr ec even respectively c tmr ec 1substituting equation 12 equation 10 following theorem 2 storeandforward routing reflecting mapping b2k slow large volume case large volume case case 63 growing mapping storeandforward routing first establish maximum weighted dilation dw growing mapping mg also show contention free lemma 6 phases 1 2 mg weighted dilation ff ff 2 respectively phase proof definition mg dilation 1 phases 1 2 phase dilation edge 2 iegamma2 volume edge ff lemma 7 storeandforward growing mapping contention since phase cw proof phases 1 2 3 4 messages mg dilation 1 thus clearly contention messages ith phase 4 volume two messages compete link simultaneously see consider single message interference set routed along single row column mesh see dotted edges figure 3 lockstep fashion messages set sent without interference 2 iegamma2 steps every message moving one hop closer destination step thus contention growing mapping storeandforward case cw reflecting mapping b2k tmg ec whose solution summarized next lemma lemma 8 total communication time growing mapping b2k store andforward machines given tmg ec pwhere c b tmg ec c tmg ec case denominator substituting equation 12 equation 10 following theorem 3 storeandforward routing growing mapping b2k slowdown large volume case assymptotically approaching 1125 large volume case 64 comparison compare two mappings following theorem follows comparing lemmas theorems preceding sections theorem 4 wormhole routing ff reflecting mapping optimal whereas growing mapping contention phase storeandforward routing small large volume cases growing mapping b2k outperforms reflecting mapping b2k 0 ff 1 k 2 k 2 mappings optimal storeandforward routing small volume case ff large volume case growing mapping 25 less communication time reflecting mapping number phases increases storeandforward routing large volume case 05 growing mapping outperforms reflecting mapping factor exponential number phases 7 conclusion paper presented two algorithms mapping binomial tree divide andconquer computation 2d mesh mapping algorithms exploit regularity topological communication structure binomial tree well regularity communication phases divide conquer binomial tree addition mapping algorithms sensitive topological structure 2d mesh underlying flowcontrol scheme supported target machine storeandforward routing versus wormhole routing developed new performance metric called communication slowdown evaluation communication overhead incurred phased computation mapped multicomputers evaluation two mappings respect communication slowdown shows reflecting mapping optimal wormhole routing growing mapping close optimal wide range message volumes mesh sizes ongoing work area includes validation analysis reflecting growing mappings simulation extensions case medium size messages computations different ff values divide conquer phases development validation completion time communication slowdown metrics applicable arbitrary mappings wider range parallel computations r limits network performance vector models dataparallel computing assignment problems parallel distributed computing communication overhead intel ipsc860 hypercube communication performance multicomputers algorithmic skeletons structured management parallel computation performance analysis kary ncube interconnection networks performance intel ipsc860 ncube 6400 hypercubes performance programming ametek series 2010 multicomputer communication network architectures virtual new computer communication switching technique algebraic model divideandconquer algorithms parallelism programming paradigms nonshared memory parallel computers graph embeddings multiprocessor scheduling aid network flow algorithms computational aspects vlsi data structure manipulating priority queues tr ctr ali karci generalized parallel divide conquer 3d mesh torus journal systems architecture euromicro journal v51 n5 p281295 may 2005 yuhshyan chen chaoyu chiang cheyi chen multinode broadcasting allported 3d wormholerouted torus using aggregationthendistribution strategy journal systems architecture euromicro journal v50 n9 p575589 september 2004