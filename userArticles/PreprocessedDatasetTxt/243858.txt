profiledriven instruction level parallel scheduling application super blocks code scheduling exploit instruction level parallelism ilp critical problem compiler optimization research light increased use longinstructionword machines unfortunately optimum scheduling computationally intractable one must resort carefully crafted heuristics practice scope application scheduling heuristic limited basic blocks considerable performance loss may incurred block boundaries overcome obstacle basic blocks coalesced across branches form larger regions super blocks literature regions typically scheduled using algorithms either oblivious profile information assumption process forming region fully utilized profile information use profile information addendum classical scheduling techniques believe even simple case linear code regions super blocks additional performance improvement gained utilizing profile information scheduling well propose general paradigm converting profileinsensitive list scheduler profilesensitive scheduler technique developed via theoretical analysis simplified abstract model general problem profiledriven scheduling acyclic code region yielding scoring measure ranking branch instructions b introduction performance vliw machine depends strongly ability compiler exploit instruction level parallelism ilp programs unfortunately task compiler made difficult presence number intractable optimization problems instruction scheduling register allocation paper study one problem scheduling profile information believe results serve good starting point developing practical heuristics included compilers vliw machines evidence present experimental results validating heuristics suggested analysis basic block program fragment may entered top exited bottom precedence graph single basic block directed acyclic graph dag 2 practice typically consists fewer vertices scheduling small basic blocks consecutively separately leads underutilization functional units due sequentialization effects block bound aries overcome limitation two broad approaches proposed one called ifconversion eliminates branches via hardware support predicated execution allowing instructions moved outside basic blocks see 4 instance approach require hardware support involves formation larger code regions traces 7 super blocks 14 super block consists sequence basic blocks strung together conditional exits branch points separate basic blocks super blocks typically formed follows given code region branch probabilities available branch region probabilities obtained profiling collecting usage statistics code executed starting entry point code region follow dominant fork branch certain branch probability reaching branch start falls certain threshold level terminate path alternatively neither fork branch predom inant terminate path chain basic blocks along path traced manner super block delete chain basic blocks defining super block code region repeat process modified portion since basic blocks deleted might entries blocks code region blocks must duplicated modified region process called tail duplication clear amount tail duplication affect size overall code thereby affecting performance face fixed instruction cache sizes light threshold parameters defining notion predominance empirically determined outside scope paper much literature scheduling ignores profile formation assumption region formation algorithm fully digested profile information stance super blocks typically scheduled heuristics oblivious profile information although techniques use profile information addendum classical scheduling techniques eg speculative yield technique 3 following 7 example 1 examines several techniques region formation algorithms become sophisticated produce nonlinear code regions encompassing balanced branches less effective digesting profile information result increasingly important coderegion annotated profile information scheduling technique effectively utilize profile information believe paper offers first step direction one might argue would better tackle problem profile driven scheduling first principles treating general code regions rather processed code regions super blocks however two good reasons restricting study processed regions 1 see shortly profiledriven scheduling generic code regions computationally intractable impractical unless number branches region small say fewer 16 2 tail duplication formation simpler regions super blocks often exposes instruction level parallelism extant generic code region thus legitimate goal study good scheduling heuristics even limited case super blocks wenow make precise abstraction general problem scheduling profile information given directed acyclic precedence graph derived source program described vertex graph represents operation specified execution time time required execute vertex also carries weight w weight w probability program exits vertex words w probability portion precedence graph rooted vertex needs computed ie vertices upon vertex depends need computed assume target machine functional units schedule vertices graph functional units achieve lowest cost ie shortest weighted execution time specifically find schedule minimize finish time operation start time general problem every node weight shown nphard even permit arbitrary precedence constraints operations 9 15 problem polynomially solvable precedence graph forest 12 generalized seriesparallel graph 1 15 1 problem nphard even without precedence constraints unless weights identical case polynomially solvable hand problem strongly nphard even weights identical precedence graph collection chains 5 light intractable nature problem adopt standard approach designing approximation algorithms bounded performance ra tio performance ratio approximation algorithm defined worstcase ratio cost approximate solution optimal solution begin general lemma shows construct optimal sequential schedule general precedence graph weights construction lemma efficiently exploited two restricted versions problem case precedence graph tree ie vertex exactly one outgoing edge sgraph case weights nonzero single path sgraph defined formally next section abstraction super block show using optimal sequential schedule list drive list scheduling algorithm multiple functional units guarantees performance ratio 2 finally heuristic extension basic lemma present generic scheme converting list scheduling algorithm insensitive profile information scheduling algorithm super blocks sensitive profile information cannot show tight performance guarantees heuristic present experimental results number sample super blocks obtained applying impact compiler spec benchmark programs report significant savings possible compared prior methods example 1 consider precedence graph figure 1 precedence graph super block three branch vertices vertices 3 7 and28 marked figure probability program exit via vertex 3 01 similarly probability exit via vertices 7 28 03 06 respectively assume given nonpipelined processor two identical functional units operations latency one cycle schedule graph processor three ways first carry critical path scheduling equivalent pr1 pr6 figure 1 precedence graph super block vertex corresponds unit latency op eration probability labels branch exits graph probabilities exits taken list scheduling distance last exit vertex 28 list priority table 1 shows schedule would obtain case along expected finish time schedule secondly schedule using speculative yield priorities 3 priority vertex weighted sum longest path length exit weight probability exit taken list vertices sorted descending order priority list scheduling table 2 shows schedule would obtain case better expected finish time scheduling critical path last exit lastly construct list schedule seeks retire exit order earliest possible time described call successive retirement scheduling construct priority list based critical path prior ity vertices preceding inclusive earliest exit vertex 3 figure delete vertices list graph iterate procedure graph consumed appending order lists created iteration listschedule using list created table 3 shows schedule would obtain case along table 1 list schedule super block figure 1 two functional unit machine using critical path last exit list exits marked expected completion cycles table 2 speculative yield schedule super block figure 1 two functional unit machine exits marked expected completion cycles fu1 22 23 24 25 26 27 28 table 3 successive retirement list schedule super block figure 1 two functional unit machine exits marked expected completion cycles expected finish time schedule although successive retirement schedule ignored profile information completely lowest finish time three schedules 2 theoretical results e denote precedence graph sink graph vertex outgoing edges assume without loss generality graph exactly one sink since easily ensure addition dummy vertex inedges sinks given graph vertex assigned weight w let p path source sink precedence graph g define notion sgraph graphtheoretic abstraction super block recall super block consists chain basic blocks conditional exits branch points separating basic blocks graph g said sgraph respect p weights w zero everywhere except path p without loss generality assume weight sink non zero delete sink break graph number components retaining component containing p precedence graph super block contain precedence edges branch vertices since cannot executed order since branch vertices vertices nonzero exit probabilities precedence graph super block sgraph say immediately precedes v edge u v graph vertex u precedes vertex v path u v vertex u 2 v let g u denote subgraph g induced set vertices preceding u subgraph said closed precedence every vertex u subgraph vertices preceding u also subgraph define rank vertex ratio r although vertex infinite rank become evident shortly interested finite rank set vertices v define weight execution time based rank instance rank set vertices preceding vertex 7 figure 1 175 notion rank set vertices meant capture relative importance comparing sum weights cost executing intuitively sum weights contribution made set vertices weighted finish time sum execution times delay suffered rest graph result scheduling set vertices first become evident basic lemma notion rank plays key role characterizing optimal sequential schedule 21 basic lemma section develop basic lemma characterizing optimal sequential schedules weighted precedence graphs ie schedules single functional unit efficient algorithms two cases precedence graph tree precedence graph sgraph obtained special applications basic lemma previ ously optimal sequential algorithms weighted trees described literature 1 8 12 applyingthe basic lemma general weighted graphs would cost time exponential number vertices nonzero weights cost practical number vertices ie number branches small theoretical point view best known approximation algorithm 11 sequential scheduling weighted dags performance guarantee 2 however algorithm based rounding solutions linear programs impractical compiler setting followingterms defined respect specific schedule use term segment refer set consecutive operations schedule two segments b 1 schedule independent operations u precedes v v precedes u given weighted precedence graph g define g smallest precedenceclosed proper subgraph g minimum rank prove main lemma lemma graph g exists optimal sequential schedule optimal schedule g occurs segment starts time zero proof let optimal schedule g g decomposed minimum number maximal segments suppose g decomposed two segments k 1 let segments g increasing order starting times let segment b denoted c let ff denote rg c j denote union blocks c definition g follows rc j ff since otherwise could included c j g let b j similarly denote union blocks follows rb otherwise smaller g schedule formed moving ahead c preserving order within schedule 0 legal since g precedence closed show cost 0 finish proof comparing costs two schedules ignore contribution vertices come b k since status remains 0 schedule 0 ik ik ik schedule ik ik ik ik taking difference gives ik ik ik ik ik ik second inequality follows earlier observations third step follows simple reordering order summation 22 schedules main lemma essentially reduces scheduling problem problem finding g recursively schedule g graph formed removing g put schedules together obtain optimal schedule entire graph unfortunately problem finding g arbitrary precedence graph nphard however number vertices graph nonzero weight small g feasibly determined exhaustive enumeration next show finding g hence finding optimal sequential schedules relatively straightforward precedence graph sgraph let g sgraph respect path p g sink path p sink zero weight sink deleted rank number vertices g reduced appropriately thus g must subgraph single sink sink must vertex p nonzero weightdetermining g straightforward schedule obtained essentially one obtained greedily scheduling successive vertices path defining sgraph early possible terms corresponding super block amounts scheduling basic blocks comprising super block controlflow order exactly successive retirement schedule given example 1 also obtain good ilp schedules super blocks sequential schedule specifically show list scheduling using optimal sequential schedule list gives good approximate solutions sgraphs defer proof full paper theorem sgraph operations equal execution time list scheduling algorithmusing optimal sequential schedule list approximation algorithm performance ratio 2 3 practical heuristic notice theorem profiledriven ilp scheduling quite limited since requires operations equal execution time practical situation offer quality heuristic based theoretical analysis earlier sections 31 modified rank function basic lemma computed rank set vertices sum latencies set divided sum exit probabilities single unit case numerator good measure length time required compute set vertices extending notion rank sequential setting ilp setting replace numerator length schedule compute set vertices call modified rank mrank set vertices length schedule sum exit probabilities basic lemma g defined smallest precedence closed subgraph g minimum modified rank intuition behind modified rank numerator time required retire denominator benefit retiring thus ratio reflects amount computatational time required per unit exit probability minimizing ratio selecting g effect maximizing return investment schedule given sgraph g found following simple procedure algorithm finding g modified rank branch b sgraph given processor construct list schedule subgraph g b rooted b ignoring profile information let length schedule let w sum exit probabilities exits g b g g b earliest b control order minimum modified rank algorithm computing g modified rank considerable flexibility selecting list scheduler including oblivious profile information 32 heuristic know compute g modified rank proceed scheduling heuristic given low words heuristic converts list scheduler precedence graphs one sensitive profile information sgraphs sense heuristic takes profileinsensive list scheduling algorithm bootstraps profilesensitive start heuristic finds g modified rank using insensitive list scheduler makes list g initial portion list g heuristic deletes g g iterates appending lists time till g consumed algorithm scheduler 1 profilelist empty 2 find g modified rank using insensitive scheduler 3 append schedule list g profilelist 4 remove g dag 5 branches remaining goto step 2 6 list schedule using profilelist example 2 return graph figure 1 apply scheduling heuristic use critical path scheduling insensitive list scheduler oblivious profile information assume processor withtwo identical functionalunits equal latencies vertices 3 candidates g initially consisting subgraph rooted vertex 3 denoted g 3 subgraph rooted vertex 7 denoted g 7 entire graph g computing modified ranks get rankg 3 table 4 list schedule constructed heuristic super block figure 1 two functional unit machine using critical path scheduler insensitive scheduler exits marked expected completion cycles numerators length critical path schedules given processor since g 7 lowest rank g therefore set profilelist critical path list g 7 remove g 7 g since vertex 28 exit remaining append critical path list profilelist list scheduling using profilelist two functional unit processor yields schedule table 4 notice expected finish time schedule lower critical path schedule table 1 speculative yield schedule table 2 successive retirement schedule table 3 4 experimental results study performance heuristic number optimized super blocks generated impact compiler spec benchmark programs restrict attention integer benchmarks since broadly speaking floatingpoint benchmarks yield super blocks nearzero sideexit probabilities 16 used impact compiler compile benchmarks decomposing program super blocks basic blocks report results scheduling blocks two different classes machine models processors uniform functional units processors heterogenous functional units models nonpipelined opcode execution times specified table 6 assumption machines pipelined interest simplicity inherent limitation technique uniform processor models 2 4 8 identical functional units respectively denoted u 2 u 4 u 8 uniform machine models unrealistic practice serves well study effect scaling number functional units processor heterogenous models h 3 h 5 h 8 shown 5 model h 3 one ialu one falu one model ialu falu mem table 5 functional units three heterogenous processors opcode time falu 4 cycles table 6 opcodes execution times loadstore unit model h 5 two ialus one falu two loadstore units model h 8 three ialus two falu three mem loadstore units assume branch operations performed falu first use critical path scheduler profile insensitive scheduling algorithm drive heuristic compare performance three algorithms 1 critical path scheduling last exit 2 speculative yield example 1 3 3 successive retirement example 1 table 7 shows improvements achieved heuristic criticalpath scheduling benchmarks studied various machine models benchmark machine model show improvement total schedule length benchmark formally define total schedule length benchmark weighted sum schedule lengths basic blocks super blocks benchmark weights execution frequencies obtained via profiling experience good measure runtime benchmark typical machine sufficient number registers table 8 shows improvements achieved heuristic speculative yield scheduling table 9 shows improvements achieved heuristic successive retirement scheduling referring table 9 notice narrow machines u 2 h 3 little performance gain evidenced successive retirement optimal sequential processor shown theoretical analysis likely good schedule narrow machines substantiate claim heuristic general paradigm converting profileinsensitive scheduler benchmark improvement espresso 128 92 54 113 105 89 li 60 14 12 36 21 09 compress 61 59 52 58 53 38 sc 47 48 51 54 62 51 cccp 43 47 41 31 46 38 cmp 12 22 25 11 18 20 eqn 24 23 21 20 19 20 lex 19 08 09 16 13 10 qsort 109 113 57 62 62 99 tbl 14 13 14 09 11 12 wc 38 38 40 30 37 45 yacc 69 41 43 47 45 44 average 41 35 28 31 33 31 table 7 comparison heuristic critical path scheduling critical path scheduling profileinsensitive scheduler shown improvement total schedule length benchmarks benchmark improvement espresso 54 37 47 35 38 48 li 13 04 05 03 05 04 compress 36 44 51 36 31 30 sc 28 42 55 30 37 46 cccp 28 38 40 23 34 40 cmp 12 22 25 11 18 20 eqn 14 20 21 15 20 21 lex 11 07 08 10 09 09 qsort 89 101 64 29 38 76 tbl 06 15 13 07 10 07 wc 29 38 40 21 22 51 yacc 36 34 42 28 39 37 average 24 27 28 16 21 26 table 8 comparison heuristic speculative yield scheduling critical path scheduling profileinsensitive sched uler shown improvement total schedule length benchmarks benchmark improvement espresso 04 47 49 04 52 67 li 21 12 03 01 30 38 compress 07 49 53 05 43 61 alvinn 11 15 12 05 01 17 sc 04 49 62 23 40 43 cccp 18 69 37 25 77 52 eqn 28 02 21 09 63 64 lex 16 17 11 20 15 15 qsort 21 64 95 27 49 84 tbl 35 04 11 01 31 18 wc 29 58 45 21 71 32 yacc 26 51 54 31 50 53 average 07 28 32 11 36 35 table 9 comparison heuristic successive retirement scheduling critical path scheduling profileinsensitive sched uler shown improvement total schedule length benchmarks profilesensitive one apply heuristic using successive retirement profile insensitive scheduler set benchmarks machine models results shown table 10 41 discussion performance studies total schedule length benchmark depends nature mix basic blocks super blocks produced compila tion heuristic designed improve performance super blocks side exits substantial exit fre quency compiler aggressive creating super blocks side exits occur infrequently opportunities performance gains limited examine detail introduce notion critical path ratio super block aims measure relative importance side exits super block end define expected critical path length weighted sum lengths critical paths exits weighted exit probabilities critical path ratio ratio expected critical path length length critical path last exit critical path ratio small compared unity side exits significant critical path ratio close unity last exit benchmark improvement espresso 04 47 49 04 51 67 li 21 15 03 01 29 41 compress 07 41 48 05 47 56 alvinn 11 15 12 05 01 17 sc 04 49 60 23 40 42 cccp 17 69 37 25 78 51 eqn 28 03 21 09 62 64 lex 16 17 11 20 14 15 qsort 15 67 97 24 48 49 tbl 35 04 11 01 31 18 wc 26 58 45 21 71 32 yacc 26 53 54 31 50 50 average 06 28 31 11 36 32 table 10 comparison heuristic successive retirement scheduling successive retirement scheduling profile insensitive scheduler shown improvement total schedule length benchmarks predominant clear every basic block critical path ratio unity figure 2 shows average improvement achieved heuristic critical path scheduling function critical path ratio plots represent averages basic blocks super blocks obtained compiling benchmarks studied plots marked u 2 u 4 u 8 figure refer respective uniform processor models example read plots observe blocks critical path ratio 02 enjoy 30 improvement average scheduled heuristic compared scheduling critical path last exit respect twofunctional unit machine u 2 critical path ratio nears unity achieved improvement falls expected since case last exit predominant heuristic converges critical path scheduling notice also number available functional units increases u 2 u 4 u 8 achieved improvement falls critical path scheduling increasingly good wider processors optimal limiting case infinitely wide processors reduced opportunity performance gains rearranging schedule also shown figure distribution blocks depicted cumulative percentage critical path ratio example read plot observe roughly 30 blocks sample critical path ratio 08 less value critical path ratio performance improvement percent hence remaining 70 blocks good candidates improvement via scheduling heuris tic suggests super block formation heuristics could form super blocks lower critical path ratios scheduling algorithm would increased opportunity performance gains another factor affects performance gains realized scheduling heuristic amount parallelism present super block super block little paral lelism critical path schedule saturate processor little performance gain obtained since schedule constrained resources hand super block lot parallism critical path schedule saturate processor much performance gain rearranging schedule favor high probability exits good measure parallelism available block processor utilization factor schedule block essentially average load processor schedule expressed percentage formally procesor utilization factor number cycles functinal unit busy summed functional units expressed percentage product length schedule number functional units thus two independent factors affect gains realized scheduling heuristic 1 importance side exits reflected critical path ratio 2 amount parallelism available reflected processor utilization examine results table 7 light two factors let us extend notion critical path ratio benchmarksthe critical path ratio benchmark weighted sum critical path ratios blocks composing weights execution probabilities block sim ilarly utilization factor benchmark weighted sum utilization factors blocks composing weights execution probabilities block heuristic perform well critical path ratio small utilization factor large test hypothesis figure 3 horizontal axis plot critical path ratio vertical axis processor utilization critical path schedule processor model box figure represents benchmark center box corresponding critical path ratio processor utilization horizontal vertical axes respectively length side box directly proportional improvement achieved heuristic bench mark corresponding entry column u 4 table 7500 02 04 imp cumulative distribution u2 u4 u8 critical path ratio figure 2 performance gains heuristic critical path scheduling critical path scheduling profileinsensitive sched uler shown improvement run time blocks function critical path ratio distribution blocks cumulative percentage critical path ratio benchmarks high critical path ratio enjoy little performance gain independent processor utilization benchmarks shown small box also benchmarks little parallelism manifested low processor utilization enjoy little performance gain even low critical path ratio thus performance gains table 7 well explained tuition lends support conclusion heuristic exhibits gains gains possible 5 acknowledgements thank impact group university illinois permission use impact compiler study c chekuri supported nsf award ccr9357849 matching funds ibm mitsubishi schlumberger foundation shell foundation xerox corp r motwani supported alfred p sloan research fellow ship ibm faculty partnership award aro muri grant daah049610007 nsf young investigator award ccr9357849 matching funds ibm mit subishi schlumberger foundation shell foundation qsort070critical path ratio processor utilization ear alvinn compress sc li cccp cmp grep lex tbl wc espresso figure 3 scatter plot performance gains heuristic critical path scheduling u 4 processor model critical path scheduling profileinsensitive scheduler box corresponds benchmark length side box proportional percentage improvement performance 6 conclusion presented theoretical analysis general problem scheduling precedence graph profile informa tion main theoretical result general lemma characterizing optimal sequential schedules weighted precedence graph heuristic extension lemma presented generic scheme converting profileinsensitive list scheduling algorithms profilesensitive scheduling algorithm super blocks experiments show settings heuristic offer substantial performance improvement prior methods range benchmarks r single machine job sequencing precedence constraints compilers princi ples enhancing instruction level parallelism compiler controlled optimization compiling cydra5 j schedulingchain structured operations minimize makespan mean flow time trace scheduling technique global microcode compaction global code generation instruction level parallelism optimal task sequencing precedence constraints computers tractability bounds multiprocessor timing anoma lies scheduling minimize average completion time offline online algorithms parallel sequencing assembly line prob lems super block effective technique vliw superscalar compilation sequencing jobs minimize total weighted completion time exploitinginstruction level parallelism presence conditional branches effective compiler support predicated execution using hyperblock ordering problems approximated singleprocessor scheduling interval graph completion tr compilers principles techniques tools scheduling chainstructured tasks minimize makespan mean flow time ordering problems approximated effective compiler support predicated execution using hyperblock compiling cydra 5 superblock enhancing instruction level parallelism compilercontrolled speculation exploiting instruction level parallelism presence conditional branches scheduling minimize average completion time ctr chandra chekuri rajeev motwani minimizing weighted completion time single machine proceedings tenth annual acmsiam symposium discrete algorithms p873874 january 1719 1999 baltimore maryland united states ghassan shobaki kent wilken optimal superblock scheduling using enumeration proceedings 37th annual ieeeacm international symposium microarchitecture p283293 december 0408 2004 portland oregon c chekuri r motwani b natarajan c stien approximation techniques average completion time scheduling proceedings eighth annual acmsiam symposium discrete algorithms p609618 january 0507 1997 new orleans louisiana united states brian l deitrich wenmei w hwu speculative hedge regulating compiletime speculation profile variations proceedings 29th annual acmieee international symposium microarchitecture p7079 december 0204 1996 paris france mark heffernan kent wilken ghassan shobaki datadependency graph transformations superblock scheduling proceedings 39th annual ieeeacm international symposium microarchitecture p7788 december 0913 2006 waleed meleis alexandre e eichenberger ivan baev scheduling superblocks boundbased branch tradeoffs ieee transactions computers v50 n8 p784797 august 2001 john cavazos j eliot b moss inducing heuristics decide whether schedule acm sigplan notices v39 n6 may 2004 nicole megow marc uetz tjark vredeveld models algorithms stochastic online scheduling mathematics operations research v31 n3 p513525 august 2006 michael bender soumen chakrabarti muthukrishnan flow stretch metrics scheduling continuous job streams proceedings ninth annual acmsiam symposium discrete algorithms p270279 january 2527 1998 san francisco california united states alexandre e eichenberger waleed meleis balance scheduling weighting branch tradeoffs superblocks proceedings 32nd annual acmieee international symposium microarchitecture p272283 november 1618 1999 haifa israel hermann schichl arnold neumaier interval analysis directed acyclic graphs global optimization journal global optimization v33 n4 p541562 december 2005 aaron smith jon gibson bertrand maher nick nethercote bill yoder doug burger kathryn mckinle jim burrill compiling edge architectures proceedings international symposium code generation optimization p185195 march 2629 2006 thomas kistler michael franz continuous program optimization case study acm transactions programming languages systems toplas v25 n4 p500548 july