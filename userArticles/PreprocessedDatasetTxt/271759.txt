parallel grid modification domain decomposition algorithm local phenomena capturing load balancing lions nonoverlapping schwarz domain decomposition method based finite difference discretization applied problems fronts layers purpose getting accurate approximation solution solving small linear systems grid refinement made subdomains contain fronts layers uniform coarse grids applied subdomains solution changes slowly smoothly order balance loads among different processors employ small subdomains fine grids rapidlychangingsolution areas big subdomains coarse grids slowlychangingsolution areas numerical implementations spmd mode ncube2 machine conducted show efficiency accuracy method b introduction grid refinement methods proved essential efficient solving largescale problems localized phenomena boundary layers wave fronts many engineering problems however still leads largesize linear systems algebraic equations solved easily even todays largest computing systems domain decomposition methods extensively investigated recently since provide mechanism dividing large problem collection smaller problems solved sequentially parallel workstation processor moderate computing capability work investigate possibility combining domain decomposition methods grid refinement techniques first divide original physical domain collection subdo mains apply fine grids subdomains contain local phenomena coarse grids paper appeared journal scientific computing 121997 99117 department mathematics wayne state university detroit michigan 48202 email yangmathwayneedu dyangnanetornlgov subdomains solution changes slowly purpose load balancing among different processors solved parallel computer distributed computing system size subdomains contain local phenomena kept small subdomains solution changes smoothly large implementation try keep approximately number degrees freedom subdomain results experimental onedimensional problems multidimensional problems considered similarly complexity section 2 describe domain decomposition method grid modification section 3 conduct numerical experiments domain decomposition method local grid refine ment section describe domain decomposition method combined grid refinement techniques 21 differential problem consider model problem 1d x x x 1 2 outward normal given constants let decomposed k nonoverlapping subdomains satisfying system 13 equivalent following split problem x x x outward normal boundary subdomainomega k 5 lions proposed nonoverlapping schwarz algorithm heuristically stated follows choose initial guess k satisfying given boundary condition 23 sequence u n k constructed gammaq u n1 km parameter chosen speed convergence l given elliptic operator despres 1 douglas et al 2 kim 4 considered discretizations procedure hybridized mixed finite element method finite difference method applied procedure wave equations mu rice 7 considered collaborating pde solvers context domain decompositions 22 finite difference discretization assume uniform grid size h k used subdomainomega k k grid points omega k ith grid point denoted x ki interface point andomega k1 x kd k x k11 1 endpoints ofomega x denote example following describe two schemes based finite difference discretization differ way discretizing convection term scheme 1 using exterior point x second order finite difference scheme first order interface condition x k1 see figure 1 gammaq k1 kgamma1d kgamma1d note q q continuous x k1 x kgamma1d x x thus 16 represents general form continuity function value flux x kgamma11 x kgamma12 x kgamma1d omega x k1 figure 1 grid points subdomainomega k interface andomega eliminating k0 15 16 equation first point subdomainomega k interior points subdomainomega k apply second order finite difference scheme last point subdomainomega k similarly 1718 point x kd k imaginary one value u n kd k 1 1718 eliminated assumption q kd k thus following linear system kgamma1d first equation 19 changed last subdomainomega k equation 21 changed kd k assumed h k chosen easy see sequence u n kj converges n 1 limit denoted u kj satisfy standard global finite difference scheme problem 13 thus u oh l 1 norm g scheme 2 scheme employ first order finite difference approximation convection term interface specific applying first order finite difference convection term 15 similarly replace 17 equation 19 changed kgamma1d kgamma1d equation 21 changed equations remain unchanged thus scheme 2 consists equations 27 20 28 22 23 scheme assumption 24 required 23 matrix form rewrite scheme 1 matrix form may helpful implementing scheme define tridiagonal matrices ff kd k ff kd define block tridiagonal matrix system 1921 rewritten kd k scheme 2 also put matrix form 39 different definitions g h 24 convergence analysis relaxation parameter let aea denote spectral radius matrix relaxation parameters km chosen aeg let elements gamma1 k denoted k ij denote gamma1 show km obtained following relation require note formula 41 valid scheme 1 scheme 2 following tang 8 give proof 41 case three subdomains deleting columns except eight nonzero ones corresponding rows g gamma1 h see aeg 2 2 2 2 let 2 z z 2 z z z virtue 43 aeg z z order let aeg choose z 0 view 3538 scheme 1 similar formulas scheme 2 1 1 2 2 finishes proof 41 case order find optimal parameters 41 need know ratio two elements inverse matrix k assume kgamma1k found ratio determined relation indeed incomplete omitting last step lufactorization k leads l diagonal elements 1 u elements u k k gamma 1gammath row 46 gives us u view 41 u thus optimal parameters kk1 found recursively 47 incomplete ludecompositions iterative matrix system 39 spectral radius 0 also gives convergence scheme 1 scheme 2 note matrix k tridiagonal thus ratio u obtained single nested loop less 3d k floating point operations incomplete lu decomposition needed implementation processor except last one computes parameter righthand boundary subdomain constant coefficients tang 8 used 41 find optimal parameters directly computing inverse matrices k note tangs analysis case minimum subdomain overlapping equivalent nonoverlapping case presented kim 4 applied procedure 47 wave problems analysis extends tang kims nonuniform grids explicit treatment discontinuous diffusion coefficients 3 numerical experiments section implement grid refinement domain decomposition strategy ncube2 mimd parallel computer distributed memory located department computer science purdue observed scheme 2 gives little accuracy scheme 1 restriction described 24 thus report results scheme 2 noted scheme 1 gives second order approximation convection term well diffusion term provides natural approach discretizing differential equation 31 hypercube machines describe briefly hypercube machines properties influence imple mentation definition rdimensional hypercube machine nodes r2 rgamma1 edges node corresponds rbit binary string two nodes linked edge binary strings differ precisely one bit see figure 2 consequence node incident r log n nodes one bit position addition simple recursive structure hypercube also low diameter log n high bisection width n2 iteration algorithm node computes error current solution solution previous iteration subdomain maximum among errors nodes need found decide iterative process stopped implementation first let nodes whose binary string form value node whose binary string let node 1 compute keep maximum two values operation half values dealt stored nodes recursive structure hypercube machine need continue log n steps get maximum value among subdomain errors maximum thus finally found node 0 maximum less prescribed small number node 0 sends message every node stop otherwise iterative process continues later iteration maximum error small figure 2 examples interprocessor connection data network hypercube machines example consider 2dimensional hypercube corresponding figure 2 first step nodes 10 11 send values nodes 00 01 respectively node 01 computes stores maximum value among nodes 01 11 node 00 computes stores maximum value among nodes 00 10 second step node 01 sends updated value node 00 node 00 computes stores maximum procedure efficiently implemented using bit masks provided c programming language 32 parallel implementation adopt following stopping criterion iterative procedure k1 denotes discrete l 1 norm however subdomain problems solved gauss elimination banded storage computations choose initial guess zero stopping criterion 48 satisfied procedure stopped relative errors l 1 norm iterative solution true solution computed test accuracy method consider example 1 du dx exact solution problem dimensionless quantity peclet number b 1 ux exhibits boundary layer thickness ob 1 example keep different values q table 1 numbers iterations l 1 norms errors true solution domain decomposition solution example 1 different peclet numbers grid sizes implemented processors subdomains number iterations 21 20 20 20 gmdd 39e2 47e2 32e2 34e2 fdm1 87e2 25e1 45e1 58e1 fdm2 34e2 35e2 35e2 35e2 domain decomposed 16 subdomains since boundary layer near point apply coarse grid h 1for left 10 subdomains fine grid h peclet number rightmost 4 subdomains ffor middle two 11th 12th counting left subdomains sizes subdomains arranged subdomain contains approximately number degrees freedom let h c h f hm size coarse fine medium grid subdomains respectively solving system obtain size subdomain denote grid modification domain decomposition method gmdd compare accuracy also employ second order finite difference method without domain decomposition 1 denoted fdm1 uniform grid total number unknowns equal gmdd 2 denoted fdm2 uniform fine grid total number unknowns fdm2 much bigger gmdd results table 1 show domain decomposition solution accurate global method number degrees freedom accurate global method much larger number degrees freedom example grid modification domain decomposition method 80 degrees freedom global finite difference method fine grid fdm2 table 1 600 degrees freedom accuracies two methods consider following nonselfadjoint problem variable coefficients example 2 x x x table 2 numerical results l 1 norm example 2 different numbers processors processor takes care one subdomain number processors 8 number iterations errors l 1 norm 721e2 626e2 627e2 519e2 table 3 numerical results example 3 discontinuous diffusion coefficient different grid sizes case 16 subdomains number iterations 78 79 79 function f right hand side chosen exact solution problem true solution boundary layer near right boundary domain decomposed different numbers subdomains right three subdomains discretized grid size 1 rest subdomains grid size 1 number subdomains equal number processors implementation results example different numbers processors shown table 2 table 2 know number iterations required procedure stop bigger problems constant coefficients see table 1 interesting observe accuracy improves number subdomains increases agrees computing experience 9 see well algorithm performs discontinuous diffusion coefficients consider example 3 x x x exact solution chosen table 4 numerical results example 4 different numbers processors processor takes care one subdomain number processors 8 number iterations 29 55 104 197 errors l 1 norm 299e2 239e2 237e2 232e2 decompose domain 16 subdomains accuracy number iterations different grid sizes example 3 shown table 3 table 3 see number iterations errors larger discontinuous diffusion coefficients continuous coefficients finally consider another convectiondiffusion problem example 4 x x x function f right hand side chosen exact solution problem true solution boundary layer near right boundary domain decomposed different numbers subdomains one third subdomains right hand side discretized grid size h f 1 two thirds subdomains left hand side grid size h c 1 one middle subdomain grid size h c 2 length subdomain chosen example 1 subdomain approximately number degrees freedom number subdomains still equal number processors implementation numerical results example shown table 4 concluding remarks implemented nonoverlapping schwarz domain decomposition method grid modification elliptic problems involving localized phenomena fronts layers order capture local phenomena save computational work apply fine grids subdomains contain fronts layers coarse grids subdomains however implemented parallel computing systems subdomain problems must approximately computational complexity loads different processors workstations balanced important synchronization achievement good speedup though implementation onedimensional steady problems methodology applies timedependent multidimensional problems timedependent problems usually first discretized time elliptic problems time step domain decomposition algorithms applied however advectiondominated transport problems discretization space time coordinated example unwinding techniques incorporated discretization process nonoverlapping schwarz domain decomposition methods recently received lot atten tion since efficiency elegant simplicity implementation great savings computer storage 3d even small overlapping subdomains could cause lot storage direct applicability transmission problems direction several types domain decomposition considered 6 11 10 12 modifications apply directly domain decompositions cross points long narrow subdomains 3 successfully implemented variant methods 12 selfadjoint nonselfadjoint elliptic partial differential equations variable coefficients full diffusion tensor case 100 subdomains 81 cross points 2d variant also works well long narrow subdomains length subdomain times large width subdomain 9 author considered dynamic domain decomposition method based finite element discretization twodimensional problems dynamic change domain decompositions provide mechanism capturing moving layers fronts load balancing different processors acknowledgement author would like thank professor john r rice valuable advice providing computing facility department computer science purdue also feels grateful professor jim douglas jr dr kim helpful discussions referees suggestions also improved quality paper r domain decomposition method helmholz problem finite difference domain decomposition procedures solving scalar waves schwarz alternating method iii variant nonoverlapping subdomains relaxation procedure domain decomposition methods using finite elements modeling collaborating pde solvers theory practice different domain decompositions different times capturing moving local phenomena parallel iterative nonoverlapping domain decomposition procedure elliptic problems parallel iterative domain decomposition algorithm elliptic problems parallel iterative nonoverlapping domain decomposition method elliptic interface problems tr relaxation procedure domain decomposition methods using finite elements generalized schwarz splittings different domain decompositions different times capturing moving local phenomena ctr daoqi yang finite elements elliptic problems wild coefficients computational science mathematics software purdue university press west lafayette 2002 j r rice p tsompanopoulou e vavalis fine tuning interface relaxation methods elliptic differential equations applied numerical mathematics v43 n4 p459481 december 2002