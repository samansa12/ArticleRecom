procedure placement using temporal ordering information instruction cache performance important instruction fetch efficiency overall processor performance layout executable substantial effect cache miss rate execution means performance executable improved significantly applying codeplacement algorithm minimizes instruction cache conflicts describe algorithm procedure placement one type codeplacement algorithm significantly differs previous approaches type information used drive placement algorithm particular gather temporal ordering information summarizes interleaving procedures program trace algorithm uses information along cache configuration procedure size information better estimate conflict cost potential procedure ordering compare performance algorithm previously published procedureplacement algorithms show noticeable improvements instruction cache behavior b introduction linear ordering procedures programs text segment fixes addresses procedures turn determines cache lines procedure occupy instruction cache case directmapped cache conflict misses result execution program alternates two procedures whose addresses map overlapping sets cache lines several compiletime codeplacement techniques developed use heuristics profile information reduce number conflict misses instruction cache reordering program code blocks 567811 though techniques successfully remove sizeable number conflict misses compared default code layout produced typical compilation process possible even better gather improved profile information consider specifics hardware configuration end propose method summarizing important temporal ordering information related code placement show use information machinespecific manner often reduces number instruction cache conflict misses particular apply new techniques problem procedure placement directmapped caches compiler 2achieves optimized cache line address procedure specifying ordering procedures gaps procedures executable codeplacement techniques may reorganize application one levels granularity typically technique focuses placement whole procedures individual basic blocks use term code block refer unit granularity codeplacement technique applies though focus placement variablesized code blocks defined procedure boundaries techniques capturing temporal information using information placement apply code blocks granularity default code layout produced compilers places procedures executable order listed source files preserves order object files linker command line therefore left chance code blocks conflict cache whenever code blocks often executed together happen overlap cache cause significant number conflict misses instruction cache several studies shown compiletime optimizations change relative placement code blocks cause large changes instruction cache miss rate 34 changes relative placement code blocks occurs performance program affected intended effect optimization also resulting change instruction cache misses makes difficult predict total effect optimizations change code size use change running time optimized executable judge effectiveness optimizations summary codeplacement techniques important improve performance instruction fetcher enable effective use compiletime optimizations reduce instruction cache miss rate application code placement algorithm requires two capabilities must able assign code blocks cache lines must information relative importance avoiding overlap different sets code blocks ways compiler set addresses code block compiler manipulate order procedures appear executable leave gaps two adjacent procedures force alignment next procedure specific cache line interesting problem determining procedures overlap hardware instruction cache previous work procedure placement almost exclusively based summary profile statistics simply indicate often code block executed often information organized weighted procedure call graph wcg records number calls occurred pairs procedures profiling run program figure 1 contains example wcg summary information used estimate penalty resulting placement procedure pairs cache locations aim existing algorithms place procedures pairs high call counts conflict cache counting number calls procedures summarizing information wcg provides way recognizing procedures temporally related execution program however wcg give us temporal information would like particular absence edge two procedures necessarily mean penalty overlapping procedures example wcg figure 1 produced condition cond alternates true false trace 1 figure 1 proc loop 20times loop 4times cond call else call endl call z endl figure 1 example simple program calls three leaf procedures weighted procedure call graph obtained condition cond true 50 time notice wcg obtained call traces given right figure example program b weighted procedure call graph c possible traces corresponding wcg trace 1 trace 2 condition cond true 40 times false 40 times trace 2 assume purposes example procedures figure 1 require single cache line three locations directmapped instruction cache one cache location reserved procedure clearly want code layout last two cache locations execution traces trace 1 experiences fewer cache conflict misses procedures given distinct cache line z shares cache line trace 2 experiences fewer cache conflict misses procedures share cache line z given cache line wcg figure 1 capture temporal ordering information needed determine layout best wcg summarizes direct call information precise information provided importance conflicts siblings illustrated figure 1 distant temporal relationships enable better code layout want measure much execution program alternates pair procedures pairs connected edge wcg refer measure temporal ordering information information concerning procedure sizes target cache configuration make better estimate number conflict misses experienced specific layout begin section 2 brief description wellknown procedureplacement algorithm sets framework understanding new algorithm present details algorithm sections 3 4 section 3 describes method extracting summarizing temporal ordering information program trace section 4 presents procedureplace ment algorithm uses information produced method section 5 explain experimental methodology present empirical results demonstrate benefit algorithm previous algorithms directmapped caches section 6 describes modify algorithm setassociative caches finally section 7 reviews related work code layout section 8 concludes procedure placement pettis hansen current approaches procedure placement rely greedy algorithms summarize differences algorithms describing selects order procedures considered placement determines place procedure relative alreadyplaced procedures begin description wellknown procedureplacement algorithm pettis hansen 8 explain new algorithm retains much structure many important heuristics found pettis hansen approach addition procedure placement pettis hansen also address issues basicblock placement branch alignment purposes paper use acronym ph referring implementation procedure placement portion algorithm pettis hansen reduce instructioncache conflicts procedures placing frequent callercallee procedure pairs adjacent addresses approach based wcg summary profile information use summary information select next procedure place determine place procedure relationship already placed procedures implementation ph produce undirected graph weighted edges contains essentially information wcg one node graph procedure program edge e pq connects two nodes p q p calls q q calls p weight pq given e pq equal 2 calls pq calls qp calls pq total number calls made procedure p procedure q collect information scanning instruc tionaddress trace program noting transition procedures counts calls returns therefore get edge weight twice number calls extra factor two change procedure placement produced ph graph used select next procedure place determine relative placement procedure ph begins making copy initial graph refer copy working graph ph searches working graph edge largest weight call edge e uv edge found algorithm merges two nodes u v single node u working graph details moment remaining edges original nodes u v nodes become edges new node u maintain invariant single edge pairs nodes ph combines pair edges e ur e vr single edge e ur weight ur algorithm repeats process searching edge largest weight working graph graph reduced single node ph way reducing chance conflict miss procedures proximity address space closer place two procedures address space less likely conflict procedures within node organized linear list called chain 8 ph merges two nodes chains combined single chain four ways let b represent chains b reverse chain four possibilities ab ab ab ab choose best one ph queries original graph determine edge e largest weight procedure p first chain procedure q second chain implementation ph chooses merged chain minimizes distance bytes p q 3 summarizing temporal ordering information algorithm aims optimize arrangement code blocks needs conflict metric quantifies importance avoiding conflicts sets code blocks ideally metric would report number cache conflict misses caused mapping set code blocks overlapping cache lines expect find metric gives exact number resulting cache conflict misses need one simply need metric linear function number conflict misses 1 section 53 shows metric used algorithm exhibits strong correlation instruction cache miss rate 1 clearly difference training testing data sets also affect metrics ability predict cache conflict misses testing run discussed previous section ph uses callgraph edge weight wpq two procedures q conflict metric simple metric drives merging nodes unfortu nately metric several drawbacks illustrated section 1 understand build better conflict metric helpful review actions cache processing instruction stream assume moment tracking code blocks size equal size cache line directmapped cache code block b maps cache line l addrb div linesize mod cachelines code block remains cache another code block maps cache line terms code layout important therefore note code blocks referenced temporally nearby reference b ideally none blocks referenced consecutive references b map cache line b way get reuse initial fetch block b experience conflict miss second reference b since reuse code block prevented single code block directmapped caches construct data structure summarizes frequency alternating two code blocks convenient build data structure weighted graph nodes represent individual code blocks refer graph temporal relationship graph trg ph conflict metric simply edge weight e pq two nodes p q trg general call graph contain edges connecting pair code blocks interleaving program execution rest section describes process build trg next section explains use resulting trg place procedures construct summary temporal locality code blocks trace analyze set recentlyreferenced code blocks transition code blocks implementing ordered set q codeblock identifiers eg procedure names ordered appeared trace always access history recentlyreferenced code blocks bound maximum size q entries eventually become irrelevant removed two ways code block identifier p become irrelevant first need latest occurrence p q code blocks executed recent occurrence p effect occurrence earlier occurrence p second p become irrelevant sufficiently large amount unique code executed since ps last occurrence evicted p cache let set code block identifiers reached since last reference p let st sum sizes code blocks referenced exactly big st needs grow p becomes irrelevant depends cache mapping code assuming code layout maximizes reuse members mapped nonoverlapping addresses cache footprint equal st therefore p becomes irrelevant st greater cache size summary perform following steps inserting new element p ordered set q first place p recent end q previous occurrence p q remove remove oldest members q removal next leastrecentlyused identifier would cause total size bytes remaining code blocks q less cache size build trg process trace one code block identifier time processing step contains set code blocks temporal locality often set code blocks appears q important occupy cache locations code block identifier p remove trace update trg follows every code block q q starting mostrecent end q increment weight edge e pq node p exist create edge e pq exist create weight 1 continue q reach previous occurrence p end q stop encounter previous occurrence p indicates reuse code blocks temporarily referenced previous occurrence p q could displaced p instruction cache collected relationship data p insert p q described process repeats processed entire trace process ing left trg whose edge weights pq record number times p q occurred within sufficiently small temporal distance present q time independent p q related programs call graph 4 placement algorithm given discussion sections 2 3 clear could use trg constructed section 3 within procedureplacement algorithm described pettis hansen 8 found however extra temporal ordering information alone sufficient guarantee lower instruction cache miss rates get consistent improvements also make two key changes way determine place procedure relative alreadyplaced procedures first involves use procedure size cache configuration information allows us make informed procedureplacement decision second involves gathering temporal ordering information granularity finer procedure unit use detailed information overcome problems created procedures larger cache size efficiency reasons also consider popular ie frequently executed procedures building relationship graph proposed hashemi et al 5 rest section outlines procedureplacement algorithm section 41 begins description trgs required algorithm iterate procedure list selecting order procedure processed main outer loop section 42 focuses portion algorithms main loop places procedure relative procedures already processed using cache configuration procedure size information placement decision simply specifies cacherelative alignment among set procedures determination procedures starting address ie placement linear address space occurs popular procedures processed section 43 presents details process 41 trgs main outer loop algorithm uses two related trgs one selects next procedure placed trg select aids determination place selected procedure trg place ph two graphs initially algorithm graphs differ granularity code blocks processed trg build code block trg select corresponds whole procedure code block trg place corresponds chunk procedure benchmarks found chunking procedures 256byte pieces works well trg place therefore contains nodes procedure p program straightforward modify algorithm previous section generate trgs simultaneously though record temporal information concerning parts procedures procedureplace ment algorithm places whole procedures use finergrain information find best relative alignment whole procedures explained though trg select contains edges per node relationship graph built ph due additional temporal ordering information process trg select exactly greedy merging manner relationship graph discussed section 2 though tried several methods creating order select procedures placement could find robust heuristic one simple elegant difference working relationship graph trg select contains popular procedures section 43 discusses place remaining unpopular procedures 42 determining cacherelative alignments ph data structure nodes working graph linear list chain pro cedures building chain restrictive terms selecting starting addresses placed procedures needs however constraint need maintain placed procedures mapped addresses result cache layout small conflict cost explain exactly calculate cost placement moment instead chains use data structure nodes trg select comprises set tuples tuple consists procedure identifier offset cache lines beginning procedure beginning cache node containing single procedure offset zero two nodes containing single procedure merged together algorithm modifies offset second procedure ensure cost metric placement two procedures cache minimized algorithm figure 2 presents pseudocode merging two nodes containing number alreadyplaced procedures three items noteworthy concerning mergenodes routine figure 2 first merge two nodes leave relative alignment procedures within node figure 2 pseudocode merging two nodes temporal relationship graph rg select procedure chunks within node identified unique ids offset chunk id records cacheline index corresponding beginning chunk offsets always units cache lines array cachelines id mergenodes node n1 node n2 initialize cache array c1 marking line procedurechunk ids node n1 occupying line foreach id offset pair p n1 int foreach idoffset pair p poffset bestoffset return n1 unchanged backtrack undo previous decisions though ability rearrange entire set procedures two nodes merged might lead better layout flexibility would noticeably increase computational complexity algorithm assume selection order procedure placement guaranteed already avoided expensive potential cache conflicts experimental results show greedy heuristic works quite well practice open research question limited amounts backtracking could improve upon layouts found current approach second mergenodes calculates cost metric potential alignment layout first node respect layout second node fix layout first node begin cache line 0 offset start second nodes layout number 0 number lines cache evaluate relative offsets using finegrained temporal information trg place given offset compute procedure piece first node procedure pieces second node overlap cache pair overlapping procedure pieces compute estimated number cache conflicts corresponding overlap accessing weight edge two procedure pieces trg place sum estimates obtain total estimate potential placement calculate estimate procedurepiece conflicts nodes intranode conflicts procedure pieces want incremental cost placement cost intranode overlaps fixed change ultimate finding calculation extra cost would increase work done algorithm third costmetric calculation produces several relative offsets cost algorithm selects first offsets simplest case merge two nodes containing single procedure call p q total size two procedures less cache size merging nodes result node equivalent chain created ph words mergenodes selects first empty cache line procedure p begin procedure q since first zerocost location q 43 producing final linear list merging phase algorithm ends edges left trg select 2 final step algorithm produces linear arrangement program procedures given relative alignment decisions contained remaining trg select nodes begin select procedure p cacheline offset 0 3 first procedure linear layout find next procedure linear layout search nodes procedure q whose cacherela tive offset results smallest positive gap cache lines end p start q understand general case assume procedure p last procedure linear layout p ends cacherelative offset pendline choose procedure q starts cacherel ative offset qstartline next procedure linear layout q produces smallest positive value gap among unconsidered popular procedures finally whenever produce gap two popular procedures search unpopular procedures one fits gap determine address popular procedures linear address space simply append remaining unplaced unpopular procedures end linear list 5 experimental evaluation section compare three different procedureplacement algorithms addition ph algorithm gbsc present results recently published procedureplacement algo rithm algorithm hashemi kaeli calder 5 refer hkc like algo rithm hkc also extends ph use knowledge procedure sizes cache size cache organization hkc uses weighted call graph additional temporal information key advantage hkc ph hkc records set cache lines occupied 2 unlike ph working graph trg select necessarily reduced single node trg select contains popular procedures possible connection two popular procedures unpopular procedure 3 assumes start text segment maps cacheline 0 easy adjust algorithm gap qstartline pendline qstartline numcachelines pendline procedure placement tries prevent overlap procedure immediate neighbors call graph begin section 51 aspects behavior code placement techniques need addressed order make meaningful comparison different algorithms particular introduce experimental methodology based randomization techniques section 52 outlines experimental methodology section 53 presents results 51 evaluating performance code placement algorithms normally expect code optimizations behave similar continuous function small changes behavior optimization cause small changes performance resulting exe cutable code placement optimizations often case small changes layout program cause dramatic changes cache miss rate example simulated instruction cache behavior specint95 perl program two slightly different layouts first layout output code layout algorithm second layout identical first except procedure padded additional bytes one cache line empty space end instruction cache miss rate changed 38 first layout 54 second layout remarkable change trivial difference layouts fact possible introduce large number misses moving one code block single cache line greedy codelayout algorithms additional problem different layouts fact substantially different layouts often result small changes input profile data step ph hkc gbsc greedily choose highestweight edge working graph two edges say weight 1000000 1000001 barely larger edge always chosen first even though small difference unlikely represent statistically significant basis preferring one edge worse ties resulting identical edge weights decided arbitrarily decisions two equally good alternatives must necessarily made one way affect current step algorithm future steps result find difficult draw conclusions relative performance different code layout algorithms small number program traces ideally would like large enough set different inputs benchmark get accurate impression distribution results unfortunately hard practice since common benchmark suites distributed handful input sets benchmark application simulate effect many slightly different application input sets first running application single input applying random perturbations resulting profile data algorithms comparison perturb weighted graphs multiplying edge weight value close one specifically initial weight w replaced perturbed weight according equation x random variable normally distributed mean 0 variance 1 scaling factor determines magnitude random perturbations using multiplicative rather additive noise attractive two reasons first additive noise cause weights become negative obvious interpretation second method inherently selfscaling sense reasonable values independent initial edge weights large enough value cause layout effectively random perturbed graphs bear little relationship profile data low values cause statistically insignificant differences edge weights observe range results produced small changes use experiments blackwell 2 shows several code placement algorithms values low 001 elicit range performance variation system values high 20 degrade average performance much exp 52 methodology implemented ph hkc gbsc procedureplacement algorithms integrated one two different environments simulation environment based atom 10 compiler environment based suif 9 results section 53 based atom environment used suif environment verify algorithms produce runnable correct code table 1 lists benchmarks used study except ghostscript specint95 benchmark suite use five eight specint95 benchmarks three compress ijpeg xlisp uninteresting small instruction working sets equally well reasonable procedureplacement algorithm compiled go perl using suif compiler version 112 benchmarks compiled using gcc 272 o2 optimization flag chose input data sets keep traces manageable size reported miss rates next section based simulation 8 kilobyte directmapped cache line size 32 bytes use training input drive procedureplacement algorithms simulate instructioncache performance resulting optimized executable using testing input 53 results graphs figure 3 show experimental results ph hkc gbsc graph shows results single benchmark three algorithms curve showing cumulative distribution results set 20 experiments based training testing traces described section 51 use randomization obtain twenty slightly different wcgs trgs result slightly different placements point along curve xcoordinate cache miss rate one placements ycoordinate gives percentage placements equal better miss rate consequently curve one algorithm left curve another algorithm first algorithm gives better results notice algorithm gives clearly better results two benchmarks 7except m88ksim perl two benchmarks ranges results overlap though gbsc yields lowest average miss rate placements summary results demonstrate benefits using temporal ordering information well algorithm considers cacherelative alignments placing code section 3 said useful conflict metric strongly correlated number cache misses figure 4 examines issue showing relationship conflictmetric values cache miss rates plot figure 4 contains 80 points point corresponds different placement go benchmark placements based gbsc algorithm however varied output algorithm produce placement range different miss rates accomplished randomly selecting 050 procedures gbsc placement randomly changing cacherelative offsets metric value plotted corresponds resulting placement figure 4a shows conflict metric based finegrained information trg place shows linear relationship actual number cache misses points graph close diagonal hand figure 4b shows metric based wcg always good predictor cache misses program name procedures popular procedures training trace testing trace miss rate default layout avg size procedure history size count size count input description length input description length go 590 k 3221 134 k 112 11x11 board level 4 stones level 6 4 stones ghostscript 1817 k 372 104 k 216 14page pre sentation 37 3page paper 38 263 89 limited 50m bbs limited 50m bbs 50 292 143 perl 664 k 271 reduced dic tionary reduced input file vortex 1073 k 923 117 k 156 persons250 reduced iteration reduced iteration table 1 details benchmark applications report sizes bytes trace lengths basic blocks benchmarks average size procedure history reports average number procedures present ordered set q building trg figure 3 instruction cache miss rates benchmarks graph shows distribution miss rates corresponding layouts produced ph hkc new procedureplacement algorithm gbsc data point graphs represents result single placement cache miss rates vary along xaxis yaxis shows cumulative distribution miss rates02061 gcph gchkc gcgbsc gcc02061 gsph gshkc gsgbsc b ghostscript02061 goph gohkc gogbsc c go m88ksim02061 m8ph m8hkc m8gbsc plph plhkc plgbsc02061 voph vohkc vogbsc f vortex 6 extensions setassociative caches point described technique collecting using temporal information specific directmapped cache implementations words assumed single occurrence procedure q two occurrences procedure p sufficient displace p assumption necessarily true setassociative caches especially implement lru policy use approach setassociative caches construct slightly different data structure replaces trg place slightly modify costmetric calculation mergenodes section focuses 2way setassociative caches implementation changes associativities follows directly explanation instead graph representation trg place convenient think temporal relationship structure database records number times codeblock pair rs appears consecutive occurrences another code block p program trace still use ordered set approach build database however process temporal associations related next code block p trace associate p possible selections two identifiers identifiers currently q previous occurrence p before4812 figure 4 correlation conflict metric cache misses data points 80 randomized layouts go benchmark xcoordinate point cache miss rate layout ycoordinate sum conflict metrics indicated method entire placement cache miss rate conflict estimate millions conflict metric based finegrained trg b conflict metric based wcg4812 cache miss rate conflict estimate millions two unique references required guarantee reuse thus database simply records frequency association p pair rs accessed dprs r p occupy set twoway setassociative cache estimate dprs program references p result cache conflicts due displacement p intervening references r access information instead trg place edge weights conflictmetric calculation mergenodes clearly innerloop calculation must also change slightly check cost association code block node n1 pairs code blocks n2 viceversa though change trg place change trg select trg select heuristic selecting order code blocks placed obviously affected caches associativity mentioned earlier heuristic approaches may work better found one 7 discussion related work much prior work area compiletime code placement related early work reducing frequency page faults virtual memory system recent work reducing cost pipeline penalties associated control transfer instructions however limit discussion studies directly address issue code placement aimed reducing instruction cache conflict misses earliest work area done hwu chang 6 mcfarling 7 pettis hansen 8 hwu chang use wcg proximity heuristic address problem basicblock placement approach unique also perform function inline expansion code placement overcome artificial barriers imposed procedure call boundaries mcfarling 7 uses interesting program representation dag procedures loops condi tionals drive codeplacement algorithm profile information still summarized way temporal interleaving blocks trace lost fact paper explicitly states unable collect temporal interleaving information algorithm assumes optimizes worstcase interleaving blocks like algorithm mcfarling 1does consider cache size modulo property evaluating potential layouts cost calculation obviously different finally algorithm unique ability determine portions text segment excluded instruction cache torellas xia daigle 11 propose codeplacement technique kernelintensive applica tions algorithm considers cache address mapping performing code placement define array logical caches equal size address alignment hardware cache code placed within single logical cache guaranteed never conflict code logical cache though subarea logical caches reserved frequentlyexecuted basic blocks general mechanism calculating placement costs across different logical caches code placement guided execution counts edges basic blocks therefore capture temporal ordering information history mechanism use analyze temporal behavior trace similar problem profiling paths procedure call graph ammons et al 1 describe way implementing efficient path profiling however data structure generated technique cannot used place trg capture sufficient temporal ordering information 8 conclusion presented method extracting temporal ordering information trace described procedureplacement algorithm uses information along knowledge cache lines procedure occupies predict accurately placements result least number conflict misses results show two factors combined allow us obtain better instruction cache miss rates previous procedureplacement techniques codeplacement techniques fluff removal 8 branch alignment 12 orthogonal problem placing whole procedures therefore combined technique achieve improvements success experiments indicates worthwhile continue research temporal behavior applications particular plan develop similar techniques optimize behavior applications layers memory hierarchy 9 r exploiting hardware performance counters flow context sensitive profiling applications randomness system performance measurement effect code expanding optimizations instruction cache design performance issues correlated branch prediction schemes efficient procedure mapping using cache line coloring achieving high instruction cache performance optimizing compiler program optimization instruction caches profile guided code positioning extending suif machinedependent optimizations atom system building customized program analysis tools optimizing instruction cache performance operating system intensive workloads nearoptimal intraprocedural branch alignment tr program optimization instruction caches achieving high instruction cache performance optimizing compiler profile guided code positioning atom performance issues correlated branch prediction schemes exploiting hardware performance counters flow context sensitive profiling efficient procedure mapping using cache line coloring nearoptimal intraprocedural branch alignment optimizing instruction cache performance operating system intensive workloads applications randomness system performance measurement ctr christophe guillon fabrice rastello thierry bidault florent bouchez procedure placement using temporalordering information dealing code size expansion journal embedded computing v1 n4 p437459 december 2005 keoncheol shin jungeun kim seonggun kim hwansoo han restructuring field layouts embedded memory systems proceedings conference design automation test europe proceedings march 0610 2006 munich germany alex ramrez josepl larribapey carlos navarro josep torrellas mateo valero software trace cache proceedings 13th international conference supercomputing p119126 june 2025 1999 rhodes greece alex ramirez josep larribapey carlos navarro mateo valero josep torrellas software trace cache commercial applications international journal parallel programming v30 n5 p373395 october 2002 john kalamatianos alireza khalafi david r kaeli waleed meleis analysis temporalbased program behavior improved instruction cache performance ieee transactions computers v48 n2 p168175 february 1999 young michael smith better global scheduling using path profiles proceedings 31st annual acmieee international symposium microarchitecture p115123 november 1998 dallas texas united states rakesh kumar dean tullsen compiling instruction cache performance multithreaded architecture proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey bartolini c prete optimizing instruction cache performance embedded systems acm transactions embedded computing systems tecs v4 n4 p934965 november 2005 architectural compiler support effective instruction prefetching cooperative approach acm transactions computer systems tocs v19 n1 p71109 feb 2001 trishul chilimbi ran shaham cacheconscious coallocation hot data streams acm sigplan notices v41 n6 june 2006 alex ramirez luiz andr barroso kourosh gharachorloo robert cohn josep larribapey p geoffrey lowney mateo valero code layout optimizations transaction processing workloads acm sigarch computer architecture news v29 n2 p155164 may 2001 chandra krintz brad calder han bok lee benjamin g zorn overlapping execution transfer using nonstrict execution mobile programs acm sigops operating systems review v32 n5 p159169 dec 1998 stephen brown jeet asher william h mangionesmith offline program remapping improve branch prediction efficiency embedded systems proceedings 2000 conference asia south pacific design automation p111116 january 2000 yokohama japan alex ramirez josep l larribapey mateo valero software trace cache ieee transactions computers v54 n1 p2235 january 2005 trishul chilimbi efficient representations abstractions quantifying exploiting data reference locality acm sigplan notices v36 n5 p191202 may 2001 alex ramirez oliverio j santana josep l larribapey mateo valero fetching instruction streams proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey young michael smith static correlated branch prediction acm transactions programming languages systems toplas v21 n5 p10281075 sept 1999 ann gordonross frank vahid nikil dutt first look interplay code reordering configurable caches proceedings 15th acm great lakes symposium vlsi april 1719 2005 chicago illinois usa brad calder chandra krintz simmi john todd austin cacheconscious data placement acm sigplan notices v33 n11 p139149 nov 1998 timothy sherwood brad calder joel emer reducing cache misses using hardware software page placement proceedings 13th international conference supercomputing p155164 june 2025 1999 rhodes greece thomas kistler michael franz automated datamember layout heap objects improve memoryhierarchy performance acm transactions programming languages systems toplas v22 n3 p490505 may 2000 murali annavaram jignesh patel edward davidson call graph prefetching database applications acm transactions computer systems tocs v21 n4 p412444 november rajiv ravindran pracheeti nagarkar ganesh dasika eric marsman robert senger scott mahlke richard b brown compiler managed dynamic instruction placement lowpower code cache proceedings international symposium code generation optimization p179190 march 2023 2005 nikolas gloy michael smith procedure placement using temporalordering information acm transactions programming languages systems toplas v21 n5 p9771027 sept 1999 martha mercaldi steven swanson andrew petersen andrew putnam andrew schwerin mark oskin susan j eggers modeling instruction placement spatial architecture proceedings eighteenth annual acm symposium parallelism algorithms architectures july 30august 02 2006 cambridge massachusetts usa bartolini c prete proposal inputsensitivity analysis profiledriven optimizations embedded applications acm sigarch computer architecture news v32 n3 p7077 june 2004 trishul chilimbi mark hill james r larus cacheconscious structure layout acm sigplan notices v34 n5 p112 may 1999 sangwook p kim gary tyson analyzing working set characteristics branch execution proceedings 31st annual acmieee international symposium microarchitecture p4958 november 1998 dallas texas united states mahmut kandemir compilerdirected collectiveio ieee transactions parallel distributed systems v12 n12 p13181331 december 2001 thomas kistler michael franz continuous program optimization case study acm transactions programming languages systems toplas v25 n4 p500548 july