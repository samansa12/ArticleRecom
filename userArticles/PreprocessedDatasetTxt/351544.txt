observability 3d motion paper examines inherent difficulties observing 3d rigid motion image sequences without considering particular estimator instead presents statistical analysis possible computational models used estimating 3d motion image sequence computational models classified according mathematical constraints employ characteristics imaging sensor restricted field view full field view regarding mathematical constraints exist two principles relating sequence images taken moving camera one epipolar constraint applied motion fields positive depth constraint applied normal flow fields 3d motion estimation amounts optimizing constraints image statistical modeling constraints leads functions studied regard topographic structure specifically regards errors 3d motion parameters places representing minima functions conventional video cameras possessing restricted field view analysis shows algorithms classes estimate motion parameters simultaneously obtained solution error projections translational rotational errors image plane perpendicular furthermore estimated projection translation image lies line origin projection real translation situation different camera full 360 degree field view achieved panoramic sensor system conventional cameras case locations minima two functions either translational rotational error becomes zero case restricted field view errors nonzero although ambiguities still remain full field view case implication visual navigation tasks visual servoing involving 3d motion estimation easier solve employing panoramic vision also analysis makes possible compare properties algorithms first estimate translation basis translational result estimate rotation algorithms opposite algorithms estimate motion parameters simultaneously thus providing sound framework observability 3d motion finally introduced framework points new avenues studying stability imagebased servoing schemes b introduction visual servoing motion estimation broad definition visual servoing amounts control motion basis image analysis thus driver adjusting turning wheel monitoring features scene system attempting insert peg hole controller control panel perceiving number screens adjusting number levers navigating system trying find home perform visual servoing tasks systems must respond appropriately changes environment thus high level described evolving dynamical systems represented function states control signals new states states control variables may functions time one approach controlling system design observer state estimator obtain estimate state example estimator might implement partial visual recovery process estimate used controller state regulator compute control signal drive dynamical system ideally observation control separable sense optimal controller optimal observer control system results coupling two guaranteed optimal 13 different agents ie dynamical systems different capabilities different amounts memory simple reactive systems one end spectrum highly sophisticated flexible systems making use scene descriptions reasoning processes end first studies visual control efforts concentrated upper echelon spectrum trying equip systems capability estimating accurate 3d motion shape environment assuming information could acquired exactly sensory feedback robotics concerned planning execution robots activities characterized look move approach servoing approaches positionorscenebased problem separation perception action computational goals turned difficult one hand reconstruction 3d motion shape hard achieve accurately addition many difficult calibration problems addressed hand spatial planning motion control sensitive errors description spatiotemporal environment realization emergence active vision 36 attention turned lower part spectrum minimizing visual processing placing emphasis regulator opposed estimator one main lessons learned research static look move control strategy ought easier things images using compute 3d motion shape led formulations visual servoing tasks controller act image ie move manipulators joints way scene ends looking particular way technical terms controller act way specific coordinate systems hand eye scene etc put particular relationship furthermore relationship could realized using directly available image measurements feedback control loop approach known imagebased robot servoing 16 18 21 recent years given interesting research results 14 23 24 28 results deal computation image jacobian ie differential relationship camera frame scene frame along cameras intrinsic extrinsic parameters regardless philosophical approach one adopts visual servoing scenebased imagebased essential aspects problem amount recovery relationship different coordinate systems ones camera gripper robot scene object etc could relationship representation change relationship since servoing system general moving observing moving parts fundamental problem recovery 3d motion image sequence whether recovery explicit implicit without relationships different coordinate frames cannot maintained servoing tasks cannot achieved thus important understand accurately 3d motion observed order understand successfully servoing accomplished experience shown practice 3d motion difficult accurately observe involving many ambiguities sensitivities regularities ambiguity 3d motion expresses trying estimate 3d motion introduced errors satisfy constraints 3d rigid motion consists sum translation rotation differences inherent ambiguities governing recovery different components 3d motion addition need study question independently specific optimization algorithms problem studied paper 2 approach veritable cornucopia techniques estimating 3d motion approach algorithm independent order results general use equivalently approach encompass possible computational models used estimate 3d motion image sequences need classify possible approaches 3d motion basis input used mathematical constraints employed system moves environment every point scene velocity regard system projection velocity vectors systems eye constitutes socalled motion field estimate motion field called optical flow starts first estimating spatiotemporal derivatives image intensity function derivatives comprise socalled normal flow component flow along local image gradient ie normal local edge system could start 3d motion estimation using normal flow input could first attempt estimate optical flow though difficult problem subsequently 3d motion means analysis difficulty 3d motion estimation must consider inputs optic flow fields normal flow fields algorithms literature use one input regarding mathematical constraints 3d motion encoded input image motion extensive work area established exist two constraints information scene available first epipolar constraint second positive depth constraint epipolar constraint ensures corresponding points sequence projection point scene positive depth constraint requires depth every scene point positive since scene front camera since knowledge normal flow imply knowledge corresponding points sequence epipolar constraint cannot used normal flow available epipolar constraint attracted work used optic flow available since many measurements present one develops function represents deviation epipolar constraint image variety approaches found literature using different metrics representing epipolar deviation using different techniques seek optimization resulting functions furthermore exist techniques first estimate rotation basis result subsequently estimate translation 9 36 37 techniques opposite 1 22 26 31 33 38 40 techniques estimate motion parameters simultaneously 7 8 17 35 43 positive depth constraint used normal flow fields relatively new employed socalled direct algorithms 8 20 27 one search 3d motion consistent input produces minimum amount negative depth put differently approaches function representing amount negative depth must minimized finally one may able use positive depth constraint optic flow available exist algorithms yet literature implementing principle looking nature observe exists great variety eye designs organisms vision important characteristic field view exist systems whose vision restricted field view achieved corneal eyes land vertebrates human eyes common video cameras fall category geometrically modeled central projection plane refer eyes planar cameratype eyes exist also systems whose vision full 360 degree field view achieved compound eyes insects placing cameratype eyes opposite sides head birds fish panoramic vision adequately modeled geometrically projecting sphere using spheres center center projection studying observability 3d motion investigate restricted field view panoramic vision turns different properties regarding 3d motion estimation approach employ statistical model represent constraints derive functions representing deviation epipolar geometry amount negative depth cameratype eye spherical eye possible meaningful algorithms 3d motion estimation understood minimization functions thus perform topographic analysis functions study global local minima specifically interested relationships errors 3d motion points representing minima surfaces idea behind practical situations estimation procedure hampered errors usually local minima functions minimized found solutions 3 problem statement 31 prerequisites use standard conventions expressing image motion measurements monocular observer moving rigidly static environment describe motion observer translational velocity rotational velocity respect coordinate system oxy z fixed nodal point camera scene point p coordinates velocity r relative camera projecting r onto retina given shape gives image motion field image formed plane figure 1a orthogonal z axis distance f focal length nodal point image point f corresponding scene point r related r z 0 unit vector direction z axis motion field becomes r f z 0 theta r theta theta z r r z x f z 0 r r f r r b figure 1 image formation plane sphere b system moves rigid motion translational velocity rotational velocity scene points r project onto image points r 3d velocity r scene point observed image image velocity r representing depth image formed sphere radius f figure 1b center projection origin image r point r jrj r norm r range image motion r u tr motion field sum two components one u tr due translation u rot due rotation depth z range r scene point inversely proportional translational flow rotational flow independent scene view seen 1 2 effects translation scene depth cannot separated direction translation tjtj computed thus choose length throughout following analysis f set 1 length assumed 1 sphere zcomponent 1 plane problem 3d motion estimation amounts finding scaled vector vector representation motion field following make analysis easier cameratype eye employ nonvector notation first two coordinates r denote image point cartesian system oxy oxkox oykoy intersection oz image plane denote image point representing direction translation vector referred focus expansion foe focus contraction foc depending whether w positive negative equations 1 become well known equations expressing flow measurement fly v tr xy translational rotational flow components respectively regarding value normal flow n unit vector image point denoting orientation gradient point normal flow v n satisfies r finally following convention employed throughout paper use letters hat signs represent estimated quantities unmarked letters represent actual quantities subscript ffl denote errors error quantity defined actual quantity minus estimated one example u rot represents actual rotational flow u rot estimated rotational flow ffl translational error vector x ff etc 32 model classic approach 3d motion estimation minimize deviation epipolar constraint constraint obtained eliminating depth range equation 1 2 planar spherical eyes r theta r 0 5 equating image motion optic flow constraint allows derivation 3d rigid motion basis optic flow measurements one interested estimates translation rotation best satisfy epipolar constraint every point r according criterion deviation euclidean norm usually used leading minimization 25 34 function 1 z z image theta rdr 6 hand normal flow given vector equations 1 2 cannot used directly constraint scalar equation 4 along inequality z 0 states since surface view front eye depth must positive substituting 1 2 4 solving estimated depth z range r obtain given estimate point r zor numerator denominator 7 opposite signs negative depth computed thus utilize positivity constraint one must search motion produces minimum number negative depth estimates formally r image point define indicator function nd ae estimation 3d motion normal flow amounts minimizing 19 20 27 function z z image nd rdr 8 expressing r terms real motion 1 2 functions 6 8 expressed terms actual estimated motion parameters equivalently actual motion parameters errors depth z range r viewed scene conduct analysis model scene needed interested statistically expected values motion estimates resulting possible scenes thus probabilistic model assume depth values scene uniformly distributed two arbitrary values z min r min zmax rmax minimization negative depth values assume directions flow measurements theta r introduces sine angle r minimization prefers vectors close center gravity points r bias recognized 40 alternatives proposed reduce bias without eliminating confusion rotation translation made uniformly distributed every direction every depth parameterizing n angle n x axis thus obtain following two functions zzmin z zzmin nd dz 10 measuring deviation epipolar constraint amount negative depth respectively functions 10 fivedimensional surfaces ffl errors motion parameters finally since scene view employ probabilistic model results statistical nature geometric constraints ffl minima 9 10 shall uncover interpreted likely occur 33 negative depth depth distortion section contains technical prerequisites needed study negative depth minimization geometric observation show relationship epipolar minimization minimization negative depth equation 7 shows estimated depth z range r given normal flow r delta n estimates motion written zor case noiseless motion measurements form equation 11 shows wrong depth estimates produced due inaccurate 3d motion values distortion multiplies real depth value produce estimate equation 12 fixed value describes surface r z r r space called isodistortion surface surface understood locus points space distorted depth multiplicative factor image measurements direction n fix n vary isodistortion surfaces resulting family change continuously varies thus scene points giving rise negative depth estimates lie 0 gamma1 distortion surfaces integral points directions giving rise negative depth estimates call negative depth volume section 5 make use isodistortion surfaces negative depth volume study geometric way function 10 resulting minimization negative depth values let us examine two different minimizations geometric perspective deriving deviation epipolar constraint consider integration points depth values expression equivalently denotes vector perpendicular u tr plane image coordinates deriving number negative depth values consider integration points depth values angle ff two vectors illustration given figure 2 two measures considered two different minimizations clearly related case negative depth consider angle ff whereas case epipolar constraint consider squared distance 2 amounts sin ffku tr tk major difference using two measures arises angles ff 90 ffi measure negative depth monotonic ff measure deviation epipolar constraint differentiate depth estimates positive negative value fact computed depth positive considered past approaches employing minimization epipolar constraint fact provides additional constraint could utilized negative depth figure 2 different measures used minimization constraints 6 ff minimization negative depth values projections motion fields b 2 epipolar constraint future maybe conjunction epipolar constraint interested influence constraint 3d motion estimation well thus addition minimization functions 9 10 discussed study minimization third function function amounts number values giving rise negative depth full flow measurements optical flow assumed analysis presented appendix b 34 model noise flow analysis plane also consider noise image measurements consider flow values form u choice noise model motivated following considerations first noise specific directions favored second assuming noise additive multiplicative dependence noise depth translational flow component proportional inverse depth therefore define noise using two stochastic variables z first second moments stochastic variables independent independent image position independent depth 35 overview paper summary results related work approach expresses functions 9 10 terms ffl ffl finds conditions ffl ffl satisfy local minima represent solutions different estimation algorithms procedures estimating 3d motion classified estimating either translation rotation first step remaining component rotation translation second step estimating components simultaneously procedures former kind result systems utilize inertial sensors provide estimates one components motion twostep motion estimation algorithms used thus three cases need studied case prior information 3d motion available cases estimate translation rotation available error imagine somehow rotation estimated error ffl functions become twodimensional variables ffl represent space translational error parameters corresponding fixed rotational error similarly given translational error ffl functions become threedimensional variables ffl represent space rotational errors corresponding fixed translational error study general case one needs consider lowest valleys functions 2d subspaces pass 0 image processing literature local often referred ravine lines courses three cases studied four optimizations epipolar minimization sphere plane full field view restricted field view vision minimization negative depth sphere plane thus twelve four times three cases since effects rotation image independent depth makes sense perform minimization negative depth assuming estimate translation available thus left ten different cases studied ten cases represent possible meaningful motion estimation procedures analysis shows 1 case cameratype eye restricted field view algorithms classes estimate motion parameters simultaneously ie prior information obtained solution error translation ff ffl rotation x0 ffl means projections translational rotational errors image perpendicular rotation around z axis least ambiguity refer constraint orthogonality constraint addition estimated translation x lie line passing origin image real translation refer second constraint line constraint similar results achieved case translation estimated first basis rotation subsequently found case rotation first estimated subsequently translation provides different results work performed absence error image measurementsin case becomes geometric analysis inherent confusion rotation translationand case image measurements corrupted noise satisfies model section 34 case derive expected values local global minima shown noise alter local minima global minima fall within valleys function without noise thus noise alter functions overall structure 2 case panoramic vision algorithms classes estimate motion parameters si multaneously obtained solution error translation rotational error perpendicular translation addition case epipolar minimization optic flow given translational error ffl obtained solution error rotation case negative depth minimization normal flow given rotational error obtained solution error translation cases ambiguities remain spherical eye case analysis simply performed noiseless flow large number error analyses carried 2 11 12 15 29 39 41 42 past cameratype eye published research kind full field view case none existing studies however attempted topographic characterization function minimized purpose analyzing different motion techniques studies consider optical flow correspondence image measurements investigate minimizations based epipolar constraint often restrictive assumptions structure scene estimator made main results obtained accordance findings particular following two results already occur literature translation along x axis easily confounded rotation around axis translation along axis easily confounded rotation around x axis small fields view insufficient depth variation fact long known experimental observation proved planar scene structures unbiased estimators 10 orthogonality constraint found confirms findings imposes even restrictive constraints shows addition xtranslation yrotation ytranslation xrotation decoupled furthermore found rotation around z axis easily distinguished motion components b maybank 32 33 jepson heeger 29 established line constraint much restrictive assumptions particular showed small field view translation far away image center irregular surface function 9 minima along line space translation directions passes true translation viewing direction fixation viewing direction becomes image center 4 epipolar minimization cameratype eye field view small quadratic terms image coordinates small relative linear constant terms therefore ignored computations carried symbolic algebraic computation software maple abbreviation intermediate results given first case noisefree flow studied considering circular aperture radius e setting focal length function zzmin e z z z r oe dr doe dz r oe polar coordinates sin oe performing integration one obtains z min assume translation estimated certain error 0 relationship among errors 3d motion minima 14 obtained firstorder conditions e1 0 yield follows ff ffl fi b assuming rotation estimated error ff among errors obtained e1 case relationship elaborate translational error depends parametersthat rotational error actual translation image size depth interval see appendix c general case need study subspaces e 1 changes least absolute minimum interested direction smallest second derivative 0 point motion errors zero find direction compute hessian 0 matrix second derivatives respect five motion error parameters compute eigenvector corresponding smallest eigenvalue scaled components vector amount seen points defined direction translational rotational errors characterized orthogonality constraint ff ffl fi line constraint x 0 next consider noise flow measurements model noise n x n defined section 34 derive ee ep expected value e ep amounts zzmin z e z ae r oe dr doe dz 16 thus z min fix x 0 ffl solve obtain relationship noiseless flow described 15 shows noise alter expected behavior techniques first step minimize translation b fix ff ffl fi ffl fl ffl solve obtain complicated relationship translational error actual translation rotational error c analyze behavior techniques minimize 3d motion parameters study global minimum ee minimization regard rotational parameters obtained 15 orthogonality constraint substituting 15 16 solving get addition gammaz thus absolute minimum ee ep found direction smallest increase e 1 described constraint orthogonality constraint line constraint 5 minimization negative depth volume cameratype eye following analysis study function describing negative depth values geometrically means negative depth volumes points corresponding negative depth distortion defined section 33 allows us incrementally derive properties function without considering respect parameters simplicity assume foe estimated foe inside image consider exact effects resulting volumes negative depth different directions outside field view first concentrate noiseless case ignore terms quadratic image coordinates 0 distortion surface equation 11 becomes gamma1 distortion surface takes form flow directions n x alternatively written cos sin 2 0 denoting angle x axis simplify visualization volumes negative depth different directions perform following coordinate transformation align flow direction x axis every rotate coordinate system angle obtain new coordinates x cos sin sin cos equations 17 18 thus become investigate techniques first step estimate rotation first study case fl extend analysis general case fl ffl 6 0 volume negative depth values every direction lies surfaces equation describes plane parallel 0 z plane distance x 0 0 origin describes plane parallel 0 axis slope 1 intersects x 0 0 plane thus obtain wedgeshaped volume parallel 0 axis figure 3 illustrates volume slice parallel x 0 z plane scene view extends depth values z min zmax denote area cross section parallel x 0 z plane negative depth volume direction seen figure 3 obtain minimum 0 lie x zzmin amounts fix fi 0 ffl solve x 0 obtain 0 distortion surface intersect gamma1 distortion surface middle depth interval plane depends depth interval thus independent direction therefore negative depth volume minimized 20 holds every direction since fi ffl sin 0 ffl obtain x0 ffl gamma1 distortion surface becomes surface easily understood slicing planes parallel x 0 0 plane every depth value z obtain line slope gamma1 intersects x 0 axis x figure 4a given z slopes lines different directions illustration volume negative depth given figure 4b z min z figure 3 slice parallel x 0 z plane volume negative estimated depth single direction z4002000 volume volume b figure 4 slices parallel x 0 0 plane 0 distortion surface c 0 gamma1 distortion surface depth values 0 volume negative depth values 0 gamma1 distortion surfaces let us express value found x 0 0 case fl order derive position 0 minimizes negative depth volume general case fl ffl 6 0 study change volume 0 changes x referring figure 5 seen depth value z change position 0 assuming z 6 0 causes area negative depth values change c 0 1 0 2 denote 0 coordinates intersection point gamma1 distortion contour depth z 0 distortion contours x x coordinates 0 therefore z change v c negative depth volume direction given zmin c dz amounts substituting z zminzmax verified order v c negative must gammasgnd interested minimizes v c solving obtain thus depends depth interval total negative depth volume obtained volume every direction minimized therefore rotational error ff independent fl ffl orthogonality constraint comment finiteness image necessary values c v c derived infinitely large image fl ffl small depth values z interval z min small coordinates intersections 0 1 0 2 lie inside image value c length image times since slope gamma1 distortion contour given z directions little effect relationship directions translational rotational motion errors effect however relative values motion errors intersections inside image 22 used describe value x 0 function fi 0 ffl interval depth values scene view b next investigate techniques minimize translation rotation first consider certain translational error change value fl ffl increase fl ffl decreases slope gamma1 distortion surfaces thus inferred figure 4a area negative depth values every direction every depth z increases thus addition know x0 ffl exact relationship fi 0 ffl x 0 characterized locations local minima function image processing literature often referred courses courses topographical sense 30 precise interested local minima direction corresponding largest second derivative compute largest eigenvalue 1 hessian h matrix second derivatives respect x 0 fi 0 ffl amounts obtain corresponding eigenvector e 1 fi 0 solving obtain last analysis noiseless case consider effects due finiteness aperture consider circular aperture assume certain amount translational error seek direction translational error results smallest negative depth volume independent direction translation 23 describes relationship x fi ffl smallest negative depth volume substituting 23 19 obtain crosssections negative depth volume function x 0 depth interval negative depth volume every direction amounts l l denotes average extent wedgeshaped negative depth volume direction total negative depth volume minimized considering circular aperture minimization achieved largest corresponds smallest extent l smallest corresponds largest l happens line constraint holds x0 y0 see figure 6 remains shown noise flow measurements alter qualitative characteristics negative depth volume thus results obtained first analyze orthogonality constraint analysis carried without considering size aperture shown analysis leads orthogonality constraint first let ignoring image size interested ev expected value integral cross sections amounts zzmin z zzmin dza approximate expectation integrand performing taylor expansion 0 second order gives x figure 5 change x 0 0 causes area negative depth values c increase 1 decrease 2 change amounts oe 2 l 1 l 2 figure crosssectional view wedgeshaped negative depth volumes circular aperture minimization negative depth volume given amount translational error occurs x0 y0 l denote areas cross sections average extents respectively two angles 1 2 two circles bounding given equations ffl z min x ffl zmax interested angle translational rotational error minimizes negative depth volume align translational error x axis 0 express rotational error sin obtain zzmin delta0 solving ev perpendicular ff ffl fi ffl minimizations considered next allow fl ffl different zero case fixed translational error volume increases fl ffl increases thus smallest negative depth volume occurs case fixed rotational error extend previous analysis studying change volume changing estimated translation noisy motion fields gamma1 distortion surface becomes x 0 distortion surfaces remain therefore vc becomes gammasgn evc takes form vc 21 thus obtain orthogonality constraint finally take account limited extent circular aperture case global minimization noise change structure isodistortion surfaces shown figure 6 presence noise smallest negative depth volume obtained foe estimated foe lie line passing image center proves orthogonality constraint full model well line constraint global minimum negative depth volume thus described constraint orthogonality constraint line constraint 6 epipolar minimization spherical eye function representing deviation epipolar constraint sphere takes simple form rmin z z sphere ae r theta r theta dadr refers surface element due spheres symmetry point r sphere exists point coordinates gammar since u tr integrand expanded product terms integrated sphere vanish thus rmin z z sphere theta dadr assuming translation estimated ffl minimizes e ep since resulting function nonnegative quadratic ffl minimum zero difference sphere plane already clear spherical case shown error translation made need compensate making error rotation planar case need compensate ensure orthogonality constraint satisfied b assuming rotation estimated error ffl translation minimizes since r uniformly distributed integrating r alter form error optimization consists sum two terms z z sphere theta da z z sphere multiplicative factors depending r min rmax angles ffl range 0 2 k l monotonic functions k attains minimum fix distance leading certain value k change position l takes minimum follows cosine theorem thus e ep achieves minimum lies great circle passing ffl exact position depending j ffl j scene view c general case information rotation translation available study subspaces changes least absolute minimum ie interested direction smallest second derivative 0 points defined direction calculate using maple 7 minimizing negative depth volume sphere assuming rotation estimated error ffl optimal translation minimizes negative depth volume since motion field along different orientations n considered parameterization needed express possible orientations sphere achieved selecting arbitrary vector point r sphere sthetar ksthetark defines direction tangent plane moves along half circle sthetar ksthetark takes every possible orientation exception points r lying great circle let us pick ffl perpendicular interested points space estimated negative range values r ksthetark estimated range r amounts sgnx provides sign x constraint divides surface sphere four areas iv whose locations defined signs functions theta delta r theta delta r ffl delta rs delta r shown figure 7 0 iv iii ii iv iiv ii iv iii area location constraint r sgnt theta delta figure 7 classification image points according constraints r four areas marked different colors textured parts parallel lines areas iii denote image points negative depth values exist scene bounded two hemispheres correspond front sphere back sphere seen front sphere direction n volume negative range values obtained consisting volumes areas ii iii areas ii iii cover amount area great circles theta delta area covers hemisphere minus area theta delta scene view unbounded r 2 0 1 every r range values areas iii result negative depth estimates area volume point r bounded ffl deltarsdeltar area iii bounded exist lower upper bounds r min rmax scene obtain two additional curves c min cmax c obtain negative depth values area cmax area iii c min ffl theta rs theta r 0 given ffl interested minimizes negative range volume corresponding negative range volume becomes smallest great circle theta delta shown next let us consider theta delta 6 0 let us change theta delta changes area type ii becomes area type iv area type iii becomes area type negative depth volume changed follows decreased spaces area ii area iii increased space area changed type iii type clearly decrease larger increase implies smallest volume obtained lying great circle since true minimum negative depth volume attained 2 b next assume prior knowledge 3d motion available want know configurations ffl negative depth values change least neighborhood absolute minimum analysis known ffl 6 0 next show ffl indeed different zero take 6 great circle let ffl perpendicular curves cmax c min expressed c 6 ts 0 sin denotes angle vectors curves consist great circle circle sin 6 ts parallel great circle figure 8 sin 6 ts circle disappears iv figure 8 configuration great circle ffl perpendicular textured part area denotes image points negative depth values exist scene bounded consider next two flow directions defined vectors 1 2 every point r 1 area iii defined 1 exists point r 2 area defined 2 negative estimated ranges r 1 r 2 add rmax gamma r min thus volume negative range obtained 1 2 amounts area sphere times rmax gamma r min area ii 1 contributes hemisphere area iii area 2 together contribute hemisphere total negative range volume decomposed word caution parameterization used directions ksthetark needed treat orientations equally varies along great circle constant speed theta r accelerates decelerates thus obtain uniform distribution normalization necessary normalization factors however affect previous proof due symmetry three components component v 1 originating set component v 2 originating set symmetric set v 1 component v 3 corresponding remaining consists range values areas type v 3 sin 6 ts zero thus rmax negative range volume equally large amounts area sphere times rmax gamma r min times takes values different zero shows ffl 6 0 exist vectors ffl 6 0 give rise negative depth volume however ffl 6 0 volume larger volume obtained setting follows figure 7 furthermore deduced given ffl negative depth volume lies areas type decreases moves along great circle away ffl areas c min cmax c min theta delta decrease proves addition conclusions preceding results constitute geometric statistical investigation observability 3d motion images basis number striking conclusions achieved first clearly demonstrate advantages panoramic vision process 3d motion estimation table 1 lists eight ten cases lead clearly defined error configurations shows 3d motion estimated accurately spherical eyes depending estimation procedure usedand systems might use different procedures different taskseither translation rotation estimated accurately planar eyes case possible procedures exists confusion translation rotation error configurations also allow systems inertial sensors use efficient estimation procedures system utilizes gyrosensor provides approximate estimate rotation employ simple algorithm based positive depth constraint translational motion fields derive translation obtain accurate estimate algorithms much easier implement algorithms designed completely unknown rigid motions amount searches 2d opposed 5d spaces 19 similarly exist computational advantages systems translational inertial sensors estimating remaining unknown rotation since positive depth constraint turns powerful since epipolar minimization consider depth positivity interesting research question arises future couple epipolar constraint positive depth constraint attempted first investigation problem study negative depth basis optic flow plane appendix b gave interesting results specifically found estimating motion parameters simultaneously minimizing negative depth optic flow provides solution error translation however rotation cannot decoupled translation makes clear cameras restricted fields view problem rotationtranslation confusion cannot escaped cameratype eyes found nature systems walk perform sophisticated manipulation systems need accurate segmentation shape estimation thus high resolution limited field view panoramic vision either compound eyes pair cameratype eyes positioned opposite sides head usually found flying systems obvious need larger field view also rely accurate 3d motion estimation always move unconstrained way face task equipping robots visual sensors necessarily copy nature also necessarily use commercially available instead could construct new powerful eyes taking advantage panoramic vision flying systems highresolution vision primates eye like one figure 9 assembled video cameras arranged surface sphere easily estimate 3d motion since moving sampling spherical motion field eye panoramic properties allowing accurate determination transformations relating multiple views unexpected benefit making easy estimate image motion high accuracy two cameras overlapping fields view also provide highresolution stereo vision collection stereo systems makes possible locate large number depth discontinuities given scene discontinuities image motion estimated accurately consequence accurate 3d motion table 1 summary results ii spherical eye cameratype eye epipolar minimization given optic flow given translational error ffl rotational error b without prior infor mation fixed translational error rotational error form b without priori information mo tion errors satisfy minimization negative depth volume given normal flow given rotational error ffl translational error b without prior infor mation given rotational error translational error form gammax b without error infor mation errors satisfy image motion eye figure 9 well suited developing accurate models world necessary many roboticservoing applications figure 9 compoundlike eye composed conventional video cameras arranged sphere looking outward r determining 3d motion structure optical flow generated several moving objects inherent ambiguities recovering 3d motion structure noisy flow field active vision active perception principles animate vision rigid body motion depth optical flow computational approach visual motion perception estimating 3d egomotion perspective image sequences error sensitivity recovery object descriptions analytical results error sensitivity motion estimation two views understanding noise sensitivity structure motion planning control simultaneous robotworld handeye calibration robustness correspondencebased structure motion new approach visual servoing robotics motion structure motion point line matches direct perception threedimensional motion patterns visual motion qualitative egomotion subspace methods recovering rigid motion algorithm implemen tation visual guided object grasping robot vision relative orientation tutorial visual servo control subspace methods recovering rigid motion ii theory interpretation moving retinal image algorithm analysing optical flow based leastsquares method theoretical study optical flow theory reconstruction image motion estimation threedimensional motion rigid objects noisy observations egomotion relative depth map optical flow determining instantaneous direction motion optical flow generated curvilinear moving observer processing differential image motion optimal computing structure motion using point correspondence optimal motion estimation understanding noise critical role motion error scene reconstruction statistical analysis inherent ambiguities recovering 3d motion noisy flow field tr algorithm analysing optical flow based leastsquares method inherent ambiguities recovering 3d motion structure noisy flow field estimating 3d egomotion perspective image sequence relative orientation estimation threedimensional motion rigid objects noisy observations analytical results error sensitivity motion estimation two views planning control subspace methods recovering rigid motion statistical analysis inherent ambiguities recovering 3d motion noisy flow field principles animate vision twoplusonedimensional differential geometry qualitative egomotion robot vision ctr john oliensis leastsquares error structure infinitesimal motion international journal computer vision v61 n3 p259299 februarymarch 2005 tao xiang loongfah cheong understanding behavior sfm algorithms geometric approach international journal computer vision v51 n2 p111137 february jan neumann cornelia fermller yiannis aloimonos hierarchy cameras 3d photography computer vision image understanding v96 n3 p274293 december 2004 abhijit ogale cornelia fermuller yiannis aloimonos motion segmentation using occlusions ieee transactions pattern analysis machine intelligence v27 n6 p988992 june 2005