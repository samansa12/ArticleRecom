cost model selecting checkpoint positions time warp parallel simulation abstractrecent papers shown performance time warp simulators improved appropriately selecting positions checkpoints instead taking periodic basis paper present checkpointing technique selection positions checkpoints based checkpointingrecovery cost model given current state model determines convenience recording checkpoint next event executed done taking account position last taken checkpoint granularity ie execution time intermediate events using estimate probability restored due rollback future execution synthetic benchmark different configurations used evaluating comparing approach classical periodic techniques testing environment used cluster pcs connected myrinet switch coupled fast communication layer specifically designed exploit potential type switch obtained results point solution allows faster execution cases exhibits additional advantage less memory required recording state vectors possibly contributes performance improvements memory critical resource specific application performance study case cellular phone system simulation finally reported demonstrate effectiveness solution real world application b execution events lp also referred causality mechanisms general conservative optimistic conservative ones enforce causality requiring lps block certain safety criteria met instead optimistic mechanisms events may executed violation timestamp order block safe policy considered whenever causality error detected recovery procedure invoked allows exploitation parallelism anytime possible causality errors occurs focus time warp optimistic mechanism 10 allows lp execute events unless pending event set empty uses checkpointbased rollback recover timestamp order violations rollback recovers state lp value immediately prior violation rolling back lp undoes effects events scheduled rolled back portion simulation done sending message antievent event must undone upon receipt antievent corresponding already executed event recipient lp rolls back well exist two main checkpointing methods support state recovery namely incremental state saving sparse checkpointing 1 former 2 23 25 maintains history beforeimages state variables modified event execution state recovery accomplished backwards crossing logged history copying beforeimages original state locations solution advantage low checkpointing overhead whenever small fractions state updated event execution however order provide short state recovery latency requires rollback distance sufficiently small second method namely sparse checkpointing traditionally defined recording lp state periodically event executions 11 value greater one used checkpointing overhead kept low however additional time penalty added state recovery precisely state recovery unrecorded state involves reloading latest checkpoint preceding state reupdating state variables replay intermediate events coasting forward shown 4 19 periodic checkpoints taken event executions give rise coasting forward length uniformly distributed 0 recently solutions mixing features methods presented 5 15 22 recent papers 16 17 shown possible achieve fast state recovery less checkpointing overhead periodic checkpointing appropriate selection checkpoint positions adopted along line present paper checkpointing technique selects positions checkpoints basing cost model associates state checkpointing recovery overhead checkpointing overhead either time take checkpoint zero depending whether state recorded recovery overhead time penalty associated possible future rollback state penalty varies depending whether state recorded state recorded must reconstructed coasting forward recovery overhead depends position last taken checkpoint granularity coasting forward events convenience recording state checkpoint determined basing cost model order solve model estimate probability state restored due rollback future simulation execution performed present method solve problem actually requires quite negligible computational effort addition remark cost model simple solved online without incurring significant overhead final point note model takes explicitly account granularity simulation event mean value among events determining recovery overhead associated given state allows solution exhibit potential providing good performance also case simulations high variance event granularity typical battlefield simulations simulations complex communication systems also report simulation results classical benchmark phold model 7 several different configurations obtained data show technique actually leads reduction checkpointingrecovery overhead thus allowing faster execution simulation happens especially benchmark parameters chosen represent large complex simulated systems addition noted amount memory used technique similar even less previous solutions remainder paper organized follows section 2 background sparse checkpointing methods presented section 3 cost model outcoming checkpointing technique described performance data reported section 4 related work pointed introduction traditional approach sparse checkpointing consists recording lp state periodically event executions checkpoint interval several analytical models presented determine timeoptimal value opt checkpoint interval assumption underlying models coasting forward length uniformly distributed 0 results reported 4 19 shown good approximation real distribution coasting forward length anytime checkpoints taken periodic basis addition models 11 13 19 assume exists fixed value time record state checkpoint usually good approximation granularity simulation events small variance general model one presented 21 takes account exact granularity simulation events affects coasting forward time thus state recovery time relevance model relies fact several real world simulations battlefield simulations simulations mobile communication systems actually high variance event granularity taken account order determine timeoptimal value opt checkpoint interval extended experimental study 14 pointed effects variation checkpoint interval rollback behavior several stochastic queuing networks connected different topologies considered presented results showed checkpoint interval slightly increases throttling effect appears tends reduce number rollbacks due interactions among lps processor instead checkpoint interval largely increased produces average much longer coasting forwards thrashing effect gives rise increase number rollbacks due interactions among lps distinct processors tackle dynamism rollback behavior originated example variations load processors even thrashingthrottling phenomena number adaptive techniques dynamically adjust value proposed 1 4 19 based observation parameters lp behavior example rollback frequency certain number executed events referred observation period recalculate checkpoint interval beginning period different approach found 12 recalculation executed every globalvirtualtime gvt evaluation 2 recently two papers 16 17 shown possible reduce overhead due checkpointing state recovery carefully selecting positions checkpoints instead taking periodically method 16 takes checkpoint decision basis observation differences timestamps two consecutive events whenever execution event going determine large simulated time increment checkpoint taken prior execution event solution implicitly assumes lp moves state state 0 probability restored due rollback inthe gvt defined lowest value among timestamps events either yet executed currently executed carried messages still transit gvt value represents commitment horizon simulation rollback simulated time preceding gvt ever occur gvt notion used reclaim memory allocated obsolete messages state information allow operations cannot undone eg ios displaying intermediate simulation results etc memory reclaiming procedure known fossil collection future execution proportional simulated time increment moving 0 although assumption suited several simulations 3 16 never extensively tested limits generality solution method 17 based notion probabilistic checkpointing works follows state estimate probability restored due rollback performed namely p e moving 0 value ff uniformly distributed interval 01 extracted checkpoint taken ff recorded probability equal p e therefore higher probability restored higher probability recorded checkpoint noted method probabilistic decision actually memoryless take account position last taken checkpoint establish must recorded checkpoint taken events ago reconstructed coasting forward without incurring significant time penalty true especially case small grained coasting forward events case need record checkpoint even probability p e minimal checkpointing technique propose paper solves latter problem cost model relies takes account position last taken checkpoint addition already pointed introduction recovery overhead associated state computed explicitly considering granularity event involved possible coasting forward mean granularity value latter feature allows solution highly general potential providing good performance case small large variance event granularity 3 selecting checkpoint positions section present cost model associated policy selecting positions checkpoints method estimate probability values needed solution cost model introduced finally discuss problem memory usage characteristic sparse checkpointing method due memory space allocated obsolete messages cannot discarded execution fossil collection procedure show solve problem checkpointing technique introduction additional rare periodic checkpoints 31 cost model selection policy lp moves one state another due execution simulation events example shown figure 1 arrow extending toward rightend represents simulated time black circles represent event timestamps labeled boxes represent state values given execution event e timestamp simulated time event timestamps lp states e figure 1 lp moves 0 due execution e points simulated time ie points corresponding event timestamps example lp moves state 0 due execution event e timestamp state passed lp course simulation execution associate probability value namely p probability restored due future rollback value p used construction cost model expresses checkpointingrecovery overhead associated denoting ffi time save reload whole lp state therefore assumed constant previous analyses see 11 13 19 21 22 checkpointing overhead cs associated state expressed follows 3 recorded 0 recorded 1 expression 1 points recorded checkpoint checkpointing overhead associated quantified time take checkpoint ffi let us model recovery overhead associated proceeding discussion remark overhead expresses latency recover state function checkpointing activity lp take account effects sending antievents recall latter overhead directly dependent checkpointing state recovery actions actions interested denote es set events move lp latest checkpointed state preceding example shown figure 2a latest checkpointed state preceding x g instead example figure 2b latest checkpointed state preceding g denoting ffi e execution time event e 2 es associate 3 present analysis use value ffi state saving time time reload recorded state current state buffer common realistic assumption however analysis easily extended cases assumption verified simulated time checkpoint es simulated time es checkpoint b figure 2 two examples es following recovery overhead rs state 4 recorded recorded 2 expression 2 states case rollback happens probability p recorded checkpoint recovery overhead consists time reload current state buffer namely ffi otherwise consists time ffi reload latest checkpoint preceding plus time replay events es ie coasting forward time note defining rs implicitly assumed probability p change depending whether recorded technically assumed checkpointing actions affect rollback behavior typical assumption common analytical models see 19 21 22 note assumption distant real behavior usually thrashing throttling phenomena pointed 14 due variations checkpointing actions significant combining 1 2 get following expression checkpointingrecovery overhead crs associated state note crs sum cs rs recorded recorded expression 3 represents cost model using model introduce following selection policy determining positions checkpoints basically selection policy state recorded checkpoint execution next event ie one moves lp subsequent state recording results minimization value crs technically denoting crs value crs case recorded 4 recall ffi e keeps account time execute event e take account time sendout new events possibly scheduled execution e therefore ffi e expresses exactly time replay e coasting forward purpose coasting forward reupdate state variables ie event sent phase crs n value crs case recorded selection policy synthesized following expression selectionpolicy moving crs crs n record else record computing value crs requires knowledge ffi p parameter ffi usually known upon execution simulation depends size number bytes state time per byte needed recording 5 instead p unknown depends several parameters features proper simulation model number processors used among others presentation solution estimate value p low cost delayed section 32 computing value crs n requires addition ffi p also knowledge execution time granularity events executed since last checkpoint preceding taken almost simulations granularity determined type event order compute crs n lp needs keep track type events es case simulations granularity simulation events cannot determined type lp needs monitor cpu time actually used execution events es note among several parameters cost model determines convenience recording checkpoint prior execution next event basing also position last taken checkpoint determines events es ii exact granularity events executed last taken checkpoint ie granularity events es remark information points ii actually encodes maximal knowledge related portion simulation already executed past checkpointing actions relevant establish amount recovery overhead associated case recorded rollback occurs precisely positions checkpoints latest one preceding granularity event set es affect time reconstruct case recorded rollback occurs would like discuss next fundamental point discussion preceded simple introductory example let us consider portion simulation execution shown figure 3 5 recall recording done either via software typical solution use special purpose hardware 8 checkpoint checkpoint es simulated simulated checkpoint b e figure 3 effects recording crs 0 immediately follows event moves lp 0 e case recorded checkpoint see figure 3a set es 0 contains event e checkpointingrecovery overhead crs 0 associated state 0 recorded recorded instead recorded checkpoint see figure 3b set es 0 contains events set es ie e 1 e 2 example plus event e therefore checkpointingrecovery overhead crs 0 becomes follows recorded recorded note also derive expressions 4 5 suppose p 0 independent checkpointing actions previous example points outcoming decision selection policy whether state must recorded determines shape function cr associated states follow simulation execution implies taking checkpoint decision basing minimization checkpointingrecovery overhead associated current state lp could lead minimization whole checkpointingrecovery overhead simulation ie resulting sum checkpointingrecovery overheads associated states passed course simulation however recall global minimization requires knowledge exact sequence states passed course simulation execution ie exact sequence events executed unknown lp furthermore even sequence known selection policy based minimization would require enormous computational effort take checkpoint decision would dramatically decrease execution speed simulation conclusion selection policy introduced selects best checkpoint positions respect portion simulation already executed known lp 32 estimating probability values pointed section 31 state solution cost model ie computing values crs crs n needs knowledge probability p section present method estimate value method resemblances presented 3 17 entering description recall method must cpu time memory space needed keeping track statistical data must approach zero cpu time compute estimate p must approach zero well happen method could severely decrease execution speed simulation note method uses large amount memory two negative effects performance may occur management large memory may lead poor locality reference virtual memory system ii amount memory destined record messages state information reduced may require frequent gvt calculation fossil collection execution let sts denote value simulated time associated state let e timestamp te event moves lp subsequent state execution event e produces increment simulated time lp moving sts te state associate simulated time interval namely whose length delimited follows probability p state restored due future rollback corresponds probability rollback occur simulated time interval recall rollback interval occurs either events scheduled later timestamps interval ie e executed event e 0 sts te scheduled lp lp scheduled event e rolls back revoking e ie antievent e arrives e executed estimate probability p basing length interval monitoring frequency rollback occurrence simulated time intervals specified length define simulated time points simulated time positive semiaxis intervals state exists interval length namely lis within interval ie interval lp keeps variable r initially set zero counts amount rollback occurrences simulated time intervals ix whenever rollback occurs state x variable r increased one recall computing length ix order identify corresponding counter r updated quite simple operation requires compute difference two simulated time values one simulated time state x timestamp event moved lp x subsequent state state estimated r n n local variable counts number states passed ie number events executed lp 6 overall sequence steps take checkpoint decision moving follows upon execution event e moves lp subsequent state length lis interval computed corresponding variable r identified estimate p computed ratio r n outcoming value used solve cost model finally selection policy see section 31 determines convenience recording prior execution event e basing solution cost model simple uniform decomposition simulated time positive semiaxis obtained imposing length equal delta interval defining value max case value max determines number intervals decomposition ie amount memory destined counters r furthermore value delta chosen depending average values distribution functions timestamp increment way individuation counter updated time rollback occurs individuation counters estimate probability values quite simple introduces negligible overhead example rollback occurs state x index counter r updated easily computed follows recall lix computed simply taking difference simulated time values note previous estimation method modified order cope nonstationary probability values caused example variations either load processors behavior lps simulated time particular basing common belief simulations near past behavior good approximation near future behavior probability values estimated using statistical data rollback occurrences related temporal window instead collected beginning execution hundred events usually constitute window length producing reliable results 4 17 19 6 events executed coasting forward counted n real simulation events actually artefact state recovery procedure therefore states passed coasting forward real simulation states lp cry pr pe b cry pr pe interval pe selection policy produces interval pe selection policy produces correct decision correct decision figure 4 general cases functions cr cr n 321 discussion effectiveness estimation method method proposed estimate p advantage implemented low cost terms cpu time memory space hand shows drawback estimated probability value might quite close real one note control trust estimate performed order solve problem complex statistical methods used might negative impact performance thus general feasible solution show however effects estimate probability values quite good significant particular states ie subset states passed course simulation simple method introduced general enough refined represent effective solution specific problem proceeding discussion introduce following simple notion say selection policy introduced section 31 leads wrong decision anytime checkpoint decision based estimated value p different one would obtained considering real value p otherwise say selection policy produces correct decision figure 4a figure 4b show two cases linear functions crs crs n versus value p recall p equal zero cr n equal zero well cr equal ffi cases shown general two functions intersection point within interval 01 p particular situation obtained cr whole interval intersect best intersect p 1 denote b p value p corresponding intersection point addition denote p r real value p p e corresponding estimated value suppose see figure 4a case cr cr n real convenience recording checkpoint decision taken selection policy estimated value p e less b therefore value p e p selection policy produces always correct decision suppose p r b see figure 4b case cr cr n real convenience recording decision taken selection policy estimated value p e larger equal b therefore value p e b p selection policy produces always correct decision overall selection policy produces correct decision anytime one following two cases occurs lower b c2 p r p e higher equal b instead produces wrong decision anytime one following two cases occurs case c3 c4 may occur value p r quite close b p case may get wrong decision even small distance p r p e anyway distance must moves e opposite side p r respect value b ii value p r quite far b p large distance exists p r anyway distance must moves p e opposite side p r respect value b previous considerations argue order selection policy produce wrong decision cases c3 c4 set conditions must satisfied ie producing situations ii states conditions actually satisfied general small subset states passed course simulation therefore majority states selection policy produce correct decisions 7 feature derives fact selection policy actually maps values continuous function ie difference cr cr n boolean domain mapping discrete domain removes effects noise ie effects estimate probability values good unless noise oversteps threshold 7 recall addition exists set states cases c3 c4 never occur independently distance real estimated probability values states crn cry whole interval 01 p states either two functions crn cry intersect intersect point b cases c3 c4 cannot occur neither pr pe higher one states selection policy always produces correct decision 33 adding periodic checkpoints cope memory usage sparse checkpointing solution suffers problem known memory usage problem brief description problem provided section solution allowing checkpointing technique cope problem presented basically memory usage problem related notion gvt fossil collection procedure recovers memory allocated obsolete state information messages specif ically rollback simulated time equal gvt possible order correctly support state recovery lp must retain latest recorded state ie latest checkpoint simulated time less equal gvt also messages carrying events timestamp larger therefore checkpoint massages cannot discarded execution fossil collection procedure states recorded course simulation possible number messages must retained large drawback incurred amount memory recovered fossil collection may small thus fossil collection procedure invoked frequently memory saturates frequently may detrimental effects performance checkpointing technique allows possibility states recorded course simulation execution may happen whenever state value probability p approaches zero extreme case p exactly equal zero state selection policy section 31 never induce lp take checkpoint pushes technique incur memory usage problem order prevent problem allow lp take rare periodic checkpoints purpose lp maintains two integer variables namely max dist event ex variable max dist records maximum number event executions allowed two consecutive checkpoint operations variable event ex represents actual distance terms events last checkpoint operation using two variables selection policy modified follows modifiedselectionpolicy moving record else record modified selection policy allow distance two consecutive checkpoints larger max dist events ie max dist state transitions thus avoiding memory usage problem checkpointing techniques based periodic checkpoints tackle memory usage problem adopting defaults maximum value checkpoint interval max usually 15 30 see 4 19 value within interval well suited max dist 34 final description checkpointing technique another point fixed order provide final complete description checkpointing technique modified selection policy introduced section 33 original one relies solution cost model turn needs estimate probability values means policy cannot applied least statistical data available note problem absence statistical data selection initial value proper checkpointing technique common problem almost existing techniques 4 16 17 19 overcome problem partition execution lp two phases phase1 starts beginning simulation execution consists hundred events phase lp collect statistical data estimate probability values records checkpoints states passed easily done adopting modified selection policy max dist initially set one second phase namely phase2 lp continues collect statistical data possibly using windowing mechanism takes checkpoint decision basing modified selection policy value max dist selected within interval 1530 figure 5 complete behavior lp reported hundred events settings dist 1 actions collect statistical data select checkpoint positions basing modified selection policy phase2 till end simulation settings select x 2 15 30 max dist x actions collect statistical data select checkpoint positions basing modified selection policy figure 5 complete lp behavior actions relevant checkpointing technique shown 4 performance study section experimental results reported compare performance achievable using checkpointing technique proposed paper hereafter ct1 one previous solutions considered three previous checkpointing techniques comparison one presented ronngren ayani ct2 19 one presented fleischmann wilsey ct3 4 one presented quaglia ct4 17 ct2 ct3 induce lp take checkpoints periodic basis ct2 based analytical model defines value timeoptimal checkpoint interval assumptions underlying model already discussed section 2 model used recalculate value checkpoint interval basing observed variations rollback frequency ct3 actually heuristic algorithm dynamic recalculation derived basing extensive profiling analysis parallel optimistic simulation digital systems based monitoring cost function equals sum checkpointing coasting forward overheads value one adaptation direction towards increasing values initially selected adaptation step one ie adaptation point increased one adaptation direction inverted time monitored value cost function shows significant increase ct4 relies probabilistic checkpoint decision already discussed section 2 consider incremental state saving method comparison previous studies 13 18 20 already pointed incremental state saving sparse checkpointing outperform distinct classes simulation problems two approaches effective distinct domain specifically incremental methods preferable simulations large state size small portions state updated event execution quite short rollback distances simulation setting sparse checkpointing provides better performance showing results comparative analysis describe main features used hardwaresoftware architecture present selected benchmark introduce performance parameters measured 41 hardwaresoftware architecture benchmark hardware architecture used cluster machines pentium ii 300 mhz 128 mbytes ram connected via ethernet number machines cluster four interprocessor communication relies message passing supported pvm 24 instance time warp kernel processor kernel schedules lps event execution according smallest timestampfirst policy antievents sent aggressively ie soon lp rolls back 9 fossil collection executed periodically one second tested performance checkpointing techniques using synthetic benchmark known phold model originally presented 7 consists fixed number lps constant number jobs circulating among lps referred job population routing jobs among lps timestamp increments taken stochastic distributions chosen benchmark two main reasons parameters eg event execution time size state etc easily modified ii one used benchmarks testing performance checkpointing techniques 1 16 19 21 addition important remark benchmark usually shows rollback behavior similar many synthetic benchmarks several real world models benchmark considered three different configurations progressively complex features concerning execution time ie granularity simulation events behavior lps ie route jobs among third configuration benchmark actually models complex system configurations separately described details following paragraphs first configuration conf1 configuration phold model composed 64 homogeneous lps timestamp increment exponentially distributed mean 10 simulated time units lps execution time granularity event fixed 140 microsec onds job population one job per lp jobs equally likely forwarded lp two distinct cases size lp state considered lp fictitious state 2 kbytes case time recording entire state approximately microseconds ii lp fictitious state 8 kbytes case time recording entire state approximately microseconds cases fictitious state consists array integers times reported obtained recording state copying entries one one case 2 kbytes state size models simulations mediumsmall state granularity respect event granularity whereas case 8 kbytes state size models simulations large state granularity second configuration conf2 configuration features conf1 except concerns granularity simulation events three distinct types jobs ie simulation events namely b c three types granularity respectively job population one job per lp type job selected among three job types according uniform distribution job served forwarded another lp job type redefined uniformly selecting set fa b cg probability 13 type job remains unchanged forwarded another lp configuration considered two distinct state sizes conf1 third configuration conf3 configuration features conf2 except concerns routing jobs among lps 8 hot spot lps 30 jobs must routed hot spot lps change course simulation change 3 theta 10 4 simulated time units sequence changes defined prior simulation execution randomly picking new hot spots among lps configuration possibly gives rise simulations reach steady state concerns rollback behavior furthermore complex point view event granularity point view routing decisions determine simulation events distributed among lps features allow conf3 nicely approximate simulation models complex systems two state sizes previous configurations considered conf3 three configurations benchmark run using four machines cluster machine runs 16 lp user load runs machine checkpointing technique ct1 probability values estimated using uniform decomposition simulated time positive semiaxis windowing mechanism used order compute estimate basing statistical data refer last 500 executed events decomposition adopted ct4 finally ct2 ct3 recalculation value checkpoint interval executed 500 events ie observation period fixed 500 events techniques 42 performance parameters report measures related following parameters ffl event rate er number committed events per second parameter indicates fast simulation execution given checkpointing technique ffl efficiency eff ration number committed events total number executed events excluding coasting forward ones parameter indicates percentage cpu time spent executing productive simulation work ie committed events affected checkpointing technique ffl average checkpointing overhead aco per state average time spent checkpointing operations per state passed course simulation note number states passed actually equal number executed events aco also expresses checkpointing overhead per event 8 ffl average recovery latency arl average time state recovery case rollback addition also report data point memory utilization mu different checkpointing techniques recall average memory utilization cannot observed without interfering simulation execution instead maximum memory utilization ie 8 states passed execution coasting forward taken account calculation aco therefore aco expresses checkpointing overhead per event computed overall committedrolledback events already pointed previous note coasting forward events actually artefact state recovery procedure real simulation events maximum amount memory destined keeping checkpoints messages easily measured note memory utilization must take account also memory destined messages carrying events indicator memory usage problem pointed section 33 configuration benchmark report average observed values previous parameters computed 20 runs done different seeds random number generation least 5 theta 10 6 committed event simulated run 43 experimental results following paragraphs report obtained results selected configurations benchmark final discussion results presented note report also parameter values measured case checkpoint execution simulation event checkpointing technique often referred copy state saving css comparison results obtained css important point real performance gain achievable sparse checkpointing techniques simulations css act control simulations case 2 kbyte state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 70 70 7174 8544 197 ct4 22 178 7382 10423 83 case 8 kbyte state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 280 280 7295 5981 549 44 663 7454 8304 122 ct4 43 584 7334 8617 115 figure conf1 obtained results reported figure 6 case 2 kbytes case 8 kbytes state size general consideration techniques ct1 ct4 show around values eff indicates affect percentage cpu time spent executing productive simulation work almost way instead css originates 9 simulations content message size 32 bytes smaller values eff phenomenon supposed derive longer average recovery latency namely arl ct1ct4 pointed 14 may give rise throttled execution simulation ie execution slightly less rollbacks indicates compared css sparse checkpointing techniques show advantage better balance checkpointing recovery overheads usually also allow reduction negative effects rollback performance 10 case 2 kbytes state size performance ct2 ct3 quite similar ct2 allowing slightly faster execution simulation ie higher value er also amounts memory used techniques similar ct3 shows slightly larger value maximum mu compared css techniques allow faster execution 18 17 respectively addition reduce amount used memory around 23 times ct4 perform better sparse checkpointing techniques values er ct1 ct4 larger observed ct2 ct3 ct1 allowing faster execution 3 compared ct4 phenomenon explained looking data concerning aco arl values aco ct1 ct4 less ct2 ct3 true especially ct1 technique compared ct2 ct3 exhibits er 6 7 higher furthermore ct1 ct4 show values arl similar ct2 ct3 thus allowing average fast state recovery less checkpointing overhead points appropriate selection checkpoint positions actually allows reduction checkpointingrecovery overhead reported values maximum mu indicate techniques ct1 ct4 use around amount memory results obtained case 8 kbytes state size quite similar previous ones main difference compared css techniques ct1ct4 show performance gain amplified aco css case 8 kbytes state size notably larger 4 times case 2 kbytes state size instead sparse checkpointing techniques allow aco case 8 kbytes state size less 2 times larger compared case 2 kbytes state size conf2 results reported section see figure 7 allow us point different checkpointing techniques tackle high variance event granularity recall conf2 three different event types three distinct granularities data show performance provided ct2 ct4 conf2 worse observed conf1 ct3 shows around performance ct1 performs slightly better conf1 shows value aco less observed conf1 consequence confirmed results reported 21 case 2 kbytes state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 70 70 7048 8421 189 ct4 22 182 7385 10226 71 case 8 kbytes state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 280 280 7446 6096 540 figure 7 results conf2 performance gain ct1 techniques slightly amplified compared conf1 behavior directly derives form high variance event granularity conf2 ct1 takes account granularity event selecting positions checkpoints ct1 recognize sequence large grained events executed last taken checkpoint allow sequence long ie break sequence checkpoint happen especially sequence pushes lp pass state high estimated probability restored due future rollback sequences events recognized thus broken techniques may originate long recovery latency order bound latency techniques induce lps take checkpoints finally note also configuration amounts memory used different techniques except case css quite similar conf3 results configuration see figure 8 point checkpointing techniques tackle high variance event granularity complex also variable behavior routing jobs among lps recall configuration pushes benchmark exhibits features quite close simulation model complex system must noted conf3 gives rise simulations higher efficiency compared conf1 conf2 presence hot spot lps allows simulation advance less chaotically good percentage jobs routed towards hot spots ie jobs free move everywhere lower probability basically performance gain shown ct1 previous configurations confirmed indicates windowing approach collection case 2 kbytes state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 70 70 7843 10654 251 ct3 19 262 8254 11932 71 case 8 kbytes state size checkpointing aco arl eff er maximum mu technique microsec microsec committed events per sec mbytes css 280 280 8016 7846 686 figure 8 results conf3 statistical data estimate probability values actually allows ct1 get potential react dynamic changes rollback behavior originated variable routing jobs lifetime simulation particular case 2 kbytes state size ct1 allows faster execution 3 10 compared sparse checkpointing techniques case 8 kbytes state size gain 3 8 gain derives especially much lower aco ct1 compared techniques 431 general comments performance data collected study indicate real advantage appropriate selection positions checkpoints advantage actually amplified case simulation models exhibiting complex features models checkpointing technique must treat state passed specific way ie decision whether state must recorded checkpoint taken looking features proper state namely probability restored due rollback position last taken checkpoint granularity intermediate events happen risk state high probability restored due rollback recorded even last checkpoint taken several event executions ago ii intermediate events large grained may detrimental effect performance case rollback state really occurs latency recover state coasting forward might quite long checkpointing techniques checkpoint decision taken periodic basis potential tackle previous problem directly way techniques bound recovery latency select adequately small value checkpoint interval turn may push checkpointing overhead non minimal recovery latency obtained expense less checkpointing overhead adequate selection checkpoint positions adopted another important point highlighted study checkpointing technique appropriate selection positions checkpoints like ct1 designed implemented basing simple statistical methods introduce quite negligible overhead implemented basic requirement satisfied order technique overcharge simulation program nevertheless technique potential provide quite good performance summary paper presented general solution tackling checkpoint problem time warp simulations checkpointing technique proposed selects positions checkpoints basing cost model expresses checkpointingrecovery overhead associated state passed course simulation cost model determines convenience recording current state execution next event requires estimate probability current state restored due rollback propose lowoverhead simple solution problem discuss effectiveness specific application simulation results also reported quantify performance achievable checkpointing technique purpose classical benchmark several different configurations used data show selection positions checkpoints induced technique improves performance compared existing approaches including conventional periodic checkpointing tech niques happens especially benchmark parameters selected order let represent simulation model complex behavior indicates presented solution highly general potential allow faster execution wide class simulations acknowledgments author would like thank bruno ciciani many interesting discussions checkpoint problem time warp simulators special thank goes vittorio cortellessa help preparation simulation code r runtime selection checkpoint interval time warp simulations reducing rollback overhead time warp based distributed simulation optimized incremental state saving estimating rollback overhead optimism control time warp comparative analysis periodic state saving techniques time warp simulators state saving interactive optimistic simulation parallel discrete event simulation performance time warp synthetic workloads design evaluation rollback chip special purpose hardware time warp space management cancellation mechanisms time warp virtual time selecting checkpoint interval time warp simulation adaptive checkpoint intervals optimistically synchronized parallel digital system simulator analytical comparison periodic checkpointing incremental state saving effects checkpoint interval time space time warp rollbackbased parallel discrete event simulation using hybrid state saving event history based sparse state saving time warp combining periodic probabilistic checkpointing optimistic simulation fastsoftwarecheckpointing optimistic simulation embedding state saving event routine instructions adaptive checkpointing time warp comparative study state saving mechanisms time warp synchronized parallel discrete event simulation event sensitive state saving time warp parallel discrete event simu lations analytical model hybrid checkpointing time warp distributed simulation incremental state saving speedes using c plus plus framework parallel distributed computing external state management system optimistic parallel simulation tr ctr francesco quaglia andrea santoro bruno ciciani conditional checkpoint abort alternative semantic resynchronization ccl proceedings sixteenth workshop parallel distributed simulation may 1215 2002 washington dc andrea santoro francesco quaglia communications network benefits semiasynchronous checkpointing time warp simulations large state pcs model proceedings 33nd conference winter simulation december 0912 2001 arlington virginia andrea santoro francesco quaglia transparent state management optimistic synchronization high level architecture simulation v82 n1 p520 january 2006 francesco quaglia andrea santoro modeling optimization nonblocking checkpointing optimistic simulation myrinet clusters journal parallel distributed computing v65 n6 p667677 june 2005 diego cucuzzo stefano dalessio francesco quaglia paolo romano lightweight heuristicbased mechanism collecting committed consistent global states optimistic simulation proceedings 11th ieee international symposium distributed simulation realtime applications p227234 october 2226 2007 moon jung chung jinsheng xu overhead reducing technique time warp journal parallel distributed computing v65 n1 p6573 january 2005 francesco quaglia vittorio cortellessa processor scheduling problem time warp synchronization acm transactions modeling computer simulation tomacs v12 n3 p143175 july 2002 francesco quaglia andrea santoro modeling optimization nonblocking checkpointing optimistic simulation myrinet clusters proceedings 17th annual international conference supercomputing june 2326 2003 san francisco ca usa francesco quaglia andrea santoro nonblocking checkpointing optimistic parallel simulation description implementation ieee transactions parallel distributed systems v14 n6 p593610 june