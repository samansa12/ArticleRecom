rigid body segmentation shape description dense optical flow weak perspective abstractwe present algorithm identifying tracking independently moving rigid objects optical flow previous attempts segmentation via optical flow focused finding discontinuities flow field discontinuities indicate change scene depth general signal boundary two separate objects proposed method uses fact independently moving object unique epipolar constraint associated motion thus motion discontinuities based selfocclusion distinguished due separate objects use epipolar geometry allows determination individual motion parameters object well recovery relative depth point object algorithm assumes affine camera perspective effects limited changes overall scale camera calibration parameters required kalman filter based approach used tracking motion parameters time b introduction visual motion provide us two vital pieces information segmentation visual scene distinct moving objects shape information objects paper examine use epipolar geometry assumption rigidly moving objects used provide segmentation visual scene recovery structure objects within epipolar geometry tells us constraint exists corresponding points different views rigidly moving object camera epipolar constraint unique object optical flow provides dense set correspondences frames therefore unique epipolar constraint used find separate rigidly moving objects scene given optical flow algorithm developed segmenting scene simultaneously recovering motion object scene algorithm makes assumption scene consists connected piecewiserigid objects image consists connected regions associated single rigid object motion rigidly moving objects determined scene structure obtained via epipolar constraint scene structure problem becomes analogous stereopsis object depth function distance along epipolar constraint dense correspondences optical flow lead rich descriptions scene geometry recent work tm94 sp93 used uniqueness epipolar constraint attempt partition sparse correspondences approaches deal small sets correspondences thus result sparse recovery shape information paper examine use dense set correspondences found optical flow partition scene rigidly moving objects epipolar geometry examined context affine camera perspective effects limited uniform changes scale weak perspective epipolar constraint equation becomes linear image coordinates thus allowing leastsquares solution parameters constraint different regions image representing independently moving rigid objects segmented fact possess different linear epipolar constraints motion image plane parameters constraint equation recovered used describe three dimensional rigid motion object scene undergone next section look previous work using dense flow scene segmentation review affine camera rigid transformation leads special form fundamental matrix lf94 expresses epipolar constraint matrix form found section 3 affine camera model epipolar constraint linear image coordinates allowing standard least squares solution outlined section 4 shown least squares solution combination two separate regions image found easily combined measurements section 6 outlines statisticbased regiongrowing algorithm estimates motion parameters segmentation scene distinct motion regions section 7 examines epipolar geometry estimated relative depth point scene calculated section 8 describes motion parameters object dynamically updated time using modified kalman filter approach section 9 results algorithm applied set real synthetic motion sequences examined finally look future improvements algorithm discussed section 10 2 review past work previous work using optical flow segment visual scene divided two general classes first class looks clues two dimensional optical flow field find potential boundaries different three dimensional objects second class uses unique epipolar constraint relating points rigidly moving objects different views since subset discontinuities two dimensional flow field actually correspond boundaries rigid objects first class distinguish independently moving objects depth boundaries also optical flow near discontinuities often difficult recover result first class algorithms operating regions image optical flow least accurate 21 motion field segmentation early work segmentation via motion looked discontinuities one components displacement field su87 tmb85 ba90 bla92 since general perspective projections motion field continuous long depth viewed surface continuous discontinuities flow field signal depth discontinuities unfortunately flow field discontinuities difficult recover example optical flow techniques based derivatives image function assume continuous affine flow thus fail regions locations depth edges motion introduce regions occlusion disocclusion often explicitly modeled optical flow routines algorithms attempt locate regions near flow boundary computing flow br87 sch89 bj94 first two papers look gradient constraint within local region schunck sch89 performs cluster analysis constraint lines bouthemy rivero br87 use statistical test find separate motions black jepson bj94 first find regions uniform brightness calculate flow within regions number segmentation algorithms assumption optical flow field locally affine image coordinates used adi85 mw86 nsko94 rcv92 wa94 assumes scene piecewisecontinuous depth ffl adiv adi85 groups optical flow vectors similar affine coordinates using hough transform assuming cluster represents motion planar object objects motion recovered clusters similar motions merged wang adelson perform splitandmerge algorithm parameterization ffl assumption planar objects motion shape computed leastsquares fashion collection measurements murray williams mw86 begin computing parameters small patches image patches merged similar parameters boundary detected residuals fit parameters high ffl nagel et al nsko94 fit derivatives intensity function directly affine flow parameters assuming deviations affine flow normally distributed random variables detect boundaries via statistical test ffl rognone et al rcv92 fit local patches flow five different flow templates templates consisted first order flow subsets full affine results fits clustered possible labels relaxation labeling performed assign labels image patches methods make assumption piecewise first order flow implies piecewise planar scene structure however objects general shape many depth variations occur even self occlusion rigid object thus piecewise planar assumption scene often invalid 22 segmentation via epipolar constraint epipolar geometry tells us linear constraint exists projected points rigid body undergoes arbitrary rigid transformation constraint unique rigid transformation used identify independently moving objects epipolar constraint used number structure motion algorithms lh81 th84 tk92 epipolar constraint used even case uncalibrated cameras lf94 ldfp93 allows segmentation without priors shape scene structure addition constraint holds point object boundaries optical flow therefore sparse object boundaries pointed koenderink van doorn kvd91 implemented shapiro et al cernuschifrias et al szb94 szb93 cfchb89 weak perspective projection motion parameters shape descriptions obtained modulo relief transformation depth scaling two views thus even restrictions scaled orthography important motion information obtained use epipolar constraint associate correspondences distinct rigid objects used torr tor93 tm94 nishimura et al nxt93 soatto perona sp93 papers form many subsets measurements use statistical test determine subsets possible correct partitions would lead combinatorial explosion hypothesis tests dense correspondences work uses assumption independent objects scene form continuous regions image plane thus initial sets constrained nearest neighbors avoid combinatorial explosion stereopsis epipolar constraint used conjunction priors scene structure help constrain problem violation prior also used detect boundaries bel93 priors usually take form penalty high depth gradients biasing solution toward piecewise continuous depth map ms85 one work making use prior structure context motion cfchb89 used prior scene structure two reasons first common priors try limit derivative depth function image coordinates biases result toward frontoparallel solutions one would like incorporate concept piecewise smoothness prior instead low depth gradient secondly prior would destroy simple direct solution problem found section 4 due coupling motion structure estimation believe strongly coupling two problems lead robust estimation structure motion proper prior investigated 23 scene partitioning problem section 6 see formulate segmentation optical flow field scene partitioning problem lec89 problems partition image distinct regions according assumed model descriptive language desired problem formulated terms cost functional attempts balance number model constraints constraints include terms fitting smooth model data simultaneously minimizing number distinct regions cost functional often modeled probability given solution assuming gaussian departures model leclerc lec89 showed minimal solution could also interpretated minimal length encoding describing scene terms given descriptive language stochastic gg84 regiongrowing bf70 hp74 continuation lec89 bz87 gy91 methods finding solutions scene partitioning problem described terms cost functional stochastic methods use simulated annealing programs gradient descent method perturbed stochastic process decreases magnitude global minimum approached continuation methods start variation cost functional solution easily found modified cost functional continuously deformed back original form solution tracked deformation deformation slow enough solution track global minimum original cost functional basis graduated nonconvexity algorithm blake zisserman bz87 mean field theory approach geiger girosi gg91 solution use regiongrowing method described web94 solve partition method uses statisticbased region growing algorithm assumes solution piecewise continuous image coordinates 3 projections rigid motions section describe weak perspective camera linear constraint introduced rigid motion leads special form fundamental matrix also introduce representation rotations used koenderink van doorn kvd91 show components fundamental matrix used obtain rotation scale parameters 31 weak perspective camera weak perspective camera projection 3d world coordinates 2d scene coordi nates projection scaled orthographic preserves parallelism projection x 3d world coordinate point x 2d image projection 2x3 matrix rotates 3d world point cameras reference frame scales axes projects onto image plane vector image plane projection translation aligning two frames simplest form matrix occurs world camera coordinates aligned cameras aspect ratio unity case written z ave average depth scene transformation valid approximation real camera variance depth viewed scene small compared z ave assume first frame camera world coordinates aligned takes form rigid transformation world points takes point x x 0 written r rotation matrix unit determinant projection point x undergoing transformation another weak perspective projection assumption 0 simply perspective effects incorporated change average depth z 0 ave gamma z ave introducing scale factor ave z 0 ave relate two frames translation component 0 smt write rotation matrix r composed 2 theta 2 submatrix b two vectors f f matrix b vector r r 23a 8 r ij elements rotation matrix r matrix removes third component right multiplying vector values vector f enter elements x 0 equation 1 write x 0 terms first projected point x z scaled depth szb93 point x ave z true depth eliminate depth component z get linear constraint relating x x 0 multiplying equation 9 vector orthogonal obtain linear constraint terms image coordinates linear constraint constraint written terms special form fundamental matrix z x f figure 1 koenderink van doorn representation rotations rotation viewing direction followed rotation axis image plane form 5 nonzero terms determined scale factor since scalar multiplying equation 14 change result form f c ec c c 15 32 koenderink van doorn rotation representation rotation space expressed number representations euler angles axisangle quarternions etc particularly useful representation vision introduced koenderink van doorn kvd91 representation rotation matrix composition two specific rotations first viewing direction cyclorotation second axis perpendicular viewing direction given angle horizontal see figure 1 assuming viewing direction along z axis rotation matrix rotation z ae axis image plane angle oe horizontal rotation viewing direction provides depth information information structure must come rotation axis image plane representation separates rotation information containing component superfluous additive component using notation total rotation matrix written using values formation fundamental matrix equations 1115 find motion parameters interest obtain matrix elements equations 18 19 identical ones used shapiro et al szb93 application require test see angle arctan function correct large factor since dealing small motions occur consecutive frames assume angle less thus subtract arctan function returns magnitude larger shown given elements fundamental matrix 15 one obtain motion parameters oe angle ae 17 obtained weak perspective two views unknown scaling factor proved huang lee hl89 koenderink van doorn kvd91 solve ae three views using nonlinear algorithm 4 solving fundamental matrix previous section saw assumptions affine camera model displacement field rigidly moving object satisfies affine epipolar constraint 11 measured constraint line point x uncertainty ellipsoid figure 2 epipolar geometry constrains displacement vector lie line velocity space perpendicular distance line measured displacement minimized find parameters fundamental matrix constraint says point x first frame projected point somewhere line second frame location line dictated fundamental matrix scenario location point second frame given optical flow v constraint written terms optical flow fundamental matrix elements related primed values c b affine epipolar constraint equation forces optical flow lie line velocity space since optical flow measured quantity sensitive noise flow may lie lines dictated fundamental matrix constraint use weighted least squares solve parameters b c minimizing weighted distance velocity space measured optical flow constraint line see figure 2 min weighting factor w comes error covariance measured optical flow omega v instead minimizing distances velocity space epipolar constraint line measured optical flow 21 one could minimize distance image coordinates point frames respective epipolar constraint lines rigid transformation frame 1 frame 2 implies epipolar constraint points frame 2 symmetry reverse motion implies epipolar constraint points frame 1 standard minimization instead optical flow measurements consist feature points tracked frame frame using feature correspondences point positions frames subject error using optical flow assuming flow associated particular point first frame flow subject error image location therefore appropriate minimize velocity space equation 21 similar cost function e 2 shapiro et al szb94 adopting terminology write minimization performed using lagrange multiplier constraint introduce diagonal matrix q zero except ones entries q 11 q 22 constraint becomes equivalent setting min ne minimization e done immediately setting weighted centroid 4d points x substituting e equation 22 min measurement matrix differentiating respect n using fact q obtain matrix equation since q two nonzero entries finding value causes w gamma q drop rank involves quadratic equation addition w realsymmetric also know real shown next paragraph smaller quadratic equations two solutions one desired solution n vector spans null space w gamma q normalize solution setting jjq njj results differentiating 23 respect sum equation 21 found substituting solution n 21 using fact w summation simply thus sum squared distances velocity space minimal fit found solving cubic equation implied 24 solution n minimizes weighted sum squared distances velocity space epipolar constraint line measured displacements correct weighting factor w use weighted least squares solution would reciprocal variance direction perpendicular epipolar line fx using fact n normalized value since know n minimizing cost functional 22 know values w therefore use value traceomega v initial value w update find n weng et al wah93 also calculated weighting factors fashion nonlinear minimization iteration algorithm recalculated weights see section 7 variance optical flow measurement direction parallel epipolar constraint line determines uncertainty value depth recovered contrast uncertainty perpendicular epipolar line used fact total contribution cost functional particular choice fundamental matrix found elements matrix w centroids measurements makes easy calculate leastsquares solution combination subsets measurement data suppose calculate measurement matrices w 1 separate regions image r 1 wish know change cost functional assign single n combination image regions need compute combined measurement matrix w simple function elements separate matrices centroids result simple calculation need performed determine whether would advantageous terms cost two regions combine measurements single region fact basis simultaneous segmentation epipolar geometry calculation algorithm outlined section 6 5 case affine flow solution fundamental matrix elements equation 24 requires matrix three ie null space dimension one otherwise one solution exist one case occurs optical flow affine image coordinates u va b c da x case linear relationship exists u v x thus w drops rank fundamental matrix cannot uniquely determined cases consequence fact family motions scene structures give rise affine flow observation also made ullman ull79 without reference fundamental matrix nontrivial causes affine flow either special arrangement points observed coplanarity special motions causes enumerated case 1 coplanar points observed points coplanar constraint exists three dimensional coordinates form ax perspective depth projected point image coordinates x linear function x ie z equation 9 see x 0 coordinates point second view linear function x thus optical flow affine image coordinates ffl case 2 rotation depth rotation depth rotation ae koenderink van doorn representation figure 1 vector equation zero causes x 0 linear function x thus optical flow affine rotation depth multiple observations used resolve case 1 assumption rigid motion independently moving object vary significantly frame frame individual fundamental matrices viewed constant therefore use one optical flow field order determine measurement matrix w formed multiple frames regain full rank comes fact viewing plane different views result gains depth illustrated figure 3 fact orthographic projection 4 noncoplanar point correspondences 3 frames sufficient determine motion structure case ull79 motions consisting pure translational motion andor rotation axis parallel optical axis case 2 always result affine flow weakperspective orthographic projections measurement matrix gain rank multiple frames region figure 3 planar object rotating axis perpendicular optical axis gains depth time use multiple frames allows recovery motion ambiguous two frames detected containing affine flow motion recovered directly affine parameters objects segmented based parameters thus objects undergoing pure translation segmented even though fundamental matrix motions uniquely defined motion segmentation algorithms based fundamental matrix handle case since optical flow corrupted noise criterion must developed deciding region contains affine flow region designated containing affine flow via ratio singular values measurement matrix symmetric matrix w gamma q rank three therefore three positive nonzero singular values singular values oe numbered increasing order following ratio used test rank less three oe 4 ratio less given threshold matrix assumed rank less three example rank 2 matrix perturbed small amount noise singular values oe 1 oe 2 order ffl ffl small oe 3 oe 4 order ffl ratio 27 small experiments threshold ratio set calculations done double precision 6 segmenting via regiongrowing method wish partition scene distinct regions region labeled unique fundamental matrix define cost functional balances cost labeling pixel penalty many different labelings define total cost functional e n summation pixels image n set nearest neighbor pixels delta function ffidelta equal one argument zero zero otherwise vector n estimate fundamental matrix pixel terms standard form cost functional bz87 n represents goodness fit term attempts keep estimate close data p n ff discontinuity penalty term tries limit frequency discontinuities n term weighted sums squared distances velocity space lagrange multiplier defined section 4 penalty term attaches fixed cost ff pixel bordering discontinuity since value unity unless model assumes scene segmented discrete way finite number regions particular motion parameters attached thus field n piecewise constant constant within region changing abruptly regions problem example scene partitioning problem lec89 scene partitioned distinct regions according assumed model descriptive language minimum cost functional e n ff seen maximum apriori probability map estimate model deviations fit coming stochastic process certain priors solve partitioning problem use regiongrowing method described web94 outline method previous section saw computing cost terms deviation fit data combining information different regions involves simple operations fit cost combining two regions dr 1 r 2 compared fit cost two regions separately dr 1 algorithm decides whether two regions merged via statistic shown similar f test statistic factor delta tolerated difference regions considered similar algorithm begins forming small initial patches size 4 theta 4 pixels patches computes solution n error dr small value delta regions combined statistic f 0 fixed confidence level merged newly formed regions tested affine flow solutions value delta increased possible mergings checked continues reach final value delta see web94 details application algorithm range scene segmentation problems use statistical test flowbased segmentation also found nsko94 br87 cases however deviation optical flow affine parameters tested instead statistical test used compare affine region nonaffine region exists subspace solutions fundamental matrix affine case test however used two affine regions case cost term equation 29 sum squared errors measurements leastsquares affine motion fit statistical test used affine nonaffine regions region growing algorithm different data terms statistic f 0 7 recovering depth recovered elements fundamental matrix region image plane attempt recover depth image point section 31 saw projected point x second frame elements f know direction vector taking dot product equation 31 rearranging obtain solve directly 00 term since enough information recover full translation however 00 term constant throughout objects projection remaining terms known scale factor solving z find ay constant object therefore additive constant z c scaled depth imaged point computed given elements matrix f recovered depth map 33 direct function optical flow measurements therefore noisy first term equation 33 distance velocity space along line fx know error covariance measured optical flow varv v uncertainty measurement direction parallel epipolar line fx equal uncertainty depth estimate thus solution fundamental matrix relative weighting factor q represents inverse uncertainty iomega v n 0 unit vector perpendicular n contrast weighting factor w used section 4 deviation estimate direction perpendicular epipolar constraint separation depth motion parameters estimation also pointed weng et al wah93 final depth estimate z found using weighted sum local estimates regionomega intersection local region point x rigid motion region associated point including depth values separate regions making assumption local points object similar depths case affine flow know object either undergoing pure translation rotating axis parallel optical axis either case depth information obtained orthographic weakperspective projection consequently depth recovery would rely cues formalism presented determination structure separate motion motion found depth comes directly equations 33 34 one strengths epipolar constraint places limit scene structure scene could consist cloud randomly placed points one could however introduce priors scene structure regularize estimate done stereopsis work examined use structure priors beyond local smoothness implied equation object two object one prediction time t1 unassigned segmentation time figure 4 illustration calculation predicted segmentation based current segmentation optical flow unassigned regions associated flow vectors filled segmentation algorithm begins prediction image 8 object tracking separate objects segmented would like track time beginning initial segmentation formed first three flow fields algorithm proceeds taking present segmentation forming prediction segmentation next flow field prediction formed taking current pixel assignment translating along pixels optical flow vector assignment rounded nearest integral pixel value disoccluded regions left unassigned segmentation algorithm run prediction image fill unassigned regions repeated new optical flow field new objects introduced filling unassigned regions new region formed merge existing regions figure 4 illustrates prediction method proposed scheme avoids run entire segmentation algorithm scratch new frame since uses previous segmentation prediction also avoids problem matching regions new frame previous frame however method requires correct initial segmentation two objects labeled single object initial segmentation may remain subsequent frames correctly labeled optical flow vectors frame according rigid object correspond use information new frame increase accuracy shape motion independently moving object point relax assumption rigid motion parameters constant frame frame used form initial segmentation adopt kalman filter approach motion parameters modeled process small amount noise way motion parameters change time new optical flow field provides new measurement estimating varying state work soatto et al sfp94 addresses case estimating elements fundamental matrix kalman filter framework although work full fundamental matrix easily adapted simpler affine form difficult part using kalman filter approach tracking motion parameters relation measurements optical flow state variables linear instead exists epipolar constraint equation 11 relating product two one linearize implicit constraint predicted state produce linear update equation details found sfp94 simply state results affine case soatto et al call essential estimator state consists 5 nonzero elements affine fundamental matrix nt vector nt lies subspace ir 5 corresponding jjq model dynamics state simply random walk ir 5 projected onto jjq new measurements come value nt well estimate error covariance p updated borrowing notation represents prediction time time represents estimate given measurements time 1 filter equations update gain matrices matrix x n theta 5 matrix whose rows made n measurement vectors 1 measurement error covariance matrix r x diagonal matrix consisting weighting terms w iomega v n gamma1 defined section 4 operation phi addition plus projection back onto jjq result gain matrix applies change n normalized back jjq 9 experimental results algorithm tested number synthetic real image sequences optical flow computed using multiscale differential method weber malik wm95 algorithm also produced expected error covarianceomega v associated flow estimate sequence segmentation scene distinct objects tracked motion objects scaled scene structure recovered begin synthetic sequence order compare ground truth data tracked motion parameters 91 sequence two texturemapped cubes rotating space imaged silicon graphics computer using texturemapping hardware still frames used input optical flow algorithm magnitude optical flow ranged zero 5 pixelsframe first 10 frames sequence cubes rotating fixed different rotation axes second 10 frames axes switched way could examine recovery motion parameters constant time rotation axes used well sample image optical flow field shown figure 5 edges foreground cube assumptions differential method optical flow invalid result optical flow noisy confidence low attempt find shape boundaries differentiating flow field components would difficulty regions trying find since flow defined segmentation algorithm found two separate moving objects frame initial segmentation along initial depth recovered smaller cube shown figure 6 estimated angle oe function frame number cube shown figure 7 original estimate good density optical flow subsequent frames show much improvement kalman filter successively tracks change rotation axis occurs frame 10 within frames estimate locked onto new directions response time tracker changed increasing decreasing r n expected variance motion parameters equation 36 92 sequence ii algorithm run real sequence consisting cube placed rotating platen sequence produced richard szeliski dec obtained john barron background stationary displacements frames small sequence largest displacement cube 05 pixel background zero flow labeled affine image sequence computed optical flow recovered depth map shown figure 8 case rotation axis cube makes angle 90 degrees image plane recovered value angle function frame number shown figure 9 large number measurements initial segmentation produced accurate estimate 93 sequence iii next image sequence consists textured patterns translating background toy train moves foreground planar background produces uniform flow frame sequence example optical flow recovered segmentation shown figure 10 planar background regions correctly recognized consisting affine flow sequence demonstrates algorithms ability identify regions affine flow boundaries appear irregular priors segmentation used priors favoring figure 5 two independently rotating texturemapped cubes created silicon graphics workstation single frame sequence sample optical flow field shown top row first 10 frames cubes rotated rotation axes indicated bottom left figure second 10 frames rotation axes indicated bottom right figure figure boundary two independently moving objects found segmentation algorithm pixel depths smaller cube frame number 200200degrees rotation axis angle foreground cube true estimate frame number 200200degrees rotation axis angle background cube true estimate figure 7 recovered value angle rotation axis cube makes image plane function frame number 10 frames rotation directions switched figure 8 single frame rubiks cube rotating platen optical flow recovered depth map seen side view shown frame number850950degrees rotation axis angle rubik cube figure 9 single frame rubiks cube rotating platen optical flow recovered depth map shown straight jagged boundaries could introduced well combining information intensity texture boundaries bj94 discussion future work shown even optical flow image sequence possible segment image regions consistent rigid motion determine motion parameters rigid motion furthermore relative depth points within separate regions recovered point displacement images recovery requires camera calibration make assumptions affine camera ie perspective effects small special form epipolar geometry case considered epipoles infinity perspective dominant motions fit motion parameters regiongrowing algorithm used simultaneous region formation motion parameter estimation dependent particular form geometry recovery full perspective case required algorithm could used however calculation fundamental matrix small displacements found optical flow stable wah93 ldfp93 figure 10 single frame mobile sequence rpi background consists translating patterns toy train traverses foreground example optical flow recovered also shown labeled image shown background parts colored grey identified undergoing pure translational motion singular value ratio test black white colored regions corresponding train rotating ball transition regions labeled affine another method motion segmentation based fundamental matrix found tor93 tm94 paper displacement vectors segregated finding outliers robust estimation fundamental matrix clusters displacements found iterative method combinatorial explosion dense displacement fields would make method difficult implement take advantage gross number estimates gain robustness opposed finding specific outliers however eigenvector perturbation method discussed tor93 would make easy test outliers could implemented framework detect remove outliers acknowledgements research partially supported path project mou 83 authors wish thank paul debevec creating synthetic image sequence r determining threedimensional motion structure optical flow generated several moving objects constraints early detection discontinuity motion baysian approach stereo correspondence problem scene analysis using regions estimating optical flow segmented images using variableorder parametric models local deformations combining intensity motion incremental segmentation tracking long image sequences hierarchical likelihood approach region segmentation according motionbased criteria visual reconstruction toward modelbased bayesian theory estimating recognizing parameterized 3d objects using two images taken different positions stochastic relaxation parallel deterministic algorithms mrfs surface reconstruction common framework image segmentation motion structure orthographic pro jections picture segmentation directed splitand merge procedure affine structure motion determining fundamental matrix analysis different methods experimental results constructing simple stable descriptions image partitioning fundamental matrix theory computer algorithm reconstructing scene two projections boundary detection minimizing functionals detecting image boundaries optical flow fields several moving planar facets motion boundary detection image sequences local stochastic tests motion segmentation correspondence using epipolar constraint multiple motions optical flow image flow segmentation estimation constraint line clustering recursive motion estimation essential manifold three dimensional transparent structure segmentation multiple 3d motion estimation monocular perspective image sequences early detection motion boundaries motion point matches using affine epipolar geometry motion point matches using affine epipolar geometry uniqueness estimation threedimensional motion parameters rigid objects wirth curved surfaces shape motion image streams thography factorization method stochastic motion clustering dynamic occlusion analysis optical flow fields outlier detection motion segmentation interpretation visual motion representing moving images layers optimal motion structure estimation scene partitioning via statisticbased region growing robust computation optical flow multiscale differential framework tr ctr chang motion segmentation using inertial sensors proceedings 2006 acm international conference virtual reality continuum applications june 14april 17 2006 hong kong china abhijit ogale cornelia fermuller yiannis aloimonos motion segmentation using occlusions ieee transactions pattern analysis machine intelligence v27 n6 p988992 june 2005 alireza babhadiashar david suter robust segmentation visual data using ranked unbiased scale estimate robotica v17 n6 p649660 november 1999 mitiche joint optical flow estimation segmentation 3d interpretation level sets computer vision image understanding v103 n2 p89100 august 2006 niloofar gheissari alireza babhadiashar david suter parametric modelbased motion segmentation using surface selection criterion computer vision image understanding v102 n2 p214226 may 2006