analytical model designing memory hierarchies abstractmemory hierarchies long studied many means system building tracedriven simulation mathematical analysis yet little help available system designer wishing quickly size different levels memory hierarchy firstorder approximation paper present simple analysis providing practical help unexpected results intuition come analysis applying specific parameterized model workload locality able derive closedform solution optimal size hierarchy level verify accuracy solution exhaustive simulation two case studies threelevel io storage hierarchy threelevel processorcache hierarchy one case configuration recommended model performs within 5 optimal one result analysis first place spend money cheapest rather fastest cache level particularly small system budgets another money spent nlevel hierarchy spent fixed proportion another level added b introduction f ast memory storage systems vital achieving good system performance cpu speeds increase faster memory disk speeds almost systems use caching throughout disk memory processor subsystems improve average time access data widening gap storage technologies makes easy lose significant performance poor cache sizing unfortunately little practical help exists system designers administrators seeking optimize cache hierarchies exhaustive simulation takes far long particularly hierarchies become complex 16 trial error running systems usually impossible prior mathematical analyses stopped short providing muchneeded intuitive insight cache sizing 10 assumed availability memory technologies b jacob p chen mudge advanced computer architecture laboratory department electrical engineering computer science university michigan ann arbor mi 481092122 email bljeecsumichedu pmcheneecsumichedu tnmeecsumichedu silverman chelmsford systems software lab hewlett packard chelmsford 01824 email sethapollohpcom personal use material permitted however permission reprintrepublish material advertising promotional purposes creating new collective works resale distribution servers lists reuse copyrighted component work works must obtained ieee material presented ensure timely dissemination scholarly technical work copyright rights therein retained authors copyright holders persons copying information expected adhere terms constraints invoked authors copyright cases works may reposted without explicit permission copyright holder arbitrary speeds costs 20 paper analyze performance general nlevel memory hierarchy using parameterized workload characterization intent derive simple intuitive method quickly generating firstorder approximations optimal hierarchy organizations end make several simplifications compare results obtained accurate simulation techniques result simple closedform solution size level hierarchy function workload locality speed cost available technologies amount money available spend system validate model tracedriven simulations threelevel processorcache hierarchy threelevel storage hierarchy cache sizes recommended model perform close optimal performance determined exhaustive simulation little money spend hierarchy model recommends spending cheapest slowest storage technology rather fastest contrary conventional wisdom focuses satisfying many references possible fastest cache level l1 cache processors file cache storage systems interestingly reflect happened pc market processor caches among last levels memory hierarchy added discuss initial money best spent slow technologies hope paper helps improve intuition configuring caches model also suggests every dollar spent nlevel hierarchy done fixed proportion every dollar increase size every level hierarchy one described discussion analysis section iv ii previous work countless articles written memory hierarchies 17 18 provide excellent overviews cpu disk caches generally focusing twolevel hierarchy 9 papers recent years used tracedriven simulation investigate aspects cache performance multiprocessor cache coherence replacement strategies tracedriven studies valuable understanding cache behavior specific workloads easily applied workloads 17 unlike traces mathematical analysis lends well understanding cache behavior general workloads though generality usually leads less accurate jacob et al analytical model designing memory hierarchies 101 sults many researchers analyzed memory hierarchies past chow showed optimum number cache levels scales logarithm capacity cache hierarchy 3 4 garciamolina rege demonstrated often better slower device less faster device 7 15 welch showed optimal speed level proportional amount time spent servicing requests level 20 studies two shortcomings 1 assume availability memory technologies arbitrary speeds costs 2 apply analyses specific model workload locality able create use technologies continuum characteristics convenient analysis makes analysis difficult system builders use failing apply specific model workload locality makes impossible provide easily used closedform solution optimal cache configuration 10 results papers contained dependencies cache configurationthe number levels sizes hit rates levels provide three main contributions beyond previous analyses ffl extend previous analyses applying general solution specific model workload locality thus able provide closedform solution optimal sizes workload level function two locality parameters device speeds costs ffl discuss resulting equations mean intuitively system designers terms general locality available device characteristics ffl verify models accuracy detailed simulation two memory hierarchies 1 storage hierarchy consisting ram disk tape 2 threelevel processorcache hierarchy consisting onchip cache l1 offchip cache l2 main memory performance cache configuration recommended model almost always within 5 best performance obtained exhaustive simulation iii analysis section derive analytic solution size level cache hierarchy analysis starts prespecified set technologies though resulting equations may used easily choose optimal subset technologies universe technologies system model a1 notation following analysis hierarchy consist n cache levels numbered 1 n backing store considered level n1 fig 1 shows typical hierarchy note hierarchy analyzed start end anywhere need begin immediately beneath cpu instance simulated io hierarchy begin onchip cache level several layers main towards cpu level 1 level 2 level n backing store level size sn tech cost cn c n1 access time fig 1 general cache hierarchy bottommost level backing store considered part hierarchy storage level cached highest level shown labeled towards cpu instead cpu analytical hierarchy begin point necessarily immediately cpu assume inclusion data level contained level immediately beneath memory could easily started disk level technology level described following three parameters average access time technology cost technology dollars per byte size level bytes unknown variables values c known constants assume choice hierarchy technologies made first also assume hierarchy realistic one level always faster expensive level total cost cache hierarchy system sum costs cache levels 1 n sake simplicity assume linear cost model 1 system budget b given a2 stack distance curves analysis cache performance depends mathematical description workload locality models fully associative cache hierarchy maintains inclusion effects assumptions discussed end section compute probability reference hitting cache level use stack distance curves measurements taken directly address streams 5 stack distance curves describe many unique bytes data separate two references item instance consider reference stream 1 refers nth time datum referenced nonlinear model used would tend obscure discussion demonstrated section v linear model gives good results two unique data touched 1 2 c b stack distance 1 2 3 one unique datum touched b stack distance c 1 c 2 2 data touched b 1 stack distance 1 two data touched stack distance 3 normalizing plot distribution stack distances cumulative probability function probability density function cumulative probability function shows x value many references made stack distance x less many references separated last reference data less x unique pieces data fig 2a relates well lrumanaged fullyassociative cache cache size catch references stack distance 1 references 0 intervening data cache size 2 catch references stack distance 1 2 cumulative probability function p x indicates proportion accesses data stack distance x smaller lrumanaged fullyassociative cache size x would therefore hit ratio p x probability density function derivative cumulative probability describes frequency references exactly stack distance x fig 2b fig 2 plots expected shape curves primarily use density function expect workloads locality fig 2b graphs pairs separated data data area density function x1 x2 describes probability access separated last reference x1 less x2 pieces unique data fully associative caches exactly probability reference missing cache size x1 hitting next cache level size x2 caches fully associative conflict misses oc cur size cache large enough capture reference stream placement policy causes additional misses reason caches fully associative may yield hits data old due placement policy yet displaced fig 3 illustrates difference fully nonfully associative caches fully associative cache draw exact line probability density curve separating cache hits cache misses based capacity interreference distance nonfully associative cache may specify probability distribution hits probability density curve references closer yaxis likely hits references farther yaxis paper conducts firstorder analysis using fully associative caches section v verifies analysis also accurate nonfully associative caches a3 average time per reference chow welch use performance measure average time per memory reference model following time access level hierarchy p probability level accessed hierarchy maintains inclusion probabilities necessarily sum one topmost level accessed every single reference hit miss p 1 1 analysis stack distance curves used compute p probability accessing level equal probability reference miss levels z 1 pxdx px probability density function average system time spent per reference accessing level thus time reference level scaled probability pxdx total system time spent per reference sum times across levels hierarchy sn pxdx 2 size bottom storage level n1 appear equation since level assumed contain data n1 intents infinite time reference level appear scaled miss rate lowest cache level expect backing store referenced misses lowest cache level fig 4 illustrates behavior access time function affected hierarchy organization graph represents twolevel hierarchy xaxis shows percentage budget spent top level hi erarchy towards left represents money spent l2 cache toward right represents money spent l1 cache curves depict constant budget values b hierarchy optimization goal specify memory hierarchy fastest average access time specifically solve size hierarchy level given access time cost technology parameters describing workload locality total system budget solution proceeds following steps 1 use lagrange multipliers 2 get general solution without constraining sizes nonnegative 2 apply spe cific parameterized model workload locality derive closedform solution allowing negative sizes solution account additional constraint sizes nonnegative jacob et al analytical model designing memory hierarchies 103 lru stack distance020610 probability reference lru stack distance005015025 probability reference cumulative probability function b probability density functionx1x2 fig 2 stack distance curves functions describe degree locality workload show distribution many unique bytes workload touches references item cumulative probability function plot hit rate versus cache size lrumanaged cache use graphs compute probability workloads reference hits given cache size fully associative b directmapped fig 3 fully associative cache model vs directmapped cache model fully associative model clear cache accesses hits accesses misses size cache clear dividing line separating two percentage hits therefore area curvea simple integral probability density function directmapped case introduces element chance particular line cache could thrown next cache reference could last cache unusually long period time depending particular address reference stream much difficult draw solid line hits misses line blurred illustrated b however modeled probabilistically know high probability references extremes near time distant time hits misses respectively however middle ranges chances guessing correctly grow worse depicted darkening shades grey b1 calculus variations first put cost function b appropriate form obtain constraint function g function n variables cost function b associated cost constraint g point minimized know lagrange multiplier combining gradients eqs 2 3 get gammat form gives us interesting ratio call costperformance ratio behavior psi ij described later necessary note psi ii 1 eq 1 total system cost eq 4 yield n independent equations solving straightforward long px b2 modeling program behavior wish replace px eq 4 specific function smith stone others noted caches miss rate modeled oneterm polynomial function size form fix ff ff fi constants ff less zero 17 104 ieee transactions computers vol 45 10 october 1996 percentage budget spent l1100predicted avg access time log fig 4 behavior sensitivity access time function example access time twolevel hierarchy depending proportion money spent level hierarchy curves represent constant budget values 19 follows 30 rule 2 also consistent workload traces section v thus assume polynomial forms p x px paper also used exponential form similar results 8 easiest start cumulative probability graph mentioned p x related caches hit ratioan lrumanaged cache size x would hit rate p x given input stream generated p x necessary p x 0 0 1 infinity ideally would form similar simplicity convenience make following changes ffl would like exponent positive move x ff denominator ffl function blows 0 replace x x 1 ffl want derivative px simple exponent replace ff ff gamma 1 ffl function defined would value 0 0 also would unitless scale value x directly fi gives us following forms p x differential px 2 30 rule first suggested smith 17 rule thumb every doubling caches size reduce cache misses 30 solving recurrence relation yields polynomial form ff fi constants ff negative fi scaling term constant c fi locality improves decreasing fi increasing ff given form px find sizes optimal hierarchy first combine eqs 4 5 arrive following ignoring negative roots values positive independent equations n unknowns 1n yields 1n since valid j independent equations form together eq 1 total system cost n equations n unknowns solve following manner using 1 example since psi similar sequence steps performed turn yielding general form jacob et al analytical model designing memory hierarchies 105 phi phi phi phi phi phi phi phi phi phi phi system budget size level fig 5 graph equation 7 note every solution linear solutions negative values nonzero values budget zero artifact using lagrange multipliers assuming variables take values even negative ones fixed section undoing effects negative solutions note values constants except b system budget eq 7 says size hierarchy level increases linearly amount money spend system costs access times c constants derived chosen technologies note denominator different level hierarchy therefore rate increase different level yintercept also different every level hierarchy shape curves shown fig 5 b3 undoing effects negative solutions eq 7 yield negative values particularly small system budgets obviously impossible negative amounts memory level negative size actually zero size appear optimal hierarchy leads concept crossover budget hierarchy level called budget greater optimal system include level systems money best spent hierarchy levels hierarchy level part system part system cost average access time find crossover budgets note highest level hierarchy optimal size less zero small budgets calculate budgets size negative remove level consideration budgets resulting equations identical original subscripts changed process repeated hierarchy obtain final equations process described following 1 linear function b positive slope since every cost access time positive every 2 simple inspection relative costs access times technologies shows since psi ji inverse psi ij j therefore least looking topmost cache level constant term yintercept linear equation eq 7 negative means optimal size level negative positive similar reason optimal size level itive means analytic optimal solution traded cache level 1 level n 3 priori cannot tell whether positive negative yintercept look 1 eq 7 leads positive solutions level point 1 becomes nonnegative crossover point 1 budget value 4 system budgets less value remove level 1 consideration without level 1 appropriate budget across remaining levels hierarchy levels 2 n leads new equation similar eq 2 integral 2 infinity well new equation similar eq 1 starting sum level 2 solve new equations unknowns manner without reference level 1 means equations b change become functions one fewer variables level 1 hierarchy affects neither average access time budget obtain general solution size ith level reduced hierarchy obtained form identical original equa tion except indices summations sum level 2 level n marks end one iteration 5 applying procedure new set equations see size 2 negative budget values remove level 2 analysis obtain new equation process repeated every level hierarchy find crossover budget level given 106 ieee transactions computers vol 45 10 october 1996 define 0 infinity notational brevity general find breaking system budget domain convenient collection intervals values given call ik valid interval levels hierarchy appear value interval remember b system budget independent variable equation eqs 9 10 depicted graphically fig 6 picturing examples 3 4level hierarchies costs access times technologies hierarchy constants need realistic values costs monotonically decrease access times monotonically increase one moves hierarchy larger figures applicable across choices technologies memory hierarchy using realistic values costs access times given budget workload characterization told find appropriate cache organization one would first find crossover values levels hierarchy using eq 9 would indicate cache levels present hierarchy budget value k use next step next step use eq find sizes level budget value interval indicated value k alternatively one could find cache sizes every realistic budget value zero one would need use eq 10 use values k 0 n iv discussion found closedform solution size level general memory hierarchy given device parameters cost speed available system budget measure workloads temporal locality 3 solution given eqs 9 10 bottom line solution indicates one spend ones money first dollar go lowest level 3 workloads locality represented two numbers obtained easily numerical analysis curve fitting one fit polynomial form p x eq 5 roughly estimated hit rate curve find ff fi without stack distance measurement real workload two points suffice example cache sizes one would expect catch 50 95 reference stream hierarchy money added system size level increase becomes costeffective purchase next level point every dollar spent system divided two levels fixed proportion bytes added lower level higher level necessarily mean money spent lower level every dollar split way becomes costeffective add another hierarchy level top point every dollar split three ways bytes added lower levels higher levels becomes costeffective add another level top since real technologies come arbitrary sizes hierarchy levels increase step functions approximating slopes straight lines b indepth look analysis closedform solution several implications first note crossover budget level always larger crossover budget level 1 crossover budget level n 0 means optimum hierarchy small budget 0 consists solely slowest cheapest cache level levels exist counterintuitivewe includ ing authors normally think adding fastest cache level first attempt speed average access without concern worstcase access solution shows intuition incorrectthe slower cheaper cache level capture misses backing store far valuable prevent references satisfied tape drive 15second access time optimize access time hits higher hierarchy slowest cache level large enough divert large fraction misses backing store system budget ngamma1 start increasing next higher cache level n gamma 1 along lowest level crossover budget given level depends workload device parameters eq 9 decreases better temporal locality smaller values fi larger values ff expected better temporal locality favors adding higher cache levels sooner decreases devices higher cache levels improve cost speed psi ij decreases lower cost faster times described detail later technology improvements decrease crossover budget summarize first conclusion money spent given level money wasted level large enough lower level large enough allows many performancecrippling accesses backing store second see within region size level increases linearly system budget within region additional dollars spent according fixed proportion third note slope two crossover budgets higher larger values decreases denominator slope jacob et al analytical model designing memory hierarchies 107 system budget size level size l3 cache size l2 cache size l1 cache system budget size level size l4 cache size l3 cache size l2 cache size l1 cache fig 6 example solutions two larger hierarchies threelevel hierarchy shown left fourlevel hierarchy shown right x 1x 2 labels represent crossover values crossover budget lowest level hierarchy always zero crossover budget next highest cache level follows crossover budgets equations linear curves simply change slopes crossover budgets adjust cost new level hierarchy graphs produced values c similar found tables ii eq 10 thus even one allocates money increase size fast cache level one still increase size lower cache level even faster 4 rate level increases depends workload device parameters ffl difference slopes higher lower cache levels decreases better temporal locality larger values ff high locality cache levels increase size nearly rate ffl slope cache level increases devices cache level improve psi ij decreases lower cost faster times 5 technology improvements decrease denominator eq 10 hence increase rate size level increases c meanings interactions psi ij ff fi remember psi ij following form ij ratio costperformances two lev els suggests level hierarchy characterized two numbers cost technology level speed technology level beneath effectiveness given cache level explains good job level cost per second cut many dollars per byte costs save second references next lower level ratios combine characterize entire hierarchy every level gets compared equations temporal locality workload characterized two variables ff fi variables ff psi ij always 4 size increases faster cost may may increase faster appear psi ij bit accurate say decreases cost level decreases access times technologies increase relative level appear together 1ff always exponent psi ij costperformance ratio psi ij indicates good job one level reducing access time compared another level scales large levels relation one another ff term tempers effect costperformance ratio example locality good ff large shape locality curve steep 1ff small effect costperformance ratio differentiating levels small result crossover budgets closer yaxis make sense include upper cache levels smaller budgets size different levels increase similar rates traditional characterization memory hierarchy pyramid difference sizes one level next much less locality poor locality good narrow tall pyramid locality poor shape differential curve less steep ff closer 1 effect pronounced size different levels increase different rates crossover budgets much outwhen crossover budgets occur sizes existing levels much larger case locality high result much broader hierarchy previous case take money add higher levels base levels much larger higher levels get added workload good locality results tall thin hierarchy workload poor locality results short wide hierarchy fi term scaling units bytes kilobytes megabytes etc effect scale crossover budgets occur xaxis scaling yintercepts workload spans enormous amount data convenient unit graphing chosen mbytes fi tend large pushing crossover budgets workload spans 108 ieee transactions computers vol 45 10 october 1996 smaller range smaller unit fi chosen fi smaller drawing crossover budgets using model choose subset technologies model specifies optimal size level given set technologies finding crossover bud gets model also determines higher levels hierarchy exist however model automatically determine technologies middle hierarchy removed instance consider hierarchy ram disk tape disk almost expensive ram almost slow tape model suggest best way arrange three levels given operating budget model attempt find weak links hierarchy except levels top model decides ram part hierarchy disk also kept example model may suggest configuration disk level slightly larger ram level indirectly showing disk technology useless hierarchy since model takes moment recommend configuration easily use choose subset devices larger pool technologies similar przybylskis dynamic programming approach hierarchy optimization 12 much simpler quickly search possible subsets process find best organization best subset technologies given budget point v verification analysis section iii makes following simplifications ffl polynomial stack distance curves perfectly model real workload particular cache would need infinitely large achieve 100 hit rate polynomial stack distance curve finite size needed achieve real work load large budget values solutions recommend endlessly increasing size levels optimal design would cease increasing size level contained data trace ffl model assumes fully associative cache model levels hierarchy ffl model ignores effects block size including certain amount prefetching cache pollution ffl model distinguish read write behavior accesses treated readsthey incur delay issued rather forced cache consistency cache overflow ffl model ignores compulsory misses affects performance predicted eq 2 however effect optimal hierarchy design since cache levels sizes miss references assuming prefetching ffl performance technology characterized single access time change size cache grows ffl cost function technology strictly proportional size extra cost first byte simplifications make eq 2 less accurate predicting hierarchy performance possibly affecting optimal hierarchy recommended eqs 9 10 goal section verify general hierarchy configurations recommended eqs 9 10 indeed achieve close optimal performance end compare models ability recommend specific sizes general hierarchies simulations real technologies performed ex haustive detailed simulation two hierarchies using two different traces real applications specifications real technologies first simulation afs server memory disk optical disk uses month network file requests trace second memory hierarchy onchip cache offchip cache main memory uses applicationlevel virtual address trace workload simulator description simulator connects together device modules cpu caches main memory disk drives optical disks cartridge tape robots device modules simulate various caches keep track usage statistics level item requested present requested next level request time level time first access plus amount data transfer divided transfer rate storage hierarchy simulations caches modeled writethrough fetchonwrite 17 processorcache hierarchy simulations caches modeled writeback fetchonwrite none simulated caches fully associative io caches set associative ram file cache 256way setassociative disk cache 1024way setassociative offchip cache 4way set associative onchip cache modeled directmapped simulate different ways allocate money quantum money 256 storage hierarchy simulation 64 processorcache hierarchy simulation b storage hierarchy simulations simulated storage hierarchy similar plan 9 11 13 file system lives entirely optical disk jukebox cached dram magnetic disk table describes specifications used simulator analytical calculations constant values various c specifications taken 6 14 b1 workload data used workload io hierarchy simulations collected logging afs server 1 server sees requests serviced clients local afs disk cache 6 used one months worth trace 6 client cache found capture mb data server jacob et al analytical model designing memory hierarchies 109 summary specs used storage hierarchy simulation simulated time access technology capacities block size cost per mb startup time bandwidth 1 block ms 160 mbsec ms 256 buys 8mb magnetic 512mb6gb ms ms optical unlimited 64 kbytes 0001 1 sec 1 mbsec 1063 ms jukebox 256 buys 256 gb data single file server april 14 1992 may 1992 full traces represent 20 million records several different types afs server requests extracted references relevant commands fetchdata storedata removefile createfile removedir makedir rest commands read write data example afs uses fetchstatus synchronize local cache server traces analyzed measurement temporal locality producing stack distance curves fig 7 using standard sumofsquares technique fit eq 5 data found b2 optimal configurations fig 8a shows optimal sizes hierarchy levels predicted analysis eqs 9 10 crossover budget disk level zero since lowest cache level hierarchy crossover budget dram around 3800 implying less 3800 spend cache levels disk ram money allocated disk fig 8b shows optimal sizes hierarchy levels determined simulator simulator written take account effects model ignores results noticeably different instead two regions really three model predicts size topmost level hierarchy remain zero crossover budget clearly crossover budget appears earlier simulated results also model predicts crossover budget slope ram line constant case simulated sults instead crossover budget appears earlier slope steady middle region general area model predicts crossover budget occur slope ram curve really takes region 1500 4000 shows locality exploited small amount ram due effect model ignores evident analysis predicts values similar optimal values determined simulator however measurement enough important performance lost using optimal configuration analysis fig 9 shows performance four configurations system budget dollars10000300005000070000simulated running time optimal configuration predicted configuration ram configuration ram extrapolated worst case observed worst case extrapolated fig 9 performance comparisons storage hierarchy xaxis represents system budget yaxis represents average time per simulated reference times include compulsory misses hierarchy consists two levels ram magnetic disk backing store optical jukebox comparison measured optimal running times running times predicted optimal configurations also shown running times allram system worst observed configurationone half gigabyte cache disk rest budget devoted entirely ram amounts ram last two configurations insignificant approached 200mb high budget values ffl optimal configuration found simulation ffl configuration recommended analysis ffl alldram configuration ffl configuration 512 mb disk remaining funds devoted dram worst observed case fig 9 shows predicted optimal configuration never performs 5 real optimal con figuration contrast two reasonable configurations dram disk 512 mb disk remainder going dram perform much 50 worse thus though configurations recommended analysis differs optimal configuration performance lost using analytic model however time saved needing simulations substantial simulations ran many months computer time applying analysis took 30 minutes write appropriate maple script less second execute lru stack distance mbytes020610 probability reference cumulative probability curve curve fit cpf lru stack distance mbytes00010003probability reference probability density curve curve fit pdf fig 7 stack distance curves afs traces cumulative probability curve shown left probability density curve right collected data shown dotted lines curves fit data shown solid lines system budget dollars10305070optimal size mbytes mbytes ram system budget dollars1000300050007000optimal size mbytes mbytes disk analysis storage hierarchy system budget dollars10305070optimal size mbytes mbytes ram system budget dollars1000300050007000optimal size mbytes mbytes disk b simulation storage hierarchy fig 8 optimal configurations storage hierarchy optimal configurations predicted measured b functions system budget xaxis represents amount money available yaxis represents optimal size level hierarchy optimal configurations measured simulation accurate simulator takes account number things ignored model writes block size access time variance real traces c processorcache hierarchy simulations also simulated typical threelevel virtual memory hierarchy consisting onchip cache l1 offchip cache l2 main memory used pixiegenerated traces several programs spec92 benchmark suite dnasa7 espresso hydro2d mdljdp2 mdljsp2 su2cor jacob et al analytical model designing memory hierarchies 111 wave5 programs chosen others large cache footprints necessary making multilevel cache simulations run reasonable amount time table ii describes specifications used simulator analytical calculations constant values various c cost onchip cache needs bit explanation one sense onchip cache completely free necessary part design cache appears nearly microprocessors hand infinitely expensive cannot arbitrarily increase size attempt find feasible analytical medium assumed cpu costs around 1k roughly half space devoted cache typical cache days around kbytes thus 16k per megabyte number c1 workload traces analyzed measurement temporal locality producing stack distance curves fig 10 using standard sumofsquares technique fit eq 5 data found c2 optimal configurations fig 11a shows optimal sizes hierarchy levels predicted analysis crossover budget l2 cache zero since lowest cache level hierarchy crossover budget l1 cache around 500 since curve fit inaccurate applied analytical approach raw data instead polynomial obtained graphs fig 11b configurations optimal according simulations shown fig 11c error bars demonstrating configurations perform within 10 optimal appropriation system budget within error bars would result performance within 10 simulated optimal note granularity analytical graph smaller simulations simulations allocate funds across hierarchy 64 quanta analytical scripts allocate funds 16 quanta fig 11c shows optimal sizes hierarchy levels determined simulator simulator written take account effects model ignores results slightly different compared results taken polynomial curve fit simulator results much like io hierarchy results model predicts two regions slopes con stant simulated results several regions slopes constant l1 cache appears ear lier size really take predicted crossover budget small budgets data suggests l1 cache effective reducing access time l2 cache consistent probability density curve fig 10 references lie within stack distance little lies region 125kb 500kb suggests l2 cache truly effective budget allows cache size 500kb compares well sharp jump l2 cache size sharp decline l1 cache size 500 budget point system budget dollars2006001000simulated average access time cycles optimal configuration predicted via raw data predicted via polynomial l2 configuration worst case observed fig 12 performance comparisons processorcache hierarchy xaxis represents system budget yaxis represents average time per simulated reference note times include compulsory misses hierarchy consists two levels onchip cache l1 offchip cache l2 backing store main memory dram comparison measured optimal running times running times predicted optimal configurations also shown running times alll1 system alll2 system worst observed configuration exactly alll1 configuration compare simulated results analytical results taken raw data much simi larity show l1 present small budget values size take around budget 1000 however less informative actual system performance compare performance simulated configurations optimal configurations fig 12 shows performance five configurations ffl optimal configuration found simulation ffl configuration recommended analysis applied polynomial curve fit ffl configuration recommended analysis applied raw locality data ffl alll2 cache configuration ffl worst observed case happens alll1 configuration fig 12 shows configuration predicted via raw data performs within 5 real optimal configuration except one place predicts l1 cache size 0 performance several times worse simulated optimal configuration analytical results using polynomial fitted curve equal alll2 configuration crossover point 500 drop within 5 optimal curve remain within 5 point contrast two perfectly reasonable configurations l1 l2 l2 l1 perform much 800 worse though configurations recommended analysis differ optimal configuration performance lost 112 ieee transactions computers vol 45 10 october 1996 ii summary specs used processorcache hierarchy simulation simulated time access technology capacities block size cost per mb startup time bandwidth 1 block onchip 0kb64kb cache 64 buys 4 kb offchip 0kb1536kb 64 bytes 1024 4 cycles 1 bcycle 20 cycles cache 64 buys 64 kb dram unlimited 64 bytes 64 20 cycles 01 bcycle 660 cycles lru stack distance kbytes0408probability reference cumulative probability function curve fit cpf lru stack distance kbytes002006010 probability reference probability density function curve fit pdf fig 10 stack distance curves spec traces cumulative probability curve shown curve fit left probability density shown right collected data shown dotted lines curves fit data shown solid lines region 125kb 600kb probability curve nonzero scale required show data obscures vi conclusions paper derived simple model determining optimal size cache level nlevel cache hierarchy model based access time unit cost level total system budget cache levels b twoparameter characterization workload locality ff fi using specific form stack distance curves able derive closedform solutions size cache level interval equations successfully recommended configurations performance within 5 optimal verified exhaustive simulations threelevel storage hierarchy threelevel processorcache hierarchy model led four observations configuring cache hierarchies first common focus erroneously hit time rather miss time designing hierarchies contrast model shows miss time important system budget large enough achieve high hit ratios lowest cache level implies first place spend money designing cache hierarchy cheapest level rather fastest level specific applications principle cpu cache designers aware larger offchip cache may yield better performance faster smaller onchip cache also tertiary storage becomes com mon storage hierarchy designers aware enough disk much important enough ram corollary first observation model recommends increasing size slower cache levels faster size faster cache levels even makes sense include faster cache levels third saw model within crossover budget interval size level increases linearly system budget fourth observed workload locality interesting effect shape memory hierarchy workloads good locality large ff small fi optimal memory hierarchy narrow dif jacob et al analytical model designing memory hierarchies 113 system budget dollars100300500optimal size cache mbytes system budget dollars500015000 optimal size cache kbytes analysis processorcache hierarchy polynomial system budget dollars100300500optimal size cache kbytes system budget dollars500015000 optimal size cache kbytes b analysis processorcache hierarchy raw data system budget dollars200600 optimal size cache kbytes system budget dollars500015000 optimal size cache kbytes c simulation processorcache hierarchy fig 11 optimal configurations processorcache hierarchy optimal configurations predicted b measured c functions system budget xaxis represents amount money available yaxis represents optimal size level hierarchy optimal configurations determined simulation accurate simulator takes account items ignored model including writes block size access time variance real traces data obtained polynomial curve fit data b obtained raw cumulative probability data error bars c indicate configuration ranges l1 l2 give performances within 10 optimal configuration ference size cache levels small inversely workloads poor locality small ff large fi optimal memory hierarchy wide difference size cache levels large 114 ieee transactions computers vol 45 10 october 1996 acknowledgments enormous thanks peter honeyman saar blumson dan muntz citi graciously allowing us use afs traces without data work would done b l jacobs work partially supported advanced research projects agency arpaaro contract numbers daal0390c0028 daah0494g 0327 p chens work partially supported national science foundation award number mip 9409229 r afs server logging optimization storage hierarchies determination caches capacity matching storage hierarchy operating system theory striped tape arrays performance memory optimization mass storage hierarchies tradeoffs twolevel onchip caching storage hierarchy optimization procedure plan 9 bell labs cache memory hierarchy design performancedirected approach cached worm file system mass storage technologies cost performance size tradeoffs different levels memory hierarchy two methods efficient analysis memory address trace data cache memories disk cachemiss ratio analysis design considerations high performance computer architecture memory hierarchy configuration analysis tr ctr bruce l jacob peter chen seth r silverman trevor n mudge comment analytical model designing memory hierarchies ieee transactions computers v46 n10 p1151 october 1997 juha alakarhu jarkko niittylahti scalar metric temporal locality estimation cache performance proceedings conference design automation test europe p10730 february 1620 2004 tanja van achteren rudy lauwereins francky catthoor systematic data reuse exploration methodology irregular access patterns proceedings 13th international symposium system synthesis september 2022 2000 madrid spain elizabeth sorenson j kelly flanagan using locality surfaces characterize specint 2000 benchmark suite workload characterization emerging computer applications kluwer academic publishers norwell 2001 santosh g abraham scott mahlke automatic efficient evaluation memory hierarchies embedded systems proceedings 32nd annual acmieee international symposium microarchitecture p114125 november 1618 1999 haifa israel tanja van achteren francky catthoor rudy lauwereins geert deconinck search space definition exploration nonuniform data reuse opportunities datadominant applications acm transactions design automation electronic systems todaes v8 n1 p125139 january jason hiser jack w davidson david b whalley fast accurate design space exploration embedded systems memory configurations proceedings 2007 acm symposium applied computing march 1115 2007 seoul korea xing du xiaodong zhang zhichun zhu memory hierarchy considerations costeffective cluster computing ieee transactions computers v49 n9 p915933 september 2000 j ph diguet wuytack f catthoor h de man formalized methodology data reuse exploration hierarchical memory mappings proceedings 1997 international symposium low power electronics design p3035 august 1820 1997 monterey california united states basilio b fraguela ramn doallo emilio l zapata probabilistic miss equations evaluating memory hierarchy performance ieee transactions computers v52 n3 p321336 march gerasimov model microprocessor wide command word cybernetics systems analysis v37 n6 p926934 novemberdecember 2001 trevor mudge strategic directions computer architecture acm computing surveys csur v28 n4 p671678 dec 1996