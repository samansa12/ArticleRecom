active camera calibration headeye platform using variable statedimension filter abstractthis correspondence presents new technique calibrating camera mounted controllable headeye platform uses trajectories arbitrary number tracked corner features improve calibration parameter estimates time utilizing novel variable state dimension form recursive filter special visual stimuli required assumptions made structure scene stationary relative head algorithm runs 4 frames per second single inmos t805 transputer fully integrated realtime active vision system updated calibration parameters regularly passed vision modules require although algorithm requires initial estimate camera focal length results presented real experiments demonstrating convergence achieved initial errors 50 b introduction scene reconstruction object recognition areas computer vision plagued need accurate camera calibration 19 calibration typically requires objects made high precision placed front cameras 13 8 requires considerable experimental care making methods impractical autonomous robot acting unstructured world reasons much emphasis placed recently fields structure motion 12 stereo 7 object recognition 21 active vision 5 algorithms obviate camera calibration however vision control robotic systems seems limit far ideas pushed order make controlled motions active system must convert image quantities angles distances requiring calibration form example consider 1d fixation target point p corresponds perspective projection point x image focal length f igonoring image distortions angle camera must turn fixate p first sight one merits active system exploiting visual feedback redirect gaze without knowing f however one underestimates f value overestimated vice versa choice f affects damping fixation control system correspondence describe calibration method exploits headeye platforms ability make precisely known head movements robustly tracking stationary points unstructured world approach novel several ways first utilises measurements image features tracked multiple images computationally efficient statistically principled manner secondly process fully integrated realtime reactive vision system gaze control 18 17 provides continual updates calibration parameters vision modules thirdly algorithm uses novel form recursive filter allows observations arbitrary number tracked features incorpo rated variable statedimension filter vsdf general work supported grants uk epsrc grant grg30003 ecs esprit programme ep 5390 authors department engineering science university oxford parks road oxford ox1 3pj uk email pm dwmrobotsoxacuk solution static estimation problems involving global state variable number local states coupled global state work respectively calibration parameters visual directions tracked features world show section iii filter effectively deal discarded states corresponding lost features time complexity linear number current local states tracked features method aspects common previously reported work like thacker courtney 23 aim improve estimates time incorporating new image measurements arrive like hartley 10 calibrate using rotational camera motions like du brady 6 use image features tracked multiple frames researchers together maybank faugeras 14 brooks et al 4 emphasize benefits selfcalibration paradigm well describes present work special objects used visual stimuli calibration parameters updated time react external disturbances calibration proceeds automatically background tasks progress following section discuss calibration parameters single camera directed two rotation axes sections iii iv give detailed description algorithm runs parallel motion algorithms implemented realtime vision system 17 results presented section v two versions algorithm demonstrating generalizable nature approach ii geometrical parameters recovered consider calibration parameters single camera two attached rotation axes elevation azimuth camera head geometry sketched figure 1 xy z frame stationary resting head frame defined setting x axis coincide elevation axis axis coincide azimuth axis arbitrary intial position elevation angle e azimuth angle gaze frame transformed x fixed unknown transformation takes head frame x camera frame x z zaxis optic axis definition perpendicular x axes parallel image plane z gammaf image frame camera frame optical centre x z f xyz frame frame transformation elevation axis z z head frames azimuth axis fig 1 model used single camera mounted 2 degree freedom elevation azimuth head configuration yorick means azimuth axis corresponds 0 axis elevation note sense head angles positive elevation means camera looking positive azimuth means camera gazing left ideally transformation xy z x would pure rotation x would identity head designs strive ideal using vernier adjustable camera mounts although important applications metrology effort seems misplaced vision devices cannot take account internal misalignments camera change example zoom changed must determined calibration prefer use less precise mounts calibrate misalignment overall transformation x z x z written priori sum pure rotation pure trans lation rotation comprises part changed precisely using rotation axes fixed unknown part arises misalignment camera mount camera body optic axis effectively ccd chip within body translation change rotation changes arises small offsets rotation axes relatively large displacement optic centre rotation centre small displacement principal point notional image centre x translation couples rotation theoretically possible determine however effect visual data translational component also proportional inverse depth practice present platform effect negligble two matters relating camera first minor significance data calibration obtained close image centre radial distortion routinely corrected using method described 3 secondly aspect ratio image frame imperfectly known lack precise knowledge hardware parameters camera ad rates two independent focal lengths calculated x directions image summarise first assume points sufficient depth viewed case greater 2m distant transformation betweene x z x rotation changed precisely mechanism camera platform used yorick 22 provides information relative head angles within 001 ffi corresponding 01 pixels image importantly proper account taken timing delays image capture early processing head odometry mapped precisely corresponding image data 22 secondly assume transformation x x frames pure rotation three small angles associated typically less 3 ffi recovered calibration two focal lengths camera fx fy x directions take account aspect ratio final assumption 3d points viewed stationary relative frames origin simplifies development calibration algorithm since intrinsic extrinsic estimated parameters constant world moves one recover scene motion well cali bration complicating matters considerably 14 1 11 consider stationary scene point stationary gaze frame x z thus p con stant shall first determine point x image plane projects given current elevation azimuth angles e elevation rotation angle e x axis azimuth rotation angle elevated axis 0 thus represented matrices ce se ce gammas 0 ca e used abbreviations etc define z unit vectors direction camera x measured fixed xy z frame let small rotations x axes rotation camera frame head frame described matrix gammaoe oe x 1 hence combining rotations together x rarer oe consider fixed point p 3d coordinates relative camera image coordinates x related standard projection equations set expressing fact measure visual direction 3d point p valid simplification long head angles e kept well away sigma90 ffi point pz approaches zero equations 2 provide basis algorithm estimate head parameters observations stationary points world algorithm decribed section iv uses variable state dimension filter described iii variable state dimension filter vsdf wish recover calibration parameters trajectory tracked features essence problem difficult combine measurements feature provides state time using typically kalman filter 2 however complicating issues first feature well providing information global state ie calibration parameters also local state 3d visual direction point world secondly visible features world constantly changing head rotates combination implies full state vector comprising local global state vectors constantly changing size similar problem arose structure motion system harris et al 9 estimates egomotion tracked corner features solution chosen separate kalman filters running local state vectors attached corner updating global state vectors end iteration good reason using harriss approach time complexity kalman filter cubic function state vector size involves matrix multiplications inversions implementing full kalman filter would prohibitive however approach suboptimal fully impose rigidity constraint upon egomotion problem formulated one contributions correspondence show certain class estimation problems involving single global state multiple local states formulated way timecomplexity linear full state vector size thus making computationally tractable observation required formulate new method local state coupled local measurement feature position global state local states approach exactly equivalent kalman filter uses different formulation brings important aspects chosen problem set take advantage observation equations relating parameters features include relations features means inverse covariance matrix full state vector contain mostly zeroes shown turns property inverse covariance matrix means calculated time linear number features using updating method normal kalman filter state vector determined also linear time use inverse covariance filter related information filter 15 benefit formulation allows features removed state vector simply removing corresponding row column inverse covariance matrix subsequent updates inverse covariance state vector exactly features retained state vector words fit state vector dimension number current features filter detail first discuss operation filter general terms describe use calibration section iv let us write set global parameters vector x corresponding focal lengths mechanical alignment errors camera calibration problem let features tracked parameters estimated world co ordinates call parameters local parameters whole parameter set x termed full state vector related observations z j time j measurement equation z w j gaussian distributed vector mean 0 covariance r j let prior estimate x x0 covariance p0 first consider whole history features time k define j follows ae tracked time step j k maximum likelihood solution innovation first term measures disagreement full state vector initial estimate x0 second term includes measurements time k note state dynamics involved x assumed constant vectors digress point analyse simplified problem recursively estimating single constant state vector x measurements zj subsequently apply results complete system presented given estimate xk x time step k covariance p k new measurement 1 new estimate xk minimise rk1 covariance zeromean measurement 1 linearizing around previous estimate xk dropping time step index simplicity obtain update rules jacobian matrix hx h h hence also evaluated old value x update p done calculating xd since assuming x constant estimates x vary slowly error introduced linearization small although important source error equivalent part extended kalman filter 2 apply results case estimating multiple state vectors x consider first bundling single vector thus complete state vector accordingly partition inverse covariance update rules c given new measurement z hx w e individual jacobians hx hy use equation 5 require p written means changes state estimates reason using form state update formulae rather directly using eq 5 applied case multiple ys coupled measurement process formulae lower computational complexity crux vsdf approach multiple measurements z noise vectors w covariances r write z r e stacked vectors matrices r b e r blockdiagonal also write inverse covariance matrix update rules terms p gamma1 updated p gamma1 state estimates updated using increments note measurement local state corresponding eq 3 zero b c remain unchanged th term update ignored increment applied case gammac update formulae constitute vsdf algorithm achieving minimization j eq 4 inspection clear computational complexity complete update single timestep linear n opposed cubic eq 5 used directly remains describe vsdf initialized local state vectors added removed a1 initialization filter given initial estimated value x0 global state vector x covariance p0 following matrix scalar initialized a2 introducing new local state local state vector yn1 introduced initial estimate determined initial measurement new matrices bn1 cn1 initialized zero finally n cremented n n 1 procedure effectively adds new column row block inverse covariance matrix p gamma1 a3 removing local states local state y1 say removed state vector data available therefore remove row column block l inverse covariance matrix p gamma1 however must ensure affect subsequent calculations reduced state new observations made accomplished subtracting following term l b l c l discarded state n shifted position l remaining states fill gap finally n decremented n n gamma 1 note extra storage required maintain information discarded states iv implementing calibration algorithm pair equations 2 written definitions fy oe x oe oe z measurement function h defined hx rows rotation matrix r defined terms e oe x oe oe z x constitutes global set parameters estimated z measured position projection drop subscripts section consider single tracked feature implement vsdf recursive update need calculate jacobian matrices h respect x readily obtained differentiation fill details concerning implementation camera calibration vsdf framework initialization initial values fx0 fy0 focal lengths fx fy pixels estimated empirically tolerable error high 50 angles oe x oe oe z likely small initial values set zero initial covariance p0 set diagonal entries oe 2 f focal lengths oe 2 oe angles oe 30pixel oe 01radians large indicate lack confidence initial estimates effect initial covariance declines time course b corner matching corners detected 25 framerate 25hz 64 theta 32 pixel central image window assumption tracked feature corresponds stationary scene point means position feature new image predicted previous estimates x visual direction calibration parameters new head angles e using eqs 2 feature searched 3 theta 3 pixel window centred predicted position corner found match accepted pixels around similar around feature detected previous image tested summing absolute differences pixel greylevel value 7 theta 7 window around feature dividing mean pixel value ratio less 01 match accepted one possible match found rejected stringency reflects need eliminate false matches expense losing true matches unique match found new feature position x incorporated new observation see next section match cannot found feature ambiguous matches may still reappear subsequent frames feature allowed remain invisible three consecutive frames removing local state vector p fig 2 shows several frames taken run calibration algorithm tracked corners superimposed fig 2 consecutive frames calibration algorithm matched unmatched newly appeared corners indicated respectively black white dotted black circles c incorporating new observations vsdf update procedure allows arbitrary subset current local states new observations incorporated subset corresponds features unique matches latest frame image positions x z take covariance r z diagonal entries oe 2 xy oe corresponding estimated random error feature positions adding new local state new corner feature appears initial image position initial estimate 3d world direction pn1 determined current parameters rearranging eqs 2 two linear equations px py rotation matrix r calculated using latest estimate x x image position xn1 time image taken new local state vector added using procedure section iiia2 first observation passed vsdf general two versions algorithm implemented first calibrates focal length full calibration algorithm described cases corner data every sixth frame 25hz image stream used algorithm runs 425hz focal length algorithm easily constructed redefining x fx fy removing terms oe x oe oe z equations section iv effectively forcing zero order run calibration algorithm either version camera first aligned head hand initial values focal lengths provided algorithm started simultaneously commencing head motion exact trajectory matter long chosen cover large enough range space head angles eg purely horizontal trajectory chosen would impossible measure vertical focal length fy implementation head follows trajectory constant angular speed 6 elevation azimuth one angular range limits 20 ffi elevation reached whereupon head reverses relevant velocity appearing bounce limit v results results focal length algorithm fig 3 shows results five runs focal length algo rithm horizontal axis essentially measures time amount data form corner matches varies time much match ceiling exam ple instead use cumulative number corner matches abscissa five runs lasting around 200 seconds used different starting values fx fy 300250 350650 650275 thus initial errors 50 algorithm still converges case algorithm converged values mean value fx taken end run 5233 standard deviation 17 pixels ie 03 mean value mean standard deviation fy 3918 146 04 mean also plotted prediction error absolute error measure available equivalent epipolar error stereo calibration algorithm 24 measures rootmeansquare rms error predicted position feature actual position image since tracking search window limited one pixel either side predicted position corner pixel positions integers rms error practice restricted range 051 occasional dips 05 seen rms error quickly drops near 05 showing tracking error small lack groundtruth calibration parameters important current purposes wish able track moving objects using general motion tracker 20 must make predictions image motion based parameter fx fy oe x oe oe z unit pixels radians mean 5283 3878 0028 0054 00058 std dev 09 10 0007 0011 00011 ratio 02 03 25 20 20 means standard deviations calibration parameters end runs shown figure 4 known head motion rms prediction error calibration exactly measure tells us well done b results full algorithm eight runs full calibration algorithm shown fig 4 focal lengths quickly converge value slightly different values previous experiment different calibration method change focussing adjustment runs angular alignment offsets take longer converge smaller effect runs took 10 minutes point parameters still converging results end runs summarized table expected percentage errors alignment offsets much larger focal lengths small less ef fect perhaps slightly surprising measurable cyclotorsion oe z gamma03 ffi indicating either misalignment camera mount ccd within camera utilising coupling image centre alignment offsets see effective image centre located fx oe gammaf oe x ie 28 11 results table present general motion detection tracking algorithms 17 20 use focal lengths sufficient perform predictions image image vi discussion conclusion applied variable statedimension filter problem calibrating single camera mounted robot head tracking corner features utilising accurate knowledge camera rotation approach extended several ways firstly could use image features instance line segments done 3d structure motion recovery would like explore issue robustness outlier detection thoroughly thus far feature matching algorithm employ restrictive allow many false matches situations model break calibration changes due instance manual refocussing vsdf reset breakdown theoretically detected testing residual j using 2 test dof degrees freedom mismatches given feature also tested measuring change j would occur measurements feature removed residual change 2 random variable implemented test space restrictions prevent us giving details believe variable state dimension filter first algorithm possesses essential properties realtime vision recursiveness low computational complexity repect image data size statistically rigorous derivation already applied structurefrommotion recovery similar problems varying state size also occur 16 error pixels xfocal length time matches pixels yfocal length time matches error pixels prediction error time matches fig 3 results five runs focal length calibration algorithm different initial values focal length horizontal axis measures cumulative number matches time taken run approximately 200 seconds error pixels xfocal length time matches pixels yfocal length time matches 2000 4000 6000 8000 006 002002006error xangle offset 2000 4000 6000 8000 006 002002006error time matches yangle offset 2000 4000 6000 8000 error zangle offset error pixels prediction error time matches fig 4 results eight runs full calibration algorithm including camera alignment offset angles horizontal axis measures cumulative number matches r euclidean structure uncalibrated images tracking data associa tion applications projective geometry robot vision self calibration motion stereo vision mobile robots qualitative surface shape deformation image curves seen three dimensions uncalibrated stereo rig calibration problem stereo 3d positional integration image sequences affine structure motion techniques calibration scale factor image center high accuracy 3d machine vision metrology theory selfcalibration moving camera stochastic models recursive affine structure motion image sequences driving saccade pursuit using image motion reactions peripheral image motion using headeye platform geometrical modelling multiple stereo views active tracking foveated feature clusters using affine structure using projective invariants constant time library indexing model based vision modular headeye platform realtime reactive vision online calibration 4 dof stereo head estimation stereo motion parameters using variational principle corner detection 3d vision using array processors tr ctr chungyi lin shengwen shih yiping hung gregory tang new approach automatic reconstruction 3d world using active stereo vision computer vision image understanding v85 n2 p117143 february 2002 joss knight ian reid automated alignment robotic pantilt camera units using vision international journal computer vision v68 n3 p219237 july 2006