diskless checkpointing abstractdiskless checkpointing technique checkpointing state longrunning computation distributed system without relying stable storage eliminates performance bottleneck traditional checkpointing distributed systems paper motivate diskless checkpointing present basic diskless checkpointing scheme along several variants improved performance performance basic scheme variants evaluated highperformance network workstations compared traditional diskbased checkpointing conclude diskless checkpointing desirable alternative diskbased checkpointing improve performance distributed applications face failures b introduction checkpointing important topic faulttolerant computing basis rollback recovery suppose user executing longrunning computation reason hardware software machine running computation fails absence checkpointing machine becomes functional user must start program thus wasting previous computation user stored periodic checkpoints programs state stable storage could instead restart program recent checkpoint called rolling back stored checkpoint longrunning computations checkpointing allows users limit amount lost computation event failure failures many programming environments intended users longrunning computations rely checkpointing faulttolerance example condor 34 libckpt 25 others 16 30 37 provide plankcsutkedu material based upon work supported national science foundation grants ccr9409496 mip9420653 cda9529459 orau junior faculty enhancement award darpa grant n000149511144 contract dabt6394c0049 transparent checkpointing uniprocessor programs checkpointers mist 4 cocheck 33 others 2 10 18 28 32 provide checkpointing parallel computing environments systems store checkpoints stable storage ie disk since stable storage typically survives processor failures however since checkpoints large hundreds megabytes per processor act storing disk becomes main component contributes overhead performance degradation due checkpointing marked parallel distributed systems number processors often vastly outnumbers number disks several techniques devised implemented minimize source overhead including incremental checkpointing 11 38 checkpoint buffering copyonwrite 9 21 compression 20 28 memory exclusion 25 however techniques performance stable storage medium still underlying cause overhead paper present diskless checkpointing goal diskless checkpointing remove stable storage checkpointing parallel distributed systems replace memory processor redundancy eliminating stable storage diskless checkpointing removes main source overhead checkpointing however come free failure coverage diskless checkpointing less checkpointing stable storage since none components diskless checkpointing system survive wholesale failure moreover memory processor network overhead introduced diskless checkpointing absent standard diskbased schemes purpose paper twofold first present basic schemes diskless checkpointing performance optimizations basic schemes second assess performance diskless checkpointing network sparc5 workstations compared standard diskbased checkpointing anticipated diskless checkpointing induces less overhead applications diskbased checkpointing enabling user checkpoint frequently without performance penalty lowers applications expected running time presence failures diskless checkpointing tolerates single processor failures cases multiple processor failures ever tolerate wholesale failures power outage knocks machines thus optimized faulttolerant scheme would twolevel scheme advocated vaidya 35 diskless checkpoints taken frequently standard diskbased checkpoints taken much larger interval way frequent case one two processors failing handled swiftly low overhead rarer case wholesale failure handled well albeit higher overhead longer rollback penalty 2 overview diskless checkpointing diskless checkpointing based coordinated checkpointing coordinated checkpointing collection processors disjoint memories coordinates take checkpoint global system state called coordinated checkpoint coordinated checkpoint consists checkpoints processor system plus log messages transit time checkpointing coordinated checkpointing wellstudied topic faulttolerance thorough discussion coordinated checkpointing reader directed survey paper elnozahy johnson wang 8 diskless checkpointing assume message log stored example syncand stop algorithm coordinated checkpointing ensures message log 28 message log contained within checkpoints individual processors reduces problem taking coordinated checkpoint saving individual checkpoints processor system diskless checkpointing composed two parts 1 checkpointing state application processor memory 2 encoding inmemory checkpoints storing encodings checkpointing processors failure occurs system recovered following manner first nonfailed application processors roll back stored checkpoints memory next replacement processors chosen take place failed processors finally replacement processors use checkpointed states nonfailed application processors plus encodings checkpointing processors calculate checkpoints failed processors checkpoints calculated replacement processors roll back application continues checkpoint note either spare processors checkpointing processors may used replacement processors checkpointing processors used system continue fewer checkpointing processors thus reducing faulttolerance however processors become available may employed additional checkpointing processors 21 exact problem specification user executing longrunning application parallel distributed computing environment composed processors disjoint memories communicate messagepassing application executes exactly n processors diskless checkpointing extra processors added system nm processors cooperate take diskless checkpoints long number processors system least n long failures occur within certain constraints application may proceed efficiently stated diskless checkpointing may broken two parts application processors checkpointing checkpoint processors encoding application processors checkpoints explained followed issues involved gluing two parts together 3 application processors checkpointing goal application processor checkpoint state way rollback called due failure another processor processor roll back recent checkpoint standard diskbased systems processor checkpoints saving contents address space disk typically involves saving values stack heap global variables registers figure 1a processor must roll back overwrites current contents address space stored checkpoint last step restores registers restarts computation checkpoint thereby completing rollback detail general process checkpointing recovery see papers condor 34 libckpt 25 memory disk registers application processor address space unused memory registers application processor address space diskless checkpoint memory registers application processor address space page faults memory clone registers application processor address space checkpoint unused b c figure 1 checkpointing disk b simple diskless checkpointing c incremental diskless checkpointing forked diskless checkpointing diskless checkpointing processor saves state memory rather disk simplest form diskless checkpointing requires inmemory copy address space registers figure 1b rollback required contents address space registers restored inmemory checkpoint note checkpoint tolerate failure application processor simply enables processor roll back recent checkpoint another processor fails one drawback simple diskless checkpointing memory usage complete copy application must retained memory application processor solution problem use incremental checkpointing 11 38 figure 1c take checkpoint application processor sets virtual memory protection bits pages address space readonly 1 application attempts write page access violation page fault occurs checkpointing system makes copy faulting page resets pages protection readwrite thus processors checkpoint consists readonly pages address space plus stored copies readwrite pages roll back checkpoint processor simply copies maps checkpointed copies readwrite pages back applications address space long application overwrite pages checkpoints incremental checkpointing improves performance memory utilization checkpointing last useful checkpointing method forked copyonwrite checkpointing 9 21 25 checkpoint application clones example fork system call unix depicted figure 1d clone diskless checkpoint roll back application overwrites state clones possible clone merely assumes role application forked checkpointing similar incremental checkpointing operating systems implement process cloning copyonwrite means process clone share pages one processes alters page thus works manner incremental checkpointing except identification modified pages page copying performed operating system results less cpu activity switching back forth system user mode moreover forked checkpointing require user access virtual memory protection facilities available operating systems 4 encoding checkpoints goal part extra checkpoint processors store enough information checkpoints failed processors may reconstructed specifically checkpoint processors processors encode checkpoints application processors way application processors fail checkpoints may recalculated checkpoints nonfailed processors plus encodings checkpoint processors 41 parity raid level 5 simplest checkpoint encoding parity figure 2a one checkpoint processor ie encodes bitwise parity applications checkpoints words let byte b j represent jth byte application processor jth byte checkpoint processor application processor fails state system may recovered follows first replacement processor selected take place failed application processor could checkpoint processor spare processor previously unused failed processor failure transient replacement processor calculates checkpoint failed processor taking parity checkpoints nonfailed processors encoding checkpoint processor words suppose processor failed processor checkpoint may reconstructed ckp note recovery scheme raid level 5 disk array technology 5 replacement processor calculated checkpoint failed processor application processors roll back previous checkpoint computation proceeds point besides parity several schemes used encode checkpoints vary number checkpoint processors efficiency encoding amount failure coverage detailed b c figure 2 encoding checkpoints raid level 5 b mirroring c onedimensional parity 42 mirroring checkpoint mirroring figure 2b another simple encoding scheme mirroring checkpoint processors ith checkpoint processor simply stores checkpoint ith application processor thus n processor failures may tolerated although failure application processor checkpoint processor cannot tolerated checkpoint mirroring low checkpointing overhead encoding calculations parity need made 43 1dimensional parity onedimensional parity figure 2c checkpoint processors application processors partitioned groups roughly equal size checkpoint processor calculates parity checkpoints group increases failure coverage one processor failure per group may tolerated moreover calculation checkpoint encoding efficient longer single bottleneck checkpoint processor note 1dimensional parity reduces raid level 5 mirroring 44 2dimensional parity twodimensional parity figure 3d extension onedimensional parity twodimensional parity application processors arranged logically twodimensional grid checkpoint processor row column grid checkpoint processor calculates parity application processors row column twodimensional parity requires 2 checkpoint processors tolerate failure one processor row column means twoprocessor failures may tolerated e2 figure 3 encoding checkpoints twodimensional parity e hamming coding f evenodd coding g reedsolomon coding 45 paritybased codes wellknown hamming codes figure 3e may used tolerate twoprocessor failures addition roughly log n processors 13 checkpoint processor calculates parity subset application processors evenodd coding figure 3f technique checkpoint processors employed twoprocessor failures may tolerated 3 encoding based parity calculations little complex schemes 46 reedsolomon coding general purpose encoding technique reedsolomon coding 24 figure 3g checkpointing processors use galois field arithmetic encode checkpoints way failures may tolerated since encoding complex parity cpu overhead reedsolomon coding greater methods achieves maximal failure coverage per checkpoint processor 5 gluing two parts together sections 3 4 discussed application processors store checkpoints internally checkpoint processors encode information final component diskless checkpointing coordinating application checkpointing processors efficient correct way section discusses relevant details coordination two sets processors focus primarily raid level 5 encodings discuss differences encodings entail 51 tolerating failures checkpointing checkpointing systems diskless checkpointing systems must take care remain faulttolerant even failure checkpointing recovery underway done making sure coordinated checkpoint remains valid next coordinated checkpoint completed checkpointing processors control process checkpointing processors completed calculating encodings current checkpoint may discard previous encodings notify application processors may discard previous checkpoints upon recovery checkpointing processors valid encodings recent checkpoint used recovery along recent checkpoints nonfailed application processors checkpointing processor valid encoding recent checkpoint previous encoding must used along previous checkpoints nonfailed application processors protocol ensures always valid coordinated checkpoint system memory checkpoint processors encodings coordinated checkpoint application processors checkpoints coordinated checkpoint checkpoint processor incomplete encoding checkpoint checkpoint processors still contain encodings coordinated checkpoint moreover application processors checkpoints coordinated checkpoint gamma 1 thus whole system may recover coordinated checkpoint failure detected recovery remaining processors simply initiate recovery procedure anew 52 space demands ramification preceding protocol moment checkpoint processors finish storing encodings processors contain two checkpoints memory current checkpoint previous checkpoint thus memory usage diskless checkpointing serious issue suppose size application processors address space bytes simple diskless checkpointing consumes extra bytes memory hold checkpoint ensure bytes extra memory consumed times application must frozen checkpointing applications address b figure 4 calculating encoding direct b fanin space may used without copied calculate checkpoint encodings encodings calculated applications address space may copied previous checkpoint expendable application unfrozen incremental checkpointing checkpointed copies pages made page faults caught checkpoint time processors calculate encodings discard checkpointed copies pages set protection application pages readonly thus incremental checkpoint size extra bytes memory necessary worst case pages modified checkpoints equals forked checkpointing checkpoint separate process checkpoint processors complete encodings three processes contained application processor application recent checkpoint previous checkpoint since process cloning uses copyonwrite optimization checkpoint process consumes extra bytes memory therefore forked checkpointing requires extra 2i bytes memory checkpointing bytes times worst case 2m checkpointing times finally diskbased checkpointing using fork optimization requires 0 bytes memory 0 consists pages modified checkpointing taking place 0 less though latency checkpointing large compared checkpointing interval 0 may close 53 sending calculating encoding raid level 5 encoding one checkpoint processor c 1 n application processors stores bitwise parity checkpoints application processor simplest way calculate parity employ direct method application processor simply sends checkpoint c 1 initially clears portion memory call e 1 store checkpoint encoding upon receiving ckp shown figure 4a figure 4 phi signs shown directly processors perform bitwise exclusive arrows one processor another represent one processor sending checkpoint another two problems direct method first c 1 become messagereceiving bottleneck since destination checkpoint messages second c 1 parity calculations problems may alleviated fanin algorithm application processors perform parity calculation log n steps send final result c 1 stores result memory shown figure 4b encodings besides raid level 5 two methods may extended direct method processor sends checkpoint multicast message proper checkpointing processors necessary eg reedsolomon coding checkpointing processors modify checkpoints exclusiveor checkpoints fanin method one fanin performed checkpointing processor may entail cooperation application processors eg reedsolomon coding subset application processors eg onedimensional parity checkpoint must modified encoding done application processor p fanin starts networks fanin algorithm preferable direct eliminates bottlenecks distributes parity calculations however network supports multicast encodings involving multiple checkpointing processors may profit direct method 54 breaking checkpoint chunks preceding description implies whole checkpoints sent processor processor since checkpoints may large often makes efficient use memory break checkpoint chunks fixed size example fanin algorithm two extra chunks memory needed receive incoming chunk another processor make parity calculation send result chunks small enough consume much memory large enough overhead sending chunks dominated messagesending startup 55 sending diffs application processors use incremental checkpointing avoid overhead sending pages modified since previous checkpoint however cause problems creating checkpoint encoding specifically encoding created anew checkpoint needs checkpointing data processors solution use diffs assume direct encoding method employed checkpoint processor first copies previous checkpoint current checkpoint application processor following modified page page k address space calculates diff k bitwise exclusiveor current copy page copy page previous checkpoint course available application processor sends diff k checkpoint processor xors checkpoint effect subtracting old copy page adding new copy way unmodified pages need sent checkpointing processor one may use diffs fanin algorithm well stipulating processor modify page checkpoint interval need send page xor pages performing fanin 56 compressing diffs sending diffs rather actual bytes checkpoint interesting opportunity compression arises suppose application modifies bytes page diff page previously checkpointed copy composed mostly zeros easily compressed using either runlength encoding algorithm sends tagged bytes rather whole pages compression trades use cpu reduced load network compression combines naturally incremental checkpointing modified pages compressed sent may also used simple forked checkpointing converting entire checkpoint diff compressing sending along effect emulating incremental checkpointing regions memory modified get compressed nothing 6 implementation experiment order assess performance diskless checkpointing compared standard diskbased checkpointing networks workstations implemented small transparent checkpointing system network 24 sun sparc5 workstations university tennessee workstation 96 mbytes physical memory runs sunos version 413 workstations connected fast switched ethernet isolated performance testing measured peak bandwidth two processors roughly 5 megabytes per second workstations little accessible local disk storage 38 megabytes per machine however machines connected via regular ethernet departments file servers using sun nfs disks bandwidth 17 megabytes per second performance nfs ethernet far worse nfs remote file writes achieve bandwidth 013 megabytes per second page size machine 4096 bytes access page tables controlled mprotect system call checkpointer runs top pvm 12 works like many pvm checkpointers 4 33 applications need recompiled object modules must relinked checkpointingmodified pvm library applications started checkpointing code gets control reads startup information control file information includes checkpoint interval checkpointing optimizations use plus checkpoints stored disk checkpointing processors application starts one application processors interrupted checkpointing interval expired processor coordinates application processors using syncandstop synchronization algorithm consistency determined processors checkpoint abbreviation description checkpointing diskfork checkpointing disk using fork simp simple diskless checkpointing inc incremental diskless checkpointing forked diskless checkpointing incfork incremental forked diskless checkpointing csimp simple diskless checkpointing compression cinc incremental diskless checkpointing compression forked diskless checkpointing compression cincfork incremental forked diskless checkpointing compression table 1 checkpointing variants implemented experiments pvm includes basic forms failure detection specifically processor current pvm session fails rest processors eventually notice failure remove failed processor pvm session pvm allows user notified events checkpointer uses facility recognize processor failures failure occurs spare processor pvm session selected replace failed processor spare processor diskless checkpointing employed checkpoint processor chosen replacement processor recovery proceeds automatically either diskbased diskless checkpoint important note checkpointer require programmer modify code enable checkpointing simple relinking necessary gamut checkpointing variants enumerated table 1 includes standard diskbased checkpointing using fork optimization test incremental diskbased checkpointing improve performance checkpointing tests 1 diskless checkpointing implement raid level 5 encoding using fanin algorithm checkpoint encodings created chunks 4096 bytes conveniently also page size choice algorithm ramifications certain optimizations work example performing incremental checkpointing encoding created chunkbychunk processor modified corresponding page empty message sent part fanin instead page using diffbased compression pages compressed using bitmapbased compression algorithm 29 compression performed sending processor sending uncompressed receiving 1 say incremental diskbased checkpointing often useful optimizations simply help tests application running time checkpoint size per node sec hmmss mbytes nbody 5722 13522 37 cell 6351 14551 414 pcg 5873 13753 666 table 2 basic parameters testing applications processor merges page compresses result sending along final compressed chunk reaches checkpointing processor uncompresses chunk merges previous checkpoint encoding stored next encoding applications used five applications test performance checkpointing applications cpuintensive parallel programs sort often require hours sometimes days execution executed instances programs took 15 2 hours run sixteen processors absence checkpointing cases clear programs scale size scaling affect performance checkpointing basic parameters application presented table 2 briefly describe application ordered checkpoint size 71 nbody nbody computes nbody interactions among particles system program written c uses parallel multipole tree algorithm 19 instance used tests 15000 particles ten iterations basic structure program follows particle represented data structure several fields particles partitioned among slave processors sixteen tests way processors close metric reside slave limit interslave communication reason slave processors differ number particles hold therefore sizes example tests slave processors averaged 37 megabytes size largest six megabytes iteration location field among others particle updated reflect nbody inter action since size particles data structure less machines page size means almost pages slave processors modified iteration leading poor incremental checkpointing behavior checkpointing interval spans multiple iterations however since much particles data left unmodified iteration iteration bytes per page changed resulting good diffbased compression two parameters affect running time memory usage nbody number particles affects time space number iterations affects running time nbody application checkpoints small enough allow number checkpoints diskless diskbased checkpointing 72 mat mat c program computes floating point matrix product two square matrices using cannons algorithm 17 matrix size tests 4608theta4608 leading 151 megabyte checkpoints per processor uniprocessor matrix multiplication typically shows excellent incremental checkpointing behavior since two input matrices readonly product matrix calculated sequentially filling whole pages time way product element calculated never subsequently modified 25 however highperformance parallel algorithms cannons algorithm differ respect cannons algorithm three matrices partitioned square blocks among n processors assumed n perfect square algorithm proceeds p steps step processor adds product two input submatrices product submatrix processors send input submatrices neighboring processors receiving new ones place repeat product submatrices calculated ramification data movement course iteration matrices modified therefore checkpoints span iterations case diskbased checkpointing incremental checkpointing beneficial effect multiple checkpoints taken iteration case diskless checkpointing incremental checkpointing successful uniprocessor case pages updated mat updated entirety leading poor diffbased compression mats time space demands determined size matrix n theta n matrix memory usage proportional n 2 running time proportional n 3 communication patterns mat depend number processors matrix sizes mat nbody applications possible take one diskbased checkpoint programs execution three diskbased checkpoints opposed seven diskless checkpoints taken mat 73 pstswm pstswm fortran program solves nonlinear shallow water equations rotating sphere using spectral transform method 14 instance used simulates state 3d system duration hours like nbody pstswm modifies majority pages iteration modifies bytes per page therefore incremental checkpointing show limited improvement diffbased compression work well pstswms checkpoints large approximately 25 megabytes per processor however since machine 96 megabytes physical memory two checkpoints may stored stressing limits physical memory pstswm scale size simulating denser particle grid size set iteration performs roughly actions therefore simulating longer time frames increases running time linear fashion without altering general behavior eg memory access pattern significantly 74 cell cell parallel cellular automaton simulation program written c program distributes two grids cellular automata evenly across application processors one grid denoted current one denoted next values current grid used calculate values next grid two grids identities swapped instance used tests simulates 18512 18512 cellular automaton grid generations iteration cell updates every automaton next grid therefore checkpoints span two iterations memory locations updated rendering incremental checkpointing useless compressibility depends data sparse grids many automata take zero values may see little change automatas values time lead good compression denser grids lead less compression tests used sparse grids program size directly proportional grid size running time proportional grid size times number iterations pair iterations performs operations thus memory access communication patterns pcg fortran program solves large sparse matrix using preconditioned conjugate gradient iterative method matrix converted small dense format approximations x calculated refined iteratively reach userspecified tolerance correct values tests 1638400 1638400 element sparse matrix program takes 3750 iterations exact mechanics memory usage pcg detailed 26 salient points follows main data structures program may viewed many vectors length n instances vectors distributed among application processors roughly three quarters vectors never modified program starts calculating rest updated entirety iteration therefore incremental checkpoints one quarter size nonincremental checkpoints data gets updated every iteration stored densely contiguous pages offering little opportunity diffbased compression program size directly proportional n like cell pstswm running time proportional size times number iterations application processor holds 666 megabytes worth data pcg therefore one simple diskless checkpoint fit memory however incremental copyonwrite checkpointing employed application one two checkpoints consume megabytes memory available size checkpoints combined speed sun nfs results inability take diskbased checkpoints pcg time store one checkpoint longer running time application reiterated instances tests chosen run period time long enough measure impact checkpointing recovery applications natural input parameters result longer execution times larger checkpoints goal tests assess performance checkpointing users longerrunning applications may able project expected running time applications presence failures employing various checkpointing variants raw data experiments appendix paper graphs section derived directly raw data cases tests executed triplicate number times test executed plus standard deviations execution times displayed tables appendix tables graphs display average data concentrate two performance measures latency overhead latency time checkpoint initiated may used recovery overhead defined previously overhead direct measure performance penalty induced application due checkpointing impact latency subtle discussed detail section 9 81 checkpointing disk figure 5 plots checkpoint latency overhead checkpointing disk diskfork tests plotted function applications perprocessor checkpoint sizes displayed leftmost graph latency diskfork tests directly proportional checkpoint size achieving bandwidth mbytessec bandwidth calculated perprocessor checkpoint size times number processors divided checkpoint latency using information checkpoint latency pcg test projected roughly 8663 seconds rightmost graph displays overhead function checkpoint size graph appears roughly linear noted overhead checkpointing simple function checkpoint size bulk checkpoint size mbyte processor30009000 latency per checkpoint sec mat pcg projected checkpoint size mbyte processor3090 per checkpoint sec mat figure 5 checkpoint latency overhead checkpointing disk diskfork checkpoint size mbyte processor100300latency per checkpoint sec checkpoint size mbyte processor100300overhead per checkpoint sec figure checkpoint latency overhead simp fork work performed checkpointing involves dma processors memory network interface card cpu affected significantly one following occurs ffl dma transaction needs initiated repeated ffl copyonwrite page fault occurs application ffl contention memory bus also effects cache result checkpointing therefore although checkpoint size rough measuring stick computing overhead diskfork checkpointing whole story shown research copyonwrite optimization excellent job reducing overhead 9 21 25 test overhead 07 55 percent checkpoint latency 82 diskless checkpointing simp fork figure 6 plots checkpoint latency overhead simp fork tests plotted function checkpoint size diskfork case simp fork latencies directly proportional checkpoint size exception simp test pcg application combined size application checkpoint exceeds size physical memory resulting pages swapped backing store degrades performance checkpointing fork test checkpoint requires additional 166 mbytes memory since unmodified pages memory shared application checkpoint therefore checkpoint latency follows linear pattern applications exception simp test pcg application bandwidth checkpointing simp fork roughly 44 mbytessec factor 34 faster diskfork bandwidth overhead simp tests identical latency since application halted checkpointing fork tests overhead reduced 294 mat 537 pcg percent although improvement degree improvement diskfork tests reason cpu involved diskless checkpointing diskbased checkpointing diskless checkpointing parity processors checkpoint must calculated takes cpu plus memory away application time diskbased checkpointing makes use cpu diskless checkpointing longer latency checkpointing causes copyonwrite page faults occur 83 rest tests diskless checkpointing results displayed figure 7 top row graphs shows checkpoint latency test application middle row shows checkpoint overhead bottom row shows average checkpoint size bit misnomer cases inmemory parity processor checkpoints size however incremental checkpointing compression fewer bytes sent per processor checkpoint size graphs checkpoint size columns appendix display average number bytes processor sends checkpointing salient features figure 7 follows first incremental checkpointing significantly reduces average checkpoint sizes mat pcg applications three applications checkpoint size simp inc roughly mat pcg applications significant reductions checkpoint latency overhead result incremental checkpointing cases mixture incremental forked checkpointing result lowest overhead diskless checkpointing tests incremental checkpointing fails decrease size checkpoints nbody cell ap plications overhead checkpointing greater simple checkpointing applications incfork tests yielded highest checkpoint latencies results diffbased compression interesting three applications nbody pstswm cell checkpoint latency sec mat incfork csimp cfork cinc cincfork515checkpoint overhead sec mat checkpoint size mat figure 7 diskless checkpoint latency overhead size per application incremental checkpointing fails programs pages updated every iteration however diff based compression succeeds reducing checkpoint size pages either sparsely modified nbody pstswm updated values cell three applications cfork tests yielded lowest checkpoint overhead note since compression adds extra demands cpu reduction overhead drastic incremental checkpointing also interesting note lowest overhead achieved cfork rather cinc cincfork tests almost pages modified checkpoints therefore incremental checkpointing merely adds overhead processing page faults two tests mat pcg diffbased compression brings checkpoint sizes fork simp tests roughly size incremental checkpointing however improve upon incremental application recovery time sec pstswm 663 cell 1383 pcg 3753 table 3 recovery times simp tests checkpointing terms size overhead modified pages showed little compressibility 84 recovery time table 3 shows time takes system recover single failure continue execution recent checkpoint simp tests processor failure simulated terminating one application processors pvm written processors recognize failure modifications take advantage automate process recovery tests checkpointing processor takes place failed application processor recovery times roughly equal checkpoint latencies simp applications noted diskfork tests recovery times equal since entire diskless checkpoint failed processor must calculated diskfork tests recovery times equal checkpoint latencies thus like latencies extremely large 9 discussion 91 diskless vs diskbased checkpointing two basic results may draw tests concerning diskless vs diskbased checkpointing ffl checkpoint latency recovery time diskless checkpointing vastly lower diskbased checkpointing stated section 82 latency recovery time diskbased checkpointing factor 34 slower diskless checkpointing result poor performance sun nfs combined fact processors use disk ffl overhead diskless checkpointing comparable diskbased checkpointing figure 8 plots overhead diskbased checkpointing overhead best diskless variant application checkpoint overhead sec figure 8 checkpoint overhead diskbased checkpointing compared best diskless variant cases nbody pstswm diskless checkpointing outperforms diskbased others diskbased outperforms diskless question mark plotted pcg unable complete diskbased checkpoint lifetime application two reasons diskless checkpointing may viewed preferable diskbased checkpointing first lowers expected running time application presence failures second less effect computing environment special concern environment shared consider turn 911 expected running time supposing failure rate governed poisson process vaidya derived equations assessing performance application presence checkpointing rollback recovery 36 equations take input average overhead latency recovery time per checkpoint plus rate failures defined follows rate failures 1mtbf optimal checkpoint interval average overhead per checkpoint average latency per checkpoint recovery time checkpoint running time application absence checkpointing recovery failures ie base test overhead ratio measure performance penalty due checkpointing recovery failures36 expected running time optimal checkpoint interval presence failures checkpointing recovery optimal expected running time application presence failures checkpointing recovery expected running time application presence failures checkpointing recovery ie application restarted scratch following failure equations repair time assumed zero approximates case spare processor ready continue computation immediately following failure repair time significant eqs 2 5 become equations may used compare checkpointing algorithms follows first algorithm opt may calculated using eq 1 next gamma r may determined eqs 2 3 desired expected running time application ckp algorithm may determined eq 4 checkpointing algorithm lowest value r one smallest expected running time thus r suffices metric compare checkpointing algorithms ckp greater nockp application cannot benefit checkpointing occurs applications running time base significantly greater opt however base grows nockp increases rapidly ckp point checkpointing improves programs expected running time presence failures table 4 use data section 8 derive values opt gamma r ckp nockp tests presented figure 8 calculated following manner study host reliability internet long et 22 determined average mtbf 2929 days assuming independent processor failures means mtbf collection 16 processors days mtbf collection 17 processors days gives value 6301 10 gamma6 failures per second 6694 10 gamma6 failures per second 17 processors use former value failure rate diskbased checkpointing checkpointing latter value diskless checkpointing table 4 shows applications diskless checkpointing performs better diskbased checkpointing seen lower expected running times ckp lower overhead ratios r therefore even though two similar checkpoint overheads extremely large latency recovery time diskbased checkpointing makes unattractive comparison diskless checkpointing another significant result table 4 two applications nbody mat expected running time presence failures minimized diskless checkpointing three applications checkpointing application test tbase topt gamma r tckp tnockp sec sec sec sec sec table 4 calculated values int gamma r ckp nockp gives smallest expected running time checkpointing improves performance somewhat surprising given relatively small execution times experiments respect mtbf cases diskbased checkpointing gives smaller expected running time execution time application grows checkpointing becomes much attractive example suppose user desires simulate 5000 hours pstswm instead 102 program take roughly 275000 seconds 318 days execution would alter size checkpoints therefore may use overhead latency recovery times presented section 8 leads expected execution times 3256 days diskless checkpointing 3390 days diskbased checkpointing 8553 days checkpointing 912 effect shared resources large checkpoint latencies detrimental ways example diskbased checkpointing entire latency period spent writing checkpoint data stable storage programs users share stable storage large checkpoint latencies undesirable performance stable storage seen others degraded long period time 23 effect diskfork checkpointing performance stable storage assessed checkpoint stored central disk processor involved application timed bandwidth disk writes test performance stable storage degraded 87 percent significant means extremely long checkpoint latencies measured tests potential degrade performance system severe manner long time diskless checkpointing hand exhibits much smaller checkpoint latencies calculation checkpoint encoding involves network cpu impact shared resources case network far less 23 92 recommendations given results experiments make following recommendations checkpointing variants tested paper three stand useful diskfork cfork incfork system similar performance useful certain cases ffl checkpoints small likelihood wholesale system failures high diskfork checkpointing employed ffl program modifies bytes per page checkpoints machine provide access virtual memory facilities cfork diskless checkpointing employed ffl program modify significant number pages checkpoints incfork diskless checkpointing employed although test applications may times fork simp useful checkpointing methods pages modified dense manner checkpoints fork lowest overhead enough memory store two checkpoints simp lower overhead otherwise none applications would benefited incremental checkpointing disk however multiple checkpoints taken program modifies fraction pages checkpoints incremental forked checkpoints outperform diskfork finally interpreting results important note speed stable storage experiments quite slow faster network faster file system file system multiple disks improve performance diskbased checkpointing relative diskless checkpointing hand system processors degrade performance diskbased checkpointing relative diskless checkpointing possible using equations section 911 extrapolate results experiments systems different performance parameters related work much research performed checkpointing rollback recovery important algorithms performance optimizations diskbased checkpointing parallel distributed systems presented 8 research directly related diskless checkpointing cited first paper diskless checkpointing presented plank li 27 paper may viewed completion original paper silva et al 32 implemented checkpoint mirroring transputer network performed experiments determine outperformed diskbased checkpointing chiueh deng 6 implemented checkpoint mirroring raid level 5 checkpointing massively parallel 4096 processors simd machine found mirroring improved performance factor 10 implementations involved modifying application perform checkpointing rather simply relinking checkpointing library scales lam 31 implemented distributed programming system built special primitives sharedmemory semantics use redundancy built system plus checkpoint mirroring necessary tolerate single processor failures low overhead similar manner costa et al 7 took advantage natural redundancy distributed shared memory system make resilient single processor failures systems export sharedmemory interface programmer embed faulttolerance implementation reliance stable storage plank et al 26 embedded diskless checkpointing raid level 5 encoding several matrix operations scalapack distributed linear algebra package thus making resilient single processor failures low overhead kim et al 15 extended work employ onedimensional parity encoding lowers overhead increases failure coverage 23 diskless checkpointing ideas extended diskbased checkpointing system disparity performance local remote disk storage environments diskless checkpointing may extended inmemory checkpoints stored local disks fast survive processor failures checkpoint encodings stored remote disks slow available following failure performance mirroring raid level 5 reedsolomon codings assessed compare favorably standard checkpointing remote disk impact checkpointing remote disk network also assessed finally 35 vaidya makes case twolevel recovery schemes fast checkpointing method tolerating single processor failures combined slower method tolerates wholesale system failures examples checkpoint mirroring employed fast method diskfork checkpointing employed slow method analysis applies methods presented paper well diskless checkpointing technique processor redundancy memory redundancy failure coverage traded checkpointing system operate absence stable storage process performance checkpointing well impact shared resources improved paper described basic diskless checkpointing plus several performance optimizations implemented tested five longrunning application programs network workstations compared standard diskbased checkpointing implementation diskless checkpointing algorithms show 34fold improvement checkpointing latency combined comparable checkpoint overhead result lower expected running time presence single processor failures several checkpointing systems 6 23 26 32 included variants diskless checkpointing improve performance checkpointing designers checkpointing systems consider variants diskless checkpointing presented paper optimize performance minimize impact checkpointing shared resources r virtual memory primitives user programs application level fault tolerance heterogeneous networks workstations evenodd optimal scheme tolerating double disk failures raid architectures mist pvm transparent migration checkpointing efficient checkpoint mechanisms massively parallel machines lightweight logging lazy release consistent distributed shared memory survey rollbackrecovery protocols messagepassing systems performance consistent checkpointing manetho transparent rollbackrecovery low overhead system program debugging via reversible execution redundant disk arrays reliable solutions shallow water test set using spectral transform method fault tolerant matrix operations networks workstations using multiple checkpointing job process recovery unixbased operating system introduction parallel computing checkpoint mechanism keykos lowlatency concurrent checkpointing parallel programs longitudinal survey internet host reliability improving performance coordinated checkpointers networks workstations using raid techniques tutorial reedsolomon coding faulttolerance raidlike systems libckpt transparent checkpointing unix fault tolerant matrix operations networks workstations using diskless checkpointing faster checkpointing n compressed differences algorithm fast incremental check pointing transparent fault tolerance parallel applications networks workstations checkpointing spmd applications transputer networks consistent checkpoints pvm applications condor distributed processing system case twolevel distributed recovery schemes impact checkpoint latency overhead ratio checkpointing scheme 25th international symposium faulttolerant computing demonic memory process histories tr ctr sangho yi junyoung heo yookun cho jiman hong adaptive pagelevel incremental checkpointing based expected recovery time proceedings 2006 acm symposium applied computing april 2327 2006 dijon france kai hwang hai jin edward chow choli wang zhiwei xu designing ssi clusters hierarchical checkpointing single io space ieee concurrency v7 n1 p6069 january 1999 junyoung heo sangho yi yookun cho jiman hong sung shin spaceefficient pagelevel incremental checkpointing proceedings 2005 acm symposium applied computing march 1317 2005 santa fe new mexico xiaojuan ren rudolf eigenmann saurabh bagchi failureaware checkpointing finegrained cycle sharing systems proceedings 16th international symposium high performance distributed computing june 2529 2007 monterey california usa saurabh agarwal rahul garg meeta gupta jose e moreira adaptive incremental checkpointing massively parallel systems proceedings 18th annual international conference supercomputing june 26july 01 2004 malo france raphael de camargo renato cerqueira fabio kon strategies storage checkpointing data using nondedicated repositories grid systems proceedings 3rd international workshop middleware grid computing p16 november 28december 02 2005 grenoble france ling jie mi xiaola lin variational calculus approach optimal checkpoint placement ieee transactions computers v50 n7 p699708 july 2001 adnan agbaria hagit attiya roy friedman roman vitenberg quantifying rollback propagation distributed checkpointing journal parallel distributed computing v64 n3 p370384 march 2004 daniel reed charngda lu celso l mendes reliability challenges large systems future generation computer systems v22 n3 p293302 february 2006 zizhong chen graham e fagg edgar gabriel julien langou thara angskun george bosilca jack dongarra fault tolerant high performance computing coding approach proceedings tenth acm sigplan symposium principles practice parallel programming june 1517 2005 chicago il usa milos prvulovic zheng zhang josep torrellas revive costeffective architectural support rollback recovery sharedmemory multiprocessors acm sigarch computer architecture news v30 n2 may 2002 daniel j sorin milo k martin mark hill david wood safetynet improving availability shared memory multiprocessors global checkpointrecovery acm sigarch computer architecture news v30 n2 may 2002 feng qin joseph tucek jagadeesan sundaresan yuanyuan zhou rx treating bugs allergiesa safe method survive software failures acm sigops operating systems review v39 n5 december 2005 sudarshan srinivasan srikanth kandula christopher r andrews yuanyuan zhou flashback lightweight extension rollback deterministic replay software debugging proceedings usenix annual technical conference 2004 usenix annual technical conference p33 june 27july 02 2004 boston