tight bounds prefetching buffer management algorithms parallel io systems abstractthe io performance applications multipledisk systems improved overlapping disk accesses requires use appropriate prefetching buffer management algorithms ensure useful blocks accessed retained buffer paper answer several fundamental questions prefetching buffer management distributedbuffer parallel io systems first derive prove optimality algorithm pmin minimizes number parallel ios second analyze pcon algorithm always matches replacement decisions wellknown demandpaged min algorithm show pcon become fully sequential worst case third investigate behavior online algorithms multipledisk prefetching buffer management define analyze plru parallel version traditional lru buffer management algorithm unexpectedly find competitive ratio plru independent number disks finally present practical performance algorithms randomly generated reference strings results confirm conclusions derived analysis worst case inputs b introduction increasing imbalance speeds processors io devices resulted io subsystem becoming bottleneck many applications use multiple disks build parallel io subsystem advocated increase io performance system availability 5 highperformance systems incorporate form io parallelism performance improved overlapping accesses several disks using judicious prefetching buffer management algorithms ensure useful blocks accessed retained buffer parallel io system consists independent disks disk buffer accessed parallel data computation spread among disks units blocks block unit retrieval disk computation characterized computation sequence ordered sequence blocks references model accesses read prefetching reading data block needed computation research partially supported grant schlumberger foundation research partially supported nsf grant ccr9303011 natural mechanism increase io parallelism computation demands diskresident block data concurrently data block prefetched disks parallel held buffer needed requires discarding block buffer make space prefetched block natural questions arise conditions worthwhile discard bufferresident block make room prefetch block used time later future decide discard block replacement policy used choosing block replaced paper answer several fundamental questions prefetching buffer management parallel io systems questions address optimal prefetch buffer management algorithm good algorithms proposed earlier sequential single disk systems context obtain several interesting results informally stated precisely stated section 2 find prove optimality algorithm pmin minimizes number parallel ios contrasts recent results prefetching obtain cpudisk overlap 4 efficient algorithm find optimal policy known secondly show pcon algorithm attempts optimize number ios disk poor parallel performance finally investigate behavior semionline algorithms using parallel io concept semionline algorithms consider paper captures dual requirements prefetching needs future knowledge online behavior future knowledge define analyze plru semionline version traditional least recently used lru buffermanagement algorithm find performance plru independent number disks contrast pcon performance degrade proportion number disks contrast singledisk systems sequential io issues studied extensively eg 2 6 formal study issues parallel io context sequential setting number block ios useful performance metric scaling average block access time provides estimate io time contrast multiple disk case direct relationship number ios io time since depends io parallelism attained goals minimizing number ios done disk minimizing parallel io time conflict traditional buffer management algorithms singledisk systems generally focused minimizing number ios parallel context may useful perform greater absolute minimal disk operated isolation number ios disk allows large number overlapped rest paper organized follows section 11 summarizes related work section 2 develops formal model summarizes main results section 31 derive tight upper bound pcon algorithm section 32 prove optimality pmin section 33 analyzes performance semionline algorithm plru 11 related work singledisk systems buffer management paging problem algorithms studied 2 6 11 several policies lru fifo longest forward distance etc proposed analyzed longest forward distance 2 policy minimizes number page faults therefore called min algorithm policies use demand io deterministic replacement ie fetch block referenced buffer choice replaced block deterministic randomized replacement algorithms eg see 8 beyond scope paper sequential case well known 11 prefetching reduce number ios required sleator tarjan 11 analyzed competitive ratio online paging algorithms relative offline optimal algorithm min showed lrus performance penalty proportional size fast memory online algorithm worst case much better fundamental results extended several ways often include models allow different forms lookahead 3 1 9 7 works deal question buffer block evict contrast situation additional question arises fetch block evict cao et al 4 examined prefetching single disk overlap cpu io operations defined two offline policies called aggressive conservative obtained bounds elapsed time relative optimal algorithm use prefetching obtain io parallelism multiple disks use number parallel ios elapsed io time cost function pmin pcon algorithms analyzed generalize aggressive conservative policies respectively however aggressive suboptimal model 4 pmin proved optimal algorithm model prefetching algorithm multiple disks analyzed 10 assumed global buffer readonce random data also investigate semionline algorithms using parallel io since prefetching involves reading blocks required future relative computation progressed presents natural situation lookahead necessary inspires us define lookahead version lru plru minimum possible lookahead one block beyond currently buffer known disk 3 find performance plru independent number disks contrast pcon whose performance degrade proportional number disks preliminaries computation references blocks disks order specified consumption sequence sigma block referenced buffer disk checked block present buffer consumed computation recently breslauer 7 arrived lookahead definition independently sequential demand context proceeds reference next block sigma referenced block present disk buffer io known demand io missing block initiated disk demand ios initiated disks system would idle block fetched however every demand io disk provides prefetch opportunity disks may used read blocks referenced near future example consider 2disk system holding blocks 1 2 b disks 1 2 respectively strictly demand io would require four nonoverlapped ios fetch blocks better strategy overlap reads using prefetching demand io block 1 second disk could concurrently prefetch b 1 1 b 1 consumed demand io block b 2 made concurrently prefetch block 2 number parallel ios case two prefetching increase io parallelism problem complicated finite buffer sizes every block read disk previously fetched block corresponding buffer must replaced prefetch blocks replacement decision made earlier absolutely necessary since computation continue without prefetched block early replacement choices much poorer replacement choices made later since computation proceeds useful replacement candidates may become available course block becomes demand block replacement cannot deferred poor replacement results greater number ios prematurely discarded discarded blocks may fetched repeatedly buffer thus tradeoff io parallelism achieved using prefetching increase number ios required due poorer replacement choices 21 definitions consumption sequence sigma order blocks requested computation subsequence sigma consisting blocks disk denoted sigma computation occurs rounds round consisting io phase followed computation phase io phase parallel io initiated number blocks one disk selected read selected disk block corresponding disk buffer chosen replacement new blocks read disks computation phase begins cpu consumes zero blocks present buffer order specified sigma point next block sigma present buffer round ends next round begins block whose absence forced io known demand block blocks fetched together demand block known prefetch blocks io phase may also initiated computation requires demand block case blocks fetched prefetch blocks often refer io phase round io time step io schedule makespan sequence hf f k set blocks one disk fetched parallel io time step k makespan schedule number io time steps required complete computation valid schedule one axioms a1 a2 satisfied block must present buffer consumed a2 buffer size blocks disk buffer time optimal schedule valid schedule minimal makespan among valid schedules normal schedule valid schedule f k 1 k contains demand block sequential schedule valid schedule blocks disk fetched order sigma start round let u denote next referenced block sigma currently buffer disk define minblock disk block disk buffer longest forward distance next reference normal sequential schedule io step k u 2 f k unless blocks disk buffer referenced u u 2 f k replace minblock disk u normal sequential schedule every io step k u 2 f k provided minblock disk minblock u fetched demand u replace minblock disk u normal sequential schedule every io step k u 2 f k unless blocks disk buffer referenced u u 2 f k among blocks buffer whose next reference u choose least recently used block replace u notice three schedules defined normal every io step one disk performing demand fetch rest either performing prefetch idle pmin plru greedy strategies almost always attempt prefetch next unread block disk situation disk idle every block buffer referenced block fetched note greedy prefetching may require making suboptimal replacement choices result increase number ios done disk show however pmin policy minimal io time therefore optimal example presented let blocks disk 1 2 round disk 1disk 2 cpu pmin schedule round disk 1disk 2 cpu pcon schedule round disk 1disk 2 cpu 9 gammagamma b3b4 b3 plru schedule fig 1 examples io schedules figure 1 shows io schedule using different policies example se quence entries second third columns indicate blocks fetched replaced disk round bold italic faced blocks indicate demand block prefetch block respectively contrast pmin conservative strategy 4 pcon pessimistic perform prefetch unless replace best block number ios done disk smallest possible however minimizing number ios done disk may result serialization accesses perform significantly worse optimal algorithm note figure 1 step 4 block fetched disk 2 pcon candidate replacement time current minblock block b 1 however b 4 demand block minblock would b 3 take advantage prefetch opportunity algorithm must know next unread block sigma requires lookahead upto least one block beyond currently buffer replacement decision made plru based solely examining current blocks buffer tracking referenced next unread block whose next reference next unread block least recently consumed block chosen replacement candidate plru applied sequence sigma used pmin pcon schedule 12 io steps obtained see fig 1 next section quantify precisely performance three algorithms 22 summary results let tpgammamin tpgammacon tpgammalru number io time steps required pmin pcon plru respectively let opt number io steps required optimal schedule let n denote length sigma also recall number disks size disk buffer blocks technical results paper follows 1 worstcase ratio makespan pcon schedule corresponding optimal schedule bounded worst pcon serialize disk accesses without increasing number ios performed disk see theorem 7 2 worstcase bound pcon stated tight consumption sequences pcon completely serializes accesses see theorem 8 3 pmin optimal schedule minimizes number parallel time steps valid schedules see theorem 11 4 worstcase ratio makespan plru schedule corresponding optimal schedule bounded worst plru inflate number ios performed disk done serial lru algorithm see theorem 13 5 worstcase bound plru stated tight consumption sequences plru inflate accesses disk factor see theorem 14 3 detailed results 31 bounds pcon begin simple upper bound tpgammacon let tmin denote maximum number ios done sequential min algorithm single disk theorem 7 consumption sequence tpgammacon opt proof show tpgammacon dtmin dt opt ios made pcon disk consumption sequence sigma exactly ios done sequential min algorithm disk sequence sigma hence number ios performed disk pcon bounded tmin worst none accesses disks overlapped whence first inequality follows finally second inequality follows since optimal parallel time disks cannot smaller minimal number ios single disk ut theorem 8 bound theorem 7 tight proof sketch construct following four lengthm sequences b j j th block disk aslo define sigma follows u n means n repetitions parenthesized sequence argued sigma 1 pmin schedule length 2nm 1 thus tpgammacon opt lower bounded 32 optimality pmin section show pmin requires minimal number parallel io steps among valid schedules proof show transform optimal schedule opt makespan l pmin schedule makespan schedules ff fi said match time steps every 2 blocks fetched replaced disk two sequences lemma 10 assume ff valid schedule length w let fl another schedule matches ff gamma 1 io time step buffers ff fl disk differ one block specifically ff block v block u fl block u block v assume v referenced u consumption sequence following references time gamma 1 construct valid schedule fi length w fi ff match fi fl match time step proof let first time step ff fetches discards either block v u either discard block v fetch block u construct schedule fi follows fi matches ff time steps w except time steps fi fetches replaces blocks fl one following must occur ff fetches block z 6 u discards block construction fi also fetch block z discard block u ff fetches block u discards block z z also discard block z ff fetches block u discards block fetch discard block three cases following io blocks buffer since fi fetches replaces blocks ff buffers ff fi time steps io time step 1 w fi consume blocks done ff clearly fi satisfies axiom a2 show fi valid schedule showing axiom a1 satisfied blocks consumed fi since ff fi buffer io io blocks consumed ff time step also consumed fi time step first time step io either block u v consumed ff since ff u buffer till least io hypothesis v consumed u hence blocks x 6 u v consumed ff time steps since buffers ff fi agree except fu v g x also consumed fi time step since ff valid schedule consumptions fi also satisfy axiom a1 hence fi valid schedule ut theorem11 pmin optimal schedule proof let delta andomega denote schedules created pmin opt algorithms respectively successively transformomega another valid schedule matches delta length asomega show pmin schedule optimal proof induction induction hypothesis assume time step tomega transformed valid scheduleomega matches delta time steps show toomega t1 discuss transformation arbitrary disk time step 1 construction applied disk independently delta andomega match letomega t1 asomega suppose delta andomega differ time step one following three cases must occur 1 consider case separately butomega fetch block let delta fetch block p discard block q 1 since delta always fetches blocks order referenced p referenced q induction hypothesis delta andomega buffer start time hence io andomega differ one block delta block p block q whileomega q p using lemma 10 ff construct valid scheduleomega t1 matchesomega time steps delta time 1 hence induction hypothesis satisfied 1 omega fetches block delta fetch block since delta fetch block time step 1 every block buffer start time step consumed block currently buffer referenced andomega buffer start time step brings fresh block p must discard block q since delta chose retain block q preference fetching block p either q must referenced p neither p q referenced first case using lemma 10 ff 1 constructomega t1 schedule satisfies induction hypothesis 1 second caseomega t1 asomega except time step omega t1 fetch block since buffers andomega t1 agree blocks except p q two blocks never referenced blocks consumed byomega time step also consumed byomega t1 time andomega fetch different blocks suppose delta fetches block p discards block q andomega fetches block discards block z 1 assume q 6 z since otherwise buffers ofomega delta differ pair blocks fp g easily constructomega t1 using lemma 10 ff induction hypothesis delta andomega buffer start time step 1 hence io andomega differ two blocks specifically set blocks buffer schedule theta first time fetches replaces block w 2 fp q zg either discard block q fetch block p z appropriate combination see cases construct t1 matchesomega time steps fetches p discards q following actions delta time step hence io zg one following occur fflomega fetches block discards q t1 also fetches discards z io fflomega fetches p discards q fetches discards z io bufferomega fflomega fetches z discards q nothing step io fflomega fetches t1 also fetches discards p io ffi fzg t1 fetch block time step io fzg fflomega fetches z discards fetches q discards p io bufferomega fflomega fetches p discards block fetches discards block io fflomega fetches z discards block fetches q discards block io consider consumptions made byomega time steps t1 notice consumption sequence p must precede q z must precede q constraints p follow since delta fetches p discards q fetches p preference constraint z follows since delta discards q rather z show toomega t1 buffers io t1 otherwise buffers must differ either pair blocks fq zg fy pg constructomega t1 concatenating prefix steps 1 schedule fi constructed using lemma 10 described let ff fl respectively schedules consisting suffixes t1 time steps greater equal end io buffers t1 differ fy pg let differ fq zg let applying lemma 10 construct desired sequence fi omega t1 obtained concatenating prefix fi consumptions blocks inomega t1 follows time steps 1 consumptions consumptions determined fi consumptions 1 till valid sinceomega valid schedule andomega t1 andomega match construction blocks consumed valid need show consume blocks asomega time steps p z buffer end io 1 consume p z io time later also since q must consumed p none blocks consumed io io 1 buffers andomega t1 agree except fp q zg blocks consumed also consumed byomega t1 time step concludes proof ut 33 bounds plru obtain upper bound worstcase performance plru show bound tight use following lemma whose proof omitted brevity lemma 12 let contiguous subsequence sigma references less distinct blocks disk consuming none blocks fetched plru theorem13 consumption sequences tpgammalru mt opt proof inductively assume consumptions made first steps pmin done less steps plru holds set references made pmin since distinct blocks consumed disk time step pmin since plru fetch block u lemma 12 pmins consumptions 1 done additional steps ut theorem 14 worstcase bound theorem 13 tight proof sketch show construction sigma two disks b blocks disks 1 2 respectively note first accesses sigma com mon plru pmin plru makes accesses every access pmin paper defined model parallel io systems answered several fundamental questions prefetching buffer management systems found proved optimality algorithm pmin minimizes number parallel ios possibly increasing number ios done single disk contrast pcon algorithm always matches replacement decisions wellknown singledisk optimal al gorithm min become fully serialized worst case behavior online algorithm lookahead plru analyzed performance plru independent number disks similar results shown hold pfifo parallel version fifo lookahead r influence lookahead competitive paging algorithms study replacement algorithms virtual storage new measure study online algo rithms study integrated prefetching caching strategies operating systems theory competitive online paging lookahead competitive paging algorithms beyond competitive analysis markov analysis multipledisk prefetching strategies external merging amortized efficiency list update paging rules tr ctr mahesh kallahalla peter j varman analysis simple randomized buffer management parallel io information processing letters v90 n1 p4752 15 april 2004 mahesh kallahalla peter j varman optimal prefetching caching parallel io sytems proceedings thirteenth annual acm symposium parallel algorithms architectures p219228 july 2001 crete island greece mahesh kallahalla peter j varman pcopt optimal offline prefetching caching parallel io systems ieee transactions computers v51 n11 p13331344 november 2002 michael penner viktor k prasanna cachefriendly implementations transitive closure journal experimental algorithmics jea 11 2006 kai hwang hai jin roy sc ho orthogonal striping mirroring distributed raid iocentric cluster computing ieee transactions parallel distributed systems v13 n1 p2644 january 2002