data structures efficient broker implementation profusion text databases internet becoming increasingly hard find useful databases given query attack problem several existing proposed systems employ brokers direct user queries using local database summary information available databases summary information must effectively distinguish relevant databases must compact allowing efficient access offer evidence one broker gloss effective locating databases interest even system hundreds databased examine performance accessing gloss summeries two promising storage methods grid file partitioned hashing show methods tuned provide good performance particular workload within broad range workloads discuss tradeoffs two data structures side effect work show grid files broadly applicable previously thought inparticular show varying policies used construct grid file provide good performance wide range workloads even storing highly skewed data b introduction last years seen explosion amount information available online falling costs storage processing communications contributed explosion emergence infrastructure provided worldwide web associated applications increasingly key issue whether piece information available online result emerging area research concerns brokers systems help users locate text databases likely contain answers queries perform service brokers use summary information available databases brokers must able query update summary information central problem broker design find representation summary information effective ability select appropriate information resources efficient query maintain gloss glossaryofservers server 17 18 one broker keeps database summaries choose promising databases given query initial studies gloss encouraging work partially supported arpa contract f336159311339 inria rocquencourt 78153 le chesnay france email anthonytomasicinriafr z computer science department stanford university stanford ca 943052140 usa email x current address trident systems sunnyvale ca usa email cluetridmicrcom department k55801 ibm almaden research center 650 harry road san jose ca 951206099 usa email schwarzalmadenibmcom lauraalmadenibmcom experiments small number databases indicate although gloss summaries orders magnitude smaller information summarize contain enough information select best databases query paper show gloss summaries employed representation summary information large scale system par ticular offer evidence gloss effectively locate databases interest even system hundreds databases suggest appropriate data structures storing large scale gloss summaries experiment two data structures partitioned multiattribute hashing grid file partitioned hashing offers best average case performance wide range workloads number hash buckets chosen correctly however grid file performs well grows gracefully number size summaries increases grid files developed store spatial data typically employed data fairly uniformly distributed gloss summaries store highly skewed show varying splitting policy used construct grid file provide good performance wide range workloads even storing highly skewed data thus side effect work demonstrate grid files generally applicable previously believed provide exploration effect different splitting policies grid file performance summary paper studies emerging problem construction distributed information retrieval systems namely performance brokers accessing updating summary information section 2 reviews gloss representation summary information section 3 discusses glosss effectiveness large numbers databases next four sections focus choosing storage method summary information section 4 discusses issues involved choosing storage method describes alternatives section 5 introduces idea using grid file store gloss summaries describes various splitting policies managing grid file growth presents simulation study grid file performance range workloads several splitting policies section 6 examines partitioned hashing alternative method efficiently storing gloss summaries section 7 compares results two storage methods explains recommend grid file section 8 positions work respect work brokers last section summarizes results conclusions provides ideas future work glossglossaryofservers server section briefly describe gloss helps users choose databases query evaluated users first submit query gloss obtain ranking databases according potential usefulness given query information used gloss produce ranking consists vector indicates many documents database contain word database vocabulary count total number documents database 17 summary information much smaller complete contents database approach scales well number available databases increases table 1 shows portion gloss summaries two databases row corresponds word column database example word information appears 1234 documents database db 1 30 documents database db 2 last row table shows total number documents database database db 1 1234 documents database db 2 1000 documents rank databases given query gloss estimates number documents match query database gloss produce estimates gloss summaries variety ways one possibility gloss assume query words appear docu database word db 1 db 2 information 1234 retrieval documents 1234 1000 table 1 part gloss summaries two databases ments following independent uniform probability distributions estimate number documents matching query database accordingly example query information retrieval expected number matches db 1 using gloss summary information table expected number matches db 2 9 gloss would return db 1 promising database query followed db 2 several estimation functions given 18 3 effectiveness gloss given set candidate databases set queries explored ability gloss suggest appropriate databases query original gloss studies 17 18 tested glosss ability select among six databases sure gloss would useful large scale broker scaled number databases two orders magnitude section describe set experiments demonstrate gloss select relevant databases effectively among large set candidates present metric evaluating closely list databases suggested gloss corresponds optimal list evaluate gloss based metric experiments used data complete set united states patents 1991 patent issued described entry includes various attributes eg names patent owners issuing date well text description patent total size patent data 34 gigabytes divided patents 500 databases first partitioning fifty groups based date issue dividing groups ten subgroups based high order digit subjectrelated patent classification code partitioning scheme gave databases ranged size order magnitude least somewhat differentiated subject properties ones would expect see real distributed environment test queries used set 3719 queries submitted inspec database offered stanford university folio boolean information retrieval system inspec patent database covers similar range technical subjects expected fair number hits patent data query boolean conjunction one words eg microwave interferometer document considered match query contains words conjunction test glosss ability locate databases greatest number matching docu ments compared recommendations omniscient database selection mechanism implemented using fulltext index contents 500 patent databases query found exact number matching documents database using fulltext index ranked databases accordingly compared ranking ranking suggested gloss calculating various values n ratio total number matching documents top n databases recommended gloss total number matching documents n best databases according ideal ranking metric normalized cumulative mean std dev 9 0764 0299 table 2 normalized cumulative recall 500 databases inspec trace recall approaches 10 n approaches 500 number databases interesting n small metric meaningful queries matching documents database eliminated queries reducing number queries sample 3286 table 2 shows results experiment table suggests compared omniscient selector gloss reasonable job selecting relevant databases average finding seventy percent documents could found examining equal number databases ideal circumstances gradual improvement number databases examined creases large standard deviations arise although gloss performs well majority queries remains stubborn minority performance poor nev ertheless using gloss gives dramatic improvement randomly selecting databases search fraction storage cost fulltext index felt initial results promising enough pursue use glosss representation summary information rigorous investigation progress ideally would like use real set test databases instead one constructed partitioning matching set queries submitted databases including boolean disjunctions well conjunctions try characterize queries gloss performs poorly study impact number query terms effectiveness metrics included example metric revealed whether matching documents scattered thinly across many databases concentrated large clumps would allow us measure corresponding impact effectiveness effectiveness also measured using information retrieval metrics 7 4 alternative data structures gloss summaries choice good data structure store gloss summaries depends type frequency operations gloss servers gloss server needs support two types operations efficiently query processing summary updates query arrives gloss access complete set document frequencies associated query keyword new updated summaries arrive gloss update data structure operating frequencies associated single database efficient access database might also needed different brokers exchange database summaries develop expertise 32 allow users relevance feedback 31 ask databases similar given database two types operations pose conflicting requirements gloss data structure process queries gloss needs fast access table word whereas handle frequency updates gloss needs fast access table database thus ideally would like simultaneously minimize access cost dimensions general however costs word database access trade consequently one must consider relative frequencies operations try find policy minimizes overall cost unfortunately relative frequencies word database access difficult estimate depend parameters number databases covered gloss intensity query traffic actual frequency summary updates etc illustrate tradeoffs let us assume query processing frequent opera tion gloss server receives 200000 query requests per day typical rate lycos worldwide web index 1 likewise let us assume update database summary day given scenario gloss covers 500 databases ratio accesses word accesses database would 4001 data structure might therefore favor performance accesses word database proportion however server received 350000 queries day covered different number databases received updates frequently vastly different ratio could occur therefore gloss needs data structure tuned adapt actual conditions observed practice simple data organization gloss cluster records according associated word build index words eg sparse b tree provide efficient access word 17 thus yielding fast query processing implement gloss using approach could adapt techniques building inverted files documents eg8 42 37 6 however approach support fast access database updating summaries exchanging brokers organizations spatial data provide variety techniques apply gloss particular interested techniques support partialmatch queries efficiently need access gloss records word database treebased approaches including quad trees kd trees kdb trees 39 r trees 19 r trees 34 bv trees 15 well suited type access answer partialmatch query might follow many paths root tree leaves similar problem arises techniques like ones based z order 29 contrast directory structure grid files 26 addressing scheme partitioned multiattribute hashing 22 make well suited answering partialmatch queries 5 using grid files gloss section describe grid files 26 used store gloss summaries describe series experiments explore performance show tune grid file favor access summary information word database 51 grid file basics grid file consists data blocks stored disk containing actual data records directory maps multidimensional keys data blocks gloss twodimensional word database identifier pairs initially one data block directory consists single entry pointing data block records inserted data block becomes full split two blocks grid file directory changes reflect 1 lycos accessible httplycoscscmuedu directory db1 db6 ostrich db3 2 data block directory db1 db3 db6 directory db1 db3 db6 data block data block z z 1 2 llama db5 5 data block data block buffalo db2 2 llama db5 5 llama db5 5 z ostrich db3 2 data block figure 1 successive configurations grid file record insertion splitting data block figure 1 shows grid file data blocks capacity two records 1 inserted two records grid file llama db 5 5 zebra db 1 2 one data block filled capacity containing two records one directory entry pointing data block insert record ostrich db 3 2 locate data block record belongs first reading directory entry corresponding word ostrich database db 3 since data block full split split data block different databases different words 2 split data block databases records databases range go one block records databases db 4 range go block also split grid file directory contain two entries one pointing data blocks insert record buffalo db 2 2 first locate data block record belongs looking directory find pointer associated range db 1 db 3 z corresponding data block data block already two records ostrich db 3 2 insertion new tuple causes data block overflow 3 split data block words reflect splitting directory creating new row first row directory corresponds word range second word range n z thus overflowed data block split one block record buffalo db 2 2 another block records ostrich db 3 2 zebra db 1 2 note directory entries corresponding database range db 4 point data block overflowed thus need split yet two directory entries form region regions may contain number directory entries always convex grid files refer division directory entries region partition region region example directory contains single partition locate portion directory corresponds record looking keep one scale per dimension grid file scales onedimensional arrays indicate partitions taken place dimension example word scale grid file configuration 3 z corresponding database scale db 52 splitting blocks rule used decide split data block called splitting policy splitting policy used adjust overall cost using grid file store summary information goal find evaluate splitting policies easily parameterized support observed ratio frequency word database accesses describe two extreme splitting policies characterize endpoints spectrum splitting behavior introduce three additional parameterized policies adjusted minimize overall cost insert record gloss grid file first find block record belongs using grid file directory record fits block insert 2 otherwise block must split either dividing two words dividing two databases splitting databases tends benefit access database whereas splitting words tends benefit access word choice splitting dimension therefore basic tool controlling relative access costs limit growth grid file directory however always look ways split block take advantage preexisting partitions directory 3 one entry grid file directory maps overflowed block region directory contains least one partition either words databases regions either side partition nonempty use one preexisting partition split block without introducing new entries directory one partition exists favor databases words multiple partitions exist single dimension choose one splits block nearly half see section 54 variation policy reduces amount unused space blocks precise figure 2 shows basic algorithm inserting record grid file line 1 computes region block record inserted according database word scales grid file directory line 2 attempts insert record overflow insertion succeeds otherwise overflow block line 5 checks region record inserted partition database scale partition region divided half along partition line records block region redistributed old new block new block assigned new region process eliminates partition region creating new region lines 78 word scale qualifying partitions line 10 need create one introducing new row column directory table 3 describes several policies choosing splitting dimension dbalways policy always attempts split block databases thus favoring access database access word conversely wordalways policy always attempts split words thus favoring access word access database two extremes lies spectrum possibilities bounded policy allows database scale grid file directory split 2 compress contents block grid file applying methods used storing sparse matrices efficiently 30 using methods 42 compressing inverted files example methods effectively increase capacity disk blocks terms number records hold 3 several alternative organizations grid file directory control growth make proportional data size alternative organizations include regionrepresentation directory br 2 directory 3 2level directory organization 20 shows implement directory disk yet explored techniques would work environment 1 compute region block record 2 record fits block 3 insert record 4 else 5 usable partitions database scale 6 divide region half database scale 7 else usable partitions word scale 8 divide region half word scale 9 else 10 split directory 11 divide region chosen scale 12 insert record figure 2 algorithm inserting record grid file gloss policy splitting dimension dbalways database wordalways word bounded dbsplits bound database else word probabilistic random probbound database else word prepartition like wordalways prepartitioning database table 3 different policies choosing splitting dimension bound times resorts splitting words thus allows splits databases favor access database putting upper bound number block reads might needed access records word bound set infinity bounded behaves dbalways whereas bound set zero bounded behaves wordalways probabilistic policy splits databases probability probbound unlike bounded policy favors splitting databases initially policy allows choice splitting dimension made independently split prepartition policy works like wordalways except database scale directory prepartitioned regions databases inserted see seeding database scale evenlyspaced partitions improves performance size region b db c db number available databases note scale chosen may possible split block scale instance may choose split block database scale scale may single value associated block consequently every record block database value case automatically split scale 53 metrics evaluation evaluate policies table 3 implemented simulation grid file c ibm risc6000 workstation ran experiments using 200 500 patent databases described section 3 around 13 gigabytes data resulting grid file 200 columns one 200 databases 402044 rows one distinct word appearing patent records file contained 2999676 total records four bytes per entry assumed disk block could hold 512 records evaluation various policies based following metrics db splits number splits occurred database scale word splits number splits occurred word scale total blocks total number blocks grid file excluding scales directory blockfill factor ratio used block space total block space measure indicates effectively data packed blocks directory size number entries database scale grid file directory times number entries word scale measure indicates overhead cost grid file directory four bytes would needed directory entry actual implementation average word database access cost number blocks accessed reading records single word database ie entire row column grid file averaged words databases corresponding scale expansion factor words databases ratio number blocks accessed reading records single word database minimum number blocks would required store many records averaged words databases corresponding scale metric compares access cost using grid file best possible access cost could achieved note since assume 512 records stored block 200 databases records single word always fit one block thus minimum number blocks required word one expansion factor words always equal average word access cost average trace word access cost expansion factor trace words similar word scale metrics averaged words occurring representative set patent queries instead words measurement used 1767 queries issued real users november 1994 fulltext patent database accessible http townhallorgpatentpatenthtml queries contain 2828 words appear least one 200 databases counting repetitions represents less one percent total vocabulary query words trace trace words occur average 9996 databases compared average 746 words thus trace words occur relatively high frequency databases weighted trace average cost metric gives overall cost using grid file given observed ratio word database accesses calculated multiplying wordtodatabase access ratio average trace word access cost adding average database access cost example ratio word database accesses observed 1001 weighted average cost 100 average word access cost average database access cost although choice splitting policy major factor determining behavior grid file performance also sensitive number subtle variations gloss summaries mapped onto grid file therefore discuss variants moving main body results 54 mapping gloss grid file insert gloss summary data database grid file one must first define mapping word integer corresponds row grid file explored two alternatives mapping alpha freq alpha mapping words databases gathered single alphabetically ordered list assigned sequential integer identifiers freq mapping set words ordered frequency instead alphabetically frequency word sum frequencies word across summaries 4 difference mapping two effects first although vast majority rows exactly one record freq map clusters rows multiple records upper part grid file top rows grid file contain record every database alpha map rows multiple records spread throughout grid file contrast distribution records across columns grid file fairly uniform second effect due fact artifact construction summary database ordered alphabetically alpha mapping therefore word id frequency pairs inserted increasing nonsequential wordidentifier order contrast inserted essentially random order since words ordered alphabetically identifiers ordered frequency similar considerations pertain order databases inserted grid file considered sequential ordering seq random ordering random seq case database 1 inserted database identifier 1 database 2 database identifier 2 etc random ordering mapping permuted randomly seq ordering corresponds statically loading grid file collection summaries random ordering corresponds dynamic addition deletion summaries information updated exchanged among brokers practice one could approximate freq mapping using predefined mapping table relatively common words assigning identifiers order remaining infrequent words mapping splits average cost total blockfill directory word database policy word db word db blocks factor size alpha seq middle 119 117 10492 10969 10859 54 13923 alpha seq right 138 115 8355 11589 8584 68 15870 alpha random middle 204 85 6103 15940 9258 63 17340 alpha random right 187 120 8734 13344 10586 55 22440 freq seq right 118 167 5841 10836 8750 67 19706 random middle 194 127 6914 12830 9737 60 24638 freq random right 167 142 8329 11877 10398 56 23714 table 4 dbalways policy different mapping splitting options consequence seq ordering insertion data grid file deterministic particular noticed default means choosing partition case overflow bad one since databases inserted left right lefthand member pair split blocks never revisited subsequent insertions always insert righthand block thus database scale split line 11 algorithm figure 2 would advantageous choose rightmost value block value split furthermore given choice preexisting partitions use splitting block would advantageous choose rightmost partition splitting line 6 algorithm examine effect parameterized algorithm figure 2 choose either rightmost value partition right middlemost value partition middle per original algorithm ran experiments eight combinations mapping splitting options dbalways wordalways bounded probabilistic policies table 4 shows results dbalways policy conclusions draw apply policies well note combination options chosen significant effect performance average word access cost worst combination options 18 times average word access cost best combination average database access cost factor 15 blockfill factor varies worst case 046 best case 068 table shows combination frequency ordering assignment word identifiers sequential insertion databases right option block splitting achieves lowest access costs word database blockfill factor slightly poorer best observed therefore used combination subsequent experiments base parameters experiments summarized table 5 55 comparison splitting policies begin comparison splitting policies examining basic behavior five policies tables 6 7 provide performance measurements policy parameterized policies probabilistic prepartition bounded present data single representative parameter value defer discussion parameter values later section start wordalways policy since behavior regular start experiment single empty block databases inserted block overflows word scale split point balances resulting blocks time 200 databases inserted word scale split 8878 times resulting grid file data block therefore contains complete frequency information number words ie multiple rows parameter value words rows 402044 records 2999676 records per block 512 database insertion seq word insertion freq block division right table 5 parameter values base set experiments see section 54 description parameters splits total blockfill directory policy word db blocks factor size probabilistic 05 202 101 8887 66 20402 prepartition bounded table performance measurements base experiment five policies introduced section 52 grid file number words data block depends number databases corresponding words appear expected average word access cost one block read clearly policy favorable one possible access word access records database however every block must read average database access cost therefore equals total number blocks file policy minimizes size grid file directory since reduces directory onedimensional vector pointers data blocks next consider dbalways policy measurements show database scale split 167 times however size grid file far exceeds capacity 167 blocks splitting must occur words well cf section 52 splits take advantage existing policy avg word avg db expansion factor avg trace cost dev cost dev db dev word cost dev wordalways 100 000 887800 000 71009 115257 100 000 prepartition bounded table 7 performance measurements base experiment five policies introduced section 52 e word access cost fraction databases bounded prepartition probabilistic figure 3 average word access cost bound changes partitions word scale exist otherwise word scale directory split splitting word scale occurred 118 times experiment leading average database access cost 10836 policy 884 times minimum number blocks must read best average database access cost policies measured however 5841 worst average word access cost frequently occurring words trace queries cost even higher point comparison two extremes dbalways wordalways policies measured probabilistic policy parameterized word database scales would chosen equal probability distribution data uniform two scales policy would average split scale number times table shows however data policy behaves much like dbalways policy policies skewed nature data ie vastly larger number distinct values word scale makes many attempts split database scale unsuccessful effect database scale quickly becomes saturated large numbers splits must occur word scale parameter value probabilistic policy gives poorer average database access cost slightly better average word access cost compared dbalways policy difference pronounced average trace word access cost blockfill factor varies little figures 3 4 show three tunable policies bounded prepartition probabilistic behave tuning parameter varies order graph results common set axes express parameter fraction total number databases thus study 200 databases xaxis value 05 figures represents parameter values 10 10 bounded prepartition probabilistic policies respectively figure 5 reveals hidden cost bounded policy uptotenfold inflation size gridfile directory parameter values midway extremes occurs bounded policy forces splits databases occur early possible insertion process whereas two policies distribute evenly bounded policy therefore e database access cost fraction databases bounded prepartition probabilistic figure 4 average database access cost bound changes500001500002500003500000 02 04 06 08 1 directory size fraction databases bounded prepartition probabilistic figure 5 directory size function policy parameter weighted average cost fraction databases bounded 1001 prepartition 1001 probabilistic 1001 figure weighted average cost wordtodatabase access ratio 1001 relatively splits words occur early insertion process regions split typically one database wide bound reached many splits words required subdivide remaining portion grid file introduces number additional directory entries equal bound value policies number splits words group databases fairly constant across width grid file total number splits words hence directory size much smaller 56 weighted average costs table 7 presents clear winner terms overall policy choice performance policy reduced single number ratio accesses word accesses database determined appropriately weighted overall access cost calculated wordtodatabase access ratio 1001 figure 6 shows weighted average cost policies across entire parameter range 5 lowest point set curves represents best choice policy parameter access ratio corresponds probabilistic policy parameter 025 best selections various ratios given tables 8 9 weighted average cost weighted trace average cost respectively access word predominates wordalways gives best performance access database common access word common dbalways preferred policy probabilistic policy appropriate parameter dominates choices 5 wordalways dbalways policies represented points probabilistic0 probabilistic1 respectively weighted avg cost blockfill factor 11 dbalways 167 67 10001 wordalways 9878 66 table 8 policy choices minimize weighted average cost different wordtodatabase access ratios weighted trace avg cost blockfill factor 11 dbalways 213 67 10001 wordalways 9878 66 table 9 policy choices minimize weighted trace average cost different wordto database access ratios 57 bounded access costs databases summarized gloss grow gradually time weighted access costs grid file must grow well using recommended policies tables 8 9 increasing cost distributed word database access costs minimize weighted average cost response time given query however depends word access costs terms contains increase without bound grid file grows response time growth unacceptable bounded prepartition policies used put upper limit word access cost case query cost depend number terms query upper limit word access cost policies determined parameter value prepartition policy word access cost exactly parameter value eg cost word prepartition10 bounded10 policy gives upper limit average cost lower 7 many words cost reach bound however tables 6 7 section 55 show penalty improved average word access cost fourfold increase directory size database average access cost corresponding tradeoffs values parameter deduced figures 3 4 5 section 55 58 experiments number experiments complete evaluation grid files storage method gloss summaries particular since must able maintain update summaries efficiently tested policies simulated updates also ran experiments smaller block size see affected results details found 38 results generally acceptable serve differentiate various policies hence repeated 6 using partitioned hashing gloss section analyze partitioned multiattribute hashing 22 alternative technique gloss access records efficiently word database first describe partitioned hashing handles gloss summaries show experimental results performance using data section 5 61 partitionedhashing basics partitioned hashing gloss records stored hash table consisting buckets bucket identified string b bits b w b bits associated word attribute records b remaining bits database attribute records hash functions hw h db map words databases strings b w b db bits respectively record w db f word w database db stored bucket address hw wh db db formed juxtaposition hw w h db db bit strings access records word w search buckets whose address starts hw w access records database db search buckets whose address ends h db db 6 hw hash function maps words integers 0 2 bw gamma 1 given word n 0 hw mapping first translating word w integer 41 taking bi w mod 12 bw c 0618033988722 similarly h db hash function maps database numbers integers 0 2 b db gamma 1 given database number db h db maps integer bi db mod 12 b db c initially assign one disk block per hashtable bucket bucket overflows assign disk blocks given fixed value b vary values b w b db letting b w greater b db favor access gloss records word since fewer buckets associated word database general consider configurations b w less b db since number words much higher number databases model records accessed frequently word database following section analyze experimentally impact b w b db parameters performance partitioned hashing gloss 62 experimental results analyze performance partitioned hashing gloss ran experiments using 2999676 records 200 databases section 5 experiments assumed 512 records fit one disk block bucket span one block average want bucket 70 full average therefore around buckets dedicate approximately bits bucket addresses section 7 shows results values b access records word w must access 2 b db buckets address prefix hw w accessing buckets involves accessing one disk blocks depending whether buckets overflowed figure 7 shows average word access cost function b w expected number blocks per word decreases b w increases since number buckets per word decreases conversely figure 8 shows average database access cost increases steeply b w increases extreme case b b db 0 need access every block every bucket hash table resulting expansion factor databases around 77328 7 contrast b 6 improvement scheme apply methodology 12 use gray codes achieve better performance partialmatch queries 7 smarter bucket organizations help alleviate situation sorting records database inside bucket example however buckets hash table would still examined get records database weighted avg cost blockfill factor table 10 choices b w b db minimize weighted average cost different word todatabase access ratios average around 1124 times many blocks database would need records clustered database partitioned hashing distribute records uniformly across different buckets example records corresponding database db belong buckets address suffix h db db surprisingly characteristic partitioned hashing lead poor blockfill factor average blockfill factor different values b w b db mostly higher 06 meaning average blocks least 60 full high values blockfill factor partly due fact last block bucket partially empty blocks bucket completely full measure performance partitioned hashing access word far computed average value various parameters words combined vocabulary 200 databases figure 7 also shows curve using words query trace section 5 average trace word access cost similar average word access cost two aspects partitioned hashing experiments explain behavior firstly number blocks read word w depend number records associated w access 2 b db buckets prefix hw w consequently access similar number blocks word example b number blocks access per word ranges 66 82 secondly 2 bw possible different word access costs hash function hw maps words 2 bw different values trace word w contribute random sample set 2 bw possible costs furthermore number words query trace 2828 word occurrences set 1304 different words significant respect number different access costs values b used experiments determine best values b w b db observed wordtodatabase access ratio computed weighted average cost different access ratios section 56 figure 9 shows results 1001 wordtodatabase access ratio ie accesses word 100 times frequent accesses database ratio best choice b weighted average cost around 184451 table 10 summarizes results different access ratios table 11 shows corresponding results trace words 8 7 comparing grid files partitioned hashing storing sum maries comparison tables 8 9 tables 10 11 shows ideal choice parameters either structure partitioned hashing grid file competitive data structures storing gloss summaries grid file outperforms partitioned hashing word database equally frequent however number practical reasons believe grid 8 1 23 study analytically derive values bw bdb would minimize number buckets accessed given query distribution average word access cost 333 average trace word access cost 222 figure 7 average word access costs function b w average database access cost 3 figure 8 average database access cost function b w weighted trace avg cost blockfill factor table 11 choices b w b db minimize weighted trace average cost different wordtodatabase access ratios weighted average cost 1001 333 weighted trace average cost figure 9 weighted average cost wordtodatabase access ratio 1001 function b w file better suited application firstly get optimum performance partitioned hashing critical choose total number buckets correctly instance suppose overestimate number records gloss summaries set number bits identify bucket instead experiments section 6 table 12 shows expected average blockfill factor drops half values see table 10 twice many buckets number records best average access costs also deteriorate example weighted average cost 1001 wordtodatabase access ratio grows 2624 alternatively underestimate number records gloss summaries set obtain results table 13 case average blockfill factor higher case however average access costs significantly higher example 1001 wordtodatabase access ratio weighted average cost experiments show crucial performance partitioned hashing choose right number buckets hash table since expect databases grow time even initially optimal choice degrade database size increases contrast grid file grows gracefully dynamic versions multiattribute hashing like ones 24 solve problem expense complicated algorithms resulting techniques closely related grid files secondly partitioned hashing tradeoff word database access cost fixed time division hashvalue bits made way correct error rebuild hash table contrast value probabilistic splitting parameter grid file dynamically tuned although changing parameter may able correct unfortunate splits existing grid file least future splitting decisions improved finally partitioned hashing treats words regardless many databases occur likewise treats databases regardless number words contain contrast cost reading row column grid file tends proportional number records contains weighted avg cost blockfill factor table 12 choices b w b db minimize weighted average cost different word todatabase access ratios weighted avg cost blockfill factor 1001 9 3 262305 072 table 13 choices b w b db minimize weighted average cost different word todatabase access ratios 8 related work many approaches solving text database discovery problem proposed 27 33 fall two groups distributed browsing systems eg 4 25 query systems eg 21 14 10 distributed browsing systems users follow predefined links data items wealth information accessible way links must maintained hand therefore frequently date nonexistent finding information frustrating say least address problem increasing number systems allow users query collection metainformation available databases eg 36 2 28 content router 35 11 metainformation typically provides sort summary contents database thus systems fit generic concept broker course different systems use different representations summary information implementations vary substantially scale growing number available databases systems index document titles generally small fraction document eg worldwide web worm 9 veronica 14 approach sacrifices important information contents database systems keep succinct sometimes humangenerated summaries contents database eg aliweb system 10 wais 21 humangenerated summaries often date since database changes summaries generally english text summaries wais may capture information user wants gloss attacks problems using words database summary automatically updating summary database changes glossbased metainformation query facility implemented servers 11 system architectures range centralized servers lycos 12 yahoo 13 collections brokers mediators indie shorthand distributed indexing 10 9 harvest 5 brokers know subset data sources special broker keeps informa 9 worldwide web worm accessible httpwwwcscoloradoeduhomemcbryanwwwwhtml accessible httpwebnexorcoukaliwebdocaliwebhtml 11 gloss accessible httpglossstanfordedu 12 lycos accessible httplycoscscmuedu 13 yahoo accessible httpyahoostanfordedu tion brokers 32 whois 40 allow brokers indexservers whois exchange information sources index forward queries receive knowledgeable brokers 13 similarly allows sites forward queries likely sources based case information received source past recently 7 applied inference networks traditional information retrieval text database discovery problem approach summarizes databases using document frequency information term type information gloss keeps databases together verse collection frequency different terms inference network uses information rank databases given query many proposals summarize database contents use summaries answer queries performance studies area 32 includes simulation study effectiveness brokers exchange content summaries concerned content summaries costs storing exchanging 7 studies inference network approach experimentally likewise 17 18 examine effectiveness storage efficiency gloss without worrying costs access update representation summary information distributed text databases clearly important broad range query systems paper goes beyond existing works addressing storage information studying performance accesses updates information 9 conclusion investigation reported paper represents important step toward making gloss useful tool large scale information discovery showed gloss fact effectively distinguish among text databases large system hundreds databases identified partitioned hashing grid files useful data structures storing summary information gloss requires showed partitioned hashing offers best average case performance wide range workloads performance degrade dramatically amount data stored grows beyond initial estimates grid file tuned perform well require initial assumption ultimate size summary information examined characteristics gloss summaries make policy splitting blocks grid file critical factor determining ultimate row column access costs evaluated several specific policies using databases containing us patent office data investigation showed expected ratio row accesses column accesses high greater 10001 experiment best policy always split words existing distributed information retrieval services exceed high ratio ratio low updates exceed queries best policy split databases whenever possible extremes policy splitting databases given probability used achieve desired balance row column access costs given probability expected number database splits ds policy performs better policies prepartition database scale ds times always divide database scale ds times important firm bound query costs policies prepartition divide database scale fixed number times used work needed explore utility gloss summaries representation summary information brokers effectiveness studied realistic environment real databases matching queries queries involve disjunction well conjunc tion work done storage summaries well unfortunate aspect grid files need relatively large directory techniques reported controlling directory size 3 must examine whether techniques applicable highlyskewed grid files generated gloss summaries compression techniques 42 would significant impact performance figures reported finally building operational gloss server large number real databases way truly determine right ratio word database access costs broader front many issues remain studied vastly expanding number scope online information sources make clear centralized solution database discovery problem never satisfactory showing need explore architectures based hierarchies 16 networks brokers r optimal partialmatch retrieval fields independently specified information brokers sharing knowledge heterogeneous distributed system new algorithm computing joins grid files harvest scalable fast incremental indexing fulltext information retrieval searching distributed collections inference networks optimizations dynamic inverted index maintenance distributed indexing scalable mechanism distributed information retrieval distributed indexing autonomous internet services content routing network wais servers multiattribute hashing using gray codes information retrieval system network resources veronica service general solution ndimensional btree problem generalizing gloss vectorspace databases broker hierarchies effectiveness gloss textdatabase discovery problem precision recall gloss estimators database discovery dynamic index structure spatial searching implementation grid file design concepts experience information system corporate users wide area information servers art computer programming volume optimal partialmatch retrieval prospero file system global file system based virtual system model grid file adaptable internet resource discovery services distributed active catalogs metadata caching descriptive name services class data structures associative searching sparse matrix technology introduction modern information retrieval scalable comparison internet resource discovery approaches content routing system distributed information servers querying network autonomous databases incremental updates inverted lists text document retrieval data structures efficient broker implementation principles database knowledgebase systems architecture whois file organization database design efficient indexing technique fulltext database systems tr implementation grid file design concepts experience multiattribute hashing using gray codes principles database knowledgebase systems vol file organization database design optimization dynamic inverted index maintenance distributed indexing content routing distributed information servers effectiveness gioss text database discovery problem incremental updates inverted lists text document retrieval searching distributed collections inference networks general solution ndimensional btree problem performance issues distributed sharednothing informationretrieval systems art computer programming volume 2 3rd ed grid file optimal partialmatch retrieval fields independently specified precision recall italicgiossitalic estimators database discovery introduction modern information retrieval class data structures associative searching rtrees internet resource discovery services new algorithm computing joins grid files rtree efficient indexing technique full text databases fast incremental indexing fulltext information retrieval generalizing gloss vectorspace databases broker hierarchies ctr ray r larson distributed resource discovery using z3950 build crossdomain information servers proceedings 1st acmieeecs joint conference digital libraries p5253 january 2001 roanoke virginia united states athman bouguettaya boualem benatallah mourad ouzzani lily hendra webfindit architecture system querying web databases ieee internet computing v3 n4 p3041 july 1999 jian xu yinyan cao eepeng lim weekeong ng database selection techniques routing bibliographic queries proceedings third acm conference digital libraries p264274 june 2326 1998 pittsburgh pennsylvania united states hosain h newton rahman dynamic adaptation multikey index distributed database system proceedings 9th wseas international conference computers p16 july 1416 2005 athens greece luis gravano hector garciamolina generalizing gloss vectorspace databases broker hierarchies proceedings 21th international conference large data bases p7889 september 1115 1995 james c french allison l powell metrics evaluating database selection techniques world wide web v3 n3 p153163 2000 athman bouguettaya boualem benatallah brahim medjahed mourad ouzzani lily hendra adaptive webbased database communities information modeling internet applications idea group publishing hershey pa ouzzani b benatallah bouguettaya ontological approach information discovery internet databases distributed parallel databases v8 n3 p367392 july 2000 luis gravano hctor garcamolina anthony tomasic gloss athman bouguettaya boualem benatallah lily hendra mourad ouzzani james beard supporting dynamic interactions among webbased information sources ieee transactions knowledge data engineering v12 n5 p779801 september 2000 diego puppin fabrizio silvestri domenico laforenza querydriven document partitioning collection selection proceedings 1st international conference scalable information systems p34es may 30june 01 2006 hong kong allison l powell james c french comparing performance collection selection algorithms acm transactions information systems tois v21 n4 p412456 october