bayesian segmentation methodology parametric image models abstractregionbased image segmentation methods require criterion determining merge regions paper presents novel approach introducing bayesian probability homogeneity general statistical context approach require parameter estimation therefore particularly beneficial cases estimationbased methods prone error little information contained regions therefore parameter estimates unreliable apply formulation three distinct parametric model families used past segmentation schemes implicit polynomial surfaces parametric polynomial surfaces gaussian markov random fields present results variety real range intensity images b introduction problem image segmentation partitioning image set homogeneous regions fundamental problem computer vision approaches segmentation problem grouped regionbased methods image subsets grouped together share property eg 26 edgebased methods dissimilarity regions used partition image eg 9 combined region edgebased methods eg 22 paper present new bayesian regionbased approach segmentation standard approach regionbased segmentation characterize region homogeneity using parameterized models approach two regions considered homogeneous explained single instance model ie common parameter value example range image applications object surfaces often modeled piecewise algebraic eg 30 parameters surface coefficients corresponding polynomial two regions homogeneous thus merged belong single polynomial surface ie coefficients corresponding polynomials practice regions parameters cannot observed directly inferred observed data knowledge imaging process statistical approaches inference made using bayes rule conditional density py k ju k expresses probability certain data statistics derived data k observed given region k parameter value u k typical statistical region merging algorithms eg 27 point estimates parameter space obtained different regions merging decisions based similarity estimates often maximum posteriori map estimate used obtained maximizing py k ju k inherent limitation nearly estimationbased segmentation methods reported date explicitly represent uncertainty estimated parameter values therefore prone error parameter estimates poor one notable exception work szeliski 29 optimal estimates variance estimates computed overcome problem present bayesian probability homogeneity directly exploits information contained statistical image models opposed computing point parameter estimates probability homogeneity based ability formulate prior probability density parameter space assess homogeneity taking expectation data likelihood posterior parameter space type expectation also used cohen fan formulate data likelihood segmentation applied gaussian markov random field model 5 work segmentations defined space pixel labelings windowbased iterative optimization segmentation determined maximizes data likelihood considering regionbased probability homogeneity introduce different decomposition prior space segmentations probability homogeneity also considered function bayes factor recent statistical literature 1 15 23 28 developed statistical decision making model selection detailed description model derivation bayesian probability homogeneity given section 2 addition providing explicit accounting uncertainty associated segmentation could feasibly used higher level vision processes recognition method extends straightforward way allow application multiple independent image models furthermore framework require specification arbitrary parameters eg threshold values since context dependent quantities statistically estimated applied bayesian probability homogeneity segmentation problems using three popular model families implicit polynomial surfaces section 3 parametric explicit polynomial surfaces section 4 gaussian markov random fields texture segmentation section 5 section 7 present experimental results model families results obtained using algorithm described section 6 developed special numerical computation methods directly computing probability homogeneity using parametric models presented paper 17 without using large data set asymptotic assumptions reason able consider small region sizes implicit polynomial results presented section 7 previous techniques obtain expectations parameter space used form assumption 3 5 27 principle bayesian probability homogeneity could applied regionbased segmentation algorithms related work used probability homogeneity key component generating probability distributions alternative segments segmentations 18 2 general probability homogeneity section provides formulation derivation general probability homogeneity version presented determines probability union two regions homoge neous probabilistic treatment general region sets appears 16 section 21 defines random variables densities used general statistical context section 22 derive expressions probability homogeneity 21 general model definitions elements image arranged 2d array given point di j set neighbors using standard fourneighbors set region r k connected subset two regions r 1 r 2 called adjacent exists di 1 neighbors often profitable begin initial partition image small regions construct new segmentations combining regions standard approach taken region merging paradigm instance sabata et al initially generate image sels corresponds regions nearconstant differential properties 26 silverman cooper begin initial grid small regions 27 denote initial set regions r represents partition r k 2 r associate following parameter space observation space degradation model prior model see table 1 parameter space directly captures notion homogeneity every region parameter value point parameter space associated unknown observer observation space defines statistics functions image elements contain information regions parameter value could use image data directly observation could choose function possibly sufficient statistic depending application increases efficiency bayesian computations although parameter values known general statistical model introduced uses two probability density functions pdfs yielding prior model degradation model prior model represented density parameter space usually uniform parameter space random vector u k could instance represent space polynomial surfaces observation space random vector k represents data functions data x 2 r k degradation model conditional density py k ju k models noise uncertainty prior model initial parameter space density pu k table 1 key components general statistical framework observations made degradation model represented conditional density observation space given parameter value considered model image noise components used similar contexts image segmentation 8 29 order determine probability homogeneity necessary consider statement form hr 1 r 2 corresponds condition r 1 r 2 homogeneous corresponds condition r 1 r 2 homogeneous use h represent condition hr 1 r 2 h represent note h true r 1 r 2 share parameter value 22 probability homogeneity derivation section derive expression bayesian probability homogeneity given observations r 1 r 2 result expression requiring three integrations parameter space given 2 5 vectors 1 2 represent observation spaces r 1 r 2 respectively words random vector 1 corresponds applying functions data variables di j belong r 1 similarly 2 obtained r 2 observations serve evidence used determine bayesian probability homogeneity represented apply bayes rule obtain denominator 1 standard normalizing factor bayes rule binary sample space fh hg expression p h represents prior probability homogeneity ie probability two adjacent regions merged 1 2 observed practice usually take p represents uniform distribution binary sample space implications prior distributions discussed 18 write 1 utilizes reasonable assumption py 1 discussed 16 0 1 decomposition factors contributing posterior probability homogeneity either ratios takes value 1 essentially bias posterior probability homogeneity using common prior density pu 12 assumption observations 1 2 independent given common parameter value u 12 write denominator marginal respect u z z using 4 marginal u k term numerator obtain z z z ratio similar forms appeared recently work statistics literature termed bayes factor smith speigelhalter used similar ratio model selection nested linear parametric models 28 aitkin developed bayes factor model comparison conditions prior model data 1 kass vaidyanathan present discuss asymptotic approximations sensitivity varying priors bayes factor 15 pettit also discusses priors concern robustness respect outliers 23 approach extends straightforward way case independent observation spaces parameter spaces case posterior probability homogeneity expressed 16 l l l l 2 similar 5 3 implicit polynomial surfaces range data surface models correspond solution sets implicit algebraic equations treated section parametric explicit polynomial models treated section 4 bolle cooper modeled objects appearing ranges images patches planes spheres cylinders position estimation 3 faugeras hebert used implicit quadric planar models object modeling segmentation recognition 7 taubin cooper developed efficient estimation procedure implicit polynomial curves surfaces arbitrary order application object recognition 30 model di j represents point 3 specified x coordinates simplicity notation denote element image x instead di j rather using indices index points belong region r k x 31 parameter manifold implicit polynomial equation represented constants j b j c j positive integers representing exponents variable used indicates implicit function x variables present formulation redundant representations solution sets ie many parameter vectors describe surface 3 profitable choose restriction parameter space facilitates integrations 5 maintains full expressive power use constraints constrain parameter space halfhypersphere sigma n termed parameter manifold 32 observation space observation considered function signed distances points x 2 r k surface determined u k termed displacements define ffix oedelta u k displacement point x surface described zero set fx oex 0g function ffix oedelta u k takes negative values one side surface positive consider following observation space definition others mentioned 16 distance approximation 3 30 note use k instead k observation space scalar chose use sum squares since obtained improved integration efficiency similar segmentation results experimentally compared using displacements directly distance approximation good small displacements approach good approximations required small displacements large displacement errors cause difficulty approximately zero tail values chisquare pdf presented section 33 33 degradation model define degradation model first need express density corresponding displacement observed point given surface use probability model range scanning error used justified 3 also used 30 model asserts density pffiju displacement observed point surface oex u gaussian random variable zero mean known variance oe 2 degradation model merely chosen representative possible models used practice different imaging systems models may appropriate instance mirza boyer use tdistribution model degradation robustness respect outliers 20 ikeuchi kanade provide detailed discussion modeling variety rangeimaging sensors 12 since taking sum squares independent standard gaussian random variables yields chisquared random variable degradation density using 8 k sumofsquares given region r k parameter value u k given 8 also gammadelta standard gamma function number elements r k variance oe 2 estimated considered part specified degradation model 34 prior model since parameter space restricted bounded set define prior pdf equal value everywhere parameter manifold captures notion uniformity due lack information however important note choice parameter manifold affects prior distribution space surfaces constraints used parameter space assumed constantvalued pdf distribution would somewhat different one selected information present ie observed data points distinction becomes less important since density parameter manifold must integrate one uniform density inverse surface area half hypersphere defines parameter manifold prior model pu k n represents area n parameter manifold obtained straightforward integration techniques 16 4 parametric explicit polynomial surfaces parametric polynomial surfaces used past segmentation work model surface patches range imagery sets intensities intensity images early work haralick watson facet model introduced intensity image subsets approximated polynomials representing idealized image 10 besl jain used polynomials variable order segmentation select best model analyzing fittingerror signs meansquare error 2 leonardis et al also used bivariate polynomials variable order select appropriate image description costbenefit objective function obtain segmentation 19 silverman cooper used explicit quadric planar equations model surfaces patches intensity images clusteringbased segmentation 27 sabata et al used parametric polynomials model surfaces hierarchical range image segmentation scheme 26 general form parametric polynomial model um b positive integers observation space k represents vector pointtosurface displacements intensities r k given parameter value u k degradation use additive gaussian iid zeromean noise model considered 27 hence gaussian pdf associated element observation space vector due independence noise model joint density obtained taking product individual displacement densities define prior model assigning uniform density compact portion parameter space problem selecting bounds uniform prior known lead difficulty bayesian analysis referred lindleys paradox 28 volume unfiorm density defined increases ratio 5 decreases select p h experiments appropriately cancel effects volume however must understood choice prior case significantly affects probability homogeneity purposes problem type changes 1 scaling factor leading correct ordering likely merges ambiguous termination criterion 5 texture segmentation using gaussian mrf model models texture used extensively segmentation section consider application general probability homogeneity gaussian markov random field gmrf model problem unsupervised texture segmentation problem considered numerous contexts extensive survey covers fractal models operator models structural texture methods frequency domain techniques provided 25 parameter space use special mrf formulation known sar model described 14 model applied texture segmentation intensity images 4 5 27 recently extended texture modeling segmentation color images 21 particular cohen fan considered maximizing likelihoods formulated integration gmrf parameter space 5 similar approach taken however interested iteratively merging region pairs maximize probability homogeneity image element di j represents single intensity xi j treated random variable ndimensional parameter space represents interaction pixel local set neighboring pixels order mrf indicates size local neighborhood considered first order mrf 4 corresponding interactions xi j xi 1 general order mrf interactions image element l th parameter interaction denoted l x hence general point xi model could also consider intensity mean r k k part parameter space instead chose estimate mean using region data experiments observation space k defined vector corresponds intensity data xi j region r k hence dimension k equal number pixels r k assume noise process occurs linear prediction 12 gaussian joint density use points r k proper pdf however considered reasonable approximation used previous segmentation schemes 4 21 27 obtain degradation model taking product density expressions individual pixels oe 2 k represents variance r k variance could also considered part parameter space however estimate variance region texture model used prior used section 4 6 computation issues provide outline algorithm used generate experiments presented section 7 algorithm resembles agglomerative clustering 27 however standard metricbased merging criterion replaced probability homogeneity 1 pair adjacent regions r store result priority queue elements sorted probability 2 remove first pair queue rm 1 update r adding rm j rm 1 removing rm 1 rm 2 3 r adjacent rm compute p hr rm jy ym insert result priority queue 4 probability first pair queue less p c alternatively number regions r c terminate 5 go 2 regard line 4 many clustering algorithms require specification number final clusters recent work done specifically addressing problem determining number clusters known cluster validation context image segmentation applications 13 32 integrals arising 5 computed using specialized monte carlobased technique implicit surface model ellipsoidal decomposition technique parameter spaces parametric polynomials mrfs computation methods discussed 17 7 experiments section presents experimental results using models presented sections 35 three models performed segmentation experiments dozens real images figure shows eight range image results using either implicit planar quadric model result first show intensity image synthetic rendering range image segmentation result figure 1a also shows initial region set r variance degradation model estimated given range image set yield accurate placement points close segment boundaries performed maximumlikelihood supervised clustering segmentation output merging algorithm first discard small final segments image point x choose region label l r represents set regions containing points adjacent x u k leastsquares parameter estimate region r k initial region set r obtained combining small grid edge map produced running canny edge detector corresponding intensity image building initial region set would like nonhomogeneous initial regions possible application edge detector provides slightly improved performance near boundaries edge detector applied synthetic renderings range data generated method discussed sabata et al 26 images figures 1ac true corresponding intensity image used remaining range images performed parameter tuning canny edge detector therefore many missed edges extra edges initial region maps first three images presented figure 1 belong msu range image set often used evaluation segmentation algorithms hoffman jain performed smoothing data iteratively clustered range points based position surface normal estimation 11 conservative clustering obtained additional merging occurs surface type classification boundary analysis performed sabata et al also provide results imagery 26 also perform smoothing data use pyramidal clustering algorithm synthetic renderings range data finally merge regions using squarederror criterion obtained remaining images figure 1 lab using k 2 grf range scanner setup range image set suitable demonstrating framework since typical segments approximately 400500 points typical segment sizes msu images around 40005000 points noise levels two sets comparable leads greater uncertainty probabilities however good segmentations obtained next two images show application parametric polynomial model segmentation intensity images necessarily propose parametric polynomials appropriate model intensitybased segmentation instead demonstrating success methodology given model family considered previously 27 figure 2a image tape dispenser figure 2b shows plastic slinky since model family accurate ie images likely underlying polynomial model f h c g figure 1 range image segmentation results additive gaussian noise number classes difficult select therefore show results section userspecified fixed class numbers figure 2cf show four texture results obtained using thirdorder mrf figure 2c composed brodatz textures figure 2d texture image constructed testing texture segmentation algorithms 6 figure 2e shows fourclass texture result image obtained piecing together photographs different quilts figure 2f image nasa magellan space probe data venusian terrain recent discussion comparisons models texture segmentation found 6 24 25 texture segmentation experiments similar imagery appear 4 27 31 32 considered coarse segmentations obtained initial region set r formed partitioning image square blocks present coarse segmentations b c e f figure 2 parametric polynomial texture segmentations since 1 minimal region size needed model contains useful information 25 2 supervised methods exist providing good boundary localization given coarse segmentation 4 5 6 conclusions paper presented new approach regionbased segmentation key approach new formulation probability union two regions homogeneous approach require parameter estimation therefore particularly beneficial cases estimationbased methods prone error experiments provide strong support bayesian formalism based quality segmentation results broad class models considered indicates general applicability methods segmentations obtained highestprobabilityfirst algorithm good context recent segmentation results model types bayesian formalism used algorithms generate probability distributions alternative segments segmentations real imagery 18 acknowledgements thank ken moroney work experiments also thank pat flynn msu pattern recognition image processing lab hans du buf becky castano fang liu narendra ahuja anonymous reviewers work sponsored nsf iri9110270 r posterior bayes factors segmentation variableorder surface fitting optimally combining pieces information simple parallel hierarchical relaxation algorithms segmenting noncausal markovian random fields maximum likelihood unsupervised textured image segmentation representation stochastic relaxation boundary detection constrained optimization facet model image data segmentation classification range images modeling sensors toward automatic generation object recognition program robust clustering applications computer vision estimation choice neighbors spatialinteraction models images approximate bayes factors orthogonal parameters bayesian framework considering probability distributions image segments segmentations methods numerical integration highdimensional posterior densities application statistical image models considering uncertainty alternatives lowlevel vision segmentation search best description image terms primitives information theoretic robust sequential procedure surface model order selection noisy range data unsupervised segmentation textured color images using markov random fields integrating region growing edge detection bayes factors outliers models using device imaginary observations segmentation 3d range images using pyramidal data structures bayesian clustering unsupervised estimation surface texture models bayes factors choice criteria linear models bayesian modeling uncertainty lowlevel vision estimation planar curves texture segmentation using voronoi polygons modelfitting approach cluster validation applications stochastic modelbased image segmentation tr ctr roland wilson changtsun li class discrete multiresolution random fields application image segmentation ieee transactions pattern analysis machine intelligence v25 n1 p4256 january adam hoover gillian jeanbaptiste xiaoyi jiang patrick j flynn horst bunke dmitry b goldgof kevin bowyer david w eggert andrew fitzgibbon robert b fisher experimental comparison range image segmentation algorithms ieee transactions pattern analysis machine intelligence v18 n7 p673689 july 1996