lazy release consistency hardwarecoherent multiprocessors release consistency widely accepted memory model distributed shared memory systems eager release consistency represents state art release consistent protocols hardwarecoherent multiprocessors lazy release consistency shown provide better performance software distributed shared memory dsm several optimizations performed lazy protocols potential improve performance hardwarecoherent multiprocessors well complexity precluded hardware implementation advent programmable protocol processors may become possible use present evaluate lazy releaseconsistent protocol suitable machines dedicated protocol processors protocol admits multiple concurrent writers sends write notices concurrently computation delays invalidations acquire operations also consider lazier protocol delays sending write notices release operations results indicate first protocol outperforms eager release consistency much 20 across variety applications lazier protocol hand unable recoup high synchronization overhead represents qualitative shift dsm world lazier protocols always yield performance improvements based results conclude machines flexible hardware support coherence use protocols based lazy release consistency less aggressively lazy form appropriate dsm b introduction remote memory accesses experience long latencies large sharedmemory multiprocessors one serious impediments good parallel program performance relaxed consistency models 6 18 help reduce cost memory accesses masking latency write operations relaxed consistency requires memory consistent certain synchronization events thus allows protocol buffer merge pipeline write requests long respects consistency constraints specified model work supported part nsf institutional infrastructure grant cda8822724 onr research grant n00014 92j1801 conjunction darpa research information science technologyhigh performance computing software science technology program arpa order 8930 brazilian capes nutesufrj fellowships release consistency 10 widely accepted relaxed consistency model release consistency memory access classified ordinary access acquire release release indicates processor completing operation processors may depend releasing processors previous writes must made visible processor performs subsequent acquire acquire indicates processor beginning operation may depend processor processors writes must made locally visible definition release consistency provides considerable flexibility coherence protocol designer make writes processor visible processors hardware implementations release consistency dash multiprocessor 17 take eager operations trigger coherence transactions eg invalidations immediately though transactions execute concurrently continued execution application processor stalls write buffer overflows reaches release operation previous transactions yet completed approach attempts mask latency writes allowing take place background regular computation better software coherence protocols adopt lazier approach distributed shared memory dsm emulation delaying coherence transactions attempt reduce total number messages exchanged processor munin 3 example buffers write notices associated particular critical section sends reaches release point paranet treadmarks 13 goes rather send write notices potentially interested processors time release keeps records allow inform acquiring processor write notices logical past releaser yet logical past acquirer postponing coherence transactions allows protocol combine messages given pair processors avoid many useless invalidations caused false sharing 8 keleher et al shown optimizations significant benefit implementation lazy release consistency 12 dsm systems ideally one might hope achieve similar benefits hardwarecoherent systems sheer complexity lazy protocols however heretofore precluded implementation hardware moreover differing architectural constants hardware software systems potential former concurrent execution application protocol makes less obvious kinds optimizations effective kinds systems lazy release consistency complicated terms code terms size complexity state information absent global garbage collection operation paranet protocol maintains complete history words modified critical sections lifetime application given current state art implementing sort protocol hardware would appear prohibitively expensive several research groups however developing programmable protocol processors 15 20 complexity lazy release consistency may manageable remains determine whether laziness profitable sorts systems devise protocol provides best possible performance paper present protocol combines desirable aspects lazy release consistency reducing memory latency avoiding unnecessary invalidations eager release consistency reducing synchronization waits executing coherence operations background protocol supports multiple concurrent writers overlaps transfer write notices computation delays invalidations acquire operations outperforms eager release consistency 20 variety applications also consider lazier protocol delays sending write notices release operations results indicate however lazier protocol actually hurts overall program performance since reduction memory access latency compensate increased synchronization overhead result reveals qualitative difference software hardware distributed sharedmemory multiprocessors delaying coherence operations much possible appropriate dsm systems hardwareassisted coherence finally study sensitivity results several architectural parameters including cache line size memory access latency memory network bandwidth results indicate performance advantage lazy protocol eager release consistency protocol increase future machines based results conclude machines hardware support coherence possible employ variant lazy release consistency avoid excessively lazy implementations rest paper organized follows section 2 describes lazy protocol together lazier variant delays sending write notices section 3 describes experimental methodology application suite section 4 presents results begins discussion sharing patterns exhibited applications proceeds compare performance lazy protocols eager release consistency protocol similar one implemented dash multiprocessor finally describes impact architectural trends relative performance protocols present related work section 5 conclude section 6 hardwaresupported coherence section present protocol lazy release consistency sharedmemory multiprocessors hardwaresupported coherence protocol resembles softwarebased protocol described 14 modified significantly exploit ability overlap coherence management computation deal fact coherence blocks evicted processors cache due capacity conflict misses basic concept behind protocol allow processors continue referencing cache blocks written processors although write notices sent home node concurrently computation main processor invalidations occur acquire operations sufficient ensure true sharing dependencies observed protocol employs distributed directory maintain caching information cache blocks directory entry block resides blocks home nodethe node whose main memory contains blocks page directory entry contains set status bits describe state block state one following uncached processor copy block initial state cache blocks shared one processors caching block none attempted write dirty single processor caching block also writing weak two processors caching block least one writing addition blocks status bits directory entry contains list pointers processors sharing block pointer augmented two additional bits one indicate whether processor also writing block indicate whether processor notified block entered weak state simplify directory operations two additional counters maintained directory entry number processors sharing block number processors writing figure 1 shows directory state transition diagram original version protocol text italics indicates additional operations accompany transition state described global property associated block local property copy block particular processors cache also notion state associated line local cache plays relatively minor role protocol specifically latter local state indicates whether line invalid readonly readwrite allows us detect initial access processor triggers coherence transaction ie read write invalid line write readonly line additional local data structure maintained protocol processor describes lines invalidated next acquire operation size data structure upper bounded number lines cache need maintain information lines dropped cache nodes protocol processor services requests issued local processor well requests remote processors affect portion directory located node local processor requests one following four read misses write misses lock releases lock acquires uncached shared read write read readers 0 write single reader writers 0 read write notices write send write notices write figure 1 directory state diagram variant lazy release consistency read misses caused processor load instructions access data located processors cache read miss nodes protocol processor allocates outstanding transaction data structure contains line block number causing miss outstanding transaction data structure equivalent rac entry dash distributed directory protocol 16 sends message blocks home node asking data request reaches home node protocol processor issues memory read block starts directory operationreading current state block computing new state soon memory returns requested block protocol processor sends message requesting node containing data new state block block made transition weak state additional message sent current writer 1 worth noting protocol never requires home node forward read request block currently written memory module contains uptodate version written fact read occurred indicates synchronization operation separates write read turn implies correctly synchronized program true sharing occurring recent version block required write misses caused processor store instructions access lines whose local state invalid readonly application processor free continue execution placing write write buffer assuming buffer full protocol processor allocates outstanding transaction data structure sends write request message home node block present processors cache local line state invalid entry write buffer cannot retired blocks data returned home node block readonly processors cache however still need contact home node inform write operation need wait home nodes response retiring write buffer entry important advantage eager implementation release consistency dash stems fact allow block multiple concurrent writers need use home node serializing point choose unique processor writer write request arrives home node home nodes protocol processor consults directory entry decide new state block new state require additional coherence 1 situation block move weak state result read request currently dirty state ie single writer messages ie block uncached cached requesting processor acknowledgment sent requesting processor however block going make transition weak state notification messages must sent sharing processors response sent requesting processor instructing wait collection acknowledgements acknowledgments could directed collected either requesting processor home node would forward single acknowledgement requesting node opted second ap proach lower complexity allows us collect acknowledgments write requests block arrive multiple processors home node keeps track write requests acknowledges received individual acknowledgments sharing proces sors downside collecting acknowledgments home node transition weak state becomes fourhop transaction causes longer delays downside less significant would singlewriter protocol ability retire write buffer entries sending initial message home node reduces probability write eventually stall processor lock releases need make sure writes releasing processor globally performed ie processors copies written blocks informed writes written data made way back main memory ensure stalling processor 1 write buffer flushed 2 outstanding requests serviced ie outstanding request data structures deallocated 3 memory acknowledged outstanding writebacks writethroughs see lock acquires need invalidate acquiring processors cache lines write notices received much latency operation hidden behind latency lock acquisition processor attempts acquire lock protocol processor performs invalidations write notices already received receives message granting ownership lock protocol processor performs invalidations additional notices received intervening time invalidating line involves notifying home node local processor longer caching block way home node update state block directory entry appropriately block longer processors writing reverts shared state processors sharing reverts uncached state block evicted cache due conflict capacity miss home node must also informed one last issue needs addressed mechanism whereby data makes way back main memory multiplewriter protocol writeback cache requires ability merge writes cache block multiple processors assuming false sharing within individual words could achieved including perword dirty bits every cache sending bits every writeback message approach complicates design cache however introduces potentially large delays release operations due cache flush operations writethrough cache solve problem providing word granularity memory updates overlapping memory updates computation programs however writethrough leads unacceptably large amounts traffic delaying cache fills read misses critical operations coalescing fully associative buffer 4 11 placed writethrough cache effectively combine best attributes write strategies provides simple design low release synchronization costs writethrough cache maintaining data traffic levels comparable writeback cache 14 also consider lazier version protocol attempts delay point write notices sent processors protocol nodes protocol processor refrain sending write request blocks home node long possible notification sent either written block replaced processors cache processor performs release operation writes buffered local data structure maintained protocol processor processing writes replaced blocks allows us place upper bound size data structure proportional size processors cache avoid complications directory processing arise process writes processors may longer caching block delaying notices shown improve performance software coherent systems 3 14 hardware implementation however delayed notices take full advantage asynchrony computation coherence management cause significant delays synchronization operations two sources performance benefits two lazy protocols compared eager release consistent protocol implemented dash multiprocessor one ability avoid invalidations hence reduce miss rate using multiple writers tolerate false sharing falsely shared block invalidated synchronization operations rather whenever written less significant source benefits reduced write buffer stall time since write buffer entries retired immediately written block already cached readonly chance write buffer stalls significantly reduced reduced writebuffer stall time secondary effect applications since benefits realized bursty writebehavior negative side release acquire synchronization points expensive processors stall waiting protocol processors complete outstanding read write requests invalidate weak lines evictions clean unwritten cache lines also force coherence messages sent blocks home node secondary effect critical path computation 3 experimental methodology 31 simulation testbed use executiondriven simulation simulate mesh connected multiprocessor 64 nodes simulator consists two parts front end mint 23 24 simulates execution processors back end simulates memory system front end calls back end every data reference instruction fetches assumed always cache hits back end decides processors block waiting memory continue execution since decision made online back end affects timing front end interleaving instructions across processors depends behavior memory system control flow within processor change result timing memory references accurate tracedriven simulation control flow predetermined recorded trace front end experiments implements mips ii instruction set back end quite detailed finitesize caches full protocol emulation distancedependent network delays memory access costs including memory contention simulator capable capturing contention within network substantial cost execution time results reported model network contention sending receiving nodes message nodes inbetween also simplified simulation programmable protocol processor abstracting away details instruction data cache misses may suffer processing protocol requests believe inaccuracy detract conclusions current designs protocol processors incorporate large caches negligible miss rate pathological cases 15 simulations simply charge fixed costs operations one exception write request shared line cost sum directory access dispatch messages sharing processors since cases directory processing hidden behind memory access cost increased directory processing cost lazy protocol affect performance table 1 summarizes default parameters used simulations using parameters ignoring contention effects may seen network memory modules cache fill would incur cost sending request message home node network b waiting memory respond data c sending data back requesting node network satisfying fill nodes local bus assuming distance 10 hops network cost sending request 21 cycles cost memory cycles cost sending data back cycles cost local cache fill via nodes bus 64 aggregate cost cache fill processor cycles system constant name default value cache line size 128 bytes cache size 128 kbytes directmapped memory setup time 20 cycles memory bandwidth 2 bytescycle bus bandwidth 2 bytescycle network bandwidth 2bytescycle bidirectional switch node latency 2 cycles latency 1 cycle write notice processing 4 cycles lrc directory access cost 25 cycles erc directory access cost 15 cycles table 1 default values system parameters 32 application suite report results 7 parallel programs run program largest input size could simulated reasonable amount time provided good loadbalancing 64processor configura tion three programs best described computational kernels gauss fft blu rest complete applications barneshut cholesky locusroute mp3d gauss performs gaussian elimination without pivoting 448 theta 448 matrix fft computes onedimensional fft 65536element array complex numbers using algorithm described akl 1 blu implementation blocked rightlooking lu decomposition algorithm presented 5 448 theta 448 matrix barneshut nbody application simulates evolution 4k bodies influence gravitational forces 4 time steps cholesky performs cholesky factorization sparse matrix using bcsstk15 matrix input locusroute vlsi standard cell router using circuit primary2grin containing 3029 wires mp3d windtunnel airflow simulation 40000 particles steps applications part splash suite 21 due simulation constraints input data sizes programs smaller would run real machine consequence also chosen smaller caches common real machines order capture effect capacity conflict misses experiments larger cache sizes overestimate advantages lazy release consistency eliminating significant fraction misses common eager lazy protocols principal goal determine performance advantage derived hardware systems lazy release consistent protocol end begin section 41 categorizing misses suffered various applications eager release consistency false sharing important part applications miss rate expect lazy protocol realize substantial performance gains continue section 42 comparing performance lazy protocol eager release consistency section 43 evaluates performance implications lazier variant protocol section provides intuition qualitative differences software hardware implementations lazy release consistency section 44 examines impact several architectural parameters relative performance lazy eager protocols shows performance advantage lazy protocols increases hypothetical future machine parameters modified simultaneously keeping technological trends application cold true false eviction write barneshut 69 90 114 629 97 blockedlu 86 247 241 127 298 gauss 75 02 01 75 171 locusroute 61 130 330 156 323 mp3d 31 311 57 135 465 figure 2 classification misses eager release consistency application miss rate eager lazy lazyext barneshut 043 041 040 blockedlu 208 194 145 gauss 272 272 233 locusroute 186 124 102 mp3d 481 378 257 figure 3 miss rates different implementations release consistency 41 application characteristics mentioned section 2 main benefits lazy protocols stem reductions false sharing elimination write buffer stall time data already cached readonly attempt identify extent benefits might realized application programs run set simulations classify misses eager release consistency applications high percentage false sharing frequently write miss readonly blocks provide best candidates performance improvements lazy consistency table 3 presents miss rates applications different protocols cases lazy variants exhibit lower miss rate eager implementation release consistency improvement realized lazy variants stems two factors one reduction false sharing second elimination writemisses false shared blocks table 2 presents classification eager protocols miss rate following components cold misses truesharing misses falsesharing misses eviction misses write misses individual categories presented percentages total number misses classification scheme refinement dubois et al 8 described detail technical report 2 write misses slightly different flavor categories result data transfers since occur block already present cache processor permission seen table applications benefit lazy protocol ie reduce miss ratebarneshut blockedlu locusroute high false sharing component mp3d also benefits although false sharing component pronounced applications still significant overall miss rate much higher remaining applications cholesky fft gauss realize gains miss rate due lazy protocol almost false sharing 42 lazy v eager release consistency section compares lazy release consistency protocol presented section 2 eager release consistency protocol like one implemented dash 17 performance sequentially consistent directorybased protocol also presented comparison purposes relaxed consistency protocols use 4entry write buffer allows reads bypass writes coalesces writes cache line eager protocol uses writeback policy lazy protocol uses writethrough 16entry coalescing buffer placed cache memory system figure 4 presents normalized execution time different protocols application suite execution time normalized respect execution time sequentially consistent protocol unit line graph lazy protocol provides performance advantage expected applications advantage ranging 5 17 application largest performance improvement mp3d mp3d highest overall miss rate false sharing write misses important components barneshuts performance also improves 9 using lazy protocol unlike remaining programs performance benefits derived decrease synchronization wait time closer study reveals decrease stems better handling migratory data lazy protocol eager bhut blu chol fft gauss loc mp3d020610 normalized execution time figure 4 normalized execution time lazy release eagerrelease consistency 64 processors bhut blu chol fft gauss loc mp3d02061014 analysis sync wbstl rdlat figure 5 overhead analysis lazyrelease eagerrelease sequential consistency left right 64 processors blocked lu locusroute suffer false sharing lazy nature protocol allows tolerate much better eager release consistency resulting performance benefits 5 13 respectively gauss hand false sharing migratory data still realizes performance improvements 9 lazy consistency studied program found performance advantage lazy consistency stems elimination 3hop transactions coherence protocol sharing gauss occurs processors attempt access newly produced pivot row dirty state furthermore access tightly synchronized potential generate large amounts contention lazy protocol eliminates need extra hop reduces observed contention thus improving performance cholesky fft small amount false sharing performance changes little lazy protocol fft runs little faster cholesky runs little slower figure 5 presents breakdown aggregate cycles processors four categories cycles spent cpu processing cycles spent waiting read requests return main memory cycles lost due write buffer stalls cycles lost synchronization delays costs category protocol presented percentage total costs experienced sequentially consistent protocol aggregate costs correlate well program execution time though mirror precisely since capture behavior programs critical path results indicate lazy consistency protocol reduces read latency buffer stalls increased synchronization overhead one programs decrease read latency sufficient offset increase synchronization time resulting net performance gains 43 much laziness required unlike basic lazy protocol evaluated far software coherent systems implementing lazy release consistency attempt postpone processing writes shared data combining writes processing synchronization release points aggressive laziness allows unrelated acquire synchronization operations proceed without invalidate cache lines modified releasing processor result programs experience reduced miss rates reduced miss latencies however moving processing write operations release points side effect increasing amount time processor spends waiting release complete software systems usually prob lem since write notices cannot processed parallel computation penalty lazyext bhut blu chol fft gauss loc mp3d020610 normalized execution time figure normalized execution time lazy release lazyextendedrelease consistency 64 processors bhut blu chol fft gauss loc mp3d02061014 analysis sync wbstl rdlat figure 7 overhead analysis lazyrelease lazyextendedrelease sequential consistency left right 64 processors paid regardless processed systems hardware support coherence however coherence overhead associated writes overlapped programs computation long program something productive aggressively lazy protocol effectively eliminates overlap end hurting performance due increased synchronization costs figure 6 shows normalized execution times original lazy protocol lazier variant refer lazier protocol lazyext analysis overheads two versions protocols shown figure 7 previous section normalization done respect run time overheads experienced sequentially consistent protocol one applications lazier version protocol poorer overall performance finding stands contrast previouslyreported results dsm systems 12 explained ability overlap processing nondelayed write notices seen figure 7 lazyext protocol improves miss latency experienced programs increases amount time spent waiting synchronization former insufficient offset latter resulting program performance degradation exception observation fft fft computes 1d fft phases separated barrier delaying processing writes allows home nodes combine processing write requests block since requests arrive moreorless simultaneously time barrier increase synchronization time processors experience shorter delays barriers since events barriers local observed miss rate applications also agrees observed miss latency lowest lazyext protocol 44 impact technological advances three major architectural parameters affect performance cache coherence protocols latency bandwidth cache line size define latency startup time request wait first word produced memory bandwidth represents number bytes transferred memory interconnects wires across local bus one processor cycle balanced system components devoted given data transfer approximately equal bandwidths chosen four applications three significant false sharing component one without enjoyed substantial performance improvements lazy consistency plotted run time different protocols function systems latency bandwidth plots appear figures 8 normalized execution time memory latency cycles barneseager barneslazyext barneslazy gausseager gausslazyext gausslazy060811214 normalized execution time memory latency cycles locuseager locuslazyext locuslazy mp3deager mp3dlazyext mp3dlazy figure 8 normalized execution time different memory latencies040608112 normalized execution time network bandwidth bitscycle barneseager barneslazyext barneslazy gausseager gausslazyext normalized execution time network bandwidth bitscycle locuseager locuslazyext locuslazy mp3deager mp3dlazyext mp3dlazy figure 9 normalized execution time different system bandwidths 9 run time normalized respect execution time sequentially consistent protocol increasing memory startup cost seen narrow performance gap two different lazy protocols increasing memory startup cost increases cost cache miss thereby increasing importance miss rate reductions experienced lazier protocol increased miss cost still enough offset additional synchronization costs lazyext protocol however even highest latency value simulations performance gap eager lazy protocols also narrows latency bandwidth increases increased latency negatively affects writethrough strategy lazy protocols since writethrough operations take longer complete increasing bandwidth allows coherence operations cache fills complete faster reduces relative impact coherence overall program performance within range parameters studied however basic lazy protocol maintains consistent performance advantage eager lazyext protocols varying cache line size yielded several unexpected results barneshut achieves best performance smallest line size studied 32 bytes blocks small different protocols almost identical normalized execution time cache line size bytes barneseager barneslazyext barneslazy gausseager gausslazyext gausslazy081216 normalized execution time cache line size bytes locuseager locuslazyext locuslazy mp3deager mp3dlazyext mp3dlazy figure 10 normalized execution time different cache line sizes run times line size increases false sharing becomes issue lazy protocols outperform eager alternative much 15 gauss achieves best performance 128byte blocks performance gap eager lazy protocols increases increase block size unlike barneshut however gauss suffer false sharing advantage lazy protocols stems ability better utilize writemerge buffer longer lines imply data held buffer without contacting memory result less main memory traffic overall program performance improves locusroute favors different line sizes depending protocol used eager release consistency achieves best performance 32byte lines basic lazy protocol favors 64byte lines contrast results barneshut gauss performance gap protocols locusroute pronounced smaller block sizes reason eviction misses increase block size increases large blocks eviction misses become important factor run times lazy eager protocols converge finally mp3d achieves best performance 64byte blocks eager protocol 128byte blocks lazy protocols expected behavior since particle data structures 64 bytes length 2 however interesting note lazyext protocol suffers severe performance degradation small block sizes high degree sharing application results large number transactions synchronization release points increasing synchronization costs protocol dramatically performance results different protocols function block size appear figure 10 far varied architectural parameters individually order examine effect relative performance eager lazy release consistency future machines however many parameters likely change therefore hypothesize future multiprocessor following characteristics cache line size 256 bytes memory startup latency 40 cycles bandwidth 32 bits per cycle assumptions agreement current technological trends show dramatic improvements processor speed application code much modest improvements memory access times maintained overall cache size system 128 kbytes per processor large enough hold working set processor large enough hide effects capacity conflict misses figures 11 12 show normalized execution times overhead breakdowns three different protocols hypothetical machine lazy release consistency seen outperform eager alternative applications applications lazy release consistency important earlier experiments 2 actually 36 bytes padded 64 reduce false sharing performance gap increased even mp3d performance gap widened additional 6 original experiment lazy consistency outperforms eager variant 23 similar gains achieved applications well performance gap lazy eager release consistency increased 2 4 percentage points compared performance difference seen original experiments observations made earlier overhead breakdown graphs continue apply lazy protocols trade increased synchronization time decreased read latency write buffer stall time additional advantage laziness future machine stems increases cache line size memory startup latency measured processor cycles longer lines increase potential false sharing increased memory startup costs increase cost servicing read misses trend toward increasing block sizes unlikely go forever future improvements compiler technology serve reduce amount false sharing seen particular block size parameters hypothetical machine seem plausible nearterm future however suggest lazy protocols become increasingly important moreover even applications without significant false sharing lazy release consistency provides least good performance eager release consistency making preferable protocol regardless sharing patterns exhibited application lazy lazyext eager bhut blu chol fft gauss loc mp3d020610 normalized execution time figure performance trends lazy lazier eager release consistency execution time bhut blu chol fft gauss loc mp3d02061014 analysis sync wbstl rdlat figure 12 performance trends lazy lazier eager release consistency overhead analysis 5 related work work builds research programmable protocol processors pioneered stanford flash 15 wisconsin typhoon 20 projects comparison silicon implementations dedicated programmable protocol processors offer opportunity obtain significant performance improvements appreciable increase hardware cost algorithmic side work bears resemblance number systems provide shared memory coherence software using variant lazy release consistency munin 25 collects write notices processor posts processor reaches synchronization release point paranet tread marks 13 relaxes munin protocol postponing posting write notices subsequent acquire munin paranet designed run networks workstations hardware support coherence petersen li 19 presented lazy release consistent protocol small scale multiprocessors caches without cache coherence approach posts notices eagerly using centralized list weak pages processes notices synchronization acquire points protocol presented paper closely related protocol developed software coherence largescale numa multiprocessors 14 protocols use concept write notices distributed directory unlike software protocol however one presented works better postpone posting notices also modified execute coherence operations application code parallel deal fact processor lose block due capacity conflict evictions work also similar delayed consistency protocol invalidation scheduling work dubois et al 7 8 protocols attempt reduce impact false sharing applications work however assumes single owner requires processor obtain new copy write hits stale block 3 protocol incurs longer delays write accesses falselyshared blocks increases applications miss rate experiments also assume infinite caches exaggerate importance coherence misses use miss rate measure performance shown section 43 miss rate indicative program performance sometimes misleading excessively lazy protocols actually hurt performance even though improve applications miss rate false sharing dealt software using compiler techniques 9 22 similarly latency write misses blocks already cached readonly reduced compiler requests writable copies appropriate citeskeppstedtasplos1994 techniques always successful however former must also tuned architectures block size latter requires loadexclusive instruction view protocol complementary work compiler would compiler successful protocol incur little additional overhead eager release consistency however application still suffers false sharing significant number writeafterread delays lazy release consistency yield significant performance improvements 6 conclusions shown adopting lazy consistency protocol hardware coherent multiprocessors provide substantial performance gains eager alternative variety applications systems programmable protocol processors lazy protocol requires minimal additional hardware cost basically storage space respect eager release consistency introduced two variants lazy release consistency shown hardware based systems delaying coherence transactions helps point delaying invalidations synchronization acquire point almost always beneficial delaying posting write notices synchronization release point tends move background coherence operations critical path application resulting unacceptable synchronization overhead also conducted experiments attempt evaluate importance lazy release consistency future architectures find miss latencies cache line sizes increase performance gap lazy eager release consistency increases well currently investigating interaction lazy hardware consistency software techniques reduce amount false sharing applications program locality increases performance advantage lazy protocols decrease direct result decrease coherence transactions required results indicate however lazy protocols improve application performance even absence false sharing eg replacing 3hop transactions 2 hop transactions gauss eliminating writebuffer stalls due writeafterread operations barneshut moreover since parallel applications favor small cache lines current architectural trend towards longer lines believe lazy consistency provide significant performance gains eager release consistency foreseeable future acknowledgements would like thank jack veenstra help support work 3 stale blocks similar weak blocks protocol r design analysis parallel algorithms algorithms categorizing multiprocessor communication invalidate updatebased coherence protocols implementation performance munin effective write policy software coherence schemes parallel block matrix factorizations sharedmemory multiprocessor ibm 3090 vf600j delayed consistency effect miss rate parallel programs detection elimination useless misses multiprocessors eliminating false sharing memory consistency event ordering scalable sharedmemory multiprocessors cache write policies performance lazy release consistency software distributed shared memory paranet distributed shared memory standard workstations operating systems software cache coherence large scale multiprocessors flash multiprocessor directorybased cache coherence protocol dash multiprocessor stanford dash multiprocessor memory consistency models cache coherence shared memory multiprocessors based virtual memory support tempest typhoon userlevel sharedmemory splash stanford parallel applications sharedmemory false sharing spatial locality multiprocessor caches mint tutorial user manual front end efficient simulation sharedmemory multi processors munin distributed shared memory using multiprotocol release consistency tr synchronization coherence event ordering multiprocessors implementation performance munin delayed consistency effects miss rate parallel programs stanford dash multiprocessor lazy release consistency software distributed shared memory detection elimination useless misses multiprocessors cache write policies performance stanford flash multiprocessor tempest typhoon simple compiler algorithms reduce ownership overhead cache coherence protocols memory consistency event ordering scalable sharedmemory multiprocessors directorybased cache coherence protocol dash multiprocessor unified formalization four sharedmemory models mint software cache coherence large scale multiprocessors algorithms categorizing multiprocessor communication invalidate updatebased coherence protocols high bandwidth latency justify large cache blocks scalable multiprocessors ctr leonidas kontothanassis michael l scott efficient shared memory minimal hardware support acm sigarch computer architecture news v23 n4 p2935 sept 1995 angelos bilas jaswinder pal singh effects communication parameters end performance shared virtual memory clusters proceedings 1997 acmieee conference supercomputing cdrom p135 november 1521 1997 san jose ca lance hammond brian carlstrom vicky wong ben hertzberg mike chen christos kozyrakis kunle olukotun programming transactional coherence consistency tcc acm sigops operating systems review v38 n5 december 2004 weisong shi weiwu hu zhimin tang interaction coherence protocols memory consistency models dsm systems acm sigops operating systems review v31 n4 p4154 oct 1997 angelos bilas dongming jiang jaswinder pal singh accelerating shared virtual memory via generalpurpose network interface support acm transactions computer systems tocs v19 n1 p135 feb 2001