recent advances direct methods solving unsymmetric sparse systems linear equations past years algorithmic improvements alone reduced time required direct solution unsymmetric sparse systems linear equations almost order magnitude paper compares performance wellknown software packages solving general sparse systems particular demonstrates consistently high level performance achieved wsmpthe recent solvers compares various algorithmic components solvers discusses impact solver performance experiments show algorithmic choices made wsmp enable run twice fast best among similar solvers wsmp factor largest sparse matrices available real applications seconds 4cpu workstation thus combination advances hardware algorithms makes possible solve general sparse linear systems quickly easily might considered large recently b introduction developing efficient parallel even serial direct solver general unsymmetric sparse systems linear equations challenging task subject research past four decades several breakthroughs made time result number serial parallel software packages solving systems available amestoy et al 2000 ashcraft grimes 1999 davis duff 1997b grund 1998 gupta 2000 li demmel 1999 shen et al 2001 schenk et al 2000 paper compare performance main algorithmic features prominent software packages solving general sparse systems show algorithmic improvements past years reduced time required factor general sparse matrices almost order magnitude combined significant advances performance cost ratio parallel computing hard authors address anshul gupta ibm j watson research center p box 218 yorktown heights ny 10598 permission make digitalhard copy part material without fee personal classroom use provided copies made distributed profit commercial advantage acm copyrightserver notice title publication date appear notice given copying permission acm inc copy otherwise republish post servers redistribute lists requires prior specific permission andor fee c acm transactions mathematical software vol 28 3 september 2002 pages 301324 ware period current sparse solver technology makes possible solve problems quickly easily might considered impractically large recently demonstrate consistently high level performance achieved watson sparse matrix package wsmp show factor largest sparse matrices available real applications seconds 4cpu workstation key features wsmp contribute performance include prepermutation rows place large entries diago nal symmetric fillreducing permutation based nested dissection ordering algorithm unsymmetricpattern multifrontal factorization guided nearminimal static task datadependency graphs uses symmetric inter supernode threshold pivoting gupta 2001b techniques unsymmetric pattern multifrontal algorithm based static nearminimal dags new others used past though combination single sparse solver paper discuss impact various algorithmic components sparse general solvers performance particular emphasis contribution components analysis numerical factorization phases wsmp performance paper organized follows section 2 compare serial time prominent general sparse solvers spend factoring sparse matrix triangular factors l uthe important phase solution sparse system linear equationsand discuss relative robustness speed solvers uniform realistic test conditions section 3 list main algorithms strategies packages use symbolic numerical phases discuss effect strategies respective per formance section 4 means experimental comparisons highlight role various algorithms used wsmp play performance lu factorization section 5 present detailed performance comparison practical setting wsmp mumpsthe general purpose sparse solver show section 2 best available time wsmps release section 6 contains concluding remarks 2 serial performance general sparse solvers section compare performance wellknown software packages solving sparse systems linear equations single cpu ibm rs6000 model s80 600 mhz processor 64 kb 2way setassociative level1 cache peak theoretical speed 1200 megaflops representative performance typical highend workstation available 1999 table 2 lists test matrices used paper largest publicly available unsymmetric sparse matrices real applications table also includes dimension number nonzeros application area origin matrices sparse solvers compared section umfpack version 22 davis duff 1997b 1997a superlumt demmel et al 1999 spooles ashcraft grimes 1999 superlu dist li demmel 1998 1999 mumps 416 amestoy et al 2001 amestoy et al 2000 wsmp gupta 2000 umfpack version 32 davis 2002 solver suite contains two versions superlu umf recent advances solution general sparse linear systems delta 303 table test matrices order n number nonzeros nnz application area origin matrix n nnz application av41092 41092 1683902 finite element analysis bbmat 38744 1771722 fluid dynamics programming e40r0000 17281 553956 fluid dynamics e40r5000 17281 553956 fluid dynamics simulation fidap011 16614 1091362 fluid dynamics fidapm11 22294 623554 fluid dynamics lhr34c 35152 764014 chemical engineering mil053 530238 3715330 structural engineering mixtank 29957 1995041 fluid dynamics nasasrb 54870 2677324 structural engineering onetone1 36057 341088 circuit simulation onetone2 36057 227628 circuit simulation pre2 659033 5959282 circuit simulation raefsky3 21200 1488768 fluid dynamics raefsky4 19779 1316789 fluid dynamics simulation twotone 120750 1224224 circuit simulation venkat50 62424 1717792 fluid dynamics wang3old 26064 177168 circuit simulation wang4 26068 177196 circuit simulation pack versions employ different algorithms important phases solution process see section 3 details wellknown packages featured section however comparisons one packages included easily available literature would alter inferences drawn results section davis duff compare umfpack mups amestoy duff 1989 ma48 duff reid 1993 mups classical multifrontal code predecessor mumps ma48 sparse unsymmetric factorization code hsl package hsl 2000 based conventional sparse data structures grund grund 1998 presents experimental comparison gspar grund 1998 solvers including superlu umfpack however comparison limited sparse matrices arising two specific applications ma41 amestoy duff 1989 1993 commercial sharedmemory parallel version mups available hsl since 1990 amestoy puglisi amestoy puglisi 2000 since introduced unsymmetrization frontal matrices ma41 since mumps robust parallel ma41 chosen use mumps instead ma41 comparison package shen et al 2001 university california santa barbara others found cosnard grigori 2000 gupta muliadi 2001 shen et al 2001 acm transactions mathematical software vol 28 3 september 2002 table ii lu factorization times single cpu seconds umfpack version 22 dist mumps wsmp umfpack version 32 respec tively best pre2000 time underlined overall best time shown boldface last row shows approximate smallest pivoting threshold yielded residual norm close machine precision iterative refinement package fm indicates solver ran memory fc indicates abnormal termination fn indicates numerical results inaccurate matrices umfp 2 slumt spls slu dist mumps wsmp umfp 3 bbmat 682 373 977 256 723 371 123 comp2c 120 111 287 420 235 445 802 e40r5000 299 178 395 fn 118 110 710 ecl32 fm 961 562 201 116 377 320 fidap011 168 fm 122 fn 127 653 226 fidapm11 944 145 151 fn 163 104 632 lhr34c 346 fm fm 115 353 132 581 mixtank fm fm 346 198 867 365 695 nasasrb 818 fm 250 267 220 110 761 onetone1 122 272 113 107 579 352 733 pre2 fm fc fm fm fm 223 fm raefsky3 390 342 100 686 609 504 204 raefsky4 109 fm 157 286 285 793 362 twotone 300 fm 724 637 794 266 465 venkat50 162 336 116 811 870 439 143 wang3old 106 281 627 369 253 107 637 wang4 973 223 162 237 186 109 852 excluded another recent software pardiso schenk et al 2000 designed unsymmetric matrices symmetric structure therefore would failed many test matrices unless padded zero valued entries structurally symmetrize package compiled 32bit mode o3 optimization option aix fortran c compilers linked ibms engineering scientific subroutine library essl basic linear algebra subprograms blas optimized rs6000 processors almost floating point operations solver performed inside blas routines using compiler blas library affords code equal access hardware specific optimiza tions maximum 2 gb memory available code table 2 shows lu factorization time taken code matrices test suite addition solvers factorization time table also lists year latest version package became available fm recent advances solution general sparse linear systems delta 305 fc fn entries indicate failure solver factor matrix satisfactorily subscripts c n indicate failure due running memory abnormal termination numerically inaccurate results respectively one ground rules experiments reported table 2 input parameters may influence behavior program fixed modified accommodate demands individual matrices however series preexperiments attempted fix parameters values yielded best results average target machine example tested packages matrices test suite various values pivoting threshold pthresh chose smallest value completed runs yielded backward error close machine precision iterative refinement messagepassing version superlu superlu dist provision partial pivoting hence threshold 0 parameters easily accessible software various block sizes superlu also fixed values appeared best average note failures first four columns table 2 fixed changing options parameters code however noted options chosen run experiments reported table 2 best test suite whole changing options may avoid failures cause many chosen report results consistent set options believe representative realworld environment solvers expected used moreover cases even alternative set options exists solve failed cases reported table 2 options known apriori determined trial error memory allocation failures however result static memory allocation data structures variable unknown sizes therefore failures artifacts implementation neither reflect actual amount memory needed allocated properly underlying algorithms robust best factorization time matrix using solver released year 2000 underlined table 2 overall best factorization time shown boldface several interesting observations made table 2 perhaps striking observation table pertains range times different packages available 1999 would take factor matrix uncommon notice fastest solver faster slowest one two orders magnitude additionally none pre1999 solvers yielded consistent level performance example umfpack 22 13 times faster spooles e40r5000 14 times slower fidap011 also noticeable marked increase reliability ease use softwares released 1999 later 21 failures first four columns table 2 two last three columns mumps clearly fastest robust amongst solvers released 2000 however wsmp twice fast mumps machine based average ratio factorization time mumps wsmp wsmp also consistent performance smallest factorization time two matrices solver fail test matrices 306 delta anshul gupta 3 key algorithmic features solvers section list key algorithms strategies solvers listed table use symbolic numerical phases computation lu factors general sparse matrix briefly discuss effect choices performance solvers detailed descriptions algorithms beyond scope paper readily available citations provided many solvers whose singlecpu performance compared table 2 designed shared distributedmemory parallel computers target architecture solvers also listed 1 umfpack 22 davis duff 1997b 1997a fill reducing ordering approximate minimum degree amestoy et al 1996 unsymmetric structure combined suitable numerical pivot search lu factorization task dependency directed acyclic graph numerical factorization unsymmetricpattern multifrontal pivoting strategy threshold pivoting implemented rowexchanges target architecture serial 2 superlumt demmel et al 1999 fill reducing ordering multiple minimum degree mmd george liu 1981 computed symmetric structure applied columns structure used experiments table 2 task dependency directed acyclic graph numerical factorization supernodal leftlooking pivoting strategy threshold pivoting implemented rowexchanges target architecture sharedmemory parallel 3 spooles ashcraft grimes 1999 fill reducing ordering generalized nested dissectionmultisection ashcraft liu 1996 computed symmetric structure applied symmetrically rows columns task dependency tree based structure numerical factorization supernodal crout pivoting strategy threshold rook pivoting performs row column exchanges control growth l u target architecture serial sharedmemory parallel distributedmemory parallel dist li demmel 1998 1999 fill reducing ordering multiple minimum degree george liu 1981 computed symmetric structure aa applied symmetrically rows columns task dependency directed acyclic graph numerical factorization supernodal rightlooking pivoting strategy numerical pivoting factorization rows preordered maximize magnitude product diagonal entries duff koster 1999 2001 recent advances solution general sparse linear systems delta 307 target architecture distributedmemory parallel 5 mumps amestoy et al 2001 amestoy et al 2000 fill reducing ordering approximate minimum degree amestoy et al 1996 computed symmetric structure aa applied symmetrically rows columns task dependency tree based structure numerical factorization symmetricpattern multifrontal pivoting strategy preordering rows maximize magnitude product diagonal entries duff koster 1999 2001 followed unsymmetric row exchanges within supernodes symmetric row column exchanges supernodes target architecture distributedmemory parallel fill reducing ordering nested dissection gupta 1997 computed symmetric structure applied symmetrically rows columns task dependency minimal directed acyclic graph gupta 2001b numerical factorization unsymmetricpattern multifrontal pivoting strategy preordering rows maximize magnitude product diagonal entries gupta ying 1999 followed unsymmetric partial pivoting within supernodes symmetric pivoting supern odes rook pivoting attempts contain growth l u option target architecture sharedmemory parallel fill reducing ordering column approximate minimum degree algorithm davis et al 2000 compute fillreducing column preordering task dependency tree based structure numerical factorization unsymmetricpattern multifrontal pivoting strategy threshold pivoting implemented rowexchanges target architecture serial performance solvers calibrated table 2 greatly affected algorithmic features outlined briefly describe order importance relationship algorithms performance characteristics solvers employ algorithms 31 pivoting strategy application fillreducing ordering application fillreducing permutation pivoting strategy used different solvers seem important factors distinguish mumps wsmp others allows two deliver consistently good performance 311 conventional strategy george ng 1985 george ng showed fillin result lu factorization irreducible square unsymmetric sparse matrix irrespective row permutation subset acm transactions mathematical software vol 28 3 september 2002 fillin symmetric factorization would generate guided sult many unsymmetric sparse solvers developed 1990s adopted variations following ordering pivoting strategy ordering algorithm would seek compute fillreducing permutation columns based sparsity pattern column permutation equivalent symmetric permutation numerical factorization phase solvers would seek limit pivot growth via threshold pivoting involving row interchanges problem strategy upperbound fill lu factorization predicted gilbert ngs result loose especially presence even one relatively dense row result initial column ordering could ineffective moreover two different column orderings equally effective reducing fill symmetric factorization could enjoy different degrees success reducing fill lu factorization evidence factor extreme variations factorization times different solvers matrices table 2 matrices symmetric structure require little pivoting nasasrb raefsky3 rma10 venkat50 wang4 exhibit relatively less variation factorization times different solvers hand consider performance wsmp umfpack 32 matrices comp2c tib contain rows much denser rest wsmp umfpack 32 use similar unsymmetricpattern multifrontal factorization algorithms however since column ordering umfpack 32 seeks minimize fill symmetric factorization rather directly lu factorization two orders magnitude slower wsmp matrices experiments section 5 verified wsmp enjoy dramatic advantage umfpack 32 matrices due differences use nesteddissection ordering prepermutation matrix rows 312 strategy used mumps wsmp briefly describe ordering pivoting strategy mumps wsmp context structurally symmetric matrix note pivoting mumps would similar even case unsymmetric matrix uses symmetricpattern multifrontal algorithm guided elimination tree liu 1990 corresponding symmetric structure hand wsmp uses unsymmetricpattern multifrontal algorithm elimination dag directed acyclic graph guide factorization therefore pivoting somewhat complex matrix factored unsymmetric structure however basic pivoting idea reason effective remain mumps wsmp start symmetric fillreducing permutation computed structure aa like modern sparse factorization codes mumps wsmp work supernodesadjacent groups rows columns nearly structures factors l u interchange amongst rows columns supernode effect overall fillin preferred mechanism finding suitable pivot however guarantee algorithm would always succeed finding suitable pivot within pivot block element whose row well column index lies within indices supernode currently factored algorithm acm transactions mathematical software vol 28 3 september 2002 recent advances solution general sparse linear systems delta 309 reaches point cannot factor entire supernode based prescribed threshold merges remaining rows columns supernode parent supernode elimination tree equivalent symmetric permutation failed rows columns location higher indices within matrix virtue properties elimination tree liu 1990 new location failed rows columns also happens next best location perspective potential fillin rows columns would produce example context fillreducing ordering based nested dissection george liu 1978 lipton et al 1979 graph coefficient matrix pivoting strategy equivalent moving vertex corresponding failed pivot partition immediate separator created partition merged parent supernode unsuccessful portion child supernode rows columns available potential interchange however part new supernode remain unfactored due lack suitable intrasupernode pivots merged parent supernode key point strategy pivot failures increase fillin gracefully rather arbitrarily moreover fewer intersupernode pivoting steps closer final fillin stays original fillreducing ordering although unlike conventional strategy proven upperbound amount fillin potentially generated empirical evidence clearly suggests extra fillin due pivoting stays reasonably wellcontained aid strategy shown recently amestoy et al 2001 duff koster 1999 li demmel 1998 permuting rows columns matrix prior factorization maximize magnitude diagonal entries often effective reducing amount pivoting factorization mumps wsmp use technique reduce intersupernode pivoting resulting extra fillin like mumps wsmp spooles uses symmetric fillreducing permutation followed symmetric intersupernode pivoting however spooles employs pivoting algorithm known rook pivoting seeks limit pivot growth l u spooles solvers discussed paper pivot considered suitable long smaller magnitude pivot threshold times entry largest magnitude column pivoting algorithm thus seeks control pivot growth l stringent pivot suitability criterion spooles causes large number pivot failures resulting fillin overshadows good initial ordering simple threshold partial pivoting yields sufficiently accurate factorization matrices including test cases therefore rook pivoting option wsmp default standard threshold pivoting 32 ordering algorithms addition decision whether compute fillreducing symmetric ordering column ordering actual ordering algorithm affects performance solvers wsmp uses nested dissection based multilevel partitioning scheme similar metis karypis kumar 1999 explained gupta 1997 wsmps ordering scheme adds heuristics acm transactions mathematical software vol 28 3 september 2002 basic multilevel approach make robust unstructured prob lems spooles uses similar ordering generates multisections graphs instead bisections ashcraft liu 1996 section 4 paper amestoy et al 2001 present empirical evidence graphpartioning based orderings used spooles wsmp generally effective reducing fillin operation count factorization local heuristics multiple minimum degree mmd liu 1985 used superlumt superlu dist approximate minimum degree amd amestoy et al 1996 used mumps variation amd used umfpack 22 column approximate minimum degree colamd davis et al 2000 algorithm used umfpack 32 solvers ordering separate phase users override default ordering provide permutation vectors ordering phase umfpack 22 wsmp perform another manipulation sparse coefficient matrix prior performing symbolic numerical processing seek reduce block triangular form duff et al 1990 achieved efficiently tarjan 1972 solving original system requires analyzing factoring diagonal block matrices symbolic algorithms employed wsmp gupta 2001b valid irreducible sparse matrices cost reduction block triangular form insignificant offer potentially large savings effective test suite however lhr34c matrix benefits significantly reduction block triangular form others either one block size largest block fairly close dimension overall coefficient matrix 33 symbolic factorization algorithms process factoring sparse matrix expressed directed acyclic task dependency graph taskdag short vertices dag correspond tasks factoring rowcolumn pairs groups rowcolumn pairs sparse matrix edges correspond dependencies tasks task ready execution tasks incoming edges completed addition taskdag datadependency graph data dag associated sparse matrix factorization vertex set datadag taskdag given sparse matrix edge vertex vertex j datadag denotes least data produced result output task required input task j taskdag unique given sparse matrix datadag function sparse factorization algorithm multifrontal algorithms duff reid 1984 liu 1992 davis duff 1997b sparse factorization work minimal datadag ie datadag smallest possible number edges given matrix task datadependency graph involved factorization symmetric matrix tree known elimination tree liu 1990 however unsymmetric matrices task datadags general directed acyclic graphs moreover edgeset minimal datadag unsymmetric sparse factorization superset edgeset taskdag gilbert liu 1993 gilbert describe elimination structures unsymmetric sparse lu factors give acm transactions mathematical software vol 28 3 september 2002 recent advances solution general sparse linear systems delta 311 algorithm sparse unsymmetric symbolic factorization elimination structures two directed acyclic graphs dags transitive reductions graphs factor matrices l u respectively union two directed acyclic graphs minimal taskdependency graph sparse lu factorization taskdependency graph edges necessary using minimal elimination structure guide factorization useful avoids overheads due redundancy exposes maximum parallelism however researchers argued computing exact transitive reduction expensive davis duff 1997b eisenstat liu 1993 proposed using subminimal dags edges necessary traversing pruning redundant edges elimination structure numerical factorizations done umfpack superlumt source overhead alternatively many unsymmetric factorization codes spooles mumps adopt elimination tree corresponding symmetric structure task datadependency graph guide factorization adds artificial dependencies elimination structure lead diminished parallelism extra fillin operations factorization wsmp uses modified version classical unsymmetric symbolic factorization algorithm gilbert liu 1993 detects supernodes processes rows columns sparse matrix enables fast computation exact transitive reductions structures l u yield minimal task dependency graph gupta 2001b addition wsmp uses fast algorithm derivation nearminimal datadependency dag minimal task dependency dag datadependency graph wsmp valid presence amount intersupernode pivoting yet empirically shown contain 0 14 4 average edges minimal taskdependency graph suite large unsymmetric sparse matrices edgeset static datadag sufficient capture possible dependencies may result row column permutations due numerical pivoting factorization powerful symbolic algorithms used wsmp enable numerical factorization phase proceed efficiently spending minimal time nonfloatingpoint operations 34 numerical factorization algorithms multifrontal method duff reid 1984 liu 1992 solving sparse systems linear equations usually offers significant performance advantage conventional factorization schemes permitting efficient utilization parallelism memory hierarchy detailed experiments gupta muliadi 2001 show three multifrontal solversumfpack mumps wsmprun much higher megaflops rate nonmultifrontal counterparts original multifrontal algorithm proposed duff reid duff reid 1984 uses symmetricpattern aa generate elimination tree guide numerical works symmetric frontal matrices symmetricpattern multifrontal algorithm used mumps incur substantial overhead unsymmetric matrices due unnecessary dependencies elimination tree extra zeros artificially symmetrized frontal matrices davis duff davis duff 1997b hadfield hadfield 1994 introduced unsymmetricpattern acm transactions mathematical software vol 28 3 september 2002 multifrontal algorithm used umfpack overcomes shortcomings symmetricpattern multifrontal algorithm however umfpack reveal full potential unsymmetricpattern multifrontal algorithm umfpack 22 used degree approximation algorithm similar amd amestoy et al 1996 fillreducing ordering algorithm shown less effective nested dissection amestoy et al 2001 moreover merging ordering symbolic factorization within numerical factorization umfpack 22 slows latter excludes possibility using better ordering retaining factorization code umfpack 32 separates analysis ordering symbolic factorization numerical factorization however discussed section 31 suffers pitfalls permuting columns based fillreducing ordering rather using symmetric fillreducing permutation unsymmetricpattern multifrontal lu factorization wsmp described detail gupta 2001b aided powerful algorithms analysis phase uses efficient dynamic data structures perform potentially multiple steps numerical factorization minimum overhead maximum parallelism uses technique similar one described hadfield 1994 efficiently handle amount pivoting different pivot sequences without repeating symbolic phase factorization gupta 2001b author defines nearminimal static task datadependency dags computed symbolic factorization describes unsymmetricpattern multifrontal factorization algorithm based dags shown gupta 2001b important property dags even though static handle arbitrary amount dynamic pivoting guarantee numerical stability unsymmetric multifrontal solvers hadfield 1994 davis duff 1997a 1997b task datadags computed fly numerical factorization use static precomputed dags contributes significantly simplification efficiency wsmps numerical factorization furthermore resulting unsymmetricpattern multifrontal algorithm also amenable efficient par allelization description wsmps sharedmemory parallel lu factorization algorithm found gupta 2001a 4 role wsmp algorithms lu factorization performance speed robustness wsmps sparse lu factorization stems 1 overall ordering pivoting strategy 2 unsymmetricpattern multifrontal numerical factorization algorithm guided static nearminimal task datadependency dags 3 use nesteddissection ordering 4 permutation highmagnitude coefficients diagonal section 3 presented arguments based empirical data symmetric fillreducing ordering followed symmetric intersupernode pivoting major feature distinguishing mumps wsmp sparse unsymmetric solvers role strategy plays performance sparse lu factorization evident results table 2 section present results targeted experiments mumps wsmp highlight role one three key algorithmic features wsmp lu factorization performance experiments described section conducted one four pro recent advances solution general sparse linear systems delta 313 table iii number factor nonzeros nnz f operation count ops lu factorization time speedup mumps wsmp run one processors default options mumps wsmp matrices nnz f ops af23560 834 256 405 227 18 958 327 396 183 22 bbmat 460 414 480 207 23 319 201 229 826 28 comp2c 705 422 102 733 13 298 078 164 067 24 e40r0000 172 172 083 061 13 206 250 056 028 20 fidap011 125 701 873 764 11 869 320 393 178 22 fidapm11 140 967 116 738 16 128 521 650 260 25 lhr34c 558 641 221 115 19 291 163 092 093 10 mil053 759 318 428 166 25 589 144 230 106 22 mixtank 385 644 648 310 21 232 195 219 832 26 nasasrb 242 945 131 102 13 189 541 698 337 21 onetone2 226 510 117 082 14 141 191 072 070 10 pre2 358 fail fail fail 792 963 127 553 23 raefsky3 844 290 456 345 13 809 257 316 140 23 raefsky4 157 109 130 897 14 103 411 491 234 21 twotone 221 293 435 261 16 108 946 135 905 15 venkat50 120 231 487 274 18 114 175 283 113 25 wang3old 138 138 151 648 23 966 591 665 350 19 wang4 116 105 118 584 20 993 609 684 308 22 cessors ibm rs6000 wh2 four 375 mhz power 3 processors peak theoretical speed 15 gigaflops peak theoretical speed workstation therefore 6 gigaflops representative performance highend workstation available 2001 four cpus workstation share 8 mb level2 cache 64 kb level1 cache 2 gb memory available single cpu run 4cpu runs wsmp mumps run 4 processors total 4 gb memory available mumps uses messagepassing paradigm mpi processes parallelism distributedmemory parallel environment mumps originally designed may add constraints overheads example numerical pivoting generally easier handle sharedmemory parallel environment distributedmemory one however mumps run mode mpi aware took advantage fact multiple processes running machine setting mp shared memory environment variable yes current version wsmp designed sharedaddressspace paradigm uses pthreads library wang3old bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wang4 fig 1 ratios factorization time mumps wsmp default options graph reflects relative factorization performance two softwares users likely observe applications give serial parallel sparse lu factorization performance mumps wsmp including fillin operation count statistics table 4 figure 1 shows bar graphs corresponding factorization time mumps normalized respect factorization time wsmp matrix relative performance wsmp improves power 3 machine able extract higher megaflops rate wsmp factorization average 23 times faster mumps single cpu 28 times faster four cpus recent advances solution general sparse linear systems delta 315 relative performance sparse lu factorization mumps wsmp shown table 4 figure 1 corresponds users likely observe applications however factorization times affected preprocessing matrices different mumps wsmp wsmp always uses row permutation maximize product magnitudes diagonal entries matrix mumps use row permutation matrices whose nonzero pattern significant symmetry avoid destroying structural symmetry additionaly wsmp uses nested dissection based fillreducing order ing whereas mumps uses approximate minimum degree amd amestoy et al 1996 algorithm order eliminate impact differences lu factorization performance ran wsmp amd ordering selective row permutation logic similar mumps figure 2 compares relative serial parallel factorization performance mumps modified version wsmp although matri ces ratio mumps factor time wsmp factor time decreases overall averages remain less due significant increase ratio matrix twotone since codes run similar preprocessing use blas libraries floating point operations factorization process would fair say figure 2 captures advantage wsmps unsymmetricpattern multifrontal algorithm mumps symmetricpattern multifrontal algorithm sparse factorization algorithm one minor difference way mumps wsmp used collect performance data figure 2 wsmp attempts decomposition blocktriangular form mumps doesnt however lhr34c play significant role determining factorization performance matrices test suite amestoy puglisi amestoy puglisi 2000 present mechanism reduce symmetrization overhead conventional treeguided multifrontal algorithm used mumps incorporated mumps mechanism may reduce performance gap mumps wsmp matrices next look role algorithm used compute fillreducing ordering structure figure 3 compares lu factorization times wsmp amd nested dissection ordering bars show factorization time amd ordering normalized respect unit factorization time nesteddissection ordering matrix whole factorization amd ordering roughly one half times slower factorization wsmps nesteddissection ordering finally observe impact row permutation maximize product diagonal magnitudes duff koster 2001 gupta ying 1999 factorization performance wsmp figure 4 shows factorization times wsmp row permutation switched normalized respect factorization times default mode row permutation active figure shows factorization 40 matrices unaffected row permutation option matrices probably already diagonallydominant close diagonally dominant row order change matrix factored whether rowpermutation option switched acm transactions mathematical software vol 28 3 september 2002 wang3old bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wsmp factor time ordering permuting options mumps fig 2 ratios factorization time mumps wsmp run ordering rowprepermutation option mumps graph enables fair comparison numerical factorization components two packages cases moderate decline two cases significant decline performance row permutation option switched hand cases moderate advantage one matrix twotone significant advantage switching row permutation happen original structure matrix symmetric nearly symmetric permuting rows destroys structural symmetry although twotone exception quite unsymmetric extra fillin acm transactions mathematical software vol 28 3 september 2002 recent advances solution general sparse linear systems delta 317 wsmp amd ordering wang3old bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wang442wsmp default nested dissection ordering fig 3 comparison factorization time wsmp run amd ordering default nesteddissection ordering bars correspond relative factorization time amd ordering compared unit time nesteddissection ordering graph shows role ordering wsmp computation resulting disruption original symmetric pattern may offset pivoting advantage gained moving large entries diagonal whole appears permuting rows matrix maximize magnitude product useful safeguard excessive fillin due pivoting case raefsky4 wang3old wsmp without row prepermutation wang3old bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wang4 wsmp row prepermutation default 7fig 4 comparison factorization time wsmp run without prepermuting rows move matrix entries relatively large magnitudes diagonal bars correspond relative factorization time without row prepermutation compared unit time default option 5 practical comparison mumps wsmp section 2 empirically demonstrated mumps wsmp contain fastest robust sparse lu factorization codes among currently available general sparse solvers section review relative performance two packages detail perspective use real application recent advances solution general sparse linear systems delta 319 table 4 compared factorization times mumps wsmp one four cpus rs6000 wh2 node noteworthy observation table 4 column wsmp 25 test cases six require 5 seconds mere workstation one matrices factored less 11 seconds real applications although factorization time usually primary importance users concerned total completion time includes analysis fac torization triangular solves iterative refinement figure 5 compare total time mumps wsmp take solve test systems equations beginning end four cpus rs6000 wh2 node matrix wsmp completion time considered one unit times packages measured relative analysis factorization solve times denoted bars different shades solve time includes iterative refinement steps necessary bring relative backward error order magnitude machine precision two new observations made figure 5 first analysis phase mumps usually much shorter wsmp surprising amd ordering algorithm used mumps much faster nesteddissection algorithm used wsmp addition amd yields significant amount symbolic information factors available mumps byproduct ordering hand wsmp must perform full separate factorization step compute structures factors task data dependency dags secondly solve phase mumps significantly slower wsmp mostly slower triangular solve mumps also partly mumps almost always requires two steps iterative refinement reach desired degree accuracy whereas single iterative refinement step suffices wsmp roughly half problems test suite majority applications sparse solvers require repeated solutions systems gradually changing values nonzero coefficients sparsity pattern figure 6 compare performance mumps wsmp important practical scenario call analysis routine package solve 100 systems sparsity pattern attempt emulate real application situation follows iteration 20 randomly chosen coefficients changed random amount 1 20 value previous iteration 4 coefficients similarly altered 200 16 coefficients altered 2000 total time package spends analysis factor solve phases used construct bar chart figure 6 since speed factorization solve phases relatively important analysis phase wsmp performs significantly better expected recall mumps unsymmetric matrices wsmp matrices permute rows coefficient matrix maximize product diagonal entries permutation based values coefficients evolving therefore rowpermutation slowly loses effectiveness iterations proceed matrices row permutation acm transactions mathematical software vol 28 3 september 2002 wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp wang3old mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps wsmp mumps total wsmp time factor analyze solve bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wang4 fig 5 comparison total time taken wsmp mumps solve system equations four cpus rs6000 wh2 node times normalized respect time taken wsmp furthermore time spent packages analysis factorization solve including iterative refinement phases denoted regions different shades recent advances solution general sparse linear systems delta 321 wang3old bbmat e40r0000 lhr34c mil053 mixtank nasasrb raefsky3 raefsky4 twotone venkat50 wang4 100 iteration wsmp timeiteration mumps time fig 6 comparison total time taken wsmp mumps solve 100 sparse linear systems nonzero pattern evolving coefficient values 4cpu rs6000 wh2 node useful anyway see figure 4 affect factorization time however others rely row permutation reduce pivoting factorization time may start increasing iterations proceed wsmp internally keeps track growth time numerical phases iterations may automatically trigger reanalysis called factor coefficient matrix new set values frequency reanalysis determined based analysis time relative increase time numerical phases iterations acm transactions mathematical software vol 28 3 september 2002 proceed reanalysis completely transparent user although analysis phase explicitly called experiment yielding data figure 6 actual time reported includes multiple analyses many matrices figure 6 shows detrimental effect overall performance wsmp reanalysis frequency chosen optimize total execution time note similar reanalysis strategy also implemented mumps due small analysis time may reduce total time matrices unsymmetric nonzero patterns 6 concluding remarks paper show recent sparse solvers significantly improved state art direct solution general sparse systems instance compare first four columns table 2 second last column table 4 comparison would readily reveal stateoftheart solver running todays singleuser workstation easily order magnitude faster best solver workstation combination available prior 1999 solving sparse unsymmetric linear systems moreover new solvers offer significant scalability performance utilized solve problems even faster parallel supercomputers amestoy et al 2001 therefore would fair conclude recent years seen remarkable advances general sparse direct solver algorithms software discussed paper improvements phases sparse direct solution process contributed performance gains include use maximum bipartite matching prepermute large magnitude elements matrix diagonal nesteddissection based fillreducing permutation applied symmetrically rows columns unsymmetric pattern multifrontal algorithm using minimal static task datadependency dags implementing partial pivoting using symmetric row column interchanges acknowledgments author would like thank yanto muliadi help conducting experiments gather data table 2 anonymous referees detailed comments helped improve presentation paper r approximate minimum degree ordering algorithm vectorization multiprocessor multifrontal code international journal supercomputer applications memory management issues sparse multifrontal methods multiprocessors fully asynchronous multifrontal solver using distributed dynamic scheduling multifrontal parallel distributed symmetric unsymmetric solvers analysis compar recent advances solution general sparse linear systems delta 323 ison two general sparse solvers distributed memory computers unsymmetrized multifrontal lu factorization spooles objectoriented sparse matrix library robust ordering sparse matrices using multisection using postordering static symbolic factorization parallel sparse lu umfpack v3 combined unifrontalmultifrontal method unsymmetric sparse matrices unsymmetricpattern multifrontal method sparse lu factorization column approximate minimum degree ordering algorithm asynchronous parallel supernodal algorithm sparse gaussian elimination direct methods sparse matrices design use algorithms permuting large entries diagonal sparse matrices algorithms permuting large entries diagonal sparse matrix multifrontal solution unsymmetric sets linear equations exploiting structural symmetry sparse partial pivoting code nested dissection regular finite element mesh computer solution large sparse positive definite systems implementation gaussian elimination partial pivoting sparse systems elimination structures unsymmetric sparse lu factors direct linear solver vector parallel computers httpwww august 1 januarymarch november 20 experimental comparison direct sparse solver packages october 19 lu factorization sequences identically structured sparse matrices within distributed memory environment fast high quality multilevel scheme partitioning irregular graphs making sparse gaussian elimination scalable static pivoting scalable sparse direct solver using static pivoting generalized nested dissection modification minimum degree algorithm multiple elimination role elimination trees sparse factorization multifrontal method sparse matrix solution theory practice scalable parallel sparse lu factorization dynamical supernode pivoting approach semiconductor device simulation pardiso highperformance serial parallel sparse linear solver semiconductor device simulation revised september tr direct methods sparse matrices role elimination trees sparse factorization multifrontal method sparse matrix solution elimination structures unsymmetric sparse italicluitalic factors exploiting structural symmetry sparse partial pivoting code modification minimumdegree algorithm multiple elimination approximate minimum degree ordering algorithm fast effective algorithms graph partitioning sparsematrix ordering unsymmetricpattern multifrontal method sparse lu factorization combined unifrontalmultifrontal method unsymmetric sparse matrices fast high quality multilevel scheme partitioning irregular graphs design use algorithms permuting large entries diagonal sparse matrices asynchronous parallel supernodal algorithm sparse gaussian elimination making sparse gaussian elimination scalable static pivoting pardiso computer solution large sparse positive definite isisupsup algorithms permuting large entries diagonal sparse matrix fully asynchronous multifrontal solver using distributed dynamic scheduling experimental comparison direct sparse solver packages lu factorization sequences identically structured sparse matrices within distributed memory environment ctr marco morandini paolo mantegazza using dense storage solve small sparse linear systems acm transactions mathematical software toms v33 n1 p5es march 2007 olaf schenk klaus grtner solving unsymmetric sparse systems linear equations pardiso future generation computer systems v20 n3 p475487 april 2004 nicholas gould jennifer scott numerical evaluation hsl packages direct solution large sparse symmetric linear systems equations acm transactions mathematical software toms v30 n3 p300325 september 2004 andreas wchter chandu visweswariah andrew r conn largescale nonlinear optimization circuit tuning future generation computer systems v21 n8 p12511262 october 2005