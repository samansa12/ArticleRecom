computing densities markov chains via simulation introduce new class density estimators termed lookahead density estimators performance measures associated markov chain lookahead density estimators given transient steadystate quantities lookahead density estimators converge faster especially multidimensional problems empirically give visually superior results relative standard estimators kernel density estimators several numerical examples demonstrate potential applicability lookahead density estimation given b introduction visualization becoming increasingly popular means enhancing ones understanding stochastic system particular rather reporting mean distribution one often finds useful conclusions may drawn seeing density underlying random variable consider problem computing densities performance measures associated markov chain chains finite state space typically amounts computing estimating finite number probabilities standard methods may applied easily case see chain evolves general state space however problem straightforward general statespace markov chains arise naturally simulation discreteevent systems hen derson glynn 1998 simple example consider customer waiting time singleserver queue traffic intensity ae 1 see section 6 sequence customer waiting times forms markov chain evolves state space 0 1 generally many discreteevent systems may research second author supported us army research office contract daag5597 10377 national science foundation grant dms9704732 described generalized semimarkov process processes viewed markov chains general state space see eg henderson glynn 1998 general statespace markov chains also prevalent theory control systems see chapter 2 meyn tweedie 1993 paper outgrowth considerably extends glynn henderson 1998 introduced new methodology stationary density estimation general overview density estimation iid observations see prakasa rao 1983 devroye 1985 devroye 1987 yakowitz 1985 1989 considered stationary density estimation problem markov chains state space ae ir stationary distribution density respect lebesgue measure showed certain conditions kernel density estimator point x asymptotically normally distributed error proportional nh socalled bandwidth n simulation runlength one conditions needed establish result hn 0 n 1 hence rate convergence kernel density estimators typically strictly slower n gamma12 depends dimension see remarks 5 7 contrast estimator propose converges rate n gamma12 independent dimension fact estimator propose several appealing features 1 relatively easy compute compared say nearestneighbour kernel density estimators 2 tuning parameters need selected unlike bandwidth kernel density estimators example 3 wellestablished steadystate simulation output analysis techniques may applied analyze estimator 4 error estimator converges 0 rate n gamma12 independent dimension state space n simulation runlength 5 relatively mild assumptions lookahead density estimators consistently estimate density also derivatives density see theorem 9 6 estimator used obtain new quantile estimator variance estimator corresponding quantile estimator rigorous convergence theory converges rate n gamma12 section 5 7 empirically estimator yields superior representations stationary densities compared methods example 1 section 6 first introduce central ideas behind lookahead density estimation familiar context although problem subsumed treatment section 3 separate development prove helpful understanding lookahead approach let irreducible positive recurrent markov chain finite state space stationary probability point 2 goal estimate stationary density delta finite state space context stationary density coincides stationary probabilities 2 estimate standard estimator idelta indicator function 1 argument true 0 otherwise estimator n simply proportion time markov chain x spends state notice however one could also estimate p delta delta transition matrix x estimator n strongly consistent estimator seen noting strong law positive recurrent markov chains discrete state space notice quantity p xi effect looking ahead see whether next iterate markov chain equal motivation name lookahead density estimator remainder paper assume general statespace necessarily discrete unless otherwise specified refer density trying estimate target density associated distribution target distribution section 2 lookahead density estimators developed several performance measures associated transient simulations pointwise asymptotic behaviour derived steadystate performance measures similarly considered section 3 section 4 turn global convergence behaviour lookahead density estimators particular give conditions lookahead density estimator converges target density l q sense theorem 5 uniformly convergent theorem 7 differentiable theorem 9 section 5 consider computation several features target distribution including mode target density quantiles target distribution finally section 6 give three examples lookahead density estimation computing densities transient performance measures markov chain taking values state space since focus section transient performance measures permit chain possess transition probabilities nonstationary recall transition kernel qx delta probability measure x 2 qdelta dy suitably measurable discrete state space q corresponds transition matrix permitting x nonstationary transition probabilities asserting exists sequence transition kernels basic assumption a1 exists oefinite measure fl function remark 1 assumption a1 automatically satisfied finite countably infinite remark 2 given paper concerned density estimation case fl lebesgue measure subset ir interest us however important note a1 restrict us context fact example 1 section 6 shows apparent subtlety fact useful remark 3 x stationary transition probabilities p discussion steadystate density estimation see section 3 clearly wish restrict chains describe several different computational settings ideas paper apply follows adopt generic notation pz delta denote fldensity rv z words pz delta function property range z also given initial distribution let p delta probability distribution pathspace x x initial distribution problem 1 compute density xr r 1 let p xr delta fldensity xr note z z z expectation operator corresponding p compute density p xr simulate n iid replicates x p a1 strong law large numbers together guarantee n 1 p xr indeed computed lookahead estimator p 1n remark 4 suppose a1 weakened assuming existence density mstep transition probability distribution provided r write p xr easily computed via independent replication x given subset let ag first entrance time problem 2 compute density xt suppose p starts c initial distribution z z 2 z a1 strong law large numbers ensure n 1 x independent replicates x p ag important class transient performance measures concerned cumulative costs specifically sequence realvalued rvs gamman may interpreted cost associated running x gammai cumulative cost corresponding time interval 0 n assume conditional x gammais independent rvs conditional distribution gammai depends x xi gamma 1 xi important special case arises ir case 1 automatically satisfied fx may viewed cost associated spending unit amount time x 2 permit additional generality 1 cost structures standard ingredient general theory additive functionals markov chains create difficulties theory proceeding discussion cumulative cost cn note problems 1 2 natural analogues however need replace a1 a2 exists oefinite measure fl function problem 3 compute density gammar 2 ir density p gammar consistently estimated n independent replicates x problem 4 compute density gammat density p gammat consistently estimated via n usual independent replicates x p first entrance time x set addition consistency p 3n p 4n a2 permits us solve couple additional computational problems relate density cumulative cost rv introduced earlier problem 5 compute density cr assume fl lebesgue measure r 1 may use a2 write z z z ygammaz z z evidently a2 strong law large numbers together guarantee n 1 p 5n consistent estimator p cr lebesgue density cr problem compute density ct earlier assume arguments used establish identity thus a2 strong law prove consistent estimator point constructed unbiased density estimators six density computation problems described turn development asymptotically valid confidence regions densities key recognize six estimators may represented p 1 index set either ir depending estimators consideration 2 let py 4 points py ddimensional vector jth component p j straightforward application multivariate central limit theorem clt yields following result points selected e ij k ddimensional multivariate normal random vector mean vector zero covariance matrix sigma j kth element given cov i1 j i1 k proposition 1 suggests approximation p n large denotes nonrigorous relation approximately distribution sigma 12 square root cholesky factor nonnegative definite symmetric matrix sigma since easily estimated consistently x sample covariance matrix follows 2 may used construct asymptotically valid confidence regions py remark 5 equation 2 implies error lookahead density estimator decreases rate n gamma12 dimensionindependent rate stands sharp contrast heavily dimensiondependent rate exhibited density estimators including kernel density estimators see prakasa rao 1983 convergence rate estimators typically nh bandwidth parameter dimension minimize mean squared error bandwidth hn typically chosen order n gamma1d4 error kernel density estimators decreases rate n gamma2d4 even one dimension asymptotic rate slower exhibited lookahead density estimator higher dimensions difference even apparent see example 2 section 6 computing densities steadystate performance measures extend lookahead estimation methodology steadystate context order concept steadystate welldefined assume x stationary transition probabilities transition kernels introduced section 2 independent n words assume exists transition kernel p p defined a1 proposition 2 a1 stationary distribution x possesses density respect fl proof let stationary distribution x note using represent stationary distribution density respect fl appropriate interpretation clear context suitably measurable z z z z z follows 3 4 stationary distribution fldensity delta value z 2 2 according proposition 2 density may expressed expectation namely see 5 relation 6 suggests using estimator n n compute n requires simulating x time establish laws large numbers clts n require x positive recurrent suitable sense a3 assume exists subset b positive scalars b integer 1 probability distribution delta deterministic function 1 2 ev ix 2 b 1 0 depending whether x 2 b language general statespace markov chain theory a3 ensures x geometrically ergodic harris recurrent markov chain see meyn tweedie 1993 details condition 1 a3 typically satisfied reasonably behaved markov chains choosing b compact set determined 1 satisfied condition 2 known lyapunov function condition many chains potential choice v something form v great deal ingenuity may necessary order construct v see example 1 section 6 illustration verification a3 case a3 ensures x possesses unique stationary distribution remark assumption a3 stronger condition necessary obtain laws large numbers clts however applications a3 particularly straightforward sufficient condition verify offer spirit consist points selected let n ddimensional vector jth component n j theorem 3 assume a1 a3 suppose 1 n 1 also exists nonnegative definite symmetric matrix ddimensional standard brownian motion denotes weak convergence d0 1 proof proof follows directly results meyn tweedie 1993 strong law consequence theorem 1701 lemma 1751 lemma 1752 together imply existence square integrable respect solution poissons equation enables application theorem 1744 yield result 2 remark 7 equation 2 implies error lookahead density estimator estimating stationary densities decreases rate n gamma12 rate observed remark 5 case independent observations furthermore exactly independent setting existing estimators including kernel density estimators converge slower rate see yakowitz 1989 convergence rate estimators typically nh bandwidth parameter dimension euclidian state space since hn 0 convergence rate slower n gamma12 yakowitz 1989 give optimal terms minimizing mean squared error choice bandwidth hn however iid sequence special case markov chain noted remark 5 fastest possible root mean square error convergence rate setting order n gamma2d4 rate heavily dimension dependent largedimensional problems one might expect slow convergence kernel density estimators obtain confidence regions density vector several different approaches possible sigmay positive definite exists consistent estimator sigma n sigmay theorem 3 asserts ir large n sigma n 12 defined set fx w confidence regions easily obtained 7 x enjoys regenerative structure regenerative method steadystate simulation output analysis provides one means constructing consistent estimators sigmay see example bratley fox schrage 1987 alternative approach exploits functional clt provided theorem 3 ensure asymptotic validity method multivariate batch means see munoz glynn 1998 details remark 8 discussion section generalizes computation density gamma1 stationary distribution particular suppose x satisfies a2 a3 2 ir defined a2 methodology section generalizes suitably global behaviour lookahead density estimator previous section focused pointwise convergence properties lookahead density estimator specifically showed finite collection points either ir depending estimator lookahead density estimator converges rate convergence described clt rate dimension independent section turn estimators global convergence properties assume throughout remainder paper complete separable metric space particular includes state space reasonable subset ir k let fl sections 2 3 let either ir depending estimator considered function f ir may define q 1 l q norm kfk q z two functions f 1 f measure distance f 1 f 2 first analyze lookahead density estimators introduced section 2 theorem 4 suppose e r kp delta gamma pdelta ik q n 1 proof evidently note n due convexity jxj q satisfying 8 right hand side 9 converges expectation e j i1 gamma py ij q consequently righthand side 9 uniformly integrable also lefthand side 9 converges zero since lefthand side dominated uniformly integrable sequence follows ejp n 1 fl ae also taking expectation sides 9 yields inequality ejp righthand side integrable hypothesis dominated convergence theorem applied 10 gives z ejp hence ekp delta gamma pdelta ik q consequently kp delta gamma pdelta ik q n 1 theorem follows 2 turn next obtaining analogous result steadystate density estimator n delta section 3 theorem 5 suppose z x 2 q 1 a3 holds initial distribution density respect fl n 1 proof condition 11 guarantees z see theorem 1437 meyn tweedie 1993 proof follows pattern theorem 2 argument yields conclusion ffl 0 almost every x therefore dominated convergence theorem allows us conclude z n 1 udelta density desired conclusion 2 remark 9 note hypotheses theorems 2 3 automatically satisfied convergence estimated density l q ensures given runlength n errors given size occur small respect fl set turn question lookahead density estimator converges limit uniformly uniform convergence especially important visualization context one guarantee error estimator uniformly small graphs estimated density close graph limit focus attention steadystate density estimator n similar results derived density estimators analogous arguments theorem 6 suppose a1 force p theta 0 1 continuous bounded a3 holds compact set k sup n 1 proof fix ffl 0 since tight see billingsley 1968 exists compact set kffl assigns ffl mass complement write 1 second term righthand side 12 may bounded 2 kffl limit supremum ffl first term note k compact kffl theta k compact p therefore uniformly continuous uniform continuity exists ffiffl whenever theta k within distance ffiffl ffl since k compact find finite collection points k open balls radius ffiffl centered 2 k exists collection jpxj 2 k letting 1ffl hence 2 k obtain uniform bound letting n 1 applying strong law harris chains n gamma1 sending ffl 0 obtain desired conclusion 2 remark 10 compact theorem 6 yields uniform convergence n continuity hypothesis p boundedness automatic setting next result establishes uniform convergence n provided assume px delta vanishes infinity theorem 7 suppose a1 holds uniformly continuous bounded assume x 2 ffl 0 exists compact set kx ffl whenever ffl a3 holds sup n 1 proof fix ffl 0 choose ffiffl whenever lies within distance ffiffl choose kffl proof theorem 6 let x kffl finite collection points open balls radius ffiffl centred x kffl x exists k note k compact theorem 6 establishes sup n 1 deal construct sequence x 2 kffl x 0 n closest point within collection fx sending n 1 allows us conclude k inequality 14 yields lim sup sup together imply theorem 2 following consequence theorem 7 improves theorem 5 convergence probability convergence basically scheffes theorem see example p 17 serfling 1980 corollary 8 conditions theorem 7 z n 1 proof result immediate fl finite measure since j n delta gamma deltaj uniformly bounded converges zero theorem 7 fl infinite measure like lebesgue measure theorem 7 asserts n delta delta pathbypath may argue z z since integrand dominated delta integrates one thereby permitting application dominated convergence theorem pathbypath 2 important characteristic lookahead density estimator smoothly approximates density computed specific suppose either considering density one realvalued rvs associated estimators p 3n delta p 4n delta p 5n delta p 6n delta since working subset euclidian space reasonable measure smoothness terms derivatives density real loss generality assume 2 ir lookahead density estimators developed take form sequence random functions g 1 estimators section 2 section 3 admit representation estimate kth derivative target density computed natural estimator therefore dy k pn dy quite weak conditions problem shown estimator computes kth derivative target density consistently see discussion result proves lookahead density estimation compute density also approximates derivatives density consistent fashion words smoothly approximates target density illustration types conditions needed order ensure lookahead density estimator smoothly approximates target density consider steadystate density estimator section 3 let p 0 x dy px theorem 9 suppose a1 holds continuously differentiable bounded derivative a3 holds differentiable density delta sup n 1 compact k furthermore jp 0 x yj v 12 x x 2 exists dy n 1 proof note z lies derivative assumed bounded bounded convergence theorem ensures limit 18 exists bounded continuous exactly argument used proving theorem 6 used obtain 16 clt 17 immediate consequence theorems 1701 1754 meyn tweedie 1993 2 important implication theorem 9 lookahead density estimator computes derivative accurately fact density estimator converges rate n gamma12 independent dimension state space furthermore independent order derivative estimated remark 11 also known kernel density estimators smoothly approximate target density see prakasa rao 1983 p 237 scott 1992 p 131 choice bandwidth minimizes mean squared error kernel density derivative estimator larger case estimating target density resulting rates convergence kernel density derivative estimators adversely affected order derivatives dimension state space example one dimension kernel density derivative estimators rth order derivative converge best rate rate fastest estimating first derivative even slower rate convergence lookahead density derivative estimator discussed computing special features target distribution using lookahead density estimators discussed earlier computation density useful element developing visualization tools computer simulation section focus computation certain features target distribution lookahead density estimator applied advantage 51 computing relative likelihood two points sections 2 3 introduced number different lookahead density estimators write generically pn delta lookahead density estimator pn delta estimator target density pdelta say pair points represents likelihood point 1 relative 2 joint clts developed proposition 1 theorem 3 used obtain clt suit able construction largesample confidence intervals relative likelihood estimator n 1 covariance matrix n 1 consistently estimated example regenerative method confidence intervals relative likelihood based 19 easily obtained otherwise one turn batch means method produce confidence intervals see munoz glynn 1997 52 computing mode density mode density provides information region within random variable interest attains highest likelihood given target distribution density pdelta goal compute modal location modal value py discussed earlier section lookahead density estimator generically pn delta obvious estimator course maximizes pn delta natural estimator py pn assume maximizer n selected measurable denote domain pdelta analysis involves using taylor expansion require 2 ir theorem 1 pdelta unique mode location 2 sup n 1 3 exists fflneighbourhood ffl 0 pdelta pn delta twice continuously differentiable 4 sup kygammay kffl n 1 5 sup kygammay kffl n 1 hn hy hessians pn delta pdelta respectively 6 hy negative definite 7 n 12 p n n 1 n 1 proof almost sure convergence n immediate consequence relations 1 2 weak convergence statement observe rpn local maxima pn delta pdelta respectively precise valid n large n lies fflneighbourhood specified relations 3 5 rpn rpn n 1 follows n 12 gammay lies line segment joining n since rpn n established weak convergence n 12 evidently first term 21 converges zero probability consequently 20 21 relation 7 converging together principle see billingsley 1968 example imply desired joint convergence result 2 remark 12 uniform convergence theory section 3 pn derivatives easily applied verify relations 2 4 5 remark 13 clt established theorem 10 shows lookahead estimator mode converges asymptotic rate n gamma12 independent dimension state space compares favourably rate convergence kernel estimators mode kernel estimator mode converges rate nh d2 bandwidth hn chosen appropriately see theorem 456 prakasa rao 1983 p 284 remark 14 construct confidence intervals based theorem 10 couple alternatives assume first fixed 2 one consistently estimate covariance matrix arises joint clt relation 7 example done transient context setting regenerative processes steadystate simulation estimate covariance structure one compute corresponding covariance estimate evaluated point n transient problems considered section 2 typically easy verify covariance matrix continuous using estimator associated n place covariance asymptotically valid steadystate context straightforward theoretically establish continuity covariance although one suspects valid great generality one potential avenue adopt methods glynn lecuyer 1995 consistent estimates covariance matrix fixed 2 available might occur nonregenerative steadystate simulations one potentially appeal method batch means see munoz 1998 53 computing quantiles target distribution focus special case ir target distribution realvalued rv setting suppose dy let py dy target distribution important special feature distribution pth quantile f specifically p 2 0 1 define pth quantile f quantity significant literature computation quantiles iglehart 1976 considered quantile estimation context regenerative simulation proved central limit theorem standard estimator seila 1982 introduced batch quantile method regenerative processes avoids difficulties associated estimation procedure proposed iglehart 1976 approach suggested heidelberger lewis 1984 based socalled maximum transfor mation mixing assumptions underlying process require regenerative structure hesterberg nelson 1998 references therein discuss use control variates obtain variance reduction quantile estimation avramidis wilson 1998 obtain variance reduction estimating quantiles use antithetic variates latin hypercube sampling kappenman 1987 integrated inverted kernel density estimator pdelta case observations iid approach similar kappenmans invert integrated lookahead density estimator let pn delta lookahead density estimator set pn dy natural estimator quantile q p theorem 11 suppose 1 pq 0 2 pdelta continuous ffl neighbourhood q 3 sup n 1 4 n 12 proof recall kpn delta gamma pdeltak 1 0 n 1 see remark 9 hence sup x n 1 follows qn q n 1 lies qn q relations 2 3 imply pn n pq n 1 result follows 22 23 relation 4 2 remark 15 similar issues discussed remark 14 arise constructing confidence intervals based theorem 11 possible consistently estimate variance parameter arises clt relation 4 either transient context setting regenerative steadystate simulation see recall lookahead density estimator pn delta may expressed sequence random functions g pn dy n evidently 24 sample mean sequence realvalued rvs sequence either iid regenerative depending context therefore standard methods may applied estimate variance parameter clt relation 4 comments remark 14 related continuity variance parameter apply directly particular one must establish variance rv n relation 4 continuous function q estimating variance q estimate variance q n asymptotically valid natural ask performance lookahead quantile estimator compares standard quantile estimator ease exposition remainder section specialise case markov chain taking values ir suppose a1 a3 force interested computing distribution function stationary distribution x natural approach estimation q first estimate f empirical distribution function fn choose estimator qn q p alternatively using lookahead methodology one could estimate q f gamma1 proof following proposition rests primarily observation estimators fn fn related principle extended conditional monte carlo bratley et al 1987 p 71 glasserman 1993 let p density stationary distribution respect lebesgue measure let var denote variance operator associated path space x x initial distribution proposition 12 suppose a1 a3 hold conditions 1 2 theorem 11 satisfied fn q n 1 0 1 n 2 0 1 standard normal rvs addition x stochastically monotone oe 2 oe 2 proof observe w 2 ir z q theorem 1753 meyn tweedie implies n 12 similarly theorem 1753 also gives n 12 x stochastically monotone view 25 apply theorem 12 glynn iglehart 1988 achieve result required uniform integrability follows fact combining results theorem 11 proposition 12 see reasonable conditions n 1 also shown reasonable conditions oe henderson glynn 1999 proposition 12 asserts oe 2 context steadystate quantile estimation stochastically monotone markov chains lookahead quantile estimator may typically expected achieve variance reduction standard quantile estimator remark 16 wellknown waiting time sequence singleserver queue stochastically monotone markov chain thus results section may applied context 6 examples present three examples application lookahead density estimators first example example steadystate density estimation illustrates establish a3 example 1 wellknown sequence customer waiting times excluding service fifo singleserver queue markov chain state space particular w satisfies lindley recursion p 181 asmussen 1987 iid sequence n v n service time nth customer un 1 interarrival time nth 1st customer verify a3 proceed follows define yet determined constant note let us assume moment generating function oet 4 ee ty 1 1 exists neighbourhood zero oet finite sufficiently small stability must ey 1 0 implies oe 0 0 0 hence exists ff 0 oeff 1 choose k 0 x k see 26 ev w 1jw 26 also see x k ev w 1jw 1 thus verified condition 2 a3 set verify condition 1 note ey 1 0 implies exists fi follows conditional w taking point mass 0 see condition 1 a3 verified therefore established following result proposition 13 moment generating function 1 exists neighbourhood 0 ey 1 0 a3 satisfied specialise mm1 queue arrival rate service rate traffic intensity ae 4 1 transition kernel w given px probability measure assigns unit mass origin noting pdelta delta bounded max 1 follows possibly scaling function conditions theorem 3 satisfied lookahead density estimator therefore converges rate n gamma12 stationary density w defining suitable kernel density estimator slightly problematical due presence point mass 0 stationary distribution need select kernel bandwidth estimate point mass 0 use mean number visits 0 run length n 0 estimate using density standard normal rv choice hn modulo multiplicative constant yields optimal rate meansquare convergence case observations iid prakasa rao 1983 p 182 seems reasonable choice context example chose traffic intensity ae 05 remove effect initialization bias note estimators affected simulated stationary version w sampling w 0 stationary distribution exact lookahead kernel 10005015025035045waiting time density density estimators mm1 queue figure 1 density estimates run length 100 density estimates x 0 together exact density plotted simulation runlengths figure observe following 1 visually lookahead density estimate appears far better representation true density kernel density estimate 2 kernel density estimate several local modes performance near origin particularly poor even run length 1000 previous example onedimensional density estimation problem results suggest rate convergence lookahead density estimators insensitive underlying dimension problem however rate convergence kernel density estimators known adversely affected dimension see remarks 5 7 assess difference performance multidimensional setting provide following example exact lookahead kernel 10010305waiting time density density estimators mm1 queue figure 2 density estimates run length 1000 example 2 let sequence dimensional iid normal random vectors zero mean covariance matrix identity matrix define markov chain inductively 1 markov chain x special case linear state space model defined p 9 meyn tweedie 1993 chose model example steadystate density easily computed particular stationary distribution x normal mean zero covariance matrix thus x stationary density exp estimate density dimensions using kernel density estimator lookahead density estimator estimators constructed simulated sample paths length 10 100 1000 sample x0 stationary distribution remove initialization bias estimate mean squared error mse density estimators repeat simulations 100 times kernel density estimator chose uses multivariate standard normal distribution kernel bandwidth rationale behind choice bandwidth table 1 reports root mse two estimators percentage true density value 0 observe dimension increases rate convergence kernel density estimator deteriorates rapidly contrast rate convergence lookahead density estimator remains constant increase runlength factor 10 relative error decreases factor approximately 3 independent dimension problem remark 17 possible construct lookahead density estimators far complicated linear state space models one considered critical ingredient a1 easily satisfied 0 estimator runlength table 1 root mse estimators 0 percentage 0 example innovation vectors w k known density respect lebesgue measure final example application stochastic activity networks sans example easily captured within markov chain framework therefore gives idea potential applicability lookahead density estimation methodology example 3 example estimate density network completion time length longest path source sink simple stochastic activity network taken avramidis wilson 1998 consider san figure 3 independent task durations source node 1 sink node 9 labels arcs give mean task durations assume tasks 6 densities respect lebesgue measure network completion time l density pdelta respect lebesgue measure figure 3 stochastic activity network mean task duration shown beside task suppose sample task durations except task 6 compute lengths l8 longest paths source node nodes 6 8 respectively f given task ab f ab denotes task duration distribution function f ab ab delta f ab delta lebesgue density a1 strong law large numbers ensure lookahead density estimator f strongly consistent estimator py purposes simulation experiment assumed task durations exponentially distributed means indicated figure 3 resulting density estimate depicted figure 4 run length 1000 150000500150025completion time density estimated network completion time density figure 4 estimate network completion time density remark 18 approach taken example clearly generalizes sans arcs entering sink node densities respect lebesgue measure remark 19 one need base lookahead density estimator arcs incident sink example one might instead focus arcs leave source example arcs correspond tasks 1 2 1 3 one would condition longest paths nodes 2 3 sink acknowledgments r applied probability queues convergence probability measures guide simulation nonparametric density estimation l 1 view course density estimation filtered monte carlo estimation stationary densities markov chains likelihood ratio gradient estimation stochastic recursions quantile estimation dependent sequences regenerative steadystate simulation discreteevent systems asymptotic results steadystate quantile estimation markov chains control variates probability quantile estimation simulating stable stochastic systems improved distribution quantile estimation markov chains stochastic stability batch means methodology estimation quantiles steadystate distribution multivariate standarized time series output analysis simulation experiments batch means methodology estimation nonlinear function steadystate mean nonparametric functional estimation multivariate density estimation theory batching approach quantile estimation regenerative simulations approximation theorems mathematical statistics nonparametric density estimation nonparametric density regression estimation markov sequences without mixing assumptions tr ctr shane g henderson simulation mathematics random number generation mathematics simulation proceedings 33nd conference winter simulation december 0912 2001 arlington virginia