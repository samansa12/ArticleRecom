optimizing threaded mpi execution smp clusters previous work shown using threads execute mpi programs yield great performance gain multiprogrammed sharedmemory machines paper investigates design implementation threadbased mpi system smp clusters study indicates proper design threaded mpi execution pointtopoint collective communication performance improved substantially compared processbased mpi implementation cluster environment contribution includes hierarchyaware adaptive communication scheme threaded mpi execution threadsafe network device abstraction uses eventdriven synchronization provides separated collective pointtopoint communication channels paper describes implementation design illustrates performance advantage linux smp cluster b introduction commercial success smp architectures smp clusters commodity components widely deployed high performance computing due great economic advantage clustering 1 2 mpi messagepassing standard 14 widely used highperformance parallel applications implemented large array computer systems paper studies fast execution mpi programs dedicated smp clusters mpi paradigm mpi nodes execute piece program separate address spaces mpi node unique rank allows mpi node identify communicate peers result global variables declared mpi program private mpi node natural map mpi node pro cess however communication processes go operating system kernels could costly previous studies 16 18 show processbased implementations suer large performance loss multiprogrammed sharedmemory machines smms mapping mpi node thread opens possibility fast synchronization address space sharing approach requires compiler transform mpi program threadsafe form demonstrated previous tmpi work 16 18 approach deliver significant performance gain large class mpi c programs multiprogrammed smms extending threaded mpi implementation single smm support smp cluster straightforward smp cluster environment processes threads within machine communicate shared memory communication processes threads dierent machines go network normally several orders magnitude slower sharedmemory access thus addition mapping mpi nodes threads within single machine important ecient mpi implementation take advantage twolevel communication channel hierarchy common intuition cluster environment internode messaging delay dominates performance com munication thus advantage executing mpi nodes threads diminishes shown later experience counters intuition multithreading yield great performance gain mpi communication smp cluster environment using threads speeds synchronization threads single smp node also greatly reduces buering orchestration overhead communication among threads dierent nodes paper present design implementation threadbased mpi system linux smp cluster examine benefits multithreading platform key optimizations propose hierarchyaware adaptive communication scheme threaded mpi execution threadsafe network device abstraction uses eventdriven synchronization provides separated collective pointtopoint communication channels eventdriven synchronization among mpi nodes takes advantage lightweight threads eliminates spinning overhead caused busy polling channel separation allows flexible ecient design collective communication prim itives experiments conduct dedicated smp cluster expect greater performance gain demonstrated nondedicated cluster future work rest paper organized follows section 2 introduces background overview threadbased mpi system tmpi cluster section 3 discusses design tmpi system section 4 reports performance studies section 5 concludes paper 2 background overview design based mpich known portable mpi implementation achieves good performance across wide range architectures 8 scheme targeted mpi programs executed using threads thus first give type mpi programs address paper briefly give overview mpich system give highlevel overview threadbased mpi system tmpi smp clusters 21 using threads execute mpi programs using threads execute mpi programs improve performance portability mpi program minimize impact multiprogramming due fast context switch ecient synchronization threads shown 16 experiments sgi origin 2000 indicate threaded mpi execution outperforms sgis native mpi implementation order magnitude multiprogrammed smms mentioned need compiletime transformation mpi program emerges process model used mpi paradigm major task procedure called variable privatization basically provide perthread copy global variable insert statements original program fetch threads private copy variable inside function global variables referenced algorithm based general mechanism available thread libraries called threadspecific data tsd extend tsd make feasible run multithreaded mpi programs note tsdbased transformation algorithm able support multithreading within single mpi node however current tmpi runtime system allow threads within single mpi node call mpi functions simultaneously mpithreadserialized detailed information please refer 18 every mpi program transformed map mpi nodes threads one major restriction aecting applicability threaded execution mpi program cannot call lowlevel library functions threadsafe eg signals since scientific programs involve type functions particularly mpi specification discourages use signals techniques applicable large class scientific applications two minor factors need mentioned aect much applicability techniques 1 total amount memory used mpi nodes running one smp node fit single virtual address space problem considering 64bit os becomes popular 2 fixed perprocess file descriptor table size unix systems since unixs network library uses file descriptors represent stream connec tions applications might fail total number files opened mpi nodes single smp relatively large applications regular read computewrite pattern modified separating file io program circumvent problem 22 mpich smp clusters mpich follows sophisticated layered design welldocumented discussed literature design borrows ideas mpich briefly summarize architectural design mpich section goal mpichs layered design make easy fast port system new architectures yet allow room tuneup replacing relatively small part software shown figure 1 mpichs communication implementation consists four layers bottom top 1 device layer includes various operating system facilities software drivers kinds communication devices 2 adi layer layer encapsulates dierences various communication devices provides uniform interface upper layer adi layer exports pointtopoint communication interface 7 3 mpi pointtopoint primitives built directly upon adi layer also manages highlevel mpi communication semantics contexts communicators 4 mpi collective primitives built upon point topoint primitive layer messages share channel pointtopoint communication collective communication mpich uses special tagging distinguish messages belong user pointtopoint communication internal messages collective operation mpi collective mpi pointtopoint adi chameleon interface t3d sgi others shmem mpi collective mpi point point abstract device interface devices figure 1 mpich communication architecture port mpich dierent platform necessary wrap communication devices target system provide adi interface design mainly targeted large parallel systems networked clusters maps mpi nodes individual processes easy modify current mpich system map mpi node lightweight thread lowlevel layers mpich threadsafe even though latest mpich release supports mpi2 standard mt level actually mpithreadsingle cluster node mpi node process mpich daemon process interprocess pipe shared memory connection ws ws ws ws figure 2 mpich using combination tcp shared memory shown figure 1 current support smp clusters mpich basically combination two devices sharedmemory device network device tcpip figure 2 shows sample setup configuration example 8 mpi nodes evenly scattered cluster nodes also 4 mpi daemon processes one cluster node fully connected daemon processes necessary drain messages tcp connections deliver messages across clusternode boundaries mpi nodes communicate daemon processes standard interprocess communication mechanisms domain sockets mpi nodes cluster node also communicate shared memory ws ws ws ws cluster node mpi node process mpich daemon process interprocess pipe connection figure 3 mpich using tcp one also configure mpich compile time make completely oblivious sharedmemory architecture inside cluster node use loopback devices communicate among mpi nodes running cluster node case setup look like figure 3 example show number mpi nodes node distribution previous configuration dierent previous one 8 daemon processes one mpi node sending message mpi nodes cluster node go path sending message mpi nodes dierent cluster nodes possibly faster 23 threaded mpi execution smp cluster cluster node mpi node thread connection direct mem access thread sync ws ws ws ws figure 4 communication structure threaded mpi execution section provide overview threaded mpi execution smp clusters describe potential advantages tmpi facilitate understanding take sample program used figure 2 illustrate setup communication channels tmpi threadbased mpi system figure 4 see map mpi nodes cluster node threads inside process add additional daemon thread process despite apparent similarities figure 2 number dierences design mpich 1 tmpi communication mpi nodes cluster node uses direct memory access instead sharedmemory facility provided operating systems 2 tmpi communication daemons mpi nodes also uses direct memory access instead domain sockets 3 unlike processbased design remote message send receive delegated daemon processes threadbased mpi implemen tation every mpi node send receive remote mpi node directly shown later sections dierences impact software design provide potential performance gain tmpi threadbased mpi systems additionally tmpi gives us following immediate advantages processbased mpi systems comparing mpich system uses mixing tcp shared memory depicted figure 2 1 mpich usually shared memory limited system resource osimposed limit maximum size single piece shared memory 1 also systemwide bound total size shared memory fact one test benchmark coming mpich failed limited sharedmemory resource threadbased system doesnt suffer problem threads process access whole address space 2 easy way mpich aggregate dier ent types devices result mpi node use nonblock polling check pending messages either device could waste cpu cycles sender ready yet synchronizations among threads flexible lightweight combined eventdriven style daemons mpi nodes freely choose busy spinning blocking waiting message 3 shared memory used mpich persistent systemwide resource automatic way perform resource cleaning program doesnt clean execution operating systems could run sharedmemory descriptors buggy user programs exit without calling proper resource cleanup functions leave garbage shared memory os thus reliability user programs running mpich based cluster sensitive type errors threadbased system tmpi problem shared address space access completely userlevel operation comparing threadbased mpi system purely tcpip based mpich implementation depicted figure 3 following disadvantages 1 two data copying send message two mpi nodes cluster node mpich synchronization two mpi nodes also becomes complicated threadbased system tmpi 2 proliferation daemon processes network connections situation get even worse fatter cluster nodes nodes processors run mpi nodes 24 related works mpi network clusters also studied number projects lammpi 13 4 mpi system based upon multicomputer management environment called trollius 3 dierent mpich sense design specific network clusters lower level communication provided standalone service unique request progression interface address issue optimize mpi performance cluster smps suns mpi implementation 17 discusses optimize mpis collective communication primitives large scale smp clusters focus work 1 version redhat linux 60 installed kernel version 2215 number 4mb optimize collective operations single fat smp node mpistart 9 made couple optimizations smp clusters modifying mpichs adi layer propose twolevel broadcast scheme takes advantage hierarchical communication channels collective communication design extends idea highly optimized threaded mpi execution magpie 10 optimizes mpis collective communication primitives clusters connected widearea network mpifm 11 mpiam 19 12 attempt optimize performance lower level communication devices mpi techniques applied tmpi system mpilite 15 lpvm 20 tpvm 6 study problem running message passing programs using threads single sharedmemory machine knowledge research eort towards running mpi nodes using threads smp clusters research complements work focusing taking advantage executing mpi node using thread 3 system design implementa tion section detail design implementation threadbased mpi system tmpi 31 system architecture mpi inter intra others mpi communication inter intramachine communication abstract network thread sync interface os facilities thread pthread thread impl figure 5 tmpi communication architecture system architecture mpi communication primitives shown figure 5 2 four layers bottom top 1 operating system facilities tcp socket interface pthread 2 network thread synchronization abstraction layer potentially layer allows portability tmpi systems performance tuneup providing dierent implementations network communication thread synchronization thread synchronization abstraction almost direct mapping pthread apis except threads launched batch style create thread entities start single function call time function call returns threads finish execution network device abstraction tailored threaded mpi execution model dierent either traditional socket interface mpichs adi interface talk detail section 32 section 33 2 synchronization primitives shown figure 5 compareandswap 3 low level abstraction communication management threads intra dierent cluster nodes intraclusternode communication manages communication among threads single cluster node interclusternode communication layer wraps network abstraction interface manages logical communication multithread level specific thread local rank unique among threads cluster node global rank unique among threads cluster nodes given global rank need find cluster node thread resides local rank cluster node well reverse lookup also needed another functionality interclusternode communication module resource discover allocation api allows flexible placement mpi nodes eg many cluster nodes used ranks mpi nodes placed cluster node decisions made anywhere completely automatic fully controlled user supplied parameters 4 mpi communication primitive implementation including notions communicators message tags contexts implemented upon three building blocks intra interclusternode communication thread interface particularly collective primitives implemented awareness twolevel communication hierarchy despite similarities mpich design shown figure 1 couple notable dierences two systems top layer tmpi aware dierent mechanisms communicate threads dierent cluster nodes implementation organize communication take advantage twolevel hierarchical communication channel discussed section 33 section 34 tmpi collective communication primitives built upon pointtopoint communication prim itives instead implemented independently top layer network device abstraction provides pointtopoint collective communication among processes dierent cluster nodes 32 tmpi network device abstraction network device abstraction tmpi called netd abstracts network application group relevant processes dierent machines unique rank provides basic communication functionalities application thin layer contains 28 core functions grouped three categories connection management includes creation processes number cluster nodes setuptear communication channels relevant processes fully connected query id total number processes collective communication provides collective communication among relevant processes created netd current implementation uses adaptive algorithm choose among three dierent spanning trees based number processes involved size small simple scatter tree used hypercube used size large balanced binary tree chosen size falls middle pointtopoint communication netd unique pointtopoint communication api message contains message header part optional payload part content message header interpreted netd receive message caller must provide netd callback function called message handle netd buers message header invokes handle sender id message message header message handle responsible examining header performing necessary actions receiving payload part one interface necessary eciently support mpi communication primitives tmpi mpi node receive message unknown source mpianysource situation complicated tmpi normal network devices provide atomic receive operation thus multiple threads wait messages port single logic message could fragmented received dierent threads get around prob lem tmpi uses daemon thread receive incoming messages invoke message handle context daemon thread message handle responsible decoding actual source destination buering incoming data notifying destination thread 33 separation pointtopoint collective communication channels netd weve mentioned figure 4 every thread process access communication ports originated process feature inspired us idea separating collective pointtopoint communication channels allows tmpi take full advantage synchronous nature collective communication eliminate intermediate daemon overhead reason figure 4 thick line actually represents two tcp connec tions one dedicated collective operations pointtopoint communication daemon threads responsible serializing incoming messages pointtopoint communication separation pointtopoint communication channels collective communication channels based careful observations mpi semantics mpi receive operations much complicated collective operations besides wildcard receive operation discussed outoforder notion message tags asynchronous notion nonblock receives thus daemon thread required serialization also buering purposes due limited buering network devices daemon threads actively drains incoming messages deadlock situations permitted mpi standard could happen figure 6 shows example node 0 node 1 would blocked mpibsend statement without presence daemon threads even enough buer space available collective communication mpi operations never oforder always synchronous sense collective operation completed mpi nodes involved reaches rendezvous point 3 structure spanning tree determined runtime operation mpich separate collective pointpoint communication channels highlevel mpi collective communication primitives implemented top point topoint communication layer result collective operations go pointtopoint communication daemons cause unnecessary overhead separation pointto point collective communication channels could benefit processbased mpi implementation well however may eective tmpi two processes cluster node cannot directly share network communication ports eg sockets 34 hierarchyaware collective communication design collective communication tmpi implemented series intra interclusternode collective communi cation examples mpibcast interbcast followed intrabcast mpiallreduce intra reduce followed interreduce interbcast finished intrabcast intraclusternode collective communication takes advantage address space sharing implemented based ecient lockfree fifo queue algorithm way collective communication take full advantage twolevel communication hierarchy conceptually twophase collective communication building spanning tree two steps idea first mentioned mpistart project 9 essentially designated root mpi node cluster node forms spanning tree connecting cluster nodes mpi nodes connect local root cluster node form whole spanning tree spanning tree exactly n1 edges cross clusternode boundaries called network edges n number cluster nodes involved communication noted mpich uses shared memory setting actually take twostep approach builds spanning tree directly given number mpi nodes without knowing distribution mpi nodes cluster nodes result spanning tree collective communication mpich may network edges figure 7 compares spanning trees sample mpi program size 9 running 3 cluster nodes see tmpi left part results 2 network edges mpich right part 5 network edges 3 possible employ techniques pipelining asynchronous operations optimize collective operations however optimizations required mpi standard eectiveness eminent real applications based experience spanning trees mpi program 9 nodes three cluster nodes three cluster nodes contain mpi node 02 35 68 respectively thick edges network edges tmpi mpich figure 7 collective communication spanning trees tmpi mpich adaptive buffer management pointto point communication pointtopoint communication tmpi bears lot similarities mpich design conceptually mpi node receive queue unexpectedmessage queue sender comes corresponding receiver send request handle deposited receivers unexpected message queue similarly receiver comes corresponding sender receive request handle stored receive queue pair sender receiver dierent cluster nodes daemon thread receiver side act behalf remote sender one dicult problem facing design temporary buering message corresponding receiver ready yet intraclusternode pointtopoint com munication always block sender till receiver comes internal buer space available ever sender sends message remote receiver know whether sucient buer space hold message message size mpi could arbitrarily large traditional conservative solution threephase asynchronous messagepassing protocol 5 tmpi address space sharing fast synchronization among threads lead us ecient adaptive buering solution combination optimistic eager pushing protocol threephase protocol basically sender needs make guess based message size whether transfer actual message data send request metadata eagerpushing protocol send metadata first send data later receiver ready threephase protocol remote daemon receiver side acknowledge whether sender made correct guess figure 8 shows three simplified cases tmpis inter clusternode pointtopoint communication protocol provide detailed description following note figures accommodate cases synchronous ready send operations figure 8 sender sends request actual data receiver side either receiver already arrives still internal buer space available daemon accepts data store send request information actual data proper queue notify sender data accepted wake receiver necessary senderside dae mpibsendbuf bigsize type 1 mpirecvbuf bigsize type 1 mpibsendbuf bigsize type 0 mpirecvbuf bigsize type 0 figure possible deadlock without daemon threads successful eagerpush reqdat r got dat b failed eagerpush degrades threephase protocol reqdat got req receiver ready dat r got dat r c threephase protocol got req receiver ready dat r got dat r sender daemon q msg queue r receiver network transaction msg queue op receiver arrivalwakeup network boundary figure 8 pointtopoint communication nodes dierent cluster nodes mon receives confirmation frees data behalf sender figure 8 b sender still sends data request time receiverside daemon cannot accept incoming data daemon receives discards data store request metadata unexpectedmessage queue later receiver arrives discovers partially completed send request asks associated data sender senderside daemon sends data receiver side receiverside daemon receives data saves data receiversupplied user buer tells sender data received subsequently senderside daemon deallocate buer upon receiving acknowledge note actual data transferred twice case figure 8 c sender decides send request part data part separately whole flow essentially figure 8 except actual data transfered design allows optimal performance sender makes correct guess functions correctly degraded performance guesses wrong remaining issue decide sender switch eagerpush threephase protocols decision complicated fact internal buer space tmpi shared mpi nodes cluster node aggregated among series requests common intuition choose eagerpushing protocol often possible could still preferable buer request even though buer space avail able amount buer space might used hold data multiple subsequent requests like traditional nonpreemptive scheduling problem favor short requests algorithm could suboptimal due lack future knowledge current implementation tmpi sender send data request message size statically defined threshold receiver side receiver daemon greedily buers incoming data whenever possible current threshold set 100kbytes based empirical study finally allowing receive daemon send messages could result deadlock condition designed carefully tmpi netd layer supports blocked nonblocked send nonblocked send merely puts message queue send daemon responsible sending message deallocate memory necessary receive daemon always uses nonblocked send 36 discussions benefit address space sharing tmpi one benefit threadbased mpi implementation potential saving data copying addressspace shar ing intraclusternode pointtopoint communication tmpi needs one intermediate data copying mpich takes two intermediate data copying shared memory three intermediate data copying without shared memory interclusternode pointto point communication since daemons either sender receiverside access sender receiverbuer tmpi takes zero two intermediate data copying mpich always needs three intermediate data copy ing additionally data need move across process boundaries tmpi data need transfered across process boundaries three times mpich since two involving processes must synchronized transfer data one mpich performance sensitive os scheduling multiprogrammed environment tmpi scalability presence single receive daemon thread handle incoming messages potential bottleneck terms scalability tmpi possible configure multiple daemons incoming connections partitioned among multiple daemons however currently compiletime parameter plan study adaptively choose number daemons runtime fu ture also create instances nonblock send daemons make responsible messages send operations initiated mpi nodes could beneficial sudden surge outgoing data want block sender threads current small scale settings none configurations neces sary point tmpi design scalable accommodate large clusters fat smp nodes 4 experiments section evaluate eectiveness proposed optimization techniques threaded mpi implementation versus processbased implementation choose mpich reference processbased implementation due wide acceptance emphasize experiments meant illustrate whether flaws mpich design instead discussed previous sec tions want show potential advantages threaded mpi execution smp cluster environments fact optimization techniques tmpi possible multithreaded mpi implementation implemented prototype system linux smp clusters includes 45 mpi functions mpi 11 standard listed appendix yet support heterogeneous architectures 4 support userdefined data types layouts mpich version use contains functions mpi 11 standard provides partial support mpi2 standard however adding functions relatively independent task aect experimental results experiments conducted cluster six quad xeon 500mhz smps 1gb main memory cluster node two fast ethernet cards connected lucent canjun switch operating system redhat linux 60 running linux kernel version 2215 channel bonding enabled 5 41 microbenchmarkperformance point topoint communication section use microbenchmarks make finegrain analysis pointtopoint communication subsystems tmpi mpich pingpong test first use pingpong benchmark access performance pointtopoint communication vary data size 4 bytes 1 megabytes common practice choose dierent metrics small large messages messages size smaller 1 4 note mpich detects whether underlying system homogeneous startup time data conversion overhead incurred 5 channelbonding allows single tcp connection utilize multiple network cards could improve network bandwidth help reduce network delay case achievable raw bandwidth 200mbps pair cluster nodes kilobytes report performance terms roundtrip delay messages lager 1 kilobytes report transferrate defined total amount bytes sentreceived divided roundtrip time round trip time pingpong short message tmpi mpich transfer rate b pingpong long message tmpi mpich figure 9 interclusternode pingping performance figure 9 shows pingpong performance two mpi nodes dierent cluster nodes see message size small tmpi performs slightly better mpich except messages small case tmpis saving interprocess data transfer overhead system calls context switches becomes evident message size becomes larger tmpi constant 2mb bandwidth advantage mpich due saving data copying round trip time pingpong short message tmpi transfer rate b pingpong long message tmpi figure 10 intraclusternode pingpong performance two versions mpich used mpich shared memory mpich1 mpich without shared memory access impact shared memory thread processbased mpi systems figure 10 shows pingpong performance two mpi nodes cluster node compare performance three mpi systems tmpi mpich shared memory mpich1 mpich without using shared memory mpich2 evident ignoring underlying sharedmemory architecture yields much worse performance mpich2 comparing two systems tmpis advantage mpich1 mainly comes saving intermediate memory copying long messages fast synchronization among threads short messages result tmpi performance nearly doubled mpich shared memory note tmpi mpich1s performance drops reaching peak transfer rate likely caused underlying memory contention oneway message pipelining second benchmark simple oneway sendrecv test sender keeps sending messages receiver bench mark examine impact synchronization among mpi nodes compare average time takes sender complete send operation short messages still use transfer rate metrics large messages message size bytes single op time oneway sendrecv short message tmpi mpich message size kb transfer rate b oneway sendrecv long message tmpi mpich figure oneway sendrecv performance figure 11 shows oneway sendrecv performance two mpi nodes dierent cluster nodes theoretically speak ing thread processbased mpi implementations yield similar performance short messages average time send operation equal single trip time divided number outstanding messages fly basically limited network bandwidth however mentioned processbased mpi implementation interclusternode message passing needs travel local daemon remote daemon time data need copied daemons local buer unless sender receiver daemons precisely synchronized either buer could full empty cause stall pipeline even though might still bandwidth available seen figure 11 mpich performance unstable message size small due diculty synchronization among processes message size becomes large fewer outstanding messages performance less sensitive synchronization additionally also see tmpi 30s advantage mpich short messages 2mb bandwidth advantage large messages due saving extra data copying needed processbased mpi system comparison repeat oneway sendrecv test two mpi nodes cluster node result shown figure 12 compare among three mpi systems notation figure 10 expected mpich1 performs almost identical tmpi small messages slightly poorer tmpi large messages intermediate daemon processes along data path either system cost extra data copying mpich1 amortized among multiple outstanding requests hand mpich2 shows irregular behavior certain range message sizes note figure 12 use dierent scale accommodate performance curve mpich2 message size 800 bytes single send operation takes 34ms complete message size goes beyond op time tmpi message size bytes oneway sendrecv short message tmpi op time transfer rate b oneway sendrecv long message tmpi figure 12 intraclusternode oneway sendrecv performance two versions mpich used mpich shared memory mpich1 mpich without shared memory mpich2 falls normal range 50s 150s able identify exact source problem think might something resource contentions os level regardless glitch performance mpich2 much worse two mpi systems due ignorance underlying shared memory 42 microbenchmark performance collective communication compare performance collective communication primitives run three microbenchmarks calls mpireduce mpibcast mpiallreduce number times respectively compare average time operation data volume involved benchmarks small cost mainly comes synchronization run benchmarks three different settings 4 mpi nodes cluster node 41 nodes scattered 4 dierent cluster nodes 14 nodes scattered 4 mpi nodes 44 mpibcast mpireduce use three dierent variations regard root nodes dierent iterations test always stay rotate among mpi nodes rotate repeat using root couple times root shift combo number conclusions drawn experiment results shown figure 13 1 cases mpich2 performs worst among three mpi systems except 14 case mpich1 mpich2 performance almost signifies importance taking advantage shared memory mpi system smp cluster environment 2 tmpi 71 times faster mpibcast 77 times faster mpireduce mpich1 exploits shared memory within smp among factors including address space sharing hierarchy aware algorithms performance gain mainly comes separation collective pointtopoint communication channels theoretically speaking mpibcast mpireduce operation always faster mpiallreduce operation however unit mpi reduce mpi bcast mpi allreduce node distr root tmpi mpich1 mpich2 tmpi mpich1 mpich2 tmpi mpich1 mpich2 rotate rotate rotate combo16125322242856656622204102462054 736 1412 19914 figure 13 collective communication performance numbers shown table average time operation run benchmark three mpi systems tmpi mpich shared memory mpich1 mpich without shared memory mpich2 mpi reduce mpi bcast test cases root always root rotates among mpi nodes rotate fix root number times rotate combo notation b used node distribution means use b cluster nodes mpi nodes experiments show cases mpich mpibcast mpireduce operation performs worse mpiallreduce operation anomaly caused mpichs design collective communication top pointtopoint communication messages collective communication still go daemons get stored message queues matched traversing queues many outstanding requests cost queue operations become expensive due contentions daemons could become bottleneck mpiallreduce test suer problem mpi nodes synchronized one outstanding request hand separating communication channels pointtopoint collective com munication tmpi show anomaly 3 tmpi root tests perform much better rotating root tests 14 44 cases means tmpi take better advantage message pipelining due address space sharing elimination intermediate daemons 4 figure also evidences advantage hierarchy aware communication design example mpibcast test 44 performance roughly equal summation 41 case 14 case since tmpi broadcast 44 case 14 broadcast followed 41 broadcast individual cluster node hand without using twolevel spanning tree mpich1s 44 performance 1060 worse summation 41 case 14 case similar conclusions also hold mpireduce mpiallreduce 43 macrobenchmark performance section use two application kernel benchmarks access eectiveness tmpi optimizations kernel benchmarks use matrixmultiplication mm gaussianelimination ge perform computationintensive linear algebra computation mm consists mostly mpibsend mpirecv ge mpibcast run mm 1 16 mpi nodes ge 1 24 mpi nodes detailed node distribution shown figure 14 mm ge 9 33 4 22 figure 14 distribution mpi nodes b means use b cluster nodes mpi nodes ensure number cluster nodes number mpi nodes cluster node decrease increase total number mpi nodes compare tmpi mpich uses shared memory smp performance results depicted figure 15 see number mpi nodes small 4 tmpi mpich perform similarly however number mpi nodes becomes large cluster nodes involved tmpi shows better scalability mpich mm tmpi constant 150mflop advantage mpich mainly comes saving intermediate copying ge neither system keep linear speedup mpich performance even degradates reaching peak 12 mpi nodes tmpi outperforms mpich 100 4 6 cluster nodes involved indeed verifies advantages tmpi smp cluster environment reason tmpi gains much advantage ge case compared mm case ge calls mpi broadcasting function mm uses point topoint communication demonstrated previous section tmpi outperforms mpich substantially collective communication 5 concluding remarks paper presented design implementation threadbased mpi system smp clusters contributions include novel network device abstraction interface tailored threaded mpi execution smp clusters hierarchyaware communication proposed number optimization techniques including separation number mpi nodes mflop matrix multiplication tmpi mpich 25100300500700900number mpi nodes mflop b gaussian elimination tmpi mpich figure 15 macrobenchmark performance pointtopoint collective communication channels adaptive buering eventdriven synchronization taking advantage multithreading micro macro benchmark testing experiments show tmpi outperform mpich substantially noted tmpi optimization targeted class c programs mpich designed general mpi programs experiments confirm even cluster environment internode network latency relatively high exploiting threadbased mpi execution smp deliver substantial performance gains global communication fast lightweight syn chronization experiments focus dedicated cluster future work study performance multiprogrammed environment threadbased synchronization may achieve performance gain 6 acknowledgements work supported part nsf acir0082666 acir0086061 ccr9702640 would like thank lingkun chu help cluster administration would also like thank kai shen anonymous referees valuable comments 7 r case networks workstations beowulf parallel workstation scientific computation lam open cluster environment mpi parallel computer architecture hardwaresoftware approach tpvm distributed concurrent computing lightweight processes abstract device definition support implementation highlevel pointtopoint message passing interface delivering network performance numerical applications mpis collective communication operations clustered wide area systems mpifm higher performance mpi workstation clusters httpwwwlscndedulam forum year1999year httpwww mpisim using parallel simulation evaluate mpi programs adaptive twolevel thread management fast mpi execution shared memory machines optimization mpi collectives clusters largescale smps proceedings acmieee supercomputing 99 program transformation runtime support threaded mpi execution shared memory machines httpnowcsberkeleyedufastcommmpi lpvm step towards multithread pvm tr highperformance portable implementation mpi message passing interface standard mpifm mpisim magpie optimization mpi collectives clusters largescale smps adaptive twolevel thread management fast mpi execution shared memory machines program transformation runtime support threaded mpi execution sharedmemory machines mpistart multiprotocol active messages cluster smps parallel computer architecture ctr jian ke martin burtscher evan speight runtime compression mpi messanes improve performance scalability parallel applications proceedings 2004 acmieee conference supercomputing p59 november 0612 2004 rohit fernandes keshav pingali paul stodghill mobile mpi programs computational grids proceedings eleventh acm sigplan symposium principles practice parallel programming march 2931 2006 new york new york usa lingkun chu hong tang tao yang kai shen optimizing data aggregation clusterbased internet services acm sigplan notices v38 n10 october weirong zhu yanwei niu guang r gao performance portability earth case study across several parallel architectures cluster computing v10 n2 p115126 june 2007