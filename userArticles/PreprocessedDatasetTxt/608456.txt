statistical approach case based reasoning application breast cancer data given large set problems individual solutions case based reasoning seeks solve new problem referring solution problem similar new problem crucial case based reasoning decision problem closely matches given new problem new method proposed deciding question basic idea define family distance functions use distance functions parameters local averaging regression estimates final result distance function chosen resulting estimate optimal respect certain error measure used regression estimation method illustrated simulations applied breast cancer data b introduction assume one interested solution problem latter described number observable variables necessary variables determine solution completely assume correlation observable variables solution furthermore assume list problems type available values observable variables solutions known instead categories problemsolution one may also think premiseconclusion causeeffect current statefinal result concretely health conditionobserved survival time case based reasoning seeks solve new problem refering solution problem similar new problem basic assumption solution problem data base similar new problem close unknown solution new problem different rule based reasoning knowledge represented rules rather data base built previous experience phrases case based reasoning rule based reasoning coined field artificial intelligence see eg menachem kolodner 1992 crucial case based reasoning decision cases closely match given new case article propose new method deciding question basic idea define family distance functions use distance functions parameters local averaging regression estimates final outcome choose distance function resulting estimate optimal respect certain error measure used regression estimation article apply case based reasoning context prediction survival times breast cancer patients treated different therapies therapy list cases given includes observed survival time variables describing case examples latter size primary tumor number affected lymph nodes menopausal status categorial variables part tumor classification system tnm lists one selects cases similar given new case physician tries gain information appropriate therapy new patient considering therapy final result statistical approach case based reasoning 3 cases naive approach decide cases closely match new case use cases values variables new case unfortunately number observable variables large usually none cases therefore naive approach general useful another approach used context predicting survival times breast cancer patients mariuzzi et al 1997 range observable variable divided four quartiles values variables coded 1 2 3 4 according quartile belong distance observable variables x 1 coded l defined l cases chosen respect distance function closely new case main drawback distance reflect possibly different influence individual variable final result instance values x 1 might influence survival time much value x 2 article propose new method determine cases data base closely match new case section 2 give short introduction nonparametric regression proposed method described detail section 3 illustrated simulated data section 4 applied breast cancer data section 5 2 nonparametric regression independent identically distributed random variables x r valued realvalued ey 2 1 regression analysis one wants predict observed x ie one wants find function r r x close closeness measured mean squared error one interested function 4 j dippon et al minimizes socalled l 2 risk efjm introduce regression function xg arbitrary measurable function r one z denotes distribution x therefore l 2 risk arbitrary function f close optimal value squared l 2 error optimal predictor depends distribution x applications distribution usually unknown thus unknown often possible observe independent copies based data nonparametric regression problem asks estimate mn l 2 error r jmn 21 local averaging estimates response variables rewritten 0 hence one consider sum function evaluated x random error zero mean motivates construct estimate mx averaging x close x hopefully mx close mx average ffl close zero local averaging estimate represented nonnegative weights sum one statistical approach case based reasoning 5 popular local averaging estimate nadarayawatson kernel estimate nadaraya 1964 watson 1964 weights hn hn r socalled kernel function socalled bandwidth hn often one uses spherical symmetric kernels k satisfy univariate kernel function r r denote k jxj euclidean norm x kernel functions one gets hn hn usually kernel functions chosen k0 0 socalled naive kernel used mx estimated average x ball radius h 1 center x general k r r eg gaussian kernel one uses weighted average estimate mx weight given close x 22 choice bandwidth choice bandwidth hn crucial kernel estimate components hn small weight close zero estimate determined induces high variance estimate hand components hn big far away x big weight x far away x even smooth mx might far away mx induces large error estimate 6 j dippon et al quality estimate important apply method chooses hn close optimal value depends usually unknown distribution x using data dn well known method tries crossvalidation described sequel information see hardle 1990 eg recall aim nonparametric regression construct mn l 2 risk small bandwidth kernel estimate chosen 2 minimal compared choices bandwidth application possible 2 depends unknown distribution x propose estimate l 2 risk 2 choose bandwidth minimizing estimated l 2 risk fixed function f r r l 2 risk estimated socalled empirical use 3 depends dn estimate 2 socalled resubstitution estimate optimistic estimate l 2 risk minimization leads estimates well adapted dn suitable predict new data independent dn avoided splitting data dn two parts learning testing data computing kernel estimate learning data choosing bandwidth empirical risk testing data minimal resulting bandwidth depends way data splitted drawback one wants use bandwidth kernel estimate uses whole data dn thus nothing way data splitted avoided repeating procedure several eg randomly chosen splits sample choosing bandwidth average empirical l 2 risk testing data minimal kfold crossvalidation splits chosen special deterministic way let 1 k n notational simplicity assume n k integer divide data k groups equal statistical approach case based reasoning 7 size n k denote set consisting groups except lth one nl data set nl bandwidth h 2 r construct kernel estimate mngamma n h x nl k l1ng k k l1ng k choose bandwidth thatk l1n l minimal use bandwidth h bandwidth hn kernel estimate 1 nfold crossvalidation denoted crossvalidation case nl whole sample minimized respect h 23 curse dimensionality large estimating regression function especially difficult reason case general possible densely pack space x finitely many sample points even sample size n large fact often referred curse dimensionality phrase due bellman 1961 illustrated example examples found friedman 1994 independent identically distributed r valued random variables x uniformly distributed hypercube 0 1 consider expected supremum norm distance x closest neighbor x 1 ae min oe kx ae min oe 8 j dippon et al thus z 1p ae min oe instance d1 10 1000 022 d1 20 10000 028 thus large even large sample size n supremum norm distance x closest neighbor sample close zero observe supremum norm distance two points sample always less equal one 3 basic idea section apply concepts nonparametric regression introduced previous section case based reasoning consider prediction final result case based reasoning regression estimation problem hence assume final result real valued random variable observable variables components r valued random variable applications often observable variables categorical random variables handle variables described section 5 recall aim case based reasoning determine cases given list closely match new case done defining distance function determines distance dx x two cases observable variables x x given distance function one define k similar cases new case k cases among whose distances new case x belongs k smallest occuring distances basic idea determine distance function define regression estimate depending distance function choose distance function minimizes estimate l 2 risk resulting regression estimate regression estimates use kernel estimates introduced previous section define distance function dh r theta r r dh statistical approach case based reasoning 9 kernel estimate written family distance functions psi corresponds family regresion estimates kernel function simulations section 4 application section 5 use gaussian kernel aim choose distance function corresponding regression estimate minimal l 2 risk already explained previous section possible l 2 risk depends unknown distribution x instead estimate l 2 risk crossvalidation choose distance function dh h 2 r estimated l 2 risk nh minimal method summarized follows estimate l 2 risk kernel estimate nh crossvalidation determine h 2 r estimated l 2 risk minimal compared choices h 2 r use corresponding distance function dh 31 subset selection seen previous section estimating regression function difficult dimension x large problem occurs every estimate hence kernel estimate use paper well way handle problem make assumptions underlying distibution eg assume regression function additive cf stone 1985 stone 1994 paper assume even large say 20 regression function mainly depends say 3 6 components x assumption holds distance function determined applying method small subset observable variables leads regression estimation problem small dimension x course applications know observable variables regression function mainly depends order check consider big small subsets observable variables apply method subsets choose subset via crossvalidation estimated l 2 risk optimal estimate minimal j dippon et al 32 simplification computation subset observable variables variable subset method described requires computation vector scaling factors leads multivariate minimization problem order avoid solving many minimization problems use following simplification first step determine observable variables univariate scaling n computing described optimal bandwidth univariate kernel estimate fitting data x yields scaling factors h 1 second step choose subset fi g dg distance function h r via crossvalidation estimated l 2 risk minimal respect h 2 r finally choose subset fi g via crossvalidation estimated l 2 risk corresponding optimal kernel estimate minimal observe minimization estimated l 2 risk nh h 2 r univariate minimization problem 33 robustification bandwidth estimation well known bandwidth selection crossvalidation often highly variable see simonoff 1996 authors suggested alternatives plugin methods claimed superior ordinary crossvalidation loader argues theoretical results support claims plugin methods depends sensitively pilot estimate bandwidth see ch 10 loader 1999 let nh kernel estimate bandwith h order robustify crossvalidation bandwidth selection given statistical approach case based reasoning 11 cv function cvh defined 4 suggest following heuristic rule specified idea behind rule following often graph cv function resembles valley possibly several local minima bottom flat bottom position global minimum seems accidental estimate middle valley appears less variable measure choose two parameters define level r pq dependence regression estimate equals mean responses fy coincides empirical variance 1 yng simulations first used choice might happen r pq sup hh0 cvh order avoid set r pq cvh values p q used paper robustification implies possibly dispense explaining fraction empirical variance fy g doesnt seem harmful since interested finding similarity neighborhoods prediction j dippon et al 4 application simulated data 41 simulated model let us consider defined 2 0 1 fixed constant model independent random variables x u 0 1 apparently third component x 3 influence small first component x 1 random vector x larger influence response second component x 2 words small constant regression function almost constant respect x 2 case constant respect x 3 figure 1 simulate realizations x independent copies x described subsections 32 33 2 f1 2 3g robustified estimate e h 0 optimal bandwidth h 0 univariate kernel estimator based sample computed crossvalidation significantly less 1 expect relation 1 furthermore corresponding estimated l 2 risks ascending order figure 2 model selection procedure defines different distance functions 0 1 3 given 5 distance function compute minimal estimated l 2 risk multivariate kernel estimator 6 respect h 0 consider distance function best estimated l 2 risk minimal inclusion component reduces estimated l 2 risk slightly distance function smaller set components slightly larger corresponding estimated l 2 risk preferred use resulting distance functions define neighborhoods statistical approach case based reasoning 1302061 component 1 x02061 component 2 x fig 1 graph regression function considered function first two components predictor variable x scatter plot simulated realizations x ffi 0 consider every point n x ffi similar x every point outside n x ffi sense realizations x k similar ones x whose distances belongs k smallest among 42 results simulations pair n parameters 2 f03 05 1g n 2 f100 200g simulation repeated 20 times different seeds generator producing pseudo random numbers discuss results simulations performed parameter set n 05 100 detail suggested section 3 compute bandwidths e h 1 0 one twenty runs procedure found 0 cases cv curves univariate regression estimates corresponding minimal value cv curve look 14 j dippon et al figure 2 furthermore optimal value h iand robustified value e h idiffer slightly however cases situation appears figure 3 smooths related e h iseem appropriate one twenty runs method fails detect first component stronger influence function values second component see figure 4 compare multivariate kernel estimates 6 distance functions selecting different subsets prediction variables compute minimum cvh 0 estimate cvh given 4 l 2 risk 6 compare ratios cvh 0 cv1 table 1 shows run subset selection procedure favors fx 1 x 2 g fx 1 g cases preferred gain small significant hence 20 runs choose subset fx 1 x 2 g relation e h 1 determines geometry neighborhoods used characterize similar cases parameter pair n 05 100 ratios computed bandwidths e h 1 turned 2 016 054 045 060 050 023 057 034 076 second row table 2 one extract minimum maximum median interquartile range ratios visualize variability resulting distance functions neighborhoods projected first two components plotted around center 05 parameter chosen way area sets equals 110 see figure 5 comparing results sample sizes indicates larger sample sizes lead less variable neighborhoods statistical approach case based reasoning 15 component 2 fig 2 determination univariate bandwidths e h 1 e h 2 e h 3for 6th simulation run left column crossvalidated l2 risk regression estimate ey jx depending bandwidth h optimal bandwidth h jand robustified bandwidth e h jare indicated tick marks within range x axis right column univariate kernel estimate ey jx using optimal bandwidth h idotted robustified bandwidth e h isolid 2 f1 2 3g finding curves related h iand e h ican hardly distinguished true simulated samples j dippon et al component 1 component 2 component 3 fig 3 determination univariate bandwidths e h 1 e h 2 e h 3for 3th simulation run left column crossvalidated l2 risk regression estimate ey jx depending bandwidth h optimal bandwidth h jand robustified bandwidth e h jare indicated tick marks within range x axis right column univariate kernel estimate ey jx using optimal bandwidth h idotted robustified bandwidth e h isolid 2 f1 2 3g despite fact bandwidths h iminimizes cv error criterion bandwidths useful compare dependency random variable sample robustified bandwidth e h iseems appropriate statistical approach case based reasoning 17 component 1 component 2 fig 4 determination univariate bandwidths e h 1 e h 2 e h 3for 11th simulation run left column crossvalidated l2 risk regression estimate ey jx depending bandwidth h optimal bandwidth h jand robustified bandwidth e h jare indicated tick marks within range xaxis right column univariate kernel estimate ey jx using optimal bandwidth h idotted robustified bandwidth e h isolid 2 f1 2 3g 20 samples suggested method fails detect first component stronger influence function values second component j dippon et al table 1 ratio cvh0cv1 estimated l2 risk multivariate kernel estimate specified set components parameters simulated model run selected subset 9 040 097 100 019 043 098 023 statistical approach case based reasoning 19 table 2 statistics ratios e h 1 e h 2each computed 20 simulation runs parameters statistics e h 1 e h 2a n min 1st quart median mean 3rd quart max 10 200 014 093 110 102 116 143 component 1 x componentof component 1 x componentof component 1 x componentof component 1 x componentof component 1 x componentof component 1 x componentof fig 5 plot show level lines regression function parameter 2 f03 05 1g cutted ellipsoidal neighborhoods around point 05 05 neighborhood set computed one simulated samples size contains 110th unit square j dippon et al 5 application breast cancer data compute distance function space covariates suggested section 3 determine given new breast cancer patient unknown survival time similar cases among patients database known censored survival time data made available robert boschkrankenhaus stuttgart germany collected years 1987 1991 followup 80 months cases described 10dimensional parameter vector consider nine first parameters predictor variables includes age diagnosis age years menopause status ms equals 1 2 pre post menopause respectively histological type breast cancer ht values number affected lymph nodes pn grouped four classes values size pt grouped four classes occurence metastases pm values 0 1 yes respectively grading tumor gr values f1 2 3g estrogene status es values 1 2 positive negative resp progesterone status ps values 1 2 positive negative resp last component parameter vector describes observed censored survival time ost years considered reponse variable many cases actual survival time cant observed since patient still alive end study patients withdrawal study hence observed survival time understood minimum actual survival time time elapsed date diagnosis date death censoring time c time date diagnosis date patient known alive approach estimated censored survival time instead complicated often unknown uncensored survival time order simplify problem hope simplification doesnt affect result much used estimate construct similarity neighborhoods rather estimate survival time function covariate vector latter compare carbonez et al 1995 age ost continuously distributed rvs pt pn gr ordered categorical rvs ms ht pm es ps nominal rvs values predictor variables allowed statistical approach case based reasoning 21 table 3 robustified bandwidths e h jfor univariate regression problems products 1 e h jtimes spread component j allow compare maximal influence component j distance function component age ms ht pt pn pm gr es ps missing assume covariate vector new patient z z covariate patient database fz related continuous ordered categorical rv define distance function j h j z j missing k z j l missingg otherwise related nominal rv define distance function j j z j x j z j missing z j x j z j missing described section 3 j 2 compute crossvalidation optimal 0 univariate regression estimates nh realization response variable figures 6 7 show cv function cv regression estimates related robustified estimate e h j 0 displayed table 3 range x covariate variable x define l 2 22 j dippon et al 50 100 150 2001182age observed survival time observed survival time 10 12 14 16 18 202610 126 observed survival time observed survival time pn observed survival time statistical approach case based reasoning 23 observed survival time observed survival time observed survival time 10 12 14 16 18 202610h ps observed survival time j dippon et al table 4 number l 2 covariates subset displayed possesses smallest estimated l2 risk l best subset cvh l 6 age pt pn pm es ps 07894 7 age ht pt pn pm es ps 07894 8 age ms ht pt pn pm es ps 07932 9 age ms ht pt pn pm gr es ps 08281 subset dg distance function h fixed positive number obtain multivariate regression estimate compute cv function cv function h 0 determine subset j l smallest global minimum cvh l related cv function table 4 shows results model selection step together table 4 scree plot figure 8 suggests choose distance function includes variables pn pm es adding fourth component relative improvement ratio cvh 4 cv1 compared cvh 3 cv1 less 005 hence propose use distance defined pn 071 pm 142 es 079 given new case covariate x compute r dx z z 0 according increasing values r 0 fz g fixed k 2 statistical approach case based reasoning 25 number components fig 8 scree plot l cvh l 9g subset fz database consists k cases similar new case respect distance history logs may help physician choosing appropriate therapy new patient 6 discussion often case nonparametric estimators multivariate setting suggested method deficiencies limitations instance assume random vector 26 j dippon et al takes values 0 0 1 0 0 1 1 1 probability 14 let defined 0 x 2 f0 0 1 1g 1 otherwise ey jx 1 far constant hence case proposed method fail adjusting socalled resubstitution estimate l 2 risk penalizing functions leads various bandwidth selection procedures generalized crossvalidation shibatas model selector akaikes information criterion akaikes finite prediction error rices see eg hardle 1990 hardle 1991 may used instead least squares crossvalidation criterion research improve regression estimate instance dimension reduction handled projection pursuit regression adapted find structures linear subspaces covariate space additionally fact censored observation times taken account application concerning survival times breast cancer patients influence chosen therapy ignored might lead underestimation influence known predictor variables reason choice therapy usually depends predictor variables therapy influence survival time isnt problem one data choice therapy independent predictor variables data exist predictors used requirement fulfilled new predictor unknown past considered unimportant therefore used choosing therapy distance function additionally based new predictor allows judge importance new predictor 7 acknowledgements research partly supported robert bosch foundation stuttgart grateful prof h walk stuttgart stimulating discussions readers wishing obtain breast cancer data splus code algorithms contact authors statistical approach case based reasoning 27 r adaptive control processes overview predictive learning function approximation theory pattern recognition applications applied nonparametric regression smoothing techniques implementations local regression likelihood estimating regression smoothing methods statistics additive regression nonparametric models use polynomial splines tensor products multivariate function estimation smooth regression analysis tr random approximations measures accuracy nonparametric curve estimation