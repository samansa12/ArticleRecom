profileguided code compression computers increasingly used contexts amount available memory limited becomes important devise techniques reduce memory footprint application programs leaving executable form paper describes approach applying data compression techniques reduce size infrequently executed portions program compressed code decompressed dynamically via software needed prior execution use data compression techniques increases amount code size reduction achieved application infrequently executed code limits runtime overhead due dynamic decompression use software decompression renders approach generally applicable without requiring specialized hardware code size reductions obtained depend threshold used determine code infrequently executed hence compressed low thresholds see size reductions 137 188 average set embedded applications without excessive runtime overhead b introduction recent years increasing trend towards incorporation computers wide variety devices palmtops telephones embedded controllers etc many devices amount memory available limited due considerations space weight power consumption price example widely used tms320c5x dsp processor texas instruments 64 kwords program memory executable code 23 time increasing desire use sophisticated software devices encryption software telephones speechimage processing software palmtops fault diagnosis software embedded processors etc since devices typically secondary storage application requires memory available able run makes desirable reduce applications runtime memory requirements instructions data memory footprint possible focus work reducing overall memory footprint reducing space required instructions intuition underlying work simple programs obey socalled 8020 rule states essence programs execution time spent small portion code see 17 corollary bulk programs code generally executed infrequently work aims exploiting aspect programs using compression techniques yield smaller compressed representations may require greater decompression effort runtime infrequently executed portions programs expectation increased compression infrequently executed code contribute significant improvement overall size reduction achieved concomitant increase decompression effort lead significant runtime penalty code affected infrequently executed apparently simple idea poses interesting implementation challenges requires nontrivial design decisions include management memory used hold decompressed functions discussed section 2 design effective com pressiondecompression scheme decompressor code small quick section 3 identification appropriate units compression decompression section 4 well optimizations improve overall performance system section 6 work combines aspects profiledirected optimization runtime code generationmodification program compression discuss related work section 8 call sites original compressed code decompressor call sites function offset table f runtime buffer 110 b compressed figure 1 code organization compression 2 basic approach 21 overview figure shows basic organization code system consider program three infrequently executed functions 1 f h shown figure 1a structure code compression shown figure 1b code functions replaced stub short sequence instruc tions invokes decompressor whose job decompress code function runtime buffer transfer control decompressed code function offset table specifies location within compressed code code given function starts stub compressed function passes argument decompressor index table argument indicated figure 1b label 0 1 etc edge stub decompressor decompressor uses argument index function offset table retrieve start address compressed code appropriate func tion start generating uncompressed executable code runtime buffer decompression stops decompressor encounters sentinel illegal instruction inserted end code function decompressor flushes instruction cache transfers control code generated runtime buffer decompressed function finishes execution returns caller usual way since control transfers stubs decompressor decompressor runtime buffer alter return address transmitted original call site special action necessary return decompressed function call site method partitions original program code two parts infrequently executed functions f g h placed compressed code part frequently executed functions remain nevercompressed part stub code manages control transfers compressed functions must also lie never compressed part important note comparing space usage original compressed programs latter must take account space occupied stubs decompressor function offset table compressed code runtime buffer never compressed original program code implementation uses notion function somewhat general usual connotation term source language programs discuss exactly constitutes func tion section 4 22 buffer management scheme described conceptually fairly straightforward fails mention several issues whose resolution determines performance important issue function calls compressed code suppose figure 1 code f contains call g since f compressed call site runtime buffer call executed described call stub g code g decompressed executed expected happens g returns return address points instruction following call f problem instructions f overwritten g decompressed return address points location runtime buffer contains gs code question address therefore function call executed runtime buffer guarantee correct code executed call returns answer question inextricably linked way choose manage runtime buffer following options buffer management 1 may simply avoid problem refusing compress function whose body contains function calls since may result function call within runtime buffer reject option severely limits amount code subjected compression 2 may choose ensure decompressed code function never overwritten function calls within body returned simplest way never discard decompressed code function case compressed code function decompressed oncethe first time calledwith subsequent calls bypassing decompressor entering decompressed code directly conceptually resembles behavior justintime compilers translate interpretable code native code 1 22 alternative discard decompressed code function longer call stack since point certain function called returned already approach taken lucco 19 though rather immediately discarding function execution caches function hope might reexecuted smalltalk80 system also extracts executable version function intermediate representation procedure first invoked 8 caches bsr ra g return f offset instruction entrya original entrystub decompress indexf 0 nevercompressed runtime stub list bsr ra decompress indexf 98 return br g97 entry runtime buffer instruction offset b transformed runtime createstub created figure 2 managing function calls runtime buffer executable code discards prevent system running memory main drawback approach runtime buffer must made large enough hold decompressed functions possibly coexist call stack worst case entire program resulting memory footprint includes space needed runtime buffer well stubs decompressor function offset table therefore bigger original program approach therefore suitable limitedmemory devices 3 decompressed function f calls function g within runtime buffer may choose allow decompressor overwrite fs code within buffer approach used implementation benefit need runtime buffer large enough hold code largest compressed function pointed however means call g returns runtime buffer may longer hold correct instructions return problem solved ensure code f restored runtime buffer point callee g returns point control transferred caller f discuss done suppose function f within runtime buffer calls compressed function g scheme causes decompressor overwrite fs code buffer gs code correctness restore fs code buffer call g returns control transferred appropriate instruction within f since dont additional storage area fs code could cached restoring fs code runtime buffer requires decompressed means control returns g must first diverted decompressor decompress f transfer control decompressor must also given additional argument specifying control transferred decompressed function since program may reenter f instruction entry point one option create stub compile time contains function call g followed code call decompressor restore f runtime buffer transfer control instruction fs call g stub obviously cannot placed runtime buffer since may overwritten must placed nevercompressed portion program since every call compressed function requires stub restore stubs amount large fraction final executables size eg compress code never executed profiling create restore stubs occupy 13 average programs 20 nevercompressed code compress code accounts 1 instructions executed profiling average percentage rises 27 rather creating restore stubs compile time instead create runtime g called temporary restore stub exists g returns transfer g prefaced code generates restore stub makes return address original call point stub unconditional jump branch made g every control transfer compressed code created restore stub would effect maintaining call stack calls compressed code compressed code recursive could require arbitrarily large amount additional space instead create one restore stub particular call site compressed code maintain usage count restore stub determine stub longer needed asked create restore stub first check see stub call site already exists increase usage count use address return address otherwise create new restore stub usage count equal 1 effect implements simple reference countbased garbage collection scheme restore stubs text area memory program conceptually consists three parts nevercompressed code runtime stub list runtime decompression buffer figure 2b return g restore stub invokes decompressor recognizes called restore stub decrements stubs usage count restores f runtime buffer transfers control appropriate instruction runtime scheme never creates restore stubs compiletime scheme though require additional 8 bytes per stub order maintain count fact maximum number restore stubs exist one time test suite 9 aggressive profile threshold code considered compression accounts 1 total dynamic instruction count profiled program see section 5 figure illustrates done figure 2a shows function f whose body contains function call callsite cs0 calls g instruction bsr r label puts address next instruction return address register r branches label callsite cs0 offset 96 within body f relative beginning fs code return address passes callee following instruction offset 97 figure 2b shows result transforming code decompressor called call g returns function call g cs0 replaced function call createstub using return address register ra createstub creates restore stub call site uses existing restore stub call site exists changes ra contain stubs address transfers control unconditional branch offset 97 transfers control g note single original instruction bsr becomes two instructions runtime buffer save space compressed code two instructions created decompressor single bsr ra g filling runtime buffer g returns instructions restore stub executed causes decompressor invoked argument pair indexf 98 indexf fs index within function offset table 98 offset within fs code control transferred decompression overall effect control returns function call fs code decompressed control transferred instruction following function call original code important note scheme described call stack original compressed program exactly size point programs execution fact need modify return sequence function function g may called either runtime buffer nevercompressed code general may call sites call site nevercompressed function createstub invoked g returns instruction following call instruction usual way call site compressed code return address passed g corresponding restore stub control transfers stub g returns hard see fact control transfers happen correctly regardless g uses return address passed example g may save address environment entry restore exit keep register leaf function pass return address function tailcall optimization carried cases control transfers longjmp function may returned without corresponding call means usage count callsites restore stub may inaccurate even worse restore stub may longer exist reason functions call setjmp compressed 23 decompressor interface decompressor invoked two arguments index function offset table indicating function decompressed offset runtime buffer indicating location runtime buffer control transferred decom pression rather pass arguments decompressor register put dummy instruction called tag follows call decompressor low 16 bits contain offset high 16 bits function index since decompressor never returns caller instead transfers control function decompresses runtime buffer instruction never executed however access via return address set call decompressor various registers may used return address register call decompressor restore stub register used original call instruction used guaranteed free entry stub free register register free push value register ra use ra restore end decompressor decompressor however must know register contains return address called accomplish giving decompressor multiple entry points one per possible return address register entry point register r pushes r onto stack jumps body decompressor decompressor knows return address top stack decompressor 1 saves registers use stack 2 places instruction start runtime buffer unconditionally jumps offset provided tag 3 fills rest runtime buffer decompressing function indicated tag 4 restores saved registers 5 unconditionally jumps start runtime buffer immediately jumps appropriate offset creating unconditional jump instruction runtime buffer avoid need register control transfer end decompressor offset within runtime buffer insert one instruction jump instruction sets return register address restore stub creating stub restores ra entry stub free register note createstub decompress contained function saves multiple entry points one per possible return address register two functions easy determine return address whether function called inside runtime buffer act cre atestub outside act decompress 3 compression decompression primary consideration choosing compression scheme minimizing size compressed functions would like achieve good compression even short sequences instructions since functions may want compress small second consideration size decompressor since becomes part memory footprint program fi nally decompressor must fast since invoked every time control transfers compressed function already runtime buffer since functions choose compress low execution count dont expect invoke decompressor often execution faster decompressor ever means tolerate compression frequently executed code turn leads greater compression opportunities compression technique use simplified version splitting streams approach 9 data compressed consists sequence machine code instructions instruction contains opcode field several operand fields classified type example test platform branch instruction consists 6bit opcode field 5bit register field 21bit displacement field 2 order compress sequence instruc tions first split sequence separate streams values one per field type extracting field type sequence field values type successive instructions compress stream separately test platform split instructions 15 streams note instruction contains field types reconstruct instruction sequence decompress opcode opcode stream tells us field types instruction obtain field values corresponding streams repeat process opcode stream empty compress stream encoding field value stream using huffman code optimal stream twopass process first pass calculates frequency field values constructs huffman code second pass encodes values using code since huffman code designed stream must stored along encoded stream order permit decompression use variant huffman encoding called canonical huffman encoding permits fast decompression yet uses little memory 5 like huffman code canonical huffman code optimal characterbased code characters case field val ues fact length canonical huffman codeword character length huffman codeword character thus number n codewords length encodings codewords length canonical huffman code n ibit numbers b 2 example n 28 codewords notice codewords completely determined given number codewords length ie n store n characters encoded array ordered codeword value advantage canonical huffman code codeword rapidly decoded using arrays n dj v b n return compressed program consists codeword sequence code representation array n value list array dj stream fact since every instruction begins opcode completely specifies remaining fields struction merge codeword sequences individual streams one sequence simply interpret first bits codeword sequence using huffman code opcode stream use decoded opcode specify appropriate huffman codes use remaining fields example decoding branch instruction would read codeword sequence using first opcode code register code finally displacement code total space required compressed program approximately 66 original size achieve somewhat better compression streams using movetofront coding prior huffman coding undesirable affect increasing code size running time decompression algorithm approaches decompress larger parts instruction multiple instructions one decompression operation may result better faster decompres sion approaches typically require complex decompression algorithm one requires space data structures 4 compressible regions functions use unit compression decompression may agree functions specified program often case programspecified function contain frequentlyexecuted code compressed infrequentlyexecuted cold code compressed unit compression programspecified function entire function cannot compressed contains code cannot considered compression result amount code available compression may significantly less total amount cold code program addition runtime buffer must large enough hold largest decompressed function single large function may often account significant fraction cold code program runtime buffer large enough contain function offset spacesavings due compression address issue create functions arbitrary code regions allow regions compressed decompressed means control transfers compressed region code may longer follow callreturn model func tions example may contend conditional branch goes one compressed region code another different compressed region since runtime buffer holds code one region time branch one region another must go stub invokes decom pressor terrible complication compressed region might multiple entry points requires entry stub ways original function instance function calls within compressed region still handled discussed section 2 face problem choose regions com press want regions reasonably small runtime buffer small yet want control transfers different regions number entry stubs small optimization problem input control flow graph e program vertex b represents basic block size jbj equal number instructions block edge b represents control transfer b addition input specifies subset u vertices compressed output partition subset compressible vertices u regions following cost minimized nevercompressed code offset table jbjg runtime buffer sr size region r compression set blocks requiring entry stub ie 62 r ig constant 2 number words required entry stub buffer size bound080100120 normalized code size c c c c e e e e f f buffer size bound080100120 normalized code size c c c c c e e e f f f buffer size bound080100120 normalized code size c c c c c e e e e e f c buffer size bound080100 normalized code mean key figure 3 effect buffer size bound code size c number external function calls within r decompressor creates additional instruction call note included size restore stub list calculat ing size even given partition nphard problem practice cannot afford calculate sr possible regions r assume fixed compression factor applies regions ie b2r jbj unfortunately resulting simplified problem nphard partition reduces resort simple heuristic choose compressible regions first decide basic blocks compressed criteria decision discussed detail section 5 also fix upper bound k size runtime buffer current implementation uses empirically chosen value bytes determined described create initial set regions performing depthfirst search control flow graph limit depthfirst search produces tree contains k instructions composed compressible blocks single function profitable compress set blocks tree make tree compressible region otherwise mark root tree never reinitiate depthfirst search though might visited subsequent depthfirst search starting different block continue depthfirst search compressible blocks visited decide region containing instructions profitable compress compare 1 number instructions saved compressing region number instructions e added entry stubs e 1 region profitable compress mentioned use empirically determined upper bound k size runtime buffer guide partitioning functions compressible regions choose small value k get large number small compressible gions correspondingly large number entry stubs function offset table entries tend offset space benefits small runtime buffer resulting large overall memory footprint value k large get smaller number distinct compressible regions function offset table entries savings offset space required runtime buffer empirical observations variation overall code size k varied shown figure 3 three different thresholds cold code well mean thresholds values yield similar curves seen benchmarks least smallest overall code size obtained prefer latter value larger runtime buffer means get somewhat larger regions correspondingly fewer interregion control transfers results fewer calls decompressor runtime yields somewhat better performance partition obtained depthfirst search practice typically contains many small regions partly due presence small functions user library code partly due frag mentation incurs overheads two sources first compressible region requires word function offset table second interregion control transfers require additional code form entry restore stubs invoke decompressor overheads reduced packing several small regions single larger one still contains k instructions pack regions start set regions created depthfirst search repeatedly merge pair yields savings without exceeding instruction bound k pairs exist pair regions fr r 0 g r swapped r 0 following save entry stub every basic threshold010030050070090fraction code cold code compressible code figure 4 amount cold compressible code normal ized block region r incoming edges r 0 possibly r region every call region r r 0 save restore stub may also save jump instruction every fallthrough edge region r r 0 principle packing regions way involves spacetime tradeoff packing saves space since region decompressed entirety execution resulting larger regions incur greater decompression cost runtime however given infrequentlyexecuted code subjected runtime de compression actual increase runtime cost significant 5 identifying cold code discussion far implicitly assumed identified portions program cold therefore candidates compression determination portions program cold carried follows start threshold 00 10 specifies maximum fraction total number instructions executed runtime according execution profile program cold code account thus means code identified cold account 25 total number instructions executed program runtime let weight basic block number instructions block multiplied execution frequency ie blocks contribution total number instructions executed runtime let tot instr ct total number instructions executed program given execution profile given value consider basic blocks b program increasing order execution frequency determine largest execution frequency n bfreqbn weightb tot instr ct basic block whose execution frequency n considered cold figure 4 shows geometric mean relative amount cold compressible code programs different thresholds seen figure 4 amount cold code varies 73 total code average threshold code never executed considered cold 94 cold code accounts 1 total number instructions executed program runtime 100 however cold code compressed amount compressible code varies 69 program 00 90 001 96 10 reason cold code compressible given threshold discussed section 4 region code may considered compression even cold profitable 6 optimizations 61 buffersafe functions discussed earlier function calls within compressed code cause creation execution restore stub additional instruction runtime buffer overhead avoided callee buffersafe ie code might call invoke decompressor callee buffersafe runtime buffer overwritten callees execution return address passed callee simply address instruction following call instruction runtime buffer need create stub call decompress caller call returns words call within compressed region buffersafe function left unchanged two benefits space cost associated restore stub additional runtime buffer instruction eliminated time cost decompressing caller return call avoided use straightforward iterative analysis identify buffersafe functions first mark regions clearly buffersafe ie identified compressible contain indirect function calls whose possible targets may include nonbuffersafe regions information propagated iteratively regions r region marked nonbuffersafe r 0 region control enter reither function call via branch operationthen r 0 also marked nonbuffersafe repeated new region marked way region left unmarked end process buffersafe benchmarks tested analysis identifies average 125 compressible regions buffersafe gsm g721 enc benchmarks largest proportion buffersafe regions little 20 19 respectively compressible regions inferred buffersafe 62 unswitching code region contains indirect jumps jump table necessary process code ensure runtime control transfers within decompressed code runtime buffer carried correctly two choices either update addresses jump table point runtime buffer locations corresponding targets would reside region decompressed unswitch region use series conditional branches instead indirect jump table note either case know size jump table context binary rewriting implementation may always possible unable determine extent jump table block containing indirect jump table set possible targets jump must excluded compression sake sim plicity current implementation uses unswitching eliminate indirect jump space jump table reclaimed 7 experimental results ideas implemented form binaryrewriting tool called squash based squeeze compactor compaq alpha binaries 7 squeeze based alto postlinktime code optimizer 20 squeeze alone compacts binaries already program profiling input timing input file name size kb file name size kb adpcm clintonpcm 2950 mlk ihaveadreampcm 14752 clintonadpcm 738 mlk ihaveadreamadpcm 1821 lenatif 2624 dec clintong721 738 mlk ihaveadreamg721 3688 gsm clintonpcm 2950 mlk ihaveadreampcm 14752 jpeg dec testimgjpg 58 roses17jpg 251 jpeg end testimgppm 1015 roses17ppm 6811 pgp compressionps 7172 ti320usermanualps 84566 rasta ex5 c1wav 170 phonepcmlewav 837 figure 5 inputs used profiling timing runs b c e f code size reduction thresholds key figure reduction due profileguided code compression different thresholds space optimized 30 average squash using runtime decompression scheme outlined paper compacts squeezed binaries another 1419 average evaluate work used eleven embedded applications mediabench benchmark suite available wwwcsucla eduleecmediabench adpcm speech compression decompression epic image data compression util dec g721 enc reference implementations sun microsystems ccitt g721 voice compression decoder encoder gsm implementation european gsm 0610 provisional standard fullrate speech transcoding jpeg dec jpeg enc implement jpeg image decompression compression mpeg2dec mpeg2enc implement mpeg2 decoding encoding respectively pgp popular cryptographic encryptiondecryption program rasta speechanalysis program inputs used obtain execution profiles used guide code compression well used evaluate execution speed figure 7b described figure 5 profiling inputs refer used obtain execution profiles used carry compression timing inputs refer inputs used generate execution time data uncompressed compressed code details benchmarks given appendix programs compiled using vendorsupplied c compiler cc v52036 invoked cc o1 additional flags instructing linker retain relocation information produce statically linked executables 2 vendorsupplied compiler cc produces compact code optimization level o1 carries local optimizations recognition common subexpres sions global optimizations including code motion strength reduc tion test replacement split lifetime analysis code schedul 2 requirement statically linked executables result fact alto relies presence relocation information distinguish addresses data tru64 unix linker ld refuses retain relocation information executables statically linked adpcm epic geom code size reduction 168thresholds000001a code size adpcm epic geom execution time normalized 100 104thresholds000001b execution time figure 7 effect profileguided compression code size execution time ing sizeincreasing optimizations inlining integer multiplication division expansion using shifts loop unrolling code replication eliminate branches programs compacted using squeeze squeeze eliminates redundant unreachable dead code performs interprocedural strength reduction constant propagation replaces multiple similar program fragments function calls single representative function ie performs procedural abstraction squeeze effective compacting code start executable produced cc o1 remove unreachable code noop instructions squeeze reduce number instructions remain approximately 30 average remaining instructions given squash along profile information obtained running original executable sample inputs obtain execution counts programs basic blocks squash produces executable contains nevercompressed code entry stubs function offset table runtime decompressor compressed code buffer used hold dynamically generated stubs runtime buffer space included code size measurement squashed executables figure 6 shows amount code size reduction obtained using profileguided compression varies cold code threshold code never executed considered cold case see size reductions ranging 90 g721 enc 221 pgp mean reduction 137 size reductions obtained increase increase makes code available compression thus reductions ranging 121 ad pcm 237 pgp mean reduction 168 extreme considered cold code size reductions range 215 adpcm 318 pgp mean 265 noteworthy much size reductions obtained using quite low thresholds rate reduction code size increases quite small ex ample increasing five orders magnitude 000001 10 yields additional 10 benefit code size reduction however increased runtime overhead associated repeated dynamic decompression code quickly begins make felt experience set programs others indicates beyond 00001 runtime overhead becomes quite noticeable obtain reasonable balance code size improvements execution speed focus values 000005 execution time data obtained workstation 667 mhz compaq alpha 21264 ev67 processor split twoway setassociative primary cache 64 kbytes instruction data cache 512 mb main memory running tru64 unix case execution time obtained smallest 10 runs executable otherwise unloaded system figure 7 examines performance programs terms size speed ranging 00 000005 final set bars figure shows mean values code size reduction execution time respectively relative squeezed code number top bar gives actual value geometric mean case seen low coldcode thresholds runtime overhead incurred profileguided code compression small 00 compressed code speed average code without compression incur average execution time overhead 4 average overhead 24 given corresponding size reductions obtainedranging 137 188these overheads seem unreasonably high note reductions size top roughly 30 code size reduction obtain using prior work code compaction important note context execution speed compressed code suffer dramatically timing inputs ie inputs used measure actual execution speed cause large number calls decompressor happen two rea sons first code fragment cold profile may occur cycle either loop within procedure interprocedural cycle arising recursion second region partitioning algorithm described section 4 may split loop multiple regions either case loop cycle executed repeatedly timing inputs repeated code decompression significant adverse effect execution speed example first situation occurs specint95 benchmark li interprocedural cycle never executed pro file executed many times timing input example second situation occurs benchmark mpeg2dec runtime buffer size bound k small eg 8 related work work combines aspects profiledirected optimization runtime code generationmodification program compression dynamic optimization systems dynamo 4 collect profile information use generate modify code runtime systems designed minimize memory footprint executable rather decrease execution time tend focus optimization effort hot code whereas compression efforts aggressive cold code closely related work hoogerbrugge et al compile cold code interpreted byte code stackbased machine 14 contrast use huffman coding compress cold code dynamically uncompress compressed code runtime needed thus system incur memory cost bytecode interpreter significant amount work architectural extensions execution compressed code examples include thumb arm processors 3 codepack powerpc processors 15 mips16 mips processors 16 special hardware support used expand compressed instruction executable form prior execution approach advantage incurring space overheads control stubs time overheads software decompression requirement special hardware limits general applicability lefurgy et al describe hybrid system decompression carried mostly software assistance special hardware instructions allow direct manipulation instruction cache 18 decompression carried granularity individual cache lines previous work program compression explored compressibility wide range program representations source programs intermediate representations machine codes etc 24 resulting compressed form either must decompressed perhaps compiled execution 9 10 11 executed interpreted 13 21 without decompression 6 12 first method results smaller compressed representation second requires time space overhead decompression execution avoid requiring large amount additional space place decompressed code choosing decompress small pieces code demand using single small runtime buffer similar techniques partial decompression decompressiononthefly used similar situations 9 19 techniques require altering runtime operation hardware computer earlier work code compression yield smaller executables treated executable program simple linear sequence instructions used suffix tree construction identify repeated code fragments could abstracted functions 6 12 recently shown possible obtain results good better using aggressive interprocedural sizereducing compiler optimizations applied control flow graph program instead using suffixtree construction linear sequence instructions 7 9 conclusions future work described approach use execution profiles guide code compression infrequently executed code compressed using data compression techniques produce compact representations decompressed dynamically prior execution needed several benefits use powerful compression techniques allows significant improvements amount code size reduction achieved low execution frequency thresholds runtime overheads small finally special hardware support needed runtime decompression compressed code experimental results indicate proper choice cold code thresholds approach effective reducing memory footprint programs without significantly compromising execution speed see code size reductions 137 average set embedded ap plications relative code size obtained using prior work code compaction 7 concomitant effect execution time ranges slight speedup 00 27 slowdown average currently looking number ways enhance work include algorithms compression decompression well algorithms constructing compressible regions within program acknowledgements gratefully acknowledge loan equipment karen flat richard flower robert muth compaq corp 10 r effective code generation justintime java compiler alpha architecture handbook transparent runtime optimization system managing gigabytes compressing indexing documents images enhanced code compression embedded risc processors compiler techniques code compaction efficient implementation smalltalk80 system code compression adaptive compression syntax trees iterative dynamic code optimization two basic technologies mobileobject systems binaries custom instruction sets code compression code compression system based pipelined interpreters decompression core powerpc empirical study fortran programs reducing code size runtime decompression optimizing ansi c interpreter superoperators overview ibm java justintime compiler texas instruments inc code compaction bibliography tr optimizing ansi c interpreter superoperators code compression binaries fast effective code generation justintime java compiler enhanced code compression embedded risc processors code compression system based pipelined interpreters compiler techniques code compaction dictionary program compression alto analyzing compressing assembly code managing gigabytes adaptive compression syntax trees iterative dynamic code optimization efficient implementation smalltalk80 system ctr saumya debray william evans cold code decompression runtime communications acm v46 n8 august arvind krishnaswamy rajiv gupta dynamic coalescing 16bit instructions acm transactions embedded computing systems tecs v4 n1 p337 february 2005 stacey shogan bruce r childers compact binaries code compression software dynamic translator proceedings conference design automation test europe p21052 february 1620 2004 yuan xie wayne wolf haris lekatsas profiledriven selective code compression proceedings conference design automation test europe p10462 march 0307 karine heydemann francois bodin henripierre charles softwareonly compression system tradingoffs performance code size proceedings 2005 workshop software compilers embedded systems p2736 september 29october 01 2005 dallas texas e wanderley netto r azevedo p centoducatte g araujo multiprofile based code compression proceedings 41st annual conference design automation june 0711 2004 san diego ca usa shaoyang wang rongguey chang code size reduction compressing repeated instruction sequences journal supercomputing v40 n3 p319331 june 2007 israel waldman shlomit pinter profiledriven compression scheme embedded systems proceedings 3rd conference computing frontiers may 0305 2006 ischia italy john gilbert david abrahamson adaptive object code compression proceedings 2006 international conference compilers architecture synthesis embedded systems october 2225 2006 seoul korea rajeev kumar amit gupta b pankaj mrinmoy ghosh p p chakrabarti postcompilation optimization multiple gains pattern matching acm sigplan notices v40 n12 december 2005 taweesup apiwattanapong mary jean harrold selective path profiling acm sigsoft software engineering notes v28 n1 january jeremy lau stefan schoenmackers timothy sherwood brad calder reducing code size echo instructions proceedings international conference compilers architecture synthesis embedded systems october 30november 01 2003 san jose california usa shukang zhou bruce r childers mary lou soffa planning code buffer management distributed virtual execution environments proceedings 1st acmusenix international conference virtual execution environments june 1112 2005 chicago il usa mario latendresse marc feeley generation fast interpreters huffman compressed bytecode proceedings workshop interpreters virtual machines emulators p3240 june 1212 2003 san diego california hongxu cai zhong shao alexander vaynberg certified selfmodifying code acm sigplan notices v42 n6 june 2007 haifeng john trimble somu perianayagam saumya debray gregory andrews code compaction operating system kernel proceedings international symposium code generation optimization p283298 march 1114 2007 steve haga andrew webber yi zhang nghi nguyen rajeev barua reducing code size vliw instruction scheduling journal embedded computing v1 n3 p415433 august 2005 mario latendresse marc feeley generation fast interpreters huffman compressed bytecode science computer programming v57 n3 p295317 september 2005 bjorn de sutter bruno de bus koen de bosschere sifting mud low level c code reuse acm sigplan notices v37 n11 november 2002 ozturk g chen kandemir kolcu compilerguided data compression reducing memory consumption embedded applications proceedings 2006 conference asia south pacific design automation january 2427 2006 yokohama japan guilin chen mahmut kandemir optimizing address code generation arrayintensive dsp applications proceedings international symposium code generation optimization p141152 march 2023 2005 marc l corliss e christopher lewis amir roth implementation evaluation dynamic code decompression using dise acm transactions embedded computing systems tecs v4 n1 p3872 february 2005 zhang chandra krintz design implementation evaluation adaptive code unloading resourceconstrained devices acm transactions architecture code optimization taco v2 n2 p131164 june 2005 mary j irwin exploiting frequent field values java objects reducing heap memory requirements proceedings 1st acmusenix international conference virtual execution environments june 1112 2005 chicago il usa bjorn de sutter bruno de bus koen de bosschere linktime binary rewriting techniques program compaction acm transactions programming languages systems toplas v27 n5 p882945 september 2005 chang hong lin yuan xie wayne wolf code compression vliw embedded systems using selfgenerating table ieee transactions large scale integration vlsi systems v15 n10 p11601171 october 2007