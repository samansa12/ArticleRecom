analysis bounded time warp comparison yawns article studies analytic model parallel discreteevent simulation comparing yawns conservative synchronization protocol bounded time warp assumed simulation problem heavily loaded queuing network probability idle server closed zero model workload job routing standard ways develop validate methods computing approximated performance measures function degree optimism allowed overhead costs statesaving rollback barrier synchronization workload aggregation find bounded time warp superior number servers per physical processor low ie sparse load aggregating workload improves yawns relative performance b introduction discreteevent simulations model physical systems literature parallel discreteevent simulation pdes usually views physical system set communicating physical processes represented simulation logical process lp lps communicate timestamped messages reflecting changes system state timestamp reflects instant state change occurs physical process model parallel discrete event simulation poses difficult synchronization problems due underlying sense logical time lp maintains logical clock representing time corresponding physical process simulated fundamental problem determine lp may execute known future event advance logical clock lp advances logical clock far ahead lp system may receive message timestamp logical past called straggler threat stragglers dealt saving simulation state periodically rolling back appropriate straggler arrives messages sent times ahead stragglers timestamp must undone fundamental problems pdes reviewed misra 1986 fujimoto 1990 righter walrand 1989 nicol fujimoto nicol fujimoto 1994 give current stateoftheart review pdes synchronization protocols fall two basic categories although detailed taxonomy given reynolds 1988 conservative protocols eg chandy misra 1979 bryant 1977 peacock et al 1979 lubachevsky 1988 chandy sherman 1989 nicol 1993a allow lp process event timestamp one unable assert receive another event timestamp less point future optimistic protocols eg time warp jefferson 1985 allow lp process event known certain lp later need process event earlier timestamp causality errors corrected rollback mechanism earliest synchronization protocols asynchronousan lp synchronizes solely basis interactions lps directly communicates recently synchronous protocols attracted interest details vary nicol p reynolds jm duva basic idea incorporate barrier synchronizations global reductions functions future simulation times examples include moving time window sokol et al 1988 conservative time windows ayani rajae 1992 conditional events chandy sherman 1989 bounded lag lubachevsky 1988 synchronous relaxation eick et al 1993 bounded time warp turner xu 1992 breathing time buckets steinman 1991 yawns nicol 1993a advantage conservative protocol synchronization information moves quickly system lowering overhead costs efficiency usually comes price pessimistic synchronization eg lp may block threat receiving message time whereas threatened message actually lp b lp c global mechanisms allow efficient computation simulation times like advantage optimistic protocol elimination separate gvt global virtual time calculation reduction risk cascading rollbacks conservative methods price paid reduction asynchrony limited opportunities parallelism interest conservative yawns protocol performance relative optimistic techniques comparison bounded time warp btw protocol suits purposes well like yawns iterative algorithm requiring global synchronization end iteration worthwhile note differences two approaches protocols consist three phases first phase lps cooperatively define global window simulation time second phase lps concurrently process events timestamps falling within window third phase lps engage barrier synchronization primary difference size global window simulation time yawns creates windows small enough guarantee processing within window correct btw defines larger windows allows lps optimistically process events within larger window comparing yawns btw sidebyside better understand costs benefits employing optimism windowbased framework constructing small windows yawns avoids overheads optimism cost reduced parallelism larger frequency barrier synchronization constructing larger windows btw enjoys larger degree potential parallelism lower frequency barrier synchronization pays statesaving rollback overheads yawns analyzed elsewhere nicol 1993a present analysis btw develops approximated form probability distribution number events lp executes within window quantifies distribution using numerical techniques style approach standard many areas modeling relatively novel among analyses parallel simulation allows one model complex phenomena would otherwise possible one crucial point approximation validated via simulation btw computation another crucial point model incorporates delay instant antimessage sent instant received point profound impact conclusions analysis model predicts btws optimal window size much larger yawnss surprisingly one two events processed average lp within optimally sized window facilitate comparison derive formulas analysis bounded time warp comparison yawns delta 3 yawns btws performance function synchronization statesaving eventreprocessing costs using determine problem sparseone finegrained lp per processorthen asymptotically number lps increases btw prevails however fix size architecture aggregate lps onto processors yawns prevail contribution paper present validated approach analytically approximating behavior complex synchronization protocol unlike previous analyses parallel simulation protocols approach general enough incorporate numerous overhead costs include effects workload aggregation using approach compare yawns btw identify function overhead costs situations advantageous use optimism situations advantageous remain conservative reader uninterested mathematical details may well still interested qualitative conclusions details produce remainder paper organized follows section 2 describes analytic model relationship others literature section 3 develops methods approximating probability distribution lps workload including reprocessed messages due roll backs section 4 applies approximations compare yawns btw section 6 presents conclusions 2 model analysis parallelized queueing network simulation simulated servers heavy load lps represent servers events occur jobs either enter service received queue servers use nonpreemptive scheduling jobs postservice destination presumed known time enters service destination chosen uniformly random set lps allow data content next destination serviced job depend upon contents times jobs received lp prior time job enters service message reporting jobs arrival new destination sent recipient time job enters service called presending job important aspect yawns time warp message sendtime receivetime corresponding serviceentry service departure times service time reflecting advancement simulation time also random exponentially distributed rate cost processing serviceentry event job arrival event unity expression physical execution times units simple models like basis several analytic studies model similar one studied gupta akyldiz fujimoto gupta et al 1991 well refer gaf study asynchronous time warp main differences use unit cost executing event gaf model uses exponentially distributed execution cost model basically queueing system single servers nonpreemptive queuing discipline whereas gaf model queuing system infinite servers model indirectly reflects effects communication delay gaf model assumes instantaneous communication differences significant enough prevent us quantitatively comparing model results gafs note gafs assumption exponentially distributed event execution costs tend 4 delta p dickens nicol p reynolds jm duva worsen performance model instantaneous communication infinite servers tend improve furthermore one increases available parallelism gaf model increasing number messages model one must increase number lps model also loosely related selfinitiating model studied nicol nicol 1991 subsumed nicols messageinitiating model study yawns nicol 1993a former model concentrates effects fanouts greater one ignores effects rollback latter model provides analysis yawns use paper bonding model eick et al eick et al 1993 closely related essentially describes behavior parallelized queuing simulation identical except message describing jobs departure sent simulation instant job departs assumption keeping normal practice serial simulations however parallel simulations always presend messages increases parallelism another difference model reexecuted event chooses new destination message uniformly random whereas bonding model assumes directed lp neither model particularly realistic regard critical facet model finally randomly uniform routing assumption shared model studied felderman kleinrock felderman kleinrock 1991 model timestamp advancement event execution time differently analysis unique several ways first nearly aforementioned models regard communication statesaving synchronization negligible believe costs largely define synchronization approach best suited problem explicitly incorporated model sec ondly analysis optimistic windowbased scheme performance depends level optimism regard eick et als model simi lar analytic approach different also extended eick et al model finally analysis nicol nicol 1993a considers beneficial effects aggregating lps shall see consideration make advantageous forego optimism sufficiently aggregated case whereas optimism better nonaggregated case analytic approach computational based simplifying approxima tions develop intuitive approximation probability distribution number events processed lp executing window workload distribution includes reprocessed events induced rollbacks distribution basis add overhead costs compute average execution cost real time per unit simulation time proceeding analysis useful review yawns mechanism presume lps executed events simulation time assumptions permit presending messages lp examine state predict departure time next job receive service excluding one receiving service assuming message arrivals prior job entering service sort lookahead called conditional knowledge chandy sherman chandy sherman 1989 validity conditional using standard minimum reduction techniques lps quickly compute conservative yawns window wt construction job entering service wt window also departs analysis bounded time warp comparison yawns delta 5 service coupling feature message presending message generated event wt receive time wt btw similar sense requires lps synchronize upper edge optimistic window time window understood pro cessors whereas original btw algorithm proposed window synchronization mechanism whose cost linear number lps model use algorithm logarithmic cost described nicol 1993b steinman 1992 every time event processed whether initially due rollback chooses destination message random regardless previous behavior event window allows messages content destination sensitive function complete message history lp time job enters service feature places btw disadvantage lazy cancellation ineffective thus two messages generated upon reprocessing event antimessage cancel previous routing new routing message sent another probably different lp like analyses time warp neglect cost processing antimessage sender receiver however model antimessage recognized instantaneously recipient recipient processed known events window feature makes sense cost probing new message high enough govern activity case current distributed memory architectures 3 analysis principle challenge modeling optimistic protocols capture effects rollbacks occurrence one straggler message may trigger one rollbacks specific case additional challenge capturing effect btws global synchronization rollback propagation difficult analytic problem make headway use intuitive approx imations straggler arrives time first postrollback event lp time stamp additional rollback triggered receive time message sent time must lie inside btw synchronization window probability occurs depends relative positioning time within windowthe closer end window less likely trigger another rollback fact condition knowing straggler message arrives time model assumptions compute exactly probabilistic effects straggler antimessage generation actual arrival time distribution message intractably complex approximate form numerically compute parameter estimates form thereby allowing computation effects stragglers form based intuition arrival time straggler message viewed sum service times given message arriving time trace back chain service durations given different jobs different lps approximation novel among analyses parallel simulation part calculation use standard approximations replacing conditional binomial distribution meanmatched poisson distribution assumption independence random variables whose correlation structure low due randomizing effects stochastic routing 6 delta p dickens nicol p reynolds jm duva approximated distributional form message arrival times permits us compute probability distribution random number w events executed including reexecutions within window width w clearly depends dependence expressed notation initial goal determine probability distribution w note distribution lps uniformity assumptions made given distribution add overhead execution costs determine mean time required complete window processor requiring longest time serves metric measuring average execution time required per unit simulation time focus generations messages notion arises follows imagine lps synchronize executes known events window receiving affected message present synchronization set messages sent first sweep timestamps defined generation 1 noted earlier messages sent first sweep timestamps greater explicitly excluded consideration effect processing present window generation 1 message causes lp rollback reprocess events window lie ahead receive timestamp reprocessing turn generates another set messagesones generation 2 continuing vein message generation direct result rollback caused generation message denote random number generation messages received lp g denote r random number events processed result receiving generation messages analysis simulated nonpreemptive queueing network load high every server always busy small job arrive one window wait service one windows discounting possibility job going service window arrives time lp knows number entry times service times jobs place service window jobs associated times remain unaltered throughout processing window however contents destinations messages lp sends permitted change function messages arriving number service entry events lp random variable poisson distributed mean since routing jobs taken uniformly random lp also knows j job arrival events j also poisson mean j independent event reprocessing costs depend quickly parallel simulator receives reacts straggler messages example analysis gupta et al gupta et al 1991 assumes zero message transmission delay rollback occurs immediately following complete processing whatever event served instant straggler message arrives two stragglers arrive processing time reprocessing effect though straggler least time stamp received others exact additional cost consider effect communication delay may algorithm small enough lp events window time takes message travel processors recipient lp already ready synchronize time analysis bounded time warp comparison yawns delta 7 even communication faster frequently case observed actual applications cost probing new messages event prohibitively high distributed memory architectures probe involves system call model straggler message received effect straggler reexecute events lp send antimessages messages generated previously events lp receives k generation stragglers processed serially incurring k separate recomputation costs aspect model concerns timing message arrivals subsequent processing btw need behave way may long lp events window communication lag noteworthy define generation 0 messages corresponding service entry events job arrival events write r express total number events processed window observe event reexecutions counted r 0 overhead distribution reprocessing cost r depends number generation messages given total number n generation messages system number arriving lp binomial bn 1p random variable p number lps principle could carry analysis forward retaining binomial form practice computational advantage modeling binomial poisson random variable matching mean approximation standard n large 1p small case early generations whose contributions dominate w noted earlier distribution messages arrival time complex handle exactly owing inescapable probabilistic dependencies approximation arrival time distribution message notes message corresponds serviceentry event lp arrival time serviceentry time plus exponential service entry event rank reflecting whether first second service entry event lp arrival time distribution message sent th service entry event following time plus convolution exponentials ie arrival message rank 1 occasion condition serviceentry event lying case messages arrival time distribution altered conditioning order message sent generations 0 th service entry event must reprocessed implying arrival earlier stragglerinformation alters ms arrival time distribution model attempt capture distributional dependency simplifying assumption every generation arrival message timestamp whose distribution plus erlang conditioned less chose representative random generationi arrival rank probability rank k expected fraction ik generation messages rank k letting density function erlangk conditioned less approximate arrival time density function 8 delta p dickens nicol p reynolds jm duva total events processed window service entry events window j job arrival events service rate queue server generation arrival messages received reprocessed generation arrivals reprocessed single generation arrival ij fraction generation arrivals rank j density function erlangj conditioned cumulative distribution function erlangj bnp binomial random variable parameters n p cumulative distribution function erlangj conditioned sum first j gamma 1 stages less table 1 summary notation arbitrary generation message mixture k2 ik f k show approximate coefficients fa ik g table summarizes notation random quantities lporiented rather systemoriented remains determine weighting factors fa ik g distributions w g r approach condition determine distributions suitably conditioned call g k r k w k model assumptions correlation message arrival times lp slight taking independent compute w individual random variables convolution independent straightforward uncondition j since j independent poisson values eg fa ik g built increasing shown first consider eg 1 generation 1 message arises whenever serviceentry event sends arrival message timestamp less arrival events sent service entry events previous windows condition serviceentry events joint distribution times identical k independent variables ross 1983 pg 37 choosing one k uniformly random probability arrival message lies outside given prfarrival message time service entry event z ta leads observation mean number arrival messages generated ta fall outside ta 10 gamma e gamma since mean total number arrival messages generated obtain values fa 1k g also easily derived arrival message rank j necessary erlang associated arrival time less analysis bounded time warp comparison yawns delta 9 bayes theorem obtain f k cumulative distribution erlangk rate parameter turn analysis higher generations suppose eg values fa ij g known generation condition consider distribution r k formulation arrival time cause reprocessing every known arrival event serviceentry event given may view placement time events k uniforms consequence number events reprocessed rollbackinducing arrival distribution binomial bk representing sum k bernoullis success probability va coupling fact approximated distributional form generation messages compute prfn events reprocessed generation message j z ij equation 1 approximates distribution random variable r k random number events reprocessed single generation message conditioned ignore fact arrival message arrival event set known arrival events continuously flux successive generations accepting approximate distribution r random convolution independent instances r k poisson rate eg true distribution bg n n fold convolution values fa ij g computed similar fashion condition generation arrival time condition serviceentry events number falling v binomial probability generation message rank j generated arrival zero arent enough serviceentry events ie otherwise probability j gamma 1 st serviceentry event occurs v message generates falls within gives creates rank j generation z ij recall h j cumulative distribution function erlangj conditioned sum first stages less us probability reprocessed rankj gamma 1 serviceentry event produces message next generation nicol p reynolds jm duva fig 1 reprocessing rank 4 serviceentry event generates rank 5 message next generation figure 1 helps explain ideas situation shown arrival message time ahead first three service entry events service entry events ahead arrival ranks 4 5 respectively arcs illustrate sendreceive time difference messages sent reprocessed events rank 4 event message falls within window rank 5 event message order rank 5 message generated 4 th ranked service event must lie right v must receive time message distribution receive time exponential added distribution th service event latter conditional erlang4 rank j let b i1j result unconditioning equation 2 recalling reprocessed serviceentry event generates two messages timestamp mean number generation rank j 2 theta eg theta b i1j coefficients fa i1j g given finally mean number arrival messages next generation simply using recursions one may every compute distribution r k generations conditioned random variables r 0 may taken independent processes driving highly randomized arrivals elsewhere whence may compute distribution convolution w finally knowing distribution compute distribution w unconditioning known poisson distribution w describes workload single lp terms numbers events processed large numbers lps randomizing message routing may treat lp workloads independent random variables straightforward express expected maximum workload among n lps letting mn maximum workload know every nonnegative integer w analysis bounded time warp comparison yawns delta 11 emn x numerical problems may arise computing x small x large good approximation emn socalled characteristic maximum used instance eick et al eick et al 1993 given n characteristic maximum w smallest value w c prfw w c g 1n since w discrete refine estimate linear interpolation w 0 cumulative distribution function w c w c gamma 1 essence creating continuous version w solving w c prf estimates emn course computer program calculating distributions must truncate infinite sums taking found summing first twelve generations yields convergent numbers 2 0 2 precise complexity analysis computation involves enumerating number discrete points used model distribution functions messy proposition considering code adaptively chooses number points needed practically speaking computational complexity large data point curves illustrate required small number seconds computation personal computer course research experimented several different forms approximate message arrival time distribution form developed validated large number empirically observed observations drawn many values n figure 2 provides representative sample valida tion comparing model predictions em 64 em 1024 simulationbased measurements varying values simulation heavily loaded queueing network simulation synchronized btw measurement point estimated one hundred window replications purpose ensure model captures general trends omit confidence intervals see model predicts behavior well range predictions span factor ten smallest largest although breakdown larger end likely due models overly pessimistic calculation every straggler causes reexecution every event ahead within window larger window sizes btw increasingly deviates behavior recognizing two stragglers concurrently one smaller arrival time causes recomputation also instructive consider fraction committed events events later reprocessed behaves function illustrated figure 3 plot ratio expected maximum committed workload processor expected maximum total workload 64 1024 lps curves shown fraction useful work decreases linearly certain point suggests within model framework make sense nicol p reynolds jm duva size window mean service time100300maximum number events processed observed predicted observed predicted fig 2 comparison observed predicted mean maximum events processed window lp increase indefinitely explained section follow 4 comparison yawns instructive consider emn behaves function emn basically product three terms number message generations required lps finished window ii average number rollbacks per generation iii average number messages reprocessed per rollback simulations suggested number generations grows linearly observation agrees analysis eick et al eick et al 1993 number messages reprocessed rollback also increases linearly simple reason increasing window size introduces new events top window rolled back along ones rolled back smaller windows average number rollbacks per generation also linear arrival message assumed cause reevaluation later messages emn least cubic function cost per simulation time unit emn aa whose units execution time per simulation time unit least quadratic suggests may minimizing cost figure 4 confirms intuition fact interesting note appears slightly less agreement model eick et al even though models costs different conclude excellent choice show remains presence reasonable overheads remainder presume equality incorporate effects statesaving well assume perevent cost analysis bounded time warp comparison yawns delta 13 size window mean service time040080fraction committed events 1024 lps fig 3 fraction committed events function 64 1024 lps size window mean service time200400 expected cost per simulation time unit fig 4 emn aa function 64 1024 lps 14 delta p dickens nicol p reynolds jm duva log base 2 number lps100200 expected cost per simulation time unit fig 5 ema function log 2 statesaving factor ff cost executing n events attendant statesaving ffn ff 1 note model presume state saved event presumes aggregate statesaving overhead amortized events ff equivalent saying effect statesaving cause execution run 1ff speed equivalent computation statesave emn hence figure 4 incorporate cost synchronization statesaving effect statesaving cost ff simply shift curves illustrated figure 4 vertically factor ff optimal window size change include synchronization cost z window true cost per simulation time unit ffemn aa za depending value z optimal window size may grow however analysis figure 4 shows z must large significantly alter optimality window sizes near seen emn aa least quadratic function simple calculus shows minimizing emn aa sa oz 13 concretely may ask value z forcing optimal window size almost twice occurs roughly adjusted function equal rightmost two points curve figure 4 ie emn algebra yields number reflecting synchronization cost three times larger windows entire computation cost point ten times larger cost executing committed events overheads large arent practical remainder consider case z moderate eg windows computation cost may continue use closetooptimal window size order compare synchronization costs yawns btw must consider synchronization performed optimistic computation software solution described nicol nicol 1991 every lp engaging synchronization activity finds apparently synchronization point could analysis bounded time warp comparison yawns delta 15 assume synchronization cost every straggler message however seems excessive instead well assume number synchronizations one would incur synchronizing end generation fact reasonable way program btw following synchronization processors determine whether stragglers decide whether move next window experience optimistic barrier studied nicol 1993b cost close twice conventional syn chronization simulation studies show window width 25 generations average figure relatively insensitive number lps turns behavior emn n almost perfectly linear function log n range considered emn log n 29 taking b execution cost conventional barrier synchronization overall execution cost per unit simulation time given n lps context earlier remarks concerning synchronization cost z function reasonable 5b order computation cost say 5b 29 consider yawns nicol nicol 1993a established average width conservative window least n windows small average maximum number events processed lp larger 2 large n much closer 1 including barrier synchronization yawns cost per unit simulation time greater c yawns n may use equations 3 4 compare approaches given values overhead costs higher level observe btw olog 2 n cost yawns n cost sufficiently large n btw always achieve lower cost large must n depict graphically figure 6 plotting solution ff equation c function log 2 n various values b solutions plotted 1 since statesaving never accelerate cost executing event given value ff known value b one determine n ff determine btw better yawns n n imagine statesaving doubles cost executing event plotting line look intersection various synchronization cost curves n associated intersection define n instance btw better n 128 however btw needs n 100 needs impacted strongly increasing synchronization costs synchronizes order times often btw assumptions weve analyzed yawns show simulation time advances exponentially distributed amounts one lp assigned processor yawns relatively high cost however yawns performance sensitive assumptions lps service time bounded fl 0 size yawns window least fl nicol p reynolds jm duva 40 60 80 100 120 log base 2 n100300alpha fig 6 function specifying lp threshold n yow better yawns seemingly minor change assumptions defeats assured asymptotic superiority btw changes yawns cost o1fl relative performance yawns btw depend primarily ff b fl next show considering effects aggregating lps onto processors yawns circumvents btws assured superiority even service times exponentially distributed reasoning straightforward let n denote number lps p denote number processors presume processor simulates np lps prior analysis yawns model assumptions shows average size yawns window yn number events lp executes window poisson rate 2yn since lps independent number events processor executes window poisson rate n np mp mean expected maximum p poissons rate yawns cost per unit simulation time per coresident lp yawns n 125 theta eick et aleick et al 1993 study asymptotics mp r showing mp r log p log log p small r mp r 2r r unboundedly n implying sufficiently large n yawns n analysis bounded time warp comparison yawns delta 17 log base 2 lps per processor4080ex costs per unit sim time per coresident yawns fig 7 yawns btw normalized cost per unit simulation time aggregation function lognp second term vanishes n grows showing yawns normalized execution cost per lp asymptotically constant result imply yawns normalized cost asymptotically 4 constants asymptotic analysis missing expres sions however figure 7 plots predicted cost asymptotic function lognp also plots predicted performance btw assuming values n p statesaving overhead factors 15 shown figures obtained computing appropriate convolutions w finding expected maximum convolved processor load since aggregation may change relative optimality btw computed costs assuming window sizes differences presented data small synchronization costs contribute little overhead cost high loads clear yawns better btw high degrees aggregation statesaving overhead significant also noted model works btw aggregated case lps tend communicate lps processor one may expect advantages due significantly reduced communication costs especially true model recomputation cost due delayed stragglers consequential however assumption messages routed uniformly random means locality present model costing assumptions remain valid aggregated case long event processing costs order communication window size small nicol p reynolds jm duva 5 extensions believe general analytic approach extended valuable ways first extension permits analysis simulations routing probabilities uniform since core analysis single lp analysis driven assumed message arrival rate one easily envisions constructing different workload probability distributions lps different arrival rates one compute expected maximum lp workload numerically note however assumption independence lp workloads may special cases become less viable anticipate effect change performance yawns btw performance methods degrade load imbalance arrival events however btws performance suffer additional rollback induced workload lps higherthanaverage arrival rates one also imagines changes lp message arrival rates remain routing probabilities changed induce localityconsider ring lps communicate neighbors long servers remain heavily loaded approach remains question change affects actual simulation valid experience random butuniformly balanced routing contexts differences exist small another consideration relax assumption servers heavily loaded dont believe changes approach much number service events window size becomes poisson rate aea ae server utilization also need account possibility job entering service upon arrival details appear manageable lastly importantly believe possible extend analysis explicitly model communication delay message sent received accomplish envision modeling arrival process lp nonhomogeneous poisson process whose rate function depends communication lag computational model based physical time given probabilistic description time compute description time however approach offers possibility accounting phenomena earliest known straggler initiates rollbacks hope extension type sharpen predictive power larger windows 6 conclusions analyzed simple model parallel simulation compare performance conservative yawns synchronization protocol optimistic bounded time warp protocol approach novel problem area relatively simple show compute approximate probability distributions processor workload distributions add overheads due statesaving synchronization addition consider effects performance due aggregating many lps onto processor analysis predicts btw optimallysize window prediction borne experiments window relatively large compared yawns still small average logical processor executes two events within using window size construct equations predicting btws analysis bounded time warp comparison yawns delta 19 yawns execution cost per unit simulation time observe assumption one lp per processor btw asymptotically better yawns number lps grows however analyze performance allowing many lps per processor find yawns better btw moderate levels aggregation statesaving costs nonnegligible farreaching quantitative conclusions questionable model type yawns btw small changes model assumptions significantly affect quantitative results qualitatively though may infer actual reprocessing costs resemble model global synchronization costs arent high likely limiting optimism good thing windowbased framework also conclude probability distributions driving simulation time advance lower support yawns well problem sparse relative architecture however problem disappears large problems lps highly aggregated onto processors perhaps strongest conclusion offer performance parallel simulations strongly function statesaving synchronizationcommunication costs problem size degree aggregation specific synchronization protocols synchronization methods ought chosen problem known take advantage problems characteristics open important question remains whether windowbased framework offers better performance completely asynchronous one addressed problem believe extension analytic approach gupta et al model assumptions may lead desired comparison also believe precise treatment effects communication delay possible lead better understanding effect underlying architecture synchronization behavior acknowledgments good friend colleague j mark duva passed away fall 1995 paper published sorely missed r parallel simulation using conservative time windows simulation packet communication architecture computer systems technical report mitlcstr188 case study design verification distributed programs conditional event approach distributed simulation synchronous relaxation parallel simulations applications circuitswitched networks bounds approximations selfinitiating distributed simulation without lookahead parallel discrete event simulation virtual time bounded lag distributed discrete event simulation distributed discreteevent simulation performance bounds parallel selfinitiating discrete event simulations acm transactions modeling computer simulation 1 cost conservative synchronization parallel discrete event simu lation global synchronization optimistic parallel discrete event simulation parallel simulation today distributed simulation using network processors spectrum options parallel simulation distributed simulation discrete event systems mtw strategy scheduling discrete simulation events concurrent execution speedes synchronous parallel environment emulation discrete event simulation speedes unified approach parallel simulation performanceevaluation bounded time warp algorithm tr virtual time distributed discreteevent simulation parallel discrete event simulation performance bounds parallel selfinitiating discreteevent simulations bounds approximations selfinitiating distributed simulation without lookahead cost conservative synchronization parallel discrete event simulations global synchronization optimistic parallel discrete event simulation synchronous relaxation parallel simulations applications circuitswitched networks parallel simulation using conservative time windows spectrum options parallel simulation performance analysis time warp multiple homogeneous processors simulation packet communication architecture computer systems ctr seng chuan tay yong meng teo rassul ayani performance analysis time warp simulation cascading rollbacks acm sigsim simulation digest v28 n1 p3037 july 1998 marco pedicini francesco quaglia parallel implementation optimal lambdacalculus reduction proceedings 2nd acm sigplan international conference principles practice declarative programming p314 september 2023 2000 montreal quebec canada francesco quaglia vittorio cortellessa bruno ciciani tradeoff sequential time warpbased parallel simulation ieee transactions parallel distributed systems v10 n8 p781794 august 1999 jinsheng xu moon jung chung predicting performance synchronous discrete event simulation systems proceedings 2001 ieeeacm international conference computeraided design november 0408 2001 san jose california marco pedicini francesco quaglia pelcr parallel environment optimal lambdacalculus reduction acm transactions computational logic tocl v8 n3 p14es july 2007 jinsheng xu moon jung chung predicting performance synchronous discrete event simulation ieee transactions parallel distributed systems v15 n12 p11301137 december 2004