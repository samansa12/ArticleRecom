solving sumofratios problem interiorpoint method consider problem minimizing sum convex function p1 fractions subject convex constraints numerators fractions positive convex functions denominators positive concave functions thus fraction quasiconvex give brief discussion problem prove spite special structure problem cncpcomplete even p1 fraction involved show problem reduced minimization function p variables function values given solution certain convex subproblems based reduction propose algorithm computing global minimum problem means interiorpoint method convex programs b introduction nonlinear programming problems often involve objective functions expressed terms one several ratios exploiting special structure fractional programs subject extensive studies last decades overview fractional program ming refer reader schaible 1995 references given therein fractional programs single ratio maximum finitely many ratios fairly well understood suitable conditions problems still satisfy form generalized convexity exploited algorithms numerical solution problems example polynomialtime interiorpoint methods classes problems see freund jarre 1994 1995 nemirovskii 1996 numerical analysis manuscript 99313 bell laboratories murray hill new jersey june 1999 available www httpcmbelllabscomcsdoc99 roland w freund florian jarre hand fractional programs sums ratios much difficult well understood see schaible 1995 1996 problems possess form generalized convexity special cases ones discussed schaible 1984 hirche 1985 general multiple maxima minima algorithms classes sumofratios problems described cambini et al 1989 chen et al 1998 falk palocsay 1992 konno kuno 1990 konno yamashita 1998 ritter 1967 review article schaible 1996 however algorithms optimization linear ratios subject linear constraints purpose paper present suitable interiorpoint approach solution much general problems convexconcave ratios convex constraints approach based approximating sumofratios problem sequence convex minimization problems convex problems interiorpoint methods become methods choice point view theoretical complexity practical efficiency using simple warmstart strategy cost solving individual convex subproblems reduced iterations finally interiorpoint method provides certain dual information needed overall approach precisely consider problem minimizing maximizing sum single function p 1 ratios subject convex constraints explore use interiorpoint methods solution problems precisely study problems subject x 2 subject x 2 2 sequel make following assumptions assumption 1 ae ir n compact convex set f j x 0 minimization problem 1 functions h f 1 convex functions concave maximization problem 2 functions h f 1 concave functions convex simplicity restrict minimization problems 1 results algorithms 1 paper easily solving sumofratios problem 3 converted maximization problems 2 simply exchanging min max convex concave section 2 first discuss simplest case namely sum convex function show problem npcomplete propose method finding global minimizer section 3 method generalized case p 2 section 4 report results numerical experiments section 5 make concluding remarks 2 sum one fraction convex function throughout section assume 1 case problem 1 reduces form subject x 2 3 f functions satisfy conditions specified assumption 1 ie f h convex g concave fx 0 fixed r 0 let ae r oe r g feasible set 4 empty case set qr 1 note xr necessarily unique course qr definition q obvious xr solves 3 r minimizes q thus problem 3 reduced onedimensional problem minimizing function q determining xr given value r 0 convex optimization problem solved several methods separation oracle ae ir n given evaluation q given value r done given precision ellipsoid method separation oracle mean subprogram accepts input vector x 2 ir n produces output either information x 2 vector h 2 ir n h 6 0 h h x 2 second case vector h defines hyperplane separates x selfconcordant barrier functions sets ae r gx r oe 4 roland w freund florian jarre real numbers known qr also evaluated interiorpoint method barrier function convex set c function convex finite interior c goes infinity x approaches boundary c notion self concordance first introduced nesterov nemirovskii 1994 roughly speaking selfconcordance defined local lipschitz condition hessian barrier function shown nesterov nemirovskii 1994 many convex sets possess easily computable self concordant barrier functions concept interiorpoint methods based selfconcordance general approach remark special case constant function h problem 1 reduced problem form 3 ie one ratio means charnescooper transformation charnes cooper 1962 see eg cambini et al 1989 selfconcordant barrier function conic hull introduced transformation discussed freund et al 1996 general constant charnescooper transformation used reduce problem 1 sumofratios problem simple reduction may crucial algorithms whose computational costs grow rapidly number ratios example given sumofratios problem efficient first employ charnescooper transformation apply algorithm present paper reformulation using algorithm solution original problem 2 21 properties function q next recall wellknown properties function q given 4 5 oet convexity f ae fxr r oe similarly convexity h implies concavity g also follows gx hence x feasible 4 solving sumofratios problem 5 spite 6 7 8 function q quasiconvex ie general may happen note q quasiconvex problem 3 could solved polynomial time using goldenmean search q view derivation may still ask whether function q may smooth local minimizers 3 whether minimizing q might easier solving problem 3 directly assuming evaluate q derivatives observation function q necessarily simpler 3 illustrated figure 1 depicts function q special case real interval plot shows q may exhibit irregular behavior 22 npcompleteness next prove problem 3 essentially npcomplete end show wellknown npcomplete problem namely following knapsack problem recast special instance problem 3 knapsack problem let integer 1 weights costs c g problem find subset 0 ae maximized subject constraint discussion knapsack problem proof np completeness refer reader garey johnson 1979 result npcompleteness problem 3 stated follows theorem 2 problem 3 npcomplete following sense let data knapsack problem 2 weights given exists convex piecewise linear function f linear function g linear function h defined interval f g h respective derivatives evaluated polynomial time f g h take values polynomial size solving problem 3 equivalent solving given knapsack problem remark 3 right endpoint 2 interval theorem 2 polynomial first sight might lead impression reduction knapsack problem problem 3 exponential 6 roland w freund florian jarre course case indeed case linear pro grams may also involve nonpolynomial upper lower bounds one needs polynomiality coding length problem coding length problem 3 least hence coding length endpoint 2 fact polynomial coding length problem finally note function fg convex fflapproximation problem 3 could computed polynomial time npcompleteness theorem 2 result size endpoint 2 lack convexity proof theorem 2 let 2 weights w given data knapsack problem data construct special problem form 3 equivalent knapsack problem end first enumerate 2 subsets simply counting 1 2 binary system subset 0 exists index 1 k 2 kth subset enumeration determine k knowing index k without looking subset also determine weight w kth subset knowing index k c solving knapsack problem equivalent finding min 1k2 later use note next set 1 2 define functions f functions g h linear functions given function f defined piecewise linear interpolant points hence interval k x solving sumofratios problem 7 using 10 one readily verifies function f convex clearly given x 2 possible evaluate fx od arithmetic operations number digits needed represent function values 2d plus number digits needed evaluate finally show set functions f g h defined minimizer 3 index k kth subset k ae solves knapsack problem let 1 consider objective function 3 1012 second derivative objective function satisfies x 2 shows objective function 3 concave k k 1 thus minimum k k 1 attained 1 11 12 corresponding function values 2 2 therefore problem 3 equivalent 9 turn equivalent solving knapsack problem special instance problem 3 constructed proof theorem 2 evaluation associated function 5 qr particularly simple indeed let x r x 2 dx r r r r r 0 shows objective function 4 monotonically increasing therefore minimum 4 attained function qr 5 identical objective function 3 figure 1 plot function q case knapsack problem figure 1 displays example minimizing q identical solving problem 3 general however may anticipate 8 roland w freund florian jarre value r value figure 1 objective function random w c structure higherdimensional problem 3 far complicated scalar function q propose approach solving problem 3 evaluating q various values r exploiting lipschitz properties q emphasize case function q many local minimizers approximately magnitude class problems constructed proof theorem 2 approach solving problem 1 necessarily slow unless 23 global minimization method f g h smooth due structure function q generally piecewise smooth function compute global minimizer r q construct lowerbound function qr qr minimize q function q depends partition assume r 1 r r k r note solving sumofratios problem 9 value r 1 obtained given lower bound g value r k solving concave maximization problem 13 let given define lowerbound number ae r i1 oe q qr r 2 r r i1 note evaluating righthand side 14 amounts solving convex optimization problem let x solution minimization problem 14 follows using two inequalities r 2 r r i1 get r r r i1 r r r r r r r r r note inequality 15 follows r r 1 q gammaqr bound 16 proves leftsided lipschitz continuity q indeed near bound close value qr however bound reduces q lower value qr i1 roland w freund florian jarre note bound form 15 qr i1 place qr possible may occur qr i1 ae qr intuitively happen longer contains points f h reasonably small case lipschitz constant q right may much larger one left determine suitable lipschitz property right define function ae r i1 oe observe q convex r moreover q satisfies r r i1 remark evaluating qr i1 problem 17 solved lagrange multiplierdenoted g sequelcorresponding constraint gx r i1 also computed indeed interiorpoint methods implemented multiplier obtained extra cost lagrange multiplier leads bound r r i1 see eg theorem vii332 hiriarturruty lemarechal 1993 lowerbound function qr defined maximum bounds 16 18 simple method solving problem 3 proceeds follows given k points new point r interval r r i1 contains minimizer minf chosen r inserted list 19 thus k increased one process repeated note update qr involves interval r r i1 neighboring r interval split two subintervals r r r i1 minimum qr evaluated intervals particular effort minimizing q merely consists bookkeeping figure 2 gives example bounds leading qr note slopes qr qr may opposite sign interior r r i1 function qr may good approximation qr hence may poor choice reliable choice used numerical examples r 1 solving sumofratios problem 11 slope q 0 arg min qr ffl figure 2 functions q q keep evaluation q moderate costs suffices compute approximations qr along error esti mates interiorpoint methods particularly suitable computing approximate solution xr convex problem 4 along certified error bound form jqr ffl computation xr takes olog1ffl iterations provided selfconcordant barrier function level sets functions f g h known observation key point proposed algorithm next present statement algorithm algorithm 4 conceptual overall algorithm input functions f g h compact convex set defining singleratio problem 3 stopping tolerance ffl 0 step 0 determine r 1 r 2 roland w freund florian jarre value r 1 exists stop problem violates assumption 1 otherwise compute qr 1 qr 2 lagrange multipliers g number support points r delta step 1 set step 2 compute qr along lagrange multiplier g g step 3 based 18 evaluate arg min r2r r qr arg min step 4 increase k one insert r list r delta step 5 find step 6 qr min 1k qr r approximate minimizer otherwise return step 1 remark step 3 algorithm 4 bound qr may either obtained setting q gamma1 solving additional problem form 14 latter case expensive results better bound qr since 16 18 used cases 18 overly large efficient rely 18 solve 14 note minimizers lowerbound function qr computed step 3 algorithm 4 stored heap step 5 merely consists selecting first element heap finally remark practice feasible set usually form ae oe given convex functions solving sumofratios problem 13 3 minimizing sum several fractions section return general problem 1 minimizing sum convex function p ratios basic idea solving problem 1 similar special case treated section 2 assumption 1 satisfied case vector p parameters analogy definitions 4 5 xr qr case sr ae oe initially assume vectors r 1 r 2 computed minimizer r q satisfying r 1 r r 2 usual sign understood component wise component r 1 r 2 computed separately case let r r r i1 direction deltar 2 ir p given relations satisfied bounds 16 18 generalized provide bounds qr deltar split deltar lagrange multipliers constraints 20 theorem vii332 hiriarturruty lemarechal 1993 lower bound q given obtain lower bound q direction deltar define value r i1 r follows 14 roland w freund florian jarre r r i1 r i1 r r i1 r i1 r i1 r r r i1 r i1 r i1 r i1 r r i1 combining relations get r i1 bound analogous one 22 may replace r r r r obtain new bound r i1 deltar r i1 r i1 deltar r i1 solving sumofratios problem 15 based bound define anisotropic trust region point r long lower upper limits like r r i1 previous derivation given union trust regions support points r forms voronoi diagram ir p vertices contain candidates minimizer lowerbound function qr definition voronoi diagrams properties algorithms numerical computation refer reader aurenhammer 1991 fortune 1997 case candidates minimizer qr may result best choice inserting new value r somewhere known points r addition computation vertices voronoi diagram complicated expensive propose simpler scheme based bounds analogous 18 lowerbound function qr defined box ae oe given vectors r j r 2 b obtain 21 next summarize resulting overall algorithm algorithm 5 conceptual overall algorithm p 2 input h compact convex set defining multiratio problem 1 stopping tolerance ffl 0 step 0 r 1 j exist 1 j p stop problem violates assumption 1 otherwise compute qr 1 qr 2 lagrange multipliers j g j number support points r delta containing arg min qr roland w freund florian jarre step 1 set index split pays define r r step 2 compute qr along lagrange multiplier j function g j step 3 based 21 evaluate arg min l qr arg min l step 4 increase k one insert r list r delta splitting b along hyperplane r r l two boxes one r one r step 5 find k r arg min r qr 2 b step 6 qr min 1k qr r approximate minimizer otherwise return step 1 4 numerical experiments algorithm 4 minimizing sum convex function convexconcave fraction implemented matlab solution convex subproblems use interiorpoint method described jarre saunders 1995 seen figure 1 resulting problem 3 may complicated may many local minimizers nevertheless anticipate parameterization respect r smooth many local minimizers 3 thus result function q easier minimize objective function original problem 3 section report numerical results algorithm 4 applied certain examples random data case expectation function q easier minimize original problem 3 fully met fact function q appeared unimodal respect r examples solving sumofratios problem 17 test examples minimization problems form 3 ae oe matrices hfg constructed positive semidefinite therefore 23 functions h f convex function g concave feasible set convex data 23 chosen randomly follows matrix first generated random lower bidiagonal matrix l nonzero entries uniformly distributed gamma1 1 computed guarantees positive semidefinite tridiagonal matrix similarly h f g constructed random positive semidefinite tridiagonal matrices 23 h f g vectors also generated randomly scalars fl chosen interior feasible domain guaranteed nonempty functions f g guaranteed zero finally run experiments problems 23 values n ranging values ranging note constraints 23 nonlinear therefore adaptations simplex method solving problem 3 data 23 would rather complicated figure 3 plot function q typical example 23 marks point r method evaluated function q order able guarantee final iterate indeed approximate global minimizer thus stands application interiorpoint method solve convex problem form 4 since interiorpoint method warmstarted using starting points convex combination almost final iterates two neighboring problems overall number interiorpoint iterations less eight average curve qr course known general plotted merely illustration values determined solving convex problem form 4 200 evenly spaced values r figure 4 show detailed enlargement points generated algorithm 4 near global minimizer problem 20 plot shows distance support points r right minimizer much smaller left indicating particular case lipschitz bound 16 provides much roland w freund florian jarre 5 value r value exact function points generated algorithm figure 3 function qr random example accurate approximation qr 18 thus algorithm evaluate refinement points left minimizer table report number iterations taken matlab implementation solve problem 23 constraints different dimensions n stopping criterion examples chosen qr final guaranteed qr opt unknown global optimum 23 numerical results intended provide first rough estimate dependence algorithm dimension n space stress numbers newton steps hessian evaluations table could reduced sophisticated implementation number newton steps given table refers sum exact inexact newton steps inexact newton steps hessian matrix previous newton step used place current hessian matrix overall computational effort dominated number hessian evaluations number rs refers number support points r qr evaluated solving sumofratios problem 19 value r value exact function points generated algorithm figure 4 function qr near global minimum random example table iteration numbers rs 20 17 14 14 ip iterations 407 384 299 326 hessians 644 584 478 548 newton steps 1277 1134 980 1135 random examples presented exhibited one local minimizer function q figure 3 therefore constructed small problems three dimensions way several local minimizers integer values r two local minimizers nearly value qr method refines minimizers global minimizer identified plot figure 5 shows worstcase behavior method takes large number steps identifying point near fflglobal minimizer stopping tolerance ffl decreased bounds near refined increase accuracy global minimizer roland w freund florian jarre 502040608value r value exact function points generated algorithm figure 5 function qr case several local minimia needless say algorithm 4 lend solving knapsack problem section 22 structure knapsack problem exploited algorithm 4 lipschitz bounds 16 18 weak provide sufficiently sharp lower estimate function q interval length one hence algorithm 4 least expensive enumerating possible integer solutions knapsack problem represents example algorithm 4 suitable believe applications structure similar random problems algorithm 4 provides reliable reasonably fast method identifying global minimum 5 conclusions considered sumofratios problem ir n sum convex function p convexconcave fractions minimized subject convex constraints proposed approach transform problem problem minimizing suitably defined function q variables function q evaluated using interiorpoint method convex minimization established lipschitz bounds solving sumofratios problem 21 q also evaluated numerically using interiorpoint method based bounds method derived find fflapproximation global minimizer sumofratios problem presented numerical experiments proposed algorithm case minimizing sum convex function convexconcave fraction implementation algorithm case described elsewhere acknowledgements would like thank siegfried schaible bringing sumof ratio problem attention providing us copy technical report schaible 1996 authors grateful referees editor constructive comments helped us improve presentation paper r voronoi diagramsa survey fundamental geometric data structure maximizing sum ratios information optimization sciences 10 programming linear fractional function als efficient algorithms implementations optimizing sum linear fractional func tions optimizing sum linear fractional func tions voronoi diagrams delaunay triangulations interiorpoint method fractional programs convex constraints interiorpoint method multifractional programs convex constraints selfconcordant barrier functions conic hulls fractional programming computers intractability guide theory npcompleteness convex analysis minimization algorithms practical interiorpoint method convex programming generalized linear multiplicative fractional programming minimization sum product several linear fractional functions polytope polynomiality method analytic centers fractional problems parametric method solving certain nonconcave maximization problems simultaneous optimization absolute relative terms fractional programming fractional programming sums ratios tr ctr takahito kuno revision trapezoidal branchandbound algorithm linear sumofratios problems journal global optimization v33 n2 p215234 october 2005 yang dai jianming shi shouyang wang conical partition algorithm maximizing sum dc ratios journal global optimization v31 n2 p253270 february 2005 harold p benson using concave envelopes globally solve nonlinear sum ratios problem journal global optimization v22 n14 p343364 january 2002 h p benson global optimization algorithm nonlinearsum ratios problem journal optimization theory applications v112 n1 p129 january 2002