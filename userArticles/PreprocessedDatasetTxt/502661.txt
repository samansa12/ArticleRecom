scaling replica maintenance intermittently synchronized mobile databases avoid high cost continuous connectivity class mobile applications employs replicas shared data periodically updated updates replicas typically performed clientbyclient basisthat server individually computes transmits updates clientlimiting scalability basing updates replica groups instead clients however update generation complexity longer bound client population size clients download updates pertinent groups proper group design reduces redundancies server processing disk usage bandwidth usage dimininishes tie complexity updating replicas size client population paper expand previous work done group design include detailed io cost model update generation propose heuristicbased greedy algorithm group computation experimental results adapted commercial replication system demonstrate significant increase overall scalability clientcentric approach b introduction intermittently synchronized database isdb systems allow mobile data sharing applications reduce cost forgoing continuous connectivity allow sharing dedicated update server maintains primary copy global database data held mobile clients client maintains replica subset global database schema update server maintains primary copy global database receiving updates clients distributing demand clients based knowledge subscriptions see figure 1 typically server generates update les clients individual basis server scans set updates client update decides client receive update way client receives customized update le containing relevant data technique simple straightforward requires server work direct proportion number clients limiting scalability system resulting greater time maintain local replicas paper build previous work proposed organizing updates groups shared clients 5 using approach server manages update processing limited controllable number groups irrespective number clients instead receiving updates customized specic needs client accesses updates groups containing data needs groupbased approach results better server scalability work server decoupled actual number clients maintained 5 11 example salesperson may enter oce morning visiting customers load sales data server onto laptop throughout day salesperson updates local copy sales data regardless connectivity server conditions permit reliable connection established server synchronize local data using updates generated proper groups connectivity options include conventional wireless modems high speed wireless lans eg docking mobile device wired base station furthermore coworkers may concurrently update replicated data short develop detailed cost model group design oer remedy scalability problem natural isdbs share data present extensive experimental results demonstrating improved eciency using design techniques begin section 2 placing work context related work dene architecture iobased cost model evaluating spe cic data grouping section 3 section 4 propose heuristic set operators modifying data groupings greedy algorithm apply operators also outline handle changes system conguration section 5 compare approach intuitive grouping alternatives demonstrate grouping algorithm provides signicantly greater scalability client population size finally summarize observations describe future work section 6 note sake brevity include proofs theorems paper present subset experimental results detail reader may refer 12 2 related work isdb instance distributed computing sys tem multiple databases independently operate shared data assumptions clients mobile commonly suer long periods disconnection server however make traditional concurrency control protocols applicable traditional distributed database systems use twophasecommit protocol help ensure acid properties transactions 7 protocol communication intensive therefore impractical clients unreachable long periods timeeg mobile client powers order save energy response researchers proposed replicating data among multiple clients allowing operate replicas independently 1 allows quicker response time reduces possibility deadlock reduces need energyconsuming communication server allows mobility resistant network outages downside relaxing acid properties 3 aid functionality architecture must include dedicated centralized server collects updates resolves con icts described 2 server increases availability reliability shared data may suffer performance problems amount work server must increases number clients served architecture goal coda intermittently connected le system similar isdbs researchers coda predicted experience possibility reintegration storm occurs multiple clients simultaneously try synchronize local caches server 9 results unmanageably long reintegration times client similar project called dbmate supports intermittently connected database systems experiments dbmate show server design improve synchronization performance 8 work paper generalizes results group design similar materialized view design large database systems try reorganize monolithic sets data order speed response time clients however view design slightly dierent goals sumptions utility view design measured closely resultant views cover expected queries main cost disk space consumed storing views 4 group design isdbs utility groups measured quickly generated cost roughly much extra data must transmitted clients furthermore since views assumed contain subsets relational data groups contain updates manipulated dierent ways reasons algorithms view design inapplicable group design 3 model standard isdb architecture includes database server update server le server network clients database server stores global database update server generates sets updates replicas stored clients updates made available clients set le servers clients intermittently connect le server via network client composed client update agent local dbms client downloads dates client update agent processes applying replicas contained local dbms data ow client server discussed paper interested reader may refer 10 details global database divided publications frag ments horizontal partitions database client subscribes subset fragments based data needs server maintains multiple possibly overlapping datagroups fragments designed based client subscrip tions dbms records updates clients log modied also stores scope 3the update aectsof update update session dened process update server scans log outstanding updates datagroup generates update le called update log containing updates data groups scope resultant update logs placed le server use clients frequency update sessions application dependent controlled system administrator client downloads update logs correspond local subscription clients update server processes applies contents update logs local fragment replicas basic approach update processing practiced industry call clientcentric one datagroup dened client exactly match local subscription proposed datacentric approach 5 datagroups created according data shared number datagroups generally independent number clients consider following two steps critical synchronizing client generating update les server transmitting clients emphasize clientside processing availability powerful mobile computing platforms eg pentiumclass laptops means clientside processing performance bottleneck especially client able install updates disconnected two critical steps tightly coupled update server generate update logs quickly available download sooner update logs take time generate client must wait longer download therefore reasonable increase cost one steps decrease greater problem statement given global database divided set fragments g proportion updates applied f update session estimated weight w fragment weights determined either using database statistics function volume data fragment denition spans ie fragments size number clients subscribe ie fragments subscription level subscription level fragment size subscription level fragments server stores set datagroups generates update log containing updates groups fragments size update log function sum weights corresponding datagroup client set interests c c f client subscribes set datagroups groups client subscribe contain superset fragments interest client stated formally c set c given mapping clients datagroups power set g client covering constraint goal generate set datagroups g mapping minimizes total cost function see equation clientcentric grouping jcj datacentric grouping approach determines grouping based aggregated interests entire client population capabilities system architecture figure 2 gives simple example datacentric redesign case interests one client subset another intuitively number fragments database xed number clients increases absolute amount overlap interests increases suggests datacentric redesign increases usefulness growing client population 31 cost model cost model assumes io time dominant cost factor therefore good approximation overall update processing cost particular grouping scheme three server network activities make total cost update mapping mapping updates respective datagroups 1 update log storage storage update logs update operation one three data manipulating onto disk update log propagation loading transmission update logs total cost therefore total cost update mapping cost update storage cost update propagation cost 2 components equation 2 explicitly modeled variables use shown following table variable description units appropriate cs server disk seek time secs cl server disk latency time secs cd cs cl ct server disk transmission rate secsbyte rate client k server vb buer size update log le bytes vd average update operation record size bytes vp average fragment denition record size bytes vt average temporary table record size bytes vg average datagroup denition record size bytes vs number operations update le total size update le number datagroups n number clients update datagroup mapping cost time required map updates datagroups assume log updates distributed updatetofragment mapping table publication information sequentially read memory 2cd ct vf results join saved temporary le cd temporary le fragmenttodatagroup mapping table subscription information read 2cd joined memory produce nal result hence update mapping cost update storage disk io cost measures time required store update logs onto disk server assume mainmemory buer maintained update log whenever buer lled contents written disk happens update logs left term parentheses indicates time spent disk latencies experienced update log buer lled whereas right term indicates much time required store actual data disk recall weight fragment estimates proportion operations commands namely insert update delete combinations operations constitute transactions contained update logs 2 term record table refers data structure eg row containing respective information salesman northeast manager salesman northeast manager data data data data data data data data north east south west north east south west database server f definition g mapping f client population clientcentric grouping datacentric grouping redesign figure 2 example clientcentric datacentric redesign using aggregated interests applied fragment update storage cost server client update propagation cost measures time required load memory transmit appropriate update logs clients assuming unicast communication server client log client downloads sequentially read joined memory transmitted network clients bandwidth update propagation cost equation disk latencies experienced reading client ks update logs cd jkj client k volume data read transmitted vf although servers disk rate xed ct clients transmission rates independent 32 potential cost reducing alternative illustrative purposes discuss certain extreme datagroup design strategies single large datagroup amount disk resources used however clients must receive updates regardless particular interests transmission costs high costly solution ex treme one datagroup generated fragment similar serverside organization proposed 8 note number fragments high managing datagroups becomes costly another solution generate one datagroup per client c clientcentric solution standard used industry shown 5 results high levels redundant work client population grows alternative propose lies somewhere solutions based clients share data another option ameliorate system architecture multiple update servers work parallel generate update logs subset clients described 10 instead precluding architectural solutions complement datacentric design exam ple clients allocated update server based potential eectiveness resultant datacentric grouping one way cluster clients based interest anities 6 however assume single update server work outside scope paper 4 heuristic approach grouping complexity grouping problem modeled np complete mathematical programming problem oer heuristic algorithm start introducing three operators perform grouping operations fragments dierent cost proles thus applicable dierent situations end section introduce means greedily applying operators brevity include formal cost analysis one found 12 based cost equations introduced section 31 certain conclusions drawn ways manipulating grouping order reduce update processing costs namely manipulate number datagroups composition datagroups subscription clients datagroups order change update processing costs common ways redesigning datagroups although different side eects include merging splitting subtracting overlapping datagroups 7 although similar operators used materialized view design operators based algorithms explained section 2 generally inapplicable therefore dene operators give denitions sideeects applicability see figure 3 41 operators redesigning datagroups merging two datagroups involves replacing union clients subscribing least one merged datagroups instead subscribe union preserving covering constraint see section 3 overlap merged datagroups storage cost reduced proportion size overlap client originally subscribed one merged datagroups client must receive super uous updates fragments contained merged datagroup resulting increased update log transmission costs applicability merge operator typically increases amount data must transmitted client expect operator used much unless network bandwidth high degree overlap two datagroups high splitting involves nding two nontotally overlapping partially intersecting datagroups splitting form third datagroup subscribers either datagroup must also subscribe third datagroup splitting reduces overlap datagroups increase amount data transmitted respective subscribers however overhead terms disk seeks latencies additional datagroup generated applicability split splitting increase relevance volume updates increases degree overlap two datagroups increases time saved rewriting large sets updates osets increase disk seek scan times subtracting two datagroups applies one subset either proper smaller two subtracted larger one eliminating lap datagroup subtracted becomes empty case subset relationship proper discarded subscribers larger datagroup must also subscribe smaller one smaller one exists overhead terms disk latencies incurred clients subscribe additional datagroups number datagroups increased operation savings proportional degree overlap subtracted datagroups subscribers datagroups need receive extra data applicability subtract operator diers two subset restriction operands nonetheless operator typically fewer side eects neither increases amount data sent clients way merge number datagroups way split example consider two datagroups b generate update logs 10kb due denitions b update logs always single byte dif ference may make sense merge b saves server work maintaining one fewer data group storing corresponding update log cost however clients subscribing one b must download additional byte 19kbps additional byte adds less millisecond transfer time alternatively splitting b forces server maintain denition additional datagroup generate additional bytesized update log depending server load may cost eective hand b generate update logs 10kb 5kb common may make sense split datagroups although splitting case would force server maintain denition additional datagroup gererate additional byte sized update log would save server storage time magnitude overlap without increasing volume data sent client drawback splitting forces server maintain additional datagroup savings storage however increase importance datagroups grow two datagroups merged instead clients subscribing one b would spend 2 seconds downloading super uous data addition 4 seconds spent downloading pertinent data 19kbps 42 greedy heuristic application strategy proposed pursues local cost minima cost reduction made applying operators greedy algorithm starts clientcentric solution applies possible subtraction operations set datagroups costreduction possible operator search costeective merge split one exists perform repeat cycle greedy heuristic true perform possible costreducing subtraction operations let benecial merge let benecial split either results cost reduction perform one reduces cost neither performed quit od subtraction given precedence typically fewest sideeects terms cost penalties reduces search space two operators furthermore merge split increase applicability subtract 43 redesign time passes isdb changes conguration new clients may periodically added isdb given subscription problem deciding proper data groups assign problem similar np hard setcovering problem moreover existing clients may change subscriptions type connection server may change client may move one location another change subscription match locale another client may acquire faster higher bandwidth connection problem redesign therefore two levels redesign subscriptions groups remain xed redesign groups well subscriptions address problems heuristically solutions necessary greedy heuristic described paper complexity therefore oer techniques reduce need running techniques relevant proofs fully described 12 431 addition clients section roughly describe map data groups subscriptions new clients problem similar np complete weighted setcovering problem merge split subtract figure 3 merge split subtract operators boxes represent datagroups dashed lines indicate overlap solve clientaddition problem similar way subscription greedily map datagroup best lowest costeectiveness costeectiveness ratio size datagroup size dened section total size fragments covered rst time datagroup process repeated entire subscription covered ratio bound results algorithm theorem 41 solution achieved greedy algorithm within factor hn approximation minimal cost cover n th harmonic number n size subscription 432 rerunning redesign algorithm time passes conguration isdb changes making datacentric grouping less costeective examples changes include changing client connectivity client subscriptions server speed since keep track changes recomputing current clientcentric cost ccc straightforward using cost model section 3 comparing cost actual current cost current datacentric grouping cdc administrator decide redesign datagroups cost improvement sets estimated redesign time cr conservative rule thumb deciding benet redesign varies depending application 5 experiments 51 goals goal experiments show datacentric grouping updates using greedy heuristic denoted dc results faster refresh times average client intuitive methods refresh time includes time required server generate update logs including computation storage transmit proper client costs correspond ones described section 3 grouping methods consider described table 1 experimental design database composed 100 fragments fragment assigned value p 0 client subscribes fragment probability p assign values p consider two probability distributions one highly skewed zipan one uniform results average client subscribing 1 database total volume updates linear function number clients allocated fragment proportion fragments p value client assumed network bandwidth c client population client bandwidth varying parameters values ects wide range appli cations oltpclass mobile oce application described beginning paper omit experiments varying update volume sake brevity see table 2 show experimental parameters creases advantage using dc increases techniques example dierence dc cc increases number clients performance gains generally come detecting removing redundant update processing ie overlapping subscriptions show circumstances also come ooading work onto components architecture 52 experimental setup ran experiment ethernet lan consisting pentium ii computers running windows nt update services provided synchrologic imobile 266mhz pc 64mb ram performance trends using alternative isdb middleware oracle ibm sybase similar reported database server sybase sql anywhere v6 running 200mhz pc 128mb ram database stores universal relation apply updates distributed clients datacentric experiments extensions based described 5 incorporated imobile one consequences extensions extra set metadata must sent client size metadata le empirically estimated 24 jgj number datagroups generated metadata grows number groups increasing number groups results need store mapping information extra metadata increases refresh times dc og op generally adding transmission time extra cost becomes insignicant however workloads increase aect trends results 53 experiment 1 varying client population results data distributions nearly identi cal method op bad low populations generates update logs regardless whether subscribed population increases probability datagroup subscribed becomes low method og makes sense clients saves grouping methods notation comments datacentric dc groups generated greedy heuristic clientcentric cc employed industry creates unique group client onegiantgroup og minimizes costs server storing updates clients single group oneperfragment op minimizes network costs eliminates storage redundancy generating single group fragment table 1 grouping methods parameter description values control values fg number clients 1 5 50 f100g 200 500 1000 workload updatesclient f50g client bandwidth bps 192 distribution updates fragments zipf table 2 parameter values experiments20601001401 5 50 100 200 500 1000 clients refresh time og op cc clients refresh time og op cc dc uniform distribution b zipf distribution figure 4 perclient refresh time seconds varying client population51525354519200 57600 512000 1024000 10240000 bandwidth bps refresh time og op cc bandwidth bps refresh time og op cc dc uniform distribution b zipf distribution figure 5 perclient refresh time seconds varying client bandwidth server work amount super uous data sent client grows however population making grouping infeasible method cc breaks high population increasing amount redundant work must growing population tests dc uses proposed greedy heuris tic consistently good performance resulting lowest nearly lowest refresh times populations method dc outperforms op dc groups together fragments often subscribed together method dc avoids problems associated og cc generating many datagroups little overlap many compromise server performance see figure 4 please note total volume data distributed scaled per client client population increases keep total volume data constant order isolate clientpopulation eects however experimental results given greater total volume data make dc results even favorable respect others 54 experiment 2 varying client bandwidth practice clients may choose among many connectivity options including wireless modem conventional modem highspeed wireless lan simply docking portable device oce lan therefore study changing bandwidths aect eectiveness various grouping methods although og performs poorly little band width gains bandwidth increases og work server already minimized bandwidth reduces harmful eects shipping super uous data method op good performance well fails take advantage increased bandwidth generating fewer groups order save server work therefore ultimately performs worse og high bandwidth cc worst performance redundant work must done server regardless network performance important result indicates regardless capability network perclient isdb refresh processing using cc performance oor method dc best generating multiple disjoint groups conserve network resources poor generating fewer groups conserve server resources network fast see figure 5 6 conclusion paper dene detailed model isdbs describe model inherently leads performance problems client refresh oer grouping solution propose redesigning updates groups based aggregated interests entire client population datacentric allows clients share groups intended many clients formulate redesign technique dene detailed cost dene operators manipulate costs based system conguration devise way applying based greedy heuristics tested greedy heuristic clientcentric approach two intuitive solutions monolithic group containing updates individuals groups fragment overall heuristic outperforms others terms refresh time greedily allocates resources neededeither server network depending conguration isdb fur thermore relative benet datacentric grouping increases client population improving scalability work isdbs ongoing example limited client connectivity unicast currently dominant form communication practice currently exploring use multicast means improving network scalability 7 acknowledgments authors would like acknowledge ms mireille jacobson valuable editorial assistance 8 r replication consistency lazy helps sometimes replicating allocation data distributed database system workstations dangers replication solution implementing data cubes eciently grouping techniques update propagation intermittently connected databases vertical partitioning algorithms database design principles distributed database systems data partitioning disconnected client server databases experience disconnected operation mobile computing environment framework server data fragment grouping improve scalability intermittently synchronized databases minimizing redundant work lazily updated replicated databases tr vertical partitioning algorithms database design dangers replication solution implementing data cubes efficiently replication consistency principles distributed database systems 2nd ed data partitioning disconnected client server databases replicating allocating data distributed database system workstations framework designing update objects improve server scalability intermittently synchronized databases grouping techniques update propagation intermittently connected databases ctr efficient synchronization mobile xml data proceedings eleventh international conference information knowledge management november 0409 2002 mclean virginia usa