computing hopf bifurcations paper addresses problems detecting hopf bifurcations systems ordinary differential equations following curves hopf points twoparameter families vector fields established approach problem relies upon augmenting equilibrium condition hopf bifurcation occurs isolated regular point extended system propose two new methods type based classical algebraic results regarding roots polynomial equations properties kronecker products matrices addition utility augmented systems use standard newtontype continuation methods also particularly well adapted solution computer algebra techniques vector fields small moderate dimension b introduction consider ndimensional system ordinary differential equations defined 1 c 2 gammasmooth function defined subset u ae ir n depends upon vector parameters ff 2 ir k equilibrium system point x 2 ir n property fx parameters ff varied equilibrium points undergo bifurcation two types elementary bifurcations occur generic oneparameter families systems saddle nodes hopf bifurcations saddlenode bifurcation jacobian derivative evaluated equilibrium point possesses simple zero eigenvalue similarly necessary condition hopf bifurcation presence pure imaginary eigenvalue pair spectrum x f one would like robust algorithms calculation parameter values one bifurcations occurs parametrized families vector fields case saddle node bifurcations one may obtain bifurcation locus augmenting equation fx procedure calculate equilibrium points x f numerical rank n gamma 1 inflated system detection saddle nodes previously proposed using detd x f augmenting equation 1 28 treat hopf bifurcations similar manner one requires explicit equations determine whether nsquare matrix x f pair pure imaginary eigenvalues paper examines procedures locating hopf bifurcations based singularity matrices obtained algebraic transformations jacobian matrix equilibrium previous investigators proposed variety approaches determination hopf bifurcation points may divided two broad classes typical indirect method employs numerical algorithm computing spectrum jacobian point along path equilibria interpolating locate parameter values pair eigenvalues cross imaginary axis vector fields small dimension unsymmetric qr factorization algorithm widely ad vocated larger problems krylov subspace techniques fast provide mathematics department center applied mathematics cornell university center applied mathematics cornell university z mathematics department cornell university adequate accuracy iterations 29 13 direct method equations characterize hopf point augment usual equilibrium condition standard techniques used solve roots resulting system algorithms frequently used practice solve explicitly purely imaginary eigenvalues together normalized basis corresponding eigenspace 17 31 32 22 approach may viewed simultaneously solving equilibrium point eigensub space iterative method sense transition indirect direct methods replaced use highly stable robust linear algebra techniques spectral computations rootfinding algorithms locally convergent strategy drawback minimal dimension inflated system increases least 2n 1 may decrease performance expected algorithm used solve resulting nonlinear system equations increase demand good initial values small stepsizes side effect methods produce information required detection pair purely imaginary eigenvalues significant computational cost purpose paper examine algebraic structure hopf bifurcation computations use insight gained construct direct methods rely upon minimally augmented systems computation hopf bifurcations methods based algebraic properties polynomial resultants matrix symmetric products algebraic theory applied many areas applied mathematics particular develop criticality conditions lyapunov stability analysis root location 4 primary focus develop theoretical basis algorithms study hopf bifurcation multiparameter vector fields modest dimensions complete detailed description dynamics reasonable objective experience context suggests approach may prove fruitful three reasons first bifurcation analysis multiparameter dynamical system typically proceeds number phases earliest aimed providing gross decomposition product space phase parameter variables regions greater lesser interest criteria hopf bifurcation easily evaluated based fixed point jacobian alone without requiring details spectrum lead fast algorithms scanning parameter space candidate regions interest second recent developments computer algebra techniques widespread availability powerful computing machines require reassessment mathematical algorithms normally reserved exclusively problems small di mension application computer algebra methods problems dynamical systems already proved effective normal form computation centermanifold reduction perturbation analysis 30 clear approaches computing hopf bifurcations require use iterative algorithms direct evaluation eigenvalues unsuitable use symbolic methods instead hopf condition expressed terms functions jacobian problems application symbolic methods become feasible third steady progress computer hardware software evolution promises continue trend towards fast robust methods solution linear algebra problems seems desirable exploit reliable methods matrix manipulation exchange reducing size difficulty inherent solution nonlinear equations even required penalty increase dimension matrices involved problems especially special structure approach may yield algorithms effective widespread use companion paper one 20 studies implementation methods three examples detailed comparisons algorithms discussed though make comments comparisons final section paper methods detecting hopf bifurcation based algebraic techniques appeared literature present paper complements extends results number ways particular program linlbf khibnik coworkers 26 incorporates method following curves hopf bifurcations based resultant two polynomials similar described subresul tant condition described section 2 provides way discriminating hopf points resonant saddle points used either method describe three formally different forms resultant criteria lead matrix formulations distinctly different properties prove equivalent development augmented systems based tensor products new although important classical role occupied tensors study stability criteria ordinary differential equations suggestive proof hopf bifurcations isolated solutions augmented equations neighborhood contain degenerate point applies augmented systems based either resultants tensor products next section recall algebraic preliminaries required express necessary hopf condition terms singular set certain algebraic functions either jacobian equilibrium point associated characteristic polynomial present two new methods following curves hopf bifurcation points 2 parameter families discuss variations arise due various ways singularity matrix may measured concluding remarks comments performance algorithms discussion methods extending approach bifurcation points greater degeneracy collected together section 4 2 hopf algorithms using polynomial resultants 21 algebra matrix resultants seek explicit criteria specify whether n theta n matrix coefficients may depend upon parameters pair pure imaginary eigenvalues section develop desired necessary conditions expressed terms corresponding characteristic polynomial matrix let j jacobian matrix f denote characteristic polynomial clearly p nonzero root pair f gammag common root two equations p pgamma p gamma pgamma making substitution rearranging construct two new polynomials n even let 2a ngamma2while n odd set p nonzero root pair f gammag exists z satisfies r two polynomials common root share common factor since r e r univariate polynomials degree r equal degree r e euclidean algorithm may used answer question compute sequence polynomials property p i1 remainder dividing p igamma1 p thus one requires degrees p strictly decreasing polynomials q sequence terminates p k found divides easy verify induction p ideal generated r e r polynomial ring rz implies polynomials common factor repeated divisions produce p k nonzero constant hand r e r common factor greatest common denominator appears p k divides p kgamma1 way euclidean algorithm may used determine whether two polynomials share common root euclidean algorithm closely related collection determinants constructed coefficients two polynomials n even let sylvester matrix pair equations 2 n gamma 1 theta n gamma 1matrix given rows nrows n odd matrix defined rows rows determinant r polynomial coefficients p referred sylvester resultant r e r sylvester matrix singular equivalently polynomials r e r share common root computation sylvester resultant usually performed construction pseudoremainder sequence pair polynomials modulo units ring coefficients polynomials terms pseudoremainder sequence intermediate terms produced euclidean algorithm explicit formulas coefficients intermediate terms defined terms determinants appropriate submatrices called subresultants shall use subresultants correspond linear remainder term euclidean algorithm coefficients linear remainder may obtained considering determinants two 3submatrices denote matrix obtained deleting rows 1 nand columns 1 2 thus n even 0 obtained sylvester matrix removing boxed entries shown relationship characteristic polynomial corresponding matrices leads result theorem 21 let sylvester matrix polynomials r e r equation 2 j precisely one pair pure imaginary eigenvalues p purely imaginary roots proof elementary properties resultants 8 chapter 3 prop 8 share common factor irz suppose common factor linear loos 27 explicit form two polynomials irz solution dets results common complex root z r e r unique real negative may one pair pure imaginary roots case may resolved computing higher subresultants conditions theorem satisfied magnitude shared root z given case hopf bifurcation related directly period limit cycle created bifurcation point efficient method evaluating sub resultants including determinants 0 1 generalized polynomial remainder sequences algorithm due habicht brown collins detailed discussion see loos 27 case equation 2 determinant sylvester matrix expressed explicitly terms eigenvalues j according following result theorem 22 let n roots polynomial p let n gamma 1 theta n gamma 1 sylvester matrix associated pair r e r 1ijn proof note 1ijn sylvester resultant r symmetric polynomials rewritten uniquely polynomials coefficients c polynomial denote two polynomials prodc spectively polynomials integer coefficients res irreducible 34 polynomials prod res define hypersurface affine space c n namely point lies hypersurface polynomial quadratic factor form hence exists integer res zc order show apply classical algorithm rewriting symmetric functions terms elementary symmetric functions begin noting lexicographic leading term 1ijn unique monomial elementary symmetric functions leading term namely therefore monomial c 1 c 2 c 3 occurs coefficient gamma1 n prod ever monomial occurs coefficient gamma1 12bngamma12c expansion res dets verified definition matrix desired factor quotient two coefficients quotient equals gamma1 proof theorem 22 completewe note theorem 21 imposes two requirements characteristic polynomial j singularity condition resultant matrix inequality involving subresultants many classical results root location systems polynomial equations example wellknown routhhurwitz criterion stability matrices determines whether eigenvalues matrix nonpositive real parts describe two criteria polynomial factor form appealing alternatives calculation sylvester resultant ease exposition consider case n 2 even discussion similar results case n odd follow analogously let denote space real nsquare matrices charpoly ir nx map associates element characteristic polynomial n ae dense subset matrices simple eigenvalues equivalence relation defined condition induces partition n similarity classes equivalence class partition useful representative element matrix displays coefficients associated characteristic polynomial along row column element called companion matrix notice n even r e monic polynomial thus may take c 6 6 6 6 6 4 representative element c since charpolyc moreover exists nonsingular matrix w c recall matrix polynomial degree k elements expression form coefficients scalars unit matrix alternative expression r given following theorem 4 section 12 theorem 23 r defined even r e c ro odd r c used denote detc thus vanishing r c provides alternative condition r theorem 21 involves matrix smaller dimension develop third equivalent criterion consider bezout resultant n even consider two polynomials specified equation 2a define brackets nand take c bezout matrix b corresponding polynomial pair r e r ndimensional square symmetric matrix entries constructed sums bracket products coefficients c follows kkmin modification required definition case n odd c n value prescribed characteristic polynomial p c n1 taken unity sylvester bezout matrices intimately related see theorem 113 barnett 4 note notation dett 1 leads following theorem theorem 24 bezout matrix corresponding polynomial pair detb moreover coefficients linear remainder term euclidean algorithm may expressed determinants certain bezout submatrices analogy subresultants defined sylvester form consider two submatrices b obtained deleting first column th row b bezout subresultants formed determinants b 0 b 1 together equation 6 may used specify hypersurface nsquare matrices purely imaginary eigenvalue pair since found particular relationship given following theorem described literature provide sketch proof theorem 25 let b bezout matrix polynomials r e r equation 2 j precisely one pair pure imaginary eigenvalues rb 6 0 detb 0 p purely imaginary roots proof bezout matrix b symmetric theta mmatrix barnett 4 section 15 satisfies following identity indeterminates w z suppose common complex root say w equation 7 conclude z 2 c substitute distinct values z invert corresponding vandermonde matrix see equation 8 implies 1 w zero vector assumptions bezout matrix rank gamma 1 unique scaling vector kernel computed cramers rule nonzero constant c find implies w negative positive proof complete w 0 common root r e r 1thus three distinct equivalent methods computing singularity condition necessary establish jacobian pair purely imaginary eigenvalues one sylvester related directly sufficiency condition one com panion small dimension compared n finally one bezout small symmetric structure illustrate ideas presented concerning polynomial resultants following example example consider case equation 2 becomes r sylvester matrix two relevant submatrices 0 1 given theorem 21 p pair purely imaginary roots 1vanishes product singularity condition may expressed terms companion matrix r e matrix polynomial r finally bezout matrix associated easy verify bezout subresultant condition provided expression det necessarily positive p pair imaginary conjugate roots table 1 provides list resultant equality subresultant inequality conditions functions polynomial coefficients vector fields dimension two six 3 hopf algorithms using symmetric products 31 algebraic properties symmetric products practical applica tions computation characteristic polynomial coefficients problematic since known algorithms numerically unstable method danilewski la verrier etc otherwise unremarkable example matrices constructed technique yields arbitrarily inaccurate polynomial coefficients detailed dis cussion see wilkinson 36 despite fact computational methods employ numericallydetermined matrix characteristic polynomial coefficients used extensively engineering linear systems analysis control theory empirical evidence suggests effective thus clear numerical calculation explicit coefficients cannot recommended general technique classes matrices techniques break complete understanding failure modes wellestablished example wilkinson observes jacobian matrices derived damped oscillatory systems frequently associated wellconditioned characteristic polynomials circumstances eigenvalue methods based explicit use coefficients appears fast reliable based numerical experiments early iterative solver deuce 37 circumvent difficulties explicitly determining characteristic polynomial coefficients seek method determine whether square matrix pair eigenvalues whose sum zero directly entries jacobian matrix simple procedure involves kronecker tensor products matrices finite dimensional vector spaces v w let linear operator n theta n matrix representation terms basis e let another linear operator theta representation terms basis f k tensor product vomega w mnthetamn matrix entries ij b kl terms basis e vomega w moreover eigenvalues behave multiplicatively tensor products k eigenvalues 1 corresponding eigenvectors u v k k eigenvalue addition assume 1 2 nondefective dimv tensor sum special action eigenspaces since spectrum operator consists n 2 pairwise sums eigenvectors u tensor sum suggests obvious candidate augmenting function j jacobian j eigenpair sums zero detjomega n nomega j vanishes n appropriate identity matrix notice since eigensum distinct eigenvalues occurs twice tensor sum corank2 hopf bifurcation point important numerical disadvantages remove twofold redundancy eigenvalues tensor product one split eigenspaces sigma1 involution oe vomega v interchanges factors oev restriction n dimensional eigenspace gamma1 oe operator whose eigenvalues commutes oe maps oeeigenspaces follows construct matrix corresponding restriction 1 eigenspace oe using different approach matrix representation restricted operator originally constructed directly elements argument matrices stephanos 33 later fuller 12 let b nthetan matrices entries ij b ij respectively 1 bialternate product biproduct b denoted afib mthetam matrix whose rows labeled pq columns labeled rs pr ps ps qr qs oe case obtain operator n dimensional space whose eigenvalues pairwise sums eigenvalues without repetition theorem 31 let n theta n matrix eigenvalues afi eigenvalues ii 2afi n eigenvalues j n nsquare identity matrix 1j n notice subscripts used compute biproduct entries indexed pairs avoid confusion lexicographically ordered pair label used refer element fi b shall enclose braces definition rowcolumn matrix index used employ standard notation thus index provides information position entry biproduct matrix label indicates elements arguments product involved example consider arbitrary 3theta3 matrix 3 conventions require compactness index notation possibility confusion drop comma separating row column indices thus example two products given 22 21 12 11 13 11 23 22 13 12 12 11 13 11 13 12 22 21 23 21 23 22 3 4 11 22 23 gammaa 13 33 12 gammaa 31 21 22 33 substituting n definition bialternate product solving elements yields simple formula entries n n rows pq columns rs entries given formula ps pr r 6 p algebraic properties bialternate product transformation confers certain structure upon matrix afi n may used construction hopf algorithms example simple manipulation row column labels yields following lemma lemma 32 let n theta n matrix lower upper triangular n lower upper triangular particular diagonal 2afi n proof suppose lower triangular let ij nonzero notice contributes diagonal elements 2afi n consider case n first assignment 9 may written k 1jk n row column label convention l l l kj shows 2afi n fikkjg diagonal similar arguments hold second fourth assignments 9 fifth apply lower triangular case thus 2afi n lower triangular similar argument holds upper triangular result diagonal follows immediatelysimple extension index counting arguments used used establish nonzero offdiagonal element jacobian propagated product lemma 33 suppose ij nonzero 6 j entries 2afi n moreover jg entries contained band three assignments specified equation 9 apply may written 1j k n shows total number offdiagonal entries 2afiin contributed ij given 2 nonzero entry ij may contribute elements 2afi n fpqrsg three rules 13ac let row row row row column indices corresponding labels pq rs rules 13a 13b 13c respectively find bandwidth wish maximize differences col asterisk replaced rule identifier ab c simple calculations show row row comparing bounds establishes result ij j case analogouslyfinally since bialternate product derived restriction tensor product matrices invariant subspace inherits several important properties tensor calculus particular straightforward verify lemma 34 ff scalar ab depending parameter following properties hold ff iv v theta theta provided partial derivatives exist vi ab fi 32 bialternate product algorithms algebraic theory symmetric matrix products described simple necessary condition hopf point point bifurcation point 1dimensional system det vanishes however found condition distinguishes purely imaginary eigenvalues directly jacobian bialternate products analogy subresultant criterion described earlier one use bialternate products effectively continuation method calculations hopf bifurcation curves relying observation transitions eigenvalues depart imaginary axis occur degenerate bifurcations propose following curves hopf bifurcations two parameter families solving equations expressing singularity bialternate product jacobian ensuring imaginary eigenvalues bounded away zero multiple imaginary eigenpairs occur begin simple proof equation 14 regular zero set provided appropriate genericity transversality conditions hold theorem 35 suppose system equilibrium x ff following properties satisfied single pair eigenvalues whose sum zero ie dff isolated nonsingular solution det x f fii n proof let suffices show f x ff nonsingular kellers bordering lemma 25 nonsingular dx ff since assumption k3 complement critical eigenvalues j x x ff product defines smooth function neighborhood solution e2 nonzero simplicity notation let j using theorem 31 ff since second term sum vanishes also true dff differentiating equilibrium condition fx evaluating result dx dff substituting equation 18 17 gammad x det j x fii n well together equation 16 implies establishes resultto utilize either augmented system defined vanishing resultant biproduct eulernewton continuation framework must specify jacobian extended system computed since corrector step linear system form must solved discussion follows use denote augmented column vector independent variables f referring theorem 35 assume components x fx ff fi ff fx ff fi readily available either analytically automatic differentiation see 18 references therein worst case finitedifference estimation one way computing derivatives apply forward central difference formula scalarvalued function n partials alternative suggested extension lemma due halanai published davidenko 11 lemma 36 let matrix 1 whose entries c 1 realvalued functions ij x l det x l tr denotes trace function adj adjoint matrix moreover ax invertible inomega x l det x l x 2omega identifying matrix lemma either jfiin resultant matrix section 22 shows partial derivatives augmented equation may computed without resorting differencing determinant function moreover cases second derivatives f known formulae indicate may used directly adjoint form undesirable since computation adjax om 4 however since objective corrector step essentially drive singularity expect calculation gamma1 increasingly unstable near solution point therefore require similar formula valid near generic solution expect rank drop one due vanishing single eigenvalue case singular values oe well separated results chan 7 show isolate vanishing pivot ludecomposition using appropriately chosen permutation matrix p form ffl order smallest singular value thus expect conditioning l u much improved compared using block forms inverses la ua together relation ffl delta detu obtain rearrangement lemma 37 let matrix defined lemma 36 suppose invertible open l k x 2omega exist matrices p q u l vectors v w ffl 0 x l det x l p permutation matrix q orthogonal ffl either ooe n gamma1 applying lemmas 34 37 augmented system defined equation 14 one obtains 1 l n l det jyfii n l jy formula shows partial detjfii composed weighted sums entries matrix derivatives j particular z weight matrix detu scale dependent upon j l thus compute row entries corresponding augmented singularity equation one need evaluate factors per corrector step conclude section remarks concerning properties bialter nate product matrices germane solution linear algebra problems arise algorithms hopf bifurcation specifically wish exploit structure jfiin way mitigate dimension increase linear systems n nn gamma 1 foremost among observation bialternate product matrix j sparse sparse even n modest dimension table 2 shows fraction nonzero entries jfiin dense j function n sparsity bialternate product consequence relationship tensor sum iomega j composed dense blockdiagonal band bandwidth n offdiagonal blocks n nonzero entries block similar internal structure inherited bialternate product matrix conclusion implied lemmas 32 33 example consider fate th lower subdiagonal j bialternate product transformation consider elements j 32 image jfiin remains lower subtriangle inspection proof lemma 33 shows bound difference row column indices elements bialternate product matrix originating j ij tight monotonically increasing thus th subdiagonal j generates wedge fanlike structure nonzero entries jfii n narrow upperleft corner bialternate product matrix achieves maximum width result n ngammam th entry j finally equation 9 shows product matrix symmetric general basic sparsity pattern illustrate observations figure 2 shows sparsity pattern generated dense jacobian matrix dimension observation jfiin bandstructured sparse may exploited hopf pathfollowing algorithms variety ways example augmented equation defined depends upon singularity bialternate product property preserved similarity transformation thus equation 14 may replaced det naturally desirable choices unitary well reduction j hessenberg form chosing product householder matrices numerically stable yields bialternate product block hessenberg structure subdiagonal bandwidth n gamma 2 sparsity structure upper triangle described jacobian reduced tridiagonal form j fi n block tridiagonal matrix routines designed banded structures exploited achieve corresponding reduction computational work 4 concluding remarks algorithms described computing hopf bifurcations specifically designed compute points simple pair pure imaginary eigenvalues jacobian system briefly discuss extension algorithms ones seek points codimension two bifurcation three cases arise codimension two conditions linearization vector field equilibrium namely takensbogdanov bifurcation double hopf bifurcation simultaneous simple zero pure imaginary eigenval ues case seek minimally inflated systems n equations locate codimension two bifurcation points case takensbogdanov bifurcation easy terms characteristic polynomial jacobian one wants constant linear coefficients vanish condition equivalent jacobian j corank1 square jacobian j 2 corank2 alternatively jacobian bialternate product jacobian vanish last criteria also satisfied point zero eigenvalue pair imaginary eigenvalues locating points double hopf bifurcation bit complex one calculate terms polynomial remainder sequences presence two pairs eigenvalues whose sum zero parameter value two polynomials r e constructed characteristic polynomial common quadratic factor coefficients polynomial computed subresultants sylvester matrix r e r order two pairs roots imaginary common quadratic factor r e r negative real roots easily expressed inequalities coefficients common monic factor must positive coefficients positive discriminant bialternate product methods computing points multiple hopf bifurcation discussed forthcoming paper govaerts guckenheimer khibnik 16 companion paper 20 examine issues relating implementing hopf continuation using resultant biproduct formulations study performance suite example problems current research interest neurobiology several algorithms including ones based bezout resultant bialter nate product applied compute curves hopf bifurcations two dimensional parameter space following six dimensional vector field gammag na 3 consider accuracy convergence root finding algorithms well number operations required compute curves hopf bifurcations summarizing findings number floating point operations required continuation curve hopf bifurcations using augmentation function based upon bezout resultant required slightly fewer operations 664777 flops use algorithm described jepson griewank reddien 17 based upon 2n dimensional augmentation function 701244 flops however test convergence root finding naturally chosen initial values parameter values near point double hopf bifurcation method based upon use bezout resultant augmentation function gave consistent results use determinant biproduct augmentation function substantially slower 2786163 flops biproduct calculations exploit sparsity biproduct matrix computing determinant acknowledgments research john guckenheimer mark myers partially supported grants national science foundation department energy many calculations performed software package dstool 3 developed cornell university bernd sturmfels partially supported nsf grants dms9201453 dms9258547 nyi david lucile packard fellowship r efficient algorithm determination certain bifurcation points journal computation applied mathematics lectures bifurcations versal families russian mathematical surveys dstool computer assisted exploration dynamical systems ams notices polynomials linear control theory generalized gaussnewton procedure multiresponse parameter estimation siam journal scientific statistical computing existence computation lufactorizations small pivots mathematics computation inversion matrices method variation parameters soviet mathematics evaluation determinants method variation parameters soviet mathematics conditions matrix characteristic roots negative real parts journal mathematical analysis applications two methods numerical detection hopf bifurcations international series numerical mathematics matrix computations classification unfoldings degenerate hopf bifurca tions journal differential equations preparation calculation hopf points direct method ima journal numerical analysis automatic differentiation algorithms theory dynamical systems computing hopf bifurcations ii three examples neurophysiology preprint four parameter family planar vector fields archive rational mechanics analysis new algorithms evaluation complex bifurcation points ordinary differential equations comparative numerical study applied mathematics computation eigenvalues matrices dependent upon parameter numerische math ematik numerical solution bifurcation nonlinear eigenvalue problems applications bifurcations theory linlbf program continuation bifurcation analysis equilibria codimension three continuation bifurcation numerical techniques applications generalized polynomial remainder sequences computer algebra symbolic algebraic computation comparison methods determining turning points nonlinear equa tions computing numerical detection hopf bifurcation points continuation bifurcation numerical techniques applications bifurcation theory computer algebra direct method computation hopf bifurcation points siam journal applied mathematics algorithm computation hopf bifurcation points comparison methods journal computational applied mathematics computation hopf branches bifurcating takens bogdanov points problems symmetries international series numerical math ematics algebraic eigenvalue problem evaluation zeros illconditioned polynomials part ii numerische mathematik tr ctr w govaerts yu kuznetsov b sijnave implementation hopf doublehopf continuation using bordering methods acm transactions mathematical software toms v24 n4 p418436 dec 1998 randall beer parameter space structure continuoustime recurrent neural networks neural computation v18 n12 p30093051 december 2006