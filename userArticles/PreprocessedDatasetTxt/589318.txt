rescaling stepsize selection proximal methods using separable generalized distances paper presents convergence proof technique broad class proximal algorithms perturbation term separable may contain barriers enforcing interval constraints two key ingredients analysis mild regularity condition differential behavior barrier one approaches interval boundary lower stepsize limit takes account curvature proximal term give two applications approach first prove subsequential convergence broad class proximal minimization algorithms convex optimization different stepsizes used coordinate applying methods dual convex program obtain wide class multiplier methods subsequential convergence primal dual iterates independent adjustment penalty parameter constraint adjustment rules penalty parameters generalize wellestablished scheme exponential method multipliers results may also viewed generalization recent work bental zibulevsky siam j optim 7 1997 pp 347366 auslender teboulle bentiba comput optim appl 12 1999 pp 3140 math oper res 24 1999 pp 645668 methods derived varphidivergences second application established full convergence novel stepsize condition bregmanfunctionbased proximal methods general monotone operator problems box prior results area required strong restrictive assumptions monotone operator b introduction denote possibly unbounded ndimensional box paper considers two closelyrelated problems minimization problem min fx 1 closed proper convex function variational inequality possibly setvalued maximal monotone operator nb x denotes cone vectors normal set b x well known mild regularity conditions 1 special case 2 subgradient mapping f last decade seen considerable progress theory proximal point methods based generalized distances 11 13 19 5 21 31 14 2 3 17 methods use scalarvalued regularization function derive betterbehaved versions problems 1 2 article consider separable regularization terms form scalar functions conforming general assumptions see assumption 21 particular assume x 2 int b approaches boundary b kr 1 dx yk 1 r 1 denotes gradient respect first vector argu ment distancelike measure example squared euclidean distance bregman distance 8 divergence 19 see section 22 using regularization terms proximal methods 1 take form x ff k positive ndimensional vector whose elements called stepsizes note allow different stepsizes coordinate suggested variety computational theoretical studies 32 5 2 3 moreover since kr 1 dx x k k 1 x approaches boundary b regularization acts stabilizing proximal term also kind barrier function keeping iterates within int b case variational inequality 2 3 generalizes finding x k1 satisfying recursion rrr derive general results types algorithms section 2 assuming stepsizes conform special rule takes account curvature proximal term rule although restrictive appears cover cases greatest practical interest shall see covers stepsizepenalty selection rules proposed 32 5 2 3 section 3 uses results section 2 obtain subsequential convergence results generalized proximal minimization algorithm 3 critical application 3 considered section 32 f minus dual function convex program st differentiable convex functions 1 also assume problem feasible ie choosing b box containing nonnegative orthant f negative dual function 5 may implement 3 via multiplier method sequence unconstrained penalized versions 5 must solved construction leads class multiplier methods extremely broad subsuming classical quadratic augmented lagrangian exponential method multipliers 32 6 multiplier methods stepsize choice ensures indices x k corresponding penalty term augmented become flat permit infeasibility primal limit points empirically technique speeds convergence also appears convergence rate analysis 32 exponential method multipliers case bental zibulevsky 5 proved optimality accumulation points exponential method together class proximal terms closely related divergences results extended 3 section 3 places results broader context includes bregman distances section 4 restrict attention bregman distances known better part decade ddelta delta bregman distance stepsizes vary coordinate recursion 4 converges solution variational inequality 2 various special cases subdifferential closed proper convex function f domt int b meaning constraints must already embedded operator 9 results extended paramonotone operators category includes special case unfortunately many interesting practical cases subdifferential maps saddle functions paramonotone recently auslender et al 2 obtained strong results general maximal monotone specific divergence choice ddelta delta noted 4 results extended generally nonbregman case ddelta delta obtained adding quadratic member class phi 2 3 1 actually results section 32 continue hold 28 one supposes closed proper convex assumes appropriate conditions effective domains objective constraints 24 chapter 28 however generality makes proofs convoluted dropped sake simplicity exposition page 4 rrr 3599 section 4 shows convergence general maximal monotone proximal method 4 ddelta delta bregman distance solution 2 impose additional assumptions derived section 2 first assume bregman function used construct distance twicedifferentiable part standard bregman function setup second addition general stepsize rule also require stepsizes vary coordinate ff n k resulting condition stronger usual requirement stepsize simply bounded away zero crucial analysis blends techniques section 2 traditional fejer monotonicity arguments still managed substitute conditions ddelta delta ff k parts algorithm conditions part problem solved finally allow calculations required recursions 3 4 performed approximately likely necessary practice rescaling minimization case section 3 adopt constructive approximation criterion inspired 17 29 however criterion tailored proximal minimization case appears new variational inequality analysis section 4 use simple verifiable criterion 14 although extension sophisticated criterion 29 may well possible summary primary contributions paper ffl novel convergence proof framework broad class proximal algorithms ffl using framework establish subsequential convergence wide range proximal minimization algorithms 3 differing stepsize parameters coordinate result turn leads subsequential convergence broad class multiplier methods differing penalty parameters constraint ffl using framework show convergence interior bregman proximal point algorithms maximal monotone operators novel stepsize condition without usual restrictive assumptions operator new proximal minimization approximation criterion section 3 constitutes additional contribution fundamental analysis section develops fundamental analysis necessary results concentrate attention variational problem 2 since subsumes minimization problem 1 mild assumptions order simplify notation denote 00 rrr able present necessary assumptions functions assumption 21 following properties 211 closed strictly convex minimum moreover int dom delta 212 continuously differentiable exists strictly positive 213 essentially smooth 24 chapter 26 214 exist ae ffl 0 either assumption strict convexity standard generalized proximal methods assumption twice differentiability also quite common although many existing results require oncedifferentiable essential smoothness assumption makes distance act like barrier function forcing iterates defined recursion 4 hence approximate version 6 remain interior box b section 22 specialize assumptions case bregman distances divergences similar comments made finally fourth part assumption new theory generalized proximal methods restrictive practice particular show section 22 bregman distances divergences condition written terms kernels used obtain regularizations holds examples aware addition make following standard regularity assumption view barrier function properties required sensible application 4 assumption 22 domt int b 6 able present proximal minimization algorithm rescaling proximal method variational inequality rpmvi 1 initialization let choose scalar c 0 initial iterate x 0 2 int b 2 iteration choose ff k 2 r n ff k phi b find x k1 e k1 page 6 rrr 3599 c let repeat iteration guarantee convergence rpmvi need additional assumptions stepsizes fff k error sequence fe k g see assumption 23 define whence clear 6 assumption 23 let ffi k g real sequence converging zero error sequence fe k g regularization functions stepsizes fff k must chosen order guarantee 231 ff 232 x accumulation point fx k g ie infinite set k n x infinite set k 0 k x assumption 232 may seem artificial point sections 3 4 describe settings easily verifiable 21 convergence analysis assume throughout section assumptions 21 22 hold sequences conforming recursions rpmvi algorithm assumption 23 exist sections 3 4 present conditions specific settings guarantee existence sequences lemma 24 let x 2 r n limit point fx k g ie x k k x infinite set k n lim lim inf lim sup proof consider three possible cases first suppose sake contradiction assume using assumption 232 infinite set k 0 k 0 rrr k 2 k 0 jfl k x therefore ff ff assumption 231 choice ff k result contradicts next consider case x suppose lim inf kk1 fl k using assumption 232 must 0 infinite set k 0 k k 2 k 0 ff ff cd 00 let ffl assumption 214 infinite set k 00 k 0 x k 2 k 00 conclude assumption 2d 00 aecd 00 since x sufficiently large k 2 k 0 page 8 rrr 3599 delta x minimum x kgamma1 implies 0 hence ff sufficiently large k 2 k 0 contradiction finally case analogous case lemma 25 let x limit point fx k g ie x k k x infinite set k n proof assumption 22 must exist e ex monotonicity implies k 0 show unboundedness ffl k gk would contradict inequality sufficiently large k unbounded must exist infinite k 0 k ffl k gk 0 converges least one ffl k implies unbounded coordinate either therefore unbounded coordinate ffl k gk 0 hand coordinates ffl k also bounded thus sufficiently large k 2 k must negative contradicting 9 2 finally main convergence theorem rpmvi follows rrr theorem 26 fx k g sequence generated rpmvi algorithm assumptions 21 22 23 holding limit points fx k g solutions variational inequality problem 2 proof let x limit point fx k g ie x k k x infinite set k n lemma 25 know corresponding sequence must exist k 0 k must outer semicontinuous 27 128b follows fl 2 x lemma 24 implies conditions equivalent incidentally possible eliminate requirement twicedifferentiability delta cost additional complexity description method specifically consider replacing assumption 214 condition exist functions stepsizes selected scalar c 0 k 0 ff k conclusions theorem 26 continue hold may examine variation analysis subsequent research present approach equivalent taking l choice since 00 rate change 0 delta around 22 examples functions present example functions conform assumption 21 particu lar show two classes regularizations widely studied literature bregman distances 11 13 divergences 19 conform assumption mild restrictions 221 bregman distances bregman distances introduced 8 studied context proximal methods 11 12 13 well many subsequent works construct regularization one uses auxiliary convex function h defines nonseparable distances also constructed similar way separable case common following properties guarantee assumption 21 holds assumption 27 following properties 271 h closed int continuously differentiable strictly positive second derivative throughout 272 h essentially smooth 273 exist ae 0 ffl 0 either note assumption 271 implies h strictly convex assumption 273 corresponds assumption 214 since 00 fortunately restrictive consider case finite since lim x know h 00 must unbounded x violate assumption h 00 would oscillate unboundedly x far aware every separable bregman function proposed far conforms assumption 273 stringent easiertoverify condition follows lemma 28 ffl 0 x nonincreasing x 2 b nondecreasing assumption 273 holds proof suppose therefore assumption 273 holds 1 case b 1 analogous 2 examples functions h assumptions hold log x finally note finite yet assume h must approach finite limit x similarly x assumption quite common theory bregman distances 11 13 9 29 similarly 21 needed results section 3 use however variational inequality analysis section 4 rrr 3599 page 11 222 divergences divergence regularizations studied context proximal methods example 19 recently 5 3 works box considered positive orthant ie auxiliary strictly convex scalar function used define distance time following hypotheses used guarantee assumption 21 assumption 29 function r gamma1 1 291 closed convex int 292 twice differentiable 0 1 00 0 0 293 294 essentially smooth 295 exists ae 0 ae 0 00 slight variations assumptions appear example 5 3 together following examples next lemma states assumption 295 implies assumption 214 lemma 210 let defined 10 assumption 214 equivalent existence ae 0 ae 0 00 proof first observe 00 00 page 12 rrr 3599 therefore assumption 214 reduces taking letting range 0 x setting conversely 12 true 11 holds arbitrary choice ffl note 5 one assumes iterations form ff k greater cx k positive constant 2 3 property guaranteed redefining distance measure assuming stepsizes bounded away zero case iteration lim inf k1 e rewriting iteration respect instead recover rule 5 turns techniques special case stepsize choice rule gives case divergence identical one redefines constant factor c thus reader note class divergences described assumption 29 encompasses regularizations studied 5 2 3 particular includes classes phi 1 phi 2 described 3 however stepsize rule rpmvi stringent one 5 2 3 also assumes stepsize bounded away zero overcome slight restriction point assumption ff k used first part proof lemma 24 replaced assumption 00 continuous strictly positive condition holds divergences since 00 sense results seen extensions 5 2 3 rrr 3 proximal minimization methods rescaling section applies analysis rpmvi method minimization problem 1 leave assumption 21 standing assumption also make following standard regularity assumption view barrier function properties required sensible application 3 assumption 31 dom f int b 6 note since int b open assumption implies ri dom f int b 6 implies dom f int b 6 using 24 theorem 238 one show minimization problem 1 equivalent variational inequality problem 2 moreover assumption 22 holds specialize rpmvi rescaling proximal minimization method rpmm 1 initialization choose c 0 oe 2 0 1 choose nonnegative scalar sequences fs k g fz k g 2 iteration choose ff k 2 r n ff k phi b find x oe ae k1 oe standing convention min psi z k1 whenever c let repeat iteration note one chooses k z reduces constructive criterion reminiscent 29 page 14 rrr 3599 31 convergence analysis start showing iteration step well defined f bounded b lemma 32 f bounded b unique point solves iteration step rpmm e solution 1314 exists f bounded b proof let lower bound f b given 2 r level set last set level set b must bounded since assumption 211 function attains minimum unique point x k 24 corollary 871 therefore fdelta attains minimum b uniqueness minimum follows strict convexity ddelta x k 2 apply convergence analysis previous section sequence fx k g computed rpmm suffices show assumption 23 holds verification assumption 231 straightforward lemma 33 definition ae k oe k 1 assumption 231 holds rpmm proof nonnegativity fs k g fz k g follows ffi k g also nonnegative one also fi k 0 moreover since oe 2 0 1 oe ff k assumption 231 holds 2 7 define k 0 let fl k 2 r n vector elements lemma 34 rrr 3599 page 15 proof claim fl k 2 fx k follows definition fl k second claim using convexity delta x ff using 14 follows ff ae k ae k oe fi fi x ae k oe gammas k proving next result state helpful technical lemma lemma 35 22 section 22 suppose fa k g ffl k g ae r sequences fa k g bounded exists finite recursion k1 k holds k convergent possible establish assumption 232 also holds lemma 36 f bounded b ffx k g convergent hence assumption 232 holds rpmm proof using lemma 34 ns recalling fs k g summable lemma 35 implies ffx k g convergent sequence page using lemma 34 follows taking limits conclude fl k thus theorem 26 implies optimality accumulation points sequence g strengthen observation theorem 37 suppose assumptions 21 31 hold f bounded b fx k g limit point ffx k g converges infimum f b limit points fx k g minimizers f b condition guarantees existence limit points fx k g boundedness solution set level set f proof noted lemma 36 implies assumption 232 holds assumption 23 holds entirety assumption 21 holds hypothesis setting assumption 31 implies assumption 22 thus conclusions theorem 26 apply let x limit point fx k g ie x k k x infinite set k n theorem 26 asserts assumption 31 x minimizer f b moreover since lemma 25 states ffl k gk bounded since ffx k g convergent lemma 36 min lim therefore lim k1 fx k finally boundedness level set proper closed convex function implies boundedness level sets 24 corollary 871 lemma 36 states ffx k g convergent consequently bounded fx k g also bounded limit points 2 32 multiplier methods discuss applying rpmm dual convex program 5 obtain multiplier methods use proximal methods derive multiplier methods constrained convex optimization nowclassical subject may traced seminal paper 26 context generalized proximal methods applications found example 30 13 19 21 31 3 17 section consider case proximal step done exactly ie let e 30 13 19 17 unfortunately approximatestep acceptance rule rpmm translate directly easily verifiable acceptance criterion approximate solution penalized problem 17 low however partial results direction may obtained stringent assumptions original problem 5 see appendix b criterion spirit 14 depend assumptions subject ongoing research 15 observe approximation criteria 17 29 also translate readily multiplier method rrr 3599 page 17 setting hand assumption primal objective function g 0 strongly convex 26 21 3 present inexact multiplier methods based rather different acceptance rule involving optimizing augmented lagrangian function within tolerance ffl minimum value consider convex problem 5 let ffi c denote indicator function convex set c define f minus dual function associated 5 plus dual problem 5 equivalent minimization f furthermore assume assumption 38381 primal problem 5 finite optimal value conforms slater condition 382 conform assumption 21 383 x 0 x 2 dom f f defined 15 assumption following consequences assumption 381 implies dual solution set nonempty bounded 16 duality gap assumption 383 implies assumption 31 holds f defined 15 assumption 38 fix e iterate x k1 rpmm applied negative dual functional f may calculated following multiplier method whenever unconstrained problems 17 solutions phi phi denotes monotone conjugate 24 p 111 respect first argument phi g 3 theorem 310 gives conditions guaranteeing k1 satisfying 17 exists relegate technical aspects proof equivalence 1618 rpmm applied f defined 15 appendix since similar earlier 2 case interest includes classical method multipliers problems inequality constraints 26 along various extensions described 13 20 3 classical conjugate function defined 24 chapter 12 via r n 1 1 monotone conjugate classical conjugate page proofs various special cases 1718 example 30 13 19 21 17 particular corollary a4 establishes equivalence two calculations given equivalence theorem 37 asserts subsequential convergence sequence dual solution 5 primal sequence however historically harder prove good behavior example case bregman distances guarantee feasibility primal accumulation points relied stringent assumptions like r n ae int b 13 strict complementarity 18 case rpmm strong stepsize restrictions feasibility therefore optimality accumulation points fy k g easily demonstrated theorem 39 suppose assumption 38 holds pick scalar c 0 let x 0 2 r n suppose possible obtain sequence fff k obeys recursions 16 18 fx k g bounded accumulation points solutions dual 5 moreover lim sup lim fg 0 k g converges optimal value primal problem 5 therefore accumulation point fy k g solves primal problem proof shown corollary a4 sequence fx k g would computed using rpmm solve dual problem minimize f particular fx k g limit points must nonnegative moreover slater condition implies dual function bounded level sets boundedness fx k g optimality limit points follow theorem 37 let us analyze primal sequence role 7 e k let fx k gk convergent subsequence fx k g x respective accumulation point x k k x lemma 24 implies fx k g bounded relations imply rrr 3599 page 19 suppose purposes contradiction 20 hold must infinite set k ae n ffl 0 bounded exists refined subsequence k 0 k fx k g k 0 convergent limit imply g k k 0 gamma1 since lemma 25 asserts fi k bounded conclude k gamma1 however divergence would imply x k 0 infinitely many k 2 k 0 k contradiction 23 therefore lim 20 holds finally prove fg 0 k g converges optimal value may use 17 18 chain rule see k minimizes lagrangian corresponding primal problem fixed multiplier x k hence let gammaf denote dual optimal value equal primal optimal value since duality gap theorem 37 states fx k taking limits 25 using 24 follows lim feasibility optimality accumulation points fy k g consequences continuity g finally natural seek conditions penalized subproblems 17 must solutions primal sequence fy k g bounded following result addresses questions standard assumption bounded solution set theorem 310 suppose primal solution set bounded given ff k 0 exist satisfying recursions 1718 moreover primal sequence fy k g bounded proof first assertion suffices show penalized problems 17 solutions given closed proper convex function define recession function 1 via dom may chosen arbitrarily 24 theorem 85 boundedness primal solution set equivalent 7 section 53 page 20 rrr 3599 thus existence solution 17 corollary lemma a5 appendix along sum rule recession functions 24 theorem 93 prove fy k g bounded theorem 39 shows sequences fg k g 27 unboundedness fy k g would imply unboundedness would contradict g 0 k convergence optimal value 2 remark penalty parameter adjustment rule 16 discussed section 222 essentially subsumes context broader divergences corresponding rules described 32 exponential method multipliers 5 3 4 general divergence setting end section giving examples phi functions may derived separable bregman distances see section 221 examples may obtained 21 28 bregmanderived distance whence phi h phi denotes standard monotone conjugate h note phi used minimization operation 17 additive terms h w constant may discarded following examples may easily verified may disregarded choice gives classical quadratic method multipliers inequality constraints gammaw term may disregarded yielding exponentional method multipliers 4 bregman interior point proximal methods variational inequalities turn attention boxconstrained variational inequality problem 2 possibly setvalued maximal monotone operator section confine bregman distances defined section 22 augment assumption 22 follows rrr 3599 page 21 assumption 41 maximal monotone solution set 2 nonempty exists e goal show convergence approximate version iteration 4 without conditions modify extend assumption 27 follows assumption 42 properties specified assumption 27 furthermore h continuous defining 421 x 2 b ff 2 r level set fy 2 int b j h x ff g bounded 422 fx k g ae int b converges x 2 r n lim k1 h x x k 423 rge h note finite b corresponding h required take finite value algorithm stated box interior proximal point algorithm bippa 1 initialization let 2 iteration choose ff k ff k c maxf1 h 00x g find vectors repeat iteration 41 convergence analysis first cite result showing iteration step bippa well defined lemma 43 13 theorem 4i assumption 42 unique point x k1 solves iteration step 28 bippa e note shown unpublished dissertation 28 28 unique exact solution even assumption 423 hold result permits one dispense completely assumption 423 however proof essentially minor modificiation 1 theorem a1 quite involved include guarantee convergence bippa must assume vanishing behavior fe k g use assumptions 14 although general criterion used rpmm conditions better suited analysis since permit us use properties associated fejer monotonicity still feasible enforce computationally page 22 rrr 3599 assumption 44 14 error sequence fe k g conforms tox exists finite note assumption implies assumption 231 holds k1 state necessary lemmas lemma 46 assumption 44 holds sequence fx k g bounded h proof result follow 14 lemma 3 show z 2 nb ez exists finite butx assumption 44 implies right hand side relation finite hence exists finite using assumption 44 conclude ez exists finite 2 also use key result solodov svaiter 29 theorem 47 29 theorem 24 let h satisfy assumption 42 given two sequences fx k g ae b fy k g ae int b either one convergent lim k1 h sequence also converges limit theorem implies bregman function classical sense 8 10 using theorem 47 lemma 46 derive corollary 48 assumptions 41 42 44 fx k g least one limit point moreover infinite set k n x k k x x x therefore assumption 232 holds rrr presenting main convergence theorem bippa present final technical lemma help us prove uniqueness accumulations points fx k g lemma 49 assumption 44 z converges value 0 1 denote dz proof consider z 2 implies 29 holds using assumption 44 h hypotheses lemma 35 satisfied converges necessarily nonnegative value 2 main convergence theorem follows theorem 410 assumptions 41 42 44 fx k g converges solution proof let x accumulation point fx k g ie x k k x infinite set k n point exists lemma 46 theorem 26 prove uniqueness limit point assumption 422 know defined lemma 49 zero suppose fx k g another accumulation point x k k 0 x 0 infinite set k 0 n follows theorem 47 x another possible application fundamental analysis try generalize idea adding square euclidean norm arbitrary generalized distance obtain fejer monotonicity solutions 2 2 3 special case divergences difficulty generalize condition defines class phi 2 3 topic subject ongoing research r interiorproximal methods convex linearly constrained problems extension variational problems logarithmicquadratic proximal method variational inequalities interior proximal multiplier methods based second order homogeneous kernels modified lagrangian methods variational inequality problems penaltybarrier multiplier methods convex programming problems nonlinear programming constrained optimization lagrange multiplier methods relaxation method finding common point convex sets application solution problems convex programming interiorpoint method bregman functions variational inequality problem paramonotone operators iterative rowaction method interval convex program ming proximal minimization algorithms dfunctions convergence analysis proximallike minimization algorithms using bregman functions nonlinear proximal point algorithms using bregman functions approximate iterations bregmanfunctionbased proximal algorithms practical general approximation criterion methods multipliers based bregman distances necessary sufficient condition bounded multipliers nonconvex programming strict convex regularizations augmented lagrangian methods proximal points methods convex optimization twice differentiable cubic augmented lagrangian proximal minimization methods generalized bregman functions introduction optimization extension fenchels duality theorem convex functions convex analysis conjugate duality optimization augmented lagrangians applications proximal point algorithm convex programming variational analysis springerverlag topicos em metodos de ponto proximal inexact hybrid generalized proximal point algorithm new results theory bregman functions entropic proximal mappings applications nonlinear programming convergence proximallike algorithms convergence exponential multiplier method convex programming tr ctr alfred auslender paulo j silva marc teboulle nonmonotone projected gradient methods based barrier euclidean distances computational optimization applications v38 n3 p305327 december 2007 paulo j silva jonathan eckstein doubleregularization proximal methods complementarity applications computational optimization applications v33 n23 p115156 march 2006