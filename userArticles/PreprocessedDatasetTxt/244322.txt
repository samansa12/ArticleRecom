framework resourceconstrained rateoptimal software pipelining abstractthe rapid advances highperformance computer architecture compilation techniques provide challenges opportunities exploit rich solution space software pipelined loop schedules paper develop framework construct software pipelined loop schedule runs given architecture fixed number processor resources maximum possible iteration rate la rateoptimal minimizing number buffersa close approximation minimizing number registersthe main contributions paper first demonstrate problem described simple mathematical formulation precise optimization objectives periodic linear scheduling framework mathematical formulation provides clear picture permits one visualize overall solution space rateoptimal schedules different sets constraints secondly show precise mathematical formulation solution make significant performance difference evaluated performance method three leading contemporary heuristic methods experimental results show method described paper performed significantly better methodsthe techniques proposed paper useful two different ways 1 compiler option used generating faster schedules performancecritical loops interested users willing trade cost longer compile time faster runtime 2 framework compiler writers evaluate improve heuristicsbased approaches providing quantitative information much heuristic methods could improved b introduction oftware pipelining proposed efficient method loop scheduling derives static parallel schedule periodic pattern overlaps instructions different iterations loop body software pipelining successfully applied highperformance architectures 1 2 3 4 5 6 7 8 9 10 11 12 13 14 today rapid advances computer architecture hardware software technology r govindarajan supercomputer education research center department computer science automa tion indian institute science bangalore 560 012 india e mailgovindserciiscernetin erik altman ibm j watson research center yorktown heights ny 10598 usa e mailerikwatsonibmcom guang gao school computer science mcgill university 3480 university street montreal h3a 2a7 canada emailgaocsmcgillca work done first two authors mcgill university research partly funded research grants micronet network centres excellence canada nserc canada provide rich solution space involving large number schedules software pipelining exploiting space good compiletime schedules important find fast softwarepipelined schedule makes best use machine resources function units registers available underlying architecture paper interested addressing following software pipelining problem problem 1 opt given loop l machine architecture construct schedule achieves highest performance l within resource constraints using minimum number registers performance softwarepipelined schedule measured initiation rate successive iterations thus highest performance refers fastest sched ule schedule maximum initiation rate schedule maximum initiation rate called rateoptimal schedule following two important questions related problem 1 opt problem question 1 simple mathematical formulation developed opt problem question 2 optimality formulation pay real terms need answer question order answer question 1 consider instance problem 1 problem 2 optt given loop l machine architecture iteration period construct schedule one exists period satisfying resource constraints using minimum number registers paper consider target architectures involving pipelined nonpipelined execution units approach solving optt problem based periodic scheduling framework software pipelining framework 15 11 based periodic scheduling frame work present simple integer linear programming ilp formulation optt able express resource constraints linear constraints combining resource constraints work ning gao tight upper bound register requirement specified using linear constraints 11 unified formulation optt problem obtained 11 use fifo buffers model register requirement paper relationship ninggao formulation better understood examining fig 2 page tradeoff buffer function unit optimality depicted ieee transactions parallel distributed systems vol xx month 1996 readers familiar related work field find optimality objective problem formulation ambitious course general complexity optimal solution nphard heuristics needed solve problem efficiently however feel clearly stated optimality objective problem formulation quite important several reasons 1 solution space good schedules 1 increased considerably rapid advances highperformance architecture current future generation processors likely contain multiple function units likewise compilers advances made dependence analysis array dataflow analysis 16 alias analysis 17 expose instructionlevel parallelism code loop unrolling loop fusion techniques increase size loop body 18 given loop likely many good schedules choose optimality criteria essential guide selection best ones 2 always good number users performancecritical applications runtime performance applications utmost concern applications user may willing trade longer compilation time improvement runtime speed compilers future generation highperformance architectures deny opportunities users techniques developed paper provided users via compiler option 3 techniques proposed paper also used scheduling framework ascertain optimal solution evaluate improve exist ingnewly proposed heuristic scheduling methods thus usefulness techniques proposed paper viewed light items 1 3 implemented solution method tested 1008 loops extracted various benchmark programs spec92 nas kernels linpack livermore loops loops scheduled different architectural configurations involving pipelined nonpipelined execution units experiments able obtain optimal schedule 80 test cases considered experiments run sparc 20 required execution time median ranging 06 27 seconds different architectural configura tions geometric mean execution time ranged 09 74 seconds question 2 question addressed comparing method 3 approaches huffs slack scheduling 7 wang eisenbeis jourdan sus frlc variant despdecomposed software pipelining 19 gasperoni schwiegelshohns modified list scheduling approach 20 implemented solution method optt opt problems well three heuristic methods experimental scheduling testbed measured perfor discussion solution space softwarepipelined schedules presented section iii mance various scheduling methods 1008 kernel loops ilp approach yielded schedules faster 6 test cases compared slack scheduling 21 test cases compared frlc method 27 test cases compared modified list schedul ing terms buffer requirement ilp approach significantly better three heuristic methods spectively 61 87 83 test cases 2 paper concentrated loop bodies without conditional statements though possible extend approach loops involving conditional statements using techniques discussed in21 clear whether optimality objective still hold defer study future work work focus architectures involving pipelined nonpipelined function units function units arbitrary structural hazards dealt 22 extending formulation proposed nonpipelined function units finally become evident proposed framework easily handle optimization problems software pipelining example given number available registers minimize either number required fus weighted sum fus different fu types possible problem formulations observed figure 2 refer page 6 paper organized follows following sec tion motivate approach help exam ple solution space software pipelined schedules discussed section iii section iv formulation optt problem pipelined execution units devel oped optt formulation nonpipelined function units presented section v section vi deals iterative solution opt problem section vii results scheduling 1008 benchmark loops reported ilp schedules compared schedules generated leading heuristic methods section viii section ix discuss related work concluding remarks presented section x ii background motivation section motivate opt problem solution method presented rest paper help program example motivating example introduce notion rateoptimal schedules resource constraints illustrate search among ones optimize register usage rigorous introduction concepts given next section adopt motivating example loop l figure 1 given rau et al 13 c language instruction level representations loop given fig 1b dependence graph depicted figure 1a assume instruction 0 2 small number test cases less 4 ilp schedule worse terms either initiation rate buffer requirement due fact limit ilp search maximum 3 minutes details results presented section vii govindarajan altman gao resourceconstrained rateoptimal software pipelining 3 dependence graph address ai new ai branch 0 n b program representation fig 1 example loop executed integer fu execution time 1 time unit instructions 2 floating point fp add instructions executed fp unit execution time 2 time units lastly fp load 1 fp store 5 executed loadstore unit execution times 2 1 time units respectively assume architecture 3 integer fus 2 fp units 1 loadstore unit fur ther subsection assume pipelined function units free structural hazards operation initiated function unit time step scheduling nonpipelined function units discussed section iic performance softwarepipelined schedule l measured initiation rate successive itera tions following discussion often use reciprocal initiation rate initiation interval let us first establish lower bound ie shortest initiation interval loop l various constraints well known initiation interval governed loopcarried dependencies graph resource constraints presented architecture loopcarried dependency constraint shortest initiation interval dep given 8cycles c dc sum delays latencies instructions nodes cycle c dependence graph mc sum dependence distances around cycle c 23 cycles c crit maximum value dccrit mccrit termed critical cycles graph example graph refer fig 1a self loop instructions critical cycle thus dep given dependency graph 2 resource constraints architecture also impose lower bound initiation interval resource type function unit eg integer fu impose lower bound resource constraint bound res instructions execute fu type r number fus type r example res integer res res loadstore overall resource constraint bound denoted res res r fu types r thus considering dependence resource constraints lower bound minimum initiation interval lb example pipelined fus schedule loop l obeys resource constraint period greater equal lb 2 smallest iteration period tmin lb resourceconstrained schedule exists called rate optimal period given resource constraints given loop observed initiation rate 1 given ddg may improved unrolling graph number times unrolling factor decided based either dep res value however purpose paper consider unrolling graph though techniques developed paper used cases well 4 ieee transactions parallel distributed systems vol xx month 1996 schedule motivating example time steps b illustration opt problem paper investigate periodic linear schedules time various operations begin execution governed simple linear relationship linear schedule considered paper jth instance instruction begins execution time integer offset initiation interval iteration period given schedule initiation rate schedule table gives possible schedule schedule 2 example loop schedule obtained linear schedule form prologue time step 0 time step repetitive pattern time steps 10 11 first time step repetitive pattern time step store instructions executed requiring 1 fp unit 1 integer fu 1 loadstore unit instructions 3 4 5 executed second time step time step requiring 2 fp units 1 loadstore unit since resource requirement repetitive pattern less available architecture resourceconstrained schedule schedule one resourceconstrained schedules achieves fastest initiation interval next let us compute register requirement schedule schedule instruction 0 fires six times first 5 fires since data dependence values produced 0 must buffered accessed 5 order insure correct execution program conceptually sort fifo buffers need placed producer consumer nodes paper assume buffer reserved time step instruction issued remain reserved last instruction consuming value completes ex ecution size buffer depends lifetime value therefore buffer size 6 needs allocated instruction 0 another example four instances 1 executed execution first instance 4 consequently buffer size 4 required instruction similar way buffer size 1 required instructions 3 4 buffer size 2 required instruction 5 store successor instruc tions since store latency 1 5 requires 1 buffer thus total buffer size 15 required schedule shown instruction total conceptual fifo buffers either directly implemented using dedicated architecture features circular buffers rotating registers 24 mapped physical registers appropriate register moves conventional architectures described 8 25 25 26 demonstrated minimum buffer requirement provides tight upper bound total register requirement buffer assignment done classical graph coloring method subsequently performed generally leads minimum register quirement paper assume coloring phase always performed buffer size de termined consequently restrict attention fifo buffers logical registers question interest exist rate optimal schedules l resource constraint use fewer registers exactly posed problem 1 opt problem introduction answer affirmative illustrated schedule b table iib uses 14 buffers schedule also resource constrained iteration period 2 values instructions buffer requirements schedule shown instruction total may verified schedule period 2 satisfying resource constraint uses less 14 buffers thus schedule b solution sought opt problem rateoptimal schedule given loop l note generated schedule using method outlined section ivc govindarajan altman gao resourceconstrained rateoptimal software pipelining 5 ii schedule b motivating example time steps c schedule nonpipelined fus next let us focus issues involved scheduling nonpipelined fus fus nonpipelined instruction initiated execution pipe continues keep fu busy completes execution thus res lower bound nonpipelined fus res fus type r ir represent set instructions execute type r represent execution time instruction motivating example section iia res integer res res loadstore thus lower bound lb schedule schedule c nonpipelined fus shown table iii table use notation eg 2 indicate instruction 2 continues execution previous time step repetitive pattern starting time step 9 indicates time step 2 fp 1 integer 1 loadstore units quired thus appears schedule c resourceconstrained rateoptimal schedule nonpipelined fus unfortunately schedule legal schedule c cannot find fixed assignment instructions fus mean compiletime mapping instructions specific fus cannot done repetitive pattern see consider repetitive pattern starting time step 9 assign first fp unit instruction i2 time step 9 second fp unit i4 time step 10 first fp unit free time step 11 second fp unit free time 12 time step 9 taking time steps modulo 3 mapping 3 first fp unit time step 11 second fp unit time 9 implies instruction migrates switches one fu another course execution switching impractical order ensure instruction switch fus execution require fixed assignment instructions fus unfortunately exist schedule period fixed fu assignment requires 2 fp units addition 1 integer 1 loadstore unit indicated example architectures nonpipelined fus software pipelining problem involves instruction scheduling instruction scheduled execution also mapping instructions assigned fus thus obtain rateoptimal resourceconstrained software pipelining need formulate two related problems namely scheduling mapping unified framework section v discusses formulation nonpipelined fus table iic shows correct software pipelined schedule motivating example schedule instructions share first fp unit 2 executes second fp unit note period schedule order give proper perspective problems addressed paper discussion solution space linear schedules presented following section iii solution space linear schedules section presents overall picture solution space periodic linear schedules p working within space set periodic linear schedules interest periodic schedules use r function units less denoted region labeled r obviously r subset p may noted initiation intervals schedules r greater equal tmin defined section ii since interested rateoptimal schedules denote schedules period tmin region labeled periodic schedules use r function units intersection sets r refers set schedules period tmin using r less function units denoted region labeled tr schedules tr rateoptimal resource constraint 6 ieee transactions parallel distributed systems vol xx month 1996 iii schedule c nonpipelined execution units time steps iv schedule fixed fu assignment time steps tr r tr r schedule space schedule space intersect trb b tb interesects trb trb buffer optimal trr trr schedules period tmin r schedules using r fewer resources schedules period tmin minimum buffers tr schedules period tmin using r fewer resources schedules period tmin using r fewer resources minimum buffers schedules period tmin using r fewer resources n fewer registers fig 2 schedule space given loop r schedule uses r resources faster initiation interval example loop l schedule element tr definition tmin guaranteed exists least one schedule uses r less resources hence tr always nonempty optimally use available registers architec ture important pick tr schedule uses minimum registers set schedules denoted region labeled trb note existence schedule guaranteed fact region tr nonempty definition set trb example schedule member trb schedule b put problem statement proper perspective goal opt problem see introduction problem 1 find linear schedule lies within region trb however compiler writer trb region indirect interest following sense compiler writer interested finding schedule shortest period using r fewer fus requiring n registers available registers machine schedules form trr region shown fig 2 region trr may contained may contain may intersect may disjoint trb 3 one four relationships possible due following reasons 1 guarantee exists schedule period using n fewer registers case 3 sake clarity fig 2 show case trr intersects trb govindarajan altman gao resourceconstrained rateoptimal software pipelining 7 trr null 4 2 mentioned section iib logical buffers provide good approximation physical registers one easily see trr schedule exists possible either trr schedules trb trb schedules trr schedules 3 though minimum buffer requirement provides tight upper bound register requirement minimum register schedule need necessarily minimum buffer schedule thus trr intersects trb trr contained trb 4 last though unlikely possible none trr schedules trb case seen later possible modify formulation sections iv v find trr schedule using approach followed 26 27 details approaches additional complexity introduced beyond scope paper reader referred 26 details due additional complexity introduced approach modeling register requirements directly restrict attention paper finding trb schedule lastly figure 2 region labeled denotes set schedules initiation interval tmin use minimum number registers initiation interval tmin may schedules use fewer registers trb however schedule tb may may satisfy resource constraint r example loop l fact intersection tb r empty figure 2a depicts situation course always case fig 2b represents case tb intersects r notice case trb subset tb interesting feature tb region schedule belonging tb computed efficiently using lowdegree polynomial time algorithm developed ning gao 11 alluded introduction fact used key heuristic later searching solution trb specifically register requirement schedule used lower bound number registers opt problem iv optt formulation pipelined fus section first briefly introduce background material subsequent subsection develop integer program formulation optt problem section ivc optt formulation motivating example fig 1 shown definitions paper deals innermost loops represent loops data dependence graph ddg nodes represent instructions arcs dependences instructions loopcarried dependences ddg could cyclic node produces result 4 case either next higher value needs considered register spilling required current iteration result used node j dd iterations later say arc j dependence distance dd use ij denote ddg represented means dd initial tokens arc j definition iv1 data dependence graph 4tuple v set nodes e set dependence distance vector arc set e delay function node set v paper focus periodic schedule form discussed section ii periodic schedule said feasible obeys dependence constraints imposed ddg following lemma due reiter 23 characterizes feasible periodic schedules lemma iv1 reiter 23 initial execution times feasible periodic schedule period satisfy set inequalities delay node period ij dependence distance arc j paper assume rateoptimal period tmin always integer given ddg unrolled suitable number times resulting unrolled ddg integer period concentrated paper straightline code huff found large majority fortran loops contain conditionals 7 loops involving conditionals assume hardware model supports predicated execution 24 ifconversion 28 performed support model well 13 shown predicated execution simplifies code generation modulo scheduling b ilp formulation order represent repetitive pattern also known modulo reservation table software pipelined schedule succinct form introduce matrix matrix theta n matrix period schedule n number nodes ddg element either 0 1 depending whether instruction scheduled execution time step repetitive pattern make things clearer consider repetitive pattern schedule b 6 matrix requirements particular fu type r time step computed adding elements row correspond instructions executed fu type r example number fp units required time step calculated adding t2 t3 t4 thus seen 2 fp units required time step 0 1 fp unit required time step 1 similarly adding t1 t5 observe number loadstore units required time step 1 thus 8 ieee transactions parallel distributed systems vol xx month 1996 general number fus type r required time schedule x ti ir denotes set instructions execute r f r fus type r resource constraints architecture specified ti f r r 2 next concentrate constraints trix order ensure instruction scheduled exactly repetitive pattern require sum column matrix 1 also expressed linear constraint schedule b values variables used linear form main question relate matrix variables purpose rewrite words k defined represents modulo operation schedule b observe position instruction repetitive pattern perhaps two different ways therefore express terms theta notice transpose matrix used equation transpose theta 0 1 transpose using equation 4 rewriting matrix form obtain theta 6 6 6 6 6 6 4 theta general transpose theta 0 lastly need represent register requirements schedule linear form mentioned earlier paper model register requirements fifo buffers placed producer consumer nodes approach followed 11 assume buffer space reserved soon producer instruction commences executions remains reserved last consumer instruction begins execution consider instruction successor j result value produced consumed j ij iterations duration called lifetime result equal periodic schedule time would fired therefore many buffers needed store output instruction one successor j register requirement maximum j words number buffers b associated instruction given 8j th rewriting equation 8 get 25 demonstrated minimum buffer requirement provides tight upper bound total register requirement buffer assignment done classical graph coloring method subsequently performed generally leads minimum register quirement paper assume coloring phase always performed schedule determined integrating buffer requirements ilp formulation obtain formulation minimizes buffer requirements constructing rateoptimal resource constrained schedules purpose objective function minimizing total number buffers used schedule minimize complete ilp formulation shown figure 3 c optt formulation motivating example illustrate operation optt formulation examine motivating example presented section ii minimum iteration period ddg figure 1 2 nodes equation 14 gives dependence constraints feasible schedule govindarajan altman gao resourceconstrained rateoptimal software pipelining 9 ilp formulation pipelined fus minimize subject transpose theta 0 integers fig 3 ilp formulation pipelined fus equation 13 requires node scheduled exactly equation 11 relates elements matrix k following three equations respectively represent resource constraints integer loadstore fp units 00 3 10 3 19 register requirement instruction given equation 9 given ddg constraints finally objective minimize total number buffers subject constraints equations ti k b nonnegative integers solving integer program formulation yields schedule b solving integer programming problem need obtain values ti variables k variables thus obtain values variables determine schedule variable take values within specific range determined dependences iteration period ddg turn restrict range ti take value 1 v optt formulation nonpipelined fus section develop formulation optt problem nonpipelined fus illustrated section ii c problem requires scheduling mapping performed simultaneously following section show resource usage nonpipelined fus modeled formulation mapping problem discussed section vb resource usage nonpipelined fus order estimate resource requirements nonpipelined fus need know instruction initiated given matrix also long executes example instruction 4 schedule c initiated time step 10 time 1 repetitive pat tern executes time step 11 equivalently since execution time fp multiply repetitive pattern words instruction 4 requires fu time steps 1 2 repetitive pattern likewise instruction 3 requires fu time steps 2 0 repetitive pat tern thus need define usage matrix u matrix represent usage nonpipelined fus first illustrate matrix usage matrix u schedule c notice fp instructions load instructions take 2 time units execute require fu one time step usage matrix adding appropriate elements row gives fu requirement type r obtain u matrix instruction initiated time requires fu time step repetitive pattern alternatively say instruction requires function unit time step execution less steps prior thus define u notice execution time clean pipelines initiate new operation cycle resource usage instruction conceptually one cycle hence cases example loop instructions 0 5 take one time unit execute hence u ti 5 instruction defined 0i 3 2i 3 1i 3 0i 3 2i 3 1i 3 2i 4 0i 4 1i 4 requirement type r fus time step since less number available fus replacing resource constraint equation 10 ilp formulation refer figure 3 equations 24 25 obtain scheduling part ilp formulation nonpipelined fus however explained section iic complete formulation must include mapping part fixed fu assignment well otherwise schedules produced formulation may require switching instructions fus course execution 5 following subsection show mapping problem also formulated framework b fixed fu assignment consider schedule c shown table iii since loop kernel repeatedly executed map times 9 10 11 0 1 2 shown figure 4a 5 alternatively may possible unroll loop number times use different fu assignment instruction unrolled iterations however extent unrolling required may large may known priori time steps time step b fig 4 repetitive pattern partial resource usage usage fp units shown figure 4b note function unit used i3 wraps around time 2 0 problem time 2 i3 begins executing function unit used i2 times 0 1 since instruction supposed use fu every iteration causes problem time 0 i3 still executing fu needed i2 problem equation 25 notes number fus use one time ie number solid horizontal lines present 3 time steps figure 4b however need ensure two segments corresponding instruction assigned fu problem bears striking similarity problem assigning variables overlapping lifetimes different registers particular circular arc coloring problem 29 must ensure two fragments corresponding 3 get color fact represented dotted arc figure 4b addition arcs 3 overlap 2 4 meaning 3 must different color either similarly 2 4 must different colors using usage matrix formulate coloring problem using integer constraints two instructions j executing time clearly must get different fu assigned c c j represent colors function unit mapped instructions j respectively c 6 c j u ti u tj 1 constraint represented integer programming adopting approach given hu 30 introduce set w ij integer 01 vari ables one variable pair nodes using type function unit roughly speaking w ij variables represent sign c n number nodes ddg upper bound number colors govindarajan altman gao resourceconstrained rateoptimal software pipelining 11 22 prove constraints equa tions 26 27 28 together guarantee two nodes assigned different colors mapped different function units overlap ilp formulation require least many function units colors hence replace equation 25 equations 26 28 complete ilp formulation shown figure 5 ilp formulation nonpipelined fus minimize subject transpose theta 0 integers fig 5 ilp formulation nonpipelined fus vi solution method opt problem successful formulation optt problem provides basis solution opt problem solve opt problem need iteratively solve optt formulation increasing values starting lb find schedule satisfying function unit con straint words tmin smallest value greater equal lb schedule obeying resource constraint exists want solve optt formulation iteration period tmin observed cases tmin near lb 8 7 thus using iterative search starting lb quickly converge tmin solving ilp formulation optt problem guide search giving lower bound number buffers required illustrate idea fol lows let smallest iteration period schedule obeying function unit constraint exists value solving minimum register optimal schedule formulation proposed ning gao 11 obtain lower bound number buffers ning gaos formulation linear program formulation solved efficiently however since formulation 11 include resource constraints obtained schedule may may satisfy resource constraints vii performance ilp schedules section present performance results ilp scheduler section viii devoted comparison heuristic methods implemented ilp based software pipelining method unix workbench experimented 1008 singlebasicblock inner loops extracted various scientific benchmark programs spec92 integer floating point linpack livermore nas kernels ddgs loops obtained instrumenting highly optimizing research compiler considered loops 64 nodes ddg 7 ddgs varied widely size median 7 nodes geometric mean 8 arithmetic mean 12 solve ilps used commercial program cplex order deal fact ilp approach take long time loops adopted following approach first limited cplex 3 minutes trying solve single ilp ie maximum 3 minutes allowed find schedule given sec ond initiation intervals min necessary soon schedule found tmin 5 try greater values assumed following execution latencies various instructions applied scheduling different architectural configurations considered architectures pipelined nonpipelined execution units also considered architectures fus generic ie fu execute instruction fus referred homogeneous fus heterogeneous fu type like loadstore unit hand execute instructions specific type class types six different architectural configurations considered experiments latencies instructions instructions integer fp add load store multiply divide pipelined homogeneous fus pipelined homogeneous fus nonpipelined homogeneous fus nonpipelined homogeneous fus pipelined heterogeneous fus 2 integer fus one loadstore fp add multiply divide units a6 a5 function units nonpipelined 1008 loops scheduled architectures large majority cases ilp approach found optimal schedule close tmin shown table vii specific architectures homogeneous pipelined fus a1 a2 ilp approach found optimal schedule 88 cases nonpipelined homogeneous fus optimal schedule found 71 cases lastly architectures heterogeneous fus a5 a6 varies 80 85 architectural configurations small fraction test cases ilp method found schedule greater possible tmin cases obtained schedule possible optimal schedule say possible tmin possible optimal schedule since evidence cplex 3 minute time limit expired without indicating whether schedule exists lower value tmin table vii indicates far schedule found possible optimal schedule vi schedule quality terms iteration period initiation interval number loops next proceed compare close ilp schedules optimal buffer requirement deriving minimal buffer rateoptimal schedules cplexs 3 minute time limit sometimes exceeded finding buffer optimal schedule cases took best schedule obtained far words could one schedule set tr fig 2 schedule could possibly lie trb evidence 3 minute time limit cplex exceeded compare buffer requirement schedule schedule obtained ninggao formulation 11 note ninggao formulation obtains minimal buffer rate optimal schedules using linear programming techniques include resource constraints thus bound obtained ning gaos formulation loose lower bound may may exist resourceconstrained schedule buffer requirement let us denote buffer requirement tb tr trb schedules b respectively compare quality schedules take minimum buffer requirement bmin b trb trb schedule found otherwise thus trb schedule found bmin overly optimistic lower bound table vii shows quality ilp schedules terms buffer requirements consider cases ilp approach found schedule optimal otherwise seen table ilp approach produces schedules require minimal buffers 85 90 cases architectures involving heterogeneous fus pipelined nonpipelined homogeneous pipelined fus 6 4 fus architectures homogeneous nonpipelined fus a3 a4 quality schedule terms computation rate 1t buffer requirement poor compared architectural configurations due increased complexity mapping rather scheduling complexity mapping instructions fus significantly higher homogeneous fu heterogeneous fus cause instruction potentially mapped fus hence overlap execution pairs instructions needs considered hand heterogeneous model need consider pairs instructions executed fu type finally long take get schedules measured execution time henceforth referred compilation time scheduling method workstation geometric mean arithmetic mean median execution time 6 architectural configurations shown table vii histogram execution time various architectural configurations shown figure 6 table vii observe geometric mean execution time less less 2 seconds architectures homogeneous pipelined fus less 5 seconds architectures heterogeneous fus median execution time less 3 seconds cases architectural configurations a3 a4 homogeneous nonpipelined fus required govindarajan altman gao resourceconstrained rateoptimal software pipelining 13 vii schedule quality terms buffer requirement initiation interval number loops 12 seconds 25 seconds 30120 seconds 120600 seconds seconds 10 20 30 40 50 70 80 90 100 test cases architectures fig 6 histogram execution time larger execution time compared configurations due increased complexity mapping instructions viii average execution time obtain ilp schedules architecture execution time geo mean median arith mean a3 660 265 631 a6 470 235 557 conclude section noting even though ilp based scheduling method successful large majority test cases still could find schedule 15 20 test cases given time limit number tries cases number alternatives 1 allow ilp 3 minutes 2 change order ilp solver attempts satisfy constraints 3 move exact approach enumeration 26 4 fall back heuristic made systematic investigation 1 2 although found successful loops enumeration achieves number loops scheduled ilp approach described although loops successfully scheduled two approaches identical 26 ilp approach used basis heuristics example heuristic limits scheduling times node could added constraints ilp viii comparison heuristic methods extensive experimental evaluation indicates ilp approach obtain schedule large majority test cases reasonably quickly optimality objective associated computation cost pay terms computation rate buffer requirement derived schedules often argued existing heuristic methods without mathematical optimality formula well consequently need find optimal schedules results indicate otherwise consider 3 leading heuristic methods comparative study huffs slack scheduling 7 wang eisenbeis jourdan sus frlc 31 gasperoni schwiegelshohns modified list scheduling 20 partic ular compare ilp approach 3 scheduling methods architecture configurations pipelined fus modified list scheduling frlc methods handle nonpipelined fus comparison ilp approach restricted huffs slack scheduling method nonpipelined architectures a3 a4 a6 table viii compares computation rate buffer requirements ilp schedules heuristic methods various architectural configurations par ticular columns 3 4 tabulate number loops ilp schedules better percentage improvement tmin achieved similarly columns 8 9 represent improvements buffer requirements due approach followed obtaining ilp schedules restricting time solve ilp problem 3 minutes trying schedule next higher value suboptimal schedules computation rate andor buffer requirements ilp schedules greater heuristic methods small fraction test cases columns 5 6 represent respectively number test loops percentage improvement tmin achieved heuristic methods columns 10 12 table viii buffer improvements note buffer requirements compared corresponding schedules iteration period seen table viii huffs slack scheduling method performed equally well better terms iteration period homogeneous fus huffs method found faster schedules 3 8 test cases especially fus homogeneous nonpipelined ever heterogeneous fus ilp schedules faster 13 20 test cases architectures a5 a6 cases ilp schedules faster average 13 15 shown column 4 table viii high computation costs ilp schedules pay 14 ieee transactions parallel distributed systems vol xx month 1996 ix comparison heuristic methods tmin buffer requirements ilp better inexact ilp better inexact better better inexact tecture method loops impr loops impr loops loops impr loops impr loops pipelined architectures gasperoni 194 gasperoni 394 26 28 4 533 463 20 13 5 57 nonpipelined architectures a3 significant dividends terms buffer requirements architecture configurations 45 test cases corresponding schedules iteration period buffer requirements ilp schedules less huffs slack scheduling method geometric mean improvement buffer require ments achieved ilp schedules range 15 22 compared gasperonis modified list scheduling wang et als frlc method ilp produced faster schedules 18 40 187 394 test cases various architectural configurations considered improvement tmin achieved ilp schedules significant 26 48 means schedules generated ilp method run 50 faster generated frlc method modified list scheduling method heuristic methods score well small fraction 3 test cases buffer requirements ilp schedules better 17 frlc modified list scheduling 460 640 test cases attractive feature heuristic methods execution time execution time heuristic methods less 1 second 90 loops mean execution time less second architectural configurations three heuristic methods huffs slack scheduling method required slightly computation time experiments reveal ilpbased optimal scheduling method produce good schedules though expense longer compilation time advent efficient ilp solvers compilation time likely decrease future irrespective high compilation costs experiments suggest possible use ilp approach performance critical applications following subsection present case ilp approach even though use approach production compilers debatable remarks hope experimental results presented previous section help compiler community assessment ilp based exact method despite reasonably good performance large majority test cases use ilp based exact methods production compilers remains questionable however course experiments noticed many loop bodies occur repeatedly different programs developed tool analyzes whether two ddgs similar sense 1 execute operations least execute operations latency function unit 2 set edges dependence distances operations found 1008 test cases 415 loops unique one loop body common 73 different loops repetition loop bodies one hand implies benchmark suite consists 415 unique test cases rather 1008 hand suggests number distinct loops appearing scientific programs limited compiler could use ilp approach precompute optimal schedules commonly occurring loops scheme could also tailored individual users adding new loops database compiler encounters fact ilp computation could run background user may get nonoptimal code first time hisher code govindarajan altman gao resourceconstrained rateoptimal software pipelining 15 vs multiplicity multiplicity number nodes execution time architecture a1 multiplicity execution time execution time architecture a4 multiplicity execution time execution time architecture a6 multiplicity execution time fig 7 analysis ddgs benchmark suite compiled later compilations desired schedule would database complexity tool analyze whether two ddgs similar oe 4 worst case oe average case e number edges ddg cases e n number nodes ddg 53 seconds required sunsparc20 find 415 unique loops 1008 ie 53 milliseconds per loop practical use tool requires database ddgs schedules stored encoded form number ddgs database compared given loop drastically reduced simple comparison number nodes number arcs ddgs one last question remains usefulness database ddgs precompiled schedules many precompiled schedules required longer compilation time question relevant database ddgs contain loops schedule anyway found shorter compilation time perhaps take lesser time determine schedule search database investigate plotting compilation time 415 unique loops multiplicity often ddg repeat benchmark suite also plot size ddgs versus multiplicity fig 7 seen figure 7 though repetition ddgs common size ddg small large ddgs repeat perhaps low degree multiplicity 2 6 plots compilation time ddgs various architectural configurations multiplicity also indicate similar results ie though majority database likely contain ddgs take shorter compilation time exist ddgs require longer compilation time repeat benchmark suite perhaps low degree multiplicity especially true architectural configurations a3 a6 initial results show ddgs require longer compilation time repeat though lower degree multiplicity however study tradeoff involved cost storing database loops precompiled schedules advantage obtaining optimal schedules quickly tradeoff determines usefulness database approach study required derive stronger conclusive results ix related work software pipelining extensively studied 2 4 5 6 8 12 14 15 32 13 7 14 19 variety techniques suggested finding good schedule bounded function units readers referred 33 comprehensive survey lam 8 proposed resourceconstrained software pipelining method using list scheduling hierarchical reduction cyclic components matrix similar modulo resource reservation table concept originally due rau glaeser 12 put rep resent resource usage steady state mapping resource usage time mod lams solution opt problem also iterative huffs slack scheduling 7 also iterative solution opt problem heuristics give priority scheduling nodes minimumslack time sched uled ii try schedule node time minimizes combined register pressure node inputs outputs reported extremely good results addressing opt problem heuristicbased scheduling methods proposed wang et al 19 gasperoni schwiegelshohn 20 compared ilp schedules perform three scheduling methods section viii fps compiler 12 cydra 5 compiler cydrix tm fortran 34 4 hppa compiler 35 production compilers based heuristic methods implementing resourceconstrained software pipelining rau et al 13 addressed problem register allocation modulo scheduled loops method register allocation performed already scheduled loops different code generation schema modulo scheduled loops discussed 36 37 petri net based approach software pipelining loops presence resource constraints presented ebcioglu et al proposed technique enhanced software pipelining resource constraints 5 6 38 related work scheduling graphs presence conditionals reported 21 ning gao 11 proposed efficient method obtaining softwarepipelined schedule using minimum buffers fixed initiation rate however address function unit requirements formulation comparison approach tries obtain fastest computation rate minimum buffers given resource constraint 39 feautrier independently gave ilp formulation similar method however method include fu mapping nonpipelined execution units eichenberger davidson abraham 27 proposed method minimize maximum number live values time step given repetitive pattern formulating problem linear programming problem however approach start repetitive pattern already satisfies resource constraint possible incorporate approach formulation model register di rectly rather logical buffers approach independently developed incorporated formulation altman 26 hwang et al proposed integer programming formulation scheduling acyclic graphs context highlevel synthesis systems 40 x conclusions paper proposed method constructing software pipelined schedules use minimum buffers run fastest iteration rate given resource con straints graph coloring method applied obtained schedule get schedule uses minimum reg isters approach based integer programming formulation formulation quite general 1 used provide compiler option generate faster schedules perhaps expense longer compilation time especially performancecritical applications 2 since formulation precisely stated optimality objectives used ascertain optimal solution hence evaluate improve existingnewly proposed heuristic methods empirically established usefulness formulation applying 1008 loops extracted common scientific benchmarks six different architecture models varying degrees instructionlevel parallelism pipelining experimental results based benchmark loops indicate method find optimal schedule optimal terms computation rate register usage large majority test cases reasonably fast geometric mean time find schedule less 5 seconds median less 3 seconds even though ilp method takes longer produced schedules smaller register requirements 60 test cases ilp schedules faster better computation rate counterparts 14 test cases average believe results presented paper helpful assessing tradeoffs ilp based exact methods software pipelining acknowledgments kemal ebcioglu mayan moudgill gabriel silberman instrumental completing paper wish thank qi ning vincent van dongen philip wong anonymous referees helpful sugges tions thankful ibm technical support acknowledge natural science engineering research council nserc micronet network centres excellence support work r compactionbased parallelization optimal loop parallelization realistic resourceconstrained software pipelining algorithm compiling cydra 5 compilation technique software pipelining loops conditional jumps global resourceconstrained parallelization technique lifetimesensitive modulo scheduling software pipelining effective scheduling technique vliw machines efficient resourceconstrained global scheduling technique superscalar vliw proces sors finegrain compilation pipelined machines novel framework register allocation software pipelining scheduling techniques easily schedulable horizontal architecture high performance scientific computing register allocation software pipelined loops fortran compiler fps164 scientific computer polynomial time method optimal software pipelining dataflow analysis scalar array references designing programming languages analyzability fresh look pointer data struc tures unrolling loops tran decomposed software pipelining new approach exploit instructionlevel parallelism loop programs efficient algorithms cyclic scheduling reverse ifconversion scheduling mapping software pipelining presence structural haz ards scheduling parallel computations cydra 5 departmental supercomputer design philosophies decisions tradeoffs register allocation optimal loop scheduling optimal software pipelining function unit register constraints min imum register requirements modulo schedule conver sion control dependence data dependence register allocation framework based hierarchical cyclic interval graphs new approach software pipelining complicated loops branches loop storage optimization dataflow machines instructionlevel parallel process ing history overview perspective overlapped loop support cydra 5 software pipelining parisc compilers code generation schema modulo scheduled loops efficient scheduling fine grain parallelism loops new compilation technique parallelizing loops unpredictable branches vliw ar finegrain scheduling resource con straints formal approach scheduling problem highlevel synthesis tr ctr recursive time estimation algorithm program traces resource constraints proceedings 1998 acm symposium applied computing p635640 february 27march 01 1998 atlanta georgia united states mautsuen yang rangachar kasturi anand sivasubramaniam pipelinebased approach scheduling video processing algorithms ieee transactions parallel distributed systems v14 n2 p119130 february hongbo rong zhizhong tang r govindarajan alban douillet guang r gao singledimension software pipelining multidimensional loops acm transactions architecture code optimization taco v4 n1 p7es march 2007 hansaem yun jihong kim soomook moon time optimal software pipelining loops control flows international journal parallel programming v31 n5 p339391 october hongbo rong zhizhong tang r govindarajan alban douillet guang r gao singledimension software pipelining multidimensional loops proceedings international symposium code generation optimization feedbackdirected runtime optimization p163 march 2024 2004 palo alto california r govindarajan guang r gao palash desai minimizing buffer requirements rateoptimal schedule regular dataflow networks journal vlsi signal processing systems v31 n3 p207229 july 2002 karam chatha ranga vemuri hardwaresoftware partitioning pipelined scheduling transformative applications ieee transactions large scale integration vlsi systems v10 n3 p193208 june 2002