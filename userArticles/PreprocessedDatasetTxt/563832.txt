approach phrase selection offline data compression recently several offline data compression schemes published expend large amounts computing resources encoding file decode file quickly compressors work identifying phrases input data storing data series pointer phrases paper explores application algorithm computing repeating substrings within string phrase selection offline data compressor using approach obtain compression similar best known offline compressors genetic data poor results general text seems however alternate approach based selecting repeating substrings feasible b introduction data stored cd dvd static database compressed often decompressed many times given scenario compression scheme aord spend several hours computing time make multiple passes input consume many megabytes ram compression process order make compressed representation small possible decompression however fast memory ecient compression scheme said oine one way meet demand fast decoding high compression levels identify suitable phrase book input data stored series pointers entries phrase book example figure 1 shows simple string much wood woodchuck chuck woodchuck could chuck wood compressed using three different phrase books rst representation favours phrases appear frequently string hence space character forms phrase second representation looks include space character start end word form phrase third greedily chooses longest repeating phrase similar strategy employed compressors based lz77 schemes 1977 gzip winzip pkzip nal le phrase book series pointers must stored dicult tell inspection example three phrase books yield best compression phrase book representation 1 contains 27 characters 26 pointers phrase books representation two three characters copyright c 2001 australian computer society inc paper appeared twentyfifth australasian computer science conference acsc2002 melbourne australia conferences research practice information technology vol 4 michael oudshoorn ed reproduction academic notfor prot purposes permitted provided text included phrase books signicantly less pointers unfortunately variables involved choosing phrase book much complicated merely number pointers number characters phrase book assuming sort statistical coder example human coding arithmetic coding used actually encode pointers phrase book frequency distribution self entropy two components better indicators tness phrase book particular example cost zeroorder human code characters phrase book pointers data portion shown last row figure 1 indicates rst phrase book leads smallest representation 21 bytes even calculations approximation nal compression levels obtained code nature necessary information describes human codes employed prelude included estimates oine compression use phrase book new idea rubin 1976 storer szymanski 1982 nevillmanning witten 1994 increased availability cheap powerful computers computationally intensive techniques viable encoding order improve compression levels construction good phrase books task identifying best possible phrase book input shown npcomplete storer szymanski 1982 using heuristics lot machine power compression levels superior alternate techniques achieved data sets nevillmanning witten introduced approach induces context free text using grammar rules describe phrase book compression nevillmanning witten 1994 larsson moat cannane williams explore use repeated pairing characters order build phrase book emphasis small large data sets respectively larsson moat 2000 describe ecient algorithm nding long repeating substrings place phrase book bentley mcilroy 1999 paper expands work apostolico lonardi recently introduced offline compressor apostolico lonardi 2000 calculates measure compression gain possible nonoverlapping substrings string high gain factor indicates substring chosen phrase phrase book good compression would result similarly low gain score substring indicates particular substring chosen phrase phrase book compression algorithm used offline outlined figure 2 representation 1 representation 2 representation 3 much 1 much 1 much 1 wood 3 could 3 c 3 2 woodchuck 4 ould 4 could 4 chuck 5 5 5 woodchuck 4 chuck 6 could 3 c 3 wood 3 chuck 5 huck 7 chuck 6 wood 2 8 chuck 6 wood 2 chuck 6 ould 4 5 c 3 wood 3 wood 2 chuck 6 9could 4chuck 6wood 3 phrases 12 pointers 9 4 8 total figure 1 string much wood could wood chuck chuck woodchuck could chuck wood represented three possible phrase books rst occurrence phrase shown gray case numbered order rst occurrence nal three rows show cost human encoding phrase book pointers bytes alluded example calculating exact gain compression given substring dicult task commencement encoding way knowing many phrases end phrase book probability distributions characters phrase book pointers data component accordingly apostolico lonardi experimented three approximate gain formulations using simple approach achieve excellent levels compression genetic sequences competitive compression levels general data apostolico lonardi 2000 details results found wwwcspurdueeduhomesstelooffline implementation offline relies sux tree data structure trie holds possible suxes string ukkonen 1995 references therein acknowledge however sux tree large slow data structure task paper introduce alternate approach performing compression using offline algorithm based string processing algorithm nding repeating substrings string focusing repeating substrings rather suxes string hypothesise time taken perform gain calculations string manipulations using offline approach signicantly reduced section 2 describes crochemores algorithm crochemore 1981 nding repeating substrings input string compress calculate gain possible nonoverlapping substrings input string compressed choose substring highest gain factor add phrase book step 3 remove occurrences chosen substring string store pointer original phrase occurrence step 4 recalculate gain measure substrings input string covered chosen phrase step 5 still positive gain factor repeat step 2 remaining uncovered string output phrase book list pointers representing input string figure 2 basic algorithm employed offline within string explains use select phrases oine compression scheme crush section 3 describes experimental results compression levels timing crush offline finally section 4 discusses results implications crush compressor consists two stages rst analyses input string using crochemores algorithm generate two dimensional array c stores information substrings given length data structure traversed calculate gain measure substrings occurring leftmost uncompressed position input string highest gain substring chosen phrase book note approach deviates offline algorithm make local choice leftmost uncovered position rather global choice possible uncovered positions remaining string two stages explained detail following two subsections summarised figure 3 21 stage 1string analysis crochemores algorithm crochemore 1981 nd ing repeating substrings input string begins grouping positions string character single class classes rened subclasses get repeating substrings length two turn classes rened get substrings length three example consider input string b b b b positions form initial classes strings length one b rst stage accomplished time n number characters input string assuming alphabet characters string drawn indexable exam ple ascii next stage algorithm splits class classes represent starting position substrings length two rst class splits classes aa ab class b splits classes ba b end string symbol ab aa ba b using nave approach stage accomplished n time simply checking character following position class example order rene class would necessary check positions case f3 8 11g must form class aa forms class ab process renement continues ignoring class contains single position must represent substring repeats rene ments possible ab aa ba aba aab baa abaa aaba baab abaab baaba abaaba nave approach renement adopted stage total running time 2 could levels requiring n time crochemore oers two insights allows time reduced log n crochemore 1981 rst necessary refer back original string order rene class renement achieved respect classes level order members class level l rened class level must share character l1st position nave approach checks character directly class member however members class share l 1st char acter length l suxes must also identical example substrings aba b next position share three character sux bab substrings length share sux length l positions plus one must appear another class level l example substring aba occurs position substring baa occurs position taking account overlap two character sux aba two character prex baa deduce string abaa must occur positions precisely happens rening class aba f1 4 6 9g level 3 check positions f2 5 7 10g fall class level 3 deduce strings form class level 4 case 2 7 10 inhabit class baa f1 6 9g forms class level 4 similarly f5g class level 3 f4g forms class level 4 observation alone reduce running time algorithm used conjunction observation classes need rened level running time comes consider example rening 9g level 3 classes level 4 many classes level three need inspect order perform renement discussed classes must prex ba overlaps sux aba inspect renements took place level 2 produce level 3 see class split 2 classes level 3 namely f5g precisely two classes need consider rening 9g turn means use one perform renement aba f1 4 6 9g remaining positions must fall class level 4 case either rene f1 4 6 9g using f5g get class f4g remaining class f1 6 9g rene f1 4 6 9g using f2 7 10g get class f1 6 9g remaining class f4g obviously choose smallest classes rene leaving largest class left processing required precisely approach adopted crochemores algorithm stage small classes rened observe class level l rened two classes level l 1 longest smallest classes cannot greater half size parent class character string appear small class olog 2 n times hence involved renement olog n times seeing n characters overall running time crochemores algorithm log n brief description intuition behind crochemores algorithm hides complex intricate details required achieve fast memory ecient implementation algorithm implementation used paper operates space storing list classes level renement discarding lists previous levels constant factor quite high space bound current implementation requiring 44n bytes memory 22 stage iiphrase selection order use results crochemores algorithm phrase selection current implementation crush stores class information level derived memory conservation encoding primary aim crush simple array n integers used hold circular list class members level formally element cli array c pointer next member class containing position level l nal class member pointing back rst member example crochemores algorithm c would number levels restricted k parameter crush total space requirement c okn array c exists phrase selection begin unlike offline crush makes phrase selections set substrings beginning leftmost uncovered position overlap already covered position offline compressor however considers possible nonoverlapping substrings phrase choice crush chooses phrase p highest gain measure g p set possible substrings g p 0 character uncovered position skipped left nal stage processing nal stage simply treats uncovered characters single letter phrases innite stores single letter phrase book uncovered occurrences pointers reported computing g p cost storing occurrences phrase zeroorder character model less cost storing single copy series pointers copy gave best results experiments accordingly crush uses similar gain measure let h cost bits storing single character input string using simple character based model statistical coder example human coding arithmetic coding h would around 2 3 bits ascii code quantity h estimated preliminary scan data records probability character setting shannons lower bound compression levels shannon 1948 approach adopted crush let f p frequency phrase p occurs text l p number characters phrase p cost storing f p copies phrase uncompressed text approximated hf p l p bits phrase p chosen phrase book one copy required cost approximately hl p bits phrase plus h bits store either length phrase terminating symbol phrase phrase book apart phrase book copy p also necessary store f p pointers phrase cost pointer new phrase estimated dlog 2 number phrases already phrase book 2000 accurate estimate pointer cost amounts cost binary code pointers currently phrase book course crush continues p number phrases increase net effect slowly make cost adding phrase expensive total gain compression phrase p included phrase book therefore uncompressed representation phrase book entry cost pointer costs figure 3 shows pseudo code complete algorithm used crush steps 1 2 simply run crochemores algorithm create c array step 4 performs phrase selection step 5 nishes skipped positions positive gain step 4 processing time required crush dominated traversals c lists step 432 possible substring may k 1 entire pointer chain items must traversed order calculate frequency substring step 46 also sees chain pointers relating selected phrase traversed second time record pointers mark positions covered note steps 432 46 must also exclude self overlapping positions consideration implementation crush described implementation offline downloaded wwwcspurdueeduhomesstelooffline run purdue corpus purdue 2001 table 1 shows compression speed results achieved using pentium iii 800mhz cpu 640mb ram primary cache running linux c code compiled using gcc version egcs29166 full optimisations phrases crush limited characters length values reported table 1 used gain formula nal term added order bias phrase selection towards single chars reduce number phrases chosen initial experiments showed crush using gain measure stated previous section aggressive phrase selection problem discuss compression values assume human coder used coding phrase book pointer lists preludecosts codes included codes number codewords small less 100 cases prelude size negligible eect nal compression levels table shows compression results competitive les corpus unusual given local rather global approach phrase selection one obvious failure crush nd good phrases le spor 2x le spor repeated twice example shortcomings local choice approach adopted spor 2x le les purdue corpus consists 258 2 blocks 14 lines genetic data shown figure 4 le offline rst chooses upstream sequence 800 1n highest gain phrase proceeds choose 200 phrases length 800 characters maximum allowed occur four less times crush hand must rst deal characters select phrase upstream sequence 800 1n fact crush determines upstream sequence 800 1n rst decent phrase leaving preceding characters encoded singletons amongst crushs phrase choices le phrases upstream sequence 800 1 upstream sequence 800 1 upstream sequence 800 1 3 upstream sequence 800 1 4 upstream sequence 800 1 9 upstream sequence 800 1 7 upstream sequence 800 1 8 upstream sequence 800 1 5 upstream sequence 800 1 6 upstream sequence 800 1 clearly could improved crush gets line 2222 le location block offline designates second best phrase block already covered earlier choices smaller phrases available choice crush similar problem occurred general text ran crush small text les calgary calgary 2001 canterbury canterbury 2001 input string compressed k maximum length phrase consider phrase book level one classes crochemores algorithm algorithm level k storing level c array cki points next member class containing position level k step 3 set positions uncovered step 4 uncovered positions step 41 let smallest uncovered position step 42 let j minsmallest covered position k step 43 level 2 k j step 431 set f 0 step 432 position c list rooted cki k positions fcc1 ck1g uncovered set f f 1 step 433 set g k hfk hk step 44 find step 45 gm 0 record position skipped mark covered goto step 4 step 46 position c list rooted cmi step 461 k positions fcc1 ck1g uncovered record pointer position c new phrase positions fc c covered step 5 position recorded skipped step 45 step 51 single character position phrase add phrase book step 52 record pointer phrase position output phrase book list pointers phrase book figure 3 algorithm used crush file size bzip2 offline crush offline crush name bytes bpc bpc bpc secs secs spor earlyii 25008 2894 2782 2217 62 11 spor earlyi 31039 1882 1835 2222 85 19 helden cgn 32871 2319 2264 2219 98 21 spor middle 54325 2281 2176 2196 213 90 helden 112507 2261 2116 2227 750 585 spor 222453 2218 1953 2195 2785 2912 400k 399615 2249 2136 2275 9897 10348 spor 2x 444906 1531 0148 2194 11337 10467 table 1 compression timing results purdue corpus corpora compression results abysmal averaging around four bits per character table also shows running time purdue corpus low anticipated running times calgary canterbury corpora exceptionally fast hardly surprising given poor compression results reason low running time general text short phrases initially chosen cover much input string subsequent processing need look remaining substrings table 2 shows breakdown running time purdue corpus generated using gprof soft ware proling code indicated far majority time spent counting frequency phrases step 432 figure 3 string processing portion crush crochemores algorithm extremely fast paper reported simple attempt apply crochemores algorithm nding repeating substrings phrase selection oine data compres file steps 1 step 432 2 spor earlyii 2 78 spor earlyi 2 82 helden cgn 2 85 spor middle 1 91 helden 0 96 spor 0 98 400k 0 99 table 2 percentage running time taken crochemores algorithm steps 1 2 frequency counting step 432 crush purdue corpus sion followed model apostolico lonardi greedily choosing phrases stage maximise approximation compression gain expected phrase included phrase book global approach phrase selection however trialled local approach shown work well string covering algorithms yang 2000 rts2 rts2 upstream sequence 800 1 gtaatggttcatttctttaatagccttccatgactcttctaagttgagtttatcatcagg tagtaaggatgcacttttcgatgtactatgagactggtccgcacttaaaaggcctttaga tttcgaagaccacctcctcgtacgtgtattgtagaagggtctctaggtttatacctccaa tgtcctgtactttgaaaactggaaaaactccgctagttgaaattaatatcaaatggaaaa gtcagtatcatcattcttttcttgacaagtcctaaaaagagcgaaaacacagggttgttt gattgtagaaaatcacagcg mek1 mek1 upstream sequence 800 1 acagaaagaagaagagcgga ndj1 ndj1 upstream sequence 800 1 gtacggcccattctgtggaggtggtactgaagcaggttgaggagaggcatgatgggggtt figure 4 beginning le spor 2x string processing portion compressor based crochemores algorithm crochemore 1981 fast subsequent processing stage limited poor data structure several techniques oer hope improvement running time crush rst replace pointer chain data structure stores results crochemores algorithm later processing alternate structure recently smyth tang shown repeating substring information required crush stored n space arrays smyth tang 2001 structure plays role sux tree generated directly crochemores algorithm hence stores repeating substrings overhead construction minimal increase running time rst stage crush using arrays signicantly reduce memory requirements crush speed processing repeating substring information importantly allow frequency phrases calculated e ciently major bottleneck shown table 2 typically 90 time spent calculating phrase frequencies current implementation another avenue resource savings alternate implementation crochemores algorithm future versions software make use new arraybased implementation crochemores algorithm baghdadi et al 2001 practice runs much faster standard implementation reduces space requirements 44n 12n bytes one nal avenue worth exploring context recent algorithm due smyth tang 2001 calculates repeating substrings nonex tendible left right currently crochemores algorithm supplies set substrings nonextendible right running crochemores algorithm reverse string collating results run string set candidate strings phrase book reduced time utility remaining string enhanced anticipate substantial improvement compression results approach implemented major point deviation approach apostolico lonardi phrase choice crush considers phrases starting leftmost uncovered position input stringa local approach clearly major contributing factor poor compression levels general text examining phrase choices made crush offline example progc calgary corpus shows many good phrases selected offline unavailable crush partially covered earlier phrase choice indeed crush chooses four phrases single characters hence poor compression results reason introduction 2f p l p term gain calculation formula biasing gain towards single characters limits early selection short phrases occur frequently phrases whose selection prevents use longer matches later processing downside course extremely dicult infrequent long phrases chosen le purdue corpus h typically around 25 bits per character phrase length 800 selected must occur least 6 times whereas spor 2x offline routinely chooses phrases length 800 frequency less 6 interesting note local approach however still gave good compression majority purdue corpus reason crush performs well purdue corpus rather text general high gain phrases purdue corpus occur towards start data les allows early selection crush unlike general text high gain substrings never considered possible phrase candidates parts phrases covered earlier local choice implementing global approach using current pointer chain data structure crush would prohibitively expensive tree data structure smyth tang 2001 incor porated however global approach may become feasible option compression results purdue corpus indicate global approach would improve compression performance general data another technique intend incorporate crush accurate gain measure generation repeating substring information fast appropriate data structure store information aord spend time estimating gain phrase approximation based self entropy pointers phrase book representation lead improved compression levels wide range data also iterative approach makes multiple passes data improve gain estimates worth investigating avenue exploration allowing phrases overlap phrases allowed overlap data section compressed le longer simple sequential list pointers phrases phrase book pointer must also paired indication much phrase represents overlaps previous text human coding similar used storing informa tion fast decoding guaranteed least one bit per pointer must added nal le therefore maintain compression levels nonoverlapping implementation average size pointers must reduce one bit reduction pointer size would occur suitable change frequency distribution pointers occurred overlap allowed large reduction number pointers preliminary experiments allowing phrase overlap purdue corpus seem indicate allowing overlap benecial acknowledgments thanks lu yang yang 2000 making available code kcover algorithm f franek making available code ecient implementation crochemores algo rithm thanks also anonymous referees helpful comments r fast spaceecient approach substring nement data compression using long common strings calgary corpus canterbury corpus optimal algorithm computing repetitions word crochemores algorithm revisited compression induction hierarchical grammars purdue corpus experiments text mathematical theory communication mathematical theory communication computing repeats using space log n time online construction sux trees computing kcover string universal algorithm sequential data compres sion tr data compression via textual substitution experiments text file compression generalpurpose compression efficient retrieval data compression using long common strings ctr frantiek frank jan holub william f smyth xiangdong xiao computing quasi suffix arrays journal automata languages combinatorics v8 n4 p593606 april