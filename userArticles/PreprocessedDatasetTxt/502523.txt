probabilistic modeling transaction data applications profiling visualization prediction transaction data ubiquitous data mining applications examples include market basket data retail commerce telephone call records telecommunications web logs individual pagerequests web sites profiling consists using historical transaction data individuals construct model individuals behavior simple profiling techniques histograms generalize well sparse transaction data paper investigate application probabilistic mixture models automatically generate profiles large volumes transaction data effect mixture model represents individuals behavior linear combination basis transactions evaluate several variations model large retail transaction data set show proposed model provides improved predictive power simpler histogrambased techniques well relatively scalable interpretable flexible addition point applications outlier detection customer ranking interactive visualization forth paper concludes comparing relating proposed framework transactiondata modeling techniques association rules b introduction large transaction data sets common data mining ap plications typically data sets involve records transactions multiple individuals transaction consists selecting visiting among set items eg market basket items purchased list web pages individual visited specic session transaction data examples store department number transactions figure 1 examples transactions several dividuals rows correspond market baskets columns correspond particular categories items darker pixel items purchased white means zero solid horizontal gray lines correspond transaction data introduced plot indicate boundaries transactions dierent individuals interested problem making inferences individual behavior given transaction data large set individuals period time particular focus techniques automatically inferring proles individuals transaction data paper prole considered description model individuals transaction behavior specically likelihood individual purchase visit particular item finding proles fundamental problem increasing interest data mining across range transactionrelated applica tions retail crossselling web personalization forecasting forth figure 1 shows set transactions 5 dierent individuals rows correspond market baskets transactions columns correspond categories items store departments example data set examples taken involves 200000 transactions 50000 customers twoyear period set retail stores heterogeneity purchasing behavior clear even simple plot dierent customers purchase dierent numbers items dierent departments dierent amounts goal paper investigate parsimonious accurate models individuals purchasing behavior ie individual proles paper begins dening general problem prol ing spectrum sparse individualspecic information broadly supported global patterns dene general notation problem introduce mixture model framework modeling transaction havior individual level describe model illustrate examples conduct number experiments realworld transaction data set demonstrate proposed approach feasible realworld data provides performance interpretable accurate scalable brie sketch model support several data mining tasks exploratory data analysis ranking customers novelty detection forecast ing forth conclude discussion related work 2 profiling problem proling essentially problem converting transaction data gure 1 model individual used predict future behav ior clearly human behavior highly unpredictable thus uncertainty abounds nonetheless likely regularities data leveraged average lead systematic method making predictions facet many transaction data sets fact data quite sparse example many transaction data sets including particular data set corresponding gure 1 histogram number transactions peaks 1 ie customers single transaction number transactions decreases exponentially quickly thus many customers transactions base prole others large numbers transactions assume example model individual via simple multinomial probability model indicate items chosen namely vector probabilities pc one c categories items assume combined histogram models many items total purchased per visit rate parameter governs often individual conducts transactions per unit time average eg per month crux proling problem nd middleground two proling extremes one modeling extreme could construct general model general form described whole population assume individuals homogeneous enough behavior single model adequate unlikely accurate given heterogeneity human behavior eg see gure 1 extreme could construct unique model individual based past transaction data individual eg multinomial histogram rate parameter estimated raw counts individual certainly provide individualspecic prole models however suers least two signicant problems firstly individuals small amounts data one item one transaction proles extremely sparse contain little information secondly even individuals signicant amounts data raw counts contain notion generalization unless purchased specic item past prole probability item zero ie model predicts never purchase limitations wellknown motivated development various techniques borrowing strength ie making inferences specic individual combining individual data know population whole collaborative ltering thought nonparametric nearestneighbor technique context association rule algorithms also try address problem identifying rules generalization allow identication prediction novel items seen individuals history eg brijs et al 2000 lawrence et al 2001 however methods support specic inferences items individual likely pur chase provide explicit model indi viduals behavior thus dicult combine approaches traditional forecasting prediction techniques example seasonal modeling techniques utilize information annual seasonal shopping patterns similarly clear covariate information available individuals income sex educational background etc could integrated systematic coherent manner association rule framework example paper take modelbased approach proling problem allowing information individual integrated within single framework specically propose exible probabilistic mixture model trans actions model ecient manner mixture model infer probabilistic prole individ ual compare approach baseline models based raw adjusted histogram techniques illustrate mixture model allows accurate generalization limited amounts data per individual 3 notation observed data set observed data ith customer 1 n individual data set consists one transactions customer ie fy g ij jth transaction customer n total number transactions observed customer individual transaction ij consists description set products purchased time customer purposes experiments described individual transaction ij represented vector counts component n ijc indicates many items type c transaction ij 1 c c one straightforwardly generalize representation include example price product focus number items counts equally well components n ijc could indicate time since last page request individual request web page c session j purposes paper ignore information time sequential order items purchased pages visited within particular transaction clear discussion straightforward generalize approach sequential order timing information available assuming transaction keyed unique identier individual examples keys include drivers license numbers credit card numbers retail purchasing login cookie identiers web visits practical problems associated identication data entry errors missing identiers fraudulent deliberately disguised ids multiple individuals using single id ambiguity identication web forth nonetheless increasing number transaction data applications reliable identication possible via methodologies frequent shopper cards optin web services forth rest paper assume identication problem issue ie either identication process inherently reliable relatively accurate techniques discern iden tity fact realworld transaction data set use illustrate techniques ambiguity identica tion process problem 4 mixturebasismodelsfortrans actions propose simple generative mixture model trans actions namely transaction ij generated one k components kcomponent mixture model thus kth mixture component 1 k k specic model generating counts think k models basis functions describing prototype trans actions example one might mixture component acts prototype suitbuying behavior expected counts items suits ties shirts etc probability component 3 probability component 4 component 5 department probability component 6 department figure 2 example 6 basis mixture components transaction data figure 1 given component would relatively higher items several modeling choices component transaction models generating item counts paper choose particularly simple memoryless multinomial model operates follows conditioned n ij total number items basket individual items selected memoryless fashion n ij draws multinomial distribution c possible items models possible example one could model data coming c conditionally independent random variables taking nonnegative integer values general involves parameters multinomial model allows example modeling purchase exactly one suit one pair shoes manner multinomial multiple trials model cannot achieve paper however investigate multinomial model since simplest begin also model distribution typical number items purchased within given component eg poisson model entirely reasonable giftbuying component model might much higher mean number items suitbuying model extensions straightforward discussed paper figure 2 shows example components learned transaction data gure 2 details learning discussed window shows particular set multinomial probabilities models specic type transaction components show striking bimodal pattern multinomial models appear involve departments either department 25 little probability mass crosses fact models capturing fact departments numbered lower correspond mens clothing 25 correspond womens clothing see evidence bimodality data gure 1 noting individuals fact cross purchase items number items training purchases 5026number items department test purchases figure 3 histograms indicating products particular individual purchased training data test data sides depending transaction 41 individualspecific weights assume individual exists set k weights general case weights individualspecic denoted represents probability individual enters store transactions generated component k words ik govern individual propensity engage shopping numerous possible generalizations making ik dependence time discuss ik eect prole coecients individual relative k component models idea individualspecic weights proles key component proposed approach mixture component models pk xed shared across individuals providing mechanism borrowing strength across individual data contrast individual weights principle allowed freely vary individual within kdimensional simplex eect k weights thought basis coecients represent location individual within space spanned k basis functions component pk multinomials approach quite similar spirit recent probabilistic pca work hofmann 1999 mixture models text documents proposes general mixture model framework represents documents existing within kdimensional simplex multinomial component models given assumptions stated far probability particular transaction ij assuming generated component k written kc 1 smoothed histogram profile map figure 4 inferred eective proles global weights smoothed histograms individual specic weights individual whose data shown gure 3 kc probability cth item purchased given component k n ijc number items category c purchased individual transaction ij component generated transaction ij known mixture model weights specic individual ik important point context probability model multinomial model ie mixture richer probabilistic semantics simple multinomial example application ideas g ure 3 training data test data particular individual displayed note predictability training test data although test data contains example purchase department 14 seen training data figure 4 plots eective proles 1 particular individual estimated three dier ent schemes modeling approach 1 global weights result everyone assigned generic prole 2 smoothed histogram maximum posterior map technique smooths individuals training histogram populationbased histogram 3 individual weights tuned individuals specic behavior details methods provided later paper one see gure 4 global weight prole call eective proles since predictive model mixture assumption multinomial plotted bar chart however approximate plotting one approximation ects broad populationbased purchasing patterns representative individual smoothed histogram somewhat better smoothing parameter blurred individuals focus departments 25 individualweight prole appears better representation individuals behavior indeed provide best predictive score test data g ure 3 note individualweights prole gure 4 borrows strength purchases similar cus tomers ie allows small nonzero probabilities individual making purchases departments 6 purchased past particular individuals weights ik 000 047 038 000 000015 corresponding 6 component models shown gure 2 weight placed components 2 3 6 agrees intuition given individuals training data 42 learning model parameters unknown parameters model consist parameters k multinomials c individualspecic prole weights learning parameters data two main choices either treat parameters unknown use em estimate rst learn k multinomials using em determine weights n individuals relative previouslylearned basis functions disadvantage rst approach clearly may overt data since unless large numbers transactions items per customer end many parameters observations model appendix outline three dierent techniques estimating individualspecic prole weights including full em later experimental results section investigate relative performance also include generic baseline version model experiments comparison namely global weights individ uals weights set common set weights set k weights returned em learning mixture k multinomials intuitively expect global weights tuned particularly well individuals behavior thus perform well individual weights nonetheless parsimony global weight model may work favor making outofsample predictions guaranteed individualweight models beat particularly given relative sparsity data per individual 43 individual histogrambased models also include baseline comparison simple smoothed histogram model dened convex combination maximum likelihood relative frequency histogram estimate individuals multinomial estimated directly individuals past purchases population multinomial estimated pooled population data idea smooth individuals histogram avoid zero probability items purchased past loosely corresponds maximum posteriori map strategy tuned relative weighting term maximize overall logp score test data set eect cheating method limitation approach smoothing applied individual irrespective much data available probably limit eective ness model sophisticated baseline histogram model obtained using fully hierarchical bayes ap proach fact methods described paper formulated within general hierarchical bayesian framework due space limitations omit details formulation 5 experimental results 51 retail transaction data evaluate mixture models used realworld transaction data set consisting approximately 200000 separate transactions approximately 50000 dierent individu als individuals identied matched transaction basket items pointofsale using card system data consists identiable transactions collected number retail stores part chain analyze transactions store department level 50 departments categories items names individual departments replaced numbers paper due proprietary nature data 52 experimental setup separate data two time periods transactions timestamped approximately 70 data rst time period training data remainder test period data train mixture weight models rst period evaluate models terms ability predict transactions occur subsequent outofsample test period results reported limit attention individuals least transactions entire timespan data somewhat arbitrary choice intended focus individuals hope able extract predictive power training data contains data 4339 individuals 58866 transactions 164000 items purchased test data consists 4040 individuals 25292 transactions 69103 items purchased individuals test data set appear training data set viceversa individuals test data set training data assigned global population model scoring purposes evaluate predictive power model calculate logprobability logp scores transactions predicted model higher logp scores mean model assigned higher probability events actually occurred log probability specic transaction individual ie set counts items purchased one basket individual mixture model dened ik note mean negative logp score set trans actions divided total number items interpreted predictive entropy term bits lower entropy term less uncertainty predictions bounded zero course corresponding zero uncertainty 29313335outofsample individuals 10 transactions time split model complexity k negative loglikelihood per item figure 5 predictive entropy outofsample transactions three dierent individual weight tech niques function k number mixture components 53 performance different individual profile weight models figure 5 shows predictive entropy scores three dierent individual weighting techniques described appendix function k number components mixture models plot see general mixtures k 1 perform better single multinomial models order 20 reduction predictive entropy furthermore simplest weight method wts1 accurate two methods worstperforming weight methods method allows individual prole weights learned parameters directly em method gave highest likelihood insample data plots shown clearly overtted led worse performance outofsample wts1 method performed best variety experiments conducted remainder paper focus particular weighting technique refer results obtained method simple individ ual weights 54 comparison individual global weight models figure 6 compares outofsample predictive entropy scores function number mixture components k individual weights global weights individuals assigned marginal mixture weights map histogram baseline method reference map method solid line better default leftmost points plot somewhat tuned individual behavior mixture models quickly overtake k increases performance individual global weight mixtures steadily improves somewhat attens providing 15 reduction predictive uncertainty simple map approach number mixture components k negative loglikelihood per item global weights individual weights map histogram figure plot negative log probability scores per item predictive entropy outofsample transactions global individual weights function number mixture components k also shown reference score non mixture map model individual weights systematically better global weights roughly 3 improvement predictive accuracy figure 7 shows detailed comparison dierence individual global weight models contains scatter plot outofsample total logp scores spe cic individuals xed value global weight model systematically worse individual weights model ie points bisecting line individuals lowest likelihood lower left plot individual weight model consistently better typically lower weight total likelihood individuals transactions items individual prole weights model systematically better individuals data ie shop figure 7 contains quite bit overplotting top left corner figure 8 shows enlargement part region plot level detail clearly see relatively low likelihood values individual prole models systematically better ie individuals get better predictions individual weights global weights figure 9 shows similar focused plot comparing scores individual weights yaxis map method xaxis story quite similar individual weights systematically providing better predictions note however scatter plots relatively small number individuals get better predictions smoother models conjecture may due lack sucient regularization individual prole method eg may individuals buy product never purchased individual weights model eect global weight model logp model figure 7 scatter plot log probability scores individual outofsample transactions plotting individual weights versus global weights logp global weights logp individual weights figure 8 close portion plot figure 7 10logp map model logp individual weights figure 9 scatter plot log probability scores individual outofsample transactions plotting log probability scores individual weights versus log probability scores map model committed historical data whereas others models hedge bets placing probability mass smoothly 50 departments 55 scalability experiments conducted simple experiments determine methodology scales computationally function model complexity recorded cpu time em algorithm global individual weights function number components k mixture model experiments carried pentium iii xeon 500mhz 512mb ram paging given number iterations em algorithm mixtures multinomials linear number components k number total items n interested see increasing model complexity might cause algorithm take iterations converge thus causing computation time increase rate faster linearly k figure shows happen prac tice clear time taken train models scales roughly linearly model complexity note also eectively dierence computation time global individual weight methods ie extra computation compute individual weights negligible 6 applications ranking outlier detection visualization several direct applications modelbased approach brie sketch due space lim itations particular use scores rank predictable customers customers relatively high logp scores per item predictable infor 0model complexity number components k time global weights individual weights figure 10 plot cpu time global individual weight mixture models function model complexity number components k linear population multinomial training data purchases customer 2084 probability test data purchases customer 2084 figure 11 example customer automatically detected unusual purchasing patterns population patterns top training purchases middle test period purchases bottom mation may useful marketing purposes proles used basis accurate personaliza tion forecasts future purchasing behavior made percustomer basis also use logp scores identify interesting unusual purchasing behavior individuals low per item logp score tend unusual purchases exam ple one lowest ranked customers terms score test period customer 2084 made several purchases test period department 45 interesting since almost zero purchases individual department training data figure 11 may well indicate unusual behavior individual example data may unreliable test period data may really belong customer clustering segmentation transaction data may also performed lower dimensional weightspace may lead stable estimation performing clustering directly original itemspace also developed interactive modelbased transaction data visualization exploration tool uses mixture models described paper basic framework exploring predicting individual patterns transaction data tool allows user visualize raw transaction data interactively explore various aspects individuals past behavior predicted future havior user analyze data using number dierent models including mixture models described paper resulting components displayed compared simple operations sorting ranking multinomial probabilities possible finally proles form expected relative purchasing behavior individual users generated visual ized tool also allows interactive simulation user prole allows data analyst add hypothetical items users transaction record eg adding several simulated purchases shoe department tool updates users prole realtime show aects users probability purchasing items type modelbased interactive exploration large transaction data sets viewed rststep allowing data analyst gain insight understanding large transaction data set particularly since data sets quite dicult capture visualize using conventional multivariate graphical methods 7 related work idea using mixture models exible framework modeling discrete categorical data known many years statistical literature particularly social sciences rubric latent class analysis lazarsfeld henry 1968 bartholemew knott 1999 typically methods applied relatively small lowdimensional data sets recently resurgence interest mixtures multinomials mixtures conditionally independent bernoulli models modeling highdimensional documentterm data text analysis eg mccallum 1999 homan 1999 marketing literature also numerous relatively sophisticated applications mixture models retail data see wedel kamakura 1998 review typically however focus problem brand choice one develops individual populationlevel models consumer behavior terms choosing relatively small number brands eg 10 specic product eg coee work breese heckerman kadie 1998 heckerman et al 2000 probabilistic modelbased collaborative ltering also similar spirit approach described paper except focus explicitly treating problem individual proles ie explicit models individual framework work viewed extension broad family probabilistic modeling ideas specic case transaction data deal directly problem making inferences specic individuals handling multiple transactions per individual approaches also proposed data mining literature clustering exploratory analysis transaction data typically nonprobabilistic framework eg strehl ghosh 2000 transaction data always received considerable attention data mining searchers going back original work agrawal imie lenski swami 1993 association rules association rules present dierent approach transaction data analysis searching patterns indicate broad correlations associations particular sets items work complements association rules develop explicit probabilistic model full joint dis tribution rather sets disconnected joint conditional probabilities one way think association rules indeed forecasting prediction argued modelbased approach propose systematic framework principle integrate timedependent factors eg seasonality nonstationarity covariate measurements customers eg knowledge customers age educationallevel infor mation relatively systematic fashion note also association rule algorithms depend fairly critically data relatively sparse contrast modelbased approach proposed relatively robust respect degree sparseness data hand pointed paper demonstrated utility approach relatively lowdimensional problem ie 50 departments descend product hierarchy departments classes items way specic products socalled sku level 50000 dierent items retail transaction database used paper remains seen whether type probabilistic model proposed paper computationally scaled level granularity believe mixture models proposed indeed extended model full product tree way leaves sparsity data hierarchical nature problem tends suggest hierarchical bayesian approaches play natural role leave discussion topic future work 8 conclusions research described paper viewed rst step direction probabilistic modeling transaction data among numerous extensions generalizations explore integration temporal aspects behavior building simple stationary poisson models individual extending seasonal nonstationary eects mathematically temporal aspects included model rather easily example traditionally modeling consumer behavior rst approximation one models temporal rate process often individual shops independently choice model individual purchases eg see wedel kamakura 1998 factorstyle mixture models allow single transaction generated multiple components eg customer may buy shirtsties campingoutdoor clothes transaction modeling product category hierarchies department level skulevel brie summarize proposed general probabilistic framework modeling transaction data illustrated feasibility utility accuracy approach realworld transaction data set experimental results indicate proposed probabilistic mixture model framework potentially powerful tool exploration visualization proling prediction transaction data parameter estimation a1 learning individual weights consider log likelihood function set data points mixture weights individualspecic letting denote mixture model parameters k denote mixture component multinomial parameters log similar standard mixture model uses individualspecic weights ik learning problem optimize loglikelihood respect parameters consists mixture component parameters k individualized weights ik subject set n constraints addition dene global weights model additional constraint individualspecic weights equal global set weights particular loglikelihood optimized using expectationmaximization em algorithm q function becomes equation p ijk represents classposterior transaction evaluated using old set parameters q function similar q function standard mixture model difference individualized weights used place global weights additional constraints exist set individualized weights optimizing q function respect mixture component parameters k depend weights ik depend old weights p ijk though therefore optimization unchanged optimization respect ik set lagrange multipliers leads following intuitive update equation reduces standard equation global weights used since models individualized weights large number parameters may overt data consider several dierent methodologies calculating weights 1 global weights standard mixture model 2 wts1 model weights constrained equal em global set weights together mixture component parameters learned components learned individualspecic weights learnt single em iteration using q function individualspecic weights 3 wts2 model similar wts1 model instead single iteration performs second em algorithm individualized weights mixture component weights learned eectively model consists two consecutive em algorithms one learn mixture component parameters another learn individualized weights 4 wts3 model full em algorithm used mixture component weights individualized weights updated iteration methods described represent valid em algorithm since update equations always derived appropriate q function therefore loglikelihood guaranteed increase iteration consequently algorithms guaranteed converge within standard em limitations a2 general parameters running em algorithm em algorithm always started 10 random initial random starting points run highest likelihood solution chosen parameters initialized sampling dirichlet distribution using single cluster parameters hyperprior equivalent sample size 100 em iterations halted whenever relative change log likelihood less 001 100 iterations practice results paper algorithm typically converged 001 criterion within 20 40 iterations never exceeded 70 iterations a3 acknowledgements research described paper supported part nsf career award iri9703120 work ic supported microsoft graduate research fellowship a4 r mining association rules sets items large databases data mining framework optimal product selection retail supermarket data generalized profset model latent variable models factor analysis dependency networks ference journal machine learning research personalization supermarket product recommendations latent structure analysis market segmen tation conceptual methodological foundations tr mining association rules sets items large databases probabilistic latent semantic indexing data mining framework optimal product selection retail supermarket data personalization supermarket product recommendations dependency networks inference collaborative filtering data visualization ctr chidanand apte bing liu edwin p pednault padhraic smyth business applications data mining communications acm v45 n8 august 2002 ella bingham heikki mannila jouni k seppnen topics 01 data proceedings eighth acm sigkdd international conference knowledge discovery data mining july 2326 2002 edmonton alberta canada chunnan hsu haohsiang chung hanshen huang mining skewed sparse transaction data personalized shopping recommendation machine learning v57 n12 p3559 octobernovember 2004