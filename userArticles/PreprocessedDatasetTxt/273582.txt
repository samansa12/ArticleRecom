robust solutions leastsquares problems uncertain data consider leastsquares problems coefficient matrices ab unknown bounded minimize worstcase residual error using convex secondorder cone programming yielding algorithm complexity similar one singular value decomposition method interpreted tikhonov regularization procedure advantage provides exact bound robustness solution rigorous way compute regularization parameter perturbation known eg toeplitz structure problem solved polynomialtime using semidefinite programming sdp also consider case ab rational functions unknownbutbounded perturbation vector show minimize via sdp upper bounds optimal worstcase residual provide numerical examples including one robust identification one robust interpolation b introduction consider problem finding solution x overdetermined set equations ax b data matrices 2 r nthetam b 2 r n given least squares ls fit minimizes residual kdeltabk subject resulting consistent linear model form deltab closest original one euclidean norm sense total least squares tls solution described golub van loan 17 finds smallest error subject consistency equation deltab resulting closest consistent linear model deltab even accurate ls one since modifications allowed accuracy primary aim ls tls surprising solutions may exhibit sensitive behavior perturbations data matrices b detailed sensitivity analyses ls tls problems may found 12 18 2 44 22 14 many regularization methods proposed de appear siam journal matrix analysis applications 1997 ecole nationale superieure de techniques avancees 32 bd victor 75739 paris france internet elghaoui lebretenstafr l el ghaoui h lebret crease sensitivity make ls tls applicable regularization schemes ls including tikhonov regularization 43 amount solve weighted ls problem augmented system pointed 18 choice weights regularization parameter usually obvious applicationdependent several criteria optimizing regularization parameters proposed see eg 23 11 15 criteria chosen according additional priori information deterministic stochastic nature extensive surveys 31 8 21 discuss problems applications contrast extensive work sensitivity regularization relatively little done subject deterministic robustness ls problems perturbations deterministic unknownbutbounded necessarily small work done qualitative analysis problem entries unspecified sign 26 39 many papers mentioning leastsquares robustness latter notion understood stochastic sense see eg 20 47 37 notable exception concerns field identification subject explored using framework used control system analysis 40 9 using regularization ideas combined additional priori information 34 42 paper assume data matrices subject non necessarily small deterministic perturbations first assume given model single pair b family matrices unknownbutbounded matrix precisely kdeltak ae ae 0 given x fixed define worstcase residual 1 say x robust least squares rls solution x minimizes worstcase residual ra b ae x rls solution trades accuracy robustness expense introducing bias paper assume perturbation bound ae known x35 also show tls used preliminary step obtain value ae consistent data matrices b many applications perturbation matrices deltaa deltab known structure instance deltaa might toeplitz structure inherited case worstcase residual 1 might conservative estimate led consider following structured rls srls problem given 2 ae 0 x define structured worstcase residual kffikae say x structured robust least squares srls solution x minimizes worstcase residual r b ae x robust least squares 3 main contribution show compute exact value optimal worstcase residuals using convex secondorder cone semidefinite programming socp sdp consequence rls srls problems solved polynomialtime great practical efficiency using eg recent interiorpoint methods 33 46 exact results contrasted doyle et al 9 also use sdp compute upper bounds worstcase residual identification problems preliminary draft 5 sent us shortly submission paper authors provide solution unstructured rls problem similar given x32 another contribution show rls solution continuous data matrices b rls thus interpreted tikhonov regularization technique illconditioned ls problems additonal priori information ae perturbation level regularization parameter optimal robustness similar regularity results hold srls problem also consider generalisation srls problem referred linear fractional srls problem sequel matrix functions affi bffi 2 depend rationally parameter vector ffi describe robust interpolation problem falls class x76 using framework 9 show problem npcomplete case may compute optimize upper bounds worstcase residual using sdp parallel rls interpret solution one weighted ls problem augmented system weights computed via sdp papers outline follows next section devoted technical lemmas section 3 devoted rls problem section 4 consider srls problem section 5 studies linearfractional srls problem regularity results given section 6 section 7 shows numerical examples 2 preliminary results 21 semidefinite secondorder cone programs briefly recall important results semidefinite programs sdps secondorder cone programs socps results found eg 4 33 46 linear matrix inequality constraint vector x form symmetric matrices f given minimization problem subject fx 0 called semidefinite program sdp sdps convex optimization problems solved polynomialtime eg primaldual interiorpoint methods 33 45 4 l el ghaoui h lebret problem dual problem 5 maximize gammatrf 0 z subject z 0 trf z symmetric n theta n matrix c ith coordinate vector c problems strictly feasible exists x z satisfy constraints strictly existence optimal points guaranteed 33 thm421 problems equal optimal objectives case optimal primaldual pairs x z pairs x z x feasible primal problem z feasible dual one secondorder cone programming problem one form subject kc l dual problem problem 7 subject dual variables optimality conditions similar sdps obtained socps socps expressed sdps therefore solved polynomialtime using interiorpoint methods sdps however sdp formulation efficient numerically special interiorpoint methods devised socps 33 28 1 complexity results interiorpoint methods socps sdps given nesterov nemirovsky 33 p224236 practice observed number iterations almost constant independent problem size 46 socp iteration complexity sdp refer reader 33 22 sprocedure following lemma found eg 4 p24 widely used eg control theory connection trust region methods optimization 41 lemma 21 sprocedure let f quadratic functions variable following condition f robust least squares 5 holds exist 0 converse holds provided 0 f 1 next lemma corollary result case lemma 22 let real matrices appropriate size every delta kdeltak 1 kt 4 k 1 exists scalar 0 0 proof 2 3 equal zero result obvious assume turn implies kt 4 k 1 thus given 10 holds kt 4 k 1 every u p 4 p since 2 6 0 constraint q q p p qualified satisfied strictly using sprocedure obtain exists 2 r 10 holds 1 every u p q q p p u proof noting every pair p q p p q q next lemma structured version traced back 13 lemma 23 let real matrices appropriate size let subspace r n thetan denote resp g set symmetric resp skew symmetric matrices commute every element 9 every delta 2 kdeltak 1 exist 2 g 2 g condition necessary sufficient proof proof follows scheme lemma 22 except p p q q replaced p g note 0 result simple application lemma 22 scaled matrices 6 l el ghaoui h lebret 23 elimination lemma last lemma proven 4 24 lemma 24 elimination given real matrices appropriate size exists real matrix x u w u orthogonal complements u v u v full columnrank 12 holds solution x inequality 11 oe scalar q 0 existence guaranteed 12 3 unstructured robust leastsquares section consider rls problem compute recover standard ls problem every ae 0 oea b aeoeaae bae 1 take sequel unless otherwise stated remainder paper oea b resp ra b x denotes oea b 1 resp ra b 1 x definition norm used perturbation bound frobenius norm seen shortly worstcase residual norm used largest singular value norm 31 optimizing worstcase residual following results yield numerically efficient algorithm solving rls problem unstructured case theorem 31 ae 1 worstcase residual 1 given problem minimizing ra b x x unique solution x rls referred rls solution problem formulated secondorder cone program subject kax gamma bk x proof fix x using triangle inequality robust least squares 7 choose ax 6 b unitnorm vector otherwise since delta rankone kdeltak addition implies delta worstcase perturbation frobenius maximum singular value norms equality always holds 16 finally unicity x follows strict convexity worstcase residual using interiorpoint primaldual potential reduction method solving unstructured rls problem 15 number iterations almost constant 46 iteration takes onmm 2 operations rough summary analysis method order complexity one svd 32 analysis optimal solution using duality results socps following theorem theorem 32 ae 1 unique solution x rls rls problem given b else unique optimal points problem 15 proof using results x21 obtain problem dual 15 subject z since primal dual problems strictly feasible exist optimal points optimum case optimal x unique minimumnorm solution assume primal dual problems strictly feasible therefore primal dual optimal objectives equal using 8 l el ghaoui h lebret replace values z obtain expression optimal x b remark 31 rls solution interpreted solution weighted ls problem augmented system i3 theta rls method amounts compute weighting matrix theta optimal robustness via socp 15 shall encounter generalization formula linearfractional srls problem x5 remark 32 possible solve problem perturbed case worstcase residual kax kxk optimal x determined 17 bk see example x72 33 reduction onedimensional search svd available use reduce problem onedimensional convex differentiable problem following analysis also useful x6 introduce svd related decomposition b assume optimum problem 15 18 never feasible may define multiplying obtain 1 thus optimal worstcase residual robust least squares 9 f following function function f convex twice differentiable min 1 b 62 rangea f infinite twice differentiable closed interval min 1 therefore minimization f done using standard newton methods differentiable optimization theorem 33 ae 1 solution unstructured rls computed solving onedimensional convex differentiable problem 19 computing unique real root inside min 1 equation 2 r theorem yields alternative method computing rls solution method similar one given 5 related approach used quadratically constrained ls problems 19 solution requires one svd cost onm 2 3 socp method times costly see end x31 advantage include kinds additional constraints x nonnegativity andor quadratic constraints etc socp 15 low additional cost also svd solution extend structured case considered x4 34 robustness ls solution instructive know rls ls solutions coincide case say ls solution robust happens optimal problem 19 equal 1 latter implies b b 2 rangea case f differentiable minimum min 1 df obtain necessary sufficient condition optimal equal 1 condition 21 holds rls ls solutions coincide otherwise optimal 1 x given 17 may write latter condition case normbound perturbation ae different 1 ae ae min ae min thus ae min interpreted perturbation level ls solution allows note b 2 rangea ls tls solution also coincide corollary 34 ls tls rls solutions coincide whenever norm bound perturbation matrix ae satisfies ae ae min b ae min b defined 22 thus ae min b seen robustness measure ls tls solution full rank robustness measure aemin non zero decreases condition number increases remark 33 note tls solution x tls accurate sense minimizes distance function see 18 least robust sense worstcase residual ls solution x intermediate sense accuracy robustness fact shown 35 robust total leastsquares rls framework assumes data matrices b nominal values model subject unstructured perturbation bounded norm ae think b mea sured data assumption b correspond nominal model may judicious also applications normbound ae perturbation may hard estimate total leastsquares tls solution exists used conjunction rls address issue assume tls problem solution let deltaa tls deltab tls x tls minimizers tls problem minimize subject let ae tls finds consistent linear system closest frobenius norm sense observed data b underlying assumption observed data b result consistent linear system measurement process subjected unstructured perturbations unknown bounded norm ae tls assumption point ball robust least squares 11 observed well b thus tls computes uncertain linear system representation observed phenomenon nominal model ae tls perturbation level uncertain system representation choosing x tls solution ax b amounts finding exact solution nominal system compute accurate solution zero residual take account perturbation level ae tls robust solution given solution following rls problem solution problem coincides tls one case x tls ae tls ae min stricly positive except standard ls perturbations account measurement errors structured consistent ls one consider following rls problem instead 23 kdeltabkae ls turns problem yields solution ls summarize rls used conjunction tls solving linear system ax b solve tls problem build uncertain linear system representation observed data take solution x rls rls problem nominal matrices ae tls note computing tls solution precisely tls b tls ae tls requires computation smallest singular value associated singular subspace 17 4 structured robust least squares section consider srls problem compute kffikae b defined 2 assume loss generality r b x throughout section use following 41 computing worstcase residual first examine problem computing worstcase residual r b x given x notation f let 0 using sprocedure lemma 21 f every ffi exists scalar 0 gammag using fact 0 implied f may rewrite condition gammag 0 consequence worstcase residual computed solving sdp two scalar variables bit analysis shows reduce problem one dimensional convex differentiable problem obtain corresponding worstcase perturbation theorem 41 every x fixed squared worstcase residual computed solving sdp two variables subject 29 alternatively minimizing onedimensional convex differentiable function optimal problem 30 equations ffi solution worstcase perturbation proof see appendix also show compute worstcase perturbation 42 optimizing worstcase residual using theorem 41 expression f g h given 27 schur complements obtain following result theorem 42 ae 1 euclideannorm srls solved computing optimal solution x sdp subject to6 4 robust least squares 13 mx defined 26 remark 41 straightforward manipulations show result coherent unstructured case although sdp directly amenable efficient socp formulation may devise special interiorpoint methods solving problem specialpurpose methods probably much greater efficiency generalpurpose sdp solvers study left future remark 42 discussion x35 extends case perturbations structured tls problems affine structure constraints perturbation matrices discussed 7 structured version tls problem becomes hard solve srls problem retains polynomialtime complexity 5 linearfractional srls section examine generalization srls problem framework encompasses case functions affi bffi rational show computation worstcase residual npcomplete upper bounds computed optimized using sdp first need motivate problem develop formalism posing formalism introduced doyle coauthors 9 context robust identification 51 motivations structured robust leastsquares problems 3 may convenient measure perturbation size euclidean norm indeed latter implies correlated bound perturbation one may instead consider srls problem bounds correlated perturbation size 3 measured maximum norm kffik 11 also rls problems may assume columns b perfectly known instance error deltaa deltab form otherwise unknown generally may interested srls problems perturbed data matrices write adelta bdelta b given matrices delta full normbounded matrix problem perturbation structured except via matrices l ra note special case problem solved 5 finally may interested srls problems matrix functions affi bffi 3 rational functions parameter vector ffi one example given x76 turns three extensions addressed using formalism detail 52 problem definition let subspace r n thetan 2 r nthetam r nthetan ra 2 r n thetam r b 2 r n 2 r n thetan every delta 2 deti gammaddelta 6 0 14 l el ghaoui h lebret define matrix functions adelta bdelta b given x define worstcase residual r b ae x delta delta2d kdeltakae say x structured robust least squares srls solution x minimizes worstcase residual assume loss generality denote r b 1 x r b x formulation encompasses three situations referred x51 first maximumnorm srls problem 33 readily transformed problem 35 follows let nthetan b r problem 33 formulated minimization 35 defined also recover case perturbed matrices write 34 allow delta full matrix particular recover unstructured rls problem x3 follows assume n deltab theta refers dummy elements added perturbation matrix order make square n theta n matrix case perturbation set r nthetan finally case affi bffi rational functions vector ffi well defined unit ball fffi j kffik 1 1g converted polynomial time framework see eg 48 conversion procedure give example conversion x76 53 complexity analysis comparison srls problem x4 linearfractional srls problem offers two levels increased complexity first checking whether worstcase residual finite npcomplete 6 linearfractional dependence 6 0 first cause increased complexity srls problem remains hard even matrices affi bffi depend affinely perturbation elements 0 consider instance srls problem defined 36 case problem computing worstcase residual formulated kffik 11 f robust least squares 15 appropriate f g h difference wostcase residual defined 28 norm used measure perturbation computing quantity npcomplete equivalent max cut problem 36 38 following lemma provide sake completeness simple corollary result nemirovskii 32 lemma 51 problem pab x given positive rational number matrices b l ra appropriate size mvector x rational entries linear subset determine whether r b x npcomplete proof see appendix b 54 upper bound worstcase residual although problem npcomplete minimize upper bounds polynomialtime using sdp introduce following linear subspaces r inequality r b x holds every delta 2 0 using lemma 23 obtain r b x holds exist 2 g 2 g g x 6 4 theta ax gamma b theta delta minimizing subject semidefinite constraint yields upper bound r b x turns estimate worstcase residual actually exact generic sense theorem 52 ae 1 upper bound worstcase residual r b x obtained solving sdp subject 2 g 38 upper bound exact r n thetan theta 0 optimum upper bound also exact proof see appendix c l el ghaoui h lebret 55 optimizing worstcase residual since x appears linearly constraint 38 may optimize worstcase residuals upper bound using sdp may reduce number variables appearing previous problem using elimination lemma 24 inequality 38 written 11 gammar b theta defined 39 denote n orthogonal complement r using elimination lemma 24 obtain equivalent condition 38 hold x namely g theta 0 n gammar b gammab gammar b 7 5 n every g stricly feasible constraints x satisfies 38 given ra fullrank theta gamma1 ra theta gamma1 prove applied formula 13 took oe 1 theorem 53 ae 1 upper bound optimal worstcase residual obtained solving sdp subject 2 g 38 alternatively sdp subject 41 upper bound always exact r n thetan theta 0 optimum upper bound also exact optimal x unique given 42 ra fullrank proof see appendix c remark 51 parallel unstructured case see remark 31 linear fractional srls interpreted weighted ls augmented system precisely theta 0 linearfractional srls solution interpreted solution weighted ls problem ra srls method amounts compute weighting matrix theta optimal robustness robust least squares 17 remark 52 results coherent unstructured case replace l r 0 variable set g 0 parameter theorem 32 interpreted schur complement gamma lsl matrix theta remark 53 emphasize results exact non conservative perturbation structure full particular recover generalize results 5 case columns affected otherwise unstructured perturbations remark 54 possible use approximation method 16 obtain solutions based sdp relaxations given theorem 53 expected value within 14 true value 6 link regularization standard ls solution x ls sensitive errors b illconditioned fact ls solution might continuous function b neardeficient motivated many researchers ways regularize ls problem make solution x unique continuous data matrices b section briefly examine links rls srls solution regularization methods standard ls beforehand note since problems formulated sdps could invoke quite complete sensitivity analysis results obtained bonnans cominetti shapiro 3 application general results sdps considered 35 61 regularization methods ls regularization methods ls amount impose additional bound solution vector x one way minimize whereomega squarednorm see 23 43 8 another way use constrained leastsquares see 18 p561571 classical tikhonov regularization method omegagamma regularization parameter modified value x obtained solving augmented ls problem given note every 0 x continuous b expression also arises levenbergmarquardt method optimiza tion ridge regression problem 17 mentioned 18 choice appropriate problemdependent many cases obvious elaborate regularization schemes tikhonov type identity matrix 46 replaced positive semidefinite weighting matrix see instance 31 8 interpreted weighted leastsquares method augmented system l el ghaoui h lebret 62 rls regularization noting similarity 17 46 interpret unstructured rls method one tikhonov regularization following theorem yields estimate smoothing effect rls method note improved regularity results given 35 theorem 61 unique rls solution x rls optimal worstcase residual continuous functions data matrices b furthermore k compact set r n every uncertainty size ae 0 function r nthetam theta k gamma 1 dk lipschitzian lipschitz constant 1 theorem 61 shows level robustness normbound perturbations ae regularization describe x7 numerical examples illustrate results remark 61 rls method tikhonov regularization parameter chosen solving secondorder cone problem way optimal robustness cost rls solution equal cost solving small number leastsquares problems size classical tikhonov regularization problem 45 remark 62 equation determines rls method ae choice resemblance millers choice 30 determined recursively equations formula arises rls perturbation b see remark 32 thus millers solution corresponds rls problem perturbation affects columns note solution necessarily regular continuous total leastsquares tls deserves special mention tls problem solution given x oe smallest singular value b corresponds 46 negative value implies tls deregularized ls fact noted 17 view link regularization robustness consistent fact rls trades accuracy tls robustness regularity expense introducing bias solution see also remark 33 63 srls regularization similarly may ask whether solution srls problem x4 continuous data matrices case unstructured rls problems discuss continuity optimal worstcase robust least squares 19 residual respect problems coefficient matrices fixed view theorem 42 continuity holds feasible set sdp 32 bounded obviously objective bounded thus variable also bounded 32 implies 0 bounded see 32 implies x bounded bounded implies x bounded property holds theorem 62 sufficient condition continuity optimal worstcase residual function 64 linearfractional srls regularization precise conditions continuity optimal upper bound worstcase residual linearfractional case known may however regularize quantity using method described 29 related problem given ffl 0 define bounded set ae ffl oe defined 37 easy show restricting condition number variable also bounds variable g sdp 44 yields following result theorem 63 upper bound optimal worstcase residual obtained computing optimal value ffl sdp min subject 2 g 41 corresponding upper bound continuous function b ffl 0 corresponding optimal value ffl limit equal optimal value sdp 44 noted remark 51 linearfractional srls interpreted weighted ls regularization method thus method belongs class tikhonov weighted ls regularization methods referred 61 weighting matrix optimal robustness 7 numerical examples following numerical examples obtained using two different codes sdps used code sp 45 matlab interface sp called 10 unstructured rls problems used secondorder cone program described 28 l el ghaoui h lebret iter vertical bars indicate deviation 20 trials mean min iter vertical bars indicate deviation 20 trials mean min fig 1 average minimum maximum number iterations various rls problems using socp formulation left figure show numbers values n ranging 100 1000 value n vertical bar indicates minimum maximum values obtained 20 trials b right figure show numbers values ranging 11 100 value n vertical bar indicates minimum maximum values obtained 20 trials b 1000 plots plain curve mean value 71 complexity estimates rls first largescale experiments rls problem x3 mentioned x21 number iterations almost independent size problem socps solved problem 15 uniformly generated random matrices vectors b various sizes n figure 1 shows average number iterarions well minimum maximum number iterations various values n experiments confirm fact number iterations almost independent problem size rls problem 72 ls tls rls compare ls tls rls solutions left right plots fig 2 show four points signs corresponding linear fits ls problems solid line tls problems dotted line rls problems dashed lines left plot gives rls solution perturations adeltaa bdeltab whereas right plot considers perturbation plots worstcase points rls solution indicated 0 2 ae increases slope rls solution decreases goes zero ae 1 plot confirms remark 33 tls solution accurate least robust ls intermediate case perturbations right plot obtain instance linearfractional srls full perturbation matrix mentioned x51 also possible solve problem directly x3 last case course worstcase perturbation move along aaxis robust least squares 21 tls rls tls rls fig 2 leastsquares solid total leastsquares dotted robust leastsquares dashed solutions signs correspond nominal b left plot gives rls solution perturations right plot considers perturbation b worstcase perturbed points rls solution indicated 0 2 73 rls regularization mentioned x6 may use rls regularize illconditioned ls problem consider rls problem matrix singular fig 3 shows regularizing effect rls solution left resp right figure shows optimal worstcase residual resp norm rls solution function parameter ff various values ae ae 0 obtain ls solution latter continuous function ff solution norm residual exhibit spike becomes singular ae 0 rls solution smooth spike flattened ae grows illustrates theorem 61 1 optimal worstcase residual becomes flat independent ff equal 74 robustness ls solution next example illustrates sometimes precisely b 2 rangea ls solution robust perturbation level ae min defined 22 natural robustness ls solution degradates condition number grows 0 consider rls problem 1 considered six values equals inverse condition number 05 55 table 1 shows values ae min defined 22 22 l el ghaoui h lebret ff dashed dashed dotted ff fig 3 optimal worstcase residual norm rls solution vs ff various values perturbation level ae optimal residual solution discontinuous spike smoothed robustness asked ae increases right plot curves visible table values ae min various curve ae min 006 034 078 112 128 135 six values condition number grows robustness ls solution measured ae min decreases right plot fig 4 gives worstcase residual vs robustness parameter ae six values plot illustrates ae ae min ls solution case differs rls one indeed curve residual remains equal zero long ae ae min example curve labeled 1 corresponding quits xaxis ae ae left plot fig 4 corresponds rls problem plot shows various functions f defined 20 value optimal hence rls solution obtained minimizing function f three smallest values induce functions f defined 20 minimal 1 three others optimal 1 means ae min smaller 1 first three cases larger 1 cases confirmed table 1 75 robust identification consider following system identification prob lem seek estimate impulse response h discretetime system input u output assuming system singleinput singleouput linear order u zero negative time indices u h related robust least squares 23 6 531 fig 4 left plot shows function f defined 20 six values ae 1 right plot gives optimal rls residuals versus ae values labels correspond values given table 1 convolution equations u lower triangular toeplitz matrix whose first column u assuming known exactly leads linear equation h computed standard ls practive however u subject errors may assume instance actual value ffiy u u unknownbutbounded perturbations perturbed matrices u write ith column theta identity matrix u lower triangular toeplitz matrices first column equal e first assume sum input output energies bounded adress following min kffikae example consider following nominal values fig 5 shown optimal worstcase residual corresponding ls solution given solving problems 30 32 respectively since ls l el ghaoui h lebret solution zero residual u invertible prove check figure worstcase residual grows linearly ae contrast rls optimal worstcase residual finite limit ae 1 rls ae fig 5 worstcase residuals ls euclideannorm srls solutions various values perturbation level ae worstcase residual ls computed solving problem 30 fixed assume perturbation bounds u correlated instance consider problem 48 bound kffik ae replaced physically bounds mean output energy peak input bounded problem formulated minimizing worstcase residual 35 delta following structure symbols theta denote dummy elements delta added order work square perturbation matrix structure corresponds set 36 fig6 show worstcase residual vs ae uncertainty size show curves corresponding values predicted solving sdp 43 x variable robust least squares 25 upper bound ls solution lower bound ls solution upper bound rls solution lower bound rls solution ae fig 6 upper lower bounds worstcase residuals ls rls solutions upper bound ls computed solving sdp 38 fixed lower bounds corresponds largest residuals kuffi trial x gamma yffi trial k among 100 trial points ffi trial rls solution x fixed ls solution x ls also show lower bounds worstcase obtained using 100 trial points plot shows ls solution estimate worstcase residual exact discrepancy grows linearly uncertainty size contrast rls solution estimate appears exact every value ae 76 robust interpolation following example robust interpolation problem formulated linearfractional srls problem given integers polynomial degree interpolates given points assume known exactly obtain linear equation unknown x vandermonde structure6 6 4 solved via standard ls assume interpolation points known exactly instance may assume b known parameterdependent ffi unknownbutbounded jffi seek robust interpolant solution x minimizes kffik 1ae 26 l el ghaoui h lebret problem linearfractional srls problem indeed shown 1 note deti gamma ddelta 6 0 since stricly upper triangular fig 7 shown result 1 6 423 ls solution accurate zero nominal residual every point interpolated ex actly predicted worstcase residual 17977 rls solution trades accuracy one point interpolated nominal residual 08233 robustness worstcase residual less 11573 ae 1 rls interpolation polynomial becomes horizontal consistent fact allow perturbations vector limit interpolation polynomial solid line robust least squares 27 fig 7 interpolation polynomials ls rls solutions 02 ls solution interpolates points exactly rls one guarantees worstcase residual error less 11573 rls solution zero polynomial 8 conclusions paper shows several robust leastsquares rls problems unknownbutbounded data matrices amenable convex secondorder cone semidefinite programming socp sdp implication rls problems solved polynomialtime efficiently practice perturbation enters linearly data matrices size measured euclidean norm linearfractional problem full perturbation matrix delta method yields exact value optimal worstcase residual cases examined arbitrary rational dependence data matrices perturbation parameters computing worstcase residual npcomplete shown compute optimize using sdp upper bound worstcase residual takes account structure information unstructured case shown worstcase residual unique rls solution continuous unstructured rls interpreted regularization method illconditioned problems striking fact cost rls solution equal small number leastsquares problems arising classical tikhonov regularization approaches method provides rigorous way compute optimal parameter data associated perturbation bounds similar weighted leastsquares interpretations continuity results given structured case examples demonstrated use socp code 27 generalpurpose semidefinite programming code sp 45 future work could devoted writing special code exploits structure problems order increase efficiency method instance seems many problems perturbation matrices sparse andor special eg toeplitz structure method used several related problems constrained rls may consider problems additional convex constraints added vector x constraints arise naturally eg image processing instance may consider problem 1 addi 28 l el ghaoui h lebret tional linear resp quadratic convex constraint cx 0 solve problem suffices add related constraint corresponding socp sdp formulation note svd approach x33 fails case ffl rls problems norms may consider rls problems worstcase residual error measured norms maximum ffl matrix rls may course derive similar results constant term b matrix worstcase error evaluated variety norms ffl errorinvariables rls may consider problems solution x also subject uncertainty due implementation andor quantization errors may consider worstcase residual form given may compute optimize upper bounds quantity using sdp subject examined 25 acknowledgments authors wish thank anonymous reviewers precious comments led many improvements first version paper particularly indebted reviewer pointed socp formulation unstructured problem also thank g golub r tempo providing us related references sayed sending us preliminary draft 5 paper also benefited many fruitful discussions boyd f oustry b rottembourg l vandenberghe proof theorem 41 introduce eigendecomposition f related decomposition g writes optimum exists nonzero vector u gamma f inequality 29 conclude g words gcontrollable u eigenvector proves uncontrollability using 49 obtain optimal value case thus worstcase residual computed claimed theorem robust least squares 29 every pair optimal problem 29 compute worstcase perturbation follows define optimum gcontrollable function f defined 31 satisfies df 0 case optimal satisfies kffi 1 using 50 obtain f proves ffi 0 worstcase perturbation optimum df implies kffi 0 k 1 since max exists vector u loss generality may assume vector f proves ffi defined worstcase perturbation cases seen equals worstcase perturbation vector ffi shown equations always solution ffi optimal ends proof b proof lemma 51 use following result due nemirovsky 32 lemma b1 let gammap scalar function positive integer p pdimensional vector first gamma welldefined takes rational values 0 kak gamma2 positive integers p pdimensional vectors kak 01 second value function given pair p computed time polynomial p length standard representation rational vector problem l el ghaoui h lebret given integer p 0 2 r p kak 01 rational positive entries determine whether kffik 11 npcomplete besides either 51 holds kffik 11 da smallest common denominator entries prove result suffices show appropriate function gamma satisfying conditions lemma b1 reduce given p problem polynomial time set 2a function satisfies requirements lemma b1 problem p gamma p nphard given rational positive entries set b x follows first set set diagonal matrices r pthetap set finally set b 34 1 worstcase residual problem r b kffik 11 kffik 11 proof complete c proof theorem 53 section prove theorem 53 proof theorem 52 follows lines start problem 43 dual maximization 2b w r b u subject linear constraints g trgy robust least squares 31 since primal dual problems strictly feasible every primal dual feasible points optimal zf g defined 38 see 46 one obtains particular g using equation 58 55 obtain implies equality primal dual objectives trivial case easily ruled assume matrix theta defined 39 positivedefinite optimum equations 5759 deduce dual variable z rankone w using 57 59 obtain theta 55 easy derive expression 42 optimal x case theta 0 optimum ra fullrank show upper bound exact optimum case use condition 54 expression z v deduced 53 obtain implies exists theta 0 straightforward application lemma 23 shows deti gamma ddelta 6 0 obtain 61 53 12 compute 55 60 l el ghaoui h lebret therefore obtain proves matrix delta worstcase perturbation r efficient newton barrier method minimizing sum euclidean norms pertubed optimization second order regularity hypothesis linear matrix inequalities system control theory new linear leastsquares type model parameter estimation presence data uncertainties computing real structured singular value nphard structured total least squares l 2 approximation problems image reconstruction restoration overview common estimation problems unifying robustness analysis system id lmitool frontend lmi op timization algorithms regularization ill conditioned leastsquares problems robustness presence mixed parametric uncertainty unmodeled dynamics collinearity total least squares optimization weighting constant regularization least squares system identification analysis total least squares problem quadratically constrained least squares quadratic prob lems robust generalized leastsquares estimator regularization methods largescale problems backward error condition structured linear systems application constrained leastsquares estimation image restoration digital computer controllers general h1 control problem lmi existence conditions state space formulas social sciences synthese de diagrammes de reseaux dantennes par optimisation convexe continuitydiscontinuity robustness indicators least squares methods illposed problems prescribed bound several nphard problems arising robust stability analysis interior point polynomial methods convex programming theory applications application bounded parameter models robust solutions uncertain semidefinite pro grams checking robust nonsingularity nphard matrix anal connection robust control identifica tion indefinite trust region subproblems nonsymmetric eigenvalue perturbations solutions illposed problems total least squares problem computational aspects analysis robust estimation techniques regularized image restora tion robust optimal control tr ctr michele covell sumit roy beomjoo seo predictive modeling streaming servers acm sigmetrics performance evaluation review v33 n2 p3335 september 2005 jos f sturm shuzhong zhang cones nonnegative quadratic functions mathematics operations research v28 n2 p246267 may alexei r pankov konstantin v siemenikhin minimax estimation singular linear multivariate models mixed uncertainty journal multivariate analysis v98 n1 p145176 january 2007 arvind nayak emanuele trucco neil thacker simple ls estimators enough empirical study ls tls gtls international journal computer vision v68 n2 p203216 june 2006 mohit kumar regina stoll norbert stoll robust solution fuzzy identification problem uncertain data regularization fuzzy optimization decision making v3 n1 p6382 march 2004 jianchao yao estimation 2d displacement field based affine geometric invariance scene constraints international journal computer vision v46 n1 p2550 january 2002 budi santosa theodore b trafalis robust multiclass kernelbased classifiers computational optimization applications v38 n2 p261279 november 2007 dimitris bertsimas dessislava pachamanova robust multiperiod portfolio management presence transaction costs computers operations research v35 n1 p317 january 2008 juan liu ying zhang feng zhao robust distributed node localization error management proceedings seventh acm international symposium mobile ad hoc networking computing may 2225 2006 florence italy goldfarb g iyengar robust portfolio selection problems mathematics operations research v28 n1 p138 february pannagadatta k shivaswamy chiranjib bhattacharyya alexander j smola second order cone programming approaches handling missing uncertain data journal machine learning research 7 p12831314 1212006 ivan markovsky sabine van huffel overview total leastsquares methods signal processing v87 n10 p22832302 october 2007 mung chiang geometric programming communication systems communications information theory v2 n12 p1154 july 2005