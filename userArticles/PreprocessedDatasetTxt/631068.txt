experimental comparison effectiveness branch testing data flow testing experiment comparing effectiveness alluses alledges test data adequacy criteria discussed experiment designed overcome deficiencies previous software testing experiments large number test sets randomly generated nine subject programs subtle errors test set percentages executable edges definitionuse associations covered measured determined whether test set exposed error hypothesis testing used investigate whether alluses adequate test sets likely expose errors alledges adequate test sets logistic regression analysis used investigate whether probability test set exposes error increases percentage definitionuse associations edges covered increases error exposing ability shown strongly positively correlated percentage covered definitionuse associations four nine subjects error exposing ability also shown positively correlated percentage covered edges four different subjects relationship weaker b introduction considerable effort software testing research focussed development software test data adequacy criteria criteria used determine software tested enough released numerous test data adequacy criteria proposed including based control flow analysis 25 26 data flow analysis 23 29 31 34 program mutation 9 tools based several criteria built 8 14 28 many theoretical studies formal properties certain aspects relations one another done 6 12 15 34 surprisingly relatively little work focussed crucial question good exposing errors test sets deemed adequate according criteria paper describe experiment addressing question one factor makes difficult answer question given program p adequacy criterion c typically large number adequate test sets p incorrect usually test sets expose error others previous experiments failed sample large space test sets statistically sound way thus given potentially misleading results goals research twofold 1 develop experiment design allows errordetecting ability adequacy criteria compared meaningful way 2 use design measure compare several adequacy criteria variety subject programs section 2 define notion effectiveness adequacy criterion given erroneous program specification measures likelihood adequate set expose error higher effectiveness criterion c confidence program tested cadequate test set without exposure error indeed correct experiment measured effectiveness sampling space cadequate test sets nine subject programs generated large number test sets determined extent test set satisfied certain adequacy criteria determined whether test set exposed error data used measure compare effectiveness several adequacy criteria address several related questions limited attention three adequacy criteria alledges criterion also known branch testing wellknown technique widely used practice sophisticated adequacy criteria requires test data cause execution edge subject programs flow graph alluses data flow testing criterion requires test data cause execution paths going points variables assigned values points values used received considerable attention research community considered promising many testing researchers comparison also consider null criterion deems test set adequate design experiment allowed us address three types related questions given subject program pair criteria c1 c2 investigated 1 overall comparison criteria test sets satisfy criterion c1 likely detect error satisfy c2 generally test sets satisfy x requirements induced c1 likely detect error satisfy requirements induced c2 2 comparison criteria fixed test set size given test set size n test sets size n satisfy criterion c1 likely detect error satisfy c2 3 relationship coverage effectiveness likelihood test set detects error depend extent test set satisfies criterion size test set overall comparisons criteria give insight criterion selected cost factor c1 effective c2 c1 typically demands larger test sets c2 one may ask whether increased effectiveness arises differences test set sizes intrinsic characteristics criteria comparison criteria fixed test set size addresses issue factoring differences test set size lastly investigation relationship coverage effectiveness useful practice unusual demand partial satisfaction criterion believe results reported interest testing researchers testing practitioners practitioners may primarily interested experiments results implications choosing adequacy criterion researchers may also find novel design experiment interesting paper organized follows section 2 paper defines effectiveness reviews definitions relevant adequacy criteria section 3 describes design experiment section 4 describes statistical analysis techniques used section 5 describes subject programs experiment performed experiments results presented section 6 discussed section 7 experiment design compared related work section 8 conclusions presented section 9 background 21 effectiveness adequacy criterion goal testing detect errors programs say test case exposes error program p input ps output different specified output test set exposes error exposing least one test case exposes error consider following model testing process ffl test set generated using test data generation technique ffl program executed test set outputs checked adequacy test set checked ffl least one test case exposes error program debugged regression tested errors exposed test set inadequate additional test cases generated ffl process continues program executed adequate test set fails expose error point program released although program guaranteed correct better adequacy criterion confidence one correct note explicitly distinguished two aspects testing test generation application test data adequacy criterion test generation technique algorithm generates test cases whereas adequacy criterion predicate determines whether testing process finished test generation algorithms adequacy criteria based structure program tested called programbased whitebox based structure program called blackbox blackbox techniques typically specificationbased although random testing possible principle use white box techniques basis test generation example one could examine program text devise test cases cause execution particular branches however usually much difficult generate test case causes execution particular branch simply check whether branch executed given test case thus practice systematic approaches test generation usually blackbox systematic approaches checking adequacy often whitebox black box test generation techniques may involve devising test cases intended exercise particular aspects specification may randomly sample specifications domain testing techniques investigated paper combine black box test generation techniques whitebox adequacy criteria particular explore whether one white box adequacy criterion likely another detect bug particular random black box testing strategy used define measure goodness adequacy criterion captures intuition let p incorrect program whose specification let c adequacy criterion consider test sets satisfy c p may case test sets expose error others large percentage cadequate test sets expose error c effective criterion program formally consider given probability distribution space cadequate test sets program p specification define effectiveness c probability test set selected randomly according distribution expose error practice test sets generated using particular test generation strategy g random testing given input distribution form blackbox testing systematic whitebox strategy induces distribution space cadequate test sets define effectiveness criterion c p relative test generation strategy g probability cadequate test set generated g expose error p paper concerned effectiveness criteria relative various random test generation strategies see notion effectiveness captures intuition goodness adequacy criterion let pc p denote effectiveness criterion c program p probability randomly selected cadequate test set expose error ie release p treating correct particular p incorrect probability testing cadequate test set mistakenly believe p correct suppose pc1 p class p since probability mistakenly believing p correct using c2 adequacy criterion least great used c1 adequacy criterion thus testing p without exposing error least much confidence p correct used criterion c1 used criterion c2 weiss defined general notion effectiveness adequacy criterion discussed relation confidence program correctness 37 previous comparisons adequacy criteria based investigating whether one criterion subsumes another criterion c1 subsumes criterion c2 every program p specification every test set satisfies c1 also satisfies c2 might seem first glance c1 subsumes c2 c1 guaranteed effective c2 every program case may happen program specification test generation strategy g test sets satisfy c2 may better exposing errors satisfy c1 hamlet discussed related issues 21 weyuker weiss hamlet 40 frankl weyuker 17 16 examined relationship subsumption errordetecting ability 22 definitions adequacy criteria study compares effectiveness three adequacy criteria alledges criterion alluses criterion null criterion two criteria alledges uses members family criteria sometimes called structured testing criteria require test data cause execution representatives certain sets paths flow graph subject program null criterion considers test set adequate thus application null criterion using adequacy criterion included null criterion study order allow comparison alledges alluses adequate sets arbitrary sets alledges criterion also known branch testing demands every edge programs flow graph executed least one test case alledges known relatively weak criterion sense often easy devise test set covers edges buggy program without exposing bug much demanding completely impractical criterion path testing requires execution every path programs flow graph effort bridge gap branchtesting pathtesting rapps weyuker 34 defined family adequacy criteria based data flow analysis similar done optimizing compiler alluses criterion belongs family 1 data flow testing criteria also defined 23 29 31 roughly speaking criteria demand test data exercise paths points variables defined points values subsequently used occurrences variables subject program classified either definitions values stored uses values fetched example variable occurrence lefthand side assignment statement definition variable occurrence right hand side assignment statement boolean expression conditional statement typically use definitionuse association dua triple duv node programs flow graph variable v defined u node edge v used definitionclear path respect v u test case covers dua duv causes execution path goes u without passing intermediate node v redefined alluses criterion demands test data cover every dua subject program previously designed implemented tool asset 11 12 14 checks extent given test set given pascal program satisfies alluses various data flow testing criteria asset analyzes subject program determine definitionuse associations particular program unit builds modified program whose functionality identical original subject program except also outputs trace path followed test case executed executing modified program given test set asset analyzes traces determine extent adequacy criterion satisfied outputs list definitionuse associations still need covered experiment modified asset could also check whether test set satisfies alledges replaced assets interactive user interface batch interface one problem alledges alluses criteria originally defined programs adequate test set exists problem arises infeasible paths program ie paths never executed problem 1 original criteria defined programs written simple language definitions subsequently extended frankl weyuker 15 programs written pascal adopt conventions notation particularly serious alluses criterion many commonplace programs adequate test set exists example problem occurs program loop lower upper bounds nonequal constants frankl weyuker defined new family criteria feasible data flow testing criteria circumvents problem eliminating unexecutable edges definitionuse associations consideration 12 15 showed reasonable restrictions subject program feasible version alluses subsumes feasible version alledges important note original infeasible criteria really used practice apply programs infeasible edges duas feasible versions programs ideally testers examine program eliminate infeasible edges duas consideration reality often stop testing arbitrary percentage edges duas covered without investigating whether remaining edgesduas infeasible whether indicate deficiencies test set reason felt also important examine relationship percentage duas covered test set likelihood exposing error remainder paper abuse notation use terms alledges alluses refer feasible versions criteria 3 experiment design goal experiment measure compare effectiveness various adequacy criteria relative random test generation strategies several different subject programs measure effectiveness criterion c ffl generate large number cadequate test sets ffl execute subject program test set ffl check outputs consider test set exposing program gives wrong output least one element test set ffl calculate proportion cadequate test sets exposing proportion c1adequate test sets expose error significantly higher proportion c2adequate test sets expose error conclude criterion c1 effective c2 given program test generation strategy present experiment generated test sets randomly compared edges alluses null criteria programs experimented exact notion randomly generated test sets used described section 5 collected data way allow comparison family variants alledges alluses rather checking whether test set satisfied alledges alluses recorded number executable edges duas covered test set allowed us use collected data measure effectiveness alledges alluses also criteria x edge coverage dua coverage addition allowed us investigate correlation percentage edges duas covered error exposing ability subject program first identified unexecutable edges duas eliminated consideration generated large set test cases called universe executed test case universe checked output recorded whether correct saved trace path executed test case 2 sampled space adequate test sets follows selected various test set sizes n n generated many test sets randomly selecting n elements universe using uniform distribution note use uniform distribution space test sets rather used distribution arises practical test generation strategy determined whether test set exposing used asset check many executable edges duas covered paths corresponding test set care necessary choosing appropriate test set sizes generated test sets small relatively cover edges duas results statistically significant hand test sets large almost expose errors making difficult distinguish effectiveness two criteria overcome problem generated test sets batches batch contained sets fixed size observing sizes large small generated additional batches appropriate size range necessary stratification test sets size also allowed us investigate whether alluses effective alledges test sets given size design experiment imposed several constraints subject programs ffl input domain program structure reasonable way generate universe test cases example several reasonable ways randomly generate matrices less clear randomly generate inputs operating system ffl large number test cases program executed necessary means automatically checking correctness outputs two subjects matinv1 determinant executable duas covered element universe dealt considering dua wasnt covered universe unexecutable ffl failure rate program low ie errors exposed relatively inputs universe otherwise almost test set big enough satisfy alledges would likely expose error surprised discover many programs considered candidates experiment including many used previous software quality studies rejected high failure rates available tool support asset imposed additional constraint subject programs either written pascal short enough translate manually translation necessary program structure changed little possible note experiment considered effectiveness alledges adequate sets general effectiveness alledges adequate sets fail satisfy alluses models situation tester releases program passed alledges adequate test set without caring whether test set also satisfies alluses alternative model tester would classify test set alledges adequate satisfied alledges satisfy alluses alluses shown effective alledges using model difference would even greater use alternative model also note design introduces bias favor alledges used test sets big enough insure selection statistically significant number alluses adequate sets significant number alledges adequate sets resulted selection many alledges adequate sets bigger thus likely expose error alledges adequate sets would selected practitioner using model testing process 4 data analysis techniques recall interested comparing effectiveness alluses alledges null criterion variety subject programs treat subject programs data separate experiment throughout section refer effectiveness criterion mean effectiveness particular program test generation strategy clarity describe techniques used compare alluses alledges techniques comparing alluses alledges null criterion comparing coverage x duas coverage edges identical randomly chosen n cadequate test sets x number exposed least one error sample proportion good estimator pc effectiveness c fact probability cadequate test set exposes error governed binomial distribution pc minimum variance unbiased estimator effectiveness c 3 ie good statistic estimating effectiveness 41 overall comparison criteria first question posed whether alluses adequate test sets significantly effective alledges adequate test sets let p u proportion alluses adequate sets exposed error let e proportion alledges adequate sets exposed error p u significantly higher e strong statistical evidence alluses effective alledges data support hypothesis observation suggests hypothesis testing techniques suitable answering question hypothesis testing research alternative hypothesis pitted null hypothesis data used determine whether one hypothesis likely true research hypothesis alluses effective alledges expressed assertion p e p u null hypothesis two criteria equally effective expressed p note chose onesided test wanted know whether alluses effective alledges whether different important realize goal hypothesis testing quite conservative uphold null hypothesis true unless data strong testimony case reject null hypothesis favor alternative since using sample proportions estimators effectiveness criteria decision accept reject null hypothesis reduces decision whether difference sample proportions significantly large particular reject e greater prespecified critical value using standard statistical technique establishing critical values 5 call sample sufficiently large least five exposing five unexposing test sets sample sufficiently large samples difference p e approximately normally distributed mean p e assume parent populations binomial oe 2 population size enables us calculate critical values significance probabilities confidence intervals p significance probabilities indicate strength evidence rejection hypotheses confidence intervals give indication much better one criterion conservative interpretation data chose significance level meaning null hypothesis rejected probability alledges actually effective alluses 1100 several subjects every alluses adequate test set exposed error normal approximation could used cases calculated confidence intervals separately p u p e inspection data showed alluses clearly effective alledges subjects making analysis unnecessary 42 comparison criteria fixed size test sets second question asked dealt effect test set size previous results alluses adequacy criterion general requires larger test sets alledges criterion since probability test set exposes error increases size increases subjects alluses may effective alledges simply demands larger test sets hand increased effectiveness alluses may result way criterion subdivides input domain 39 determine whether differences effectiveness criteria primarily due differences sizes adequate test sets analyzed data bysize basis tables 6 7 8 display sample data subject programs size arranging close sizes groups intent table give descriptive evidence relationship alluses alledges fixed size test sets enough data also hypothesis testing individual size groups reported results right hand columns 43 relationship coverage effectiveness third question answered whether relationship extent test set satisfies alluses alledges criterion probability test set expose error difficult questions technique employed answer logistic regression regression model gives mean response variable particular group variables function numerical characteristics group response variable predictors denote mean given fixed values ordinary linear higher order regression models suitable data response variable takes yesno type values exposing exposing part regression equations put constraints value jx right hand side take real value whereas left hand side must lie 0 1 right hand side also assumed follow normal distribution whereas left hand side generally serious problems make linear regression poor choice modeling proportions 1 logistic regression overcomes problems provides many important advantages well logistic regression left hand side equation 1 replaced logit response variable log right hand side realvalued function predictors expression frequently called odds ratio response variable jx lies 0 1 odds ratio assume positive real value logarithm logit assume real value thus logistic regression equation 1 becomes one neither left right hand side constrained algebraic manipulation shows log exp fx equation regression equation goal find simplest function fx explains data well analysis treated test set size fraction coverage definitionuse associations edges predictor variables used logistic regression determine extent probability exposing error dependent upon variables used catmod module sas assist regression analysis using maximum likelihood estimation measuring goodness fit 2 tests model parameter estimates likelihood ratio 5 subject programs nine subjects obtained seven programs naturally occurring errors three programs drawn duran ntafos study 10 high failure rates made rest duranntafos subjects unsuitable experi ment programs buggyfind textfmt transpose described used duran ntafos remainder came sources obtained two subjects buggyfind using two different input distributions recall asset monitors coverage edges duas single program unit obtained two subjects matrix inversion program instrumenting two different procedures section describe programs procedures selecting random test data method used check outputs table 1 gives numbers lines code edges duas executable edges executable duas instrumented procedures proportions failure causing test cases universe subject loc edges duas exec exec failure edges duas rate detm 28 strmtch2 textfmt 26 21 50 transpose 78 44 97 42 88 0023 table 1 subject programs 51 buggyfind hoares find program 24 takes input array index f permutes elements elements left position f less equal af elements right position f greater equal af boyer elspas levitt 4 analyzed erroneous variant program dubbed buggyfind represented failed attempt translate hoares program lisp experiment translated lisp version pascal tested using two different distributions random inputs find1 test universe consisted 1000 randomly generated arrays array sizes randomly selected zero 10 elements randomly selected range 1 100 values f randomly selected 1 array size find2 universe contained one test case array elements selected f0 1 2 3 4g range n 0 5 distribution closely approximates uniform random selection test cases array sizes 0 5 find1 find2 checked output checking whether elements left position f less equal af elements right position f greater equal af 52 textformat goodenough gerhart 19 analyzed erroneous text formatting program identified seven problems program traced five faults four faults either blatant useful experiment could replicated pascal versions program textfmt program pascal version goodenough gerharts corrected textfmt program reinserted remaining fault fault corresponds goodenough gerharts problems n5 n6 causes leading blanks adjacent blankslinebreaks handled improperly would liked reinsert faults produce additional subject programs either could replicated pascal led failure rates high test case piece text 15 characters long generated repeated uniform random selection character set consisting uppercase letters lowercase letters blank newline characters outputs checked comparing output text correct version using unix diff command 53 transpose next subject program transpose routine sparse matrix package algorithm 408 collected algorithms acm 30 two faults subsequently identified 20 translated corrected fortran program pascal reintroduced one faults universe could expose alleged fault failure occurs first row matrix consists entirely zeros since sparse matrix package designed reduce memory storage matrices whose densities exceed 66 chose test cases randomly among set r c matrices densities 0 66 matrix transpose package required c r positions zeros matrices chosen randomly nonzero entries filled rowmajor ordinal values check outputs simply compared elements mij mji j 54 stringmatching programs two subject programs bruteforce stringmatching programs input text pattern supposed output location first occurrence pattern text occurs zero pattern never occurs first subject strmtch1 resulted flawed attempt modify stringmatching program pascal textbook 7 could handle variable length texts patterns error occurs pattern length zero entered case program returns value two note several reasonable specifications program case returning value two among previously observed alluses criterion guaranteed expose error one duas executed pattern length zero know effectiveness alledges null criterion program second erroneous string match program strmtch2 reflects different error also occurred naturally implementation maximum length pattern shorter program sometimes working truncated version pattern hence sometimes erroneously reports found match stringmatching programs universe consisted text pattern pairs two letter alphabet text length pattern length ranging zero four outputs checked comparing produced correct program 55 matrix manipulation three subject programs derived mathematical software package written group project graduate software engineering course one programs package matrix inversion program used lu decomposition 33 error program implementation error rather case choosing known algorithm quite meet specification problem arose lu decomposition algorithm detects singular matrices thus given singular matrices program returns error message given others returns matrix purported inverse input matrix interesting note several wellknown numerical methods textbooks 33 describe lu decomposition algorithm brief mention singularity problem thus easy imagine professional programmer misusing algorithm algorithm two steps called decomposition backsolving decomposition step implemented procedure ludcmp returns lu decomposition rowwise permutation input matrix backsolving step achieved repeated calls procedure lubksb triangular matrices used compute inverse subject program matinv1 procedure ludcmp instrumented matinv2 lubskb instrumented cases test sets drawn universe consisted square matrices sizes uniformly selected 0 5 integer entries selected uniformly 0 24 outputs checked multiplying output matrix input matrix comparing identity matrix subject program determinant used lu decomposition compute determinant square matrix program operated calling ludcmp procedure multiplying diagonal elements resulting lowertriangular matrix like matrix inversion program determinant produces error message singular matrices computes determinant incorrectly others errors programs related one another worth noting sets inputs two programs fail identical instrumented ludcmp procedure generated another universe way universe used matrix inversion subjects check outputs compared results obtained using inefficient correct program based calculating minors cofactors 6 results results experiment presented organized three subsections corresponding three types questions asked initially 1 test sets satisfy criterion c1 likely detect error satisfy c2 2 given test set size test sets satisfy criterion c1 likely detect error satisfy c2 3 likelihood test set detects error depend extent test set satisfies criterion subsections present describe tables summarize data statistical analysis interpret analysis 61 overall comparison criteria tables 2 3 4 summarize results comparisons effectiveness alluses alledges alluses null alledges null columns labeled n e n u give total numbers adequate test sets criteria alledges alluses null respectively columns labeled give proportions expose errors sixth column table gives significance probability applicable entry indicates hypothesis testing could applied yes column labeled p e p u indicates alluses significantly effective alledges columns labeled p analogous questions answer question yes confidence intervals shown last column cases normality assumption held confidence interval difference effectiveness two criteria eg p cases confidence intervals around effectiveness criterion shown example first row table 2 indicates determinant 99 confident effectiveness alledges lies 0 008 whereas alluses lies 052 10 second row indicates find1 99 confident effectiveness alluses 006 016 greater alledges examination tables shows five nine subjects alluses effective alledges 99 confidence six subjects alluses effective null criterion five subjects alledges effective null note strmtch2 alluses would considered effective alledges 98 confidence interpretation results given section 7 subj n e confidence detm 169 0041 7 1000 yes 000008 vs 052100 find1 1678 0557 775 0667 0000 yes 006016 find2 3182 0252 43 0256 0476 matinv1 3410 0023 76 1000 yes 002003 vs 094100 strmtch1 1584 0361 238 1000 yes 033039 vs 098100 strmtch2 1669 0535 169 0615 0015 textfmt 1125 0520 12 1000 yes 048056 vs 068100 transpose 1294 0447 13 0462 0456 table 2 alledges vs alluses subj confidence detm 6400 0032 7 1000 yes 003004 vs 052100 find1 2000 0484 775 0667 0000 yes 013024 find2 3500 0234 43 0256 0366 matinv1 4000 0020 76 1000 yes 001003 vs 094100 matinv2 5000 0001 4406 0001 0500 strmtch1 2000 0288 238 1000 yes 026031 vs 098100 strmtch2 2000 0456 169 0615 0000 yes 006026 textfmt 2000 0391 12 1000 yes 036042 vs 068100 transpose 3000 0407 13 0462 0336 table 3 null criterion vs alluses subj detm 6400 0032 169 0041 0255 find1 2000 0484 1678 0557 0000 yes 003012 strmtch1 2000 0288 1584 0361 0000 yes 003011 strmtch2 2000 0456 1669 0535 0000 yes 004012 textfmt 2000 0391 1125 0520 0000 yes 008018 transpose 3000 0407 1294 0447 0006 yes 000008 table 4 null criterion vs alledges subj n e 0 sig confidence detm 6304 0033 168 0042 0259 strmtch1 1960 0293 1424 0384 0000 yes 005013 strmtch2 1950 0465 795 0564 0000 yes 005015 textfmt 1772 0429 123 1000 yes 040046 vs 096100 transpose 2913 0411 100 0420 0428 table 5 allbuttwo duas vs allbuttwo edges next compare test sets cover x duas test sets cover edges particular table 5 compares test sets cover two duas cover two edges example since determinant 103 executable duas executable edges table compares 98 dua coverage 97 edge coverage program note although one program strmtch2 result hypothesis testing changed yes going 100 coverage buttwo coverage effectiveness alluses fell dramatically several subjects hand one subject find2 allbuttwo dua coverage actually slightly effective 100 dua coverage additional comparisons x dua coverage edge coverage made examining raw data 38 62 comparison criteria fixed size test sets tables 6 7 8 test sets grouped according sizes four nine subjects alluses adequate test sets effective alledges adequate sets nulladequate sets similar size thus appears four five subjects alluses effective alledges four six alluses effective null criterion improved effectiveness attributed inherent properties alluses fact alluses adequate test sets larger average alledges null adequate test sets contrast alledges adequate sets effective nulladequate sets size subjects indicates cases alledges effective null increased effectiveness primarily due fact alledges demanded larger test sets null criterion subj size n e 1924 1924 579 0021 12 1000 yes strmtch2 15 238 0366 1 1000 transpose 1020 359 0306 1 0000 table alledges vs alluses size detm 16 6100 1924 600 0020 12 1000 yes strmtch2 15 1600 0473 1 1000 transpose 1020 1200 table 7 null vs alluses size detm 16 6100 0034 5 0000 find1 15 1600 0500 211 0299 1000 find2 15 3100 0243 205 0088 1000 1620 2000 0295 1999 0296 0472 712 1500 0022 545 0013 0889 1924 600 0020 579 0021 0451 strmtch1 15 1600 0299 194 0155 1000 strmtch2 15 1600 0473 238 0366 0998 transpose 1020 1200 0298 359 0306 0385 table 8 null vs alledges size subject fs c detm strmtch2 transpose table 9 logistic regression results dua coverage subject fs c table 10 logistic regression results edge coverage 63 relationship coverage effectiveness results logistic regression shown tables 9 10 discussed section 43 regression equation form fs c function predictor variables test set size c fraction duas edges covered test set table gives functions fs c subject program able find goodfitting model asterisks table entries indicate data scattered function gives good fit complex offer much insight relationship exists coverage effectiveness regression equations give us information way effectiveness test set depends upon coverage criterion test set size functions fs c several terms difficult understand much dependence relationship inspection table alone however subjects fs c simple enough one restrict ones attention coefficient term containing highest power c coefficient positive large magnitude effectiveness depends strongly positively coverage case example find1 subject dua edge coverage find1 terms involving c positive types coverage safely conclude effectiveness strongly correlated dua edge coverage subject programs included graphs probexposing versus proportion duas edges covered selected test set sizes reader see relationship clearly figures alluses alledges graphs super imposed distinguish use dashed lines alledges graph dotdashed lines alluses graphs figure 1 one see find1 probability exposing error increases monotonically coverage increases test sets 15 test inputs fact test set size would true picked purposes subjects relationship harder determine careful analysis table 9 however shows find1 matinv1 strmtch1 effectiveness depends strongly positively coverage duas similarly analysis table 10 shows find1 matinv1 strmtch1 strmtch2 effectiveness depends positively coverage edges graphs cases tend look much like graph strmtch1 illustrated figure 2 cases probability exposing error negligible unless sufficiently large percentage duas edges covered duas edges covered probability rises sharply plateau near 10 offer possible explanation next section summary clear dependence effectiveness extent coverage alluses criterion three nine subjects fourth subject transpose probability exposing error increases percentage duas covered increases except drops slightly percentage gets close 100 four subjects dependence exists alledges criterion close examination data led us several interesting observations alluses always effective alledges null criterion cases effective much effective contrast cases alledges effective null criterion usually little bit effective buggyfind alluses performed significantly better alledges find1 universe used apparently alluses required larger test sets however find2 universe used little difference criteria also figure 1 coverage vs probexposing find1 figure 2 coverage vs probexposing strmtch1 figure 3 coverage vs probexposing find2 figure 4 coverage vs probexposing textfmt effectiveness criterion dramatically better find1 find2 shows even relatively minor changes test generation strategy profoundly influence effectiveness adequacy criterion blanket statements random testing without reference particular input distribution used misleading matinv1 alluses appears guaranteed detect error matinv2 different procedure instrumented alluses performs poorly part due fact easy satisfy alluses matinv2 partly due possibility procedure instrumented matinv2 nothing bug matinv1 detm involve instrumenting ludcmp procedure 100 dua coverage appears guarantee detection error cases 98 dua coverage much effective detm matinv1 0556 vs 0026 interesting shows adequacy criterion less effective given procedure depending upon program procedure used four subjects determinant matinv1 textfmt strmtch1 coverage duas appears guarantee detection error knew prior experiment strmtch1 surprised see three programs figure 3 contains graphs find2 figure two graphs alluses alledges test set sizes 10 20 superimposed test set sizes alledges graph shows probability exposing error monotonically increases number covered edges increases alluses graphs upward slope roughly 70 duas covered take downturn phenomenon might result insufficient data 70 coverage combined good fit regression curve data graphs shown figures 2 4 data determinant matinv1 found elsewhere 38 exhibit interesting phenomenon high values coverage probability p error detection 10 coverage decreases point reached p decreases rapidly raw data 38 corroborate ffl matinv1 effectiveness goes 10 100 coverage 003 98 coverage ie test sets covered least 98 executable duas ffl strmtch1 effectiveness 10 100 coverage 10 98 coverage butone dua 035 95 coverage 2 duas ffl textfmt effectiveness dua coverage 100 83 10 effectiveness 80 dua coverage falls 058 strangely enough values c 04 06 10 arises fact test sets coverage exposing curve fitted closely data likely way achieve coverage exactly 0524 particular set paths executed test set executing set paths guarantees exposing error time test sets execute different set paths covers duas guaranteed expose error ffl determinant effectiveness goes 10 100 coverage 0556 98 coverage thus appears cases one duas whose coverage guaranteed error detection remaining duas largely irrelevant phenomenon profound consequences testing practitioners might deal unexecutable dua problem testing arbitrary predetermined percentage duas covered happens test set fails cover crucial duas test set may much less likely detect error covered 100 executable duas example matinv1 total 298 duas 206 69 executable suppose decided test sets cover 200 duas deemed adequate quite possible test without hitting crucial duas chance exposing error much less would coverage 100 executable duas consequently recommend practitioners using data flow testing put effort required weed unexecutable defuse associations accept test sets achieve 100 coverage executable duas heuristic presented frankl 13 issue affects cost using criterion discussed weiss 37 closely examined programs alluses guaranteed expose error gain insight situations alluses seems perform well cases fault could classified missing path error ie situation programmer forgot take special action certain circumstances 3 particularly interesting structured testing criteria usually considered poor exposing missing path errors since test cases execute missing path explicitly demanded however cases turns test cases cover particular dua happen test cases would taken missing path present consequently alluses guaranteed errors detected 3 strmtch1 missing path would return 0 write error message null pattern input textfmt missing path would skip certain statements bufpos 0 determinant matinv1 missing path would return error message input singular matrix manipulation program explicit check singularity presumably omitted efficiency reasons 8 related work previous work comparing testing techniques falls two categories theoretical comparisons adequacy criteria empirical studies test generation techniques many theoretical comparisons adequacy criteria addressed error detecting ability section summarize simulations experiments analytical studies addressed fault detecting ability various testing techniques several papers investigated fault detecting ability generalization path testing called partition testing duran ntafos 10 performed simulations comparing random testing partition testing using hypothetical input domains partitions distributions errors compared probabilities technique would detect error conclusion although random testing always compare favorably path testing well enough cost effective alternative considering results counterintuitive hamlet taylor 22 extensive simulations arrived precise statements relationship partition probabilities failure rates effectiveness corroborated duranntafos results jeng weyuker 39 attacked problem analytically showed effectiveness partition testing depends greatly failure causing inputs distributed among subdomains partition frankl weyuker 17 16 investigated conditions one criterion guaranteed likely detect fault another found fact c1 subsumes c2 guarantee c1 better detecting faults c2 stronger conditions bearing faultdetecting ability also described noted studies used different model test set selection used program subdomains considered test sets size mk arising idealized test generation scheme namely independent random selection k elements sub domain using uniform distribution subdomain contrast various values n generated test sets independent random selection n elements universe considered sets adequate several empirical studies counted number errors detected particular technique programs either natural seeded errors duran ntafos 10 executed roughly 50 randomly generated test cases several programs calculated percentages exposed errors girgis woodward 18 seeded five textbook fortran programs errors subjected various test meth ods hamlet pointed 21 experiments nature may give misleading results typically rely small number test sets represent testing tech nique furthermore studies 18 employ liberal notion test case detects error experiment basili selby 2 comparing statement testing partitioning boundary value analysis codereading stepwise abstraction differed somewhat others category used human subjects generate tests evaluated extent expertise influenced results use human subjects type experiment laudable goal long testing human control human factors influence results problem approach one cannot necessarily extrapolate population one trying model since human sample may representative population third category studies involved measuring extent test sets generated using particular technique satisfied various adequacy criteria extent test sets satisfy one adequacy criterion also satisfy another example duran ntafos 10 measured extent randomly generated test sets roughly 20 120 test cases satisfied lcsaj alledges required pairs ter n criteria several studies nature performed mutation testing example demillo lipton sayward measured extent randomly generated test sets satisfied mutation testing buggyfind program 9 offutt measured extent test sets kill firstorder mutants also kill secondorder mutants 32 note type study address question errordetecting ability cited studies contributed way toward better understanding software testing several noteworthy differences experiment described paper experiment ffl compared error detecting ability adequacy criteria opposed error detecting ability test generation techniques opposed characteristics adequacy criteria ffl designed allow application rigorous statistical techniques ffl investigated real adequacy criteria opposed hypothetical partitions input domain real programs naturally occurring bugs none mentioned papers three attributes finally note also many experimental studies use rigorous statistical techniques investigate software quality issues 27 35 36 however since none aimed evaluating effectiveness adequacy cri teria directly relevant 9 conclusions described experiment comparing effectiveness randomly generated test sets adequate according alledges alluses null test data adequacy criteria unlike previous experiments experiment designed allow statistically meaningful comparison errordetecting ability adequacy criteria involved generating large numbers test sets subject program determining test sets adequate according criterion determining proportion adequate test sets exposed least one error data analyzed rigorously using well established statistical techniques first group questions posed whether c1 effective c2 subject pair criteria five nine subjects alluses significantly effective alledges six subjects alluses significantly effective null criterion five subjects alledges effective null closer examination data showed several cases alluses well actually well appearing guarantee error detection also compared test sets partially satisfied alluses partially satisfied alledges six subjects test sets covered two definitionuse associations effective test sets covered two edges thus test sets cover almost duas sometimes always likely expose error cover almost edges second group questions limited attention test sets similar size alluses adequate test sets appeared effective alledges adequate sets similar size four nine subjects four subjects alluses adequate test sets appeared effective null adequate sets similar size contrast alledges adequate sets effective null adequate sets similar size subjects indicates cases alledges effective null criterion increased effectiveness due primarily fact alledges test sets typically larger nulladequate test sets cases alluses effective alledges null criterion increased effectiveness appears due factors way criterion concentrates failurecausinginputs subdomains third group questions investigated whether probability test set exposes error depends size test set proportion definitionuses associations edges covered important question uncommon testers testing researchers assume implicitly confidence correctness program proportional extent adequacy criterion satisfied logistic regression showed four nine subject programs error exposing ability test sets tended increase test sets covered definitionuse associations also showed different set four subject programs weaker still positive correlation errorexposing ability test sets percentage edges covered sets however even subjects probability test set exposes error depended proportion definitionuse associations edges covered dependence usually highly nonlinear indicates ones confidence correctness program general proportional percentage edges duas covered summary results show alluses extremely effective appearing guarantee error detection several subjects always perform significantly better alledges null criterion subjects hand alledges effective subjects fact none subjects alledges almostalledges adequate test sets perform significantly better randomly selected nulladequate test sets size make claim collection subject programs representative software therefore believe sensible extrapolate results software general primary contribution research methodology used experiment believe results sound interesting motivate research addition even relatively small scale experiment allowed us observe existence several interesting phenomena noted section 7 foremost direction future research perform similar experiments much larger collection subjects including large programs design could also used compare adequacy criteria experiments comparing effectiveness various adequacy criteria nonrandom test generation strategies used would also useful hope researchers join us performing experiments future acknowledgments authors would like thank prof al baranchik hunter college mathematics department advice statistical methods mohammed ghriga roongko doong helping prepare subject programs zhang ming helping data analysis tarak goradia useful comments earlier version paper hunter college geology geography department use statistical analysis software anonymous referee made several useful suggestions presentation material r analysis ordinal categorical data comparing effectiveness software testing strate gies statistical concepts methods elements statistics formal evaluation data flow path selection criteria extended overview mothra software testing environment hints test data selection help practicing programmer evaluation random testing asset users manual use data flow information selection evaluation software test partial symbolic evaluation path expressions version 2 applicable family data flow testing criteria assessing faultdetecting ability testing methods formal analysis fault detecting ability testing methods experimental comparison error exposing ability program testing criteria toward theory test data selection remark algorithm 408 theoretical comparison testing methods partition testing inspire confidence data flow analysis approach program testing proof program find survey dynamic analysis methods approach program testing experimental evaluation assumption independence multiversion programming data flow oriented program testing strategy algorithm 408 sparse matrix package part required element testing investigations software testing coupling effect numerical recipes art scientific computing selecting software test data using data flow information experimental comparison three system test strate gies preliminary report experimental evaluation effectiveness random testing faulttolerant software methods comparing test data adequacy criteria comparison alluses alledges design analyzing partition testing strategies comparison program testing strate gies tr selecting software test data using data flow information numerical recipes art scientific computing experimental evaluation assumption independence multiversion programming comparing effectiveness software testing strategies applicable family data flow testing criteria theoretical comparison testing methods experimental comparison three system test strategies preliminary report formal evaluation data flow path selection criteria partition testing inspire confidence program testing analyzing partition testing strategies comparison program testing strategies assessing faultdetecting ability testing methods investigations software testing coupling effect remark algorithm 408 approach program testing proof program algorithm 408 sparse matrix package part f4 oh pascal formal analysis faultdetecting ability testing methods selectmyampersandmdasha formal system testing debugging programs symbolic execution use data flow information selection evaluation software test data ctr p g frankl n weiss correction experimental comparison effectiveness branch testing data flow testing ieee transactions software engineering v19 n12 p1180 december 1993 phyllis g frankl oleg iakounenko empirical studies test effectiveness acm sigsoft software engineering notes v23 n6 p153162 nov 1998 tohru matsuodani kazuhiko tsuda evaluation debugtesting efficiency duplication detected fault delay time repair information sciencesinformatics computer science international journal v166 n14 p83103 29 october 2004 dick hamlet learn testing program acm sigsoft software engineering notes v23 n2 p5052 march 1998 kalpesh kapoor jonathan p bowen test conditions fault classes boolean specifications acm transactions software engineering methodology tosem v16 n3 p10es july 2007 jennifer black emanuel melachrinoudis david kaeli bicriteria models alluses test suite reduction proceedings 26th international conference software engineering p106115 may 2328 2004 mary jean harrold gregg rothermel performing data flow testing classes acm sigsoft software engineering notes v19 n5 p154163 dec 1994 n juristo moreno vegas towards building solid empirical body knowledge testing techniques acm sigsoft software engineering notes v29 n5 september 2004 w eric wong joseph r horgan saul london aditya p mathur effect test set minimization fault detection effectiveness proceedings 17th international conference software engineering p4150 april 2428 1995 seattle washington united states dick hamlet subdomains testing profiles components acm sigsoft software engineering notes v25 n5 p7176 sept 2000 l c briand labiche wang using simulation empirically investigate test coverage criteria based statechart proceedings 26th international conference software engineering p8695 may 2328 2004 martina marr antonia bertolino unconstrained duals use achieving alluses coverage acm sigsoft software engineering notes v21 n3 p147157 may 1996 w eric wong yu qi kendra cooper source codebased software risk assessing proceedings 2005 acm symposium applied computing march 1317 2005 santa fe new mexico hong zhu formal analysis subsume relation software test adequacy criteria ieee transactions software engineering v22 n4 p248255 april 1996 sira vegas victor basili characterisation schema software testing techniques empirical software engineering v10 n4 p437466 october 2005 phyllis g frankl yuetang deng comparison delivered reliability branch data flow operational testing case study acm sigsoft software engineering notes v25 n5 p124134 sept 2000 bev littlewood peter popov lorenzo strigini nick shryane modeling effects combining diverse software fault detection techniques ieee transactions software engineering v26 n12 p11571167 december 2000 elaine j weyuker using operational distributions judge testing progress proceedings acm symposium applied computing march 0912 2003 melbourne florida gregg rothermel lixin li christopher dupuis margaret burnett see test methodology testing formbased visual programs proceedings 20th international conference software engineering p198207 april 1925 1998 kyoto japan chi keen low chen ralph rnnquist automated test case generation bdi agents autonomous agents multiagent systems v2 n4 p311332 november 1999 karen j rothermel curtis r cook margaret burnett justin schonfeld r g green gregg rothermel wysiwyt testing spreadsheet paradigm empirical evaluation proceedings 22nd international conference software engineering p230239 june 0411 2000 limerick ireland pretschner w prenninger wagner c khnel baumgartner b sostawa r zlch stauner one evaluation modelbased testing automation proceedings 27th international conference software engineering may 1521 2005 st louis mo usa lutz prechelt walter f tichy controlled experiment assess benefits procedure argument type checking ieee transactions software engineering v24 n4 p302312 april 1998 phyllis g frankl richard g hamlet bev littlewood lorenzo strigini evaluating testing methods delivered reliability ieee transactions software engineering v24 n8 p586601 august 1998 phyllis frankl dick hamlet bev littlewood lorenzo strigini choosing testing method deliver reliability proceedings 19th international conference software engineering p6878 may 1723 1997 boston massachusetts united states prem devanbu stuart g stubblebine cryptographic verification test coverage claims acm sigsoft software engineering notes v22 n6 p395413 nov 1997 n juristo moreno vegas limitations empirical testing technique knowledge lecture notes empirical software engineering world scientific publishing co inc river edge nj richard demillo aditya p mathur w eric wong critical remarks hierarchy faultdetecting abilities test methods ieee transactions software engineering v21 n10 p858861 october 1995 heng lu w k chan h tse testing contextaware middlewarecentric programs data flow approach rfidbased experimentation proceedings 14th acm sigsoft international symposium foundations software engineering november 0511 2006 portland oregon usa matthew j rutherford antonio carzaniga alexander l wolf simulationbased test adequacy criteria distributed systems proceedings 14th acm sigsoft international symposium foundations software engineering november 0511 2006 portland oregon usa natalia juristo ana moreno sira vegas reviewing 25 years testing technique experiments empirical software engineering v9 n12 p744 march 2004 alessandro orso saurabh sinha mary jean harrold classifying data dependences presence pointers program comprehension testing debugging acm transactions software engineering methodology tosem v13 n2 p199239 april 2004 james h andrews susmita haldar yong lei felix chun hang li tool support randomized unit testing proceedings 1st international workshop random testing july 2020 2006 portland maine mary jean harrold analysis testing programs exception handling constructs ieee transactions software engineering v26 n9 p849871 september 2000 premkumar thomas devanbu stuart g stubblebine cryptographic verification test coverage claims ieee transactions software engineering v26 n2 p178192 february 2000 gregg rothermel margaret burnett lixin li christopher dupuis andrei sheretov methodology testing spreadsheets acm transactions software engineering methodology tosem v10 n1 p110147 jan 2001 hyunsook sebastian elbaum gregg rothermel supporting controlled experimentation testing techniques infrastructure potential impact empirical software engineering v10 n4 p405435 october 2005 lionel c briand massimiliano di penta yvan labiche assessing improving statebased class testing series experiments ieee transactions software engineering v30 n11 p770793 november 2004 peifeng hu zhenyu zhang w k chan h tse empirical comparison direct indirect test result checking approaches proceedings 3rd international workshop software quality assurance november 0606 2006 portland oregon ramkrishna chatterjee barbara g ryder william landi complexity pointsto analysis java presence exceptions ieee transactions software engineering v27 n6 p481512 june 2001 gregor v bochmann alexandre petrenko protocol testing review methods relevance software testing proceedings 1994 acm sigsoft international symposium software testing analysis p109124 august 1719 1994 seattle washington united states barbara g ryder william landi philip stocks sean zhang rita altucher schema interprocedural modification sideeffect analysis pointer aliasing acm transactions programming languages systems toplas v23 n2 p105186 march 2001 hong zhu patrick v hall john h r may software unit test coverage adequacy acm computing surveys csur v29 n4 p366427 dec 1997