parametric design synthesis distributed embedded systems abstractthis paper presents design synthesis method distributed embedded systems systems computations flow long pipelines interacting software components hosted variety resources managed local scheduler method automatically calibrates local resource schedulers achieve systems global endtoend performance requirements system modeled set distributed task chains pipelines task represents activity requiring nonzero load cpu network resource task load requirements vary stochastically due secondorder effects like cache memory behavior dma interference pipeline stalls bus arbitration delays transient headofline blocking etc aggregate effectsalong tasks perservice load demandand model via single random variable ranging arbitrary discrete probability distribution load models obtained via profiling tasks isolation simply using engineers hypothesis systems projected behavior endtoend performance requirements posited terms throughput delay constraints specifically pipelines delay constraint upper bound total latency computatation accumulate input output corresponding throughput constraint mandates pipelines minimum acceptable output ratecounting outputs meet delay constraints since percomponent loads generally distributed since resources host stages multiple pipelines meeting systems endtoend constraints nontrivial problem approach involves solving two subproblems tandem 1 finding optimal proportion load allocate task channel 2 deriving best combination service intervals load proportions guaranteed design algorithms use analytic approximations quickly estimate output rates propagation delays candidate solutions parameters synthesized estimated endtoend performance metrics rechecked simulation percomponent load reservations increased synthesis algorithms rerun improve performance point system configured according synthesized scheduling parametersand revalidated via online profiling paper demonstrate technique example system compare estimated performance simulated online behavior b introduction embedded systems intrinsic realtime constraints imposed external inputs puts perspective environment time computation paths endpoints may flow large set interacting components hosted variety resources managed local scheduling queuing policies crucial step design process involves calibrating tuning local resource management policies original realtime objectives achieved realtime scheduling analysis often used help make problem tractable using approach upper bounds derived processing times communication delays using worstcase assumptions tasks messages deterministically scheduled guarantee timing constraints get met constraints might include individual threads processing frequency packets deadline perhaps rate network driver run type system hard realtime analysis used help predict ensure performance objectives attained approach becoming increasingly difficult carry first achieving neartight executiontime bounds virtually impossible due architectural features like superscalar pipelin ing hierarchies cache memory etc mention nondeterminism inherent almost network given well fact programs actual execution time datadependent worstcase timing estimate may several orders magnitude greater average case one incorporates worstcase costs design result often lead extremely underutilized system moreover parameters like processing periods deadlines used help achieve acceptable endtoend performance ie means end end reality missing deadline rarely lead failure fact occurrence expected unless system radically overengineered hard realtime scheduling theory provides sufficient way build embedded system strictly necessary may yield efficient design paper explore alternative approach using statistical guarantees generate costeffective system designs model realtime system set task chains task representing activity requiring specific cpu network link example chain may correspond data path camera display video conferencing system reflect servoloop distributed realtime control system chains realtime performance requirements specified terms maximum acceptable propagation delay input output ii minimum acceptable average throughput designing system treat first requirement hard constraint endtoend computation takes longer maximum delay treated failure contribute overall throughput applications may able use late outputs yet within system model currently count contrast second requirement viewed statistical sense design system exceed average minimal acceptable rate assume tasks cost ie execution time program delay network link specified arbitrary discrete probability distribution function problem solution strategy given set task chains realtime performance requirements objective design system meet requirements chains system model includes following assumptions help make solution tractable ffl model tasks load requirements stochastically terms discrete probability distribution function pdf whose random variable characterizes resource time needed one execution instance task successive task instances modeled independent ffl assume static partitioning system resources words task already allocated specific resource true embedded systems design often involves making taskplacement decisions however note tuning resource schedulers definition subservient allocation phase often involves accounting devicespecific localities eg io ports dma channels etc well systemlevel issues eg services provided node papers focus narrowed scheduling synthesis problem hand note holistic design tool could integrate two problems use systemtuning algorithms subroutines also objective achieve overall statistical level realtime performance still use tools provided hard realtime scheduling help solve problem method involves following steps 1 assigning task fixed proportion resources load 2 determining reasonable service interval frame proportion guaranteed using techniques provided realtime cpu network scheduling guarantee frame task get least designated share resources time share fails sufficient currently running task finish executing runs next frame gets frames share etc given model design problem may viewed following interrelated subproblems 1 cpu network load partitioned among tasks every chains performance requirements met 2 given loadassignment framesizes set maximize effective output rate discuss sequel load proportions cannot quantized infinitesimal timeframes hence tasks frame gets progressively smaller starts paying large price guarantees form wasted overhead paper present algorithms solve problems algorithm problem 1 uses heuristic compare relative needs tasks different chains competing resources algorithm problem 2 makes use connecting markov chains estimate effective throughput given chain since analysis approximate validate generated solution using simulation model related work like much work realtime systems results extend preemptive uniprocessor scheduling analysis many old new solutions problem eg 1 15 20 21 moreover many methods come equipped offline analysis tests determine priori whether underlying system schedulable tests loadoriented sufficiency conditions predict tasks always meet deadlines provided system utilization exceed certain predefined threshold classical model generalized large degree exist analogous results distributed systems network protocols etc example model applied distributed hard realtime systems following straightforward manner eg see 26 31 network connection abstracted realtime task sharing network resource scheduling analysis incorporates worstcase blocking times potentially suffered highpriority packets wait transmission lowerpriority packets extent resulting global scheduling problem solved set interrelated local resourcescheduling problems 30 classical model extended consider probabilistic execution times uniprocessor systems done giving nominal hard amount execution time task instance assumption task usually complete within time nominal time exceeded excess requirement treated like sporadic arrival via method similar used 19 previous work 8 9 relaxed precondition period deadline parameters always known ahead time rather used systems endtoend delay jitter requirements automatically derive tasks constraints turn ensure endtoend requirements met uniprocessor system similar approach uniprocessor systems explored 2 execution time budgets automatically derived endtoend delay requirements method used imprecise computation technique metric help gauge goodness candidate solutions concepts later modified use various application contexts recent results adapted endtoend theory discrete continuous control problems eg 18 27 realtime constraints derived set control laws objectives optimize systems performance index satisfying schedulability original approach 8 9 also used produce schedules realtime traffic fieldbus networks 6 7 switch priorities synthesized ensure endtoend rate latency guarantees related idea pursued radar processing domains 11 optimization method produces percomponent processing rates deadlines based systems input pulse rate prescribed allowed latency endtoend design becomes significantly difficult distributed contexts solving problem usually involves finding answer following question given endtoend latency budget optimal way spend budget pipeline hop aside complexity basic decision problem solution also involves practical issue getting local runtime schedulers guarantee piecewise latencies results presented 25 address problem deterministic context extend original uniprocessor method 8 distributed systems statically partitioning endtoend delays via heuristic optimization metrics 25 similar approaches proposed soft transactions distributed systems 17 transactions deadline partitioned systems resources knowledge paper presents first technique achieves statistical realtime performance distributed system using endtoend requirements assign periods execution time budgets light method viewed less scheduling tool one approach problem realtime systems design accomplish goal assume underlying runtime system capable follow ing 1 decreasing tasks completion time increasing resource share 2 enforcing resource proportional shares allocated every task minimum quantization 3 within constraints isolating tasks realtime behavior activities sharing resource regard build many results developed providing oslevel reservation guarantees ratebased proportionalshare queuing networks since concepts integral understanding work paper treat length ratebased methods tasks get allocated percentages available bandwidth obviously percentages cannot maintained infinitesimal timeintervals rather proportionalshares serviced approximate sense ie within margin error magnitude error usually due following factors 1 quantization ie degree underlying system multiplex traffic 2 priorityselection ie order tasks selected service higher levels quantization multiple streams share fifo queues serviceorders depart true proportionalsharing analytical results rely perhaps oldest known variant ratebased scheduling timedivision multiplexing tdm tdm abstraction task guaranteed fixed number timeslots predefined periodic intervals call frames analytical techniques assume tasks timeslots reserved ie task claim load load gets wasted appeal tdm basic reason need handle inherently stochastic workload model tasks internally decide much load need specific instances load demands quite high arbitrary instances may minuscule instances moreover task started assume semantics mandate also needs finished since unregulated workloads cannot simply reshaped since endtoend latency guarantees still must guaranteed tdm ensures reasonable level fairness different tasks resource successive instances task downside scheme tdm ends wasting unused load ratebased disciplines solve problem redistributing service longer intervals cost occasionally postponing projected completion times certain tasks disciplines however conceived inherently regulated workload models eg linear bounded arrival processes 3 settings transient unfairnessis often smoothed simply reshaping departure process ie inserting delay stages many algorithms developed provide proportionalshare service highspeed net works including virtual clock method 38 fairshare queuing 4 generalized processor sharing gps 23 rate controlled static priority queuing rcsp 36 models also used derive statistical delay guarantees particular within framework rcsp 37 gps 39 related results found 5 using policy like virtual clock 38 34 fcfs variety traffic distributions 14 statistical service quality objectives achieved via proportionalshare queuing conjunction serverguided backoff servers dynamically adjust rates help utilize available bandwidth recently many ratebased disciplines sprouted analogues cpu scheduling example waldspurger et al 32 proposed lottery scheduling multiplexes available cpu load based relative throughput rates systems constituent tasks authors also presented deterministic variant called stride scheduling 33 method provides oslevel server method similar weightedfairqueuing wfq discipline used switches wfq also known packetized gps pgps discrete quantized version fluidflow abstraction used gps scheduling decisions wfq made via simulating proportionalsharing tasks readyqueue idealized model continuoustime multiplexing task would hypothetically finish first gps gets highest priority put run queue next scheduling round stoica et al 29 proposed related technique similarly uses virtual timeline determine runtime dispatching order concept also applied hierarchical scheduling 13 multiple classes tasks eg hard soft realtime applications coexist system several schemes proposed guarantee processor capacity shares systems realtime tasks simultaneously isolate overruns caused tasks system example mercer et al 22 proposed processor capacity reservation mechanism achieve method enforces tasks reserved share within reservation period microkernel control also shin et al 28 proposed reservationbased algorithm guarantee performance periodic realtime tasks also improve schedulability aperiodic tasks noted many proportionalshare methods subjected responsetime studies different types arrival processes done switches cpus entire networks note problem determining aggregate delay network dual problem assigning perhop delays achieve endtoend deadline latter top approach designer tells network perhop latencies network needs guarantee latencies delay analysis works bottomup fashion network basically tells user endtoend delay given proportionalshare allocations chain observation seemingly different problems inextricably related topdown deadline partitioning could function without way getting bottomup feedback similarly bottomup method assumes preallocated load chain reality negotiated meet chains endtoend latency throughput requirements realtime domains solving one problem requires solving deriving endtoend latency involves answering following question chain flows n nodes managed ratebased discipline endtoend response time issue quite simple arrival process poisson streams service times exponentially distributed nodes use fifo service discipline simple jackson queuing network like many straightforward productform techniques applied question gets trickier linearly regulated traffic stream different arrival rate deviations bounded different intervalsizes stream different proportional service guarantees fortunately compositional results exist presented various ratebased disciplines deterministic 12 24 35 statistical 39 37 workloads deterministic endtoend per connection delays considered 24 leakybucket regulated traffic using pgps scheduling technique 35 similar study performed using nonworkconserving service discipline also noted statistical treatments provided pgps 39 rcsp 37 section 4 present analytical approximation tdm abstraction perhaps extreme case nonworkconserving discipline method used estimates endtoend delays products tdm queues chains load demand node generally distributed tasks chain different pdfs queue sizes constrained single slot problem innately complex moreover design algorithm needs test huge numbers solution candidates achieving system objectives hence delay analysis fast consequently coarse time cannot coarse must sufficiently accurate expose key performance trends entire solution space shown section 4 approach problem compositional topdown fashion algorithm starts analyzing chains head task isolation resulting statistics used help analyze second task etc line delay throughput metrics obtained chains output task hence chain whole 3 model solution overview stated model system set independent pipelined task chains every task mapped designated cpu network resource chain abstraction example capture essential data path structure video conferencing system distributed process control loop formally system possesses following structure constraints boundedcapacity resources set resources r r corresponds one systems cpus network links associated r maximum allowable capacity ae maximum load resource multiplex effectively typically function scheduling policy case workstation r 7 r 9 r 4 figure 1 example system topology switching arbitration policies case lan task chains system n task chains denoted th task chain computation gamma carries endtoend transformation external input x output also producerconsumer relationship exists connected pair tasks ij gamma1 ij assume oneslot buffer pair since queuing policy chooses newest data buffer hence producer may overwrite buffered data consumed stochastic processing costs tasks cost modeled via discrete probability distribution function whose random variable characterizes time needs one execution instance resource maximum delay bounds gamma delay constraint md upper bound time take computation flow system still produce useful result example means gamma produces output time used corresponding input sampled earlier gamma 500ms computed results exceed propagation delay dropped minimum output rates gamma rate constraint mor specifies minimum acceptable average rate outputs meet delay constraints example mor means chain gamma must average produce 10 outputs per second moreover mor implicitly specifies maximum possible framesize tasks framesize 01 would suffice output produced every frame example consider example shown figure 1 possesses six chains labeled rectangles denote shared resources black circles denote tasks shaded boxes resource usage pdfs tasks derived et ms vart minmax numsteps endtoend constraints maximum resource utilizations figure 2 constraints example external inputs outputs systems resource requirements endtoend constraints shown figure 2 system tasks load demand varies stochastically due secondorder effects like cache memory behavior dma interference pipeline stalls bus arbitration delays transient headofline blocking etc using one random variable model tasks load essentially collapse residual effects single pdf also accounts tasks idealized bestcase executiontime model discrete probability distribution used purpose two points articulated first fairly obvious pertask load models illfounded synthesis results little use indeed situations one cannot convolve abovementioned effects single pdf may tempting stochastically bundle driver processing interference tasks load model often one situations sort factor needs represented explicitly task method easily accommodate alternative process obtaining good model abstraction nontrivial requires accounting matters like causality ie charging load deviations tasks cause scale ie comparing tasks loading statistics mean variance residual effects charged sensitivity ie statistically gauging effect load quantization endprocess results problems well outside scope paper interested readers consult 16 decent introduction statistical performance modeling however none problems trivial given sufficient time patience statistical competence one employ standard techniques handling second point bit subtle though equally true purposes design coarse load model represented single stationary distribution better load model sort systems design one needs start basic notion pertask performance alternative designing system based blind guesswork consider task representing innerproduct function vectorsizes range 1000020000 elements actual vectorsizes change dynamically assume profile task representative dataset resulting load demands appear track inner two quartiles normal distribution quantize resulting histogram use model tasks pdf assume cannot explicitly model vectorsize controlled variable perhaps value truly nondeterministic perhaps choose treat way since addition contributes little marginal accuracy pipelines estimated departure process statistics cases quasinormal distribution may fact best model achieve innerproduct may sufficient purposes design lead reasonable results real system objective use models tool abstractly predict trends synthesis algorithms objective directly represent system obtain load model one often appeal method outlined method commonly used hardwaresoftware codesign task profiled isolation resulting histogram gets postprocessed stationary responsetime distribution experienced good results via method multiplatform simulation work digital video playout systems 10 second technique used preliminary stage designer coarsely estimate tasks average load use create synthetic distribution eg exponential normal chi square etc load models would correspond hypotheses task might behave integrated system done tasks pdfs quantized acceptable level results fed synthesis tool system topology handle number hypothetical pertask load profiles designer gain margin confidence systems robustness subtle changes loading conditions take latter approach running example discretize two different continuous distributions reuse results multiple tasks figure 2 derived denotes base continuous distribution generated quantized using parameters min max et mean variance numsteps number intervals case exponential distribu tion cdf curve shifted min probabilities given values past max distributed interval proportionally granularity discretization controlled num steps assume execution time associated interval maximum possible value within interval example time requirement 11 follows normal distribution 10ms mean 8ms standard deviation minimum time 4ms maximum time 35 ms continuous distribution chopped 10 intervals since first interval contains times within 4ms 7ms associate time 7ms interval give corresponding portion continuous cdf note attempt hard realtime approach solution would possible example 31 requires 200ms dedicated resource time run means 31 frame must less 200ms yet mor must produce new output least 5 times flow graph endtoend constraints system resource distributions final load assignment assignment throughput approximation quantum increase mor unsatisfied chains candidate system simulate constraint satisfaction failure figure 3 design overview per second turn means 31 frame also greater 200ms frame exactly 200ms task induces utilization 10 resource r 1 exceeding resources intrinsic 09 limit disallowing capacity tasks hosted 31 runtime model within system model tasks chain gamma considered scheduled quasicyclic fashion using timedivision multiplexing abstraction resourcesharing f sized frames gamma loadshares guaranteed f intervals constituent resources hence synthesis algorithms job 1 assign task ij proportion resources capacity denote u ij 2 assign global f frame gamma given ij runtime behavior described follows 1 within every f frame ij use u ij resources capacity policed assigning ij executiontime budget upper bound amount resource time provided within f frame truncated discrete units assume system cannot keep track arbitrarily fine granularities time 2 particular execution instance ij may require multiple frames complete e ij running time expended frame 3 new instance ij started within frame previous instance ij still running ij input buffer contains new data already exceeded md policed timestamp mechanism put computation input sampled due chains pipeline structure note n tasks gamma must since data flow n elements produce computation 32 solution overview schematic design process illustrated figure 3 main steps follows 1 partitioning cpu network capacity tasks 2 selecting chains frame optimize output rate 3 checking solution via simulation verify integrity approximations used ensure chains output profile sufficiently smooth ie bursty partitioning algorithm processes chain gamma finds candidate loadassignment vector denoted u element u ij u contains load allocated ij resource given load assignment gamma synthesis algorithm attempts find frame f gamma achieves optimal output rate computation done approximately given f rate estimate derived 1 treating gamma outputs uniformly deriving iid perframe success simply multiplying theta 1 approximate chains output rate lower mor requirement load assignment vector increased finally sufficient load found chains resulting system simulated ensure approximations sound excess capacity given chain hope improving overall rate 4 throughput analysis section describe approximate gamma output rate candidate load frame parameters chain section 5 show make use technique derive systems f u parameters every chain assume currently processing gamma framesize f load vector u estimate output probability recall outputs exceeding maximum allowed delay md counted hence need way determining latency system one benefit proportionalshare queuing follows since chain effectively isolated others f intervals observation analyze behavior gamma independently without worrying headofline blocking effects components use discretetime model time units terms chains framesize ie discrete domain f0 corresponds real times f0 f reduction make analysis tractable also corresponds worstcase conditions since underlying system may schedule task execution time within f frame assume input may read early beginning frame output may produced late end frame one exception chains states interest occur frame boundaries exception modeling aggregate delay discrete time domain treat b md c hence fractional part last frame ignored leading tighter notion success consequently erring side conservatism theoretically could model computations delay constructing stochastic process chain whole solving possible delay probabilities would probably futile venture even smaller chains model would simultaneously keep track tasks local behavior since chain may hold 0 ongoing computations many one computation per task easy see statespace would quickly explode instead go constructing model compositional albeit inexact manner processing task locally using results successors consider following diagram portrays flow computation single task age deltaout age ij random variables defined follows 1 dataage age ij variable charts computations total accumulated time entering head leaving ij 2 blocking time b ij duration time input buffered waiting ij complete current computation 3 processing time psi ij random variable ranging ij pdf psi ij e corresponding variable units frames 4 interoutput time deltaout ij approximation ij interoutput distribution terms frames measures time two successive outputs assume data always ready chains head hence age ij approximated via following recurrence relation age i1 age j 1 approximate entire age ij distribution assuming three variables independent ie prage prage note ij success probability ij 1 probability non stale output produced random frame processing final task chain approximate endtoend success probability output probability appropriately scaled probability excessive delay injected execution point endtoend success rate estimated note method topdown ie statistics derived i1 i2 using synthesized metrics i1 i3 etc also note processing i1 already figure 4 chain x ij maxpsi ij information require pdf words trivially prdeltaout retrieve fresh input whenever ready therefore incurs blocking time i1 execute new phase whenever finishes previous phase blockingtime obtaining reasonable blockingtime metrics stage nontrivial affair especially longertailed distributions involved carrying analysis consider stochastic process x ij whose states transitions characterize two factors 1 ij remaining execution time next task instance 2 whether input processed dropped transitions described using simple markov chain shown figure 4 maximum execution time 6f transitions eventbased ie triggered new inputs ij gamma1 hand states measure remaining time left current execution essence moving state k l denotes 1 new input received 2 induce blocking time l frames sake analysis distinguish three different outcomes moving state k state l transition descriptions use term denote endtoend delay bound terms frames ie c 1 dropping k l task currently executing already another input queued buffer calculated induce blockingtime k new input overwrite induce l blockingtime frames 2 failure k 0 new input arrives stale get processed finishtime current execution 3 success k l new input arrives get processed blocking time l figure 5 illustrates case successful transition l deltaout figure 5 transition k l case destination state 0 case b destination state l 0 tl distinguish outcomes 13 via partitioning statetransition matrix ie p denote transition matrices dropping failure success respectively calculated terms parameters discussed ie age getting complete transition matrix probabilities usual fashion ie x p turn steadystate probabilities used derive ij perframe success probability k index denotes kth element resulting vector essense calculation computes probability 1 input read random frame 2 successfully processing obtained summing successful outflow probabilities simple bayesean method used achieve stationary blockingtime pdf l0 final ingredient derive task ij interoutput distribution deltaout ij use coarse meanvalue analysis ij produces output know goes idle phase waiting fresh input producer followed busy phase culminating another output let idle ij random variable counts number idle cycles busy phase using information model event denoting computestart pure bernoulli decision probability st ij st eidle ij 1 ie output delivered st ij probability random cycle starts next busy phase approximate idle durations via modified geometric distribution pridle derive distribution prdeltaout ij pridle finally approximate endtoend success probability output proba bility appropriately scaled account excessive delay injected execution definition endtoend output rate given follows example example perform throughput estimation gamma 6 assuming system parameters f 30ms recall delay bound chain 5 within headtotail approach first consider task 61 recall however distributions age 61 deltaout 61 identical psi 61 quantized load distribution moreover also next consider second last task 62 following tables show pdfs psi 62 markov chains steady states blocking times age 62 6 00005 0000001 00 01153 7 000008 00 00 00269 9 00 00 00 13 theta 10 gamma3 summing successful outflow probabilities hence chains iid success probability defined follows prage 62 6 multiplying framerate get 5 system design process revisit highlevel problem determining systems parameters objective satisfying chains performance requirements stated introduction design problem may viewed two interrelated subproblems 1 load assignment given set chains cpu network load partitioned among set tasks performance requirements met 2 frame assignment given loadassignment tasks chain optimal frame chain effective throughput maximized note loadallocation main interchain problem frameassignment viewed strictly intrachain issue timedivision abstraction altering chains framesize effect average rates chains system consider synthesis algorithm figure 6 note f expressed milliseconds initialized largest framesizes could achieve desired output rates deltaf returns ng e 1 n 2 ij ng 6 f find ij maximizes return failure get f f f figure synthesis algorithm denotes global timescale example chosen 1000 since units millisec onds also note task ij resource share u ij initialized accommodate corresponding mean responsetime time et ij system could solved initial parameters execution times constant load assignment loadassignment works iteratively refining load vectors u feasible solution found entire algorithm terminates output rates chains meet performance requirements discovers solution possible employ backtracking tasks load never reduced means solution space searched totally tightlyconstrained systems potential feasible solutions may found loadassignment taskbased ie driven assigning additional load task estimated need heart algorithm found lines 67 remaining unsolved chains considered objective assigning additional load deserving task one chains selection made using heuristic weight w ij reflecting potential benefit increasing ij utilization quest increasing chains endtoend performance weight actually combines three factors plays part achieving feasibility 1 additional output rate required normalized via rangescaling interval 01 2 currentmaximum capacities tasks resource current capacity denoted ae k resource r k 3 tasks current load assignment idea high load assignment indicates diminishing returns setting working chains tasks would probably beneficial results paper heuristic used theta ae selected task gets utilization increased tunable increment smaller increments obviously lead greater likelihood finding feasible solutions however also incur higher cost results presented paper set additional load given selected task chains new framesize rate parameters determined meets minimum output requirements removed consideration frame assignment get frame derives feasible frame one exists problem frameassignment seems straightforward enough nonlinearities surmount first true usable load task given bu due fact system cannot multiplex load arbitrarily fine granularities time second analysis assume effective maximum delay rounded nearest frame errs side conservatism negative effect second factor likely higher larger frames since results truncating fractional part computations final frame hand first factor becomes critical smaller frames hence approximation utilizes simple rules since loads monotonically increased restrict search frames lower current one restrict search situations framebased delay estimate truncates ff theta 100 percent continuoustime deadline ff 1 subject guidelines frames evaluated via throughput analysis presented section 4 determines current design process solution example ran algorithm figure 6 find feasible solution result presented figure 7 sparc ultra algorithm synthesized parameters example approximately minutes wallclock time results presented figure 7 note resources capacity spare r 1 highest load configuration 072 r 7 lowest 035 others around 50 loaded spare load used increase chains output rate desired held chains designedin later synthesized solutions chains b resource capacity used system 072 039 045 04 065 052 035 062 065 065 figure 7 synthesized solution example system 6 simulation since throughput analysis uses key simplifying approximations validate resulting solution via simulation model recall analysis injects imprecision following reasons first tightens end output delays rounding fractional part final frame analogously assumes chains statechanges always occur frame boundaries hence even intermediate output times assumed take place frames end approximation inherent compositional dataage calculation ie assume perframe output ratios predecessor tasks iid allowing us solve resulting markov chains quasiindependent fashion simulation model discards approximations keeps track tagged computations chain well true states induce participating tasks also clock progresses along realtime domain hence task ends middle frame gets placed successors input buffer time also simulation model schedules resources using modified deadlinemonotonic dispatcher deadline considered end frame higherpriority tasks get run earlier analytical method assumes recall analysis implicitly assumes computations may take place late possible within given frame hand simulator inherit simplifications used design example inputreading assumed happen task gets released ie start frame analysis context switch overheads considered rather charged load distributions figure 8 summarizes differences two models validation design following table compares analytical throughput estimates derived via simulation simulated rates displayed 95 confidenceintervals simulation analysis maximum delay md bmd f c theta f state change measured frame boundary output rate measured iid scheduling framebased late possible deadline monotonic data reading time start frame start frame figure 8 comparison analysis model simulation model 100 trials trial ran 100000 frames largest frame system last column shows standard deviation outputrates calculated ttime moving averages wrt simulated 10g means 1second intervals tool following 1 gamma output rate charted 1second intervals 2 intervals deviation calculated 3 sumofsquared deviations obtained divided degrees freedom sample 4 squareroot result produced moving averages note resulting simulated system satisfies minimum throughput requirements chains hence satisfactory solution desired improve doling excess resource capacity ie simply iterating design algorithm figure 9 compares simulated analytic results multiple frames assigned three selected chains framesizes changed one chain time system utilization remains fixed synthesized values simulation runs displayed ran 10 000 frames largest frame observation eg graph largest frame tested denoted 200 ms run lasted 2000 seconds graphs show average outputrates chains entire simulation trial along corresponding standard deviation computed onesecond interval samples vs mean combinatorial comparison allows us make following observations first output rates generally increase framesizes decrease point system starts injecting significant amount truncation overhead due multiplexing recall runtime system cannot multiplex infinitesimal granularities execution time rather tasks utilization allocated integral units frame second relationship throughput burstiness direct note chains deviations tend increase higher lower frames reflects two separate facts first fairly obvious artifact measurement process success rate frame size analysis simulation 200135success rate frame size chain 3 success rate analysis simulation 2001357success rate frame size chain 6 success rate analysis simulation standard deviation success rate frame size chain standard deviation standard deviation success rate frame size chain standard deviation deviation success rate frame size chain 6 standard deviation figure 9 analysis vs simulation standard deviations second moving averages calculate variance statistics 1second intervals yields deviations computed basis single reference timescale method inserts bias low frames since processes get sampled frequently turn lead artificially higher deviations large frames another effect comes play recall tasks dispatched frame boundaries input waiting predecessors hence producer overruns frame even slight amount consumer wait next frame use data consequently adds datas age whole however note simulated deviations particularly high especially considering fact include onesecond intervals measured output rates actually exceed mean also output rates decrease framesizes increase curves smooth small spikes observed simulated analytical results effect due multiplexing overhead discussed injected since executiontime budgets integral example tasks assigned utilization 011 framesize 10 executiontime budget 1 resulting actual usable utilization 01 however output rates monotonically decrease larger frames consider candidates result integral executiontime budgets finally note difference analysis simulation larger framesize divide maximum permissible delay result rounding fractional part computations final frame cause us overestimate outputs age remarks coarse analytical estimations essential synthesis stage showed section 3 deterministic realtime approach would fail work small example problems associated stochastic timing deviations would increase larger systems note also could rely exclusively simulation synthesis phase ie substitute analysis based timing information singlerun simulations approach would require three months synthesize small example hence since require coarse analytical estimates design stage validating solution essential first pass obvious choice discreteevent simulation reasonble set simulation runs requires several minutes often significantly cheaper going directly integration discovering design flaw implementation nasty proposition indeed eg hardware found insufficient application hosted simulation model provides decent margin confidence designs robustness particularly since underlying assumptions fundamentally different used analysis simply put sake validity two performance models better one however simulation end story objective build appli cation calibrating kernels drivers use analyticallyderived parameters point one subjects system important validity test online profiling even careful synthesis strategy testing usually leads additional system tuning help compensate imprecise modeling abstractions used static design 7 conclusion presented design scheme achieve stochastic realtime performance guarantees adjusting percomponent load allocations processing rates solution strategy uses several approximations avoid modeling entire system example estimating endtoend delay use combination queuing analysis realtime scheduling theory simple probability theory search algorithm makes use two heuristics help significantly reduce number feasible solutions checked spite approximations simulation results quite promising show approximated solutions reasonably tight also resulting secondmoment statistics show outputrates relatively smooth much work remains done first plan extending model include rigid characterization system overhead due varying degrees devicelevel multiplexing currently assume executiontime allocated integral units devicespecific penalty functions considered also plan getting better approximations handover time tasks chain result tighter analytical results also investigating new ways achieve faster synthesis results speed convergence one needs metric approximates direction improvement solution space whole would let synthesis algorithm shoot large numbers incremental improvements hopefully attain quicker solution however note problem trivial solution space contains many nonlinearities readymade global metric unconditionally predict monotonic improvement yet potentially take advantage relatively easy optimization strategies hillclimbing simulated annealing key success lies finding reasonable energy attraction function necessarily one exact finally currently deploying design technique several largescale field tests distributed applications hosted sp2 myrinet systems part project requires extending scheme handle dynamic system changes online arrivals departures permit ted componentwise pdfs vary time accomplish working selftuning mechanisms get invoked chains throughput degrades certain threshold would trigger online adjustment chains allocated load well associated frame size note analogous common problem studied context computer networks handling onthefly qos renegotiations help smooth fluctuating service demands fact investigating various strategies proposed problem evaluating whether modified arcane equally challenging domain embedded realtime systems r preemptive priority based scheduling appropriate engineering approach algorithms scheduling realtime tasks input error endtoend deadlines calculus network delay analysis simulation fair queueing algorithm communication configurator fieldbus algorithm schedule tran smission data messages transmission scheduling fieldbus strategy schedule data messages fieldbus endtoend constraints guaranteeing realtime requirements resourcebased calibration periodic processes analyzing realtime properties dataflow execution paradigm using synthetic aperture radar application hierarchical cpu scheduler multimedia operating systems network algorithms protocol multimedia servers fixed priority scheduling periodic tasks varying execution priority art computer systems performance analysis techniques experimental design deadline assignment distributed soft realtime system visual assessment realtime system design case study cnc controller optimal algorithm scheduling softaperiodic tasks fixedpriority preemptive systems note preemptive scheduling periodic scheduling algorithm multiprogramming hard realtime environment processor capacity reserves operating system support multimedia applications generalized processor sharing approach flow control integrated services networks single node case generalized processor sharing approach flow control integrated services networks multiple node case resource conscious design realtime systems endtoend approach task schedulability realtime control system reservationbased algorithm scheduling periodic aperiodic realtime tasks proportional resource allocation algorithm realtime analysis hard realtime communication lottery scheduling flexible proportionalshare management stride scheduling deterministic proportionalshare resource management providing endtoend performance guarantees using nonworkconserving dis ciplines providing endtoend statistical performance guarantees bounding interval dependent stochastic models new traffic control algorithm packet switching networks statistical analysis generalized processor sharing scheduling discipline tr ctr dongin kang stephen crago jinwoo suh poweraware design synthesis techniques distributed realtime systems acm sigplan notices v36 n8 p2028 aug 2001