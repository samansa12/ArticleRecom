request combining multiprocessors arbitrary interconnection networks several techniques proposed allow parallel access shared memorylocation combining requests one following attributesrequirements priori knowledge request combine restrictions routingof messages network use sophisticated interconnection network nodeswe present new method combining requests aboverequirements obtain new method request combining developing aclassification scheme existing methods request combining classificationscheme facilitated separating request combining process two partoperation determining combining set set requests participate ina combined access distributing results combined access membersof combining set classification combining strategies based upon whichsystem component processor elements interconnection network performs ofthese tasks approach uses interconnection network establish thecombining set processor elements distribute results lies unexploredarea design space also present simulation results assess benefits theproposed approach b introduction arvind iannucci state design largescale shared memory multiprocessor must address two basic issues 2 1 must tolerate long latencies memory requests 2 must achieve unconstrained yet synchronized access shared data several techniques example caches prefetching 24 low level context switching 25 proposed tolerate latency memory requests heretofore known methods allowing unconstrained yet synchronized access shared data implementations request combining earliest published proposal request combining chopp system 28 several read requests common memory location combined interconnection network satisfied single access memory location two read requests destined memory location meet node network source one requests saved one read request forwarded memory response read request arrives node combining took place two responses sent back toward processors idea combining read requests read combining chopp extended nyu ultracomputer allow several types requests combine 6 ultracomputer uses fetchf primitive f associative commutative operator enhanced interconnection network topology omega network proposed perform combining fetchf primitive ultracomputer style request combining illustrated figure 1 fetchfx e request meets fetchfx j request network node combining takes place e saved wait buffer alu node computes efj request fetchfx efj forwarded memory response v received memory fetchfx efj request decombining takes place v forwarded response fetchfx e request efv forwarded response fetchfx j request e removed wait buffer correct operation guaranteed combining requests satisfies serialization principle final state system must consistent servicing requests unspecified serial order 6 three distinct features ultracomputer style request combining 1 requests combined forward trip network 2 state saved network requests combined 3 requests decombined return trip network combining network node first requires comparison determine two requests combinable two requests must fetchf requests memory location requires use comparators network nodes two requests combined request removed queue value e saved wait buffer operation efj carried alu request fetchfx efj placed queue forward memory wait buffer must large enough hold many values requests combined node else combining take place return trip returning request searches wait buffer decombining must take place appropriate actions initiated implies return path must identical forward path decombining take place return path must least one node common forward paththe node combining state stored almasi gottlieb 1 give several examples hardware combining eliminate serial bottlenecks several alternative proposals request combining appeared literature 8 11 19 21 29 32 primary focus efforts reducing cost combining network accomplished either altering topology combining network requiring system software reduce amount contention shared data paper two purposes first develop taxonomy used categorize combining methods proposed date allows us enumerate issues involved make comparison known techniques combining requests second propose new approach request combining one used arbitrary interconnection topologies develop taxonomy section 2 classify existing methods using taxonomy observe one area design space call interconnectprocessor combining explored arbitrary interconnection networks explore section 3 present new scheme request combining potential new combining scheme evaluated section 4 section 5 summarizes paper suggests directions research 2 taxonomy request combining 21 parallel prefix computation request combining kruskal rudolph snir 14 observed request combining similar problem parallel prefix computation 15 given elements prefix computation produces results f associative operator computing results parallel termed parallel prefix computation 15 examine similarity request combining parallel prefix consider example four processors add constant c shared variable x receive previous value x assume processors simultaneously execute atomic operation fetchadd xc values returned processors x x c x2c x 3c regardless order requests serviced memory final value x4c simply set results r 1 r 2 r 3 r 4 r 5 produced prefix computation set elements xcccc addition operator based observation see arbitrary request combining two part operation first part task combining method determine set requests destined memory location need combined call set requests combining set second task distribute results combined access appropriate processors performing prefix computation combining set prefix computation network one proposed scan primitives blelloch 3 used distribute results combined access network state saved forward trip prefix computation network results distributed return trip similar ultracomputer approach towards combining however use prefix computation network requires priori knowledge combining set blelloch proposed scan primitives single instruction multiple data simd paradigm elements perform prefix computation case combining set stored array array distributed across processors participation prefix computation based processors activation status therefore use prefix computation network distribute results combined access combining set must established prior insertion prefix computation network alternatively ultracomputer approach towards combining combining set determined dynamically interconnect comparing addresses requests forward trip network results distributed appropriate processors return trip network two techniques use different system components establish combining set ultracomputer uses interconnect whereas blelloch uses priori knowledge processor elements therefore obtain taxonomy request combining specifying system component processor elements interconnect performs tasks involved combining requests 22 classification existing request combining strategies based upon combining set determined results prefix computation computed distributed design space request combining divided four regions figure 2 interconnect interconnect combining iic covers schemes interconnection network determines combining set distributes results processorinterconnect combining pic processors establish combining set interconnection network distributes results schemes processors perform tasks classified processorprocessor combining ppc finally interconnectprocessor combining ipc indicates interconnection network determines combining set processors distribute results following subsections discuss existing methods request combining according region design space belong 221 interconnectinterconnect combining iic chopp 28 nyu ultracomputer 6 methods request combining instances iic interconnection network determines combining set distributes results ibm rp3 21 researchers proposed basic ideas ultracomputer method combining implementation however rp3 two interconnection networks one network combines requests one services noncombining requests distinction made noncombinable potentially combinable requests typically synchronization requests interconnect dynamically determines combining set potentially combinable requests two alternative techniques iic presented tzeng 29 hsu yew 11 tzeng separates interconnect routing section combining section assumed requests may combine distinguished noncombining requests examination opcode requests directed combining section network combining section network determines combining set hsu yew propose single stage shuffleexchange combining network addition noncombining network two proposals similar ibm rp3 method combining difference topology combining network reduces hardware cost networks however basic technique request combining three schemes ibm rp3 hsu yew tzeng technique used ultracomputer interesting example iic read combining found schemes hierarchical cachememory structures cacheonly memory architecture coma machines 7 27 nonuniform memory access machines hierarchical caches 18 23 30 read combining implemented using technique similar chopp method read combining read miss cache block one level hierarchy causes request propagated next higher level hierarchy subsequent read misses cache block level hierarchy cause state saved state allows data forwarded appropriate requesting processors response arrives higher level hierarchy 222 processorinterconnect combining pic alternative approach reducing cost combining network determine combining set prior inserting elements network approach taken schemes fall classification pic design space schemes perform iic schemes performing pic use interconnection network distribute results combined requests however processor elements interconnection network determine combining set blellochs prefix computation network 3 discussed section 21 control network thinking machines cm5 17 fall category another form pic simd paradigm proposed lipovski vaughan 19 implementation uses modified carrylookahead circuit implement prefix computation network distributes results combining set determined processing elements currently active prefix computation network may extended operation multiple instruction multiple data mimd paradigm though authors explicitly state might done alternative technique combining requests mimd paradigm proposed harrison 8 uses synchronous prefix computation network requests stage network combine therefore entire combining set must inserted network time slot accomplished broadcasting information combinable locations processors based information processor determines correct time slot request addition restricted use priori knowledge combining set methods discussed section make use parallel prefix computation network distribute results networks conceptually similar ultracomputer combining network state must saved forward trip network requests decombined return trip recall requires sophisticated interconnect nodes restricts routes return messages potentially undesirable features associated result distribu tion eliminated use processor elements perform parallel prefix operation distribute results 223 processorprocessor combining ppc schemes classified iic pic interconnect viewed shared memory location forms tree memory module root tree processors leaves tree nodes combining tree realized implicit storage interconnect nodes ie wait buffers another alternative use explicit storage memory construct combining tree method request combining called software combining literature 5 31 32 classified ppc since processors bear full responsibility combining requests processors establish combining set distribute results demands network software combining one shared location divided l locations constitute storage nodes combining tree requests combined processors traverse combining tree result l processors access l locations rather processors accessing single location however l locations nodes combining tree must distributed across memory modules order alleviate excessive contention single memory module yew tzeng lawrie show software combining used barrier operations 32 goodman vernon woest 5 johnson 12 extend work yew tzeng lawrie carry arbitrary fetchf operations software combining tree tang yew also provide several algorithms traversing combining tree type memory access determines algorithm chosen eg barrier synchroniza tion semaphore read combining 31 consequence implementing combining tree explicit memory locations flexibility type memory access addition variable types memory accesses software combining permits use networks arbitrary topologies relatively unsophisticated nodes requirement implementing software combining tree access shared location shared location must known prior program execution furthermore latency combined access minimized combining tree must balanced requires priori knowledge number requests may combine 31 moreover since combining tree created based maximum number requests may combine latency complete combining operation influenced maximum number one request accessing shared location must traverse entire combining tree example balanced software combining tree height h single request must perform h memory accesses must traverse interconnection network processors responsible establishing combining set require priori knowledge burden determining combining set placed back interconnect need priori knowledge eliminated 224 interconnectprocessor combining ipc heretofore proposed methods exception special cases discuss section request combining use arbitrary interconnection network determine combining set processor elements distribute results order decide scheme worthy investigation next section compares issues implementing combining classifications 23 issues combining requests several aspects request combining touched upon previous discussion reiterate motivate ipc priori knowledge combining set restrictions placed routes messages sophistication interconnection network latency combining operation need priori knowledge combining set requires programmer specify information restrictions placed routing messages limits choices interconnection network topology sophistication interconnection network impacts cost performance system high degree sophistication might increase design time may either increase latency noncombining requests require addition second network latency combining operation time processor generates combinable request time result request received next two sections look issues affected system component establishes combining set component distributes results table 1 summarizes following discussion 231 determining combining set processor elements require priori knowledge combinable locations order establish combining set example nodes software combining tree 31 defined algorithm design contrast interconnect determines combining set dynamically comparing destination addresses messages consequence introducing comparators small increase sophistication nodes intercon nect may result slight increase latency complete combining operation 232 result computation distribution placing responsibility result distribution interconnect two disadvantages first increase sophistication interconnect result wait buffers decombining logic interconnect node second perhaps important disadvantage route return message may travel restricted must visit nodes state saved forward trip network primary advantage using processor elements distribute results combining operation restrictions placed routes messages may travel requirement visit particular node another advantage sophistication interconnect nodes increased need wait buffers however sophistication processor elements accurately processornetwork interface may increase somewhat handle protocol needed distribute results latency combining operation measured number steps needed carry operation disadvantage using processors distribute results section 3 show latency distributing results logarithmic respect number requests combining set assuming system broadcast capability based discussion feel investigation ipc yet unexplored area design space worthwhile schemes would use interconnect determine combining set use processor elements distribute results discussion also points following potential advantages ipc combining priori knowledge combining set required since interconnect dynamically determines combining set ii restrictions routes messages since processor elements distribute results iii nodes interconnection network require small amount sophistication potential drawback scheme compared iic latency combining operation 3 interconnectprocessor combining consider implementations request combining fall unexplored region design space interconnectprocessor combining ipc initially consider two flavors combinable operations restricted form fetchadd fa fetchincrement 9 26 general fa operation fetchincrement simply fi participants add constant value general fa participant could adding different value rationale simpler fi operation following process determining combining set also possible participant determine overall position combining set ie position serial order participant compute value without interactions participants following example illustrates point figure 3 shows system six processors p 0p 5 connected shared synchronization bus processor assigned one channel bus channel could wire electronic bus 26 specific frequency optical bus 9 given processor read channels write channel processor generates combinable request broadcasts intentions bus putting 1 channel processors wish participate access write 1 respective channels point processors monitoring channels bus determine number identity processors going participate combined access combining set established determining participating processors ordering combining set statically defined priorities assigned channels suppose four processors p 0p 1p 3p 5 would like perform fi operation increment constant c memory location x point four processors indicated intentions access x priority chain 0s 1s 2s 3s 4s 5 110101 four processors determines many processors ahead priority chain also participating combining operation example p 5 determines three processors ahead priority chain p 3 sees two p 1 sees one p 0 sees zero since highest priority processor participating combined access p 0 takes responsibility accessing x memory p 0 accesses x processors also read value memory bus processor restricted adding constant c shared location therefore processor may compute value locally based number participants preceding priority chain p 0 receives x p 1 computes x c memory receives x 4c one processor memory controller could also monitoring bus takes responsibility computing x4c updating memory method described proposed independently electrical bus sohi smith goodman 26 optical bus hiedelberger rathi stone 9 ease combining carried special cases prompted freudenthal gottlieb investigate use fetchincrement operation place general fa operation 4 broadcast option method must used determine combining set carry prefix operation combining set unlike networks broadcast easy way merge creation combining set ordering arbitrary interconnection network must continue separate creation combining set implementation prefix operation since prefix operation carried combining set regardless whether order elements would necessary case fi operations distribute results would necessary case fa operation see potential implementation advantage fi operation fa operation arbitrary network therefore continue discussion fa operations proposal ipc arbitrary network uses network create combining set choose represent combining set linked list though conceivable structures could also used processors use structure interact carry prefix operation expand two functions setting list distributing results processor submits fetchfx v request generates message sent interconnect destination containing x message consists least four fields address x value field v two pointers shown figure 4 pointers indicate head tail list processors ie combining set accessing memory location specified message initially processor generating request member combining set two messages destined memory location meet node interconnect two messages combined illustrated figure 5 result combining forward message sent destination location x head tail fields updated indicate head tail new combining set new combining set union combining sets two combined messages alus present value field forward message updated reflect f operation value fields combined messages link message sent processor tail combining set first message instructions create link processor head combining set second message route taken link message depends upon topology network example omega network unidirectional links link message would travel forward direction arbitrary destination reflect destination go back appropriate processor details combining operation node shown figure 5 important note state saved network point messages combined figure 6 illustrates example assume processors b generate fa requests location x shown figure 6 two requests merged message sent processor indicating processor b head list processors also participating fa operation point processor b member list added processor pointer processor b forms new linked list representing combining set location x fields forward message memory location x head list tail list b values fields shown figure prevent clutter assume processors c also formed combining set location x two lists two members two messages enroute memory two messages merge message sent processor b indicating processor c head linked list processors also participating fa opera tion creates single combining set union two original combining sets message forwarded memory fields set head first list tail second list single combining set represented one message going memory memory receives request returns value stored location x head list also sends message tail list indicating responsible providing final result memory allows results fa operations distributed processors shall discuss shortly fa request reaches destination x head tail fields request point head tail combining set several options proceed alus present network nodes combining took place used update value field forward message shown figure 5 value field message reaching x contains final result prefix operation applied value fields members combining set determined head tail pointers even though individual processor intermediate results prefix operation yet known old value memory location x returned head used prefix operation described later determine results members combining set memory location x could updated final value old value x plus value field message reaching x accesses location x proceed results prefix operation first combining set carried alus present network nodes combining took place final value prefix operation combining set determined combined message reaches memory location x must wait prefix operation combining set complete memory receive uptodate value happens requests location x time two options first option simply lock memory location x final result prefix operation known tail combining set responsible unlocking x makes requests x wait building second combining set waiting prefix operation first complete locking x fairly easy shall see section 4 implications performance second option append new combining set onto old combining set prefix operation progress thereby creating one combining set make prefix operation robust enough operate variablesize combining sets appending new combining set onto old combining set care must taken avoid potential race conditions particular message memory tail old combining set telling create pointer head new combining set thereby continuing prefix operation could arrive prefix operation old combining set completed final result way memory message must reflected back memory supply upto date value new combining set allow start prefix operation message handling protocol must take possibility race conditions account take appropriate action prevent incorrect operation first glance appending onto combining set prefix operation progress appears good idea also implications performance shall see section 4 discussion discern amount sophistication required interconnect nodes use comparators necessary determine two messages destined memory loca tion small amount additional logic required construct new message sent back processors update tail message forwarded memory alus needed expect update memory final value immediately consider prefix operation could carried combining set represented linked list purposes discussion result distribution assume processors use pointto point messages reflected memory modules necessary communication naive method distributing results start head list sequentially move one node next list although hotspot using naive method distribute results messages unnecessarily serialized eliminate serialization distribution results turn literature parallel applications see prefix operation combining set carried parallel several algorithms performing parallel prefix computation linked list exist literature 10 13 15 20 algorithms concerned case nodes linked list processors available case number nodes linked list equivalent number processors participating combined access therefore use partial sums algorithm given hillis steele 10 shown figure 7 algorithm uses recursive doubling iteration loop performs half many operations previous iteration entire computation complete algorithm advantage result computed ologs steps number nodes list ie cardinality combining set example partial prefix sum computation list eight nodes shown figure 8 array initial indexed processor number contains number next processor initial linked list array forward indicates processor communicated current iteration algorithm important note recursive doubling algorithm defined simd machine therefore appropriate synchronization must added mimd operation figure 9 shows mimd version result distribution ipc reader referred to16 discussion transformation simd mimd processors also require limited amount memory olog storing pointers neighboring processors combining set tried exhaust methods ipc addressed issues involved ipc undoubtedly alternative data structures maintaining combining set associated algorithms distributing results however provide viable solution deserves investigation 4 evaluation ipc investigate overall system performance using ipc developed simulator multiprocessor system performs ipc enhanced omega network establishes combining sets described section 3 processors use mimd version recursive doubling parallel prefix algorithm distribute results combined access simulator consists three distinct parts processor elements interconnection network memory modules table 2 summarizes parameters system processor elements memory reference generators additional code required distribute results combined access processors generate memory reference cycle probability r providing network accept request memory references h percent directed single hot memory location 22 32 processor may one outstanding fa request unlimited outstanding uniform requests however processor generate requests outstanding fa yew et al 32 call limitedvariable access pattern interconnection network used simulations enhanced omega network node bidirectional links 1 queue exists forward network reverse network therefore switch forward network two inputs three outputs whereas switch reverse network three inputs two outputs assume message single packet buffering occurs contention network two messages combine one buffered assume full comparator used determine arriving message combinable buffered message pairwise combining carried node simulated system 256 processors connected 256 memory modules simulations vary h 032 percent r 20100 percent figure 10 shows average latency maximum bandwidth combining performed previously shown 22 32 point saturation bandwidth ceases increase latency increases first experiment implemented ipc without alus network nodes locking memory prefix operation current combining set complete figure 11a presents latencies 1 use bidirectional links design choice made still possible use ipc networks separate forward reverse net works messages link combining sets together would reflected memory modules however conditions ipc still allows use adaptive routing techniques requests saturation bandwidths varying hot rates comparing figs 10 11 note different scales see latencies decreased small values h increased large values saturation bandwidth also decreased values h reason twofold since lock memory loca tion prevent second combining set starting prefix operation consequently hot requests second combining set stalled long time waiting prefix operation first combining set com plete illustrated figure 12 fig 11b presents latency hot requests fig 12 presents average amount time hot request spends waiting lock memory released comparing figs 11b 12 see time waiting lock released significant portion overall hot request latency next experiment carried involved appending requests arrive memory onto end combining set prefix operation already progress case requests wait prefix operation previous combining set complete rather join form larger combining set join existing prefix operation expectation reducing waiting time would decrease hot request latency unfortunately experimental results presented figure 13 indicate otherwise fig 13a shows saturation bandwidth latency requests fig 13b shows latency hot requests varying hot rates reason disappointing results experiment appending requests combining set decreases time spent requests waiting memory actually increases time carry prefix operation since hot requests get appended one one prefix operation cant complete long requests appended participant value ready entire prefix operation complete extreme case hot requests appended one one parallel prefix degenerates serial prefix one processor use value entire prefix operation complete moreover since deterministic pattern requests appended uniform trend results based upon results experiment feel appending new arrivals onto existing combining set prefix operation already progress something done caution study needed area final experiment ipc uses alus network nodes case since final result prefix operation available intermediate results need make succeeding hot requests wait prefix operation progress previous combining set prefix operations could operation multiple combining sets simultaneously figure 14a presents latencies saturation bandwidths requests figure 14b presents hot requests varying hot rates compare figures 10 14 see ipc quite effective reducing degradation due hot spots ipc reduced latency requests improved overall network bandwidth well reduced latency hot requests interesting latency hot requests lower higher hot rate figure 14b higher hot rate larger combining set established therefore hot requests serviced parallel overall proposed method ipc effective ultracomputer style combining equivalent results ultracomputerstyle combining found paper pfister norton 22 however results suggest option worth considering 5 summary conclusions unconstrained yet synchronized access shared memory locations achieved combining requests formulated taxonomy various techniques request combining separating combining operation two parts establishing combining set distributing results taxonomy divides request combining design space four regions defined system component processor elements interconnection network performs tasks request combining classification existing implementations request combining enabled us obtain four primary issues implementation request combining must address need priori knowledge requests combine complexity interconnect nodes restrictions placed routing messages interconnect latency complete combined access shown current methods request combining occupy three four regions design space address first three issues satisfactorily presented implementation lies yet unexplored region known interconnectprocessor combining ipc interconnect establishes combining set processor elements distribute results show implementations area design space following advantages need priori knowledge combinable location restrictions routing messages low sophistication interconnect nodes also carried several experiments assess benefits ipc observed ipc effective technique alleviate degradation caused serial access memory must used care implementations ipc could degrade latency hot requests intolerably thereby reducing network bandwidth even though reduce latency uniform requests feel flexibility performance benefits ipc make attractive design choice research needed area definitive answer obtained many alternatives ipc need investigated including choice data structure used maintain combining set well algorithm used carry prefix operation combining set one step direction recent thesis johnson investigates use ipc build tree implement scalable cache coherence scheme 12 direct comparisons different forms combining using real application workloads different network topologies also need done get better picture costperformance benefits various techniques request combining r highly parallel computing critique multiprocessing von neumann style scans primitive parallel operations process coordination fetchandincrement set efficient synchronization primitives largescale sharedmemory multiprocessor nyu ultracomputer designing mimd shared memory parallel machine cacheonly memory architecture synchronous combining fetchandadd operations device performing efficient task distribution bus connection data parallel algorithms effective synchronization network hotspot accesses extending scalable coherent interface largescale sharedmemory multiproces sors parallel algorithm efficient solution general class recurrence equations efficeint synchronization multiprocessors shared memory parallel prefix computation request combining multiprocessors arbitrary interconnection networks network architecture connection machine cm5 directorybased cache coherence protocol dash multiprocessor fetchandop implementation parallel computers simple efficient asynchronous parallel prefix algorithms ibm research parallel processor prototype rp3 introduction architecture hotspot contention combining multistage interconnection net works toward design largescale sharedmemory multiprocessors cache memories architecture applications hep multiprocessor computer system restricted fetchf operations parallel processing comparative performance evaluation cachecoherent numa coma architectures shared memory computer method apparatus design novel combining structure sharedmemory multiprocessors hierarchical cachebus architecture shared memory multiprocessors software combining algorithms distributing hotspot addressing distributing hotspot addressing large scale multipro cessors tr data parallel algorithms hierarchical cachebus architecture shared memory multiprocessors distributing hotspot addressing largescale multiprocessors efficient synchronization multiprocessors shared memory fetchandop implementation parallel computers efficient synchronization primitives largescale cachecoherent multiprocessors scans primitive parallel operations software combining algorithms distributing hotspot addressing process coordination fetchandincrement comparative performance evaluation cachecoherent numa coma architectures ddm network architecture connection machine cm5 extended abstract effective synchronization network hotspot accesses highly parallel computing extending scalable coherent interface largescale sharedmemory multiprocessors toward design largescale sharedmemory multiprocessors restricted fetch myampersandphi operations parallel processing parallel prefix computation directorybased cache coherence protocol dash multiprocessor cache memories critique multiprocessing von neumann style ctr todd austin gurindar sohi highbandwidth address translation multipleissue processors acm sigarch computer architecture news v24 n2 p158167 may 1996