tradeoffs powerefficient issue queue design major consumer microprocessor power issue queue several microprocessors including alpha 21264 power4tm use compacting latchbased issue queue design advantage simplicity design verification disadvantage structure however high power dissipationin paper explore different issue queue power optimization techniques vary performance power characteristics much deviate baseline implementation developing comparing techniques build incrementally baseline design well achieve higher power savings significant redesign effort quantify extra benefit higher design cost techniques provide straightforward counterparts b introduction many complex tradeoffs must made achieve goal powerefficient yet high performance design first amount performance must traded lower power second consideration received less attention amount redesign verification effort must put achieve given amount power savings timetomarket constraints often dictate straightforward modifications existing designs take precedence radical approaches require significant redesign verification efforts latter must permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copy otherwise republish post servers redistribute lists requires prior specific permission andor fee islped02 august 1214 2002 monterey california usa clear demonstrable power savings minimal negative consequences justify extra effort one microprocessor structure received considerable attention issue queue issue queue holds decoded renamed instructions issue outoforder appropriate functional units several superscalar processors alpha 21264 11 power4 10 implement latchbased issue queue entry consists series latches 1 4 queue compacting outputs entry feedforward next entry enable filling holes created instruction issue new instructions always added tail position queue manner queue maintains oldest youngest program order within queue simplifies implementation oldestfirst issue priority scheme additional important advantages implementation highly modular use scannable latches simplifies issue queue design verification however high price approach power consump tion instance integer queue alpha 21264 highest power consumer chip 11 similarly issue queue one highest powerdensity regions within power4class processor core 1 reason several techniques reducing issue queue power proposed 2 3 5 however prior efforts exclusively focused approaches require considerable redesign verification effort well design risk thus far lacking quantitative comparison range issue queue power optimization techniques vary design effortrisk addition power savings performance cost analysis results several possible issue queue design choices appropriate depending redesign verification effort design team afford put achieve lowerpower design 2 noncompacting latchbased issue queue figure 1 illustrates general principle latchbased issue queue design bit entry consists latch multiplexer well comparators shown figure source operand ids entry feedsforward next queue entry multiplexer used either hold current latch contents load latch contents next entry design shown figure 1 loads dispatched instructions uppermost unused queue entries holes created instructions issue filled via compaction operation entries shifted downwards dispatching entries tail queue compacting queue issue oldest youngest program order maintained queue times oldest instruction lying bottom queue shown figure 1 thus simple positionbased selection mechanism like described 9 priority moves lower upper entries used implement oldestfirst selection policy issue priority instruction age although compaction operation may necessary simpler selection mechanism may major source issue queue power consumption latchbased designs time instruction issued entries shifted fill hole resulting latches clocked lower entries issue priority upper entries instructions often issue lower positions resulting large number shifts therefore large amount power dissipation eliminate powerhungry compaction operation make issue queue noncompacting 7 noncompacting queue holes result instruction issue particular entry immediately filled rather holes remain new entry dispatched queue point holes filled priority order bottom top however noncompacting queue oldest youngest priority order instructions lost thus use simple positionbased selection mechanism like described 9 give priority older instructions compacting design hold 21 mux entry n1 detail queue entry queue compaction figure 1 latchbased issue queue design compaction solve problem lost instruction ordering maintaining much powerefficiency advantages noncompacting queue reorder buffer rob numbers sequence numbers typically tag dispatched instruction used identify oldest youngest order however problem arises scheme due circular nature rob may implemented ram head tail pointers example assume simplicity 8entry rob oldest instruction lies location 111 youngest 000 instruction commits head pointer rob decremented point next en try similarly tail pointer decremented instruction dispatched implementation oldest instruction may longer lie location 111 working example location fact tail pointer may wrap around back entry 111 newer entries nearest tail may occupy highernumbered rob entry older entries 6 oc curs oldestfirst selection scheme longer work properly problem solved adding extra highorder sequence number bit call sorting bit kept issue queue instructions dispatched allocated sequence number consisting rob entry number appended sorting bit 0 sequence numbers stored entry issue queue whenever rob tail pointer wraps around entry 111 example sorting bits flash set 1 issue queue newly dispatched instructions however including one assigned rob entry 111 continue receive sorting bit 0 sequence numbers steps summarized figure 2 guarantee newly dispatched instructions lower sequence number prior older instructions already residing queue sorting bit adjustment place older instructions properly selected ready instructions follows significant bits sequence numbers ready instructions ored together result 1 ready instructions whose significant bits 0 removed consideration next step second significant bit sequence numbers ready instructions still consideration ored together result 1 ready instructions still consideration whose second significant bits 0 removed consideration nth step step 2 except least significant bit sequence number used end step ready instructions removed consideration except oldest however orbased arbitration mechanism requires final linear chain highest order lowest order bit significantly increases delay selection logic compared selection logic described palacharla 9 4 bits entry queue note processor 128 instructions rob 128 entries flight full sequence number consists 7 bits sorting bit lack full age ordering 4bit sequence numbers results cpi degradation shown section 5 although improvement cpi degradation incurred age ordering positionbased selection noncompaction tail head pointer pointer start point 1s rob sorting bit00sorting bit update criteria tail pointer hits start point sorting bits queue flash set 1 figure 2 mechanism updating sorting bit issue queue 3 camrambased issue queues section describe issue queue powersaving optimizations require redesigning baseline latchbased queue camram structure source operand numbers placed cam structure remaining instruction information placed ram structure number entries corresponds size issue queue camram structure arguably complex terms design verification time support compaction however lower power dissipation camram logic relative random logic camrambased issue queue approach potential reduce average power dissipation queue potentially consuming less power latchbased lution camrambased issue queue still offers opportunities power reductions cam ram structures require precharging discharging internal high capacitance lines nodes every operation cam needs perform tag matching operations every cycle involves driving clearing high capacitance taglines also precharging discharging high capacitance matchline nodes every cycle similarly ram also needs charge discharge bitlines every read operation following subsections discuss approaches reduce power camrambased issue queue 31 dynamic adaptation issue queue finegrain clock gating suitable latchbased issue queues shared resources bitlines wordlines taglines precharge logic sense amps etc camrambased designs make clock gating less effective latchbased designs however camram based designs amenable dynamic adaptation issue queue match application requirements described 2 size issue queue needed maintain close peak performance varies application application even among different phases single application thus issue queue adapts different program phases potential significantly improve power efficiency little impact cpi performance paper implement basic approach proposed 2 scheme issue queue broken multientry chunks disabled onthefly runtime hardwarebased monitor measures issue queue activity cycle window period counting number valid entries queue appropriate control signals disable enable queue chunks 2 32 banked issue queue banking common practice rambased structures eg caches reduce delay ram power dissipation cambased structures also banked 8 albeit potential impact cpi performance loworder n address bits normally used comparison instead used select one 2 subarrays remaining bits compared appropriate bits cam subarray entry similarly n bits used pick subarray new entry placed thus one n subarrays activated cam access cpi degradation comes nonuniform usage different subarrays causing subarrays become full others inefficient usage entries compared single cam structure results either entries needlessly replaced new entries able inserted even available space subarrays result cpi degradation relative single cam structure issue queue cam structure presents additional complication two fields source operand ids match operation performed prevents one subarray disabled fourbank design approach ideal enabling one subarray access propose novel banked design exploits fact frequently least one two source operands ready instruction dispatched figure 3 shows frequently one neither two source operands ready instructions dispatched integer queue simulation six spec2000 integer programs using methodology described section 4 average 13 dispatched integer instructions neither operand ready remaining 87 instructions least one operand available therefore require one match operation instruction wake banked issue queue organization exploit property shown figure 4 organization uses four banks holds two source operand ids one full sixbit source operand field assuming 64 physical registers held instruction info ram section entry consists four loworder register id bits held cam part entry note 2 bits already used bank selec tion thus latter compared loworder four destination register id bits broadcast thus banked issue queue design reduces power dissipation eliminating bzip gcc mcf parser vortex vpr average10305070percentage instructions benchmarks one op ready ready none ready none ready diffbanks figure 3 percentage instructions various numbers operands available dispatch also shown percentage cases neither source operand available source operand ids associated different banks one two source operand ids cam note match logic guaranteed active one cycle ever ready logic selection logic ram part may active one cycle multiple instructions say n may become ready due result distribution case ready logic selection logic ram part may active n cycles selection logic global sense instructions may simultaneously ready multiple banks shown top figure 4 example add instruction three cases source operands ready dispatch easy handle instruction steered bank corresponding id number unavailable source operand case operands instruction available instruction steered bank corresponding first operand instruction selected bank wakes match lower four bits destination id source id corresponding unavailable operand fourth case neither operand available dispatch treated special case instructions neither source operand available placed conflict queue conflict queue simply conventional issue queue performs comparisons source operands small percentage instructions neither source operand available dispatch conflict queue need contain entries destination ids completing instructions compared entries one banks well conflict queue conflict queue small energy dissipation pales comparison savings afforded banking assume 64 physical registers instruction dependency register number ranging bank3 r1r16 goes bank1 r17r32 addr1 conflict queue predecoder bank1 bank2 multiplexer add r1r2r19 ready ready ready ready ready ready ready ready easy handle special case add instruction go separate queue conflict queue general broadcast done goes bank1 r2 specifier broadcasted bank1 specific broadcasts done figure 4 banked issue queue organization placement instructions using conflict queue case neither source operand available dispatch 4 methodology design alternatives implemented circuit level power estimations evaluated using ibm asx circuit simulation tool next generation process parameters circuits also optimized much reasonable power speed baseline latchbased issue queue circuit designs borrow existing power4 libraries appropriate microarchitectural simulations used simplescalar 30 simulate aggressive 8way superscalar outoforder pro cessor simulator modified model separate integer floating point queues baseline also included register renaming physical registers properly model banked issue queues chose workload six spec2000 integer benchmarks run 400 million instructions issue queue event counts captured simulation used circuitlevel data estimate power dissipation focus integer issue queue 32 entries paper although techniques largely applicable queue structures eg floating point queue dispatch queue reorder buffer simulation parameters chose combined branch predictor bimodal 2level fetch decode widths 16 instructions 8way machine reorder buffer size 128 entries used 64kb 2way l1 2mb 4way l2 caches four integer alus multipliers four memory ports 5 results baseline issue queue 1 entry needs clocked cycle even queue idle due need recirculate data multiplexer hold data place alternative clockgated design main clock well latch clocks gated control signal whenever entry valid bit set loaded first examine benefits clock gating issue queue largely depends fraction entries clock gated application suite figure 5 shows average number entries 32entry integer queue clock gated well overall power savings achieved vortex gcc average 50 queue entries clock gated whereas mcf parser vpr much clock gating opportunity average 34 power savings achieved clock gating issue queue without loss cpi performance tradeoffs compacting noncompacting issue queue complex degradation cpi performance potentially occur noncompaction due lack oldest first selection scheme modified simplescalar model holes created noncompacting issue queue filling holes newly dispatched instructions selection mechanism strictly based location within queue rather oldestfirst mechanism used default scheme older instructions may remain queue long time period thereby delaying completion important dependence chains leftmost bar figure 6 shows cpi degradation six spec2000 integer benchmarks degradation significant around 8 mcf parser 55 overall rightmost bar shows cpi degradation previously described oldestfirst selection scheme implemented using four bit sequence number including sorting bit average partial oldest first selection scheme reduces cpi degradation 55 23 1 baseline described paper represent real power4 issue queue mechanisms reduce power described paper present real power4 design bzip gcc mcf parser vortex vpr average51525 queue entries benchmarks power savings clock gated clock gated figure 5 number queue entries gated power savings relative baseline latchbased issue queue clock gating bzip gcc mcf parser vortex vpr average13579 cpi degradation benchmarks noncomp partold figure degradation incurred via noncompaction positionbased selection noncompaction partial oldestfirst selection power savings noncompacting latchbased issue queue relative baseline design shown figure 7 noncompacting queue power includes power overhead due oldestfirst selection logic overhead well write arbitration logic overhead provides capability writing hole newly dispatched instructions even additional overheads elimination frequent highpower compacting events considerable impact across benchmarks achieving power savings 2545 36 overall figure also shows relative power savings noncompacting camrambased issue queue noncompacting issue queue implemented clock gating redesigning issue queue camram structure achieves considerable power savings noncompacting latchbased design however combination noncompacting latchbased design clock gating achieves slightly better overall savings note slightly better power savings mcf parser vpr camram based design due lack opportunity clock gating benchmarks choice one option depends number factors including expertise design team terms clock gating versus camram implementation verification testing camram design degree additional clock skew switching current variations clock gated design tolerated rest section explore camrambased issue queue design augmented dynamic adaptation banking reduce power dissipation bzip gcc mcf parser vortex vpr average10305070power savings benchmarks latchbased compaction based latchbased compactionclkgating figure 7 power savings relative baseline noncompacting latchbased noncompacting camrambased noncompacting latchbased clock gating proposed partial oldestfirst selection scheme assume 32entry adaptive issue queue configured 32 24 16 8 entries application execution figure 8 shows power savings performance degradation adaptive scheme different cycle window values 2 note negative power savings mcf using larger cycle windows 8k 16k occurs coarse level dynamic adaptation 32entry configuration always selected incurs power penalty due overhead dynamic adaptation circuitry use smaller cycle windows allows dynamic adaptation algorithm capture finergrain phase change behavior mcf resulting smaller configurations selected benchmarks use smaller cycle windows results higher power savings lower performance degradation larger cycle windows used cycle window 4k 34 overall issue queue power savings achieved 3 cpi degradation compared camrambased design bzip gcc mcf parser vortex vpr average 202060power savings benchmarks bzip gcc mcf parser vortex vpr average2610 cpi degradation benchmarks figure 8 cpi degradation power savings adaptive issue queue relative camrambased issue queue different cycle window values explored 2 4 8way banked issue queues using conflict queue approach described section 32 top figure 9 shows banking effective relative power cam structure increases quadratically number entries banking divides queue smaller structures one selected cycle bottom part figure shows power savings achieved different issue queue sizes 2 4 8way banked queues one bank enabled clear tradeoff reduction number active entries thus bitline length higher degrees banking extra peripheral circuit overhead incurred banks small queue size 16 entries power savings greatest two banks due relatively large cost duplicating peripheral circuitry larger 64 entry queue savings bitline power afforded 8 banks outweighs peripheral logic power overhead relative power entries array savings iq entries banked cam 1 bank active 2banks 4banks 8 banks figure 9 relative power issue queue cam array function number entries top power savings degree banking issue queue size single enabled bank bottom mentioned section 32 banking incur cpi degradation due underutilization queue entries resulting static allocation dispatched instructions banks partially remedied increasing number entries bank graph top figure 10 shows cpi degradation incurred relative baseline 4way banked issue queue 4 entry conflict queue various numbers entries per bank cpi degradation reduced 25 10 entries per bank slight increase 8 entries nominally used middle graph shows performance degradation 4way banked queue entries per bank different conflict queue sizes small number entries 45 sufficient reduce cpi degradation negligible levels finally bottom graph shows percentage time various numbers banks active 8way issue machine 4banked issue queue 10 entries per bank 4 entry conflict queue well power savings achieved benchmark note results account power overheads extra entries conflict queue assume baseline banked designs entire queue disabled activity zero banks active banked approach overall 31 energy savings achieved 25 impact cpi performance compares favorably 34 power savings 3 cpi degradation adaptive approach yet banked scheme arguably straightforward implement 51 comparison different alternatives clock gating issue queue significant impact power dissipation cpi degradation despite implementation verification challenges wellknown established approach therefore represents straightforward albeit effective solution issue queue power problem bzip gcc mcf parser vortex vpr average26cpi degradation benchmarks 8ent 9ent 10ent 11ent bzip gcc mcf parser vortex vpr average5cpi degradation benchmarks bzip gcc mcf parser vortex vpr average50active banks benchmarks power savings 3053150bankact 1bankact 2bankact 3bankact 4bankact figure 10 32entry fourway banked issue queue results relative 32entry camrambased issue queue cpi degradation different numbers entries per bank top 4 entry conflict queue cpi degradation different size conflict queues middle 10 entries per bank percentage different numbers active banks power savings bottom 4 entry conflict queue 10 entries per bank side making queue noncompacting affords even greater power savings albeit cpi performance cost due elimination oldestfirst selection problem largely remedied sequencenumber sorting bit scheme proposed paper delay cost negligible power impact relative power savings noncompaction makes noncompacting scheme attractive alternative baseline compacting design combination noncompaction clock gating provides slightly better issue queue power savings camrambased design two alternatives functionally equivalent quite different terms number implementation verification cost factors may favor one designer chooses camrambased implementation adaptive camrambased issue queue delivers additional 26 power savings beyond noncompaction clock gating ever cost slight performance degradation addition significant design verification effort involved banked approach conflict queue represents attractive alternative adaptive design power savings performance degradation rival adaptive approach yet design would considered straightforward designers finally banked adaptive issue queue techniques orthogonal approaches combined afford even greater power sav ings due size issue queue 32 entries combination techniques would profitable however larger 128 entry queue could divided four 32 entry banks would use adaptive approach described paper based experience results paper expect combination would produce much greater power savings techniques investigated study 6 conclusions paper presented range issue queue power optimization techniques differ effectiveness well design verification effort part study propose sequencing mechanism noncompacting issue queues allows straightforward implementation oldestfirst se lection also devised banked issue queue approach allows one bank disabled little additional power overhead detailed quantitative comparison tech niques determine combination noncompaction scheme clock gating achieves roughly power savings camrambased issue queue also conclude adaptive banked camrambased issue queue approaches achieve significant enough power savings latchbased approaches potentially justify greater design verification effort 7 acknowledgments research supported part darpaito afrl contract f2960100k0182 nsf grants ccr9701915 ccr9811929 ibm partnership award 8 r adaptive issue queue reduced power highperformance issue logic 600mhz outoforder execution microprocessor data processing system method using unique identifier maintain age relationship executing instructions 18ghz instruction window buffer design highspeed lowpower cmos fully parallel contentaddressable memory macros power4 system microarchitecture alpha processors history power issues look future tr complexityeffective superscalar processors energyeffective issue logic energy adaptive issue queue reduced power high performance ctr rajesh vivekanandham bharadwaj amrutur r govindarajan scalable low power issue queue large instruction window processors proceedings 20th annual international conference supercomputing june 28july 01 2006 cairns queensland australia yingmin li dharmesh parikh yan zhang karthik sankaranarayanan mircea stan kevin skadron statepreserving vs nonstatepreserving leakage control caches proceedings conference design automation test europe p10022 february 1620 2004 simha sethumadhavan franziska roesner joel emer doug burger stephen w keckler latebinding enabling unordered loadstore queues acm sigarch computer architecture news v35 n2 may 2007