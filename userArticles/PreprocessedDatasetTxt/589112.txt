accurate identification active constraints consider nonlinear programs inequality constraints focus problem identifying constraints active isolated local solution correct identification active constraints important theoretical practical point view identification removes combinatorial aspect problem locally reduces inequality constrained minimization problem equality constrained problem easily dealt present new technique identifies active constraints neighborhood solution requires neither complementary slackness uniqueness multipliers also present extensions variational inequalities numerical examples illustrating identification technique b introduction paper consider problem identifying constraints active isolated stationary point x nonlinear program assumed functions f least continuously differentiable specifically interested following question given x 2 ir nm belonging sufficiently small neighborhood karushkuhntucker kkt point problem p possible correctly estimate basis problem data x set indices 0 fij g active constraints correct identification active constraints important theoretical practical point view identification removing difficult combinatorial aspect problem locally reduces inequality constrained minimization problem equality constrained one much easier deal particular study local convergence rate algorithms problem p implicitly explicitly depends fact 0 eventually identified identification active constraints difficult strict complementarity holds solution see discussion next section however far aware date technique successfully deal case complementary slackness assumption violated except case linear programs see 10 paper present new technique mild sumptions correctly identifies active constraints neighborhood kkt point technique appears improve existing techniques particular enjoys following properties simple independent algorithm used generate point x ii require complementary slackness iii require uniqueness multipliers iv rely convexity assumption v case unique multipliers also permits correct identification strongly active constraints vi identification technique applied also karushkuhntucker system arising variational inequalities identification active constraints 3 strategies identifying active constraints part optimization folklore 2 13 15 however almost invariably lack many good characteristics listed last ten years special attention devoted problem field interior point methods linear programs refer reader survey paper 10 recent works nonlinear case include 9 11 23 case box constraints considered 12 36 general nonlinear case studied related material also found 4 5 6 problem establishing whether sequence fx k g converging solution x way identifies set 0 dealt note however latter papers explicit rule given order identify active constraints close arbitrary point remark order identify active set suppose given pair x primal dual variables think algorithmic applications results paper stress algorithms produce sequence primal dual variables even rare cases occur usually possible reasonable assumptions generate continuous dual estimate using multiplier function see eg 12 references therein well section 4 paper organized follows next section introduce identification technique prove main properties identification technique critically depends definition call identification function therefore technical section 3 devoted definition identification functions different sets assumptions section 4 use results previous sections order define local active set newtontype algorithm solution inequality constrained optimization problems qquadratic convergence rate primal variables proved weak conditions section 5 give final comments conclude section providing list notation employed throughout paper k delta k indicates euclidean vector norm symbol b ffl denotes open euclidean ball radius ffl 0 center origin dimension space clear context euclidean distance point nonempty set abbreviated disty write x vector maxf0 xg maximum taken componentwise set use notation x j j order represent jj jdimensional vector components finally transposed jacobian vectorvalued mapping g point x denoted rgx ie ith column matrix gradient rg x active constraints following usual terminology constrained optimization call vector stationary point p exists vector 2 ir x solves 4 f facchinei fischer c kanzow karushkuhntucker system 1 pair x called kkt point problem p sequel x always denote fixed isolated stationary point neighborhood x contain stationary point p moreover shall indicate set lagrange multipliers associated x k set kkt points associated x solves 1g k fx set closed convex therefore set k gauvin 14 showed bounded hence compact mangasarianfromovitz constraint qualification mfcq satisfied ie hand kyparisis 22 showed reduces singleton strict mangasarianfromovitz constraint qualification smfcq holds ie denotes index set particular linear independence constraint qualification licq ie linear independence gradients active constraints implies singleton basic aim construct rule able assign every point x estimate ax ax lies suitably small neighborhood point x 2 k usually estimates kind obtained comparing value g x value example easily shown set phi x coincides set 0 x sufficiently small neighborhood kkt point x satisfies strict complementarity condition condition violated inclusion phi x 0 2 identification active constraints 5 holds furthermore singleton also sufficiently small neighborhood x relation exploited construct locally superlinearly convergent qpfree optimization algorithms unique multiplier satisfy strict complementarity condition see eg 12 20 35 refer reader 2 12 references therein complete discussion kind results analysis results established literature shows conclusion holds general strict complementarity satisfied usually possible correctly identify active constraint set otherwise relation like 3 best result established general nonlinear case overcome situation propose compare g x quantity goes 0 known rate x converges point kkt set k end introduce notion identification function called identification function ae continuous k b x 2 k implies aex c x belongs k lim aex dist x k next section shall give examples build appropriate sumptions identification functions basically definition 21 says function identification function goes 0 approaching set k slower rate distance set k note dist x k 0 whenever since k closed set hence denominator 4 always nonzero using definition 21 easy prove index set correctly identifies active constraints x sufficiently close kkt set k theorem 22 let ae identification function k 2 exists 6 f facchinei fischer c kanzow proof since g continuously differentiable g locally lipschitzcontinuous hence exists constant c 0 x sufficiently close suppose g using 4 7 obviously sufficiently small neighborhood x dist x k aex 5 2 ax instead x 2 k x local uniqueness x definition identification function also aex also case 2 ax hand continuity 62 ax x sufficiently close x therefore 2 find 6 satisfied 2 previous theorem obvious exists open set containing k identification active constraints correct using mfcq condition obtain somewhat stronger result theorem 23 let ae identification function k mfcq condition holds ffl 0 proof previous theorem every x 2 k exists neighborhood ax collection open obviously forms open cover k since set k compact view mfcq condition extract infinite cover x 2 k finite subcover omegagamma ffl easy see theorem holds ffl min j1s fffl smfcq holds even possible identify set strongly active constraints x ie set constraints whose multipliers positive end let defined following theorem holds identification active constraints 7 theorem 24 let ae identification function k smfcq holds x ffl 0 proof first recall smfcq implies reduces singleton ie g theorem 22 shows x 0 x certain neighborhood x consider index continuity implies sufficiently small neighborhood x hand let sufficiently small neighborhood dist x k aex 2 aex means 62 sufficiently close made reference karushkuhntucker system 1 expresses first order necessary optimality conditions minimization problem p showed active constraints associated isolated stationary point x identified however fact karushkuhntucker system 1 derives optimization problem plays role theory developed actually proved following given solution x system structure system 1 isolated xpart identify suitable neighborhood solution inequalities hold equalities solution x therefore consider kkt system continuous function theory section goes without change important observation since allows us extend theory developed far identification active constraints variational inequality problem find x 2 x f x continuous continuously differentiable well known standard regularity assumption 17 necessary condition solution variational inequality problem 2 ir exists x solves system 8 fore sequence fx converging solution system 8 isolated primal part apply techniques described section order identify constraints g x 0 active 8 f facchinei fischer c kanzow 3 defining identification functions exposed previous section see crucial point identification active constraints definition identification function section show possible define function problem p consider three cases first one assume functions f g analytic second case require lc 1 also need mfcq condition second order sufficient condition optimality satisfied finally third case functions required c 2 kkt point assumed satisfy regularity condition related weaker robinsons strong regularity 33 call quasiregularity extensions results kkt system 8 possible shall point relevant changes corresponding remarks cases considered cover situations identification function defined computed certainly show definition computation identification function possible cases interest 31 analytic case let f g 2 analytic around point x recall means f g 2 possess derivatives orders agree taylor expansions around x say f g 2 analytic open set x ir n analytic around x 2 x shall make use following result due lojasiewicz luo pang 25 27 theorem 31 let denote set points ir r satisfying analytic functions defined open set suppose 6 compact ae x exist using result possible define identification function problem p theorem 32 suppose f g analytic neighborhood stationary point x function ae defined logrx rx 2 0 09 identification active constraints 9 identification function k proof obvious definition ae 1 nonnegative function lim ae 1 also continuous k hence check limit lim dist x k end recall arbitrary 0 fl 0 limit lim holds see eg 28 p 328 apply theorem 31 considering system 1 defines kkt points easy see 9 yields every given compact containing x interior fl fixed positive constants therefore write lim dist x k 11 follows taking account 12 recalling definition ae 1 noting rx continuous function goes 0 right x tends x 2 stress theorem 32 holds mere assumption f g analytic remark 33 want define identification function solutions kkt system 8 substitute definition residual 10 following one obviously also case assume f g 2 analytic neighborhood kkt point consideration f facchinei fischer c kanzow 32 second order condition case subsection assume f g lc 1 ie differentiable lipschitzcontinuous derivatives denote lagrangian problem p write r x lx gradient l respect xvariables assume mfcq holds along following second order sufficient condition optimality assumption 34 w denotes cone x r x lx denotes clarkes 8 generalized jacobian respect x gradient r x l calculated x remark functions f g twice continuously differentiable one multiplier exists previous definition reduces classical kkt secondorder sufficient condition optimality shall show two conditions allow us define identification function k mfcq holds compact set end consider perturbed nonlinear program denotes perturbation parameter follows assign vector 2 ir n theta ir particular perturbation vector purpose first define function componentwise recall phi g introduce function gammag 2 phi although general functions phi everywhere continuous following properties proved identification active constraints 11 lemma 35 2 phi x b function phi continuous k c 2 x function continuous k proof since x kkt point readily follows phi x definition function phi yields phi x 2 b let x belong k according assertion order show continuity phi x show every 2 lim easily follows definition phi sufficiently large continuity using definition phi phi k large enough thus 14 follows also case c taking account assertion kkt conditions 1 problem p yield hand analogously point phi x readily follows definition g continuity function f k follows definition assertion b order prove continuity g k let x given let sequence converging x view part c show lim end first consider index 2 hence 15 follows definition hand sufficiently large hence g k indices ie 15 holds also 62 using particular perturbation vector prove following result lemma 36 let 2 ir n theta ir arbitrarily chosen phi kkt point problem pt proof kkt system perturbed program pt reads follows 12 f facchinei fischer c kanzow let arbitrary fixed obviously since find x solves 16 17 show phi also satisfies 18 19 2 phi definition g yields gy 18 19 fulfilled instead 2 n phi follows definition phi phi 19 satisfied moreover definition g implies thus 18 also valid 2 n phi therefore conclude phi kkt point pt next result easily derived theorem 45 b formula 32 f klatte 18 functions f g program p twice continuously differentiable also obtained corresponding result robinson 34 corollary 43 note assumption 34 weakened using generalized directional derivatives see 18 details references theorem 37 let mfcq assumption 34 satisfied every 2 b ffi every kkt point xt problem pt putting together last two results easily prove following theorem theorem 38 let mfcq assumption 34 satisfied proof lemma 35 c x lemma 35 compactness k ffi theorem 37 find 0 therefore since ffl j j theorem 37 assumed without loss generality theorem 37 together lemma 36 yields desired result 2 position show function ae defined used identification function theorem 39 let mfcq assumption 34 satisfied ae 2 identification function k identification active constraints 13 proof lemma 35 easily obtain ae 2 continuous k sequence lim using theorem 38 get k sufficiently large let z 1 2 k z 2 2 k projections tively closed convex set k using triangle inequality get combining relations 21 22 obtain k sufficiently large ae 2 continuous compact set k since value 0 k follows 20 21 lemma 35 b quantity distx goes 0 k 1 right hand side 23 thus also left hand side tends infinity therefore shown ae 2 possesses properties identification function 2 instead upper lipschitzcontinuity stated theorem 37 multifunction 7 kt upper holdercontinuous known rate 2 0 1 dist xt k cktk every 2 b ffi every kkt point xt problem pt technique presented subsection easily extended define ae particular theorems 38 39 remain valid ae 2 assumption 34 replaced upper holdercontinuity interesting case possible prove assumption weaker assumption 34 upper holdercontinuity multifunction 14 f facchinei fischer c kanzow 7 kt case convex problems assume f convex g 2 concave mfcq holds following growth condition holds place assumption 34 positive exist assumptions using results 19 possible show omit details ffi exist dist xt k c ktk every 2 b ffi every kkt point xt problem pt may interesting note growth condition holds particular assumption 34 fulfilled remark 310 extension results section general kkt systems straightforward since sensitivity analysis perturbed kkt systems quires date stronger assumptions key point establish result analogous theorem 37 done easily prove theorems analogous theorem 39 substituting f rf every relevant formula example kind results obtained cite following one suppose f c 1 g c 2 assume also smfcq holds x along assumption 34 according 16 corollary 8 c theorem 37 holds therefore ae 2 regular identification function kkt system 8 33 quasiregular case subsection assume functions f g c 2 shall introduce condition call quasiregularity clear later quasiregularity related weaker robinsons strong regularity 33 order motivate definition quasiregular kkt point first recall condition equivalent notion strongly regular kkt point end shall use index set 00 0 n indices strict complementarity condition hold kkt point x j 00 empty set included introduce matrix xx l rg rg j gammarg gammarg xx l rg rg j abbreviations matrices r 2 rg x rg j x respectively following result due kojima et al 21 theorem 311 following statements equivalent identification active constraints 15 x strongly regular kkt point b j 00 empty set included determinants matrices mj nonzero sign motivated point b theorem 311 introduce following definition definition 312 kkt point x quasiregular point matrices mj nonsingular every j 00 empty set included note view theorem 311 quasiregularity implied robinsons strong regularity condition converse true fact consider following example easy check global minimizer lagrange multipliers two constraints zero therefore x 0 0 quasiregular kkt point strongly regular one note example kkt point isolated kkt point chance fact shall show section quasiregularity kkt point implies local uniqueness also worth pointing quasiregularity implies linear independence active constraints easily follows fact let us introduce operator r x lx note kkt conditions equivalent nonlinear system equations differentiability assumption phi locally lipschitzian hence rademachers theorem phi differentiable almost everywhere denote phi set points phi differentiable define bsubdifferential see eg 31 phi x f facchinei fischer c kanzow note bsubdifferential subset clarkes generalized jacobian 8 31 next lemma illustrates structure bsubdifferential phi stating lemma however introduce three index sets lemma 313 let x 2 ir nm arbitrary xx lx rgxd x x diag 1 diagonal matrices b x proof follows immediately definition operator phi 2 position prove following result lemma 314 let x nm quasiregular kkt point matrices nonsingular proof let view lemma 313 exists index set gammarg gammarg gammarg gammarg denotes complement j set fix obviously matrix nonsingular matrixb xx l rg ff rg j gammarg gammarg identification active constraints 17 nonsingular turn matrix nonsingular matrix mj nonsingular hence thesis follows immediately definition 312 2 able prove main result subsection theorem 315 let x nm quasiregular kkt point problem p x isolated kkt point b function ae 3 defined ae 3 x identification function g proof obviously ae 3 continuous nonnegative function ae 3 x furthermore since f g locally lipschitzian gradients min operator semismooth see 29 32 definition semismoothness 29 proof min operator semismooth follows also phi composite semismooth functions semismooth 29 32 hence follows lemma 314 30 proposition 3 exists constant c 0 x neighborhood x x kkt point part follows immediately 24 also get ae 3 x c therefore lim ae 3 x ie ae 3 identification function 2 remark 316 case kkt system 8 everything goes sufficient assume f continuously differentiable substitute everywhere gradient r x lx function f also case definition quasiregularity related weaker strongly regular kkt point since theorem 311 carries kkt system 8 see actually case kkt systems variational inequalities probably main case quasiregularity applied fact f facchinei fischer c kanzow difficult see strict complementarity holds x local minimum point problem p quasiregularity implies conditions previous sub section however conditions quasiregularity fairly distinct one considers variational inequalities example easily checked given variational inequality defined function f set 0g point 0 quasiregular solution satisfy conditions stated remark 310 previous subsection 4 application section apply results obtained previous sections local activeset newton algorithm solution problem p algorithm introduced simple variation one presented 12 however using new results obtained work able relax assumptions used 12 result algorithm solving linear systems iteration guarantees qquadratic convergence sequence fx k g solution mild assumptions without requiring strict complementarity remark far aware exist two algorithms ensure q quadratic convergence primal variables first one due bonnans 3 requires iteration solution quadratic possibly nonconvex subproblem furthermore algorithm bonnans also requires selection suitable solution quadratic subproblem appears difficult task practice algorithm guarantees qquadratic convergence one discussed 12 already said requires stronger assumptions refer interested reader 12 detailed discussion issues consider problem p assume f g twice continuously differen tiable algorithm consider generates sequence fx k g k obtained solving linear system z k previous system nx theta matrix defined diag i2i identification active constraints 19 shall assume licq holds x along following weak second order assumption assumption 41 holds note assumption 41 extremely weak compared second order assumptions usually used local analysis algorithms solution inequality constrained optimization problems particular even coupled linear independence assumption even imply x isolated local solution problem p checked following example nonnegative constant x 2 0 easy see stationary point satisfying licq assumption assumption 41 however 0 x local solution x indeed local solution isolated recall result illustrates properties multiplier function defined 27 theorem 42 see 26 let x kkt point linear independence active constraints holds exists ffl 1 0 x well defined b x continuously differentiable pass proof algorithm 2526 qquadratically convergent primal variables end first need simple lemma lemma 43 let x kkt pair problem p satisfies licq assumption 41 exist matrix xx lx x gammarg 0 rg 0 nonsingular kmx proof assumption 41 well known properties quadratic forms see eg 1 p 78 imply exists constant oe 0 matrix xrg 0 f facchinei fischer c kanzow positive definite continuity matrix positive definite x 2 fxg b ffl 2 sufficiently small implies see eg 1 p 78 x 2 fxg b ffl 2 therefore 29 linear independence assumption imply ffl 2 0 chosen small necessary x 2 fxg b ffl 2 rg 0 using 30 31 easy show matrix mx nonsingular hence remaining result follows continuity mx 2 theorem 44 let f g 2 twice continuously differentiable locally lipschitzcontinuous hessian matrices r 2 f r 2 g 2 let x isolated kkt pair problem p satisfies licq assumption 41 suppose identification function ae known exists system 26 nonsingular sequence fx k g produced 25 satisfies converges x rate convergence qquadratic proof us consider linear system 0 arbitrary fixed recalling r x lx 0 0 33 taking account 33 differentiability assumptions f g 2 possible show see 12 details repeated use taylors formula positive numbers ffl 3 c 1 c 2 exist x 2 fxg b ffl 3 identification active constraints 21 lemma 43 32 33 x 2 fxg b ffl 3 moreover ffl 3 0 small enough follows theorem 42 c 3 0 exists x 2 fxg b ffl 3 assume suppose ffl 3 2 0 1 chosen small enough according theorem 22 therefore setting linear systems 26 32 equivalent long x k 3436 also x k 2 fxg b ffl 3 xk relations assertions theorem easily follow induction 2 stress example section 33 satisfies assumptions previous theorem corresponding theorem 41 12 final remarks paper introduced technique accurately identify active constraints inequality constrained optimization variational inequality problems remarkable feature new identification technique identifies active constraints even strict complementarity hold furthermore discussed introduction also enjoys several favorable characteristics particu lar identification technique used combination algorithm solution inequality constrained optimization variational inequality prob lems section 4 gave example application results paper active set newtontype method however believe techniques introduced paper useful many cases especially theoretical analysis design optimization methods practical point view following questions may also interest 22 f facchinei fischer c kanzow large region exact identification occurs b build identification functions scale invariant c relax assumption x isolated stationary point still obtain useful results difficult answer questions level generality adopted paper think answer come practical experiments analysis structured classes problems eg linear quadratic problems box linearly constrained problems etc acknowledgment would like thank professor klatte helpful discussions stability kktsystems r introduction matrix analysis constrained optimization lagrange multiplier meth ods rates convergence newton type methods variational inequalities nonlinear programming identification active constraints ii nonconvex case optimization nonsmooth analysis global convergence class trust region algorithms optimization problems simple bounds study indicators identifying zero variables interiorpoint methods la sapienza quadratically superlinearly convergent algorithms solution inequality constrained minimization problems practical methods optimization necessary sufficient regularity condition bounded multipliers nonconvex programming practical optimization stability analysis variational inequalities nonlinear complementarity problems nonlinear optimization problems data perturbations quantitative stability c 1 strongly stable stationary solutions nonlinear programs uniqueness kuhn tucker multipliers nonlinear pro gramming convergence trust region algorithms optimization bounds strict complementarity hold strong stability variational inequalities sur la problem de la division new results continuously differentiable exact penalty function bounds analytic systems applications calculus semismooth semiconvex functions constrained optimiza tion nonsmooth equations motivation algorithms convergence analysis algorithms solving nonsmooth equa tions nonsmooth version newtons method strongly regular generalized equations generalized equations solution surfaces constrained optimization tr ctr wang lifeng chen guoping sequential systems linear equations method general constrained optimization without strict complementarity journal computational applied mathematics v182 n2 p447471 15 october 2005 lus n vicente stephen j wright local convergence primaldual method degenerate nonlinear programming computational optimization applications v22 n3 p311328 september 2002 huang defeng sun gongyun zhao smoothing newtontype algorithm stronger convergence quadratically constrained convex quadratic programming computational optimization applications v35 n2 p199237 october 2006 n daryina f izmailov newtontype method admissible trajectories mixed complementatiry problems automation remote control v68 n2 p351360 february 2007 christian kanzow andreas klug affinescaling interiorpoint newton methods nonlinear minimization bound constraints computational optimization applications v35 n2 p177197 october 2006 n h xiu j z zhang local convergence analysis projectiontype algorithms unified approach journal optimization theory applications v115 n1 p211230 october 2002 andreas fischer houyuan jiang merit functions complementarity related problems survey computational optimization applications v17 n23 p159182 december 2000 naihua xiu jianzhong zhang recent advances projectiontype methods variational inequalities journal computational applied mathematics v152 n12 p559585 1 march