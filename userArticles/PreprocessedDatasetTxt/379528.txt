estimating small cellloss ratios atm switches via importance sampling cellloss ratio given node atm switch defined steadystate fraction packets information lost node due buffer overflow typically small quantity hard estimate simulation cell losses rare events importance sampling sometimes appropriate tool situation however finding right change measure generally difficult article importance sampling applied estimate cellloss ratio atm switch modeled queuing network fed several sources emitting cells according markovmodulated onoff process cells source destination charge measure obtained via adaptation heuristic proposed chang et al 1994 intree networks numerical experiments confirm important efficiency improvements even large nonintree networks large number sources experiments different variants importance sampling methodology also reported number practical issues illustrated discussed b introduction asynchronous transfer mode atm communication switch modeled network queues finite buer sizes packets information called cells join network several sources according stochastic processes cells may lost due buer overflow longterm steadystate fraction cells lost given node called cellloss ratio clr node typical clrs small eg less 10 8 cell losses tend occur bunches cell losses thus rare estimating clr good precision straightforward simulation timeconsuming cases practically impossible importance sampling eg heidelberger 1995 splitting method eg glasserman et al 1999 two important candidate methods improving quality estimator situation changes probability laws governing system rare events interest occur frequently eventually point longer rare events estimator modified accordingly remains unbiased multiplied quantity called likelihood ratio hope estimator ecient sense product variance computing cost smaller regular estimator dicult problem applying general figure change probability laws variance gets reduced acceptable level theoretically always exists change measure reduces variance zero usually much complicated impractical frequently leads nonmarkovian process glynn iglehart 1989 heidelberger 1995 general background eciency improvement variance reduction refer reader bratley et al 1987 fishman 1996 glynn 1994 lecuyer 1994 well explained glynn iglehart 1989 shahabuddin 1994 heidelberger 1995 sadowsky 1996 several references given application simulation communication systems studied eg parekh walrand 1989 chang et al 1994 chang et al 1995 bonneau 1996 falkner et al 1999 heegaard 1998 chang et al 1994 derived asymptotically optimal change measure based theories eective bandwidth large deviations estimating probability p queue length exceeds given level x returning empty given queue started empty single queue multiple independent arrival sources satisfy large deviation principle roughly asymptotically optimal means standard error estimator converges zero exponentially fast decay rate exponent quantity estimated function level x precise definition found chang et al 1994 heidelberger 1995 asymptotically optimal change measure minimize variance reduce several orders magnitude chang et al 1994 extended method intree networks queues acyclic tree networks customers flow towards root tree intree networks assuming infinite buers nodes obtained lower bound exponent exponential convergence rate variance esti mator could prove estimator asymptotically optimal small cell loss ratios atm via 3 missing step proving latter show square mean converges exponentially 0 rate ie exponent faster variance related paper chang 1995 obtained exact exponent convergence rate p q x towards 0 x random variable q steadystate queue length intree queueing network infinite buers exponent linked exactly change measure chang et al 1994 probabilities p p q x described closely related clr x equals buer size measures similar events seems reasonable use change measure proposed chang et al 1994 estimate clr well fact authors applied strategy estimate steadystate average number cell losses per unit time another quantity closely related clr observed large empirical variance reductions examples queueing models single node two nodes series paper pursue experiments considering much larger networks non intree consider queueing networks large number nodes fed large number markovmodulated onoff sources 300 numerical examples nodes organized successive layers cell customer goes exactly one node layer following path uniquely determined source type queueing network models trac atm switch dabrowski et al 1999 falkner et al 1999 giroux ganti 1999 apply estimate clr prespecified node network using direct adaptation methodology chang et al 1994 idea increase trac target node increasing average onoff ratio sources feeding node exact change measure determined heuristic turns equivalent algorithm 32 chang et al 1994 neglect trac directed towards target node corresponding sources assume average arrival rate exceed service rate nodes upstream target node latter condition always satisfied examples could simply enforce choosing change measure gives arrival rate equal service rate nodes condition violated exactly algorithm 32 chang et al 1994 falkner et al 1999 proposed additional heuristic based concept decoupling bandwidth introduced de veciana et al 1994 reduce change measure eect additional trac directed towards target node may nonnegligible small large networks obtain large eciency improvements em pirically especially clr small size buer target node increases seems improve eciency factor increases exponentially buer size consistent conjecture change measure asymptotically optimal must emphasized methodology heuristic clr p ii still unproven estimator proposed chang et al 1994 asymptotically optimal p proving clr presence finite buers nodes appears quite messy iii even estimator asymptotically optimal clr would asymptotic result would necessarily imply variance reduced suciently estimator practically acceptable concrete models one interested p lecuyer champoux actual experimentation methodology examples similar reallife problems interest therefore needed see practical method whether additional heuristics improve aim present paper report experimentation examples also illustrate fact typical rareevent simulation contexts variance estimators tend noisy terms relative error mean estimators even applied one must therefore careful comparing empirical variances interpretation confidence intervals important fact typically left unmentioned papers report empirical results rareevent simulation noise variance estimator caused methodology due fact cell losses rare events fact examples improves variance estimator much larger factor mean estimator along lines results sadowsky 1993 shown context estimating large deviations probabilities sum independent identically distributed random variables much simpler situation model optimal exponentially twisted change measure stabilizes moments estimator addition asymptotically optimal results generalized abstract setup sadowsky 1996 beck et al 1999 dabrowski et al 1998 also study application discretetime queueing network model atm switch model general obtain asymptotics tail queue size distribution steadystate use propose change measure estimating clr given node methodology related dierent proposed chang et al 1994 see also section 63 limited generality model order avoid excessive notation unnecessary complexity model flexible enough illustrate strategy behaves several important situations addition basic model also made several experiments generalizations variants model proposed scheme works fine variants fails others summarized section 55 particular fact source assigned fixed destination contrast random routing cell group cells important factor success method geometric distribution periods sources implied markovmodulated model certainly always realistic statistical analyses broadband trac traces ethernet video etc indicate trac often longrange dependent representative model case obtained sojourntime distributions onoff states heavytailed eg paretotype infinite variance beran et al 1995 leland et al 1994 willinger et al 1995 neame et al 1999 unfortunately methodology used paper relies heavily exponential tails onoff distributions obvious adapted heavytailed distributions hand despite empirical evidence limited representativity markovmodulated model certain contexts remain supporters model argue based experiments networks finite buers correlations long range usually important model anyway heyman lakshman 1996 krunz makowski 1998 case small cell loss ratios atm via 5 think markovmodulated model still important model better understanding eciency improvement methods proposed remains worthwhile model defined section 2 section 3 recalls acycles method batchmeans method used jointly compute confidence intervals section 4 explain applied estimate clr given target node change measure chang et al 1994 intree networks however explanation heuristic diers authors given directly terms clr along lines arguments given heidelberger 1995 pages 6263 numerical results reported section 5 also summarize numerical experiments several variants model section 6 consider various refinements basic scheme test empirically see much additional variance reduction bring report positive negative results section 7 explains clr estimated functional form function certain parameters model section 8 gives conclusion preliminary report work presented lecuyer champoux 1996 additional numerical results details found champoux 1998 2 model consider acyclic queueing network 4 layers nodes illustrated figure 1 node singleserver fifo queue finite buer size th layer called level nodes level 4 transmit cells destinations levels 2 3 2 nodes levels 1 4 nodes level2 node fed 1 level1 nodes level3 node feeds 1 nodes level 4 cells ie packets information arrive level 1 visit one node level succession leave network node level 1 fed sources assigned specific destinations ie cells produced given source follow exactly path trajectory cell switching stage levels 2 3 thus determined fixed destination arrival sources timesynchronized otherwise independent stochastically identical discretetime onoff markov modulated processes source source produces one cell per unit time period none period durations periods independent geometric random variables means 0 1 respectively arrival rate called average burst size denote 0 1 respectively assumptions imply state source evolves discretetime markov chain two states 0 1 transition probability matrix 1 markov chains comprise stochasticity model everything else deterministic arrival sources numbered 1 nodes numbered 1 2m 2 1m 1 level level two cells reach given node simultaneously placed queue buer order p lecuyer champoux number node source come deterministic ordering rule simplification tends favor cells coming certain sources nodes one could order cells randomly instead would major qualitative impact results fig 1 atm switch modeled 4 layers queues finite buer sizes nodes level buer size b constant service time 1c c service rate whenever cell arrives node buer full lost disappears network aim estimate clr given node network say node q level clr defined nt total number cells reaching node q time interval number cells lost due buer overflow node q assume total arrival rate less service rate node cells sources pass given node level c holds nodes simplify discussion assume c integer since buers finite entire model discretetime markov chain finite state space also aperiodic zero state state sources nodes empty positive recurent accessible every state consequence exists limiting distribution state space chain defined small cell loss ratios atm via 7 integer state chain time model could course generalized several directions approach would easy adapt certain types generalizations see also section 55 example buer sizes constant service times dier nodes given level dierent sources dierent transition probability matrices r source could produce cell probability additional sources may feed nodes levels higher 1 still works situations keep simpler model avoid burying key ideas complicated notation hand destinations determined randomly independently cell period source finding ecient way applying would dicult fixed sourcedestination assignment model reasonable assume typical connection source destination lasts several orders magnitude longer service times 1c much longer time required buer overflow likely path overflow assumption commonly made literature dabrowski et al 1999 falkner et al 1999 giroux ganti 1999 switch manufacturers case 3 4 nodes level statistically identical alternative estimator would take global empirical average clr nodes level straightforward simulation approach would yield better estimator concentrating single node q according empirical investigations much better concentrate single node increase trac node latter likelihood ratio less noisy less undesired overflow nodes level 3 regeneration approach confidence intervals generally easier apply model defined short time horizon models evolution decomposed short regenerative cycles model infinite horizon decompose trajectory cycles apply generalization classical regenerative method introduced nicola et al 1993 chang et al 1994 called acycle method let subset state space system take set states buer q empty let buer q empty time time 1 successive hitting times set markov chain pair also positive recurrent aperiodic markov chain finite state space pointwise limit distribution say state chain hitting times pointwise limit distribution defined complement set process time interval i1 called ith acycle let x number cells reaching node q ith acycle number x cells lost due buer overflow q let e denote mathematical expectation acycle initial state beginning p lecuyer champoux acycle distribution one limit number acycles increases average distribution system states times approaches taking average x first n acycles one obtains consistent estimator 4 estimator biased initial state time 0 normally generated would dicult ratio estimator however bias reduced warming system eg running n 0 n acycles discarding first n 0 statistics acycles asymptotically identically distributed probability law initial state dependent reduce dependence also improve normality one batch cycles usual batch means method one applies standard methodology computing confidence interval ratio expectations using batch means observations obtain confidence interval law kelton 2000 experiments fix number cycles per batch simulation time per batch explained section 51 4 applying importance sampling small vast majority 4 0 relative error ie standard deviation divided blows 3 denominator easy estimate numerator hard estimate depends rare events fact denoting observing 1 nonnegative integer one var 1 squared relative error satisfies following chang et al 1994 use numerator 3 denominator denote set sources feeding q strategy increasing trac towards q increase r 01 r 11 matrix r sources belong total long run arrival rate q becomes larger service rate system starts empty buer q state change remains eect buer q empties overflows buer overflows r set back original sources buer q empties marks end acycle call acycle strategy trac q increased suciently cell losses longer rare events certainly achieved cardinality c service rate target node small cell loss ratios atm via 9 remains decide change r proceed standard way heidelberger 1995 realvalued parameter define let spectral radius largest eigenvalue let f 0 f 1 corresponding right eigenvector prime means transposed eigenvalue written explicitly change r stochastic matrix formulation quite flexible mean arrival rate source set arbitrary value 0 1 choosing appropriate leads important simplifications likelihood ratio acycle see given acycle let n ij number times source goes state state j using probabilities 1 total number transitions generated r n 00 n number time steps state transitions sources assumed occur right discrete times cell production number cells generated q time interval 0 thus n 01 n 11 simple counting argument assuming buer overflows time one decompose buer size q q number cells already generated way node q time q 0 corresponding number time 0 f dierence total capacity service c server q 0 actual number cells served q interval time h number cells headed q lost due buer overflow either q upstream 0 6 b number cells filling buer c f total number cells served q 0 denote transition probability source state state j r ij without transition contributes factor r ij r ij likelihood ratio associated change probabilities since n ij transitions j likelihood ratio becomes n00 r 01 r 01 r 11 n11 p lecuyer champoux n11 well known v random variable defined acycle initial state distribution e v denotes expectation probabilities r acycle initial state drawn thus computing ly 1 acycle yields unbiased estimator one always 1 eective roughly l tends small variance conditional 1 0 words would like match small values l positive values 1 ie buer overflows large values l nooverflow situations still choice disposal since unbounded random variable likely significant variance standard strategy situation eg heidelberger 1995 choose disappears l ie take gives strategy provided chang et al 1994 consider sources feed q neglect possibility arrival rate exceeds service rate upstream nodes latter condition satisfied examples considered one reduce meet condition exactly chang et al 1994 note strictly increasing dierentiable function see eg chang et al 1994 example 26 1 therefore exists c assume otherwise one cannot overload node q overflows negligible anyway unless b near 0 likelihood ratio becomes variance estimator squared relative error estimator satisfies 10 ratio expectations 10 1 cauchyschwarz inequality bounding ratio constant independent b would prove relative error bounded proof sadowsky 1991 able prove based optimal exponential twisting found solving equation similar 8 asymptotically optimal estimating p single gigim queue small cell loss ratios atm via 11 finite buer results chang et al 1994 generalize dependent interarrival times still single queue continue discussion intuitive heuristic arguments suggesting l likely small 1 0 variance ly 1 also likely small firstly since q stable without since stopped soon buer overflows 1 unlikely take large values possible prove distribution exponentially bounded tail concerning matrices r values c correspond typical examples see section 5 one usually f 0 unlikely less sources without state higher steady state probability n 01 extremely unlikely therefore seems reasonable expect w less 1 large probability small variance bounded independently fact w bounded independently b n bound large unless small suces hope large negative values rare enough negligible hope appears reasonable following reasons since sources overproducing cells headed towards q initial state time 0 follows approximately limiting distribution without one normally expect q q 0 intuitively extremely unlikely remember q 0 q total number cells upstream nodes steadystate roughly without respectively moreover since production rate sources exceeds capacity q server q expected remain idle long large positive value f unlikely since exp b constant arguments suggest l tend small 1 0 another viewpoint overflow value likely slightly smaller b ie total number cells produced 0 slightly less total service capacity c buer q empty turned suggests l tend larger 1 good news view fact crude heuristic suppose assume e 1 w 9 bounded constant k 1 independent b would give case would provide approximate variance reduction factor arguments handwaving heuristics real test see variance actually reduced concrete examples one may tempted modify scheme adaptively eg stopping earlier later order reduce variability quantity e 1 w return section 6 discussion assumed implicitly large eg bounding may expect method eventually break fixed b view fact asymptotic overflow frequency fixed b p lecuyer champoux generally diers b eg shwartz weiss 1995 courcoubetis weber 1996 compare asymptotics give numerical examples fluid source models asymptotic based large gives better approximation one based large b steadystate probability queue exceeds b asymptotic based large b overestimated probability suggests change measure use might perform poorly large b small hand large converges large b asymptotic b model empirically tried examples 50 method still worked fine also observed taking slightly less experiments tended improve eciency large see section 61 variance variance estimator without compared comparing using crude argument 11 one conjecture approximation constant k 2 independent b expect estimator less noisy without also sample variance less noisy larger factor least b large explain acycles simulated estimate numerator denominator 3 case one simulates two versions cycle one without starting initial state thus acycles come pairs ith acycle pair one first simulates acycle provides estimation l numerator l value l number cell losses cycle state system reset beginning acycle second acycle simulated obtain estimator x denominator final state nois acycle obeys approximately distribution saved taken initial state next pair acycles warmup n 0 cycles without n pairs acycles thus simulated estimator confidence interval computed using batch means explained section 3 starting two acycles pair state means must save reset entire state system cycle means copying many cells node network destinations cells state source also memorizereset state random number generator two acycles pair use common random numbers tends increase correlation l decrease variance result small cell loss ratios atm via 13 5 simulation experiments 51 setup several examples parameter sets ran simulation first using standard approach without c acycles c pairs acycles case values c c chosen total cpu time nois acycles regrouped batches sensitivity analysis respect b tried dierent values b ranging 50 3200 several examples found variance estimates practically independent b range values c c use j denote samples means x x l respectively within batch j tables follow report value clr estimator variance estimator x sxy sample means sample variances sample covariance respectively tables also report relative halfwidth 257 99 confidence interval normality assumption cpu time tcpu seconds required perform simulation relative eciency e defined values noisy estimates give good indication happens cases cell loss observed acycles simulated put entries variance eciency left blank simulation takes cpu time nois total number simulated cells relative eciency takes variance reduction overhead account beware eciencies cpu times compared within given table across tables models dierent experiments run dierent machines sun sparcstations 4 5 20 within table common random numbers used corresponding acycles across dierent lines table 52 clr estimation level 2 example 1 let vary buer 50 sources feeding target node q ie average arrival rate q 50101 0495 service rate 3 numbers compute increases total arrival rate q 0495 1448 took note cycles much longer nois average average length increases fill buer emptying whereas nois cycles buer empties cell arrivals table 1 gives results single cell loss observed estimates useless hand relative error estimators increase significantly function b 2 estimators estimate 14 p lecuyer champoux small clrs eciency decreases slowly b 2 outlier discussed later example 2 preceding example except b 2 fixed 512 vary average burst size 1 large 1 large easy estimate small 1 parameters remaining results table 2 without cell losses observed 1 100 even case ecient total arrival rate decreases 225 150 squared relative error show table approximately constant function 1 table 1 clr estimation level 2 dierent buer sizes nois 128 28e5 25e11 45 2828 00113 128 30e5 63e13 7 1675 0838 512 25e9 54e20 24 2593 0043 768 37e11 59e22 170 3108 0001 table 2 clr estimation level 2 dierent average burst sizes nois 50 25e9 54e20 24 2593 0043 100 72e5 32e12 6 2445 0659 important question arises noisy variance eciency estimates given tables one way estimating distribution variance eciency estimators bootstrap b batch means follows put b pairs table draw b random pairs table replacement compute quantities 2 e correspond sample size b repeat n times compute empirical distributions small cell loss ratios atm via 15 n values 2 e thus obtained empirical distributions bootstrap estimators distributions 2 e interval 25th 975th percentiles empirical distribution 95 bootstrap confidence interval variance eciency table 3 gives xth percentiles q x bootstrap distributions obtained results example 1 25 50 975 table 3 bootstrap quantile estimates example 1 128 43e13 62e13 88e13 023 031 042 768 36e25 59e22 18e21 24e4 37e4 37e3 already pointed low empirical eciency estimator table 1 closer look 200 batch means one j case others less 10 9 except one seems rare event happened within particular batch observe outliers values b 2 found examples although rarely excessive presence outliers indicates remains important tail distribution j despite large reduction variance outlier important eect variance eciency estimators also bootstrap distributions seen table 3 compare behavior quantiles values b 2 assess eect outlier repeated bootstrap removing sample ie 199 remaining pairs obtained following quantiles 45e24 eect significant numbers suggest variance highly overestimated eciency underestimated bootstrap distribution widely spread true distribution confirm suspicions made 5 additional replications entire experiment independently results table 4 give idea variability table 5 provides similar results 512 one see eciency estimator unfortunately noisy hand fortunately much less noisy reassuring another reassuring empirical observation distribution variance estimator skewed towards conservatism sense observed large overestimation variance like time time observe large underestimation variance moreover variance estimators tended noisy large often practice crude estimates sought eg factor 10 variance estimators may suce otherwise one must increase sample size warn reader situation change measure eective might noisy well fact happens without however never happened examples p lecuyer champoux table 4 five additional independent replications 12e11 11e24 22 3132 0044 12e11 21e24 30 3100 0023 11e11 80e25 21 3108 0048 11e11 18e24 31 3119 0022 95e12 29e25 14 3100 0101 table 5 five additional independent replications 31e9 18e19 35 2592 0020 25e9 20e20 15 2587 0115 24e9 10e20 11 2588 0223 53 clr estimation level 3 example 3 let vary buer size b 60 sources q one node level 2 fed 2 6 hot sources node levels 1 2 fed 1 total arrival rate q 621 without 50 take results appear table 6 works nicely nois observes cell loss except smallest buer size relative error relative eciency almost constant respect b example 4 preceding example except b 3 fixed 256 vary average burst size 1 table 7 gives results nois diculty observe cell losses gives reasonable estimations table 6 clr estimation level 3 dierent buer sizes nois 128 24e5 11e10 112 7036 0002 128 41e5 53e12 14 5779 0056 768 25e13 17e28 13 12930 0029 small cell loss ratios atm via 17 table 7 clr estimation level 3 dierent average burst sizes nois 100 21e5 21e10 178 1134 0007 50 60e7 72e16 11 1042 048 100 41e5 67e12 16 881 028 54 clr estimation level 4 example 5 let vary buer size b assign 6 300 sources q distributed example 3 total arrival rate q 641 without 3692 take 000 results table 8 resemble observed level 3 eciencies smaller larger network sources simulate example also varied 1 b 2 fixed 512 results qualitatively similar table 7 table 8 clr estimation level 4 dierent buer sizes nois 128 16e3 75e8 44 3580 0004 128 11e3 40e9 15 1881 015 55 variants model made several experiments variants model explore eectiveness proposed strategy sometimes realistic situations original model called variant variant b sources longer aected fixed destinations destination cell chosen randomly independently cells uniformly destinations variant c similar p lecuyer champoux except burst ie cells source given period random destination approach section 4 badly variant b gave improvement variant c small appropriate strategy models also change probabilities destinations increase trac towards q variants b c realistic atm switches next 2 variants higher practical interest variant node level 3 k buers first one receiving cells originating sources 1 second one taking sources server level 3 takes cells buers according either roundrobin longestqueuefirst policy variant e sources produce two classes cells high priority constant bit rate cbr cells low priority variable bit rate vbr cells vbr sources markov modulated whereas cbr sources constant periods completely deterministic node two buers one cbr cells one vbr cells cbr cells always served vbr ones strategy section 4 works fine variants e provides reasonable estimates values standard simulation cannot handle also observed empirical results longestqueuefirst policy gives clr generally smaller round robin 6 refining importance sampling scheme 61 optimizing approach section 4 provides good change measure based heuristic asymptotic argument necessarily optimal value given buer size moreover choosing approach take account computational costs may depend evaluate sensitivity respect performed additional experiments varied around variance eciency estimated general rule class examples examined found optimal around 20 25 less increased eciency factor 2 compared level 2 3 typically large level 1 4 usually small optimal tends much closer significantly better emphasize noise estimated factors due variance eciency estimators however tendency persisted replicated experiments moreover gives best eciency also tends reduce significantly variance variance estimator improvements important seems reasonable use eg levels 2 3 networks similar considered perhaps try optimize adaptively small neighborhood around value simulation taking smaller conservative sense produces smaller change measure using aggressive dangerous variance increases fast area may even become infinite finite next examples illustrate typical behavior levels 3 4 example 6 let small cell loss ratios atm via 19 121 node q fed 6 sources whose trac passes example 3 take results dierent values around table 9 taking improves empirical eciency factor approximately 25 compared examining data closely found eciency improves smaller gives smaller value 2 dominant term 2 replications showed similar results registering eciencies 15 60 times higher variance estimator also much less noisy value always 36 42 table 9 comparing dierent values example 7 let 2 sources feed node q sources feed node level 3 dierent nodes levels 1 2 take case 00394 found empirically taking brings significant eciency improvement made similar experiments exactly data example 5 observed eciency improvement factor 15 2 62 defining acycles dierently instead starting acycles buer q becomes empty one start number cells buer crosses upward fixed integer essentially nothing gain direction however increasing nois acycles tend become excessively long typically buer q remains nearly empty time another idea impose lower bound say 0 length acycles get rid extremely short wasteful acycles tend occur frequently nois setup acycle ends maximum time 0 first time node q becomes empty choose 0 want choose large enough make sure acycles see overflow large acycles end first return empty state overflow according arguments section 4 overflow occurs total production twisted sources time 1 approximately equal number cells required keep server busy fill buer node q p lecuyer champoux average production rate twisted source additional time 2 empty buer turned satisfy want roughly suggest taking 0 somewhere 20 50 value upper bound experiments always gave eciency improvement since variance associated cycles dominant term variance good strategy choose 0 large enough cycles fill buer taking 0 large close good idea makes us spend much time nois cycles without bringing much additional variance reduction beyond certain point increasing 0 eventually decreases eciency example 8 used data example 5 1 95 2 300 total arrival rate 182 give 1 312 table give results raising 0 0 75 increases empirical eciency approximately factor 4 raising 0 0 150 improves empirical eciency factor 10 gain related rapid increase x decreases 0 small made 2 additional replications experiment results similar although empirical eciency suggests factor eciency improvement setup around 20 30 instead 10 variance estimator also empirically much less noisy table 10 imposing lower bounds acycle lengths 50 48e5 88e13 50 81 125 7089 037 100 48e5 50e13 38 158 243 10523 043 200 49e5 76e13 45 307 325 13890 023 50 48e5 66e13 44 81 124 4646 075 100 48e5 30e13 29 157 242 7886 098 200 48e5 25e13 26 307 324 12645 075 example 9 let sources feed target node example 3 gives average arrival rate 621 0286 small cell loss ratios atm via 21 node run simulations dierent values 0 r ij associated arrival rate 500 1 85 2 150 054 total arrival rate 326 1 200 2 150 using gave best empirical eciency case 20 times empirical eciency observed 63 stopping earlier suppose use target buer q overflows turned may several cells already network previous levels may produce overflow necessary could make sense turn earlier eg total number cells buer q previous nodes way q reaches threshold n 0 beck et al 1999 dabrowski et al 1998 use criterion turning n experiments idea showed significant improvement compared method turns q overflows n seems reduce eciency instead typical illustration example 10 let sources feed node q gives arrival rate q applied arrival rate increases 15887 2 hot sources feed dierent nodes level 2 table 11 average number cell losses per cycle n turning q overflows taking n 0 520 600 appears good usual method n 0 510 definitely worse table 11 dierent stopping criteria 500 472e9 67e18 198 151 0188 3308 11 64 retroactive manipulations control overflow criterion turning earlier considered previous subsection rather blind remember randomness model state transitions sources therefore possible principle compute given point time whether overflow q caused cells generated far turn soon happens stopping time respect filtration generated trajectory way turned target buer fills overflow guaranteed occur practice implemented actually running simulation overflow turning retroactively right time 22 p lecuyer champoux cells reached q first cell overflows time say already produced source remains stopping time model retroaction would used avoid much computation time step complicated implement implies significant overhead despite spending lot time experimenting idea unsuccessful improving eciency 65 combining indirect estimation srikant whitt 1999 proposed following indirect estimator clr approach presented ward whitt keynote address 1997 winter simulation conference clr node q satisfies total average production rate 0 sources feeding node q average output rate node q 1c service time node q steadystate fraction time server busy node q second equality follows conservation equation c using 13 estimated indirectly estimating srikant whitt 1999 showed indirect estimator brings substantial variance reduction heavy trac situations especially queues several servers random service times light trac context trac q light becomes heavy applied clear us priori indirect estimator combined could help results extensive numerical experiments summarized follows single queue several servers without indirect estimator reduces variance large factors total arrival rate exceeds service capacity increases variance large factors total arrival rate much less service capacity true even constant service times singleserver queues less servers less variability service times favors direct estimator larger buer q tends accentuate factor variance reduction variance increase indirect estimator combined observed variance increase instead variance reduction even total arrival rate larger service rate intuitive explanation seems turned soon buer overflows condition favoring indirect estimator sustained overloading q hold large enough fraction time 7 functional estimation far considered problem estimating clr fixed values model parameters real life one often interested wide range values r ij buer sizes examine clr estimated functional form function matrix r single simulation also function b reusing certain portions simulation let r r r twisted version r determined section 4 suppose want estimate clr r replaced r several r neighborhood r simulating pairs acycles r r achieved follows one simulates pairs small cell loss ratios atm via 23 cycles computes x likelihood ratio l pair afterwards estimators l x numerator denominator multiplied likelihood ratios r 00 r 01 r 11 r 11 r 00 r 01 r 11 n respectively n kl n kl total number transitions sources state k state l acycle without respectively functional estimator evaluated posteriori many dierent matrices r desired long r far away r additional overhead simulation amounts storing values n kl n kl together x pairs acycles type functional estimator based likelihood ratio discussed general context rubinstein shapiro 1993 lecuyer 1993 example example 11 give example functional estimation level 4 let sources node q take r run simulation usual compute two functional estimators first one 1 fixed estimated function 0 whereas second one 1 fixed estimated function 1 tables 12 gives partial view results first estimator relative halfwidths pointwise 99 confidence interval remain reasonable good range values 0 1 one interested wider region region partitioned subintervals dierent r used subinterval estimation function b one cannot use likelihood ratio approach b parameter probability distribution model however observe acycle simulated sample path system independent b long overflow q therefore estimating several large values b initial part simulation overflow occurs repeated value one start single simulation sample path create new subpath branch time number cells q exceeds one buer sizes interest one interested n distinct values b one eventually ends n parallel simulations lot work saved starting parallel simulations needed type approach studied generality lecuyer vazquezabad 1997 experiments method savings cpu time typically around 50 p lecuyer champoux table 12 functional estimation level 4 fixed 1 500 24e6 65e14 27 588 98e7 40e15 17 714 35e7 19e16 10 800 20e7 43e17 7 909 11e7 10e17 7 development section 4 suggests approximately linear relationship least asymptotically empirical experiments confirm linear model fits well large enough b therefore recommend estimating function b perform simulations 4 5 large values b fit linear model observations b least squares regression 8 conclusion discussed implement estimating clr atm switch model direct adaptation approach proposed chang et al 1994 extensive empirical experiments large networks indicate method viable least type model examples considered improves clr estimator also improves larger factor corresponding variance estimator although variance estimator often remains noisy even case natural way improving reliability confidence intervals would increase sample size also explored heuristic refinements scheme gave improvements respect basic scheme others improved eciency clr estimator namely taking slightly less imposing lower bound acycle length also empirically reduced noise variance estimator methodology adapted variants model addition considered section 55 eg replacing geometric sojourn time distributions states distributions exponential tail statistical studies trac traces suggest heavytailed distributions infinite variance appropriate although people still argue exponentialtailed distributions job wellenough many cases scheme considered paper appear easily adaptable heavytailed distributions finding eective way applying distributions remains challenging problem r unified approach fast teller queues atm accelerated simulation leaky bucket controller guide simulation second estimation du taux de perte de reseaux atm via la simulation et le changement de mesure sample path large deviations intree networks fast simulation packet loss rates shared bu accelerated simulation atm switching fabrics decoupling bandwidths networks decomposition approach resource management fast simulation networks queues e monte carlo concepts quality service atm networks multilevel splitting estimating rare event probabilities importance sampling stochastic simulations management science fast simulation rare events queueing reliability models acm transactions modeling computer simulation implications longrange dependence vbr video trac engineering modeling video tra simulation modeling analysis third two approaches estimating gradient functional form importance sampling large atmtype queueing networks selfsimilar nature ethernet trac extended version application mpareto process modeling broadband tra fast simulation steadystate availability nonmarkovian highly dependable systems quick simulation method excessive backlogs networks queues discrete event systems sensitivity analysis stochastic optimization score function method large deviations e optimality stability exponential twisting monte carlo estimation monte carlo estimation large deviation probabilities importance sampling simulation highly reliable markovian systems large deviations performance analysis variance reduction simulations loss models tr guide simulation 2nd ed importance sampling stochastic simulations selfsimilar nature ethernet traffic extended version importance sampling simulation highly reliable markovian systems efficiency improvement variance reduction effective bandwidth fast simulation atm intree networks fast simulation rare events queueing reliability models highvariability fast simulation packet loss rates shared buffer communications switch implications longrange dependence vbrvideo traffic engineering importance sampling large atmtype queueing networks two approaches estimating gradient functional form fast simulation networks queues effective decoupling bandwidths simulation modeling analysis quality service atm networks functional estimation respect threshold parameter via dynamic splitandmerge multilevel splitting estimating rare event probabilities variance reduction simulations loss models application mpareto process modeling broadband traffic streams ctr p de boer p kroese r rubinstein rare event simulation combinatorial optimization using cross entropy estimating buffer overflows three stages using crossentropy proceedings 34th conference winter simulation exploring new frontiers december 0811 2002 san diego california rick siow mong goh ian lijin thng twolamalgamated priority queues journal experimental algorithmics jea v9 nes 2004 victor f nicola tatiana zaburnenko efficient heuristics simulation population overflow series parallel queues proceedings 1st international conference performance evaluation methodolgies tools october 1113 2006 pisa italy sandeep juneja victor nicola efficient simulation buffer overflow probabilities jackson networks feedback acm transactions modeling computer simulation tomacs v15 n4 p281315 october 2005 victor f nicola tatiana zaburnenko efficient importance sampling heuristics simulation population overflow jackson networks acm transactions modeling computer simulation tomacs v17 n2 p10es april 2007