outoforder vector architectures register renaming outoforder instruction issue commonly used superscalar processors techniques also used significant advantage vector processors paper shows performance improved available memory bandwidth used effectively using trace driven simulation compare conventional vector implementation based convex c3400 outoforder register renaming vector implementation number physical registers 12 outoforder execution coupled register renaming provides speedup 124172 realistic memory latencies outoforder techniques also tolerate main memory latencies 100 cycles performance degradation less 6 mechanisms used register renaming outoforder issue used support precise interrupts generally difficult problem vector machines precise interrupts implemented typically less 10 degradation performance new technique based register renaming targeted dynamically eliminating spill code technique shown provide extra speedup ranging 110 120 reducing total memory traffic average 1520 b introduction vector architectures used many years high performance numerical applications area still excel first vector machines supercomputers using memorytomemory operation vector machines became commercially successful addition vector registers 12 following cray1 number vector machines designed sold supercomputers high vector bandwidths 8 modest minisupercomputers recently work supported ministry education spain contract 042995 cirit grant beai96ii124 cepba work supported part nsf grant mip 9505853 value vector architectures desktop applications recognized particular many dsp multimedia applications graphics compression encryption well suited vector implementation 1 also research focusing new processormemory organizations iram 10 would also benefit vector technology studies recent years 13 5 11 however shown performance achieved vector architectures real programs falls short achieved considering available hardware resources functional unit hazards conflicts vector register file make vector processors stall long periods time result latency problems similar scalar processors time vector processor stalls memory port becomes idle memory bandwidth goes unused furthermore latency tolerance properties vectors lost first load instruction idle memory port exposes full memory latency results suggest need improve memory performance vector architectures unfortunately typical hardware techniques used scalar processors improve memory usage reduce memory latency always useful vector architectures example data caches studied 9 6 however results mixed performance gain loss depending working set sizes fraction nonunit stride memory access data caches put widespread use vector processors except cache scalar data dynamic instruction issue preferred solution scalar processors attack memory latency problem allowing memory reference instructions proceed instructions waiting memory data memory reference instructions allowed slip ahead execution instructions vector processors generally used dynamic instruction issue except one recent design nec sx4 14 reasons unclear perhaps thought inherent latency hiding advantages vectors sufficient possibly first successful vector machine cray issued instructions order additional innovations vector instruction issue simply pursued besides inorder vector instruction issue traditional vector machines relatively small number vector registers 8 typical limited number vector registers initially result hardware costs vector register instruction sets originally developed today small number registers generally recognized shortcoming register renaming useful outoforder issue come rescue well register renaming physical registers made available vector register conflicts reduced another feature traditional vector machines supported virtual memory least fully flexible manner modern scalar processors primary reason difficulty implementing precise interrupts page faults difficulty arises high level concurrency vector machines features implementingdynamic instruction issue scalars easily adapted vectors register renaming reorder buffers allow relatively easy recovery state information fault condition occurred paper show using outoforder issue register renaming techniques vector pro cessor performance greatly improved dynamic instruction scheduling allows memory latencies overlapped completely uses valuable memory resource efficiently process moreover renaming introduced architecture enables straightforward implementations precise exceptions turn provide easy way introducing virtual memory without much extra hardware without incurring great performance penalty also present new technique aimed dynamically eliminating redundant loads using technique memory traffic significantly reduced performance increased vector architectures implementation study based traditional vector processor numerical applications primarily maturity compilers availability benchmarks simulation tools feel general conclusions extend vector applications however renaming outoforder vector architecture propose modeled convex c3400 section describe base c3400 architecture implementation henceforth reference archi tecture dynamic outoforder vector architecture referred ooova 21 c3400 reference architecture convex c3400 consists scalar unit independent vector unit scalar unit executes instructions involve scalar registers isters issues maximum one instruction per cycle vector unit consists two computation units fu1 fu2 one memory accessing unit fetch decoderename unit reorder buffer released regs sregs aregs vregs maskregs figure 1 outoforder renaming version reference vector architecture mem fu2 unit general purpose arithmetic unit capable executing vector instructions fu1 unit restricted functional unit executes vector instructions except multiplication division square root functional units fully pipelined vector unit 8 vector registers hold 128 elements 64 bits eight vector registers connected functional units restricted crossbar pairs vector registers grouped register bank share two read ports one write port links functional units compiler responsible scheduling vector instructions allocating vector registers port conflicts arise reference machine implements vector chaining functional units functional units store unit chain memory loads functional units however 22 dynamic outoforder vector architecture ooova outoforder renaming version reference architecture ooova shown figure 1 derived reference architecture applying renaming technique similar found r10000 16 instructions flow inorder fetch decoderename stages go one four queues present architecture based instruction type rename stage mapping table translates virtual register physical register 4 independent mapping tables one type register v mask registers mapping table associated list free registers instructions accepted decode stage slot reorder buffer also allocated instructions enter exit reorder buffer strict program order instruction defines new logical register physical register taken issue rf alu wb aregs issue rf sregs issue rf vregs rename fetch issue rf mem range calculation dependency calculation figure 2 outoforder renaming main instruction pipelines list mapping table entry logical register updated new physical register number old mapping stored reorder buffer slot allocated instruction instruction commits old physical register returned free list note reorder buffer holds bits identify instructions register names never holds register values main pipelines four main pipelines ooova architecture see fig 2 one type instruction decoding renaming instructions wait four queues shown fig 1 v queues monitor ready status instructions held queue slots soon instruction ready sent appropriate functional unit execution processing instructions queue proceeds two phases first instructions proceed inorder 3 stage pipeline comprising issuerf stage range stage dependence stage completed three steps memory instructions proceed order based dependence information computed operand availability stores range stage range addresses potentially modified memory instruction com puted range used following stage runtime memory disambiguation range defined bytes falling base address called range start address defined called range end v l vector length register v vector stride register note multiplier simplified v l gamma 1 short never 7 bits product v kept nonarchitected register implicitly updated either vl vs modified dependence stage using range startrange end addresses memory instruction compared previous instructions found queue memory instruction free dependences proceed issue memory requests machine parameters table 1 presents latencies various functional units present architecture memory latency shown table varied memory system modeled follows single address bus shared types memory trans parameters latency scal vect intfp intfp read xbar 2 vector startup add 12 12 mul 52 52 logicshift 12 12 div 349 349 sqrt 349 349 table 1 functional unit latencies cycles two architectures 0 ooova 1 ref actions scalarvector loadstore physically separate data busses sending receiving data tofrom main memory vector load instructions gather instructions pay initial latency receive one datum memory per cycle vector store instructions result observed latency use value 50 cycles default memory latency section 43 present results effects varying value v register readwrite ports modified original c34 scheme ooova vector register 1 dedicated read port 1 dedicated port original banking scheme register file kept renaming shuffles compiler scheduled readwrite ports therefore would induce lot port conflicts instruction queues set 16 slots reorder buffer hold 64 instructions machine 64 entry btb entry 2bit saturating counter predicting outcome branches also 8deep return stack used predict callreturn sequences scalar register files 64 physical registers mask register file 8 physical registers fetch stage decode stage four queues process maximum 1 instruction per cycle committing instructions proceeds faster rate 4 instructions may commit per cycle commit strategy v registers start aggressive implementation physical registers released time vector instruction begins execution consider vector instruction add v0v1v3 rename stage v3 remapped say physical register 9 ph9 old mapping v3 say physical register 12 ph12 stored reorder buffer slot associated add instruction add instruction begins execution mark associated reorder buffer slot ready com mitted slot reaches head buffer ph12 released due semantics vector register ph12 released guaranteed instructions needing ph12 begun execution least one cycle thus first element ph12 already flowing register file read cross bar even ph12 immediately reassigned new logical register instruction starts writ insns ops avg program suite v v vect vl hydro2d spec 415 392 39738 990 101 arc2d perf 633 429 40865 985 95 flo52 perf 377 228 12420 971 54 su2cor spec 1526 268 33568 957 125 bdna perf 2390 196 15899 869 81 trfd perf 3522 495 10953 757 22 dyfesm perf 2361 330 6962 747 21 table 2 basic operation counts perfect club specfp92 programs columns 35 millions ing ph12 instructions reading ph12 least one cycle ahead always read correct values type releasing allow precise exceptions though section 5 change release algorithm allow precise exceptions assess performance benefits outoforder issue renaming vector architectures taken trace driven approach subset perfect club specfp92 programs used benchmark set programs compiled convex c3480 machine tool dixie 3 used modify executable tracing executables processed dixie modified executables run convex machine runs produce desired set traces accurately represent execution programs trace fed two simulators reference ooova architectures 31 benchmark programs interested benefits outof order issue vector instructions selected benchmark programs highly vectorizable programs perfect specfp92 benchmarks chose 10 programs achieve least 70 vec torization table 2 presents statistics selected perfect club specfp92 programs column number 2 indicates suite program belongs next two columns present total number instructions issued decode unit broken scalar vector instructions column five presents number operations performed vector instructions sixth column percentage vectorization program ie column five divided sum columns three five finally column seven presents average vector length used vector instructions ratio columns five four respectively hydro2d10003000 execution cycles dyfesm5001500 figure 3 functional unit usage reference ar chitecture bar represents total execution time program given latency values xaxis represent memory latencies cycles performance results 41 bottlenecks reference archi tecture first present analysis execution ten benchmark programs run reference architecture simulator consider three vector functional units reference architecture fu2 fu1 mem machine state represented 3tuple captures individual state three units given point time example 3tuple represents state units working represents state vector units idle figure 3 presents execution time two ten benchmark programs see 4 8 pro grams space limitations prevents us providing two hydro2d dyfesm rep resentative execution programs eight possible states plotted time spent state memory latencies 1 20 70 100 cycles figure see number cycles programs proceed peak floating point speed states hfu2 fu1mem low number cycles states changes relatively little memory latency increases fraction fully used cycles decreases memory latency high impact total execution time programs dyfesm shown figure 3 trfd flo52 shown relatively small vector lengths effect memory latency seen noting increase cycles spent state h sum cycles corresponding states mem unit idle quite high programs four states correspond cycles mem swm256 hydro2d arc2d flo52 nasa7 su2cor tomcatv bdna trfd dyfesm2060 idle memory port 170 figure 4 percentage cycles memory port idle 4 different memory latencies ory port could potentially used fetch data memory future vector computations figure 4 presents percentage cycles total execution time latency 70 port idle time ranges 30 65 total execution time benchmark programs memory bound run single port vector machine two functional units therefore unused memory cycles result lack loadstore work done 42 performance ooova section present performance ooova compare reference archi tecture consider overall performance speedup memory port occupation effects adding outoforder execution renaming reference architecture seen figure 5 program plot speedup reference architecture number physical vector registers varied 9 64 memory latency set 50 cycles graph show speedup two ooova implementations ooova 16 length 16 instruction queues ooova 128 length 128 queues also show maximum ideal speedup theoretically achieved ideal along top graph compute ideal speedup program use total number cycles consumed heavily used vector unit fu1 fu2 mem thus ideal essentially eliminate data memory dependences program consider performance limited saturated resource across entire execution seen figure 5 ooova significantly increases performance reference chine physical registers lowest speedup 124 tomcatv highest speedups trfd dyfesm 172 170 resp remaining programs give speedups 13145 numbers physical registers greater 16 additional speedups generally small largest speedup going physical registers bdna additional improvement 83 improvement bdna due extremely large main loop generates sequence basic blocks 800 vector instructions physical registers allow better match large available ilp basic blocks hand number physical vector registers major concern observe 12 physical registers still give speedups 163 170 trfd dyfesm programs range 123 138 results suggest physical vector register 12 registers sufficient cases file 16 registers enough sustain high performance every case increase depth instruction queues 128 performance improvement quite small curve ooova128 analysis programs shows two factors combine prevent improvements increasing number issue queue slots first spill code present large basic blocks induces lot memory conflicts memory queue second lack scalar registers sometimes prevents dynamic unrolling enough iterations vector loop make full usage memory port memory outoforder issue feature allows memory access instructions slip ahead computation instructions resulting compaction memory access opera tions presence fewer wasted memory cycles shown figure 6 figure contains number cycles address port idle divided total number execution cycles bars reference machine ref outoforder machine ooova shown ooova machines physical vector registers memory latency 50 cycles ooova fraction idle memory cycles cut half cases two benchmarks memory port idle less 20 time resource usage consider resource usage ooova machine compare reference machine illustrated figure 7 notation figure 3 used representing execution state previous subsections ooova machine physical vector registers memory latency set 50 cycles figure 7 shows major improvement state h almost disappeared also fullyutilized state hfu2 fu1mem relatively frequent due benefits outof order execution already seen availability one memory instruction ready launched memory queues allows much higher usage memory port 43 tolerance memory latencies one way looking advantage outoforder execution register renaming allows long 1113 9 arc2d129 flo521216 9 nasa71216 9 trfd15speedup 9 ideal ooova128 figure 5 speedup ooova ref architecture different numbers vector physical registers swm256 hydro2d arc2d flo52 nasa7 su2cor tomcatv bdna trfd dyfesm103050 idle memory ref ooova figure percentage idle cycles memory port reference architecture ooova archi tecture memory latency 50 cycles vector register file holds physical vector registers memory latencies hidden previous subsections showed benefits ooova fixed memory latency 50 cycles subsection consider ability ooova machine tolerate main memory latencies figure 8 shows total execution time ten programs executed reference machine ooova machine memory latencies 1 50 100 cycles results 16 physical vector registers shown figure reference machine sensitive memory latency even though vector machine memory latency influences execution time considerably hand ooova machine much tolerant hydro2d dyfesm51525 execution cycles figure 7 breakdown execution cycles ref left bar ooova right bar machines ooova machine 16 physical vector registers architectures memory latency set 50 cycles crease memory latency benchmarks performance flat entire range memory la tencies 1 100 cycles another important point even memory latency 1 cycle ooova machine typically obtains speedups reference machine range 115125 goes high 15 case dyfesm speedup indicates effects looking ahead instruction stream good even absence long latency memory operations end scale see long memory latencies easily tolerated using oforder techniques indicates individ 5cycles x cycles x trfd15cycles x dyfesm10ref ideal figure 8 effects varying main memory latency three memory models 16 physical vector registers machines ual memory modules memory system slowed changing expensive sram parts much cheaper dram parts without significantly degrading total throughput type technology change could major impact total cost machine typically dominated cost memory subsystem 5 implementing precise traps important side effect introducing register renaming vector architecture enables straightforward implementation precise exceptions turn availability precise exceptions allows introduction virtual memory virtual memory implemented vector machines 15 used many current high performance parallel vector processors 7 used restricted form example locking pages containing vector data memory vector program executes 7 14 primary problem implementing precise page faults high performance vector machine high number overlapped inflight operations machines may several hundred vector register renaming provides convenient means saving large amount machine state required rollback precise state following page fault exception contents old logical vector registers kept instruction overwriting logical register known free exceptions architected state restored needed order implement precise traps introduce two changes ooova design first instruction allowed commit fully completed opposed early commit scheme using second stores allowed execute update memorywhen head reorder buffer oldest uncommitted instructions figure 9 presents comparison speedups reference architecture achieved ooova early commit labeled early ooova late commit execution stores head reorder buffer labeled late simulations performed memory latency 50 cycles make two important observations graphs figure 9 first performance degradation due introduction late commit model small eight ten programs programs hydro2d arc2d su2cor tomcatv bdna degrade less 5 physical registers programs flo52 nasa7 degrade 7 103 respectively nevertheless performance two programs trfd dyfesm hurt rather severely going late commit model 41 47 degradation respectively behavior explained loadstore dependences main loop trfd memory dependence last vector store iteration first vector load iteration address early commit model store done soon input data ready chaining producer store late commit model store must wait 2 intervening instructions producer store committed delays dispatching following load first iteration explains high slowdown similar situation explains degradation dyfesm second late commit model 12 registers 1113 9 arc2d129 flo521216 9 nasa71216 9 trfd15speedup 9 ideal late figure 9 speedups ooova reference architecture different numbers vector physical registers early late commit schemes clearly enough performance difference 12 16 registers much larger early commit model thus costcomplexity point view introduction late commit clear impact implementation vector registers 6 dynamic load elimination register renaming many physical registers solves instruction issue bottlenecks caused limited number logical registers however another problem caused limited logical registers register spilling original compiled code still contains register spills caused limited number architected registers functionally correct spills must executed furthermore besides obvious storeload spills limited registers also cause repeated loads memory location limited registers common vector architec tures spill problem aggravated storing reloading single vector register involves movement many words data memory illustrate importance spill code vector ar chitectures table 3 shows number memory spill operations number words moved ten benchmark programs benchmarks relatively loads stores due spills several large amount spill traffic ex ample 69 memory traffic bdna due spills section propose study method uses register renaming eliminate much memory load traffic due spills method propose also significant performance advantages vector load ops vector store ops total program load spill store spill hydro2d 1297 21 16 431 21 5 24 arc2d 1244 122 9 479 87 15 11 nasa7 1048 21 20 632 20 3 24 su2cor 786 201 20 404 103 20 20 bdna 142 266 table 3 vector memory spill operations columns 2 3 5 6 millions operations load spilled data executed nearly zero time eliminate spill stores however need maintain strict binary compatibility memory image reflect functionally correct state relaxing compatibility could lead removing spill stores yet pursued approach 61 renaming dynamic load elim ination eliminate redundant load instructions propose following technique tag associated physical register v tag indicates memory locations currently held register vector registers tag 6tuple define consecutive region bytes memory vl vs sz vector length vector stride access granularity used tag created v validity bit scalar registers tag 4tuple vl vs needed although problem spilling scalar registers somewhat tangential study important convex architecture limited number registers time memory operation performed range addresses computed done second stage memory pipeline operation load tag associated destination physical register filled appropriate address informa tion operation store physical register stored memory tag updated corresponding address information thus time memory operation performed alias register contents memory addresses used loading storing physical register tag indicates area memory matches register data keep tag contents consistent memory store instruction executed tag compared tags already present register files conflict found memory range defined store tag overlaps existing tags existing tags must invalidated simplify conflict checking hardware invalidation may done conservatively using register tags vector load operations eliminated following manner vector load enters third stage memory pipeline tag checked tags found vector register file exact match found exact match requires tag fields identical destination register vector load renamed physical register matches point load effectively completed time takes rename furthermore matching restricted live registers also occur physical register free list long validity bit set register free list use eligible matching load matches register free list register taken list added register map table scalar registers eliminating loads simpler match involving two scalar registers de tected register value copied one register scalar rename table affected note however scalar store addresses still need compared vector register tags vector stores need compared scalar tags ensure full consistency similar memory tagging technique scalar registers described 2 tagging used store memory variables registers face potential aliasing problems approach though complicated data automatically copied register register tag match found fore compiler techniques required adapt implied data movement application tag operation either alters rename table b invalidates tag without changing register value issue rf alu wb aregs issue rf sregs rename fetch issue rf calculation range dependency calculation vregs vrename rxbar rxbar ex0 figure 10 modified instruction pipelines dynamic load elimination ooova 62 pipeline modifications scheme described vector load eliminated disambiguation stage memory pipeline vector register renaming table dated renaming considerably complicated vector registers renamed two different pipeline stages decode disambiguation stages therefore pipeline structure modified rename vector registers one one stage figure shows modified pipeline decode stage scalar registers renamed vector registers left untouched instructions using vector register pass inorder 3 stages memory pipeline arrive disambiguation stage renaming vector registers done ensures vector instruction see renaming table modifications introduced load elimination scheme available following vector instructions moreover ensures store tags compared previous tags order 63 performance dynamic load elimina tion section present performance ooova machine enhanced dynamic load elimi nation baseline use late commit ooova described without dynamic load elimination also study ooova load elimination scalar data sle ooova load elimination scalars vectors slevle figures 11 12 present speedup sle slevle baseline ooova different numbers physical vector registers 16 32 64 slevle 16 vector registers figure 12 speedups base ooova 104 116 programs high 178 213 dyfesm trfd registers registers available storage space keeping vector data doubles allows tag matchings speedups increase significantly range programs 110 120 dyfesm trfd speedups remain high appreciably improve going 16 registers doubling number vector registers 64 yield much additional speedup swm256 hydro2d arc2d flo52 nasa7 su2cor tomcatv bdna trfd dyfesm1113 figure 11 speedup sle ooova machine 3 different physical vector register file sizes swm256 hydro2d arc2d flo52 nasa7 su2cor tomcatv bdna trfd dyfesm15speedup figure 12 speedup slevle ooova machine 3 different physical vector register file sizes programs improvement 5 tomcatv trfd seem able take advantage extra registers tomcatv goes 119 140 results show data movement eliminated captured vector registers remarkably different performance behavior dyfesm trfd requires explanation done looking sle figure 11 sle programs low speedups less yet trfd dyfesm achieve speedups 136 respectively configuration vector registers analysis two programs shows ability bypass scalar data allows programs see iterations certain loop particular ability bypass data loads stores allows unroll two critical loops whereas without sle unrolling possible 64 traffic reduction important effect dynamic load elimination reduces total amount traffic seen memory system important feature swm256 hydro2d arc2d flo52 nasa7 su2cor tomcatv bdna trfd dyfesm08traffic reduction sle figure 13 traffic reduction dynamic load elimination physical vector registers multiprocessing environments less load memory modules usually translates overall system performance improvement computed traffic reduction programs two dynamic load elimination configurations considered define traffic reduction ratio total number requests load stores sent address bus baseline ooova divided total number requests done either sle slevle configurations figure 13 present ratio physical vector registers example figure 13 shows us sle configuration dyfesm performs 11 fewer memory requests ooova configuration seen slevle typical traffic reduction 15 20 programs dyfesm trfd due special behavior already men tioned much larger reductions much 40 summary paper considered usefulness outoforder execution register renaming vector architectures seen simulation traditional inorder vector execution model enough fully use bandwidth single memory port cover main memory latency even considering programs memory bound shown outoforder issue register renaming introduced vector performance increased performance advantage realized even adding extra physical registers used renaming outof order execution useful vector processor widely recognized current superscalar microprocessors using 12 physical vector registers aggressive commit model shown significant speedups reference machine modest cost 16 vector registers range speedups 124172 increasing number vector registers 64 lead significant extra improve ments however moreover shown large memory latencies 100 cycles easily tolerated dynamic reordering vector instructions disambiguation mechanisms introduced allow memory unit send continuous flow requests memory system flow overlapped arrival data covers main memory latency introduction register renaming gives powerful tool implementing precise exceptions changing aggressive commit model conservative model instruction commits predecessors known free exceptions recover architectural state point time allows easy introduction virtual memory simulations shown implementation precise exceptions costs around 10 application performance though programs may much sensitive others one problem solved register renaming register spilling addition extra physical registers per se reduce amount spilled data introduced new technique dynamic load elimination uses renaming mechanism reduce amount load spill traffic tagging registers memory information detect certain load redundant required data already physical register conditions load performed simple rename table change simulations shown technique improve performance typically factors 107116 high 178 dynamic load elimination technique benefit physical registers since cache data inside vector register file simulations physical vector registers show load elimination yields improvements typically range 110120 moreover registers load elimination reduce total traffic memory system factors ranging 1520 cases 40 finally feel results use growing community processor architectures implementing kind multimedia extensions graphics coprocessors dsp functions incorporated general purpose microprocessors advantages vector instruction sets become evident order sustain high throughput special purpose devices frame buffers long memory latencies tolerated types applications generally require high bandwidths chip memory system available current microprocessors bandwidth latency problems outoforder vector implementations help achieve improved performance r t0 vector microprocessor new kind memory referencing arrays pointers dixie trace generation system c3480 decoupled vector architectures quantitative analysis vector code performance impact vector processor caches parallel processing feature nec sx3 supercomputer system cache performance vector supercomput ers case intelligent dram iram relationship average real memory behavior cray1 computer system explaining gap theoretical peak performance real performance supercomputer architectures hnsx supercomputers inc architecture vpp500 parallel supercomputer mips r10000 superscalar microprocessor tr cregs new kind memory referencing arrays pointers distributed storage control unit hitachi s3800 multivector supercomputer cache performance vector supercomputers architecture vpp500 parallel supercomputer relationship average real memory behavior explaining gap theoretical peak performance real performance supercomputer architectures cray1 computer system mips r10000 superscalar microprocessor decoupled vector architectures quantitative analysis vector code ctr roger espasa mateo valero exploiting instruction datalevel parallelism ieee micro v17 n5 p2027 september 1997 luis villa roger espasa mateo valero performance study outoforder vector architectures short registers proceedings 12th international conference supercomputing p3744 july 1998 melbourne australia mark hampton krste asanovi implementing virtual memory vector processor software restart markers proceedings 20th annual international conference supercomputing june 28july 01 2006 cairns queensland australia christos kozyrakis david patterson overcoming limitations conventional vector processors acm sigarch computer architecture news v31 n2 may francisca quintana jesus corbal roger espasa mateo valero adding vector unit superscalar processor proceedings 13th international conference supercomputing p110 june 2025 1999 rhodes greece francisca quintana jesus corbal roger espasa mateo valero cost effective architecture vectorizable numerical multimedia applications proceedings thirteenth annual acm symposium parallel algorithms architectures p103112 july 2001 crete island greece karthikeyan sankaralingam stephen w keckler william r mark doug burger universal mechanisms dataparallel architectures proceedings 36th annual ieeeacm international symposium microarchitecture p303 december 0305 christopher batten ronny krashinsky steve gerding krste asanovic cache refillaccess decoupling vector machines proceedings 37th annual ieeeacm international symposium microarchitecture p331342 december 0408 2004 portland oregon banit agrawal timothy sherwood virtually pipelined network memory proceedings 39th annual ieeeacm international symposium microarchitecture p197207 december 0913 2006 roger espasa mateo valero simulation study decoupled vector architectures journal supercomputing v14 n2 p124152 sept 1999 christoforos kozyrakis david patterson vector vs superscalar vliw architectures embedded multimedia benchmarks proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey roger espasa mateo valero james e smith vector architectures past present future proceedings 12th international conference supercomputing p425432 july 1998 melbourne australia jesus corbal roger espasa mateo valero mom matrix simd instruction set architecture multimedia applications proceedings 1999 acmieee conference supercomputing cdrom p15es november 1419 1999 portland oregon united states