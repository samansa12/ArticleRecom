fast flexible word searching compressed text present fast compression technique natural language texts novelties 1 decompression arbitrary portions text done efficiently 2 exact search words phrases done compressed text directly using known sequential patternmatching algorithm 3 wordbased approximate extended search also done efficiently without decoding compression scheme uses semistatic wordbased model huffman code coding alphabet byteoriented rather bitoriented compress typical english texts 30 original size 40 35 compress gzip respectively compression time close compress approximately half time gzip decompression time lower gzip one third compress present three algorithms search compressed text allow large number variations basic word phrase search capability sets characters arbitrary regular expressions approximate matching separators stopwords discarded search time without significantly increasing cost searching simple words experiments show running algorithms compressed text twice fast running best existing software uncompressed version text searching complex approximate patterns algorithms 8 times faster search uncompressed text also discuss impact technique inverted files pointing logical blocks argue possibility keeping text compressed time decompressing displaying purposes b introduction paper present efficient compression technique natural language texts allows fast flexible searching words phrases search simple words phrases patterns compressed search proceeds without decoding compressed text searching words phrases match complex expressions andor allowing errors done compressed text almost cost simple searches reduced size compressed text makes overall searching time much smaller plain uncompressed text compression decompression speeds amount compression achieved good compared well known algorithms literature ziv lempel 1977 ziv lempel 1978 compression scheme presented paper variant wordbased huffman code bentley et al 1986 moffat 1989 witten et al 1999 huffman codeword assigned text word sequence whole bytes huffman tree degree either 128 call tagged huffman code 256 call plain huffman code instead 2 tagged huffman coding byte uses 7 bits huffman code 1 bit signal beginning codeword show later using bytes instead bits significantly degrade amount compression practice byte processing much faster bit processing bit shifts masking operations necessary compression decompression search times decompression start point compressed file particular compression scheme allows fast decompression fragments contain search results important feature information retrieval systems notice compression scheme designed large natural language texts containing least 1 megabyte achieve attractive amount compression also search algorithms word oriented pattern sequence elements matched sequence text words pattern element simple word complex expression search exact allowing errors match context present three search algorithms first algorithm based tagged huffman coding compresses pattern searches compressed pattern directly compressed text search start point compressed text bytes start codeword marked highest bit set 1 conventional pattern matching algorithm used exact searching multipattern matching algorithm used searching allowing errors explained later second algorithm searches plain huffman code based wordoriented shiftor algorithm baezayates gonnet 1992 case com fast flexible word searching compressed text delta 3 pression obtained better tagged huffman code search algorithm need special marks compressed text third algorithm combination previous ones pattern compressed directly searched text first algorithm based tagged huffman coding however works plain huffman code signal codeword beginnings therefore second algorithm used check surrounding area order verify validity matches found three algorithms allow large number variations basic word phrase searching capability group generic name extended patterns result classes characters including character ranges com plements wild cards arbitrary regular expressions efficiently searched exactly allowing errors occurrences separators common words stopwords discarded without significantly increasing search cost algorithms also allow approximate phrase matching able search compressed text approximate occurrences phrase pattern allowing insertions deletions replacements words approximate phrase matching capture different writing styles therefore improve quality answers query algorithms able perform type search cost cases extremely difficult uncompressed search technique useful speed sequential search also used improve indexed schemes combine inverted files sequential search like glimpse manber wu 1993 fact techniques present nicely integrated inverted file technology obtain lower spaceoverhead indexes moreover argue favor keeping text compressed time text compression cannot considered extra effort anymore algorithms presented paper used software package called cgrep cgrep exact approximate compressed matching tool large text collections software available ftpdccufmgbrlatincgrep prototype preliminary partial versions article appeared moura et al 1998a moura et al 1998b paper organized follows section 2 discuss basic concepts present related work found literature section 3 present compression decompression method followed analytical experimental results section 4 show perform exact extended searching tagged huffman compressed texts section 5 show perform exact extended searching plain huffman compressed texts section 6 present experimental results search performance finally section 7 present conclusions suggestions future work 2 basics related work text compression exploiting redundancies text represent less space bell et al 1990 paper denote uncompressed file length bytes u compressed file denoted z length bytes n compression ratio used paper denote size compressed file percentage uncompressed file ie 100 theta nu many existing compression techniques known literature emphasize two relevant paper first technique interest de moura g navarro n ziviani r baezayates zivlempel family compression algorithms repeated substrings arbitrary length identified text repetitions replaced pointers previous occurrences methods possible achieving u even best cases second technique call zeroorder substitution methods text split symbols symbol represented unique codeword compression achieved assigning shorter codewords frequent symbols best known technique kind minimum redundancy code also called huffman code huffman 1952 huffman coding codeword symbol sequence bits codeword prefix another codeword total length compressed file minimized zeroorder substitution methods even though constant smaller 1 moreover thetau symbols text u characters bytes thetan codewords compressed text n bytes work example use ou denote number words compressed matching problem first defined work amir benson amir benson 1992 task performing string matching compressed text without decompressing given text corresponding compressed string z uncompressed pattern p length compressed matching problem consists finding occurrences p using p z naive algorithm first decompresses string z performs standard string matching takes time oum optimal algorithm takes worstcase amir et al 1996 new criterion called extra space evaluating compressed matching algorithms introduced according extra space criterion algorithms use extra space optimally om addition nlength compressed file first compressed pattern matching algorithms dealt zivlempel compressed text farach thorup 1995 presented compressed matching algorithm lz1 classic compression scheme ziv lempel 1976 runs log 2 unm time amir et al 1996 compressed matching algorithm lz78 compression scheme presented finds first occurrence space log mm time space extension amir et al 1996 multipattern searching presented kida et al 1998 together first experimental results area new practical results appeared navarro raffinot 1999 presented general scheme search zivlempel compressed texts simple extended patterns implemented particular cases lz77 lz78 new variant proposed competitive convenient search purposes similar result restricted lzw format independently found presented kida et al 1999 finally kida et al 1999 generalized existing algorithms nicely unified concepts general framework empirical results obtained roughly coincide general figure searching zivlempel compressed text take half time decompressing text searching however compressed search twice slow searching uncompressed version text search algorithms useful text kept compressed anyway give extra reason compress compression ratios 30 40 practice fast flexible word searching compressed text delta 5 text compressed using zivlempel second paradigm zeroorder substitution methods explained model therefore theoretical definition compressed pattern matching makes little sense based distinguishing ou time goals well existing approaches practical search directly compressed text faster uncompressed text taking advantage smaller size first text compression scheme allowed direct searching compressed text proposed manber manber 1997 approach packs pairs frequent characters single byte leading compression ratio approximately 70 typical text files particularly successful trend inside zeroorder substitution methods huffman coding text words considered symbols compose text semistatic version model used frequencies text symbols learned first pass text text coded second pass table codewords assigned symbol stored together compressed file model better suited typical information retrieval scenarios large text databases mainly data structures shared vocabulary text almost symbol table compressor local decompression efficient better compression faster search algorithms obtained possible search faster compressed uncompressed text need two passes text normally already present indexing text information retrieval applications overhead storing text vocabulary negligible large texts hand approach limited wordbased searching large natural language texts unlike zivlempel approach paradigm belongs turpin moffat 1997 work developed independently work paper presents algorithm search texts compressed wordbased huffman method allowing exact searching oneword pat terns idea search compressed pattern codeword compressed text work based similar idea uses bytes instead bits coding alphabet use bytes presents small loss compression ratio gains decompression search efficiency large also extend search capabilities phrases classes characters wild cards regular expressions exactly allowing errors also called approximate string matching approximate string matching problem find substrings text database given distance k less pattern p distance two strings minimum number insertions deletions substitutions single characters strings needed make equal case corresponds classical exact matching problem approximate string matching particularly interesting case extended pattern searching technique useful recover typing spelling optical character recognition errors problem searching pattern compressed text allowing errors open problem amir et al 1996 partially solve problem since allow approximate word searching find text words match pattern word k errors note limitations 6 delta e de moura g navarro n ziviani r baezayates statement single error inserts space middle flower result sequence two words flo wer none retrieved pattern flowers allowing one error similar problem appears space deletion converts many flowers single word best known software search uncompressed text without errors agrep wu manber 1992 show compressed pattern matching algorithms compare favorably agrep 8 times faster depending type search pattern course agrep limited word searching need compress file prior searching however last argument fact used direction argue thanks search algorithms new techniques update compressed text text files kept compressed time decompressed displaying purposes leads economy space improved overall efficiency experimental results paper used natural language texts trec collection harman 1995 chosen following texts ap newswire 1989 doe short abstracts doe publications fr federal register 1989 wsj wall street journal 1987 1988 1989 ziff articles computer selected disks ziffdavis publishing table 1 presents statistics five text files considered word contiguous maximal string characters set fa z z 0 9g tests run sun sparcstation 4 96 megabytes ram running solaris 251 files text vocabulary vocabtext size bytes words size bytes words size words ap 237766005 38977670 1564050 209272 065 053 doe 181871525 28505125 1949140 235133 107 082 wsj 262757554 42710250 1549131 208005 059 048 ziff 242660178 39675248 1826349 255107 075 064 table 1 statistics text files used trec collection 3 compression scheme general compression methods typically adaptive allow compression carried one pass need keep separately parameters used decompression time however natural language texts used fulltext retrieval context adaptive modeling effective compression technique following moffat 1989 witten et al 1999 chose use wordbased semistatic modeling huffman coding huffman 1952 semistatic model encoder makes first pass text obtain frequency different text word performs actual compression second pass one strong reason using combination modeling coding data structures associated include list words compose vocabulary text use derive compressed matching algorithm important fast flexible word searching compressed text delta 7 rose00000 rose rose rose original text compressed text fig 1 canonical tree compression example using binary huffman coding spaceless words reasons text retrieval applications decompression faster semistatic models compressed text accessed randomly without decompress whole text adaptive methods furthermore previous experiments shown wordbased methods give good compression ratios natural language texts bentley et al 1986 moffat 1989 horspool cormack 1992 since text composed words also separators model must also chosen moffat 1989 bell et al 1993 two different alphabets used one words one separators since strict alternating property holds confusion alphabet use known text starts word separator use variant method deal words separators call spaceless words word followed space encode word encode word separator decoding time decode word assume space follows except next symbol corresponds separator case alternating property hold single coding alphabet used idea firstly presented moura et al 1997 shown spaceless word model achieves slightly better compression ratios figure 1 presents example compression using huffman coding spaceless words method set symbols case fa rose tg whose frequencies 2 1 1 1 3 1 respectively number huffman trees given probability distribution quite large preferred choice applications canonical tree defined schwartz kallick schwartz kallick 1964 huffman tree figure 1 canonical tree allows efficiency decoding time less memory requirement many properties canonical codes mentioned hirschberg lelewer 1990 zobel moffat 1995 witten et al 1999 31 byteoriented huffman code original method proposed huffman huffman 1952 mostly used binary code symbol input stream coded sequence bits work huffman codeword assigned text word sequence whole bytes huffman tree degree either 128 case eighth de moura g navarro n ziviani r baezayates bit used special mark aid search 256 instead 2 cases except otherwise stated consider words separators text symbols separators codified using spaceless word model canonical trees used symbol table vocabulary different text words separators kept compressed using classical binary huffman coding characters define different types huffman codes used work adhere points binary huffman code sequence bits assigned word separator byte huffman code sequence bytes assigned word separator encompasses two coding schemes follow plain huffman code byte huffman coding bits bytes used huffman tree degree 256 tagged huffman code byte huffman coding 7 lower order bits byte used huffman tree degree 128 highest bit byte used follows first byte codeword highest bit 1 bytes highest bit 0 useful direct searching compressed text explained later techniques efficient encoding decoding mentioned zobel moffat 1995 easily extended case show later experimental results section significant degradation compression ratio experienced using bytes instead bits hand decompression byte huffman code faster decompression binary huffman code practice byte processing much faster bit processing bit shifts masking operations necessary decoding time searching time 32 compression ratio section consider compression ratios achieved scheme first concern huffman coding needs store together compressed file table text symbols use word compression table precisely vocabulary text set different text words table principle large ruin overall compression ratio however case large texts heaps law heaps 1978 empirical law widely accepted information retrieval establishes natural language text ou words vocabulary size typically fi 04 06 araujo et al 1997 moura et al 1997 therefore v close u hence large texts overhead storing vocabulary minimal hand storing vocabulary represents important overhead text small chose compress vocabulary symbol table using classical binary huffman characters shown figure 2 fact makes compressor better gzip files least 1 megabyte instead fast flexible word searching compressed text compression file sizemegabytes plain huffman uncompressed vocabulary plain huffmancompressed vocabulary compress gzip fig 2 compression ratios wsj file compressed gzip compress plain huffman without compressing vocabulary need decompress vocabulary search time poses minimal processing overhead even completely compensated reduced io second concern whether compression ratio cannot worsen text grows since model number symbols v grows albeit sublinearly text grows could possible average length code symbol grows key prove happen show distribution words text biased enough entropy 2 o1 show huffman codes put constant overhead entropy final step done dary huffman codes includes 7bit tagged 8bit cases use zipfs law zipf 1949 model frequency words appearing natural language texts law widely accepted information retrieval states order v words natural language text decreasing order probability probability first word times probability ith word every means probability ith word 1j constant depends text zipfs law comes two flavors simplified form assumes case v although simplified form popular simpler handle mathematically follow well real distribution natural language texts strong evidence real texts fact biased vocabulary performed araujo et al 1997 thorough set experiments trec collection finding values roughly 15 20 depending text gives experimental evidence favor generalized zipfs law ie 1 assumption 1 reason zivlempel compressors improve larger texts part search repetitions relatively short window text already seen hence prevented exploiting already processed part text estimate zeroorder wordbased binary entropy text gamma relative frequency ith vocabulary word simplicity call measure entropy paper de moura g navarro n ziviani r baezayates tested distribution separators well finding also follow reasonably well zipfs distribution moreover distribution even biased words closer 19 therefore assume words since analogous proof hold separators hand refined versions zipfs law exist mandelbrot distribution gonnet baezayates 1991 law tries improve fit zipfs law frequent values however mathematically harder handle alter asymptotic results follow analyze entropy ed distribution vocabulary v words digits used coding alphabet follows log dp log bounding summation integral allows us conclude ed o1 log h also o1 used simple zipfs law instead result would ed olog v ie average codeword length would grow text grows fact happen 1 gigabyte text independent experimental confirmation validity generalized zipfs law simple version consider overhead huffman coding entropy huffman coding optimal inability represent fractional parts bits symbol probability p use exactly log 2 1p bits represent symbol possible p power 12 effect gets worse instead bits use numbers base give upper bound compression inefficiency involved worst case huffman encode symbol probability p using dlog digits worst case symbols encoded using blog digits therefore worst case average length codeword compressed text shows regardless probability distribution cannot spend one extra digit per codeword due rounding overheads instance use bytes spend one byte per word proves compression ratio degrade text grows even number different words separators increases fast flexible word searching compressed text delta 11 table 2 shows entropy compression ratios achieved binary huffman plain huffman tagged huffman gnu gzip unix compress files trec collection seen compression ratio degrades slightly using bytes instead bits case still gzip exception fr collection includes large part nonnatural language chemical formulas compression ratio tagged huffman code approximately 3 points ie 3 u plain huffman comes extra space allocated tag bit byte method files ap wsj doe ziff fr entropy 2620 2600 2460 2750 2530 binary huffman 2741 2713 2625 2893 2688 plain huffman 3116 3060 3019 3290 3014 tagged huffman 3412 3370 3274 3608 3353 gzip 3856 3753 3494 3412 2775 compress 4380 4294 4108 4156 3854 table 2 compression ratios achieved different compression schemes entropy refers optimal coding space used store vocabulary included huffman compression ratios 33 compression decompression performance finally consider section time taken compress decompress text compress text first pass performed order collect vocabulary frequencies storing trie data structure ou total worst case time achieved since trie requires non practical amounts memory use hash table perform step implementation average time collect vocabulary using hash table ou vocabulary sorted word frequencies ov log v cost case ou fi log sorting generate canonical huffman code vocabulary words advantage using canonical trees space economic canonical tree represented using two small tables size olog v previous work shown decoding using canonical codes reduces decompression times hirschberg lelewer 1990 zobel moffat 1995 turpin moffat 1997 canonical code construction done ov cost without using extra space using algorithm described moffat katajainen 1995 finally file compressed generating codeword text word ou decompression starts reading vocabulary memory ov cost well canonical huffman tree olog v cost word compressed text decoded output written disk total time ou table 3 shows compression decompression times achieved binary huffman plain huffman tagged huffman compress gzip files trec collection compression 23 times faster gzip 17 slower de moura g navarro n ziviani r baezayates compress achieves much worse compression ratios decompression significant improvement using bytes instead bits bit shifts masking necessary using bytes 20 faster gzip three times faster compress method compression decompression ap wsj doe ziff fr ap wsj doe ziff fr binary huff 490 526 360 518 440 170 185 121 174 151 plain huff 487 520 356 515 435 106 117 81 112 96 tagged huff 491 534 364 527 446 112 121 85 116 99 compress 422 456 308 417 375 367 407 273 373 331 gzip 1333 1526 970 1339 1048 147 161 105 139 111 table 3 compression decompression times elapsed seconds whole collections achieved different compression schemes main disadvantage wordbased huffman methods space requirements compress decompress text compression time need vocabulary look table codewords used speed compression huffman tree constructed without extra space using inplace algorithm moffat katajainen 1995 milidiu et al 1998 time need store vocabulary main memory therefore space complexities methods ou fi methods used gzip compress constant space complexity amount memory used configured methods memorydemanding compress gzip constitutes drawback applications example methods need 47 megabytes memory compress 37 megabytes memory decompress wsj file gzip compress need 1 megabyte either compress decompress file however text searching systems interested advantages methods ie allowing efficient exact approximate searching compressed text fast decompression fragments important space requirements 4 searching tagged huffman compressed text first searching scheme works tagged huffman compressed texts recall tagged huffman compression uses one bit byte compressed text mark beginning codeword general huffman codes prefix free codes means codeword prefix another codeword feature sufficient decode compressed text sufficient allow direct searching compressed words due possibility false matches see problem consider word ghost example presented figure 3 although word present compressed text codeword false matches avoided compressed text codeword prefix suffix another codeword add feature tagged huffman coding scheme setting 1 highest bit first byte codeword bit fast flexible word searching compressed text delta 13 real word word ghost compressed text original text code ghost real word fig 3 example codeword word present compressed text word present original text codewords shown decimal notation tag since compressed pattern match first byte first byte codeword text know possible match correctly aligned permits use conventional text searching algorithm directly compressed text provided search whole words general able search phrase patterns phrase pattern sequence elements element either simple word extended pattern extended patterns matched single text word include ability set characters position unbounded number wild cards arbitrary regular expressions approximate searching combinations appendix gives detailed description patterns supported system search pattern compressed text made two phases first phase compress pattern using structures used compress text second phase search compressed pattern exact pattern search first phase generates unique pattern searched conventional searching algorithm approximate extended pattern search first phase generates possibilities compressed codewords match original pattern vocabulary compressed text last case use multipattern algorithm search text explain method detail show extend phrases 41 preprocessing phase compressing pattern performing exact search similar coding phase huffman compression search element pattern huffman vocabulary generate compressed codeword element pattern vocabulary occurrences pattern text approximate extended search need generate compressed codewords symbols huffman vocabulary match element pattern element pattern make list compressed codewords vocabulary symbols match done sequentially traversing vocabulary collecting words match pattern technique already used block addressing indices uncompressed texts manber wu 1993 araujo et al 1997 baezayates navarro 1997 since vocabulary small compared text size sequential search time vocabulary negligible additional cost allow complex queries difficult achieve online plain text searching since take advantage knowledge vocabulary stored part huffman tree 14 delta e de moura g navarro n ziviani r baezayates depending pattern complexity use two different algorithms search vocabulary phrase patterns allowing k errors k 0 contain sets characters position use algorithm presented baezayates navarro 1999 v size vocabulary w length word w algorithm runs ov w time search w complicated patterns allowing errors k 0 contain unions wild cards regular expressions use algorithm presented wu manber 1992 runs okv time search w simple word searched ow time using eg hash table 42 searching phase exact search obtaining compressed codeword sequence bytes choose known algorithm process search experimental results presented paper used sunday sunday 1990 algorithm boyermoore family good practical performance case approximate extended searching convert problem exact multipattern searching problem obtain set codewords match pattern use multipattern search algorithm proposed baezayates navarro baeza yates navarro 1999 algorithm extension sunday algorithm works well number patterns search large case large number patterns search best option would ahocorasick aho corasick 1975 allows search time independently number patterns assume compressed codeword pattern length c boyermoore type algorithms inspect nc bytes compressed text best case best case close average case alphabet large size 128 256 uniformly distributed compared small pattern length c typically 3 4 hand best case uncompressed text searching inspect um characters since compression ratio nu roughly hold pattern average nu cm therefore number inspected bytes compressed uncompressed text roughly however three reasons make compressed search faster first number bytes read disk n smaller u second compressed search best case close average case true searching uncompressed text third argument says cm close nu assumes search pattern taken randomly text practice model selecting randomly vocabulary matches reality much better model yields larger c value average improves search time compressed text searching phrase pattern complicated simple case arises phrase sequence simple words found even separators case concatenate codewords words separators phrase search resulting single pattern hand want disregard exact separators phrase elements simple words apply different technique general case original pattern represented sequence lists compressed codewords match ith element original fast flexible word searching compressed text delta 15 pattern start search compressed text choose one lists use algorithm oneword patterns find occurrences text occurrence one element first list searched found use lists verify occurrence entire pattern text position choice first list searched fundamental performance algorithm heuristically choose element phrase maximizes minimal length codewords l choice comes directly cost search list patterns longer codewords less probability occurrence text translates less verifications occurrences elements lists moreover text searching algorithms work faster longer patterns type heuristic also common use inverted files solving conjunctive queries baezayates ribeironeto 1999 witten et al 1999 particularly bad case filter arises searching long phrase formed common words problem gets worse errors allowed matches search even less stringent patterns general uniform cost solution types searches depicted next section 5 searching plain huffman compressed text disadvantage first searching scheme described loss compression due extra bit used allow direct searching second disadvantage filter may effective types queries show search plain huffman compressed text code special marks gives better compression ratio tagged huffman scheme also show much flexible searching carried elegant uniform way present two distinct searching algorithms first one called plain filterless automatonbased algorithm elegantly handles possible complex cases may arise albeit slower previous scheme second called plain filter combination algorithms trying direct pattern matching plain huffman compressed text using automatonbased algorithm verification engine false matches 51 automatonbased algorithm previous scheme make heavy use vocabulary text available part huffman coding data huffman tree regarded trie leaves words vocabulary path root leaf spells compressed codeword shown left part figure 4 word rose first explain solve exact words phrases extend idea extended approximate searching pattern preprocessing consists searching vocabulary marking corresponding entry general however patterns phrases preprocess phrase patterns simply perform procedure word pattern word vocabulary set bit mask indicates elements pattern word match figure 4 shows marks phrase pattern rose 01 indicates word matches second element pattern 10 de moura g navarro n ziviani r baezayates47 131 huffman tree vocabulary rose 10marks nondeterministic searching automaton fig 4 searching scheme pattern rose example word rose threebyte codeword 47 131 8 nondeterministic finite automaton stands 0 1 indicates word rose matches first element pattern words 00 since match nowhere word pattern found vocabulary immediately know pattern text next scan compressed text byte byte time traverse huffman tree downwards decompressing text 3 new symbol occurs whenever reach leaf huffman tree word symbol obtained send corresponding bit mask nondeterministic automaton illustrated figure 4 automaton allows moving state state 1 whenever ith word pattern recognized notice automaton depends number words phrase query reaching leaf return root tree proceed compressed text automaton simulated shiftor algorithm baezayates gonnet 1992 perform one transition automaton text word shift algorithm simulates efficiently nondeterministic automaton using two operations per transition 32bit architecture search phrase elements using single computer word bit mask longer phrases use many computer words needed complex patterns preprocessing phase corresponds sequential search vocabulary mark words match pattern search symbols vocabulary use algorithms described section 41 corresponding mask bits matched word vocabulary set indicate position pattern figure 5 illustrates phase pattern ro rose allowing 1 error per word ro means word starting ro instance word rose vocabulary matches pattern positions 1 2 compressed text scanning phase change cost preprocessing phase section 41 difference mark bit masks instead collecting matching words search phase takes time finally show deal separators stopwords online search 3 however much faster decompression generate uncompressed text fast flexible word searching compressed text delta 1747 131 huffman tree vocabulary rose110100row road marks nondeterministic searching automaton fig 5 general searching scheme phrase ro rose allowing 1 error nondeterministic finite automaton stands 0 1 ing algorithms cannot efficiently deal problem matching phrase disregarding separators among words eg two spaces words instead one happens stopwords usually disregarded searching indexed text difficult disregard online searching compression scheme know elements vocabulary correspond fact separators user define compression even search time correspond stopwords therefore marked leaves huffman tree corresponding separators stopwords searching algorithm ignore producing symbol arriving leaves therefore disregard separators stopwords sequence search pattern negligible cost course cannot removed sequence compression time want able recover original text 52 filtering algorithm show section search plain huffman compressed text improved upon automatonbased algorithm described previous section central idea search compressed pattern directly text done tagged huffman code scheme presented section 4 every time match found compressed text must verify whether match indeed corresponds word mandatory due possibility false matches illustrated figure 3 section 4 verification process consists applying automatonbased algorithm region possible match found avoid processing text beginning make verification divide text small blocks size compression time codewords aligned beginning blocks codeword crosses block boundary therefore need run basic algorithm beginning block contains match block size must small enough slower basic algorithm used small areas large enough extra space lost block boundaries significant ran number experiments wsj file arriving 256byte blocks good timespace tradeoff extension algorithm complex queries phrases follows idea search section 4 use automatonbased algorithm check de moura g navarro n ziviani r baezayates errors errors fig 6 nondeterministic automaton approximate phrase searching 4 words 2 errors compressed text dashed transitions flow without consuming text input vertical diagonal unlabeled transitions accept bit mask stands 0 1 matches case however use multipattern searching performance may degraded reasons section 4 also possibility verifying many text blocks number matching words vocabulary large efficiency filter may degraded use scheme filter might preferable 53 even flexible pattern matching shiftor algorithm much searching simple sequence elements instance enhanced search regular expressions allow errors matches flexible patterns wu manber 1992 baezayates navarro 1999 powerful type search basis software agrep wu manber 1992 new handful choices appear use abilities wordbased compressed text scenario consider automaton figure 6 search compressed text phrase four words allowing two insertions deletions replacements words apart well known horizontal transitions match words vertical transitions insert new words pattern diagonal transitions replace words dashed diagonal transitions delete words pattern automaton efficiently simulated using extensions shiftor algorithm search compressed text approximate occurrences phrase instance search identifying potentially relevant matches could find occurrence identifying number relevant matches text one replacement error assuming stop words disregarded explained moreover allow three errors character level well could find occurrence identified number relevant matches text since algorithm occurrence identifying identified efficiently implementable setups insensitive order words phrase phrase query could fast flexible word searching compressed text delta 19 found matches considered potentially relevant identified one deletion error considered finally proximity searching interest ir efficiently solved goal give phrase find words relatively close text would permit find occurrence identifying tagging potentially relevant matches text approximate searching traditionally operated character level aims recovering correct syntax typing spelling mistakes errors coming optical character recognition software misspelling foreign names approximate searching word level hand aims recovering correct semantics concepts written different wording quite usual languages common factor prevents finding relevant documents kind search difficult sequential algorithm indexed schemes permit proximity searching operating list exact word positions scheme described simple program elegant extremely efficient characters exclusive feature compression method opens new possibilities aimed recovering intended semantics rather syntax query capability may improve retrieval effectiveness ir systems 6 searching performance performance evaluation three algorithms presented previous sections obtained considering 40 randomly chosen patterns containing 1 word 40 containing 2 words 40 containing 3 words patterns used three search algorithms experiments run wsj text file results obtained 99 confidence interval size uncompressed wsj 2628 megabytes compressed versions 804 megabytes plain huffman method 886 megabytes tagged huffman table 4 presents exact searching times using agrep wu manber 1992 tagged direct search tagged huffman plain filterless basic algorithm plain huffman plain filter filter plain huffman sunday filtering blocks 256 bytes seen table three algorithms almost insensitive number errors allowed pattern agrep plain filterless algorithm really insensitive maps queries automaton depend k filters start taking 23 filterless version become closer k grows experiments also shows tagged plain filter faster agrep almost twice fast exact searching nearly 8 times faster approximate searching times presented constant io time factor approximately 8 seconds algorithms read wsj compressed file approximately 20 seconds agrep read wsj uncompressed file times already included tables following test complex patterns time experimented specific patterns instead selecting number random reason established model random complex pattern instead focused showing effect different pattern features follows de moura g navarro n ziviani r baezayates algorithm agrep 238 sigma 038 1179 sigma 014 1461 sigma 013 1746 sigma 016 tagged 141 sigma 018 150 sigma 033 170 sigma 071 227 sigma 223 plain filterless 221 sigma 009 231 sigma 014 247 sigma 021 250 sigma 049 plain filter 151 sigma 030 162 sigma 052 194 sigma 121 234 sigma 179 table 4 searching times elapsed seconds wsj text file using different search techniques different number errors k simple random patterns searched 1 prob means character considered zero times one possible answer problematic example pattern matches lot words vocabulary 2 local television stations phrase pattern composed common words 3 hydraulic forging phrase pattern composed uncommon words 4 braszil ecua phrase pattern composed complex expression table 4 presents exact searching times patterns presented algorithm agrep 743 1177 1460 230 1176 1451 tagged 184 206 211 165 190 260 plain filterless 228 235 236 211 233 255 plain filter 214 214 221 152 171 223 algorithm pattern 3 pattern 4 agrep 219 1171 1451 743 1176 1458 tagged 145 150 160 182 183 187 plain filterless 217 215 216 242 242 246 plain filter 150 157 165 176 176 180 table 5 searching times elapsed seconds wsj text file using different search techniques different number errors k note case results complex patterns differ much simple patterns agrep hand takes much time complex patterns pattern 1 pattern 4 7 conclusions future work paper investigated fast compression decompression scheme natural language texts also presented algorithms allow efficient search exact extended word phrase patterns showed achieve 30 compression ratio 40 35 compress gzip respectively fast flexible word searching compressed text delta 21 typical texts compression times close times compress approximately half times gzip decompression times lower gzip one third compress search times better compressed text original text twice fast moreover lot flexibility provided search patterns complex patterns searched much faster uncompressed text 8 times faster typical making heavy use vocabulary information kept compressor algorithms presented paper implemented software system called cgrep publicly available example power cgrep search pattern containing 3 words allowing 1 error compressed file approximately 804 megabytes corresponding wsj file 2628 megabytes cgrep runs 54 megabytes per second equivalent searching original text 175 megabytes per second agrep searches original text 225 megabytes per second cgrep 78 times faster agrep results good encourage keeping text compressed time textual documents user database kept permanently compressed single text collection searching interesting documents done without decompressing collection fast decompression relevant files presentation purposes done efficiently complete picture convert viable alternative mechanism update compressed text collection must provided documents added removed altered efficiently techniques studied moura 1999 shown efficient updating compressed text possible viable finally remark sequential searching viable solution text collections large case indexed schemes considered technique useful speed sequential search fact used indexed scheme retrieved text usually scanned find byte position indexed terms algorithms value task witten et al 1999 particular also used improve indexed schemes combine inverted files sequential search like glimpse manber wu 1993 glimpse divides text space logical blocks builds inverted file list word occurrences points corresponding blocks searching done first searching vocabulary inverted file sequentially searching selected blocks using blocks indices 24 space overhead significantly speed search combined compression scheme block addressing inverted files obtaining much better results work uncompressed text navarro et al 2000 acknowledgments wish acknowledge many fruitful discussions marcio araujo helped particularly algorithms approximate searching text vocabulary also thank many comments referees helped us improve work 22 delta e de moura g navarro n ziviani r baezayates complex patterns present types phrase patterns supported system word pattern allows single letters pattern set letters digits called characters position exactly allowing errors follows range characters eg tazxt az means letter arbitrary sets characters eg taeixt meaning words taxt text complements eg tabxt ab means single character except b tadxt ad means single character except b c arbitrary characters eg tdeltaxt means character second character word case insensitive patterns eg text text considered words addition single strings arbitrary size classes characters described system supports patterns combining exact matching parts approximate matching parts unbounded number wild cards arbitrary regular expressions combinations exactly allowing errors follows unions eg teaixt means words text taixt teaixt means words beginning followed e ai zero times followed xt case word seen regular expression arbitrary number repetitions eg tabxt means ab considered zero times case word seen regular expression arbitrary number characters middle pattern eg txt means character considered zero times case word considered regular expression efficiency note equivalent delta eg txt tdeltaxt obtain matchings latter considered regular expression combining exact matching parts approximate matching parts text exact occurrence te followed occurrence xt 1 error matching nonuniform costs eg cost insertions defined twice cost deletions emphasize system performs wholeword matching pattern sequence words complex expressions matched whole text words possible write single regular expression returns phrase also extension described section 53 yet implemented r efficient string matching aid bibliographic search communications acm second ieee data compression conference march let sleeping files lie pattern matching zcompressed files large text searching allowing errors new approach text searching block addressing indices approximate text retrieval faster approximate string matching modern information retrieval data compression fulltext retrieval systems locally adaptive data compression scheme string matching lempelziv compressed strings handbook algorithms data structures overview third text retrieval conference information retrieval computational theoretical aspects efficient decoding prefix codes constructing wordbased text compression algorithms method construction minimumredundancy codes unifying framework compressed pattern matching multiple pattern matching lzw compressed text text compression scheme allows fast searching directly compressed file glimpse tool search entire file systems technical report 9334 october aplicacoes de compressao de dados sistemas de recuperacao de informacao indexing compressed text direct pattern matching compressed text fast searching compressed text allowing errors adding compression block addressing inverted indices general practical approach pattern matching zivlempel compressed text generating canonical prefix encoding fast substring search algorithm fast file search using text compression managing gigabytes second fast text searching allowing errors human behaviour principle least effort complexity finite sequences universal algorithm sequential data compression compression individual sequences via variablerate coding ieee transactions information theory adding compression fulltext retrieval system tr locally adaptive data compression scheme wordbased text compression efficient decoding prefix codes text compression fast substring search algorithm handbook algorithms data structures new approach text searching fast text searching data compression fulltext retrieval systems adding compression fulltext retrieval system string matching lempelziv compressed strings let sleeping files lie text compression scheme allows fast searching directly compressed file block addressing indices approximate text retrieval fast searching compressed text allowing errors efficient string matching generating canonical prefix encoding information retrieval modern information retrieval adding compression block addressing inverted indexes inplace calculation minimumredundancy codes shiftand approach pattern matching lzw compressed text general practical approach pattern matching zivlempel compressed text unifying framework compressed pattern matching multiple pattern matching lzw compressed text ctr falk scholer hugh e williams john yiannis justin zobel compression inverted indexes fast query evaluation proceedings 25th annual international acm sigir conference research development information retrieval august 1115 2002 tampere finland robert p cook heuristic compression english word list research articles softwarepractice experience v35 n6 p577581 may 2005 dana shapira ajay daptardar adapting knuthmorrispratt algorithm pattern matching huffman encoded texts information processing management international journal v42 n2 p429439 march 2006 nivio ziviani edleno silva de moura gonzalo navarro ricardo baezayates compression key nextgeneration text retrieval systems computer v33 n11 p3744 november 2000 shmuel klein dana shapira pattern matching huffman encoded texts information processing management international journal v41 n4 p829841 july 2005 r yugo kartono isal alistair moffat alwin c h ngai enhanced wordbased blocksorting text compression australian computer science communications v24 n1 p129137 januaryfebruary 2002 vo ngoc anh alistair moffat inverted index compression using wordaligned binary codes information retrieval v8 n1 p151166 january 2005 edleno de moura clia f dos santos daniel r fernandes altigran silva pavel calado mario nascimento improving web search efficiency via locality based static pruning method proceedings 14th international conference world wide web may 1014 2005 chiba japan alistair moffat r yugo kartono isal wordbased text compression using burrowswheeler transform information processing management international journal v41 n5 p11751192 september 2005 nieves r brisaboa antonio faria gonzalo navarro jos r param efficiently decodable searchable natural language adaptive compression proceedings 28th annual international acm sigir conference research development information retrieval august 1519 2005 salvador brazil kimmo fredriksson szymon grabowski general compression algorithm supports fast searching information processing letters v100 n6 p226232 31 december 2006 kimmo fredriksson online approximate string matching natural language fundamenta informaticae v72 n4 p453466 december 2006 kimmo fredriksson jorma tarhio efficient string matching huffman compressed texts fundamenta informaticae v63 n1 p116 january 2004 gonzalo navarro jorma tarhio lzgrep boyermoore string matching tool zivlempel compressed text research articles softwarepractice experience v35 n12 p11071130 october 2005 gonzalo navarro nieves brisaboa new bounds dary optimal codes information processing letters v96 n5 p178184 december 2005 gonzalo navarro regular expression searching compressed text journal discrete algorithms v1 n56 p423443 october juha krkkinen gonzalo navarro esko ukkonen approximate string matching zivlempel compressed text journal discrete algorithms v1 n34 p313338 june joaqun adiego gonzalo navarro pablo de la fuente using structural contexts compress semistructured text collections information processing management international journal v43 n3 p769790 may 2007 p ferragina f luccio g manzini muthukrishnan compressing searching xml data via two zips proceedings 15th international conference world wide web may 2326 2006 edinburgh scotland adam cannane hugh e williams generalpurpose compression scheme large collections acm transactions information systems tois v20 n3 p329355 july 2002 andrei arion angela bonifati ioana manolescu andrea pugliese xquec queryconscious compressed xml database acm transactions internet technology toit v7 n2 p10es may 2007 marcos andr gonalves edward fox layne watson neill kipp streams structures spaces scenarios societies 5s formal model digital libraries acm transactions information systems tois v22 n2 p270312 april 2004