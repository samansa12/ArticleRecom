optimal service policy buffer systems consider switching component packetswitching network messages several incoming channels arrive routed appropriate outgoing ports according service policy one requirement design system determine buffer storage necessary input channel policy serving buffers prevent buffer overflow corresponding loss messages paper class buffer service policies called least time reach bound ltrb introduced guarantees overflow buffer size required input channel independent number channels relative speeds storage requirement twice maximal length message cases consequence class shown optimal sense nonoverflowing policy requires least much storage ltrb b introduction consider system consisting several input channels single output channel variable length messages maximumlength l bits arrive input channel stored buffer associated channel buffers emptied output channel single server whose speed least great aggregate speed input channels system workconserving subject constraint service provided complete messages accordingly server may begin serving buffer contains least one complete message b cannot idle least one buffer contains complete message c serves complete messages without interruption service provided server according rule given contents buffer beginning service period determines buffer served next simple examples service policy include exhaustive round robin first come first served system described found various devices eg packet switches communication networks server switch service policy provides rule determines buffer switch serve systems important economic reasons minimize amount storage required buffer 11 yet buffers must large enough limit overflow loss messages arrive full buffer ideally buffers would designed eliminate overflow interest nonoverflowing policy minimizes size largest buffer required message arrival pattern many applications also desirable buffer storage required channel independent number channels relative speeds enable reuse input channels system reconfigured allow higher speed channels larger number channels design problem studied 3 exhaustive round robin err service policy analyzed policy buffers served cyclic order service buffer starts continues complete messages buffer exhausted shown speeds input channels equal buffer every input channel capacity 335l sufficient prevent overflow however speeds equal required buffer sizes depend relative speeds grow linearly number input channels recently 13 upper bound equal speed channels err improved 3307l lower bound 3051l also provided paper gated round robin grr investigated equal speeds upper bound 3l found policies studied include first come first served fcfs longest queue first lqf 2 fcfs policy shown require buffers capacity 2l prevent overflow case equal speed channels unequal speed case buffer sizes exhibit linear behavior number channels err similar phenomenon established lqf 7 required buffer storage guarantee overflow 2l equal speed case depends number relative speeds input channels unequal speed case increases logarithmically number channels finally mention recent paper 9 study discipline called fair queueing presented translating work context system model shown upper bound 2l guarantees overflow equal speed case fair queueing service policy paper introduce analyze class buffer service policies called least time reach bound ltrb satisfies ac guarantees overflow buffer storage required input channel 2l cases storage required ltrb independent number channels relative speeds also optimal sense nonoverflowing policy requires least much storage ltrb policy operates follows service message completed next message served chosen buffer would overflow first input channels remain continuously busy none served model arrivals standard gradual input noninstantaneous input model often used study switches communication networks model appeared extensively literature analysis systems 1 5 6 10 12 also used analysis dams 4 8 noninstantaneous input model describes accurately instantaneous input models real systems interarrival times messages limited speeds input channels input channel may either bits arriving bits arriving messages loaded gradually buffer arrive opposed arriving instantaneously emphasize results proved hold every instance systems satisfying assumptions regardless distribution arrivals service times onoff statistics input channels remainder paper organized follows section 2 noninstantaneous input model described ltrb class service policies presented section 3 proposition involving properties certain set difference equations proved section 4 proposition used establish ltrb overflow buffer storage twice maximum message length section 5 brief discussion results presented consider system n input channels input buffer let 0 rate bitssec channel discussed introduction assume gradual input noninstantaneous input model arrivals bits arriving channel stored corresponding input buffer buffer full bits lost input channel may either state bitssec arriving state bits arriving channel arriving bits form messages message consists l bits impose statistical assumptions periods input channels message lengths single server whose service rate bitssec serves messages residing input buffers without loss generality normalize server speed 1 rate represents speed channel relative service rate aggregate rate input channels service rate 1 server restricted serve complete messages thus buffer contains part message message cannot served complete message present buffer addition messages served without interruption message fragments cannot served finally server workconserving ie idle complete message buffer since complete messages served epochs server decides upon next message handle times least one buffer contains complete mes sage since messages served without interruption server workconserving decision epochs either instants service completion server idle instants least one complete message formed buffer assume system starts operate buffer contains l bits total number bits system initially greater nl bits since service rate least large aggregate arrival rate server busy since buffer contain l bits server idle total number bits system cannot exceed nl bits time define class ltrb policies need following notation let q number buffered bits channel time noted q satisfy define quantity note q 2l simply time take queue size channel reach buffer size 2l assuming continuous stream bits arrive channel policies ltrb class operate attempting serve buffer minimal time reach bound however since complete messages served slight variation scheme necessary least time reach bound class policies decision epoch server chooses serve buffer among buffers complete message j buffers j least l bits one member policy class policies following decision epoch server chooses serve buffer minimal buffers complete message another variant policy b ltrb class following decision epoch server chooses serve buffer minimal buffers least l bits buffer l bits buffer complete message chosen proceed give mathematical description ltrb class policies decision epoch channel chosen served required complete message transmit note q l equivalent ls therefore channel satisfying ls must complete message thus eligible chosen service define least l bits g 2 complete message g 3 since l maximum message length l although may l chosen served f ltrb policy one f let f set channels service policy chooses according minimal ie clear relation decision epochs yields class ltrb policies setting f obtain first example policy discussed choice channel serve one minimal time reach bound channels complete message setting f gives extreme policy b choice channel serve one among least l bits minimal time reach bound channels less l bits channel complete message may chosen main goal prove member ltrb class policies requires buffer storage 2l bits input channel prevent overflow number channels n set channel speeds fs g prove following theorem 1 consider system n channels channel speeds server speed operating member class ltrb policies 3 shown buffer size 2l lower bound policy satisfying properties ac section 1 thus obtain following result immediately theorem 1 theorem 2 ltrb class optimal terms buffer storage policies workconserving complete messages served 3 analysis 31 preliminaries determine whether overflow occurs given policy buffer sizes decision epochs need examined reason overflow occurs occurs decision epoch necessarily busy period seen follows consider arbitrary busy period let n beginning nth service note instants time constitute decision epochs within busy period claim enough show overflow occur decision epochs suppose overflow occurs time decision epoch let channel one overflows n since channel still least one complete message end present service channel already overflowed decision epoch n claim holds channel overflowed n clearly served otherwise queue size would increase n therefore next decision epoch n1 end current service overflow still occur channel fact q served time q channel served time thus overflow occurs busy period occurs decision epoch within busy period need concentrate points time note queue size channel start busy period l initial value let oen length nth message served busy period also represents nth service time since server speed normalized 1 let time service channel actually receives input thus f n channel chosen served nth decision epoch service completed value channel 6 f n served decrease ffi n channel f n increase oens f n completion service n note equations hold service policy f modeling assumptions study difference equations type general framework includes equations obtained f belongs class ltrb policies 32 generalized framework discussion suggests study following mathematical model general setting given l 0 state nvector also given initial state satisfying interest certain sequences called triples defined follows determines state trajectory theta 0 satisfies mentioned evolution states channels within busy period defined 1 follows 7 arbitrary service policy f however additional constraints equations generated behavior queueing system models switch example messages length l cannot consecutively chosen service channel beginning busy period since sufficient time would elapsed second message arrive another example amount bits buffer cannot become negative value cannot become larger 2l prove proposition difference equations type 7 without taking account constraints equations model behavior queueing system described included constitute small set cases covered result although proposition quite general mathematical point view significance framework developed allows certain inductive arguments carried yield queue size upper bound theorem 1 otherwise additional constraints would always taken account complicating arguments next describe triples wish consider let triple corresponding state trajectory theta define triple admissible step n f n n n 2 l n admissible admissible terms queueing model note policies ltrb class yield triples admissible one example admissible triple obtained index f n corresponds minimal value n step n triple strict step n f n n n strict strict queueing model decision epoch channel minimal defined 1 complete message choosing channels serve yields strict triple furthermore choices f n constitute policy necessarily member ltrb class prove theorem 1 show trajectory theta always positive namely carry proof three steps first show strict triple n l handle admissible triples nonstrict steps show theta positive case corresponds queueing model channels remaining percentage time service finally prove theta always positive admissible note last result yields theorem 1 since defined 1 positive decision epochs busy period implies overflow occurs channel given buffer size 2l continuing introduce notation set j two nvectors i2j b also use notation simply write delta b 33 strict triples prove following proposition strict triples proposition 1 let triple corresponding state trajectory theta strict proof first prove induction n delta n j hypothesis delta 0 j claim holds assume holds induction hypothesis fact delta ffim j oem f 62 j claim delta j complete proof suppose since strict step particular f multiplying ith equation summing 2 j obtain inequality thus 10 follows ff mg 10 11 contradicts induction hypothesis completes proof claim specializing case shows n l proves proposition 2 interesting note certain queueing models channel minimal defined 1 guaranteed complete message thus strict policy always implemented example consider case continuously buffers initially contain l bits equal speed channels channel smallest value largest queue size apparent 1 since channels initially start l bits periods total number bits system always remains nl thus maximal queue size least l bits time channel smallest complete message 34 uniform triples prove main result uniform triples ie admissible triples satisfying additional assumption ffi queueing model case corresponds channels remaining percentage time messages served one example behavior occurs case continuous input channels service time nth message extreme corresponds case input channels shows positions compared n change except index f n n property used extensively proof following proposition proposition 2 let triple corresponding state trajectory theta assume admissible proof consider step n 0 strict n theorem clearly holds since minimal must satisfy n ls 8 thus may restrict attention uniform triples strict n triples may classified number nonstrict steps 1g prove theorem induction k case corresponds triples strict first n steps holds proposition 1 assume theorem true uniform triples nonstrict steps show true uniform triple nonstrict steps last nonstrict step n strict steps note r 6 assumption since admissible triple r n nl index f m1 must correspond minimal step since strict strict 1 thus theorem holds may assume 1 proof induction step splits two cases depending whether members r chosen steps 1 n case 1 first suppose claim 15 implies 12 sufficient prove f n n 0 strict n set k ng since k includes indices chosen steps since k r delta ffim k l using 14 note proves claim f jkj 2 1g last step prior n l implies pl since strict l f l l f n l pl used fact ffi f l 1 therefore since l shown summing equation 17 obtain equations 16 18 sk 0 find f n n 0 completes proof induction step 15 holds case 2 suppose 1 first step fm ng f k claim obviously holds may assume f k chosen steps k pm similarly f chosen step pm using inequalities yield however holds 1 first step fm ng satisfying 20 note 2 r 6 since strict 1 implies ng wish delay choosing f step k obtain triple nonstrict steps consider triple defined let corresponding state trajectory follows 21 want show u strict steps n induction hypothesis yield proposition l therefore 6 f since strict l 1 also f thus u strict l 2 1g step k 20 thus 6 f since strict k 1 shows u also strict k claim oek 1 see note 6 f f thus consequence result triple u strict since u strict agree thus u nonstrict steps induction hypothesis completes proof proposition 2 2 relating proof queueing model case 1 channels less l bits mth decision epoch chosen service m1 n channels correspond minimal epochs size direct calculation shows overflow occurs serving case 2 policy less nonstrict choices constructed delaying service channel chosen originally epoch later busy period 35 admissible triples extend result admissible triples arbitrary ffin triple define set define cardinality prove main proposition admissible triples proposition 3 let triple corresponding state trajectory theta admissible proof clear n admissible triple u n agrees 1 thus need prove proposition admissible triples 1 proof induction therefore result holds case proposition 2 assume proposition holds admissible triples show holds 1 let admissible choose step n j 2 n proof proposition splits two cases depending whether index j ever chosen step n case identify admissible triple u related use induction hypothesis case 1 first suppose case j l f l l j 6 f l index j chosen step n define triple u follows note state trajectory corresponding u clearly l using 24 follows u admissible also l oe l induction hypothesis case 2 next suppose l 2 fn k first step k n define triple easy verify u triple example shows 0 k l state trajectory corresponding u k state oel given 26 l 2 fn see derivation equation 27 u admissible l next definition k thus u admissible k since consider step k 1 6 j j implies u admissible l therefore u admissible triple induction hypothesis completes proof proposition 3 2 describe proof terms queueing model recall case channels remain percentage time messages served covered proposition 2 handle general case channel j turned additional length time nth service periods channels uniform added buffer channel j case 1 corresponds channel j never chosen service example may never contain complete message case 2 corresponds serving dummy bits keeping channels turned service 4 optimality ltrb use results section 3 prove optimality least time reach bound ltrb class service policies introduced section 2 interest service policy buffer size required channel prevent overflow independent number channels speeds show ltrb policies possess property addition members class optimal terms buffer size approach examine instance evolution behavior system apply proposition 3 previous section conclude overflow occur proof yield upper bound 2l buffer size channel prevent overflow however mentioned section 2 value 2l lower bound policy workconserving complete messages served thus proof upper bound shows ltrb optimal among policies recall l maximum message length relative speeds n channels number bits storage channel time denoted time queue size channel reach 2l assuming continuous flow bits rate service given channel since overflow occurs occurs decision epoch busy period may concentrate instants time recall states decision epochs busy period satisfy difference equations form 7 oen length message chosen service nth epoch f n channel containing message length corresponding period channel queue size channel beginning busy period l initial state satisfies definitions sequence oen ffin f n represents triple defined section 3 also clear members ltrb class yield triples admissible results previous section may applied policies mentioned certain restrictions triples arise naturally queueing model example buffer size q n cannot negative value n cannot go 2l allowed triples studied section 3 also queueing model message cannot transmitted sufficient time elapsed arrive example may possible channel transmit l bits two successive steps thus set triples generated queueing model small subset set possible triples considered section 3 however may apply general result obtained section show overflow occur system operating ltrb policy buffers size 2l theorem 1 consider system n channels channel speeds server speed operating member class ltrb policies proof discussed decision epochs n busy period need considered channels remain percentage time service message situation covered proposition 2 general case input flow channels turned arbitrarily handled proposition 3 2 theorem 1 shows bound 2l valid number channels set channel speeds however certain cases even smaller bound may hold example suppose channel speeds identical case constant independent channel thus choosing minimal equivalent choosing buffer maximal queue size among channels complete message shows longest queue first policy lqf ltrb class using results 7 lqf upper bound buffer storage case fact shown policies ltrb class require buffer storage 2l independent number channels relative speeds policies also optimal terms storage see first note 3 example given show buffer size 2l lower bound policy satisfies properties ac discussed section 1 let us briefly review lower bound example consider n buffer system channel speeds identical aggregate speed equal server speed suppose initially n buffers contain maximal length message l bits serving one buffers least order dictated policy takes time least maximal length messages must served server speed unity final buffer yet served contain least bits n 1 obtain lower bound 2l policy thus following immediate consequence theorem 1 theorem 2 ltrb class optimal terms buffer storage policies workconserving complete messages served paper introduced new class service policies called least time reach bound ltrb servicing messages reside input buffers switch according policy message completed service next message chosen taken buffer would overflow first assuming continuous flow bits input channels service proved operating class policies guarantees overflow thus message loss buffer storage input channel twice maximal length message number channels set speeds class optimal sense nonoverflowing policy satisfying conditions ac requires least much storage ltrb obvious advantages storage requirements increase number incoming channels compared logarithmic growth longest queue first lqf service policy linear growth exhaustive round robin err first come first served fcfs service policies buffer sizes much smaller need changed every time input channel added switch thus system robust yet gain advantages switch must able determine number bits incoming buffers end service message must also know speeds incoming channels err switch simpler since queue lengths buffers need observed buffer served switch lqf similar ltrb except need know speeds incoming channels conclusion observe tradeoff amount storage required complexity switch r stochastic theory datahandling system multiple sources buffer sizing isdn frame relay switch real time packet switching performance analysis single server queue superimposed renewal processes storage gradual input calculus network delay buffer size requirements longest queue first limiting distributions storage problems fair fair queueing stochastic behavior buffer nonidentical input lines communication buffers analysis design output buffered data communication system input buffer requirements round robin polling systems tr fair fair queuing buffer size requirements longest queue first ctr yossi azar yossi richter management multiqueue switches qos networks proceedings thirtyfifth annual acm symposium theory computing june 0911 2003 san diego ca usa zvi rosberg cell multiplexing atm networks ieeeacm transactions networking ton v4 n1 p112122 feb 1996 amotz barnoy ari freund shimon landa joseph seffi naor competitive online switching policies proceedings thirteenth annual acmsiam symposium discrete algorithms p525534 january 0608 2002 san francisco california yossi azar yossi richter zeroone principle switching networks proceedings thirtysixth annual acm symposium theory computing june 1316 2004 chicago il usa yossi azar yossi richter improved algorithm cioq switches acm transactions algorithms talg v2 n2 p282295 april 2006