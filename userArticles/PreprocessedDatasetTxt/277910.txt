modeling set associative caches behavior irregular computations much work devoted study cache behavior execution codes regular access patterns little attention paid irregular codes important portion codes scientific applications handle compressed sparse matrices work probabilistic model prediction number misses kway associative cache memory considering sparse matrices uniform banded distribution presented two different irregular kernels considered sparse matrixvector product transposition sparse matrix model validated simulations synthetic uniform matrices banded matrices harwellboeing collection b introduction sparse matrices kernel many numerical appli cations compressed storage permits operations memory savings generates irregular access patterns fact reduces makes hard predict performance memory hierarchy work probabilistic model prediction number misses kway associative cache memory considering sparse matrices uniform banded distribution presented want emphasize important body model reusable different algebra kernels important approach study cache behavior traditionally use tracedriven simulations whose main drawback large amount time needed process traces another possibility nowadays provided performance monitoring tools modern microprocessors builtin hardware counters make work supported ministry education science cicyt spain project tic961125c03 xunta de galicia project xuga20605b96 eu briteeuram project be951564 available data number cache misses tools obviously restricted evaluation specific cache architectures available finally analytical models present advantage reduce times obtaining estimations make parametric analysis cache flexible weak point traditionally limited precision although models use parameters extracted address traces general analytical models developed require input traces previous works focuse dense algebra codes little attention devoted sparse kernels due irregular nature access patterns example studies self interferences vector involved sparse matrixvector product directmapped cache without considering interferences data structures derive general framework model kind codes nevertheless example potential usability types models modeled cache behavior common algebra kernel sparse matrixvector product complex one transposition sparsematrix last code includes different access patterns presents important degree data reusability certain vectors remainder paper organized follows section presents basic model parameters concepts sparse matrixvector product cache behavior modeled section section dedicated modeling transposition sparse matrix models extended banded matrices section section models verified cache behavior depict studied finally section concludes paper 2 probabilistic model model considers three types misses intrinsic misses self cross interferences intrinsic miss takes place first time memory block accessed self interferences misses lines previously replaced cache another line belongs program vector cross interferences refer misses lines replaced two consecutive references lines belonging vectors direct mapped caches memory line always mapped cache line replacements take place whenever accesses two memory lines mapped cache line take place however kway assso ciative caches lines mapped set k cache lines case line replaced selected following cache size words ls line size words nc number cache lines csls nnz number non zero elements sparse matrix number rows sparse matrix n number columns sparse matrix fi average non zeros elements per row nnzm k associativity nk number cache sets nck pn probability position sparse matrix contains non zero element fin probability least one entry group ls positions sparse matrix r size integer size real table 1 notation used random lru criterium model oriented kway associative caches lru replacement order replace line cache kind k different new lines mapped set must accessed reusing line considered behavior direct mapped caches replacement probability given line grows number lines affected accesses two consecutive references way lines distributed among different sets depends memory location vectors accessed determines set corresponding given line handle areas covered accesses given program vector v area vector ratio sets received k lines vector v ratio sets received lines v means vi ratio cache sets require accesses new different lines replace lines contained access v started besides k number lines set number additional parameters model considers depicted table word mean logical access unit say size real integer chosen size real model totally scalable uniform distribution theta n sparse matrix nnz non zero elements entries allows us state following considerations number entries group ls positions belongs binomial bls pn pn probability given position matrix containing entry way probability generating access given line vector times multiplying sparse matrix p calculated table shows 21 area vectors union essential issue way obtain total area vector add area vectors corresponding accesses different program vectors given two area vectors corresponding accesses vectors u v define union area vector ratio sets received lines two vectors u v 0 u u v00110011 u u figure 1 area vectors corresponding accesses vector u vector v cache n resulting total area vector l figure 2 area vectors corresponding sequential access access lines uniform reference probability vector covering 11 lines cache n 2 ratio sets received k lines figure illustrates area vector union process symbol used denote vector union op eration method makes assumptions relative positions program vectors memory based addition independent probabilities area ratios 22 sequential access calculation area vector depends access pattern corresponding program vector define area vector function access pattern find codes analyzed example area vector access n consecutive memory positions 2 average number lines fall set l k sets receive average k lines term ls added n stands average extra words brought cache first last lines access 23 access lines uniform reference probability area vector access n word vector one cache lines divided probability p l accessed may calculated li n p l li n p l bnp binomial distribution 1 eg example access sequential access presented define binomial distribution non integer number elements figure 3 correspondence location non zeros banded matrix transposed groups moved vectors define output matrix figure case k accesses type area vector k l n p l 24 access groups elements uniform reference probability transposition sparse matrix find case vector n words divided groups words probability pg accessing group happens main loop algorithm accesses non zeros input matrix per rows sequentially moving group corresponding column belong vectors define output matrix group many positions non zeros associated column input matrix one lines group accessed processing row input matrix consecutive accesses group address consecutive memory positions area covered access type given sg n pg ae ls line vector uniform probability accessed whereas ls probability lstpg case l sg may extended order calculate area covered k accesses k n p due space limitations show main expressions model found 25 access areas displaced successive references model may extended consider case area access probability displaced successive references let gb b pg area vector corresponding access b consecutive groups elements uniform probability per group pg accessing one one elements group value given sg b delta pg define k gb b pg area vector corresponding k accesses type banded sparse matrix transposition case one k accesses corresponds processing new row sparse matrix row column leaves band left makes probability accessing group corresponding null new one joins band right thus adding group set groups may accessed processing row situation depicted figure 5 processing first row groups 1 jri ri11 enddo enddo figure 4 sparse matrixvector product 5 may accessed non zero associated column second row sets 2 6 third sets 37 may accessed accesses following pattern cover three adjacent areas 1 set lines growing access probability area 1 figure 2 set lines constant access probability area 2 figure 3 last set symmetric first one size decreasing access probability area 3 figure average access probabilities lines three consecutive areas known see remains combine obtain corresponding area vector 26 number lines vector competing cache set finally calculation self interference probability function compute average number lines line vector competes cache set needed function defined ae average number lines vector mapped cache set 3 modeling sparse matrixvector product code sparse matrix algebra kernel shown figure format used store sparse matrix compressed row storage crs contains sparse matrix entries c stores column entry r indicates point c new row sparse matrix starts permits knowing number entries per row three vectors destination vector product present purely sequential access thus misses intrinsic self interferences misses due cross interferences specially taking account considering kway associate cache therefore number misses vectors calculated number cache lines cover intrinsic misses nevertheless vector x suffers series indirect accesses dependent location entries sparse trix addressed value cj number misses accessing vector calculated multiplying number lines referenced per dot product number rows sparse matrix miss probability one accesses first value calculated p delta nls x covers nls lines one probability p accessed dot product times given row sparse matrix stated previous section miss probability calculated opposite hit probability hits take place whenever accessed line referenced previous dot product suffered self cross interferences cross interferences generated accesses remaining vectors present sequential access cross interference area given total area vector associated accesses vectors c r area vector calculated way explained section adding individual area vectors corresponding accesses program vector period consid ered case interested calculating cross interference area vector dot products cross area vector covered accesses vector v dot products four vectors sequential access expression ss derived section applied values obtained considering one element r fi components c accessed per dot product scale factor r applied integer vectors order take account integer data often stored using less bytes real ones factor quotient number bytes required real datum one required integer self interference probability line x competes average cn lines vector see definition cn cache set probability p accessed dot product times row sparse matrix result number different candidate lines x replace given line accessed dot products belongs binomial hit probability first access line x dot product jth row sparse matrix times vector x p1gammap igamma1 probability last access line taken place dot products ago int x interference area vector generated accesses produced dot products calculated cross interfence area vector obtained added self interference area vector given access uniform access probability per line 1gamma1gamma p lines vector x generate self interferences another line calculated using finally average hit probability calculated end jci2 end end kri ri11 ctpi end end figure 5 transposition sparse matrix must point model takes account first access line x dot product nnz gammapdeltam deltanl accesses low probability resulting miss refer lines accessed previous iteration inner loop 4 modeling transposition sparse matrix section model extended operation greater degree complexity sparse matrix transposi tion previous section assume sparse matrix transposed stored crs format figure shows transposition algorithm described matrices represented vectorsa c r ct rt respectively observe loop 4 multiple indirection levels left right side sentences follows employ similar approximation one developed previous section estimate number misses vectors ct rt remaining vectors sequential accesses already considered previous algorithm 41 vectors ct two vectors follow exactly access pattern may observed loop 4 figure thus explain estimation number misses one ct identical taking account integer vector access pattern one modeled sg described section pattern similarities one explained section vector x access probability uniformly distributed along vector difference vector x probability constant line vec tor vectors ct corresponds sets many elements column original sparse matrix holds result general form hit probability process jth row sparse matrix similar one following differences ffl probability accessing considered line vector processing row p ffl probability accessing another line mapped cache set processing previous rows 1gamma1gammap 1gammas ffl vector nnz elements number lines compete set line considered cnnz equation calculates interference area vector ffl calculating cross interference probability scheme adding area vectors corresponding access remaining vectors used r c calculated according remaining area vectors l n delta nnz delta 42 vector rt vector referenced four loops algorithm first loop totally sequential access produces misses second loop accesses rt follow similar pattern vector x sparse matrixvector product differences consist one possible source cross interferences vector c rt integer vector real value vector number misses loop 2 first hit rt2 p hit rt2 calculated following expressions introducing modifications mentioned vector rt completely accessed sequential manner previous loop reason must add probability first hit rt2 getting hit due existence portions rt cache initiating loop final expression found loop 3 vector rt sequentially accessed without accesses vectors estimated number misses p first hit rt3 may estimated p first hit rt2 delta pr delta finally loop 4 access rt similar sparse matrixvector product described section loop must also consider hit probability p first hit rt4 due previous load rt generated loop 3 5 extension banded matrices large number real numerical problems engineering lead matrices sparse banded distribution entries section present modifications model requires order describe cache behavior matrices type model parameter pn see table calculated fi w w bandwidth consequently p takes value 51 sparse matrixvector product number misses vector x one affected band distribution entries modeling behavior vector identical one described section number accesses different lines dot products vector x involved multiplied miss probability calculated calculation p hit x expression must replaced w one line x may accessed product maximum w rows addition number lines x compete another cache set cw instead cn influences p hit x j expression entries row distributed among w positions instead n 52 transposition sparse matrix calculation number misses modified similar way vector x sparse matrixvector product line vector spreads access probability processing w rows sparse matrix instead thus reducing limit sum calculates hit probability reason number lines given line vector competes cache set access period cnnz cnnzn delta w besides accessed following pattern described area vector funcion gb section probability accessing processing previous rows given line mapped cache set line considering 1gammas also cross interference probability calculation needs modified according new access patterns similar changes needed estimation number misses vector ct taking account made integer values prediction number misses vector rt loops 2 4 based model vector x sparse matrixvector product calculation p hit rt2 p hit rt4 requires modifications explained previous section number different lines accesses dot product longer n delta rls w delta rls changes needed also calculate probabilities hit due reuse p first hit rt2 p first hit rt4 finally value p first hit rt3 p first hit rt2 delta pr delta w 6 results model validated simulations synthetic matrices uniform distribution non zero elements banded matrices harwellboeing collection traces simulations obtained running algorithms replacing original accesses calls functions calculate position accessed write disk traces fed dineroiii cache sim ulator belonging warts tools tables show model accuracy sparse matrixvector product combinations input parameters uniform banded sparse matrices respec tively tables display results sparse matrix transposition model without loss generality considered square matrices analy sis r 1 cs expressed kwords ls words maximum error obtained trial set 515 synthetic matrices 2812 harwellboeing matrices reason last result entries distribution real matrices completely uniform produces high deviations sparse matrix transposition model see table nevertheless consider amount deviation still acceptable analysis purposes besides small size matrices collection favor convergence probabilistic model also want point average error predicted measured table 2 predicted measured misses deviation model sparse matrixvector product uniform entries distribution nnz numbers misses thousands name n w nnz ff cs ls k predicted measured table 3 predicted measured misses deviation model sparse matrixvector product harwellboeing matrices predicted measured table 4 predicted measured misses deviation model transposition sparse matrix uniform entries distribution nnz numbers misses thousands name n w nnz ff cs ls k predicted measured table 5 predicted measured misses deviation model transposition sparse matrix harwellboeing matrices pn log ls figure number misses 4way associative cache 2kw sparse matrixvector product 10k theta10k matrix function ls pn k2 k4 log ls figure 7 number misses sparse matrixvector product 10k theta 10k matrix function line size 2kw cache different associativities synthetic matrices 065 5 real matrices figures present relationship number misses different parameters introduced models case cs ls display base 2 logarithm number cache kwords line words respectively figure shows relationship number misses ls pn sparse matrixvector product evolution approximately linear respect pn number accesses directly proportional nnz follow sequential pattern may observed number misses significantly decreases ls increases accesses vectors except x sequential see figure larger lines exploitation spatial locality obtain nevertheless ls large 64 words matrix lower degree sparsity pn 01 increase self cross interferences probabilities vector x begins unbalance advantages obtained efficient use spatial locality exhibited remaining vectors effect shown figure increases value pn relationship w cs banded sparse matrixvector product shown figure graph0515x figure 8 number misses sparse matrixvector product sparse matrix 20ktheta20k tries function w cs k2 k4 log figure 9 number misses sparse matrixvector product 20k theta 20k matrix 2m entries 8000 function cache size ls 8 different associativities considered broad bands order illustrate effect self interferences access vector x bandwidth reduction large influence number misses reduces self interference probability increases reuse probability lines vector x non zeros spread narrower rows spatial locality improvement columns temporal locality improve ment number misses near minimum reached increases cs beyond size little use intuitive good miss rates reached cs w size line cache line band currently processed row extra room needed avoid combined effect self cross interferences shall demostrate analysis fixed bandwidth different degrees associativity cache sizes figure number misses matrix displayed relation cache size different associativities observe improvement reached 8kw cache due elimination self interferences cache size increments size help gradually reduce cross interferences hand caches k 1 log figure 10 number misses transposition sparse matrix 20ktheta20k function w cs different behavior misses reduction gradient high cs 16kw reason 8kw cache k different lines x mapped cache set lines usually accessed order cache uses lru replacement cross interference may generate misses lines x mapped cache set result cross interferences affect many lines set hold thus generating misses fact see 4way associate cache performs little worse 2way cache cache size caches cs 16kw cache sets enough lines left absorb accesses vectors comprise sparse matrix destination vector without increasing interferences x due combination lines vector reside cache set small cache sizes associativities perform similarly due large number interferences conclusion associative caches help reducing interference effect number lines compete given cache line smaller equal k otherwise performance quite similar direct mapped cache moreover case lines mapped cache set usually accessed order high associativities may perform worse sparse matrix transposition figures represent data algorithm figures sparse matrixvector product respectively first one shows decrease number misses bandwidth reduction noticeable point cs becomes greater w reasons explained previous algorithm anyway reduction much softer sparse matrixvector product accesses vector rt loops 2 4 directly favoured bandwidth reduction stand small portion misses hand number misses vectors ct account vast majority misses decreases slowly cs increases w decreases although also heavily dependent bandwidth reason cases shown figure data belonging vectors process columns inside band original matrix fit cache nnzn delta w entries case set fit see number misses becomes stable area k2 k4 log figure 11 number misses transposition sparse matrix 20ktheta20k matrix 2m entries 8000 function cache size ls 8 different associativities graph misses c r remain almost completely constant due sequential access obtaining benefit bandwidth reduction somewhat lower cross interference probability figure shows general behavior algorithm respect k associativity degree although similarities sparse matrixvector product depend w determine cache sizes hit rate obtains reasonable values explained reason none cache sizes considered contain considerable portion data algorithm accesses w iterations process whole band loop 4 one causes misses accesses rt mainly loop 2 benefit increase cs values larger w specially noticeable sparse matrixvector product another similarity worse behavior caches k 1 cache size close w due added effect cross interferences self interferences cache lines usually accessed order penalizes lru replacement algorithm cache size noticeable larger bandwidth higher associativities perform better figure order get hints values cache parameters algorithm stabilizes misses figures show data smaller matrix using 4 process band matrix working set vectors ct account misses comprise 25w elements average 25 elements per column hit rate obtains values near maximum figure cache size exceeds value increases cs beyond limit provide little performance improvement improvements noticeable cache size increase high due strong reduction cross interference must take account graph constructed 4way associative cache somewhat greater cache sizes would needed obtain good cross interference reduction direct mapped cache see figure associative caches help reducing miss rate small cache sizes figure average always less 2 lines competing set process row 200 lines vector log figure 12 number misses transposition sparse matrix 5ktheta5k 125k entries function w cs k2 k4 log figure 13 number misses transposition sparse matrix 5ktheta5k matrix 125k entries 200 function cache size ls 4 different associativities non null access probability 200 lines belonging vector ct lines belonging vectors smallest caches considered 512 lines expected increase cache size reduces hit ratio difference direct mapped caches set associate caches cs 8kw cache size increase helps reducing cross interferences finally relationship line size matrix density number misses last algorithm proved sparse matrixvector product difference gradient increase misses relation pn three times larger normal number accesses per non zero original matrix eight sparse matrixvector product algorithm three 7 conclusions future work presented fullyparametrizable model estimation number misses generic kway associative cache lru replacement applied sparse matrixvector product transposition sparse matrix model deals possible types dineroiii time model time 100 1000 1 1000 100 1000 10 100 100 1000 1 1000 100 1000 10 100 100 1000 1 1000 100 1000 10 100 table simulation model user times calculate number misses transposition banded sparse matrix 200 mhz pentium n nnz thousands time seconds misses demonstrated high level accuracy predictions considers uniform distribution entries whole matrix given band table shows besides providing information modelization much faster simulation even time required generate trace takes almost much time execution simulator included table illustrated model may used study cache behavior code shown importance bandwidth reduction case banded matri ces even high degrees associativity model also applied study possible architectural cache parameter modifications order improve cache performance future work includes extension model consider prefetching subblock placement hand working modeling non uniform distributions entries sparse matrices focusing common patterns appear real matrices suites finally order obtain accurate estima tions studying inclusion data structures base addresses parameter model r analysis cache performance operating systems multiprogramming templates solution linear systems building blocks iterative methods users guide harwellboeing sparse matrix collection cache miss prediction sparse matrix computations cache miss equations analytical representation cache misses cache profiling spec benchmarks case study sparse matrix technology sparse matrix computations implications cache designs characterizing behaviour sparse algorithms caches cache interference phenomena tracedriven memory simulation survey tr analysis cache performance operating systems multiprogramming characterizing behavior sparse algorithms caches sparse matrix computations cache interference phenomena block algorithms sparse matrix computations high performance workstations tracedriven memory simulation cache miss equations cache profiling spec benchmarks ctr gerardo bandera manuel ujaldn emilio l zapata compile runtime support parallelization sparse matrix updating algorithms journal supercomputing v17 n3 p263276 nov 2000 basilio b fraguela ramn doallo emilio l zapata probabilistic miss equations evaluating memory hierarchy performance ieee transactions computers v52 n3 p321336 march chunyuan lin jenshiuh liu yehching chung efficient representation scheme multidimensional array operations ieee transactions computers v51 n3 p327345 march 2002 b b fraguela r doallo j tourio e l zapata compiler tool predict memory hierarchy performance scientific codes parallel computing v30 n2 p225248 february 2004 jingling xue xavier vera efficient accurate analytical modeling wholeprogram data cache behavior ieee transactions computers v53 n5 p547566 may 2004 chunyuan lin yehching chung jenshiuh liu efficient data parallel algorithms multidimensional array operations based ekmr scheme distributed memory multicomputers ieee transactions parallel distributed systems v14 n7 p625639 july