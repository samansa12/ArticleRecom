buffered banks multiprocessor systems abstracta memory design based logical banks analyzed shared memory multiprocessor systems design physical bank replaced logical bank consisting fast register subbanks slower memory subbanks buffered input output queues substantially reduce effective cycle time reference rate saturation principal contribution work development simple analytical model leads scaling relationships among efficiency bank cycle time number processors size buffers granularity banks scaling relationships imply interconnection network sufficient bandwidth support efficient access using highspeed memory lowerspeed memory substituted little additional interconnection cost scaling relationships shown hold full datapath vector simulation based cray ymp architecture model used develop design criteria system supports 192 independent reference streams performance system evaluated simulation range loading conditions b introduction gap memory speed processor request rate increasing rapidly high performance systems gap due decrease processor cycle time use superscalar multiple issue mecha nisms increase number processors shared memory systems demands gigabit per second network commu nication addition designers sought replace expensive sram memories cheaper slower drams order support dramatically increased main memory sizes reasonable cost face demands several manufacturers introduced complex circuitry dram chips order reduce effective memory access time mit subishi example introduced proprietary cached dram chip small sram reduces memory access time reference contained sram 9 another cached dram developed rambus 6 approaches include synchronous dram technology 14 enhanced dram technology 4 pipelined memories also proposed 11 effect memory hierarchies highperformance memory systems extensively studied ordinary interleaved memory memory cycle time minimum time required successive references memory module cycle time regulates quickly processor fill memory pipeline conflicts due bad reference patterns cause processor block latency time takes read request navigate memory pipeline return value processor hierarchical memory systems contain caches bank level memory cycle time latency longer constant caching reduce effective cycle time latency paper explores buffering alternative supplement caching chip level proposed design based buffering scheme called logical bank buffering physical banks subdivided buffered described section ii principal contribution paper development simple model derivation scaling relationships among efficiency bank cycle time number processors size buffers granularity banks goal logical bank design provide mechanism using large slower memories moderate number high performance processors maintaining current operating efficiency second contribution work full datapath simulation register feedback realistic interconnection network high performance machines cray mp separate interconnection network read return values simple memory banks replaced memory hierar chy references arrive return network unpredictable times moderate loading resulting contention appear problem several approaches equalizing performance reads writes heavy loading examined buffering proposed number authors possible solution problem memory conflicts simulation study briggs 2 showed buffering processor level pipelined multiprocessors improve memory bandwidth provided average request rate exceed memory service time smith taylor 20 explored effects interconnection network buffering realistic simulation model simulations paper based simi lar simpler interconnection network buffering paper memory modules rather within interconnection network emphasis simulations verification scaling relationships proposals reduce memory conflicts made skewing related techniques 781213 shown effective reducing intraprocessor conflicts recent simulation study sohi 21 explores skewing input output buffering single reference streams consisting vectors length 1024 fixed strides skewing techniques effective situation considered paper conflicts processors main cause performance degradation skewing used conjunction logical banks reduce intraprocessor contention study uses memory efficiency throughput primary measures memory performance efficiency memory system defined ratio total memory requests total number memory requests includes requests denied conflict bank conflict assumed conflict occurs processor attempts reference next cycle memory efficiency measured viewpoint processor indicates degree processors able successfully issue memory references efficiency essentially pa probability acceptance calculated briggs davidson 3 models lm memories without buffering following sohi 21 throughput defined ratio vector references conflictfree system actual time vector references sohi argues ratio appropriate throughput measure comparing memory designs vector processing environment throughput fraction optimal rate entire vectors delivered system vector element read latency defined time first attempt access vector element availability element vector register efficiency depends number processors number banks bank cycle time load unbuffered designs multiprocessor machines give quadratic relationship memory speed number banks fixed performance 1 memory cycle time doubled relative processor speed interconnection costs must quadrupled maintain memory performance proposed design twotier system results show interconnection network bandwidth sufficient support processors using highspeed mem ory lowerspeed memory buffers substituted little additional interconnection cost performance degradation section ii describes logical bank design analytical model writes developed section iii shown reasonable agreement random reference simulations section iv relationship efficiency system parameters bank cycle time number banks number processors analyzed several design criteria developed applied later sections vector systems section v introduces simulation model uses synthetically generated references vector multiprocessor system similar cray ymp model incorporates full datapath simulation including return conflicts register feedback recommended simulation study smith taylor 20 vector results compared model predictions moderate processor loading section vi shown even small number buffer slots result significant gains performance section vii design criteria applied 64 processor system 192 independent reference streams heavy processor loading range stride distributions performance writes excellent degradation reads several approaches reducing degradation examined including subbank output buffering additional lines optimal ar bitration port handshaking portline buffers increased return bandwidth found last alternative completely eliminates degradation final discussion conclusions presented section viii ii logical banks logical bank 16 consists fast register logical bank register lbr number subbanks queue pending requests shown figure 1 memory within logical bank divided equal subbanks addressed using standard interleaving techniques consecutive addresses go consecutive subbanks reference logical bank gated lbr la cycles register free la logical bank access time room queue specified subbank reference routed queue otherwise lbr remains busy slot available one reference logical bank occur interval l l called logical bank cycle time minimum time interval successful references logical bank interval may longer lbr waiting queue slot reference streams attempt access logical bank lbr busy logical bank conflict occurs one reference delayed model simulations discussed later assumed la parameters define multiprocessor system shared memory organized logical banks shown table 1 default values used later simulations except otherwise indicated singleport processors number reference streams n also equal number pro cessors vector simulations processors allowed multiple ports reference streams pro cessors reference streams assumed either read write read streams difficult handle values must returned processor return fanin network reads requires additional hardware arbitration read values arrive fanin network predictable time return values must include tag bits indicating destination hardware also required cached drams used since effective access time longer constant case either fact cached drams used conjunction logical banks reduce effective physical subbank cycle time little additional hardware logical banks introduced seznec jegou support data synchronized pipeline architecture dspa 19 design includes reordering unit data flows logical bank chronological order scheme proposed paper reordering unit required logical bank reordering occurs processor buffering distinct caching miss penalty overhead cache management proposed circuitry would take small chip area incorporated chip alternatively could built interface offthe shelf memory chips system interconnection network particularly appropriate situations average utilization maximum capacity periods maximal loading addition reducing average access time logical banks smooth type bursty memory traffic typical highly vectorized programs 17 iii model random writes model efficiency logical bank memories derived later sections throughput latency related ef ficiency assumed reference stream initiate one reference per clock cycle reference attempt fails retried reference stream following cycle long lbr available processor sees memory consisting logical banks cycle time l logical bank cycle time efficiency case given e l efficiency determined interreference stream conflicts logical bank level queues full memory behaves almost though logical banks effective memory cycle time case minimum delay incurred transferring reference queue subbank c physical memory cycle time efficiency case denoted e p simple probabilistic argument shows probability successful reference e expected number attempts per successful reference isx e average number cycles takes reference stream initiate reference viewpoint processor contrast average reference time viewpoint physical memory directly related bank cycle time delays let p probability logical bank register lbr available reference first initiated successful reference take 1 attempts conditional probability p 1 attempts probability effective efficiency weighted average two cases depending probability slots available appropriate subbank queue average number cycles successful reference estimated bye e combined effective efficiency relationship written expression effective efficiency called logical bank model remainder paper probability p lbr full estimated considering logical bank system k independent queues md1b queuing discipline queuing model exponential arrival rate deterministic service time one server finite queue fixed queue size distribution number references queue depends parameter ae p average arrival rate p effective queue service time estimated q probability free stream initiates reference n number independent reference streams b number physical subbanks kl simple simulation used compute table probabilities given value ae queue size probabilities individual queues free determined value p entire logical bank estimated follows k subbanks per logical bank lbr busy k queues m1 slots filled extra slot lbr thus f probability queue size 1 full probability lbr method used calculate p graphs given later estimates e p e l de rived situation logical banks analyzed random accesses bailey 1 systems n singleport processors b memory banks let memory bank cycle time processor modeled markov chain state processor waiting bank busy cycles 0 denotes state processor derived steady state expression efficiency system q represents probability free processor attempt reference current clock cycle relevant values n b efficiency dominated expression square root r efficiency inversely proportional drops fairly rapidly bank cycle time doubled number banks must increased factor four maintain efficiency bailey model used estimate e p using bank cycle time logical bank efficiency e l also estimated using bailey model l number logical banks system l logical bank cycle time assumed one much discussion paper due assumptions made derivation bailey model performs poorly small number processors bank cycle time near one unfortunately effective efficiency sensitive value e l p close one another model developed model called direct model derived using markov chains manner similar used bailey assume reference stream one three states free state 1 state making successful reference 2 state attempting reference unsuccessful 3 let probability given free stream attempt reference probability stream probability stream making successful reference probability stream making unsuccessful reference probability reference attempt successful following probability conservation equation holds matrix gamma state transition probabilities given table 2 gamma ij entry ith row jth column represents conditional probability next state given current state j reference attempt successful higher priority stream making reference bank average half remaining streams higher priority given stream since one higher priority stream make successful reference bank probability one streams making successful reference one l banks may estimated 2l ffi given 2l vector priori probabilities three states steady state probabilities obtained relationship given equations plus conservation equation used obtain expression direct model better agreement simulations used estimate e l remainder paper iv predictions model buffering produce fairly dramatic improvements efficiency provided memory system close saturation section logical bank model compared model simulations random references excellent agreement comparison validates model suggests relationships design parameters necessary achieving particular level efficiency following sections vector simulation model compared randomreference model relationships suggested analytical model tested consider multiprocessor system independent reference streams shared memory consisting 256 banks parameters represent eightprocessor cray ymp three ports per processor maximal memory configuration performance system compared augmented system physical bank replaced logical bank consisting single subbank queue size two case corresponds adding buffering physical bank level without adding additional logical bank structure buffers lbr reference streams assumed generate writes figure 2 efficiency random reference streams plotted versus subbank cycle time following bailey 1 reference rate selected give base operating efficiency unbuffered case 67 logical bank model agrees well results scalar simulations operating efficiencies 6 significant improvement performance observed buffering bank cycle time 18 simulation shows efficiency 22 without buffering efficiency 66 buffering memory efficiency real cray ymp higher predicted 67 selected buffering mechanisms incorporated various stages cray ymp interconnection network described smith taylor 20 figure 3 efficiency plotted versus number reference streams excellent agreement model predictions random reference simula tions base efficiency 67 maintained many 96 reference streams buffering introduced bank level logical bank model overestimates efficiency near saturation md1b queuing model assumes references thrown away queues full processor attempts initiate reference next cycle certain probability q 1 real system simulation reference retained tried next cycle simple analysis presented shows queue sizes quite small give substantial improvements performance table 3 shows probability number items queue less queue size different values different system loadings ae 5 probability queue fewer three slots two queue slots plus lbr filled 9731 value indicative small queues suffice estimate may completely accurate near saturation references fulfilled thrown away model hence infinite queue case considered infinite queue model references never blocked always queued expected queue size subbank infinite queue case 10 exqueue ae 5 expected queue size less 25 subbank table 4 shows probability queue contains x items queue infinite queue case probability two fewer slots filled 947 probability borderline reasonable performance probability four fewer elements queue 9957 subbank input queue size four adequate handle references p 1 effective efficiency e l fixed load q e l constant constant 2l furthermore obtained noting e l decreasing function q ffl condition ffl 1 means least five times many logical banks reference streams efficient performance buffered unbuffered cases compared case one subbank per logical bank effect buffering efficiency held constant 5 subbank cycle time number banks increased paper assumed decreasing since ffl depends number processors number banks queue size four probability logical bank hit 9957 efficiency approximately l since e l independent c increasing function l b logical bank model predicts efficiency actually increase slowly bank cycle time number banks increased ae held fixed 5 thus fixed reference rate q doubling c compensated doubling number banks halving number processors reference streams contrast system without logical banks c b must remain fixed maintain efficiency systems without logical banks one would quadruple number banks order compensate doubling bank cycle time argument applied system queue size two probability logical bank hit least 947 efficiency weighted average relatively constant logical bank efficiency e l unbuffered efficiency e p latter efficiency drops rapidly bank cycle time confirm relationships models without logical banks load q fixed 4 number reference streams fixed 24 figure 4 efficiency plotted versus subbank cycle time number banks varied ae held constant 5 logical bank model maintains almost constant efficiency bank cycle time increased predicted queue size four system queue size two shows slight falloff efficiency initially lower asymptotic value bank cycle time small ae held 5 banks logical bank conflicts become significant bailey model run parameter values efficiency drops dramatically predicted model similar scaling relationships derived bank cycle time fixed number banks number reference streams varied one use relationship ae e determine design parameters required achieve specified level performance cray ymp eight processors three ports per processor 24 independent reference streams bank cycle time five 256 physical banks maximum reference rate 1ffl queue size four probability logical bank hit nearly one efficiency simply estimated previous expression ffl 256 logical banks one subbank per logical bank 92 logical bank model predicts buffering four queue slots result high efficiency unbuffered efficiency predicted bailey model parameters 56 model predictions tested section vii vector simulation results logical bank model summarized follows fully loaded system consisting n reference streams l logical banks logical bank cycle time one subbank input queue size four efficiency greater 90 provided ae queue size two ae chosen less 2 notice first relationship depends total number subbanks b second relationship depends number logical banks l per processor interconnection costs depend l long enough logical banks adequately field requests processors increase bank cycle time compensated increase number subbanks without significant increase interconnection costs point however data bus arbitration scheme able handle read return traffic point discussed fully section vii increase l one effect lowering overall efficiency curves shape design parameters determined case using bailey model estimate e l efficiency depends parameter efficiency 90 obtained provided v vector simulation model order test performance logical bank organization predictions logical bank model simulation study based cray ymp architecture interconnection network developed cray ymp architecture selected highly pipelined interconnection network provide effective l 1 accomplished references issue immediately interconnection network block later conflicts arise complete data path simulation system processor register feedback performed reference streams generated randomly realistic assumptions simulation includes ports lines sections subsections described vector simulation model assumes n p processors p ports processor initiate p memory operations cycle ports assumed generate independent reference streams n port designated either read stream write stream interconnection model simplified version network described smith taylor 20 processor four lines direct connections particular sections memory ports particular processor access memory crossbar connection processors four lines section number determined lowest two bits address consecutive references directed different sections memory section divided eight subsections individual subsections subdivided banks case cray ymp 256 banks subsection contains eight banks following notation smith taylor interconnection network denoted 8 processors 4 theta 48 theta 8 1 theta 8 256 memory banks simulations systems n p processors l logical banks number subsections fixed eight number banks per subsection increased interconnection described np processors 4 theta 4np theta 81 theta l8l memory banks cray ymp processor access particular subsection every c cycles c physical bank cycle time means processor accesses memory bank processor blocked issuing additional references entire subsection containing bank full bank cycle time conflict called subsection conflict like section conflict strictly intraprocessor conflict references different processors subsection proceed without conflict provided addressed banks already use simulation logical banks based conflict scheme described particular memory location referenced line subsection logical bank subbank numbers calculated line free reserved r cycles subsection checked subsection free reserved cycles logical bank checked logical bank register lbr free reserved l cycles reference initi ated reference generates hold fails issue conflict occurs level reference occupied lbr l cycles moved appropriate subbank queue queue full reference must spend cycles queue processed physical memory assumed reference must occupy subbank least c cycles subbank accept another refer ence operation write subbank free accept another reference c cy cles reads complicated return trip processor described vector read reference considered completed element values arrived processor read data values must routed physical memory bank appropriate processor vector reg ister additional conflicts may occur one value may become available particular cycle logical bank single output latch latch free value moved subbank latch subbank freed latch busy subbank must wait latch free accepting another value output queue included subbank shown figure 1 value moved subbank output queue blocking subbank due return conflicts less likely occur data values latched particular processor line compete processing return interconnection network real system separate forward return interconnection networks simplify simu lation return interconnection network modeled pipeline accept one value per section per cycle pipeline length assumed ten accounts length forward return pipelines last value vector read emerged pipeline read considered complete simulation also incorporates feedback loop vector registers memory processor certain number vector registers eight assumed runs paper vector operation initiated simulation free processor vector register randomly selected reserved duration operation register available operation holds register becomes available register reserved operation freed elements vector arrived processor contrast vector write considered completed last element operation issued vector register freed time although actual memory value may inserted sometime later buffering priority simulation rotated among processors circular fashion processor favored scheme similar priority scheme used cray x mp cray ymp uses fixed subsection priority scheme lend modification number processors varied priority scheme little effect results simulation simulation generates representative reference stream vectorized code described memory operations assumed vector operations associated stride length gatherscatter operations considered simulation stride fixed interval successive references within single vector opera tion stride one assumed probable strides maximum stride equally probable default probability stride one vectors 75 used unless otherwise indicated effect type load performance examined section vii maximum length vector operations determined length vector registers processor operation long vector required compiler splits several vector operations one uses maximum vector register length possible vector lengths assumed equally probable except maximumlength assumed occur frequently system load determined operation initiation rate port free certain probability p f current cycle memory operation initi ated value p f may different read write ports measure system load relationship p f scalar reference rate q derived order compare vector case scalar case already discussed let vl maximum allowed vector length p l probability maximum length reference average length vector reference 0118 value used bailey 1 calculations efficiency unbuffered case study interreference times vector references perfect club benchmarks run cray ymp 18 shows typical interreference times order 10 200 cycles value appears reasonable parameters used simulation chosen close current cray ymp values summarized table 5 scalar simulations performed section iv performed setting unbuffered case l physical bank cycle time seen interconnection network vector data path simulator written c run network sun worksta tions vector simulations done paper run one hundred thousand cycles although runs long ten million cycles run divided blocks cycles statistics computed block addition entire run statistics longer runs vary significantly shorter runs lack variation unexpected since port processor initiate reference cycle large number independent reference streams statistics averaged vi results moderate loading figure 5 shows comparison efficiencies function bank cycle time vector simulation logical bank model system eight processors three ports per processor number logical banks fixed 256 one subbank per logical bank queue size four slots per subbank buffering delays drop performance increasing bank cycle time example vectors stride one bank cycle time 20 efficiency 92 logical bank buffering 22 without buffering agreement simulation logical bank model good subbank cycle times less 10 agreement model simulation better loads random component case three fourths strides one remainder randomly distributed p shown figure 5 case efficiency 68 subbank cycle time 20 overall efficiency slightly model falloff occurs roughly place predicted model logical bank model corresponds random reference streams falls simulations two different stride distributions agreement logical bank model vector simulation quite good considering vector simulation includes lines sub sections register feedback dip efficiency bank cycle times integral multiples four real phenomenon preserved long simulation runs figure 6 efficiency plotted versus number reference streams subbank cycle time five remaining parameters figure 5 number reference streams could quadrupled 24 eight processors 96 32 pro cessors still maintaining efficiency 67 analysis section iv random references predicts efficiency high increase slightly number banks bank cycle time increased keeping nb constant value 5 scaling relationship holds case vector references well figure 7 number reference streams fixed 24 eight processors number subbanks per logical bank one number banks varied linearly bank cycle time order keep ae constant 5 condition satisfied number logical banks greater 120 case provided c 3 ae held constant 5 comparison simulation set parameters run without buffering efficiency dropped dramatically subbank cycle time increased runs shown two stride distributions p previous vector runs performed read ports unbuffered memory difference memory efficiency reads writes buffering introduces unpredictable delays one result become available particular cycle interconnection network particular section conflicts type arise references delayed turn causes subbanks block return conflicts thus cause effective increase bank cycle time corresponding drop efficiency addition single output queue slot subbank eliminates difference performance reads writes moderate loading however load increased either increasing initiation rate percentage stride one vectors port return bandwidth may insufficient handle load problem addressed next section analytical model derived section iii predicts efficiency memory writes possible indicators performance include throughput latency throughput defined section fraction optimal rate entire vectors delivered system 21 vector element read latency defined time first attempt access vector element availability element vector register figure 8 compares efficiency put read latency load varied bank cycle time 20 chosen near knee curves figure 5 parameters figure except bank cycle time fixed initiation rate varied probability op p f refers probability vector operation initiated free port value corresponds value figure 5 throughput slightly higher efficiency unbuffered case slightly lower efficiency buffered case buffered throughput still considerably better unbuffered throughput unbuffered case read latency constant plus number attempts takes issue request mentioned section iii number attempts reciprocal efficiency fact unbuffered case read latency curve figure 8 predicted better 3 percent efficiency curve unbuffered read element latency 36 buffered read element latency 51 efficiency least moderately good indicates last element vector read delayed 15 cycles would without buffering buffering read latency affected return conflicts dependent return scheme used different return schemes discussed next section since writes require return path write element latency directly related number attempts issue element operation write latency curves shown predicted efficiency curve within percent buffered unbuffered case vii results maximal loading extreme case port attempts memory reference cycle con sidered first analysis done writes logical bank model used pick design parameters 64processor system performance reads analyzed improvements return interconnection network considered equalize performance reads writes logical bank model used guide picking design parameters 64 processor cray ymp minimizes per processor interconnection cost achieving efficiency least 90 assuming load 10 condition ffl 1 gives l 960 assuming bank cycle time five condition ae 5 gives b 1920 number logical subbanks powers two thus 64 processors configuration operates minimum per processor interconnection cost high efficiency 1024 logical banks 2048 physical sub banks ae approximately 5 queue size four required 99 probability available queue according table 4 queue size two four subbanks per logical bank required bring ae 3 figure 9 shows performance designs function percentage stride one vectors case two subbanks per logical bank queue size four indistinguishable case four subbanks per logical bank queue size two predicted logical bank model case 2048 banks queue size two shown comparison logical bank model based assumption random references account presence bad strides buffering shown reduce effect bad strides moderate loading 7 designs preclude use address mapping alleviate intraprocessor conflicts 58 reads difficult handle hot spots develop return lines shown figure 10 performance difference reads writes function stride quite dramatic even surprising fact performance reads actually drops percentage stride one vectors load increased drop occurs arbitration method used return simulations simple round robin priority scheme logical banks reference particular port de layed causes banks waiting port delayed system operating sustained maximal initiation rate ports never catch various solutions solving hotspot problem examined including additional output buffering physical sub banks additional lines optimal arbitration port handshaking portline queues additional return ports found additional lines alone solve problem queue depths subbank required make significant difference efficiency optimal arbitration logical banks examined round robin succession port reference made already use reference block line another reference issued port handshaking control mechanism particular port blocked initiating reference return conflict port previous cycle methods improve performance bring read performance write performance vector strides one since drop read performance appeared due insufficient return port bandwidth two alternative approaches developed increase bandwidth first approach involved adding portline queues design modification port contains queue line line deposit result port cycle port services one queue per cycle round robin succession second approach involved doubling number return ports one possible design return port oddnumbered vector elements another return port evennumbered vector elements alternative design designate one return port pair return lines second alternative would simplify portline interconnection switches would complicate vector register bus structure internal processors figure 11 compares portline buffering doublereturn ports variety strides maximal loading output buffering subbanks eliminated port line buffering improves efficiency increase port bandwidth doubling number return ports brings read efficiency line write efficiency viii discussion main result paper summarized follows shared memory system sufficient bandwidth achieve high efficiency fast memory replacement physical banks logical banks allow efficiency achieved using considerably slower memory without significantly affecting interconnection costs type buffering particularly useful vector multiprocessors vector memory operations naturally pipelined increases memory latency partially amortized entire vector operation logical bank model detailed vector simulations given paper show number logical banks scales number processors bank cycle time scales number physical banks consequently slower memory used logical banks divided subbanks contrast unbuffered case bt 2 c n must constant constant efficiency change inverse quadratic inverse linear dependence bank cycle time number banks particularly important drawback memory systems variable bank cycle time values become ready return unpredictable times approach seznec jegou reorder values bank level solve problem values arriving processor order issued problem addressed cray ymp architecture addition tag return value cray ymp architecture allows three independent vector memory operations proceed simulta neously vector memory operations chained vector registers vector registers turn chained functional units chaining allows results produced one vector operation used input succeeding operation first instruction completed component results first instruction used second instruction become available pipeline setup occur component previous operation available 15 current architecture values arrive order vector register keeps track last value arrived values arrive order vector element must bit indicating whether value arrived additional hardware incorporated chain forward next element arrived relative order among different registers assured existing reservation issue mechanisms well known 1 memory performance shared memory vector processors strongly dependent type load generated since choice load distribution affects results desirable test design realistic loading con ditions addresstrace collection methods 22 useful generating statistical information load information collected types investigations difficult use directly testing new designs efficiency depends actual addresses exact time references issued diffi culties approach taken paper develop guidelines applicable range load distributions larger number reference streams less serious impact details one reference stream overall efficiency buffering greatly reduces dependence memory efficiency type load writes illustrated runs two previous sections dependence load occurred return conflicts reads number alternative designs evaluated effort reduce performance degradation due return conflicts found doubling number return ports eliminated difference reads writes range loads acknowledgment work supported cray research inc computational support provided university texas center high performance computing national science foundation ili program grant use0950407 r vector computer memory bank contention effects buffered memory requests multiprocessor systems ganization semiconductor memories parallelpipelined processors enhanced dynamic ram simulation study cray xmp memory sys tem fast path one memory vec tor access performance parallel memories using skewed storage scheme address transformations increase memory performance dynamic ram secondary cache art computer systems performance analysis 12mhz data cycle 4mb dram pipeline operation prime memory system array access scrambled storage parallel memory systems synchronous dynamic ram cray xmpmodel 24 case study pipelined architecture vector pro cessing bus conflicts logical memory banks cray ymp type processor system dynamic behavior memory reference streams perfect club benchmarks charac terization memory loads vectorized programs optimizing memory throughput tightly coupled multiprocessor accurate modeling interconnection networks vector supercomputers highbandwidth interleaved memories vector processors simulation study address tracing parallel chines tr ctr hua lin wayne wolf codesign interleaved memory systems proceedings eighth international workshop hardwaresoftware codesign p4650 may 2000 san diego california united states del corral j llaberia minimizing conflicts vector streams interleaved memory systems ieee transactions computers v48 n4 p449456 april 1999 toni juan juan j navarro olivier temam data caches superscalar processors proceedings 11th international conference supercomputing p6067 july 0711 1997 vienna austria anna del corral jose llaberia increasing effective bandwidth complex memory systems multivector processors proceedings 1996 acmieee conference supercomputing cdrom p26es january 0101 1996 pittsburgh pennsylvania united states