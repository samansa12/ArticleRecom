realtime garbage collector low overhead consistent utilization use garbage collection languages like java becoming widely accepted due safety software engineering benefits provides significant interest applying garbage collection hard realtime systems past approaches generally suffered one two major flaws either provably realtime imposed large space overheads meet realtime bounds present mostly nonmoving dynamically defragmenting collector overcomes limitations avoiding copying cases space requirements kept low fully incrementalizing collector able meet realtime bounds implemented algorithm jikes rvm show realtime resolution able obtain mutator utilization rates 45 1625 times actual space required application factor 4 improvement utilization best previously published results defragmentation causes 4 traced data copied b introduction garbage collected languages like java making significant inroads domains hard realtime concerns automotive commandandcontrol systems however engineering product lifecycle advantages consequent simplicity permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copy otherwise republish post servers redistribute lists requires prior specific permission andor fee popl03 january 1517 2003 new orleans louisiana usa copyright c acm 1581136285030001 500 programming garbage collection remain unavailable use core functionality systems hard realtime constraints must met result realtime programming requires use multiple languages least case realtime specification java 9 two programming models within language therefore pressing practical need system provide realtime guarantees java without imposing major penalties space time present design realtime garbage collector java analysis realtime properties implementation results show able run applications high mutator utilization low variance pause times target uniprocessor embedded systems collector therefore concurrent parallel choice complicates simplifies design design complicated fact collector must interleaved mutators instead able run separate processor design simplified since programming model sequentially consistent previous incremental collectors either attempt avoid overhead complexity using noncopying approach therefore subject potentially unbounded fragmentation attempt prevent fragmentation performing concurrent copying therefore require minimum factor two overhead space well requiring barriers reads andor writes costly tend make response time unpredictable collector unique occupies underexplored portion design space realtime incremental collectors mostly noncopying hybrid long space available acts like noncopying collector consequent advantages space becomes scarce performs defragmentation limited copying objects show experimentally design able achieve low space time overhead high consistent mutator cpu utilization order achieve high performance copying collector developed optimization techniques brooksstyle read barrier 10 using eager invariant keeps read barrier overhead 4 order magnitude faster previous software read barriers collector use either time workbased scheduling previous work realtime garbage collection starting bakers algorithm 5 used workbased scheduling show analytically experimentally timebased scheduling superior particularly short intervals typically interest realtime systems workbased algorithms may achieve short individual pause times unable achieve consistent utilization paper organized follows section 2 describes previous approaches realtime collection common problems encountered section 3 presents informal overview collector section 4 analyzes conditions realtime bounds met section 5 analyzes space requirements collector compares realtime collectors section 6 describes implementation collector section 7 presents experimental results section 8 discusses issues realtime garbage collection raised work finally present conclusions 2 problems previous work previous approaches realtime garbage collection generally suffered variety problems section describe problems 21 fragmentation early work particularly lisp often assumed memory consisted cons cells fragmentation therefore non issue bakers treadmill 6 also handles single object size johnstone 17 showed fragmentation often major problem family c c benchmarks built nonmoving realtime collector based assumption fragmentation could ignored however measurements based relatively shortrunning programs believe apply longrunning systems like continuousloop embedded devices pdas web servers fundamentally averagecase rather worstcase assumption meeting realtime bounds requires handling worstcase scenarios furthermore use dynamically allocated strings java combined heavy use strings webrelated processing likely make object sizes less predictable dimpsey et al 14 describe compaction avoidance techniques ibm product jvm based johnstones work show techniques work quite well prac tice however compaction occur expensive siebert 23 suggests single block size used java allocating large objects linked lists large arrays trees however approach simply traded external fragmentation internal fragmentation siebert suggests block size bytes large number 8byte objects internal fragmentation cause factor 8 increase memory requirements 22 high space overhead avoid problems resulting fragmentation many researchers used copying algorithms 5 10 basis realtime collection collectors typically high space overhead first full collection performed complete semispace required target data minimum space overhead factor 2 secondly space required mutator continue run allocate collector operates order achieve good mutator utilization collector running space overhead factor 35 typical 12 johnstones noncopying collector 17 space overhead often factor 68 23 uneven mutator utilization much literature focused maximum pause times induced collection fact equally important metric mutator utilization fraction processor devoted mutator execution period low utilization mutator may unable meet realtime requirements even though individual pause times short uneven utilization endemic collectors use tospace invariant mutator sees objects tospace collectors implemented readbarrier checks object accessed fromspace copies tospace returning pointer mutator therefore tight coupling operations mutator scheduling operations collector examples bakers copying algorithm 5 uses explicit readbarrier appelellisli collector 2 uses virtual memory protection collectors property mutator utilization poor right collector starts fault rate high alternative use replicating collector maintains fromspace invariant perform mutator updates fromspace tospace ml collectors nettles otoole 21 cheng blelloch 12 however requires fairly costly replication updates rather simple write barrier pointer updates result strategy better suited mostly functional languages like ml less wellsuited imperative languages like java 24 inability handle large data structures algorithms attempt avoid factor 2 space overhead copying collectors work incrementally collecting portion heap time notable example train algorithm 16 recently benyitzhak et al 7 implemented parallel incremental collector operates fixed fraction heap time minimize pause times large heaps fundamental problem algorithms attempt collect subset heap time defeated adversarial mutators large cyclic structures objects high degree high mutation rates ways force collectors perform work without fixed bound 3 overview collector incremental uniprocessor collector targeted embedded systems overcomes problems previous section using hybrid approach noncopying marksweep common case copying collection fragmentation occurs collector snapshotatthebeginning algorithm allocates objects black marked argued collector increase floating garbage worstcase performance different approaches termination condition easier enforce realtime collectors used similar approach 31 overview collector collector based following principles segregated free lists allocation performed using segregated lists memory divided fixedsized pages page divided blocks particular size objects allocated smallest size class contain object mostly noncopying since fragmentation rare objects usually moved defragmentation page becomes fragmented due garbage collection objects moved another mostly full page read barrier relocation objects achieved using forwarding pointer located header object 10 read barrier maintains tospace invariant mutators always see objects tospace incremental marksweep collection standard incremental marksweep similar yuasas snapshotatthebeginning algorithm 24 implemented weak tricolor invariant extend traversal marking redirects pointers pointing fromspace point tospace fore end marking phase relocated objects previous collection freed arraylets large arrays broken fixedsize pieces call arraylets bound work scanning copying array avoid external fragmentation caused large objects since collector concurrent explicitly control interleaving mutator collector use term collection refer complete marksweepdefragment cycle term collector quantum refer scheduler quantum collector runs 32 object allocation fragmentation allocation performed using simple segregated freelist ap proach free list empty new page chosen broken equalsize blocks resulting blocks placed onto list note allocator page size necessarily operating system page size use kb internal fragmentation regulated using geometric progression list sizes free list whose blocks size next larger size s1 generally choose resulting worstcase fragmentation 125 ever measured internal fragmentation collector never exceeded 2 programs obey locality size property object sizes allocated frequently past tend high correlation object sizes allocated future therefore expect normal case garbage collector find unused blocks particular size class simply reused relatively rare cases object allocation cause external fragmentation collector performs defragmentation choose results low internal fragmentation allows relatively large number size classes collectors based segregated lists must concerned external fragmentation therefore keep number size classes small choosing leading poweroftwo size classes high internal fragmentation overhead decreasing may need one underutilized page per size class assuming 4byte word size number size classes c bounded free lists actually kept chains pages rather chains blocks page associated mark array allocation cursor actually pair pointing page block within page organization allows formatting pages performed lazily therefore avoids full sweep memory collection 33 defragmentation end sweep phase determine whether sufficient number free pages allow mutator continue execute another collection cycle without running mem ory assuming worstcase selection object sizes mutator assume mutator act adversarially maximize external fragmentation number free pages drops threshold perform defragmentation free least many pages defragmentation performed follows page compute number live objects pages within size class sorted occupancy finally move objects least occupied occupied pages within list note never causes new pages allocated transfers objects pages within size class 34 read barrier use brooksstyle read barrier 10 maintain tospace invariant mutator object contains forwarding pointer normally points object moved points moved object collector thus maintains tospace invariant sets comprising fromspace tospace large intersection rather completely disjoint pure copying collector use read barrier tospace invariant collector suffer variations mutator utilization work finding moving objects performed collector read barriers especially implemented software frequently avoided considered costly show case implemented carefully optimizing compiler compiler able optimize barriers fundamental design choice read barrier whether lazy eager lazy barrier property registers stack cells point either fromspace tospace objects forwarding operation performed time use eager barrier hand maintains invariant registers stack cells always point tospace forwarding operation performed eagerly soon quantity loaded eager barriers major performance advantage quantity loaded dereferenced many times instance reference array integers loaded used loop eager barrier perform forwarding operation lazy barrier perform forwarding operation every array access course cost eager invariant strict complex maintain whenever collector moves objects must find outstanding register stack cells reexecute forwarding operation apply number optimizations reduce cost read barriers including wellknown optimizations like common subexpression elimination well specialpurpose optimizations like barriersinking sink barrier point use allows nullcheck required java object dereference folded nullcheck required barrier since pointer null barrier perform forwarding unconditionally optimization works whatever nullchecking approach used runtime system whether via explicit comparisons implicit traps null dereferences important point avoid introducing extra explicit checks null guarantee exception due null pointer occurs place would original program result optimizations mean cost 4 read barriers shown section 7 35 arraylets large objects pose special problems garbage collectors copying collectors repeatedly copied performance penalty high noncopying collectors external fragmentation make impossible allocate large object instance single small object middle heap make impossible satisfy request object slightly larger half heap furthermore incremental realtime collectors large objects pose additional problem moved reasonably bounded amount time siebert 23 suggested using fixedsize blocks 32 64 bytes object allocations creating large arrays using tree structure unfortunately requires rewriting every array access loop severe performance penalty arrayintensive programs since common loop optimizations defeated mostly noncopying collector allows different contiguously large arrays twolevel structures consisting sequence arraylets arraylet except last fixed size chosen power two division operation required indexing implemented shift arraylet size therefore advantage never needing allocate large objects contiguously therefore subject external fragmentation hand access array elements still efficient combined stripmining optimizations usually efficient contiguous layout arraylet size must chosen carefully tradeoffs involved sufficiently large size one assume objects contiguous smaller arraylet size simplifying implementation maximum array size represented single root size 2 4 1 mb case however necessary simply allocate entire block root array wasted space end block negligible compared total size array thus accommodate arrays size 4 8 mb larger objects scan free block list necessary number contiguous free blocks system must able return objects larger 8 mb real time maximum size tuned varying arrays represented uniform manner arraylet pointers laid reverse order left array header array contiguous one arraylet pointer points data field right header arraylets implemented system presented paper yet highly optimized however use arnolds thin guards 3 eliminate indirection array types exist arraylets array accesses operate full speed arraylets stripmine regular iterations ar raylet size thus arraylets suffer performance penalties used access pattern irregular 36 open issues main issue addressed collector making stack processing incremental issue two parts system root scanning maintenance eager invariant read barrier stacklets 13 break stacks fixedsize chunks quantize associated work however provide partial solution copy top stacklet running thread return mutator mutator begin either pushing popping high rate high rate popping problematic collector must halt mutator copies popped stacklet many stacklets popped short interval mutator utilization temporarily become low also force memory consumption stack double due snapshots high rate pushing problematic collector may trouble keeping mutator case solution model stack pushes enter new stacklets modelled allocation use associated methods measuring controlling allocation rates benchmarks available us stacks remained small limiting factor pause time resolution operating system clock therefore implementation presented paper include stacklets intend address issue incrementalizing stack operations future work particular exploring alternative write barriers termination conditions 4 realtime scheduling section derive equations cpu utilization memory usage collector using two different scheduling poli cies one based time based work define realtime behavior combined system comprising user program garbage collector following parameters instantaneous memory allocation rate time mbs instantaneous garbage generation rate time mbs p garbage collector processing rate mbs since tracing collector measured live data time idealized axis collector runs infinitely fast call mutator time practical matter thought time measured program sufficient memory run without garbage collecting convention uppercase letters refer primitive quantities lowercase quantities derived primitive parameters required relative rates mutator collector basic parameters define number important characteristics application relevant realtime garbage collection amount memory allocated garbage generated interval 1 2 1 maximum memory allocation interval size maximum memory allocation rate instantaneous memory requirement program exclud ing garbage overhead fragmentation time 41 mapping mutator real time consider realistic execution collector infinitely fast execution consist alternate executions mutator collector time along real time axis denoted variable function maps real mutator time functions operate mutator time written f functions operate real time written ft live memory program time thus maximum memory requirement entire program execution 42 timebased scheduling timebased scheduling interleaves collector mutator using fixed time quanta thus results even cpu utilization subject variations memory requirements memory allocation rate uneven timebased realtime collector two additional fundamental parameters qt mutator quantum amount time seconds mutator allowed run collector allowed operate ct timebased collector quantum seconds collection time time assume scheduler perfect sense always schedules mutator precisely qt sec onds typical value qt might 10 ms section 7 show close able get ideal practice cheng blelloch 12 defined minimum mutator utilization mmu given time interval minimum cpu utilization mutator intervals width parameters qt ct derive mmu qt first term numerator corresponds number whole mutator quanta interval x term corresponds size remaining partial mutator quantum defined ct expression fairly awkward number intervals becomes large reduces straightforward utilization expres sion lim qt plot mmu perfectly scheduled system using 10 millisecond mutator collector quanta shown figure 1 important note small time scales interest realtime systems x term significant ms mmu 12 maximum value 13 also higher scheduling frequency collector quickly converges theoretical limit practice large time intervals ut lower bound utilization since cases collector runs intermittently utilization figure 1 mmu perfectly scheduled timebased collector consider space utilization timescheduled collector since assuming collection rate constant time collector run mtp seconds process mt live data since collector tracebased work essentially proportional live data garbage time mutator run qt seconds per ct seconds executed collector therefore order run collection time require excess space qt ct define maximum excess space required freeing object collector may take many three collections first collect object second object may become garbage immediately collection began therefore discovered following collection cycle third may need relocate object order make use space first two properties universal third specific approach result space requirement collector paired given application including unreclaimed garbage including internal fragmentation time overall space requirement however expected space utilization et worstcase utilization highly unlikely discussed detail 43 workbased scheduling workbased scheduling interleaves collector mutator based fixed amounts allocation collection workbased realtime collector parameterized qw workbased mutator quantum number mb mutator allowed allocate collector allowed run cw workbased collector quantum number mb collector must process time mutator yields excess space required perform collection time excess space required collection entire execution note therefore must case qw cw else space may grow without bound consequently space requirement program time space requirement entire program execution 431 workbased cpu utilization computing mutator cpu utilization collector scheduling workbased inherently problematic operations mutator may affect amount time allocated mutator words time dilation linear fixed timebased scheduling variable nonlinear applicationdependent workbased scheduling due problems possible obtain closedform solution utilization begin noting mutator pause involves collector processing cw memory rate p hence mutator pause simplified model constant mutator quantum involve allocation qw memory minimum total mutator time quanta given minimum solves equa tion time interval increases maximum amount allocation time decrease monotonically increasing function hence 1 therefore solution 19 found iterative method analogous iterative solution rate monotonic scheduling realtime systems 18 let k largest integer kd k 20 minimum mutator utilization interval size first term numerator time taken k whole mutator quanta interval term corresponds size remaining partial mutator quantum defined 22 workbased collector utilization zero fact large allocation nqw bytes lead zero utilization time nd simply expresses analytically fact workbased collector much larger burden programmer achieve realtime bounds making sure memory allocation sufficiently discretized evenly spaced 44 mutation addition allocation form work mutator interact operation collector actual heap mutation mutation thought alternate way roots added along stack scanning impose following division labor mutator collector mutators write barrier responsible making sure nonnull unmarked objects placed write buffer ensures work performed collector attributable mutation n number objects keeping overhead write barrier constant collector periodically processes write buffer treats entries like potential roots marks objects gray places work queue scanning note worst case work queue reach size n must account mutation formulas collector performance mutation consumes memory like allocation mutator simply redefine comprise directly allocated memory indirectly allocated memory due mutation mutation consumes memory size one object pointer desired formulas could broken account kind space consumption individually 45 sensitivity parameters degree collector able meet predicted behavior depend quite strongly accuracy parameters used describe application collector strategy application parameters g collector parameters p either qt ct qw cw timebased workbased collectors respectively practice user describes application terms maximum memory consumption maximum allocation rate 451 sensitivity timebased collector cpu utilization rate ut timebased collector strictly dependent quantization parameters qt ct utilization steady depending implementation induced jitter subject minimum quantization implementation support hand space required perform collection et determines total space st required run application dependent maximum memory usage application amount memory allocated interval thus user underestimates either total space requirement st may grow arbitrarily particular timebased collectors subject behavior intervals time allocation rate high furthermore estimate collector processing rate p must also lower bound actual rate however space consumed application relatively long interval time namely amount time application runs single collection takes place qt ct therefore allocation rate time typically close average allocation rate program variation tend low therefore first order timescheduled collector meet time space bounds long user estimate correct 452 sensitivity workbased collector workbased collector space overhead collection ew straightforward compute accurate long user estimate total live memory accurate hand cpu utilization rate given interval depends allocation rate well collector processing rate p interval interval require realtime performance instance 20 ms since interval small peak allocation rate interval size likely quite high show section 7 thus expect cpu utilization workbased collector vary considerably allocation rate particular note timebased collector dependent allocation rate much larger scale namely amount time garbage collection therefore first order workscheduled collector meet space bound long user estimate correct cpu utilization heavily dependent allocation rate realtime interval 453 robust collector robust realtime collector primarily use timebased scheduling policy memory resources become scarce indi cating input parameters collector may degradation desirable collector begin slowing allocation rate done number ways classical approach realtime systems separate threads priority classes system becomes unable meet realtime bounds lowpriority threads successively suspended 15 another approach begin using hybrid strategy becomes progressively workbased collector comes closer memory limit approach guarantee realtime bounds met robust even allocation rate memory utilization toppriority threads underestimated done instead implemented pure timebased workbased collector scheduling policies section 7 compare experimentally tradeoffs evaluated 5 space costs compare relative space costs different types realtime collectors since purely noncopying algorithms subject high often unbounded fragmentation suitable use true realtime systems since collector significantly different architecture copying realtime collectors space bounds quite different incremental semispace copying collectors inherent space requirement 2 e maximum live heap memory e space required allow allocation proceed single garbage collection f maximum stack depth g maximum size global variable area collector expectedcase space requirement f g worstcase cost m3ef gn n maximum number uncollected objects live dead extra 2en space incurred data structure size close freed immediately beginning collection collector must run find requiring e extra space garbage found causes external fragmentation requiring extra collection cycle relocate data make available requires another e extra space program traverses heap pessimal fashion forcing maximum number pointers pushed onto work queue mark operation requires n extra words memory two things note worstcase memory requirements collector first difference worstcase collector copying collector e space e required run collection typically lower maximum live memory tuned maximum number uncollected objects maximum uncollected space divided average object size words ea since typically order 8 java programs n typically small relative thus programs worstcase space requirements collector still smaller copying semispace collector second likelihood one worstcase scenarios occurring concurrently low practice means amount memory devoted system varied expected worstcase space requirements depending acceptable failure rates system question figures include extra space overhead required bound internal fragmentation parameter set 18 implementation parameter reduced expense potentially requiring additional partially used blocks extra size classes 18 number size classes measured fragmentation exceed 2 benchmarks include space overhead due forwarding pointer since highperformance copying algorithms also use forwarding pointer bacon et al 4 shown extra header word leads 14 increase space utilization assuming one uses object model singleword header basis 6 implementation issues implemented realtime collector based ideas introduced previous sections implementing collector required coding collector proper well adding read barriers compiler certain cases infeasible introduce read barrier omitting barrier correct long pin object guarantee never moves fortunately objects fall category runtime data structures immor tal maintaining separate immortal heap omit moving objects without introducing fragmentation 61 triggering collection worstcase analysis collector run program space amount maximum live data e space required run single collection ew depending scheduling policy however executing boundary conditions result collector always running even application utilization 50 col lection lead overall slowdown program factor 2 likely unacceptable comparison running stoptheworld collector result virtually infinite slow solution provide headroom program run time collection must occur example enough headroom provided collector runs 25 time overall utilization rises 875 implementation set headroom e collection thus triggered amount memory use e 62 control interleaving ideally timescheduled collector would use precise timer control scheduling mutator collector pro cesses unfortunately aix allow userlevel access timers resolution less 10 ms therefore must 201compress 202jess 209db 213javac 222mpegaudio 227mtrt 228jack geo barrier lazy eager figure 2 relative overhead lazy eager read barriers jikes rvm optimizing compiler use approximate method based polling mutator polls timer slow path allocation moves new page mutation buffer fills keeps polling fast inlined cases subject inaccuracy however practical matter acceptable increasing mutator utilization time resource consumption low collector hand performs work progressively finer work quanta gets closer end time quantum ct time consumed close exceeds quantum mutator resumed workscheduled collector also subject inaccuracy scheduling performed slow path allocator even though precise count bytes allocated kept fast inlined path 7 measurements present empirical results section results obtained ibm rs6000 enterprise server f80 running aix 51 machine 4 gb main memory six 500 mhz processors 4 mb l2 cache virtual machine run single cpu experiments run unloaded multiprocessor operating system processes ran different cpus avoid perturbing measurements system implemented part jikes research virtual machine rvm version 211 ibm tj watson research center 1 methods compiled optimizing compiler since system realtime adaptive compilation turned measurements started dummy run benchmark forces methods compiled optimizing compiler often requires space applications heap resized compilation heap sizes given way measure intrinsic properties application rather compilation 71 read barrier costs since collector makes use read barriers read barriers often considered prohibitively expensive begin showing optimized implementation brooksstyle read barrier eager invariant achieve low overhead implemented lazy eager barriers ibm jikes rvm 1 present relative performance system without barriers read barriers initially considered expensive practical hardware support done number commercially available machines symbolics lisp machine 20 first implementation know brooks read barrier north reppy 22 concurrent collector pegasus ml however measure barrier cost total cost zorn 25 compared cost hardware software page protectionbased read barriers determined software read barriers much better protection based read barriers still cost 20 zorn measured bakerstyle read barriers require average four alubranch instructions straightforward implementation read barrier requires compare branch load however cases able optimize away compare branch perform common subexpression elimination remaining loads results shown figure 2 geometric mean lazy barrier overhead 6 maximum 11 overhead javac significantly better previous results still acceptable opinion hand geometric mean eager barrier overhead 4 maximum less 10 compress mean overhead order magnitude better previous results opinion low enough incorporation highly aggressive optimizing compiler given potential benefits space utilization incrementality shown following sections hand variance still large consider slowdown compress acceptable turns problem compress due shortcoming optimizer preventing performing loopinvariant code motion bug fixed expect overhead compress drop 5 72 collector performance tested realtime collector specjvm98 benchmarks synthetic fragger benchmark designed act adversarially allocates high rate uses maximal amount memory creates maximal fragmentation spec benchmarks mpegaudio excluded performed little allocation would necessary garbage collections addition compress excluded current implementation fully support arraylets compress makes frequent use large arrays table presents overall results benchmarks run target utilization ut ms collector quantum ms program include high watermark live data maximum memory actually used average allocation rate allocation rate entire execution whereas peak allocation measures maximum allocation rate mutator quantum qt collection rate p shows quickly collector trace live data application program show target application utilization worst actual utilization occurred average maximum pause times cluded finally show total amount moved traced data indication much defragmenting work necessary benchmarks similar amount maximum live maximum memory allocation rate coll min pause time benchmark live used ratio avg peak rate util avg max copied traced javac 34 693 20 142 2580 394 0446 113 123 121 2994 jess 21 524 25 192 942 532 0441 110 124 20 3240 jack mtrt 28 444 16 96 1143 451 0446 110 123 23 1769 db fragger 20 477 24 175 1859 384 0441 110 124 126 3070 table 1 overall results timebased collector total runtime program target mutator quantum ms target collector quantum target utilization 045 ms sizes mb rates mbs times milliseconds data 20 30 mb required anywhere 45 70 mb point execution variance space usage arises several factors heap size requirement appears primarily correlated average allocation rate instance note high allocation rate jess correspondingly high maximum memory ratio measured values rate collection p range 367 574 mbs primarily due variation pointer density data structures programs shows theoretical assumption p constant introduce large error nonetheless significant average allocation rates ranged 96 192 mbs peak allocation rates ranged 821 258 mbs spikes allocation rates demonstrate infeasibility using purely workbased scheduling policy goal maintaining high minimum utilization benchmarks ran collector target application utilization 045 obtained minimum utilization 0441 0446 thus maximum deviation 2 last two columns table 1 show amount data copied traced entire execution program maximum amount data copied 4 data traced interest ingly javac introduces amount fragmentation fragger wrote specifically fragmenting adversary program note amount data traced collector roughly comparable amount data would copied semispace collector although collector would require significantly larger heap obtain performance table 2 summarizes results changed time workbased collector scheduling table shows quantities changed appreciably timebased collector also since utilization target often zero also give utilization interval 50 ms even longer interval best case half target value average pause times considerably lower maximum pause times workbased collector much higher 92 ms fragger ms minimum mutator utilization poor measurements confirm experimentally analytic results section 4 73 detailed evaluation examine three benchmarks detail mtrt javac fragger chosen represent range difficulty collector time workbased schedul ing compare distribution pause times utilization time mmu full range intervals space consumption three benchmarks pause time distributions shown figures 3 8 figures show timebased collector achieves highly uniform pause times majority pauses 122 ms comparison workbased collector much uneven distribution note differences scale x axes workbased collector considerably shorter average pauses distribution much uneven much longer tail distribution adversarial nature fragger clearly seen figure 8 workbased collector keeps vast majority pauses 10 ms tail extends almost 100 ms one considered maximum pause time pause time distribution graphs would give impression utilization workbased collector would 23 times worse non adversarial programs however figures 9 14 show short interval order likely interest realtime systems 222 ms workbased scheduling produces large variance mutator utilization often dropping almost zero easily occur single large object allocated forcing collector perform many collector quanta row hand timebased collector performs extremely well small amount jitter due slight imprecision work predictor utilization collection almost exactly target mtrt javac first collection application enters fairly regular cycle concurrent collector 13 12 time however adversarial nature fragger apparent timebased collector collects continuously workbased collector utilization frequently drops zero figures 17 show minimum mutator utilization mmu 12 time workbased collectors superimposed one graph time scale ranges 10 milliseconds length program run small time scales mmu timebased collector almost precisely matches shape perfect curve shown figure 1 larger time scales effect mutator come play utilization rises target mmu workbased collector much lower interestingly much less sawtooth shape time scale small number collections workbased collector may briefly exceed timebased collector utilization number collections becomes large appear approach asymptotic cost compute mmu precisely using quadratic algorithm 10 seconds use approximate algorithm small error cheng belloch 12 used sampling technique plotted mmu certain values minimum pause benchmark utilization time uw uw 50ms avg max jess 0 0180 31 262 jack mtrt table 2 overall results workbased collector mutator allocation quantum processing quantum ms times milliseconds thus hiding irregularity curve blackburn et al 8 use variant mmu produces monotonic curve strictly derivable mmu curve definition utilization appropriate large time scales collectors operate several hundred milliseconds hides information important short time intervals interest true realtime systems finally figures show space consumption time time workbased collectors maximum live data collector trigger threshold also shown surprising little difference time workbased memory consumption given large differences behavior seen previous graphs variation clear winner type scheduling sometimes requires slightly slightly less space shape space curves similar slightly translated 8 realtime issues section 2 outlined problems common realtime collectors design choices made collector avoid problems following ways fragmentation avoided combination means internal fragmentation limited choosing small ratio adjacent size classes external fragmentation prevented defragmenting heap needed breaking large arrays arraylets space overhead limited using mostly noncopying al gorithm fromspace tospace mostly sharing physical storage uneven mutator utilization avoided use timebased scheduling policy sensitive variations average allocation rate small realtime intervals large intervals order full collection large data structures handled using arraylets effectively turns large objects small objects 81 flaws bakers realtime definition baker 5 begins seminal paper realtime garbage collection stating realtime list processing system one time required elementary list operations bounded small constant approach basis later work realtime collection 2 6 10 11 17 19 24 however implicitly workbased approach seen sections 4 7 small time intervals typically interest realtime systems workbased collectors may subject poor utilization baker attempts finesse problem interleaving collector mutator finegrained manner hides problem keeps individual pauses low prevent numerous closelyspaced pauses case bakers copying collector read barrier converts originally simple load instruction sequence tests loads possibly copy object let us say cost read barrier times cost original read operation consider short interval containing read operations utilization 1 ultimately comes question one means small 2 utilization probably acceptable however typical values 10 20 short intervals utilization may drop low useless saw experimentally table 2 fundamentally three ways ameliorate problem increase decrease make bimodal increasing dependent realtime requirements application example decreasing brooks variant 10 bakers algorithm read requires one extra load instruction costly barrier performed writes considerably less frequent however resolution 1 ms could lot writes write barrier unlikely less 10 often much higher utilization could still low attempts made reduce cost write barrier using store buffer 24 preallocating space copied object deferring actual copy collection time 15 nettles otoole 21 introduced replicating copying collectors 12 16 represent another point tradeoff space collectors read barrier overall cost write barrier expensive may update fromspace objects baker attempted keep performance uniform interleaving allocator cons car cdr operation however finegrained interleaving higher relative cost operations many subsequent collectors attempted reduce time overhead concurrent collection batching work appelellisli collector 2 uses virtual memory page traps extreme example however limits resolution function well cost quantized work varies widely example due variation object quanta occur irregularly variation low possible given determine best batch size analytically ultimately distinction generally made literature hard realtime soft realtime oversimplification really continuum depends required response time cost variability collector operations 82 timebased collectors previous work realtime collection focused workbased scheduling notable exceptions par ticular henriksson 15 implemented brooksstyle collector 10 application processes divided two priority lev els highpriority tasks assumed periodic bounded compute time allocation requirements memory preallocated system tailored allow mutator operations proceed quickly lowpriority tasks responsetime goals set henriksson gives schedulability analysis using realtime scheduling techniques joseph pandya 18 analysis workbased formula utilization similar formula timebased scheduling collector highpriority mutators always interrupt collector ready run thus see interruptdriven workbased scheduling essentially periodic timebased scheduling garbage collectors nettles otoole 21 north reppy 22 run collector separate thread appears timebased approach however nettles otoole dynamically detect situations mutator allocating faster collector case pause mutator fixed amount work performed north reppys collector feedback way balancing mutatorcollector quanta mutators high allocation rates may fail 9 conclusions presented hybrid realtime collector operates primarily nonmoving incremental marksweep collector prevents fragmentation via use limited copying 4 traced data measurements fragmentation bounded collector provable space bound yet retains lower space overhead fullycopying realtime collector key fully incremental defragmentation lowoverhead read barrier maintains consistency without compromising realtime bounds shown optimizing java com piler highly efficient software read barrier implemented cause 4 mean slowdown implemented collector shown real applications achieve highly predictable mutator utilization rates highly stable pause times realtime resolution generally able achieve 45 utilization collector 1625 times actual memory high water mark application acknowledgements thank david grove assistance implementing read barrier optimizations entire jikes rvm team providing research platform made work possible also thank rob ocallahan david grove mike hind anonymous referees helpful comments 10 r jalapeno virtual machine thin guards simple effective technique reducing penalty dynamic class load ing list processing realtime serial computer treadmill algorithm parallel incremental com paction beltway getting around garbage collection gridlock realtime specification java trading data space reduced time code space realtime garbage collection stock hardware parallel generational stack collection profiledriven pretenuring java server perfor mance case study building efficient scheduling garbage collection embedded sys tems incremental garbage collection mature objects finding response times realtime system compacting incremental collector performance production quality compiler garbage collection large lisp system concurrent garbage collection stock hardware eliminating external fragmentation nonmoving garbage collector java barrier methods garbage collection tr concurrent garbage collection stock hardware realtime concurrent collection stock multiprocessors realtime garbage collection generalpurpose machines treadmill realtime replication garbage collection generational stack collection profiledriven pretenuring compacting incremental collector performance production quality compiler haskell eliminating external fragmentation nonmoving garbage collector java list processing real time serial computer parallel realtime garbage collector algorithm parallel incremental compaction beltway incremental collection mature objects space timeefficient implementation java object model thin guards garbage collection large lisp system trading data space reduced time code space realtime garbage collection stock hardware noncompacting memory allocation realtime garbage collection ctr yuqiang xian guangze xiong minimizing memory requirement realtime systems concurrent garbage collector acm sigplan notices v40 n3 p4048 march 2005 michael bond kathryn mckinley bell bitencoding online memory leak detection acm sigplan notices v41 n11 november 2006 wei fu carl hauser realtime garbage collection framework embedded systems proceedings 2005 workshop software compilers embedded systems p2026 september 29october 01 2005 dallas texas dinakar dhurjati sumant kowshik vikram adve chris lattner memory safety without runtime checks garbage collection acm sigplan notices v38 n7 july matthias meyer true hardware read barrier proceedings 2006 international symposium memory management june 1011 2006 ottawa ontario canada angelo corsaro ron k cytron efficient memoryreference checks realtime java acm sigplan notices v38 n7 july tobias mann morgan deters rob legrand ron k cytron static determination allocation rates support realtime garbage collection acm sigplan notices v40 n7 july 2005 mike fulton mark stoodley compilation techniques realtime java programs proceedings international symposium code generation optimization p221231 march 1114 2007 shahrooz feizabadi godmar back garbage collectionaware utility accrual scheduling realtime systems v36 n12 p322 july 2007 david f bacon realtime garbage collection queue v5 n1 february 2007 yang chang andy wellings low memory overhead realtime garbage collection java proceedings 4th international workshop java technologies realtime embedded systems october 1113 2006 paris france tony printezis measuring garbage collection responsiveness science computer programming v62 n2 p164183 1 october 2006 daniel spoonhower joshua auerbach david f bacon perry cheng david grove eventrons safe programming construct highfrequency hard realtime applications acm sigplan notices v41 n6 june 2006 danny dub marc feeley bit compact scheme system microcontrollers higherorder symbolic computation v18 n34 p271298 december 2005 daniel spoonhower guy blelloch robert harper using page residency balance tradeoffs tracing garbage collection proceedings 1st acmusenix international conference virtual execution environments june 1112 2005 chicago il usa lothar thiele reinhard wilhelm design timing predictability realtime systems v28 n23 p157177 novemberdecember 2004 david f bacon perry cheng david grove michael hind v rajan eran yahav matthias hauswirth christoph kirsch daniel spoonhower martin vechev highlevel realtime programming java proceedings 5th acm international conference embedded software september 1822 2005 jersey city nj usa david f bacon perry cheng david grove garbage collection embedded systems proceedings 4th acm international conference embedded software september 2729 2004 pisa italy hansj boehm space cost lazy reference counting acm sigplan notices v39 n1 p210219 january 2004 diab abuaiadh yoav ossia erez petrank uri silbershtein efficient parallel heap compaction algorithm acm sigplan notices v39 n10 october 2004 hyeonjoong cho chewoo na binoy ravindran e douglas jensen scheduling garbage collector dynamic realtime systems statistical timing assurances realtime systems v36 n12 p2346 july 2007 cheadle j field marlow l peyton jones r l exploring barrier entry incremental generational garbage collection haskell proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada konstantinos sagonas jesper wilhelmsson message analysisguided allocation lowpause incremental garbage collection concurrent language proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada v krishna nandivada david detlefs compiletime concurrent marking write barrier removal proceedings international symposium code generation optimization p3748 march 2023 2005 chengliang zhang kirk kelsey xipeng shen chen ding matthew hertz mitsunori ogihara programlevel adaptive memory management proceedings 2006 international symposium memory management june 1011 2006 ottawa ontario canada chris andreae yvonne coady celina gibbs james noble jan vitek tian zhao scoped types aspects realtime java memory management realtime systems v37 n1 p144 october 2007 wenke chen sanjay bhansali trishul chilimbi xiaofeng gao weihaw chuang profileguided proactive garbage collection locality optimization acm sigplan notices v41 n6 june 2006 konstantinos sagonas jesper wilhelmsson efficient memory management concurrent programs use message passing science computer programming v62 n2 p98121 1 october 2006 joshua auerbach david f bacon daniel iercan christoph kirsch v rajan harald roeck rainer trummer java takes flight timeportable realtime programming exotasks acm sigplan notices v42 n7 july 2007 david atienza jose mendias stylianos mamagkakis dimitrios soudris francky catthoor systematic dynamic memory management design methodology reduced memory footprint acm transactions design automation electronic systems todaes v11 n2 p465489 april 2006 glenn ammons jonathan appavoo maria butrico dilma da silva david grove kiyokuni kawachiya orran krieger bryan rosenburg eric van hensbergen robert w wisniewski libra library operating system jvm virtualized execution environment proceedings 3rd international conference virtual execution environments june 1315 2007 san diego california usa david f bacon perry cheng v rajan controlling fragmentation space consumption metronome realtime garbage collector java acm sigplan notices v38 n7 july sven gestegard robertz roger henriksson timetriggered garbage collection robust adaptive realtime gc scheduling embedded systems acm sigplan notices v38 n7 july chandrasekhar boyapati alexandru salcianu william beebee jr martin rinard ownership types safe regionbased memory management realtime java acm sigplan notices v38 n5 may martin vechev eran yahav david f bacon correctnesspreserving derivation concurrent garbage collection algorithms acm sigplan notices v41 n6 june 2006 martin vechev david f bacon write barrier elision concurrent garbage collectors proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada david detlefs christine flood steve heller tony printezis garbagefirst garbage collection proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada filip pizlo antony l hosking jan vitek hierarchical realtime garbage collection acm sigplan notices v42 n7 july 2007 dinakar dhurjati sumant kowshik vikram adve chris lattner memory safety without garbage collection embedded applications acm transactions embedded computing systems tecs v4 n1 p73111 february 2005 narendran sachindran j eliot b moss emery berger mc2 highperformance garbage collection memoryconstrained environments acm sigplan notices v39 n10 october 2004 jesper honig spring filip pizlo rachid guerraoui jan vitek reflexes abstractions highly responsive systems proceedings 3rd international conference virtual execution environments june 1315 2007 san diego california usa okehee goh yannhang lee ziad kaakani elliott rachlin schedulable garbage collection cli virtual execution system realtime systems v36 n12 p4774 july 2007 stephen blackburn antony l hosking barriers friend foe proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada david f bacon perry cheng v rajan unified theory garbage collection acm sigplan notices v39 n10 october 2004 antony l hosking portable mostlyconcurrent mostlycopying garbage collection multiprocessors proceedings 2006 international symposium memory management june 1011 2006 ottawa ontario canada zhang ning guangze xiong minimizing gc work analysis live objects acm sigplan notices v41 n3 march 2006 david f bacon perry cheng david grove martin vechev syncopation generational realtime garbage collection metronome acm sigplan notices v40 n7 july 2005 yoav ossia ori benyitzhak marc segal mostly concurrent compaction marksweep gc proceedings 4th international symposium memory management october 2425 2004 vancouver bc canada stephen blackburn kathryn mckinley ulterior reference counting fast garbage collection without long wait acm sigplan notices v38 n11 november stephen blackburn perry cheng kathryn mckinley oil water high performance garbage collection java mmtk proceedings 26th international conference software engineering p137146 may 2328 2004 g chen kandemir n vijaykrishnan j irwin b mathiske wolczko heap compression memoryconstrained java environments acm sigplan notices v38 n11 november matthew hertz yi feng emery berger garbage collection without paging acm sigplan notices v40 n6 june 2005 cheadle j field j w ayres n dunn r hayden j nystrompersson visualising dynamic memory allocators proceedings 2006 international symposium memory management june 1011 2006 ottawa ontario canada stylianos mamagkakis david atienza christophe poucet francky catthoor dimitrios soudris energyefficient dynamic memory allocators middleware level embedded systems proceedings 6th acm ieee international conference embedded software october 2225 2006 seoul korea