implications classical scheduling results realtime systems important classical scheduling theory results realtime computing identified implications results perspective realtime systems designer discussed uni processor multiprocessor results addressed well important issues future release times precedence constraints shared resources task value overloads static versus dynamic scheduling preemption versus nonpreemption multiprocessing anomalies metrics examples scheduling algorithms used actual applications given b introduction every realtime systems designer familiar set important classical scheduling theory results ie results largely taken literature complexity theory operations research knowledge results rarely provides direct solution designer implications results provide important insight choosing good design scheduling algorithm system avoiding poor even erroneous choices literature scheduling theory vast make pretense comprehensive paper minimum set results together implications presented example scheduling theory results presented include jacksons rule smiths rule mcnaughtons theorem liu laylands rate monotonic rule moks theorems richards anomalies besides learning important results want reader able answer least following questions work done first author sabbatical computer science dept univ massachusetts work supported part nsf grants iri 9208920 cda 8922572 onr grant n0001492j1048 iri italy ffl really know earliest deadline scheduling ffl known uniprocessor realtime scheduling problems ffl known multiprocessing realtime scheduling problems ffl anomalous behavior occur avoided ffl boundary polynomial nphard scheduling problems ffl task set characteristics cause nphardness type bounds analysis useful realtime systems ffl impact overloads scheduling results ffl metric used theory impact usefulness result realtime computing system ffl different results exist static dynamic scheduling many dimensions scheduling problem accepted tax onomy paper divide scheduling theory uniprocessor section 2 multiprocessor section results uniprocessor section begin independent tasks consider precedence constraints shared resources overload multiprocessor case since results address precedence shared resources together divide work static dynamic algorithms preliminaries presenting major scheduling results basic concepts must clearly understood discuss differences static dynamic offline online scheduling well various metrics implications npcomplete nphard terms used throughout paper defined 21 static versus dynamic scheduling classical scheduling theory deals static scheduling static scheduling refers fact scheduling algorithm complete knowledge regarding task set constraints deadlines computation times precedence constraints future release times set assumptions realistic many realtime systems example realtime control simple laboratory experiment simple process control application might fixed set sensors actuators well defined environment processing requirements types realtime systems static scheduling algorithm operates set tasks produces single schedule fixed time sometimes confusion regarding future release times future release times known algorithm developing schedule still static algorithm contrast dynamic scheduling algorithm context paper complete knowledge currently active set tasks new arrivals may occur future known algorithm time scheduling current set schedule therefore changes time dynamic scheduling required realtime systems teams robots cleaning chemical spill military command control applications see paper theoretical results known realtime dynamic scheduling algorithms offline scheduling often equated static scheduling wrong building realtime system offline scheduling analysis always done regardless whether final runtime algorithm static dynamic many realtime systems designers identify maximum set tasks worst case assumptions apply static scheduling algorithm produce static schedule schedule fixed used online well understood properties given assumptions remain true tasks meet deadlines cases offline analysis might produce static set priorities use run time schedule fixed priorities drive schedule fixed common rate monotonic approach discussed later realtime system operating dynamic environment feasible meet assumptions static scheduling ie everything known priori case algorithm chosen analyzed offline expected dynamic environmental conditions usually less precise statements overall performance made online dynamic algorithm executes generally scheduling algorithm possibly modifications applied static scheduling dynamic scheduling used offline online important difference known performance algorithm cases example consider earliest deadline first edf scheduling applied static scheduling know optimal many situations enumerated applied dynamic scheduling multiprocessors optimal fact known algorithm optimal 22 metrics classical scheduling theory typically uses metrics minimizing sum completion times minimizing weighted sum completion times minimizing schedule length minimizing number processors required minimizing maximum lateness cases deadlines even considered results deadlines considered usually added constraints example one creates minimum schedule length subject constraint tasks must meet respective deadline one tasks miss deadlines feasible solution classical metrics deadlines included constraints interest realtime systems designers sum completion times generally interest direct assessment timing properties deadlines periods however weighted sum important tasks different values impart system upon completion using value often overlooked many realtime systems focus simply deadlines combination value deadline minimizing schedule length secondary importance possibly helping minimize resources required system directly address fact individual tasks deadlines true minimizing number processors required minimizing maximum lateness metric useful design time resources continually added maximum lateness less equal zero case tasks miss deadlines hand metric always useful minimizing maximum lateness doesnt necessarily prevent one many even tasks missing deadlines see figure 1 d1 d2 d3 d4 d5 d1 d2 d3 d4 d5 maximum lateness maximum lateness first schedule minimizes max lateness tasks miss deadline second schedule greater max lateness four tasks five complete deadlines figure 1 minimizing maximum lateness example rather mentioned metrics much realtime computing work minimizes number tasks miss deadlines looks optimal algorithms defined following manner optimal scheduling algorithm one may fail meet deadline scheduling algorithm paper metrics mentioned either directly applicable realtime systems show even though nice theoretical result exists limited applicability realtime systems related metrics complexity various scheduling problems shall see many scheduling results npcomplete nphard np class decision problems solved polynomial time nondeterministic machine recognition problem r npcomplete r 2 np problems np polynomial transformable r recognition optimization problem r nphard problems np polynomial transformable r cant show r 2 np 3 uniprocessor systems general follow notation 18 problem definition form ff j fi j fl ff indicates machine environment section paper indicating uniprocessor machine fi indicates job characteristics preemptable nonpreemptable independent precedence constrained deadline etc fl indicates optimality criterion maximum lateness total tardiness etc note optimality criterion depends metric chosen strongly relies system objectives task model 31 preemption vs nonpreemption jacksons rule suppose n independent jobs words job process task used interchangeably throughout scheduling literature job j processing time due date j given sequence scheduling job defined completion time c j let us define lateness job j l want minimize maximum lateness assuming jobs executed nonpreemptively want solve problem 1 stands single machine nopmtn stands nonpreemption objective function minimize simple solution problem earliest due date edd algorithm follows theorem 31 jacksons rule 16 sequence optimal puts jobs order nondecreasing due dates 2 proof theorem given simple interchange argument 18 presenting argument beyond scope paper first result may seem useful realtime systems designer often require task miss deadline since static scheduling algorithm maximum lateness greater zero designer knows must increase computing power system meet requirements missing deadlines shall see edd optimal many situations also note since tasks known ready execute time zero preemption would improve situation realtime system requires sophisticated programming model one first extensions consider introduction release times say job j release time r j execution cannot start time r j unfortunately problem extended release times nphard 19 case obtain great benefit permit jobs preempted instant fact problem easy algorithm solution exists polynomial complexity algorithm based jacksons rule slightly modified order take release times account theorem 32 sequence instant schedules job earliest due date among eligible jobs ie whose release time less equal current time optimal respect minimizing maximum lateness 2 result easily proven interchange argument proof obtained way similar time slice swapping technique used 9 24 show optimality earliest deadline first edf least laxity first llf algorithms respectively one implication results practical considerations prevent us using preemption usually gives greater benefit nonpreemption terms scheduling complexity unfortunately deal shared resources realtime systems address critical sections one technique create nonpreemptable code creates nphard problem another implication theorems minimization maximum lateness implies optimality even deadlines must met maximum lateness required less equal zero fact wellknown paper liu layland 21 focussed aspect edf scheduling set independent periodic processes showing full processor utilization always achievable giving simple necessary sufficient condition schedulability tasks j period task j edf algorithm also shown optimal various stochastic condi tions results imply edf works well many different situations recently variations edf used multimedia applications robotics realtime databases note however none classical results edf precedence constraints shared resources overloads taken account address aspects subsequent sections another important common area realtime scheduling scheduling periodic tasks rate monotonic algorithm often used algorithm assigns task static priority inversely proportional period ie tasks shortest periods get highest priority fixed set independent periodic tasks deadlines periods know theorem 33 liu layland 21 set n independent periodic jobs scheduled rate monotonic policy period worst case execution time respectively large n obtain utilization bound 69 meaning long cpu utilization less 69 tasks make deadlines often referred schedulability test deadlines periodic tasks less period rule longer optimal rather must use deadline monotonic policy 20 periodic process shortest deadline assigned highest priority scheme optimal sense static priority scheme schedule set periodic processes deadline monotonic algorithm note deadline monotonic pure edf scheduling tasks may different periods assigned priorities fixed rate monotonic algorithm extended many ways important deals shared resources see section 33 schedulability tests formulated deadline monotonic algorithm 1 rate monotonic scheduling algorithm chosen space station freedom project faa advanced automation system aas influenced specification ieee futurebus dods 1991 software technology strategy says rate monotonic scheduling major payoff system designers use theory predict whether task deadlines met long costly implementation phase project begins 1992 acting deputy administrator nasa stated development rate monotonic scheduling system allow space station freedoms computers budget time choose variety tasks decide one first much time spend process rate monotonic also useful simple applications realtime control simple experiment might contain sensors whose data must processed periodically chemical plant large number periodic tasks alarms alarms treated periodic tasks whose minimum interarrival time equal period static scheduling using rate monotonic algorithm applied 32 precedence constraints many systems practical interest expect tasks independent rather cooperate achieve goal application cooperation among tasks achieved various types communication semantics depending chosen semantics application tasks experience precedence constraints blocking accessing shared resources precedence relation among tasks makes scheduling problem complex since tasks ready scheduled time simple edf rule longer optimal following precedence constraints expressed notation j associated digraph gve v set tasks e set edges edge connecting tasks ij task precedes task j simple scheduling problem set tasks nopreemption identical arrival time precedence relation among described solved lawler 17 edflike algorithm works backwards starting leaf tasks precedence graph algorithm works follows scheduling list built starting bottom reverse topological order adding list step task minimum value chosen metric whose successors scheduled lawlers algorithm optimal runs 2 lawlers algorithm gives solution tasks identical start time unfortunately sufficient systems practical interest periodic tasks dynamically arising tasks common start time problem nonpreemptive scheduling jobs different release times general precedence constraints simple one fact problem corresponding proven nphard lenstra 19 np hardness general precedence constrained problem major obstacle nonpreemptive scheduling spite fact optimal results polynomial algorithms exist similar problems general assumptions constrained example polynomial algorithm found unit computation time tasks arbitrary precedence constraints interesting results related precedence constraints obtained working subclasses general precedence relation polynomial algorithms found precedence relations form intrees every task one predecessor outtrees tasks one successor precedence relation seriesparallel graph easy show intree outtree cases included general class seriesparallel graphs seriesparallel graph interesting subset general precedence relation optimality results found seriesparallel graph defined recursively way ffl gfjg0 series parallel graph seriesparallel graphs series parallel graphs alternatively graph seriesparallel graph transitive closure contain z graph z graph graph contains subgraph 4 nodes f ijkl g following edges figure graphically depicts intrees outtrees seriesparallel graphs z graph series parallel graph efficient solutions exist seriesparallel graphs exist z graph unfortunately z graphs arise practice details results follow theorem 34 lawler 18 given set tasks related seriesparallel precedence graph optimal solution exists every cost function admits string interchange relation 2 formally cost function string interchange relation given two strings jobs ff fi quasi total order among following relation holds intuitively formula means cost function admits string interchange relation lower value obtained individual tasks lower value scheduled first theorem says interested minimizing maximizing cost function admits intree outtree zgraph figure 2 precedence relations string interchange relation eg minimizing lateness possible find optimal schedule polynomial time every set tasks related seriesparallel precedence graph algorithm solves problem works decomposition tree tree shows subgraphs connected series parallel relation form global precedence graph decomposition tree found oj number nodes number edges algorithm starts tasks successor decomposition tree every node calculates string sequence combining strings jobs coming sons final node representing original graph reached whole optimal scheduling list computed common feature algorithm also found similar algorithms literature dealing intrees outtrees work precedence graph related decomposition tree starting jobs successors predecessors build sequence suboptimal schedules technique useful various scheduling heuristics extent lawlers optimal algorithm seriesparallel graphs even optimal algorithms work intrees outtrees help us realtime systems unfortunately high level communication semantics found programming languages give rise precedence constrained jobs z graphs meaning optimal algorithms dont apply heuristics need used one example z graph arises simple pair tasks linked asynchronous send synchronous receive see figure 3 note remote procedure calls rpc give rise z graphs preemption allowed classical results go providing solutions general precedence constraints preemption reduces complexity scheduling problem precedence related tasks different arrival times problem fact solvable 2 bakers algorithm 2 asynchsend synchreceive process process b process process b message figure 3 program example gives rise z graph bakers procedure recursive computational complexity seems suited offline scheduling due difficulty describing algorithm space limitations describe algorithm however important feature algorithm number preemptions limited n1 n number jobs thus making preemption overhead bounded practical situations scheduling preemption overheads must bounded taken account rarely see issue addressed classical scheduling theory solutions scheduling list explicitly created another technique encode precedence relations parameters used scheduling algorithm example deadlines release times blazewicz 4 shows adjust deadlines precedence constraints encoded deadlines priori run time simply use edf scheduling result comes fact task deadlines depend deadlines successors deadlines task start times depend start time predecessors start times theorem assumes shared resources among tasks theorem 35 blazewicz 4 edf optimal tasks general precedence relation different release dates deadlines start times revised according following formulas starting tasks successor processing every step tasks whose successors processed r starting tasks predecessor 2 result allows us transform set dependent tasks set independent ones obtaining equivalent problem edf policy optimality technique revised deadlines arrival dates used online 7 offline algorithms 24 unfortunately optimality technique lost tasks precedence constraints also share resources exclusive way moreover arbitrary protocols used access shared resources revision tasks deadlines release times longer sufficient guarantee correct ordering jobs without additional constraints general problem scheduling set tasks precedence constraints arbitrary resource conflicts nphard offline algorithms face np hardness general problem trying find acceptable solutions means heuristics branch bound techniques example given algorithm xu parnas 32 every step suboptimal schedule obtained even examples online systems driven heuristics spring system 26 scheduling list built online 33 shared resources shared resources commonly used multitasking applications general purpose systems wellknown problem solved example mutual exclusion primitives realtime systems straightforward application solution hold defining runtime scheduler totally online knowledge future arrival times tasks following proven theorem 36 mok 24 mutual exclusion constraints impossible find totally online optimal runtime scheduler 2 proof simply given adversary argument furthermore author showed much negative result theorem 37 mok 24 problem deciding whether possible schedule set periodic processes use semaphores enforce mutual exclusion nphard 2 transformation 3partition problem scheduling problem shown prove theorem moks opinion reason nphardness scheduling problem lies possibility mutually exclusive scheduling blocks different computation times confirmation point view problem minimizing maximum lateness n independent unittime jobs arbitrary release times easy 18 moreover add precedence constraints want minimize maximum completion time makespan want solve problem still easy 11 algorithm solves makes use forbidden regions intervals time task start schedule feasible idea nonpreemption scheduling task certain point time could force late task miss deadline point several choices possible one followed mok enforce use mutually exclusive scheduling blocks computation time another example sha et al 27 baker 2 efficiently find suboptimal solution clever allocation policy guaranteeing time minimum level performance former solution called kernelized monitor key idea assign processor time quantums length q length ith critical section words grain system made coarser furthermore ready times deadlines tasks previously modified according partial order tasks adjusting edf scheduler technique forbidden regions mentioned following theorem proven theorem 38 mok 24 feasible schedule exists instance process model precedence constraints critical sections kernelized monitor scheduler used produce feasible schedule 2 27 sha et al introduce priority ceiling protocol pcp allocation policy shared resources works rate monotonic scheduler successively chen lin 5 extend utilization protocol edf scheduler main goal similar protocols bound usually uncontrolled priority inversion situation higher priority job blocked lower priority jobs indefinite period time recall block occur job tries enter critical section already locked job finding bound priority inversion allows evaluate worst case blocking times eventually experienced jobs accounted schedulability guaranteeing formulas words means evaluate worst case loss performance key ideas behind pcp prevent multiple priority inversions means early blocking tasks could cause priority inversion minimize much possible length priority inversion allowing temporary rise priority blocking task done following way define ceiling critical section priority highest priority task currently locks could lock critical section allow locking critical section priority requesting task higher ceiling critical sections currently locked case blocking task holds lock inherits priority requesting task leaves critical section following properties shown ffl job blocked enters first critical section ffl pcp prevents occurrence deadlocks course former property used evaluate worst case blocking times jobs 2 baker describes similar protocol stack resource policy srp handles general situation multiunit resources static dynamic priority schemes sharing runtime stacks allowed protocol relies following two conditions ffl prevent deadlocks job permitted start resources currently available sufficient meet maximum requirements ffl prevent multiple priority inversion job permitted start resources currently available sufficient meet maximum requirement single job might preempt key idea behind protocol job needs resource available blocked time attempts preempt rather later actually may need shared resource main advantages earlier blocking save unnecessary context switches possibility simple efficient implementation srp means stack summary dealing shared resources realtime system utmost importance classical results given section provide good means handling resources uni processor many researchers feel techniques work well multiprocessors distributed systems systems shared resources typically addressed online planning algorithms 26 28 33 static schedules developed offline heuristics alternative approaches avoid blocking shared resources scheduling competing tasks different points time 34 overload value edf llf algorithms shown optimal respect different metrics however overload conditions algorithms perform poorly experiments carried locke 22 others shown edf llf rapidly degrade performance overload intervals due fact algorithms give highest priority processes close missing deadlines typical phenomenon may happen edf system overloaded domino effect since first task misses deadline may cause subsequent tasks miss deadlines situation edf provide type guarantee tasks meet timing constraints undesirable behavior practical systems since realworld applications intermittent overloads may occur due exceptional situations modifications environment arrival burst tasks cascades system failures real world example situation could cause flexible manufacturing application produce completed products deadlines order gain control tardy tasks overload conditions value usually associated task reflecting importance task within set dealing task sets values tasks scheduled smith rule theorem 39 smiths rule 29 finding optimal schedule given sequence puts jobs order non decreasing ratios ae smiths rule resembles common shortest processing time first spt rule equivalent tasks equal weights however sufficient solve problem scheduling general precedence constraints problems turn np complete 19 true even simpler ones interesting solutions found particular kind precedence relations fact optimal polynomial algorithm found problems unfortunately realtime systems precedence constraints imposed tasks often general heuristic proposed spring project deadline cost driven algorithms combined together rules dynamically revise values deadlines accordance precedence relations 6 number heuristic algorithms also proposed deal overloads 30 13 improve performance edf baruah et al 3 shown exists upper bound performance online preemptive algorithm working overload conditions goodness online algorithm measured respect clairvoyant scheduler one knows future means competitive factor ratio r cumulative value achieved online algorithm cumulative value achieved clairvoyant schedule value associated task equal tasks execution time task request successfully scheduled completion value zero given tasks terminate within deadline according metric proved following theorem theorem 310 baruah et al 3 exist online scheduling algorithm competitive factor greater 025 theorem says online scheduling algorithm guarantee cumulative value greater 14th value obtainable clairvoyant scheduler bounds true load refined given load example load less 1 bound 1 load surpasses 1 bound drops immediately 385 loads greater 1 2 bound gradually drops 385 25 loads greater 2 bound 25 worth pointing bound achieved restrictive assump tions tasks set zero laxity overload arbitrary finite duration tasks execution time arbitrarily small task value equal computation time since real world applications tasks characteristics much less restrictive 14th bound theoretical validity work needed derive bounds based knowledge task set 35 summary uniprocessor results many basic algorithms theoretical results developed scheduling uni processors many based earliest deadline scheduling rate monotonic schedul ing extensions results handle precedence resource sharing occurred work designers realtime systems wealth information concerning uniprocessor scheduling still required results scheduling overload fault tolerance although fault tolerance usually requires multiple processors well also necessary develop integrated comprehensive scheduling approach addresses periodic aperiodic tasks preemptive nonpreemptive tasks sys tem tasks values combined cpu io scheduling name issues example operational flight program a7e aircraft 75 periodic 172 aperiodic processes significant synchronization requirements extensions rate monotonic integrate periodic aperiodic tasks could used application 4 multiprocessor realtime scheduling realtime systems relying multiprocessors unfortunately less known schedule multiprocessor based realtime systems uniprocessors partly due fact complexity results show almost realtime multiprocessing scheduling nphard partly due minimal actual experience exists systems even number heuristics exist relatively low spite negative implications complexity analysis provides important understand complexity results ffl understanding boundary polynomial nphard problems provide insights developing useful heuristics used design tool online scheduling algorithm ffl understanding algorithms achieve polynomial results provide basis upon base heuristics ffl fundamental limitations online algorithms must understood better create robust systems avoid operating misconceptions ffl serious scheduling anomalies avoided section present multiprocessing scheduling results deterministic static scheduling without preemption dynamic online scheduling without preemption identify various anomalies briefly discuss similarity problem bin packing important implications theory stressed throughout section summary global picture multiprocessor realtime scheduling given 41 deterministic static scheduling 411 nonpreemptive multiprocessing results let model multiprocessing set p processors tasks r resources processors identical task worst case execution time nonpreemptive tasks may related partial order indicating eg task ti must complete task tj important note scheduling theory results tasks considered constant execution time computer applications tasks never constant execution time must understand implication fact example fact gives rise one interesting multiprocessing anomalies realtime scheduling see section 43 resource rk number indicates much exists tasks require portion resource directly models resource like main memory also model mutually exclusive resource requiring task access 100 resource complexity results deterministic scheduling theory multiprocessing tasks nonpreemptive partial order among resource constraints even single resource constraint single deadline show almost problems npcomplete delineate boundary polynomial nphard problems present basic results every realtime designer know list following theorems without proof compare table 1 metric used following theorems amount computation time required determining schedule satisfies partial order resource constraints completes required processing given fixed deadline theorem 41 coffman graham 8 multiprocessor scheduling problem 2 processors resources arbitrary partial order relations every task unit computation time polynomial 2 theorem 42 garey johnson 10 multiprocessor scheduling problem 2 pro cessors resources independent tasks arbitrary computation times npcomplete 2 theorem 43 garey johnson 10 multiprocessor scheduling problem 2 pro cessors resources arbitrary partial order task computation times either 1 2 units time npcomplete 2 proc res ordering comp complexity arbitrary unit polynomial arbitrary 1 2 units npcomp forest unit npcomp forest unit polynomial arbitrary unit npcomp table 1 summary basic multiprocessor scheduling theorems theorem 44 garey johnson 10 multiprocessor scheduling problem 2 pro cessors 1 resource forest partial order computation time every task equal 1 npcomplete 2 theorem 45 garey johnson 10 multiprocessor scheduling problem 3 processors one resource independent tasks tasks computation time equal 1 npcomplete 2 theorem 46 hu 15 multiprocessor scheduling problem n processors sources forest partial order task unit computation time polynomialtheorem 47 ullman 31 multiprocessing scheduling problem n processors resources arbitrary partial order task unit computation time npcompletefrom theorems see nonpreemptive multiprocessing scheduling almost problems npcomplete implying heuristics must used problems basically see nonuniform task computation time resource requirements cause npcompleteness immediately implication results designs use local resources object based systems functional language based systems schedule based unit time slot significant advantages far scheduling complexity concerned course realtime systems unit tasks attempt carve process unit times creates difficult maintenance problems possibly wasted processing cycles tasks consume less allocated unit time note results refer single deadline tasks task deadline problem exacerbated 412 preemptive multiprocessing realtime scheduling generally true tasks scheduled preemptable scheduling problem easier certain situations advantage preemption following classical results pertain multiprocessing scheduling tasks preemptable ie theorem 48 mcnaughton 23 instance multiprocessing scheduling problem p identical machines preemption allowed minimizing weighted sum completion times exists schedule preemption value sum computation times small schedule finite number preemptions 2 see example given metric may advantage preemption however find schedule without preemption nphard note metric sum completion times shortest processing time first greedy approach solves problem np advantage preemption result important implication creating static schedule certainly prefer minimize preemption practical reasons run time knowing advantage preemption designer would create static schedule preemptions theorem 49 lawler 18 multiprocessing problem scheduling p processors task preemption allowed try minimize number late tasks nphard 2 theorem indicates one common forms realtime multiprocessing scheduling ie u j late tasks requires heuristics 42 dynamic multiprocessor scheduling realtime classical scheduling results dynamic multiprocessing scheduling treat preemptive nonpreemptive cases together first consider certain conditions uniprocessor dynamic earliest deadline scheduling optimal algorithm optimal multiprocessor answer theorem 410 mok 24 earliest deadline scheduling optimal multiprocessor case 2 illustrate true consider following example 3 tasks execute 2 processors task characteristics given tasknumbercomputation time dead scheduling earliest deadline would execute 1 p1 2 p2 3 misses deadline however schedule 3 first p1 1 2 p2 tasks make deadlines optimal algorithm exist static version problem tasks exist time one considers deadlines computation time 14 algorithm complicated present dynamic earliest deadline scheduling multiprocessors optimal next question whether dynamic algorithm optimal general answer theorem 411 mok 24 two processors deadline scheduling algorithm optimal without complete priori knowledge 1 deadlines 2 computation times start times tasks 2 implies classical scheduling theory algorithms requires knowledge start times optimal used online also points cannot hope develop optimal online algorithm general case optimal algorithms may exist given set conditions one important example situation assuming worst case situations exist simultaneously scenario schedulable also schedulable run time even arrival times different later arrivals cant make conditions worse worst case analysis approach possible given system usually sufficient conditions cannot developed ensuring conditions costly probabilistic approaches needed number good heuristics exist dynamic multiprocessor scheduling beginning see much needed stochastic analysis conditions especially valuable able create algorithms operate levels guarantee example even though system operates stochastically nonoptimally might able provide minimum level guaranteed performance mentioned various heuristics exist realtime multiprocessor scheduling resource constraints 26 however general heuristics use nonpreemptive model advantages nonpreemptive model context switches higher understandability easier testing preemptive model avoidance blocking possible main disadvantage nonpreemptive model usually less efficient utilization pro cessor heuristics also exist preemptive model 33 advantages preemptive model high utilizations low latency reacting newly invoked work disadvantages many context switches difficulty understanding run time execution testing blocking common heuristics whether preemptive nonpreemptive cases fairly expensive terms absolute online computation time compared simple algorithms edf sometimes requires additional hardware support terms scheduling chip mentioned earlier overload performance bounds analysis important issues assume situation sporadic tasks preemption permitted task meets deadline value equal execution time obtained else value obtained let system operate normal overload conditions let 2 processors theorem 412 baruah et al 3 online scheduling algorithm guarantee cumulative value greater onehalf dual processor case 2 bounds results uniprocessor case presented section 34 implications theorem pessimistic pessimism arises assumptions made concerning lack knowledge task set reality significant knowledge know arrival new instances periodic tasks flow control may know maximum arrival rate capped know minimum laxity task system greater value exploit knowledge bounds may pessimistic require algorithms directly address performance multiprocessing system overload conditions 43 multiprocessing anomalies designers must aware several important anomalies called richards anomalies occur multiprocessing scheduling avoided assume set tasks scheduled optimally multiprocessor priority order fixed number processors fixed execution times precedence constraints theorem 413 graham 12 stated problem changing priority list increasing number processors reducing execution times weakening precedence constraints increase schedule length 2 implication result means tasks deadlines accompanying increase schedule length due anomaly cause previously valid schedule become invalid ie tasks miss deadlines initially counter intuitive think adding resources extra processor relaxing constraints less precedence among tasks less execution time requirements make things worse insidious nature timing constraints multiprocessing scheduling example best illustrate theorem true consider optimal schedule reduce time required first task t1 first processor means second task t2 processor begin earlier however may cause task another processor block shared resource miss deadline executed earlier blocking would occurred tasks would made deadlines originally optimal schedule see figure 4 schedule length schedule length task 2 task 4 share resource exclusive mode tasks statically allocated task 1 task 2 processor 1 task 3 task 4 task 5 processor 2 figure 4 one example richards anomalies especially important note online scheduling algorithms must deal problem tasks completing worst case times simple solution avoids anomaly tasks complete early simply idle often inefficient however algorithms 28 strive reclaim idle time carefully address anomalies occur 44 similarity bin packing another tremendously active area scheduling research bin packing algorithms bin processor maximum capacity boxes jobs tasks placed bins require percentage capacity goal either given fixed number bins pack jobs minimize maximum length bin rather fill bins capacity minimizing number bins required bins computers multiprocessor provide computing capacity deadline set jobs jobs require amount processing time realtime scheduling usually assumed memory requirements implicitly met common algorithms best fit bf first fit ff first fit decreasing best fit decreasing bfd latter two algorithms arrange list jobs nonincreasing list respect capacity requirements apply first fit best fit respectively theoretical bounds exist describe eg minimum number bins required worst case bounds ff bf large task sets 1710l l optimal minimum number bins 12 ffd bound 119l known bound bfd less equal ffd bound 12 work limited value realtime systems since single deadline issues precedence constraints real considerations taken account however useful implications ffl know worst case avoid design ffl obtain estimate number processors required application ffl since average behavior also important since analysis offline good packing achieved permute packing using average case information put constraints job sizes etc bin packing results extended incorporated realtime design tools 45 summary multiprocessor results multiprocessor scheduling problems np deterministic scheduling major problem either specific problem npcomplete use polynomial algorithm develop optimal schedule use offline heuristic search techniques based classical theory implies offline techniques usually find feasible schedules optimal ones many heuristics perform well average case deteriorate exponential complexity worst rare case good design tools would allow users provide feedback redesign task set avoid rare case static multiprocessor scheduling problem largely solved sense know proceed must point however good tools implemented heuristics still necessary many extensions treat sophisticated sets task system characteristics still possible online multiprocessing scheduling must rely heuristics would substantially helped special scheduling chips heuristics must avoid richards anomalies 28 better results operation overloads better bounds account typical priori knowledge found realtime systems algorithms guarantee various levels performance required dynamic multiprocessing scheduling infancy 5 conclusion classical scheduling theory provides basic set results use realtime systems designers many results known uniprocessors multiprocessors complexity fundamental limits performance bounds important scheduling problems known anomalies must avoided identified still necessary realtime designers take basic facts apply problem difficult engineering problem many cases many new results needed deal directly metrics interest realtime applications realistic task set characteristics typical much theory presented many issues outside scope paper including distributed scheduling integration cpu scheduling communication scheduling io scheduling groups tasks single deadline placement constraints impact placement run time scheduling fault tolerance needs kinds timing requirements besides simple deadlines periods integration critical noncritical tasks interaction scheduling algorithms system design implementation including run time overhead areas wide open areas research r hard realtime scheduling deadline monotonic approach stackbased scheduling realtime processes competitiveness online realtime task scheduling scheduling dependent tasks different arrival times meet dead lines dynamic priority ceilings concurrency control protocol realtime systems dynamic scheduling groups tasks precedence constraints distributed hard realtime systems dynamic scheduling realtime tasks precedence constraints optimal scheduling twoprocessor systems control robotics procedural control physical processes complexity results multiprocessor scheduling resource constraints scheduling unittime tasks arbitrary release times deadlines bounds performance scheduling algorithms earliest deadline scheduling realtime database systems simple scheduling algorithms parallel scheduling assembly line problems scheduling production line minimize maximum tardiness optimal sequencing single machine subject precedence con straints recent results theory machine scheduling optimization approximation deterministic sequencing scheduling survey complexity fixed priority scheduling periodic realtime tasks scheduling algorithms multiprogramming hardreal time environment besteffort decision making realtime scheduling scheduling deadlines loss functions fundamental design problems distributed systems hardreal time environment n job one machine sequencing algorithm minimizing number late jobs efficient scheduling algorithms realtime multiprocessor systems priority inheritance protocols approach realtime synchronization resource reclaiming multiprocessor realtime systems various optimizers single stage production transient overloads faulttolerant realtime systems polynomial complete scheduling problems scheduling processes release times deadlines precedence exclusion relations preemptive scheduling time resource constraints tr ctr kaiyu chen sharad malik david august retargetable static timing analysis embedded software proceedings 14th international symposium systems synthesis september 30october 03 2001 montral pq canada anup k bhattacharjee k ravindranath pal r mall ddsched distributed dynamic realtime scheduling algorithm progress computer research nova science publishers inc commack ny 2001 anup k bhattacharjee k ravindranath pal r mall ddsched distributed dynamic realtime scheduling algorithm progress computer research nova science publishers inc commack ny 2001 david bartholomew stewart richard mortier virtual private machines usercentric performance proceedings 11th workshop acm sigops european workshop beyond pc september 1922 2004 leuven belgium laura e jackson george n rouskas deterministic preemtive scheduling realtime tasks computer v35 n5 p7279 may 2002 enrico vicario static analysis dynamic steering timedependent systems ieee transactions software engineering v27 n8 p728748 august 2001 karl j gramp comparison different tasking architectures used mobile satellite communication ground station software proceedings conference triada 96 disciplined software development ada p2328 december 0307 1996 philadelphia pennsylvania united states geoff coulson configurable multimedia middleware platform ieee multimedia v6 n1 p6276 january 1999 dirk ziegenbein jan uerpmann rolf ernst dynamic response time optimization sdf graphs proceedings 2000 ieeeacm international conference computeraided design november 0509 2000 san jose california darko kirovski miodrag potkonjak systemlevel synthesis lowpower hard realtime systems proceedings 34th annual conference design automation p697702 june 0913 1997 anaheim california united states chunho lee miodrag potkonjak wayne wolf systemlevel synthesis application specific systems using search generalized forcedirected heuristics proceedings 9th international symposium system synthesis p2 november 0608 1996 louchka popovazeugmann matthias werner extreme runtimes schedules modelled time petri nets fundamenta informaticae v67 n13 p163174 january 2005 babak hamidzadeh yacine atif dynamic scheduling realtime tasks assignment ieee concurrency v6 n4 p1425 october 1998 megerian milenko drinic miodrag potkonjak watermarking integer linear programming solutions proceedings 39th conference design automation june 1014 2002 new orleans louisiana usa hsungpin chang rayi chang weikuan shih rueichuan chang gsr global seekoptimizing realtime diskscheduling algorithm journal systems software v80 n2 p198215 february 2007 sanjoy k baruah jayant r haritsa scheduling overload realtime systems ieee transactions computers v46 n9 p10341039 september 1997 babak hamidzadeh yacine atif krithi ramamritham schedule execute decision support performanceimplications realtime systems v16 n23 p281313 may 1999 sorin manolache petru eles zebo peng schedulability analysis multiprocessor realtime applications stochastic task execution times proceedings 2002 ieeeacm international conference computeraided design p699706 november 1014 2002 san jose california yanbing li wayne h wolf hardwaresoftware cosynthesis memory hierarchies readings hardwaresoftware codesign kluwer academic publishers norwell 2001 jayanta k dey james kurose towsley online scheduling policies class iris increasing reward increasing service realtime tasks ieee transactions computers v45 n7 p802813 july 1996 g waddington hutchison resource partitioning general purpose operating systems experimental results windows nt acm sigops operating systems review v33 n4 p5274 oct 1999 wan yeon lee sung je hong jong kim online scheduling scalable realtime tasks multiprocessor systems journal parallel distributed computing v63 n12 p13151324 december zhang yiping fan miodrag potkonjak jason cong gradual relaxation techniques applications behavioral synthesis proceedings ieeeacm international conference computeraided design p529 november 0913 yungchia lin yiping chungwen huang jenq kuen lee weikuan shih tingting hwang energyaware scheduling simulation methodologies parallel security processors multiple voltage domains journal supercomputing v42 n2 p201223 november 2007 marco di natale john stankovic scheduling distributed realtime tasks minimum jitter ieee transactions computers v49 n4 p303316 april 2000 victor c lee kamyiu lam ben kao priority scheduling transactions distributed realtimedatabases realtime systems v16 n1 p3162 jan 1999 martin trngren fundamentals implementing realtime control applicationsin distributed computer systems realtime systems v14 n3 p219250 may 1 1998 p v van der stok h janssenraemaekers realtime atomic multicast algorithms implemented shared memory multiprocessor realtime systems v24 n1 p5591 january rayi chang weikuan shih rueichuan chang realtime disk scheduling multimedia applications withdeadlinemodificationscan scheme realtime systems v19 n2 p149168 sept 2000 miguel felder mauro pezz formal design notation realtime systems acm transactions software engineering methodology tosem v11 n2 p149190 april 2002 peter buhr ashif harji philipp e lim jiongxiong chen objectoriented realtime concurrency acm sigplan notices v35 n10 p2946 oct 2000 bharadwaj veeravalli xiaolin li chi chung ko influence startup costs scheduling divisible loads bus networks ieee transactions parallel distributed systems v11 n12 p12881305 december 2000 antonio pessoa magalhes joo gabriel silva stabilizing preruntime schedules help gracetime realtime systems v17 n1 p6586 july 1999 jia xu inspection verification software timing requirements ieee transactions software engineering v29 n8 p705720 august hadad sarit kraus yakov gal raz lin temporal reasoning collaborative planning agent dynamic environment annals mathematics artificial intelligence v37 n4 p331379 april miodrag potkonjak wayne wolf methodology algorithms design hard realtime multitasking asics acm transactions design automation electronic systems todaes v4 n4 p430459 oct 1999