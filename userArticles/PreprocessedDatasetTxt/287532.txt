using matrix sign function compute invariant subspaces matrix sign function several applications system theory matrix computations however numerical behavior matrix sign function associated divideandconquer algorithm computing invariant subspaces still completely understood paper present new perturbation theory matrix sign function conditioning computation numerical stability divideandconquer algorithm iterative refinement schemes numerical examples also presented extension matrixsignfunctionbased algorithm compute left right deflating subspaces regular pair matrices also described b introduction since matrix sign function introduced early 1970s subject numerous studies used many applications example see 30 31 11 26 23 references therein main interest use matrix sign function build parallel algorithms computing invariant subspaces nonsymmetric matrices well associated eigenvalues challenge design parallel algorithm nonsymmetric eigenproblem uses coarse grain parallelism effectively scales larger problems larger machines waste time dealing parts spectrum user interested deals highly nonnormal matrices strongly clustered spectra work 2 reviewing existing approaches proposed design parallel nonsymmetric eigenroutine toolbox includes basic building blocks lu factorization matrix inversion matrix sign function standard eigensolver routines qr algorithm new algorithms spectral divideandconquer using sign function discussed tools could used different combinations different problems architectures extracting eigenvalues nonsymmetric matrix andor corresponding invariant subspaces rather using black box eigenroutines provided eispack 32 21 lapack 1 expect toolbox approach allow us flexibility developing efficient problemoriented eigenproblem solvers high performance machines especially parallel distributed memory machines however numerical accuracy stability matrix sign function divideandconquer algorithms based poorly understood paper address issues much work also appears 3 let us first restate basic definitions ideas establish notation matrix sign function matrix defined follows 30 let jordan canonical form matrix 2 c nthetan eigenvalues j lie open right half plane c j gamma lie open left half plane c gamma published siam j mat anal appl vol19 pp205225 1998 department mathematics university kentucky lexington ky 40506 baimsukyedu z computer science division mathematics department university california berkeley z bai j demmel matrix sign function assume eigenvalue lies imaginary axis otherwise signa defined easy show spectral projection corresponding eigenvalues open right left half planes p respectively let leading columns orthogonal matrix q span range space p example q may computed rankrevealing qr decomposition spectral decomposition 1 eigenvalues c 22 eigenvalues c gamma algorithm proceeds divideandconquer fashion computing eigenvalues 11 22 rather using jordan canonical form compute signa shown signa limit following newton iteration k1 2 2 iteration globally ultimately quadratic convergent exist different scaling schemes speedup convergence iteration make suitable parallel computation computing matrix sign function mobius transformation spectrum divided along arbitrary lines circles rather along imaginary axis see report 2 references therein details unfortunately finite precision arithmetic ill conditioning matrix k respect inversion rounding errors may destroy convergence newton iteration 2 cause convergence wrong answer consequently left bottom corner block matrix q aq 1 may much larger u denotes machine precision means numerically stable approximate eigenvalues eigenvalues 11 22 would like paper first study perturbation theory matrix sign func tion conditioning numerical stability overall divideandconquer algorithm based matrixsign function realize difficult give complete clear analysis partial understanding expect newtion iteration converge accurate coarse analysis also bound condition numbers intermediate matrices newton iter ation artificial possibly pathological test matrices constructed verify theoretical analysis besides artificial tests also test large number eigenvalue problems random matrices eigenvalue problems appli cations electrical power system analysis numerical simulation chemical reactions areodynamics stability analysis examples conclude bounds numerical sensitivity stability matrix sign function computation based algorithms reachable pathological cases often pessimistic worst cases happen rarely addition discuss iterative refinement approximate invariant subspace outline extension matrix sign function based algorithms compute left right deflating subspaces regular matrix pencil gamma b matrix sign function computing invariant subspaces 3 rest paper organized following section 2 presents new perturbation bound matrix sign function section 3 discusses numerical conditioning matrix sign function backward error analysis computed invariant subspace remarks matrix sign function based algorithm versus qr algorithm presented section 4 section 5 presents numerical examples analysis sections 2 3 4 section 6 describes iteration refinement scheme improve approximate invariant subspace section 7 outlines extension matrix sign function based algorithms generalized eigenvalue problem concluding remarks presented section 8 2 perturbation bound matrix sign function matrix eigenvalues pure imaginary axis matrix sign function defined words set illposed problems matrix sign function set matrices least one pureimaginary eigenvalue computationally observed eigenvalues close pure imaginary axis newton iteration variations slowly convergent may misconvergent moreover even iteration converges error computed matrix sign function could large use desirable perturbation analysis matrix sign function related distance nearest illposed problem perturbation theory condition number estimation matrix sign function discussed 25 23 29 however none existing error bounds explicitly reveals relationship sensitivity matrix sign function distance nearest illposed problem section derive new perturbation bound explicitly reveals relationship denote eigenvalues positive real part ie denotes smallest singular value addition recall wellknown inequality matrix 2norm theorem 21 suppose pure imaginary zero eigenvalues perturbation ffl j kffiak let 3 furthermore 4 z bai j demmel im r r r fig 1 semicircle gamma proof prove bound 7 bound 5 proved using similar technique following roberts 30 kato 24 matrix sign function also defined using cauchy integral representation z gamma simple closed curve positive direction enclosing sign spectral projector without loss generality take gamma semicircle radius figure 1 definition 8 signa seen study stability matrix sign function perturbation ffi sufficient study sensitivity projection projection corresponding condition 6 eigenvalues perturbed across pure imaginary axis semicircle gamma also encloses therefore z z r gammar z 2 gamma2 first integral denoted 1 integral straight line semicircle gamma second integral denoted 2 integral curved part semicircle gamma taking spectral norm first integral term noting definition condition 6 inequality 3 z r gammar matrix sign function computing invariant subspaces 5 z r gammar z r gammar z r gammar taking spectral norm second integral term 2 z 2 gamma2 kre z 2 gamma2 r r third inequality follows 3 fourth choice radius r semicircle gamma desired bound 7 follows bounds ki 1 k ki 2 k identity remarks order 1 language pseudospectra 35 condition 6 means kffiak pseudospectra cross pure imaginary axis 2 perturbation bound 7 see stability matrix sign function perturbation requires kffiakpseudospectra bounded away pure imaginary axis also small recall da distance nearest matrix pureimaginary eigenvalue 3 natural take condition number matrix sign function algorithms computing da related problems found 14 9 8 12 4 bound 7 similar bound norm frechet derivative matrix sign function x given roberts 30 length closed contour gamma recently asymptotic perturbation bound signa given byers mehrmann 13 show first order ffi kffiak 6 z bai j demmel assumed form 1 kffiak sufficiently small separation matrices 11 22 33omega kronecker product comparing bounds 7 9 note first bound 7 global bound asymptotic bound second assumption 6 bound 7 simple geometric interpretation see remark 2 unspecified interpret assumption sufficient small kffiak bound 9 3 conditioning matrix sign function computation 2 point may much efficient compute half machine precision ie compute absolute error bounded u 12 ksk avoid ill conditioning newton iteration achieve half machine precision believe matrix must condition number less u gamma12 ill conditioned say singular values less u 12 kak need use preprocessing step deflate small singular values unitary similarity transformation obtain submatrix condition number less u gamma12 compute matrix sign function submatrix deflation procedure may also needed intermediate matrices newton iteration worst case look closely situation near convergence newton iteration relate error distance nearest illposed problem 18 illposed problems matrices pureimaginary eigenvalues without loss generality let us assume form 11 12 otherwise matrix b schur decomposition form r solution sylvester equation must exist unique since 11 22 common eigenvalues known spectral projector p corresponding eigenvalues 11 r following lemma relates r norm projection p signa condition number lemma 31 let r let ae 1 gamma2r 2 ae therefore proof 1 let r easy verify r satisfies 12 gamma2r matrix sign function computing invariant subspaces 7 2 using singular value decomposition svd r urv one reduce computing svd computing svd gamma2sigma permutations equivalent computing svds 2 2 matrices turn simple calculation note solution r sylvester equation 12 equality attainable 33 lemma 31 see conditioning matrix sign function computation closely related norm projection p therefore norm r turn closely related quantity specifically krk large ka 12 k moderate ill conditioned matrix sign function means large krk turn means small following stewart 33 means harder separate invariant subspaces corresponding matrices 11 22 following theorem discusses conditioning eigenvalues signa distance signa nearest illposed problem theorem 32 let r lemma 31 1 let ffi property ffi pure imaginary eigenvalue may chosen smaller language 35 fflpseudospectrum excludes imaginary axis ffl 1ksk intersects ffl 1ksk 2 condition number eigenvalues kpk words perturbing small ffi perturbs eigenvalues kpk kffiskokffisk 2 3 close u gamma12 newton iteration 2 floating point arithmetic compute absolute error bounded u 12 ksk proof 1 problem minimize oe min gamma iii real oe min smallest singular value gamma iii using unitary similarity transformation permutation part 1 lemma 31 see equivalent minimizing oe min oe j real straightforward calculation minimum obtained 8 z bai j demmel 2 condition number semisimple eigenvalue equal secant acute angle left right eigenvectors 24 17 using reduction 2 2 subproblems unitary transformation coordinates changes angles vectors straightforward calculation 3 since absolute error ffi computing 1 essentially error computing newton iteration converge ffi cannot large ffi pure imaginary eigenvalues result 1 means kffisk therefore u iteration 2 compute absolute error bounded u 12 ksk naturally desired analysis know conditioning intermediate matrices k newton iteration help us addressing question detect possible appearance pure imaginary eigenvalues modify terminate iteration early necessary unfortunately difficult make clean analysis far convergence unable relate error step iteration conditioning problem coarse analysis however case matrix diagonalizable theorem 33 let eigenvalues j none pure imaginary zero right eigenvectors x j left eigenvectors j normalized let k matrix obtained kth newton iteration 2 k oe oe min proof may express eigendecomposition wish bound j jk j k easily done noting jk lie inside disk defined disk symmetric real axis points minimum maximum absolute value real solving extreme points yields matrix sign function computing invariant subspaces 9 means oe similarly oe proves bound 15 know error introduced step iteration mainly caused computation matrix inverse approximately bounded norm oe 1 uoe gamma3 oe min error cannot make intermediate k become singular cause iteration fail analysis shows uoe gamma3 oe oe u 14 iteration fail coarse bound generalizes result 3 theorem 2 note symmetric orthonormal eigendecomposition theorem 3 therefore shows symmetric condition number intermediate matrices k affects numerical stability newton iteration essentially determined square distance eigenvalues imaginary axis 1 nonsymmetric diagonalizable theorem 33 also see condition number intermediate matrices k related norms spectral projectors corresponding eigenvalues j quantities form simple algebraic manipulation referee predicted symmetric case condition number k might determined distance square distance able prove prediction z bai j demmel expression see eigenvalue j near pure imaginary axis ie ff j small first order taylor expansion oe j term ff j therefore first order ff j condition numbers intermediate matrices k implies even eigenvalues wellconditioned ie kp j k large also eigenvalues closer imaginary axis u 12 condition number k could large newton iteration could fail converge 4 backward stability computed invariant subspace discussed previous section possible ill conditioning matrix respect inversion rounding errors newton iteration generally expect able compute matrix sign function square root machine precision provided initial matrix condition number smaller u gamma12 means newtion iteration converges computed matrix sign function uksk assumption b approximate spectral projection corresponding therefore p first columns b rank revealing qr decomposition b span approximate invariant subspace b q form 11 12 22 b approximate eigenvalues c b 22 approximate eigenvalues c gamma since expect computed matrix sign function half machine precision reasonable expect computing invariant subspace half precision turn means backward error computed decomposition b q bounded problem ill conditioned section try justify expectation end first need bound error space spanned leading columns transformation matrix q ie need know much right singular subspace exact projection matrix perturbed p perturbed matrix norm j since p projector subspace spanned right singular vectors corresponding nonzero singular values p call set singular values practice course question rank determination wellknown perturbation theory singular value matrix sign function computing invariant subspaces 11 decomposition 34 page 260 space spanned corresponding singular vectors perturbed ojgap gap defined compute gap note always unitary change basis projector form sigma diagonal straightforward calculation find singular values projector f number ones set singular values equal maxf2 gamma n 0g since f thus error ffi q q bounded hence backward error computed spectral decomposition bounded second order perturbation term kffiqk therefore 2 n following first order bound backward stability computed invariant subspace uksk uksk use bound 5 matrix sign function 21 da da defined 4 distance illposed problem hand use bound 13 matrix sign function 21 22 separation matrices 11 22 assumed form 11 note error bound 23 essentially error bound given byers mehrmann 13 although use different approach 13 assumed 19 f 21 21 block matrix f therefore u term 23 replaced ou z bai j demmel bounds 22 23 reveal two important features matrix sign function based algorithm computing invariant subspace first indicate backward error computed approximate invariant subspace appears larger absolute error computed matrix sign function provided spectral decomposition problem ill conditioned ie da ffi tiny second 2 n backward error decreasing function oe l oe large means oe 1 large turn means eigenvalues close imaginary axis ill conditioned harder divide eigenvalues course become ill conditioned da decreases time must counterbalance increase oe certain range interesting ask error bound 22 23 sharper ie one quantities da 22 larger 13 example 2 2 matrix given show quantity ffi larger quantity da however also devise simple examples show da larger generally choosing 11 large jordan block tiny eigenvalue da close square root ffi da computed using numerical brute force plot function da wide range 2 ir search minimal value note modifying gamma oei oe sufficiently small real number da change ffi thus da ffi completely comparable quantities believe da natural quantity use ffi since ffi always depend distance nearest illposed problem reminiscent difference quantities practice use posteriori bound ke 21 kkak anyway since block uppertriangularize b q setting 2 1 block zero ke 21 kkak precisely backward error introduce ending section let us comment stability matrix sign function based algorithm versus qr algorithm qr algorithm numerical backward stable method computing schur decomposition general nonsymmetric matrix computed schur form b schur vectors b q qr algorithm satisfy e order ukak numerical software qr algorithm available eispack 32 lapack 1 although nonconvergent examples found quite rare practice 6 16 note eigenvalues blockdiagonal b may appear order therefore application requires invariant subspace corresponding eigenvalues specific region complex plane second step reordering eigenvalues diagonal b necessary guaranteed stable implementation reordering described 7 matrix sign function based algorithm regarded algorithm combine two steps one matrix sign function computed matrix sign function computing invariant subspaces 13 within order uksk analysis section shows matrix sign function based algorithm could stable qr algorithm plus reordering unfortunately matrix ill conditioned respect matrix inversion affect qr algorithm numerical unstable anticipated computed matrix sign function therefore general matrix sign function less stable qr algorithm plus reordering 5 numerical experiments section present numerical examples verify analysis see numerical stability newton iteration 2 backward accuracy computed spectral decomposition 1 influence conditioning matrix respect inversion condition number distance deltaa eigenvalues pure imaginary axis use easily computed quantity deltaa surrogate quantity da 4 let us recall analysis sections 3 4 essentially claims 1 deltaa u 12 newton iteration may fail converge fail compute matrix sign function within absolute error u 12 ksk even matrix sign function wellconditioned see 18 2 u gamma12 even distance deltaa small newton iteration may still fail compute matrix sign function absolute error ou 12 ksk see part 3 theorem 32 3 general backward error computed spectral decomposition smaller absolute error computed matrix sign function see 21 following numerical examples illustrate claims numerical experiments performed sun workstation 10 machine precision u algorithms implemented matlab 40a use simple newtion iteration 2 compute matrix sign function stopping criterion maximal number iterations set 70 convergence computed matrix sign function use qr decomposition column pivoting rank revealing scheme 1 b rpi finally compute 11 12 22 first r columns b q spans invariant subspaces corresponding b 11 approximate eigenvalues c ke 21 kkak backward error committed algorithm test matrices constructed form u orthogonal matrix generated qr decomposition random matrix normal distribution mean 00 variance 10 choose different submatrices 11 22 12 generated matrices different specific features order observe theoretical results practice 14 z bai j demmel table numerical results example 1 exact matrix sign function condition number computed described lemma 31 condition number computed matlab function cond following tables iter number iterations newton iteration number 10 ff parenthesis next iteration number iter indicates convergence newton iteration stationary o10 ff iter th iteration forward failed satisfy stopping criterion even allowed maximal number iterations experimented numerous matrices different pathologically ill conditioning terms distance pure imaginary axis condition numbers different values sepa 11 22 two selected examples presented typical behaviors observed example 1 example matrices form 24 random 2 2 matrix normal distribution multiplying parameter c generated matrix two complex conjugate eigenpairs sigma gammas sigma 0 distance size parameter c adjust conditioning resulted matrix matrix sign function table 1 reports computed results different values table see matrices well conditioned corresponding matrix sign function also wellconditioned stated claim 1 convergence rate accuracy newton iteration clearly determined distance deltaa distance becomes smaller steady increase number newton iteration required convergence loss accuracy computed matrix sign function therefore desired invariant subspace table also see deltaa moderate newton iteration fails compute matrix sign function half machine precision nevertheless computed invariant subspace seems still half machine precision see claim matrix sign function computing invariant subspaces 15 table numerical results example 2 example 2 example test matrices form 24 12 5 5 0normally distributed random matrices submatrices 11 22 first set 5 5 1 0normally distributed random upper tridiagonal matrices diagonal elements 11 22 replaced dja ii j gammadja ii j respectively ii 1 n random numbers normal distribution 0 1 positive parameter 12 5 5 1 0normally distributed random matrices numerical results reported table 2 given parameter eigenvalues wellseparated away pure imaginary axis deltaa small however stated claim 2 see influence condition numbers convergence newton iteration therefore accuracy computed matrix sign function invariant subspace 6 refining estimates approximate invariant subspaces use matrix sign function based algorithm deflate invariant subspace matrix end form 11 12 22 size ke 21 kkak reveals accuracy backward stability computed invariant subspace spanning b higher accuracy desired may use iterative refinement techniques improve accuracy computed invariant sub space methods due stewart 33 dongarra moler wilkinson 20 chatelin 15 even though methods apparently solve different equations shown demmel 19 changing variables solve riccati equation inner loop let us follow stewarts approach present first class methods 25 know b spans approximate invariant subspaces b spans orthogonal complementary subspace let true invariant subspace represented b orthogonal complementary subspace b derived follows b invariant subspace lower left block zero ie lower left corner gammay h 11 12 22 gammay z bai j demmel zero thus must satisfy equation 12 wellknown algebraic riccati equation may use following two iterative methods solve 1 simple newton iteration 22 2 modified newtion iteration therefore need solve sylvester equation inner loop iterative refinement following numerical example use simple newton iteration 26 refine approximate invariant subspace computed matrix sign function based algorithm following stopping criterion example 3 continue example 2 table 3 lists 22 number iterative refinement steps backward accuracy improved invariant subspace shown convergence analysis iterative solvers 26 27 riccati equation stewart 33 demmel 18 let 22 assumptions k 14 k 112 iterations 26 27 converge respectively therefore sep b 22 key factor convergence iterative refinement schemes examples verify analysis analysis section 3 recall sep b 22 also affects backward stability computed invariant subspace matrix sign function based algorithm first place iterative refinement 7 extension generalized eigenproblem section outline scheme extend matrix sign function based algorithm solve generalized eigenvalue problem regular matrix pencil gamma b matrix pencil gamma b regular agammab square detagammab identically zero 22 gardiner laub considered extension newton iteration computing matrix sign function matrix pencil solving generalized algebraic riccati equations discuss another possible approach includes computation left right deflating subspaces given matrix pencil gamma b problem spectral decomposition seek pair left right deflating subspaces l r corresponding eigenvalues pencil specified region complex plane words want find pair unitary matrices ql qr matrix sign function computing invariant subspaces 17 table iterative refinement reresults example 2 28 eigenvalues 11 gamma b 11 eigenvalues gamma b selected region complex plane discuss region open right half complex plane treatment standard eigenproblem employing mobius transformations ffa divideandconquer union intersections arbitrary half planes complemented disks rather general region end directly applying newton iteration ab gamma1 convergence practice want invert b ill conditioned hence letting z iteration becomes leads following iteration converges quadratically matrix z1 next find desired deflating subspace use rank revealing qr decomposition calculate range space projection corresponding spectral open right half plane range space thus computing rank revealing qr decomposition z1 obtain invariant subspace ab gamma1 without inverting b ie cr eigenvalues pencil gamma b open right half plane cl ones gamma b open left half plane therefore obtained left deflating subspace gamma b z bai j demmel compute right deflating subspace agammab applying idea h gamma b h since transposing swaps right left spaces newton iteration implicitly applying h b gammah turns converges quadratically matrix z1 using arguments computing rank revealing qr decomposition qrrr pi r r h b gammah dl eigenvalues pencil agammab open left half plane dr ones gamma b open right half plane note desired spectral decomposition transposing need first compute deflating subspace corresponding eigenvalues open left half plane let pi pi antidiagonal identity matrix 2 29 30 immediately r h0 h l aqr q h bqr partitions 21 22 r h0 h note cl eigenvalues pencil gamma b open left half plane dr eigenvalues pencil gamma b open right half plane therefore homogeneous sylvester equation solution b 31 32 computed unitary orthogonal matrices ql qr give desired spectral decomposition 28 2 permutation pi avoided use rank revealing ql decomposition matrix sign function computing invariant subspaces 19 8 closing remarks paper presented number new results approaches analyze numerical behavior matrix sign function algorithms using compute spectral decompositions nonsymmetric matri ces analysis numerical experiments conclude spectral decomposition problem ill conditioned algorithm practical approach solve nonsymmetric eigenvalue problem performance evaluation matrix sign function based algorithm parallel distributed memory machines intel delta cm5 reported 4 course work discovered new approach essentially computes spectral projection matrix matrix sign function approach also uses basic matrix operations namely matrix multiplication qr decomposition however avoids matrix inverse point view accuracy promising approach new approach based work bulgakov godunov malyshev 10 27 28 5 improved results several important ways made truly practical inverse free highly parallel algorithm standard generalized spectral decomposition problems brief difference matrix sign function inverse methods follows matrix sign function method significantly faster converges difficult problems inverse free algorithm gives accurate answer matrix sign function algorithm interested reader may see paper 5 details acknowledgements first author supported part arpa grant dm28e04120 p95006 via subcontract argonne national laboratory nsf grant asc9313958 part doe grant defg0394er25219 via subcontracts university california berkeley second author funded part arpa contract daah049510077 university tennessee subcontract ora745302 arpa contract daal0391c0047 university tennessee subcontract ora446602 nsf contracts asc9313958 asc9404748 contracts defg0394er25219 defg0394er25206 doe contract w subcontract 951322401 argonne national labora tory nsf infrastructure grant nos cda8722788 cda9401156 information presented necessarily reflect position policy government official endorsement inferred authors would like acknowledge ralph byers chunyang nick higham volker mehrmann fruitful discussions subject would also like thank referees valuable comments manuscript r design parallel nonsymmetric eigenroutine toolbox design parallel nonsymmetric eigenroutine toolbox spectral decomposition nonsymmetric matrices distributed memory parallel computers inverse free parallel spectral divide conquer algorithms nonsymmetric eigenproblems convergence shifted qr algorithm 3 3 normal matrices reordering diagonal blocks real schur form regularity result singular values transfer matrix quadratically convergent algorithm computing l1norm bisection method computing h1 norm transfer matrix related problems circular dichotomy spectrum matrix solving algebraic riccati equation matrix sign function bisection method measuring distance stable matrix unstable matrices matrix sign function method computation invariant subspaces stability radius generalized statespace system simultaneous newtons iteration eigenproblem qr algorithm fails converge fix condition number equivalence transformations block diagonalize matrix pencils condition numbers distance nearest illposed problem three methods refining estimates invariant subspaces improving accuracy computed eigenvalues eigenvectors matrix eigensystem routines eispack guide extension generalization matrixsign function solution algebraic riccati equations matrix sign decomposition relation polar decomposition perturbation theory linear operators polar decomposition matrix sign function condition estimates matrix sign function algorithms riccati equa tions guaranteed accuracy spectral problems linear algebra parallel algorithm solving spectral problems linear algebra condition estimation matrix function via schur decomposition linear model reduction solution algebraic riccati equation separation matrix eigenvalues structural decomposition largescale systems matrix eigensystem routines eispack guide perturbation bounds subspaces associated certain eigenvalue problems matrix perturbation theory pseudospectra matrices tr ctr daniel kressner block algorithms reordering standard generalized schur forms acm transactions mathematical software toms v32 n4 p521532 december 2006