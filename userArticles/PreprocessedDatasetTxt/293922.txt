synthesis novel views single face image images formed human face change viewpoint new technique described synthesizing images faces new viewpoints single 2d image available novel 2d image face computed without explicitly computing 3d structure head technique draws single generic 3d model human head prior knowledge faces based example images faces seen different poses example images used learn poseinvariant shape texture description new face 3d model used solve correspondence problem images showing faces different poses proposed method interesting view independent face recognition tasks well image synthesis problems areas like teleconferencing virtualized reality b introduction given drivers license photograph persons face one infer face might look like different viewpoint threedimensional structure object determines image object changes change viewpoint viewpoint changes previously visible regions object become oc cluded previously invisible regions become visible additionally arrangement configuration object regions visible views may change accordingly synthesize novel view object two problems must addressed resolved first visible regions new view shares previous view must redrawn new positions sec ond regions previously visible view example image must generated syn thesized obvious latter problem unsolvable without prior assumptions human share common structure prior knowledge obtained extensive experience faces direct general solution synthesis novel views face single example image recovery threedimensional structure face threedimensional model rotated artificially would give correct image points visible example image ie one model obtained however without additional assump tions minimal number images necessary reconstruct face using localized features three huang lee 1989 even assumption face bilaterally symmetric reduces number two rothwell et al 1993 vetter poggio 1994 shape shading algorithms applied previous work recover surface structure face horn 1987 inhomogeneous reflectance properties faces make surface integration whole face imprecise questionable additionally fact face regions visible single image insufficient obtain threedimensional structure makes clear task synthesizing new views given single image face cannot solved without prior assumptions structure appearance faces general models proposed previously generalize faces images subdivided two groups drawing threedimensional head structure considering view imagedependent face models general knowledge faces incorporated flexible threedimensional head models consists handconstructed representations physical properties muscles skin face terzopoulos waters 1993 thalmann thalmann 1995 adjust model particular face two images used akimoto et al 1993 aizawa et al 1989 present purposes difficult assess usefulness approach since generalization performance new views single image never reported recent years twodimensional imagebased face models applied synthesis rigid nonrigid face transitions craw cameron 1991 poggio brunelli 1992 beymer et al 1993 cootes et al 1995 models exploit prior knowledge example images prototypical faces work building flexible imagebased representations active shape models known objects linear combination labeled examples representations applied task image search recognition cootes et al 1995 synthesis craw cameron 1991 underlying coding image new object face based linear combinations twodimensional shape examples prototypical images similar method used synthesize new images face different expression changed viewpoint beymer et al 1993 making use single given image power technique uses automated labeling algorithm computes correspondence every pixel two images rather handselected subset feature points technique applied recently problem face recognition across viewpoint change aim generating additional new views given example face image beymer poggio 1995 spite power technique serious limitation reliance solution correspondence problem across view changes large changes viewpoint still highly problematic due frequency occlusions occluding contours occur overcome difficulty present work draw concept linear object classes introduced recently context object representations vetter poggio 1996 application linear object class approach problem mediates requirement image correspondence across large view changes success novel view synthesis mapping process figure 1 two examples face images top row mapped onto reference face center using pixelwise correspondence established optical flow algorithm shown lower row separates 2dshape information captured correspondence field texture information captured texture mapped onto reference face lower row overview approach present paper linear object class approach improved combined single threedimensional model human head generating new views face using techniques tandem limitations inherent approach used alone overcome specif ically present technique based linear object class method described vetter poggio 1996 powerful addition 3d model allows much better utilization example images 3dmodel also allows transfer features particular individual face given example view new synthetic views latter point important addition linear class approach allows individual identifying features like moles blemishes present non standard locations given individual face transferred onto synthesized novel views face true even blemishes etc unrepresented general experience linear class model acquired example faces hand primary limitation single 3d head model wellknown difficulty representing variability head shapes general problem linear class model exemplarbased knowledge faces allow us solve another way looking combination approaches returns us twofold problem described beginning paper synthesis novel views single exemplar image requires ability redraw regions shared two views also ability generate regions novel face invisible exemplar view 3d head model allows us solve former linear object class approach allows us solve latter linear object classes linear object class defined 3d object class 3d shape represented linear combination sufficiently small number prototypical objects objects meet criterion following important property new orthographic views according uniform affine 3d transformation generated object class specifically rigid transformations 3d generated exactly corresponding transformed views known set proto types thus training set consists frontal rotated views set prototype faces rotated view new face generated single frontal view provided linear class assumption holds key approach representation object face view terms shape vector texture vector see also cootes et al 1995 jones poggio 1995 beymer pog gio 1995 separation 2dshape texture information images human faces requires correspondence established feature points extreme correspondence must established every pixel given face image reference image noted previ ously extremely difficult problem large view changes involved linear object class assumption requires correspondence within given viewpoint specifically correspondence single view individual face single reference face imaged view separately orien tation example face images set correspondence reference face pose correspondence different poses needed done offline manually craw cameron 1991 cootes et al 1995 automatically beymer et al 1993 jones poggio 1995 beymer poggio 1995 vetter poggio 1996 correspondence problem within views solved resultant data separated shape texture vector shape vector codes 2dshape face image deformation correspondence field reference face beymer et al 1993 jones poggio 1995 beymer poggio 1995 vetter pog gio 1996 later also serves origin linear vector space likewise texture exemplar face coded vector image intensities mapped onto corresponding positions reference face image see also figure 1 lower row threedimensional head model linear class approach works well features shared faces eg eyebrows nose mouth ears limited representational possibilities features particular individual face eg mole cheek reason single 3d model human head added linear class approach face textures mapped onto 3d model transformed image showing model new pose final ro tated version given face image ie including moles etc generated applying new image 3d model shape transformation given linear object class ap proach described detail shortly paper organized follows first algorithm generating new images face single example image described technical details implementation used realize algorithm grey level images human faces described appendix results comparison different implementations generalization algorithm shown two variations combined approach compared method based purely linear object class described previously vetter poggio 1996 first linear class approach applied parts face separately individual parts two reference face images separated using 3dmodel second 3dmodel used additionally establish pixelwise correspondence two reference faces images two different orientations correspondence field allows texture mapping across view point change finally main features possible future extensions technique discussed approach algorithm section algorithm developed allows synthesis novel views face single example view face brevity present paper describe application algorithm synthesis frontal view ie defined paper novel view example rotated view ie defined paper view 24 ffi frontal noted however algorithm restricted particular orientation faces algorithm subdivided three parts overview see figure 3 ffl first texture shape information image face separated ffl second two separate modules one texture one shape compute texture shape representations given ro tated view face terms appropriate view reference face modules used compute shape texture estimates new frontal view face ffl finally new texture shape frontal view combined warped frontal image face separation texture shape images faces central part approach representation face images consists separate texture vector 2dshape vector one components referring feature points case pixels assuming pixelwise correspondence reference face pose given example image represented fol lows 2dshape coded deformation field n selected feature points limit pixel reference image shape face image represented vector distance displacement feature respect corresponding feature reference face texture coded difference map image intensities exemplar face corresponding intensities reference face thus mapping defined correspondence field normalized texture written vector contains image intensity differences n pixels image images training set mapped onto reference face corresponding orientation done separately rotated orientation real images faces pixelwise correspondences necessary mappings computed automatically using gradient based optical technique already used successfully previously face images beymer et al 1993 vetter poggio 1996 technical details technique found appendix b linear shape model faces shape model human faces used algorithm based linear object class idea necessary sufficient conditions given vetter poggio built training set pairs images human faces pair im ages consisting rotated frontal view face 2dshape vectors r rotated shape f frontalshape computed consider threedimensional shape human head defined terms pointwise features 3dshape head represented vector contains x zcoordinates n feature points assume 2 3n linear combination q 3d shapes heads quite obvious linear transformation r eg rotation 3d thus 3d head shape represented weighted sum shapes heads rotated shape linear combination rotated shapes heads weights fi apply 2d face shapes computed images consider following projection p 3d 2d minimal number q shape vectors necessary represent change allows correct evaluation coefficients fi images words dimension threedimensional linear shape class allowed change projection p assuming projection r 2d shape given ro tated view represented rotated shapes example set r frontal 2dshape f given r computed without knowing using fi equation 1 f given images training set following equation words new 2d face shape computed without knowing threedimensional structure noted knowledge correspondence equation 1 equation 2 necessary rows linear equation system exchanged freely texture model faces contrast shape model two different possibilities generating frontal texture given rotated texture de scribed first method based linear object class approach second method uses single threedimensional head model map texture rotated texture onto frontal texture linear object class approach texture vectors equivalent method described earlier 2dshape vectors assumed rotated texture r represented q rotated textures r computed given example set follows assumed new texture f computed using ff equation 3 given frontal images training set following equation threedimensional head model whereas linear texture approach satisfactory generating new frontal textures regions visible correspondence parts correspondence pixels reference faces figure 2 threedimensional model human head used render reference images column linear shape texture model model defines corresponding parts two images column b also establishes pixelwise correspondence two views column c correspondence allows texture mapping one view c1 c2 rotated texture satisfactory regions visible views linear texture approach hardly able capture represent features particular individual face eg freckles moles similar distinct aspect facial texture features ask direct mapping given rotated texture onto new frontal texture however requires pixelwise correspondence two views see beymer et al 1993 since textures mapped onto reference face sufficient solve correspondence problem across viewpoint change reference face threedimensional model object intrinsically allows exact computation correspondence field images object different viewpoints threedimensional coordinates whole object given occlusions problematic hence pixels visible images separated pixels visible one viewpoint single threedimensional model human head incorporated algorithm three different processing steps 1 reference face images used formation linear texture 2dshape representations rendered 3d model ambient illumination conditions see figure 2a 2 3dmodel manually divided separate parts nose eye mouth region rest model using projections parts reference images different orientations could segmented corresponding parts linear texture 2dshape representation could applied separately see next paragraph shape texture models applied parts also figure 2b 3 correspondence field across two different orientations computed two reference face images based given 3d model visible part texture mapped onto reference face one orien tation mapped onto reference face second orientation see figure 2c 3 synthesize complete texture map frontal reference face new view ie regions invisible exemplar view lacking texture region visible views obtained direct texture mapping across viewpoint change merged texture obtained linear class approach see figure 3 blending technique used merge regions described detail appendix shape texture models applied parts linear object class approach 2dshape texture proposed vetter poggio 1996 improved 3dmodel reference face since linear object class approach constructed texture combined texture linear combination frontal textures output images real face l input image normalized texture mapped texture input l input shape input constucted shape sf frontal view linear combination frontal shapes approximation approximation mapping input image onto reference image figure 3 overview algorithm synthesizing new view single input image mapping input image onto reference face orientation texture 2dshape processed separately example based linear face model allows computation 2dshape texture new frontal view warping new texture along new deformation field coding shape results new frontal views output lower row right result purely based linear class approach applied parts shown center result texture mapping rotated frontal view using single generic 3d model human head bottom left real frontal view face shown assume correspondence equations 1 2 3 4 shape texture vectors constructed complete face whole hand modeling parts face eg nose mouth eye region independent separate linear classes highly prefer able allows much better utilization example image set therefore gives much detailed representation face full set coefficients shape texture representation evaluated separately part instead one set entire face apply equations 1 4 individual parts face necessary isolate corresponding areas rotated frontal reference images separation requires correspondence rotated frontal reference image equivalent equations 1 2 shape representation also equations 3 4 texture 3dmodel however used generating reference face images determines correspondence immediately example see figure 2b allows separate application linear class approach parts generate final shape texture vector whole face separation adds complexities computational process shape texture vectors obtained different parts must merged requires use blending techniques suppress visible border effects blending technique used merge regions described detail appendix algorithm tested 100 human faces face images given two orientations 24 ffi 0 ffi resolution 256by256 pixels 8 bit details given appendix leaveoneout procedure new frontal view face synthesized given rotated view 24 ffi case remaining 99 pairs face images used build linear 2d shape texture model faces figure 4 shows results six faces three different implementations algorithm center rows abc left column shows test image given algorithm true frontal view test face data base shown right col umn implementation used generating images column identical method already described vetter poggio 1996 linear object class approach applied shape texture vector whole partitioning reference face texture mapping across viewpoints applied method used identical except linear object class approach applied separately different parts face threedimensional head model divided four parts see figure 2b eye nose mouth region remaining part face segment two reference images correctly clearly necessary render threedimensional model head based segmentation texture 2dshape vectors different parts separated part separate linear texture 2dshape model ap plied final image rendered merging new shape texture vectors parts images shown column c result combination technique described b texture mapping across viewpoint change mapping given rotated face image onto rotated reference image normalized texture mapped onto frontal reference face since correspondence two images reference face given threedimensional model part frontal texture visible rotated view substituted texture obtained linear texture model described b quality synthesized frontal views tested simple simulated recognition experi ment synthetic image similar frontal face image data base 130 faces computed image comparison two common similarity measures used correlation coefficient also known direction cosine b euclidean distance l 2 measures applied images pixel representation without processing recognition rate synthesized images type abc 100 correct similarity measures independently evaluated true frontal view given rotated view face similar image result holds three different methods applied image syn thesis similarity synthetic images real face image improved applying linear object class approach separately parts improved adding correspondence two reference images method improvement indicated figure 5 decreases correlation coefficients increase different techniques input rotated synthesized images figure 4 synthetic new frontal views center columns single given rotated 24 ffi image face left column shown prior knowledge faces given training set 99 pairs images different faces shown two orientations column shows result based purely linear object class approach adding single 3dhead model linear object class approach applied separately nose mouth eye region face column b 3dmodel allows texture mapping across viewpoint change column c frontal image real face shown right column average image distance nearest neighbor real face images 47803 09589 synthetic images type 31319 09811 synthetic images type b 30393 09822 synthetic images type c 29950 09827 figure 5 comparing different image synthesis techniques using direction cosines l2norm distance measures first real frontal face images average distance nearest neighbor image different computed images test set 130 frontal face images second synthetic images type abc average value nearest neighbor computed distance measures synthetic images real face image found nearest neighbor switching technique b b c average values direction cosines increase whereas values l2norm decrease indicating improved image similarity crucial test synthesis images direct comparison real synthetic images human observers two alternative forced choice subjects asked decide two frontal face images matches given rotated image 24 ffi best one image real face synthetic image generated applying linear class method parts faces separately method b first five images data set used familiarize subjects task whereas performance evaluated remaining 95 faces although time limit response three images shown simultaneously 6 faces classified correctly 10 subjects see figure 6 cases synthetic image least one subject classified true image one case synthetic image found match rotated image better real frontal image average observer 74 correct whereas chance level 50 subjects responded average 12 seconds results demonstrate clearly improvement generating new synthetic images human face single given example view techniques proposed previously beymer pog gio 1995 vetter poggio 1996 single threedimensional model human head added linear class approach using model reference images could segmented corresponding parts additionally texture reference image could mapped precisely across view point change information used threedimensional model equivalent addition single correspondence field across viewpoint change addition increased similarity synthesized image image real face shape well texture improvement could demonstrated automated image comparison well perceptual experiments human observers results automated image comparison indicate importance proposed face model viewpoint independent face recognition sys tems synthetic rotated images compared real frontal face image also noted coefficients result decomposition shape texture example shapes textures already give us representation invariant 3d affine transformation supposing course linear face model holds good approximation target difficulties experienced human observers distinguishing synthetic images real face images indicate linear face model 99 faces segmented parts gives good approximation new face also indicates possible applications method computer graphics clearly linear model depends given example set order represent different race different age group model would clearly need examples effect well known human perception cf eg otoole et al 1994 key step proposed technique dense correspondence field images faces seen view point optical flow technique used examples shown worked well however images obtained less controlled conditions sophisticated method finding correspondence might necessary new classification synthetic versus real face images number 6 17 22 faces figure 95 different faces rotated image 24 ffi two frontal images shown human observers simultaneously decide frontal images synthesized image type b one real image table shows error rate 10 observers related number faces average observer correct 74 trails chance level 50 average response time seconds correspondence techniques based active shape models cootes et al 1995 jones poggio robust local occlusions larger distortions applied known object class shape parameters optimized actively model target image several open questions remain fully automated implementation separation parts object form separated subspaces could done computing covariance pixels example images however images high resolution may need thousands example images linear object class approach assumes orientation object image known orientation faces approximated computing correlation new image templates faces various orientations beymer 1993 clear jet precisely orientation estimated yield satisfactory results appendix face images pairs images caucasian faces showing frontal view view taken 24 ffi frontal available images originally rendered psychophysical experiments ambient illumination conditions data base threedimensional human head models recorded laser scanner cyberware tm faces without makeup accessories facial hair ad ditionally head hair removed digitally manual editing via vertical cut behind ears resolution greylevel images 256by256 pixels 8 bit preprocessing first faces segmented background aligned roughly automatically adjusting twodimensional centroid centroid computed evaluating separately average x coordinates image pixels related face independent intensity value single threedimensional model human head recorded laser scanner cyberware tm used render two reference images b computation compute 2dshape vectors r used equations 1 2 vectors spatial distances corresponding points face images correspondence points established first means find every pixel location image eg pixel located nose corresponding pixel location nose image general hard problem however since face images compared orienta tion one assume images quite similar occlusions negligible simplified condition single view make feasible compare images different faces automatic techniques algorithms known optical flow computation points tracked one image use coarsetofine gradientbased gradient method bergen et al 1992 follow implementation described bergen hingo rani 1990 every point x image error term x spatial image derivatives ffi difference intensity two compared images coarsetofine strategy refines computed displacements finer levels processed final result computation ffix ffi used approximation spatial displacement vector equation 1and 2 correspondence computed towards reference image example test images consequence vector fields common origin pixel locations reference image c linear shape texture synthesis first optimal linear decomposition given shape vector equation 1 given texture vector equation 3 computed compute coefficients ff similar fi initial vector r new image decomposed sense least square q training image vectors given training images min imizing numerical solution ff fi obtained standard svdalgorithm press flan nery 1992 new shape texture vectors frontal view obtained simple summation weighted frontal vectors equations 2 4 blending patches blending patches used different steps proposed algorithm applied merging different regions texture well merging regions correspondence fields computed separately different parts face patch work might little discontinuities borders different patches known human observers sensitive effects overall perception image might dominated images burt adelson burt adel son 1983 burt adelson 1985 proposed multiresolution approach merging images components images first image patch decomposed bandpass filtered component im ages secondly component images merged separately band form mosaic images weighted averaging transition zone finally bandpass mosaic images summed obtain desired composite image method applied merge different patches texture construction well combine texture mapped across viewpoint change missing part taken constructed one originally merging method described application images however application patches correspondence fields eliminates visible discontinuities warped images taking correspondence field image vector valued intensity merging technique applied x components correspondence vectors separately synthesis new image final step image rendering new image generated combining texture shape vector generated previous steps since given coordinates reference image every pixel reference image pixel intensity coordinates new location given new location generally coincide equally spaced grid pixels destination image final pixel intensities new image computed linear interpola tion commonly used solution problem known forward warping wolberg 1990 acknowledgments grateful hh bulthoff poggio useful discussions suggestions special thanks alice otoole editing manuscript endurance discussing paper would like thank nikolaus troje providing images 3dmodel r automatic creation 3d facial mod els hierarchical motionbased frame rate conversion face recognition varying pose face recognition one model view merging images pattern decomposition active shape models training application parameterizing images recognition reconstruc tion robot vision motion structure orthographic projections synthetizing color algorithm examples novel approach graphics extracting projective structure single perspective views 3d point sets analysis synthesis facial image sequences using physical anatomical models digital actors interactive television recognition linear combinations models symmetric 3d objects easy case 2d object recog nition image synthesis single example image importance symmetry virtual views threedimensional object recogni tion image warping tr ctr xiaoyang tan songcan chen zhihua zhou fuyan zhang face recognition single image per person survey pattern recognition v39 n9 p17251745 september 2006 philip l worthington reilluminationdriven shape shading computer vision image understanding v98 n2 p326344 may 2005 criminisi blake c rother j shotton p h torr efficient dense stereo occlusions new viewsynthesis fourstate dynamic programming international journal computer vision v71 n1 p89110 january 2007 martin giese tomaso poggio morphable models analysis synthesis complex motion patterns international journal computer vision v38 n1 p5973 june 2000 bernd heisele thomas serre poggio componentbased framework face detection international journal computer vision v74 n2 p167181 august 2007 yongmin li shaogang gong heather liddell constructing facial identity surfaces recognition international journal computer vision v53 n1 p7192 june athinodoros georghiades peter n belhumeur david j kriegman many illumination cone models face recognition variable lighting pose ieee transactions pattern analysis machine intelligence v23 n6 p643660 june 2001