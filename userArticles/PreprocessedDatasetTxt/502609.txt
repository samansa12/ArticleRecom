using navigation data improve ir functions context web search part process delivering content devices like proxies gateways log valuable information activities navigation patterns users web study consider navigation data used improve web search query posted search engine together set pages accessed search task known search session develop mixture model observed set search sessions propose variants classical em algorithm training model yields type navigationbased query clustering implicitly borrowing strength related queries mixture formulation allows us identify highly relevant urls query cluster next explore methods incorporating existing labeled data yahoo directory example speed convergence help resolve lowtraffic clusters finally mixture formulation also provides simple hierarchical display search results based query clusters effectiveness approach evaluated using proxy access logs outgoing lucent proxy b introduction searching information web tedious traditional search engines like lycos google routinely return tens thousands resources per query navigating lists time consuming frustrating paper propose narrowing search results observing browsing patterns users search tasks data support work comes devices network log requests serve content focus primarily proxy access logs easy see ideas carry kinds data collected internet permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copy otherwise republish post servers redistribute lists requires prior specific permission andor fee service provider isp logs first extract search path user follows apply statistical model combine related searches help provide guidance people beginning searches related topics capture interesting part search path search session users query together urls web pages visit response query implicit approach form query clustering combines similar search terms basis web pages visited search session clusters used improve display search engine results paper illustrate technique creating directory consisting two levels query related one groups urls user submits query search engine display relevant urls relevant directory groups relevance based data gathered previous searches clustering proposed previously ir literature use passively collected data build search sessions new data kind access orders magnitude searching activity possible specialty search engines optin systems addition exploring new source search session data also propose techniques leveraging existing manually de rived content hierarchies labeled urls improve relevance identified resources finally make work practical real proxy must consider number new implementation issues including online versions clustering algorithms balance paper organized follows section 2 discuss search session extractor section 3 describe particular mixture model query cluster ing illustrate groups finds section 4 examine kind improvement recommendations represent standard search engine related work presented section 5 conclude discussion future work section 6 2 search session extraction formalize extraction process introduce basic data element search session search session collection words user submits search engine also known query string together urls web pages visit response request users browse web proxy server record every url access including html pdf documents embedded gif jpeg images java class files search engines deal primarily web pages filter xxxxxxxxxxxx 02dec2000014855 get httpwwwgooglecomsearchqinfocom2001 xxxxxxxxxxxx 02dec2000014903 get httpwwwieeeinfocomorg2001 xxxxxxxxxxxx 02dec2000014927 get httpwwwieeeinfocomorg2001programhtml figure 1 subset fields available proxy server log corresponding search session fields ip address client timestamp recording request handled http request method url user requests file type keep html documents therefore point use terms web page html document url synonymously figure 1 present three lines proxy log represent single search session ip address users computer masked query infocom 2001 extracted url first line figure using set manuallyderived rules wwwgooglecom maintain list rules popular search engines allowing us automatically tag parse log lines corresponding search queries every time user posts query one search engines list initiate new search session new session initiated examine link structure urls subsequently requested user pages traced back list search results either directly indirectly one links included search session determine session ended either user makes another request search engine hour passed since last addition session 1 figure 2 list search session extracted log fragment figure 1 refer search session completed contains least one url remaining cases assume user examined search engine results decided none web pages relevant search session session id 1001 user id 873 query infocom2001 191459305 urls wwwieee2001 191459340 1 figure 2 sample search session fields include session id user id based ip address client query time submitted truncated julian date requested urls timestamps last column records whether url linked directly search results page 1 0 respectively implemented search session extractor takes input access log file proxy server using historical log however forced replay part users actions reconstruct path followed 1 unfortunately process complicated fact users maintain several browser windows launch multiple concurrent related search sessions simplified algorithm presented sufficient purposes present paper precise details extraction algorithm given 14 means must reretrieve pages previously visited hence extractor process usually scheduled server busy handling primary requests overhead reduced examining pages served proxy link structure well various aspects requested pages extracted background process access proxys cache currently building system kind examining data collection impacts proxy performance consider data collected proxy server handling outgoing http requests made portion lucent employees based murray hill new jersey log maintained proxy find essentially complete record sites visited population 2000 researchers developers support staff january may 2001 server logged 42 million requests table 1 list ten frequently accessed search engines lucent employees period 2 also recorded 13657 search sessions 44 com pleted roughly 60 completed sessions consisted 1 2 urls 20 length 3 4 gen eral longer search sessions larger percentage pages linked directly results page sessions length 5 comprising 20 total number search sessions 55 pages among search results seen user number sessions length 3 4 12 1 2 urls table 1 list frequently accessed search engines compiled lucent proxy logs january 1 2001 may 23 2001 queries search engine 530 wwwgooglecom searchyahoocom 112 wwwaltavistacom 44 hotbotlycoscom 42 wwwlycoscom 27 searchexcitecom 03 searchmsncom 03 wwwnorthernlightcom terms time queries exactly repeated session data set 50 issued within day tend made user exceptions queries related paper deadlines 2 worth noting wwwgooglecom much popular among research community one would expect standard ratings offered media metrix netratings 15 rank yahoocom msncom searchaolcom clear market leaders query bridaldresses bridesmaiddress flowergirldresses urls wwwpriscillaofbostoncom wwwmartasbridalcom wwwbestbuybridalcom wwwbestbuybridalcom weddingworldnet wwwmartasbridalcom weddingworldnet weddingworldnethtm wwwldsweddingscombridal dress wwwusedweddingdressescom figure 3 three search sessions initiated three different users query strings related wedding dresses kind urls visited users similar major computer science conferences searches online greeting card services near major holidays larger time scales 80 repeated queries posted different users far focused proxy logs primary source data constructing search sessions many search engines collect abbreviated navigation data help improve service 6 socalled clickthrough statistics record pages users select list search results design redirection mechanism used collect data cannot capture information users activities beyond selections search results list given fact long search sessions consist mainly pages returned search engine clickthrough data potential uncover relevant pages see applied heuristic relevance measures introduced end paper found desired pages half long sessions linked directly list search results examined user even page included among search results clickthrough statistics cannot identify requests page referred urls linked either directly indirectly search results list missing valuable information relevance sources search engine database reasons see approach potentially much powerful traditional schemes rely tracking clickthroughs 3 clustering queries preliminary data analysis collection search sessions led simple observation semantically related query terms often draw users sets urls figure 3 present three search sessions initiated different users relate wedding dresses different kinds produce requests many web pages section consider improving search results first forming groups queries based similarity associated search sessions turn combining search sessions queries given group better identify relevant urls ir literature several examples pattern retrieved items used form socalled query clusters see 16 17 context schemes would involve queries submitted users together top l relevant pages returned given search engine technique different consider pages actually selected user search task effect reducing spurious associations queries addition include pages listed search engine effectively making deficiencies spidering including user choices developed improved search scheme similar spirit collaborative filtering kind approach discussed previously ir literature typically required user report details search manually tag pages according relevance example 9 level involvement unrealistic context web searching hence impact schemes somewhat limited avoid problems basing work passively collected proxy logs initial intuition navigationbased query clustering came ir literature rather oftencited motivation popular pagerank algorithm 5 broadly speaking pagerank based amount time random surfer would spend page random walks link structure web also discussed 11 felt actual user data would better measure importance random walk idea 31 mixture model section consider models forming query groups well determining relevant urls group construct statistical mixture model describe search session data model parameters probability given query belongs particular group well set groupspecific relevance weights assigned collections urls algorithms present attempt fit model data first approach makes use standard em expectation maximization algorithm find maximum likelihood estimates model parameters end paper discuss various alternatives work real time incorporated proxy implementation help guide cluster process also introduce labeled data existing topic hierarchy contains 12 million web sites present ad hoc algorithm dealing labeled pages end paper discuss formal statistical approach uses content hierarchy specify prior distribution models parameters let q denote queries u urls query q associated one groups subscript runs 1 number queries seen training data moment assume number groups k fixed group relation captured triple denotes group id w ik probability q belongs group k group identify number relevant urls described triple k url kj weight determines likely u j associated queries belonging group k let index j range 1 number urls seen training data j might include urls content hierarchy example querygroup triple q associated grouprelevance triples k mentioned sets triples constitute parameters statistical model search sessions triples used search engine improve page rank ings user initiates new search present display query groups related search terms group select relevant urls arranged display like figure 4 arrange query groups urls weight relevant appearing top example used data content hierarchy name separate query groups eg medications figure 4 end paper discuss model extensions purely automated group naming finally see clustering addition standard page search results presenting user small organized set urls system together spiderbased search list allow new resources added system natural way fact estimates confidence used suppress display entirely forcing user help train system insufficient navigation data clustering also used modify rankings results traditional search engine guarantee new resources visible user modified rankings displayed fraction time figure 4 example cluster results query hypertension mixture model employed form query groups well relevance weights assume dataset queries would like assign k groups turn determine groupspecific relevance weights j urls moment simplify data structure let n ij denote number times url u j selected user search session query q let n vector counts associated query q model vector coming mixture form terms ff k sum one denote proportion population coming kth component also associated kth component mixture vector parameters sampling perspec tive one consider entire dataset generated two steps first pick one k groups k according probabilities ff k use associated distribution pdeltaj k generate vector n consider specification component mixture 1 assume kth component data come poisson distribution mean kj counts different url u j independent setting likelihood kth component associated vector counts n given e gamma kj fit model type introduce set unobserved missing indicator variables fl ik group k zero otherwise socalled complete data likelihood set counts n indicator variables expressed e gamma kj refer parameters kj relevance weights use probability fl kth group weight query q w ik mentioned beginning section 32 basic em algorithm expectationmaximization em algorithm convenient statistical tool finding maximum likelihood estimates parameters mixture model 8 em algorithm alternates two steps estep compute expectation complete data loglikelihood conditional observed data current parameter estimates mstep parameters maximizing expected loglikelihood estep found context estep consists calculating conditional expectation indicator variables fl ik l ff l pdeltaj k given 2 expression quantities k denote current parameter estimates note fl ik estimate probability query q belongs group k taken query group weights mstep substitute 3 maximize respect parameters ff k k case closed form expression available giving sciencemathstatisticsconferences wwwbeeriorgilsrtl computerscomputer scienceconferences wwwcomputerorgconferenconfhtm computerscomputer scienceconferences wwwacmorgsigmod computerscomputer scienceconferences wwwacmorgsigmmeventssigmm conferenceshtml computerscomputer scienceconferences wwwacmorgsigkddeventshtml figure 5 subset fields available dmoz data fields directory label url us updates l clearly simple updates make em algorithm convenient tool determining query group weights relevance weights unfortunately convergence algorithm slow guaranteed converge local maximum obtain good solution start em process several random initial conditions take best converged fits figure 6 present example three groups found standard em approach group display query terms highest weights arguable last group fairly loose combining different countries africa standpoint searches typically conducted lucent employees served proxy however degree resolution surprising proxy logs isp would sufficient sample size subdivide topic area 33 approximate algorithm labeled data query groups formed mixture model introduced section 32 allow us borrow strength search sessions initiated different semantically related query strings mixture approach however highly unstructured sense incorporate user data learn groups relevance weights section consider simple method incorporating existing information related urls say directory like dmoz wwwdmozcom yahoo essentially use directory labels obtained sources seed query groups figure 5 present subset data available dmoz hierarchy assume data structure represented set pairs l u lj l indexes groups urls u lj url lth group j runs 1 j l number urls group l weights associated data jl specified directory assume value ff figure 7 present simple algorithm establish mappings queries njtransit bridaldresses kenya njtransit bridesmaiddress tanzania njtrainwarren flowergirldresses africa newjerseytrain figure three query groups found fitting mixture model via standard em algorithm case top ranking queries per group displayed urls either query url seen either labeled data sessions already processed remaining sessions processed batch using basic em algorithm section 32 algorithm tuned threshold value 0 1 force urls session exist previously created group approximate algorithm advantage incorporating labeled data disadvantage slowly adding set clusters new topic found data end paper describe formal statistical approach using content hierarchies avoids problem 4 experimental results evaluate methods used lucent proxy data computed search session lengths without query clustering began selecting desired url search session since users provide relevance feedback pages viewed developed simple heuristic making choice first set experiments took desired url last url user visited moving new task since users may continue browse found relevant page simple choice correct search sessions subsequent experiments defined secondtolast url desired url found results experiments sim ilar suggesting clustering considerably reduce session length therefore paper present experiments last url desired url consider two metrics judge effectiveness algorithms percent queries desired url cluster position desired url group ie session length claim location desired url systems output compared number urls user visited assign url labeled data url group based directory label weight 0 session largest overlap urls query seen urls existing g urls add b else url url g add increment weight url ff query query groups associated g add output mappings cluster sessions b using basicem algorithm figure 7 pseudocode approximate algorithm number urls visited figure 8 experiment results number urls visited without clustering 46 days testing data searching task measure improvement system averaging values across search sessions provides us measure expected search length study algorithms used portion search sessions extracted access logs lucent murray hill proxies train tested another portion distinct time given performance metrics conducted number experiments involving different timebased divisions training test sets varying parameters required basic approximate em algorithms used experience different trials choose reasonable set parameters experiments new data reported used groups training basic em algorithm decided 01 labeled data dmoz image may 19 2001 training approximate algorithm results presented representative many experiments correspond training 95 days worth data testing 46 days data percent queries desired url cluster 93 thus 93 time query desired url seen training data algorithms display desired url figure 8 presents position results see algorithms reduce number urls visited 43 basic em algorithm 38 approximate algorithm means slightly misleading due presence small number outliers queries large search sessions thus also computed median positions without clustering algorithms median number urls visited 2 either clustering algorithm median position desired url 1 perhaps importantly 43 cases 29 approximate algorithm provide strictly shorter search session length figure 9 presents results testing six months data difference height without bars due different ranges training data used found value percentage queries desired url cluster dependent length number urls visited figure 9 experiment results number urls visited without clustering 6 months testing data testing data example 6 months testing data used percent matched 6069 used percent matched 93 sense effect obvious byproduct experimental refitting model periodically set urls become outofdate real system would incorporate frequent model updates end paper consider online version em algorithm would provide incremental updates search session results basic em algorithm en couraging scale well even modest data sizes entertained take many hours con verge approximate algorithm roughly 60 search sessions passed basic em allowed approximate algorithm run much less time 1 hour compared half day since smaller set data clustered approximate setup smaller value k used note percentage queries list approximate algorithm points less basic em algorithm varying value k affects time needed form clusters quality results example clustering 142 days data twice long form clusters times long 5 related work many systems involve users ranking judging web sites visit 9 2 examples feel systems require users explicitly comment web sites place burden user therefore data considerably cleaner search sessions necessarily limited coverage database 9 example contains queries seen lucent logs many techniques exist automatically determining category document based content eg 18 references 10 references 1 outlinks document eg 7 12 currently investigating techniques include content clustering algorithms advantage working proxy cache require extra spidering another approach document categorization content ignorant 3 example uses clickthrough data discover disjoint sets similar queries disjoint sets similar urls algorithm represents query url node graph creates edges representing user action selecting specified url response given query nodes merged iterative fashion termination condition reached similar spirit algorithms algorithm forces hard clustering queries limiting ability easily incorporate prior information addition system relies much richer data namely proxy logs finally literature contains large number distancebased methods clustering 4 19 present two wellknown algorithms handling large amounts data approach taken types algorithms might work well problem tens thousands clusters 6 conclusions future work developed method extract searchrelated navigation information proxy logs mixture model uses data perform clustering queries shown kind clustering improve display search engine results placing target url high displayed list basic mixture approach using basic em algorithm highly unstructured sense incorporate user data learn groups relevance weights taken probabilistic approach grouping easily incorporate prior information related urls dmoz formal way natural prior coefficients lj relevance weights gamma distribution suppose url contained category l assign lj prior gamma distribution parameters ff urls listed directory category l receive gamma distribution parameters ff 0 fi ff ff ingredients necessary em algorithm section 3 carried simple model well way force stronger tendency toward maintaining existing hierarchy topics still allowing new urls added approximate algorithm presented paper viewed rough approximation approach next standard em algorithm sufficient relatively small data sets presented paper known scale well either number queries number query clusters increases combat started working online versions em algorithm 13 process individual search sessions arrive requires reformulation model presented believe give reasonable perfor mance also extending model treat query string collection query terms simply sorted list done kind poisson structure used collection urls search session applied query terms allows us much flexible form query clusters treat new queries finally extending probability models include content pages beyond link structures hope generate even greater improvements cluster ing proxybased implementation processing pages extract content represents little overhead already examining pages links another direction exploring avoids aggregation across users described section 3 case model users searching habits replace simplifying assumption urls associated query group sampled independently directly describing user moves within sites improve calculation relevance weights addition userlevel parameters introduced capture time scale user likely refining query changing topics acknowledgments tom limoncelli tommy reingold invaluable helping us access proxy server logs used experiments 7 r theseus categorization context agglomerative clustering search engine query log scaling clustering algorithms large databases anatomy largescale hypertextual web search engine user popularity ranked search engines finding related web pages world wide web maximum likelihood incomplete data via em algorithm discussion capturing human intelligence net information retrieval web stochastic approach linkstructure analysis salsa tkc effect clustering hypertext applications web searching mining web proxy logs user model searching nielsennetratings search engine ratings learning collection fusion strategies multiple search engines database merging birch efficient data clustering method large databases tr learning collection fusion strategies fab multiple search engines database merging anatomy largescale hypertextual web search engine reexamination text categorization methods finding related pages world wide web clustering hypertext applications web searching capturing human intelligence net stochastic approach linkstructure analysis salsa tkc effect agglomerative clustering search engine query log information retrieval web ctr bernard j jansen amanda spink chris blakely sherry koshman defining session web search engines research articles journal american society information science technology v58 n6 p862871 april 2007 mathias gry hatem haddad evaluation web usage mining approaches users next request prediction proceedings 5th acm international workshop web information data management november 0708 2003 new orleans louisiana usa mark truran james goulding helen ashman coactive intelligence image retrieval proceedings 13th annual acm international conference multimedia november 0611 2005 hilton singapore bernard j jansen amanda spink searching world wide web comparison nine search engine transaction logs information processing management international journal v42 n1 p248263 january 2006