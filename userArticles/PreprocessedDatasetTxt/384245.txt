improving memory performance sorting algorithms memory hierarchy considerations sorting algorithm design implementation play important role significantly improving execution performance existing algorithms mainly attempt reduce capacity misses directmapped caches reduce types cache misses occur common setassociative caches tlb restructure mergesort quicksort algorithms integrating tiling padding buffering techniques repartitioning data set study shows substantial performance improvements obtained using new methods b introduction sorting operations fundamental many large scale scientific commercial applications sorting algorithms highly sensitive memory hierarchy computer architecture algorithms executed well sensitive types data sets restructuring standard algorithmically efficient sorting algorithms mergesort quicksort exploit cache locality effective approach improving performance highend systems ex work supported part national science foundation grants ccr9400719 ccr9812187 eia9977030 air force office scientific research grant afosr9510215 sun microsystems grant eduenafo980405 permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit direct commercial advantage copies show notice first page initial screen display along full citation copyrights components work owned others acm must honored abstracting credit permitted copy otherwise republish post servers redistribute lists use component work works requires prior specific permission andor fee permissions may requested publications dept acm inc 1515 broadway new york ny 10036 usa fax 1 212 8690481 permissionsacmorg xiaodong zhang stefan kubricht isting restructured algorithms eg 4 mainly attempt reduce capacity misses directmapped caches paper report substantial performance improvement obtained exploiting memory locality reduce types cache misses conflict misses tlb misses present several restructured mergesort quicksort algorithms implementations fully using existing processor hardware facilities cache associativity tlb integrating tiling padding techniques properly partitioning data set cache optimizations sorting fundamental subroutine often repeatedly used many application programs thus order gain best performance cacheeffective algorithms implementations done carefully precisely algorithm design programming level focus restructuring mergesort quicksort algorithms cache opti mizations results contributions summarized follows applying padding techniques able effectively reduce cache conflict misses tlb misses fully considered algorithm design tiled mergesort multimergesort 4 two mergesort alter natives optimizations improve cache overall performance experiments different highend workstations show algorithms achieve 70 execution time reductions compared base mergesort 54 reductions versus fastest tiled multimergesort algorithms partitioning data set based data ranges able exploit cache locality quicksort unbalanced data sets two quicksort alternatives significantly outperform memorytuned quicksort 4 flashsort 6 unbalanced data sets cacheeffective sorting algorithm design architecture data set depen dent algorithm design include parameters data cache size associativity tlb size associativity ratio data set size cache size well others measurements simulations demonstrate interactions algorithms machines essential issue considered sorting algorithm design tradeoff reduction cache misses increase instruction count give execution timing model quantitatively predict tradeoffs also give analytical predictions number cache misses sorting algorithms cache optimizations show increase instruction count due effective cache optimization much cheaper cycles lost different types cache misses 2 data set consists number elements one element may 4byte integer 8byte integer 4byte floating point number 8byte double floating point number use unit element specify cache capacity sizes caches cache lines always multiple element practice identical unit practically meaningful architects application program mers makes discussions straightforward algorithmic architectural parameters use describe cacheeffective sorting algorithms size data set c data cache size l size cache line k improving memory performance sorting algorithms delta 3 cache associativity number set entries tlb cache k associativity p memory page size besides algorithm analysis performance measurements different highend workstations also conducted simulations provide performance insights simplescalar tool set 1 family simulators studying interactions application programs computer architectures simulation tools take application programs binaries compiled simplescalar instruction set architecture close derivative mips instruction set generate statistics concerning program relation simulated architecture statistics generated include many detailed execution traces available measurements computer cache misses l1 l2 tlb run sorting algorithms different simulated architectures memory hierarchies similar highend workstations observe following performance factors l1 l2 cache misses per element compare data cache misses tlb misses per element compare tlb misses instruction count per element compare algorithmic complexities reduction rate total execution cycles compare cycles saved percentage base mergesort memorytuned quicksort algorithms compared evaluated experimentally analytically tested sorting algorithms variety data sets uses 8byte integer elements 9 data sets used probability density functions number generators described 7 1 random data set obtained calling random number generator random c library returns integers range 0 2 2 equilikely function equilikelyab returns integers range b 3 bernoulli function bernoullip returns integers 0 1 returns integers 0 1 2 5 pascal function pascalnp returns integers 0 1 2 returns integers 0 1 2 n returns integers 0 1 2 data set unbalanced function returns integers range 0 2 calling rand c library n data set size returns integers max100 3 cacheeffective mergesort algorithms section first briefly overview two existing mergesort algorithms cache locality well merits limits present two new mergesort alternatives address limits experimental performance evaluation measurements presented section 5 xiaodong zhang stefan kubricht 31 tiled mergesort multimergesort lamarca ladner 4 present two mergesort algorithms effectively use caches first one called tiled mergesort basic idea partition data set subarrays sort individually mainly two purposes avoid capacity misses fully use data loaded cache replacement algorithm divided two phases first phase subarrays length c2 half cache size sorted base mergesort algorithm exploit temporal locality algorithm returns base mergesort without considering cache locality second phase complete sorting entire data set second mergesort called multimergesort addresses limits tiled mergesort algorithm first phase first phase tiled mergesort second phase multiway merge method used merge sorted subarrays together single pass priority queue used hold heads lists merged algorithm exploits cache locality well number subarrays second phase less c2 however instruction count significantly increased algorithm conducting experiments analysis two mergesort algorithms show sorting performance improved two reasons first algorithms significantly reduce capacity misses sufficiently reduce conflict misses mergesort basic operation merge two sorted subarrays destination array cache low associativity conflict mapping occurs frequently among elements three subarrays second reducing tlb misses considered algorithms even data set moderately large tlb misses may severely degrade execution performance addition effect normal data cache misses experiments show performance improvement multimerge algorithm several machines modest although decreases data cache misses heap structure significantly increases tlb misses 32 new mergesort alternatives aim reducing conflict misses tlb misses minimizing instruction count increase present two new alternatives restructure mergesort cache locality tiled mergesort padding multimergesort tlb padding 321 tiled mergesort padding padding technique modifies data layout program conflict misses reduced eliminated data layout modification done runtime system software 2 10 compiletime compiler optimization 8 padding algorithm level full understanding data structures expected significantly outperform optimization system methods 11 second phase tiled mergesort pairs sorted subarrays sorted merged destination array one element time two subarrays selected sorting comparison sequence data elements two different subarrays destination array potentially conflicting cache blocks may mapped block directmapped cache 2way associative cache improving memory performance sorting algorithms delta 5 directmapped cache total number conflict misses tiled mergesort worst case approximately log 2 number passes second phase sorting represents 1 conflict miss per comparison 1 conflict misses per element placement destination array comparison respectively order change base addresses potentially conflicting cache blocks insert l elements cache line space separate every section c elements data set second phase tiled mergesort padding elements significantly reduce cache conflicts second phase mergesort compared data size number padding elements insignificant addition instruction count increment resulting moving element subarray new position padding also trivial call method tiled mergesort padding directmapped cache total number conflict misses tiled mergesort padding most4 ndlog 2 log 2 c number passes second phase sorting 3represents number conflict misses per element padding added one conflict miss per comparison reduced 3 1 conflict misses placement 1 eliminated comparing two approximations 1 2 see tiled mergesort padding reduces conflict misses tiled mergesort 25 experimental results show execution times tiled mergesort sun ultra 5 workstation directmapped cache reduced 23 68 tiled mergesort padding execution time reductions mainly come reductions conflict misses figure 1 shows example data layout two subarrays second phase tiled mergesort modified padding conflict misses reduced example directmapped cache holds 4 elements figure type lines represent pair comparison action store selected element destination array letter figure represents cache miss without padding 8 conflict misses merging two sorted subarrays destination array 4 padding added figure 2 shows l1 left figure l2 right figure misses base mergesort tiled mergesort tiled mergesort padding simulated sun ultra 5 machine simplescalar machine l1 directmapped cache 16 kbytes l2 2way associative cache 256 kbytes experiments show padding reduces l1 cache misses 23 compared base mergesort tiled mergesort misses conflict cannot reduced tiling l2 cache miss reduction tiled mergesort padding almost tiled mergesort means padding effective reducing conflict misses l2 machine conflict misses significantly reduced l2 2way associative cache 6 delta li xiao xiaodong zhang stefan kubricht x2 x3 x4 x5 x6 x7 x8 x9 padding padding destination array cache two sorted subarray conflict conflict fig 1 data layout subarrays modified padding reduce conflict misses5151k 4k 16k 64k 256k 1m 4m per element data set size elements l1 misses per element base mergesort tiled mergesort tiled mergesort padding13571k 4k 16k 64k 256k 1m 4m per element data set size elements l2 misses per element base mergesort tiled mergesort tiled mergesort padding fig 2 simulation comparisons l1 cache misses left figure l2 misses right figure mergesort algorithms random data set simulated sun ultra 5 l1 cache miss curves left figure base mergesort tiledmergesort overlapped capacity misses second phase tiled mergesort unavoidable without complex data structure size working set two subarrays destination array normally larger cache size shown potential conflict misses could reduced padding phase however padding may completely eliminate conflict misses due randomness order data sets despite experimental results presented improving memory performance sorting algorithms delta 7 section 5 appendix using 9 different data sets consistently show effectiveness padding sun ultra 5 322 multimergesort tlb padding second phase multimergesort algorithm multiple subarrays used complete sorting entire data set effectively use cache single pass makes use heap hold heads multiple lists however since heads come lists multimerged practical working set much larger base mergesort three subarrays involved time large working set causes tlb misses degrade performance explain tlb structure following paragraph experiments indicate multimergesort significantly decreases number data cache misses however also increases tlb misses offsets performance gain although rise instruction count leads additional cpu cycles multimergesort performance degradation algorithm comes mainly high number tlb misses since memory accesses much expensive cpu cycles tlb translationlookaside buffer special cache stores recently used virtualphysical page translations memory accesses tlb generally small fully associative setassociative cache entry points memory page 4k 64kbytes tlb cache miss forces system retrieve missing translation page table memory select tlb entry replace data accessed larger amount data memory pages tlb hold tlb misses occur example tlb cache sun ultrasparciii processor holds 64 fully associative entries points page 8 kbytes p 64 pages tlb sun ultrasparciii processor hold 64 theta elements represents moderatelysized data set sorting practice one data array operated time thus tlb hold limited amount data sorting processors tlbs fully associative setassociative example tlb pentium ii pentium iii processors 4way associative k 4 simple blocking based number tlb entries work well multiple pages within tlb space range may map tlb set entry cause tlb cache conflict misses second phase multimergesort insert p elements page space separate every sorted subarray data set order reduce eliminate tlb cache conflict misses padding changes base addresses lists page units avoid potential tlb conflict misses figure 3 gives example padding tlb tlb directmapped cache 8 entries number elements list multiple 8 page elements padding lists data set mapped tlb entry padding lists mapped different tlb entries multimergesort operates large data set size list multiple number tlb misses per element close 1 tlb padding average tlb miss per element multimergesort algorithm xiaodong zhang stefan kubricht0000011111000000111111000000111111000000111111000000111111 padding tlb data array tlb ps ps ps padding data array fig 3 padding tlb data layout modified inserting page space multiple locations k becomes approximately k tlb ts number average misses tlb set entry approximation derived figure 4 shows l2 misses tlb misses 5 mergesort algorithms simulated pentium ii simplescalar l1 4way set associative cache kbytes l2 4way associative cache 256 kbytes tlb 4way set associative cache 64 entries simulation shows multimergesort multimergesort tlb padding lowest l2 cache misses see left figure figure 4 multimergesort highest tlb misses significantly reduced tlb padding see right figure figure 4 example verifying approximation 4 tlb misses multimergesort substituting parameters pentium ii approximation per element multimergesort tlb padding close experimental result 047 right figure figure 4 show section 5 multi mergesort tlb padding significantly reduces tlb misses improves overall execution performance 33 tradeoffs instruction count increase performance gain figure 5 shows instruction counts total cycles saved percentage 5 mergesort algorithms compared base mergesort simulated pentium ii simulation shows multimergesort highest instruction count tiled mergesort lowest instruction counts taking advantage low l2 misses multimergesort significantly reducing tlb misses padding multimergesort tlb padding saved cycles 40 large data sets compared base mergesort even though relatively high instruction count also show tiledmergesort padding gain performance improvement pentium ii machine 4way set associative cache conflict misses major concerns improving memory performance sorting algorithms delta 926101k 4k 16k 64k 256k 1m 4m 8m per element data set size elements l2 misses per element base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding02061 per element data set size elements tlb misses per element base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 4 simulation comparisons l2 cache misses left figure tlb misses right figure mergesort algorithms random data set simulated pentium ii1003005007001k 4k 16k 64k 256k 1m 4m 8m instructions per element data set size elements instructions per element base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding cycles saved data set size elements cycles saved vs base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 5 simulation comparisons instruction counts left figure saved cycles percentage right figure mergesort algorithms random data set simulated pentium ii 4 cacheeffective quicksort first briefly evaluate two existing quicksort algorithms concerning merits limits including cache locality present two new quicksort alternatives memory performance improvement experimental results reported next section xiaodong zhang stefan kubricht 41 memorytuned quicksort multiquicksort lamarca ladner paper 4 present two quicksort algorithms cache optimization first one called memorytuned quicksort modification base quicksort 9 instead saving small subarrays sort end memorytuned quicksort sorts subarrays first encountered order reuse data elements cache second algorithm called multiquicksort algorithm applies single pass divide full data set multiple subarrays hoped smaller cache capacity performance gain two algorithms experiments reported 4 modest implemented two algorithms simulated machines various highend workstations obtained consistent performance also found quicksort alternatives cache optimizations highly sensitive types data sets algorithms work well unbalanced data sets 42 new quicksort alternatives practice quicksort algorithms exploit cache locality well balanced data challenge make quicksort perform well unbalanced data sets present two quicksort alternatives cache optimizations work well balanced unbalanced data sets 421 flash quicksort flashsort 6 extremely fast sorting balanced data sets maximum minimum values first identified data set identify data range data range evenly divided classes form subarrays algorithm consists three steps classification determine size class permutation move element class using single temporary variable hold replaced element straight insertion sort elements class using sedgewicks insertion sort 9 reason algorithm works well balanced data sets numbers elements stored subarrays first two steps quite similar sufficiently small fit cache capacity makes flashsort highly effective however data set balanced unbalanced amounts elements among subarrays generated causing ineffective cache usage making flashsort slow insertion sort 2 worst case compared pivoting process quicksort classification step flashsort likely generate balanced subarrays favor cache optimization hand quicksort outperforms insertion sort unbalanced subarrays taking advantages flashsort quicksort present new quicksort alternative called flash quicksort first two steps ones flashsort last step uses quicksort sort elements class 422 inplaced flash quicksort employ another cache optimization improve temporal locality flash quicksort hoping improve overall performance alternative called inplaced flash quicksort algorithm first third steps ones flash quicksort second step additional array used hold permuted elements improving memory performance sorting algorithms delta 11 original flashsort single temporary variable used hold replaced element cache line normally holds one element data structure single variable minimizes chance data reusage using additional array attempt reuse elements cache line replacement reduce instruction count copying data elements although approach increases required memory space improves cache overall performance 43 simulation results figure 6 shows instruction counts left figure l1 misses right figure memorytuned quicksort flashsort flash quicksort inplaced flash quicksort unbalanced data set simulated pentium iii faster processor 500 mhz larger l2 cache 512 kbytes pentium ii instruction count curve flashsort high presented left figure figure 6 figure shows instruction count memorytuned quicksort also began increase rapidly data set size grew contrast instruction counts flash quicksort inplaced flash quicksort little change data set size increased simulation also shows l1 misses memorytuned quicksort flashsort increased much rapidly flashsort inplaced flashsort algorithms simulation results consistent algorithm analysis show effectiveness new quicksort alternatives unbalanced data sets2006001000 instructions per element data set size elements instructions per element unbalanced data set memorytuned quicksort flashsort flash quicksort inplaced flash quicksort13571k 4k 16k 64k 256k 1m 4m per element data set size elements l1 misses per element unbalanced data set memorytuned quicksort flashsort flash quicksort inplaced flash quicksort fig 6 simulation comparisons instruction counts left figure l1 misses right figure quicksort algorithms unbalanced data set simulated pentium iii instruction count curve flashsort high presented left figure 5 measurement results performance evaluation implemented tested sorting algorithms discussed previous sections data sets described section 2 sgi o2 workstation sun ultra5 workstation pentium ii pc pentium iii pc data sizes xiaodong zhang stefan kubricht workstations sgi o2 sun ultra 5 pentium pentium processor type r10000 ultrasparciii pentium ii 400 pentium iii xeon 500 clock rate mhz 150 270 400 500 l2 cache kbytes 64 256 256 512 memory latency cycles 208 76 68 67 table 1 architectural parameters 4 machines used experiments used experiments limited memory size focus cache effective methods used lmbench 5 measure latencies memory hierarchy different levels machine architectural parameters 4 machines listed table 5 specifications l1 cache refer l1 data cache l2s uniform hit times l1 l2 main memory measured lmbench 5 units converted nanoseconds ns cpu cycles compared algorithms algorithms 4 6 execution times collected gettimeofday standard unix timing function reported time unit cycle per element cpe execution time theta clock rate execution time measured time seconds clock rate cpu speed cyclessecond machine program run n number elements data set performance results data sets quite consistent analysis since performance sorting algorithms using different data sets different machines consistent principle present performance results mergesort algorithms using random data set 4 machines plus performance results data sets ultra 5 show effectiveness tiled mergesort padding performance results quicksort algorithms using random unbalanced data sets 4 machines 51 mergesort performance comparisons compared 5 mergesort algorithms base mergesort tiled mergesort multimergesort tiled mergesort padding multimergesort tlb padding proportional machines memory capacity scaled mergesort algorithms n1k n16m elements algorithms showed effectiveness large data sets figure 7 shows comparisons cycles per element among 5 algorithms sgi o2 sun ultra 5 improving memory performance sorting algorithms delta 13 measurements o2 show multimergesort tlb padding performed best execution times reduced 55 compared base compared tiled mergesort 31 compared multi mergesort 2m elements hand tiled mergesort padding performed best ultra 5 reducing execution times 45 compared multimergesort 26 compared base mergesort 23 compared tiled mergesort 4m elements multimergesort tlb padding ultra 5 also well 35 improvement multimergesort 13 base mergesort 9 tiled mergesort 4m elements reason super performance improvement o2 comes long memory latency 208 cycles makes cache miss reduction techniques highly effective improving overall performance sorting algorithms l2 cache size sgi relatively small 64 kbytes tlb frequently used memory accesses thus tlb padding effective addition l1 l2 caches 2way associative data cache padding effective padding directmapped cache contrast ultra 5s l1 cache direct mapped l2 4 times larger o2 thus data cache padding effective tlb padding order show effectiveness tiledmergesort padding lowassociativity cache system sun ultra 5 plot performance curves 5 mergesort algorithms using 8 data sets ultra 5 appendix experiments show tiledmergesort padding consistently significantly outperforms mergesort algorithms ultra 5 example tiled mergesort padding achieved 70 68 54 execution time reductions zero data set compared base mergesort tiled mergesort multimergesort respectively using data sets also show tiled mergesort padding achieved 24 53 execution time reductions compared base mergesort 23 52 reductions compared tiled mergesort 23 44 reductions compared multimergesort figure 8 shows comparisons cycles per element among 5 mergesort algorithms pentium ii 400 pentium iii 500 measurements machines show multimergesort tlb padding performed best reducing execution times 41 compared multimergesort 40 compared base mergesort 26 compared tiled sort 16m elements l1 l2 caches machines 4way set associative thus issue data cache conflict misses concern discussed section 31 since tlb misses degraded performance multimergesort algorithm padding tlb becomes effective improving performance summary tiled mergesort padding machines directmapped caches highly effective reducing conflict misses multimergesort padding performs well machines 52 quicksort performance comparisons used random data set unbalanced data set test quicksort algorithms 4 machines 4 quicksort algorithms memorytuned quicksort flashsort flash quicksort inplaced flash quicksort 14 delta li xiao xiaodong zhang stefan kubricht200600100014001k 4k 16k 64k 256k 1m cycles per element data set size elements mergesorts o2 random data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 random data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 7 execution comparisons mergesort algorithms sgi o2 sun ultra 5200600100014001k 4k 16k 64k 256k 1m 4m 16m cycles per element data set size elements mergesorts pentium ii 400 random data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding200600100014001k 4k 16k 64k 256k 1m 4m 16m cycles per element data set size elements mergesorts pentium iii 500 random data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 8 execution comparisons mergesort algorithms pentium ii pentium iii figure 9 shows comparisons cycles per element among 4 mergesort algorithms random data set left figure unbalanced data set right figure sgi o2 machine performance results 4 mergesort algorithms using random data set comparable memorytuned algorithm slightly outperformed others contrast performance results using unbalanced data set significantly different expected execution times flash quicksort inplaced flash quicksort stable memorytuned quicksort flashsort performed much worse data set sizes increased timing curves flashsort even high presented right figure figure 9 figure shows comparisons cycles per element among 4 mergesort improving memory performance sorting algorithms delta 1520060010001400 cycles per element data set size elements quicksorts o2 random data set memorytuned quicksort flash quicksort inplaced flash quicksort20060010001400 cycles per element data set size elements quicksorts o2 unbalanced data set memorytuned quicksort flash quicksort inplaced flash quicksort fig 9 execution comparisons quicksort algorithms random data set left figure unbalanced data set right figure sgi o2 timing curve flashsort high presented right figure algorithms random data set left figure unbalanced data set right figure sun ultra 5 machine ultra 5 4 algorithms showed little difference execution times flash quicksort inplaced flash quicksort show strong effectiveness unbalanced data set example data set increased 128k elements execution time flashsort 10 times higher three algorithms curve high plotted figure data set increased 4m elements execution time memorytuned quicksort 3 times higher flash quicksort inplaced flash quicksort execution time flashsort 100 times higher others figure 11 figure 12 show comparisons cycles per element among 4 mergesort algorithms random data set left figure unbalanced data set right figure pentium ii pentium iii machine respec tively measurements pentiums random data set showed flashsort flash quicksort inplaced flashsort similar execution performance reduced execution times around 20 compared memory tuned quicksort flash quicksort inplaced flash quicksort significantly outperformed memoryturned quicksort algorithm unbalanced data sets two pentium machines 6 prediction model performance tradeoffs essential issue considered sorting algorithms design algorithms design memory optimization tradeoff optimization achievementthe reduction cache misses optimization effortthe increment instruction count optimization objective improve overall performanceto reduce execution time base algorithm tradeoff objective quantitatively predicted execution timing model xiaodong zhang stefan kubricht20060010001400 cycles per element data set size elements quicksorts ultra 5 random data set memorytuned quicksort flash quicksort inplaced flash quicksort20060010001400 cycles per element data set size elements quicksorts ultra 5 unbalanced data set memorytuned quicksort flash quicksort inplaced flash quicksort fig 10 execution comparisons quicksort algorithms random data set left figure unbalanced data set right figure ultra 5 timing curve flashsort high presented right figure20060010001400 cycles per element data set size elements quicksorts pentium ii 400 random data set memorytuned quicksort flash quicksort inplaced flash quicksort20060010001400 cycles per element data set size elements quicksorts pentium ii 400 unbalanced data set memorytuned quicksort flash quicksort inplaced flash quicksort fig 11 execution comparisons quicksort algorithms random data set left figure unbalanced data set pentium ii timing curve flashsort high presented right figure execution time algorithm computer system based amdahls law 3 expressed ca theta mr theta mp 5 ic instruction count algorithm cp number cycles per instruction cpu algorithm ca number cache accesses algorithm execution mr cache miss rate algorithm improving memory performance sorting algorithms delta 1720060010001400 cycles per element data set size elements quicksorts pentium iii 500 random data set memorytuned quicksort flash quicksort inplaced flash quicksort20060010001400 cycles per element data set size elements quicksorts pentium iii 500 unbalanced data set memorytuned quicksort flash quicksort inplaced flash quicksort fig 12 execution comparisons quicksort algorithms random data set left figure unbalanced data set pentium iii timing curve flashsort high presented right figure execution mp miss penalty cycles system execution time base algorithm base expressed base theta cp base theta mr base theta mp 6 execution time optimized algorithm opt expressed ic base ic opt instruction counts base algorithm optimized algorithm ca base ca opt numbers cache accesses base algorithm optimized algorithm mr base mr opt cache miss rates base algorithm optimized algorithm respectively optimized algorithms tiled mergesort tiled mergesort padding numbers cache accesses kept almost base algorithm type algorithms combine equations 6 7 predict execution time reduction rate optimized algorithm follows base base theta cp base theta mr base theta mp deltam represents miss rate reduction deltai base represents instruction count increment order obtain positive execution time reduction rate must model describes quantitative tradeoff instruction count increase miss rate reduction gives condition optimized algo xiaodong zhang stefan kubricht rithm improve performance base algorithm follows deltai c deltam r ca theta mp multiphase optimized algorithms different cache access patterns phase multimergesort multimergesort tlb padding combine equations 6 7 ca base 6 ca opt obtain condition optimized algorithm improve performance base algorithm follows deltai c deltam r theta ca mp deltam r theta base theta ca base gamma mr opt theta ca opt architecture related algorithm related parameters prediction model architecture related parameters cp mp machine dependent easily obtained algorithm related parameters ic ca mr either predicted algorithm analysis obtained running program simulated architecture simplescalar algorithm related parameters also predicted running algorithms relatively small data sets oversize cache capacity target machine using prediction model parameters simplescalar simulation able predict execution time reduction rate optimized algorithms study shows predicted results using model close measurement results 68 error rate 7 conclusion examined developed cacheeffective algorithms mergesort quicksort algorithms tested 4 representative processors products dating 1995 1999 show effectiveness simulations provide insightful performance evaluation show mergesort algorithms architecture dependent quicksort algorithms data set dependent techniques padding partitioning also used algorithms cache optimizations machine dependent architecture parameters implementing 4 methods presented paper cache size c cache line size l cache associativity k number entries tlb cache memory page size p parameters becoming commonly known users parameters also defined variables programs adaptively changed users machine machine therefore programs easily portable among different workstations acknowledgments many students advanced computer architecture class offerred spring 1999 participated discussions cacheeffective sorting algorithms imple mentations particularly arun mangalam made initial suggestion combine quicksort flashsort also appreciate alma riska zhao zhang zhichun zhu comments work helps simulations improving memory performance sorting algorithms delta 19 8 cycles per element data set size elements mergesorts ultra 5 equilikely data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 bernoulli data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 13 execution comparisons mergesort algorithms sun ultra 5 using equilikely data set left figure bernoulli data set right set50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 geometric data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 pascal data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 14 execution comparisons mergesort algorithms sun ultra 5 using geometric data set left figure pascal data set right set xiaodong zhang stefan kubricht50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 binomial data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 poisson data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 15 execution comparisons mergesort algorithms sun ultra 5 using binomial data set left figure poisson data set right set50015001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 unbalanced data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding500150025001k 4k 16k 64k 256k 1m 4m cycles per element data set size elements mergesorts ultra 5 zero data set base mergesort tiled mergesort tiled mergesort padding multimergesort multimergesort tlb padding fig 16 execution comparisons mergesort algorithms sun ultra 5 using unbalanced data set left figure zero data set right set r simplescalar tool set avoiding conflict misses dynamically large directmapped caches computer architecture quantitative approach influence caches performance sorting portable tools performance analysis flashsort1 algorithm first course data transformations eliminating conflict misses implementing quicksort programs cacheminer runtime approach exploit cache locality smp cacheoptimal methods bitreversals tr atom avoiding conflict misses dynamically large directmapped caches influence caches performance sorting cacheoptimal methods bitreversals cacheminer implementing quicksort programs ctr chen ding yutao zhong compilerdirected runtime monitoring program data access acm sigplan notices v38 n2 supplement p112 february ranjan sinha justin zobel using random sampling build approximate tries efficient string sorting journal experimental algorithmics jea 10 2005 ranjan sinha justin zobel cacheconscious sorting large sets strings dynamic tries journal experimental algorithmics jea v9 nes 2004 protecting rfid communications supply chains proceedings 2nd acm symposium information computer communications security march 2022 2007 singapore ranjan sinha justin zobel david ring cacheefficient string sorting using copying journal experimental algorithmics jea 11 2006 gayathri venkataraman sartaj sahni srabani mukhopadhyaya blocked allpairs shortestpaths algorithm journal experimental algorithmics jea 8 song jiang xiaodong zhang tokenordered lru effective page replacement policy implementation linux systems performance evaluation v60 n14 p529 may 2005 allocations jobs known unknown memory demands ieee transactions parallel distributed systems v13 n3 p223240 march 2002 james fix setassociative cache performance search trees proceedings fourteenth annual acmsiam symposium discrete algorithms january 1214 2003 baltimore maryland bernard e moret tandy warnow reconstructing optimal phylogenetic trees challenge experimental algorithmics experimental algorithmics algorithm design robust efficient software springerverlag new york inc new york ny 2002 bernard e moret david bader tandy warnow highperformance algorithm engineering computational phylogenetics journal supercomputing v22 n1 p99111 may 2002 gerth stlting brodal rolf fagerberg kristoffer vinther engineering cacheoblivious sorting algorithm journal experimental algorithmics jea 12 2007