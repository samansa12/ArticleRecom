efficient costeffective techniques browsing indexing large video databases present paper fully automatic contentbased approach organizing indexing video data methodology involves three steps step 1 segment video shots using cameratracking technique process also extracts feature vector shot consists two statistical variances varba varoa values capture much things changing background foreground areas video shot step 2 video apply fully automatic method build browsing hierarchy using shots identified step 1 step 3 using varba varoa values obtained step 1 build index table support variancebased video similarity model video scenesshots retrieved based given values varba varoa three interrelated techniques offer integrated framework modeling browsing searching large video databases experimental results indicate many advantages existing methods b introduction rapid advances data compression networking technology video become inseparable part many important applications digital libraries distance learning public information systems electronic commerce movies demand name proliferation video data led research partially supported national science foundation grant ani9714591 significant body research techniques video database management systems vdbmss 1 general organizing managing video data much complex managing text numbers due enormous size video files semantically rich contents particular contentbased browsing contentbased indexing techniques essential possible users browse video materials nonsequential manner retrieve relevant video data efficiently based contents conventional ie relational database management system tuple basic structural element retrieval well data entry case vdbmss video applications video clips convenient units data entry however since entire video stream coarse level ab straction generally beneficial store video sequence shots facilitate information retrieval requirement calls techniques segment videos shots defined collection frames recorded single camera operation process referred shot boundary detection sbd existing sbd techniques require many input parameters hard determine significant influence quality result recent study 2 found techniques using color histograms 3 4 5 6 need least three threshold values accuracy varies 20 80 depending values least six different threshold values necessary another technique using edge change ratio 7 values must chosen properly get satisfactory results 2 general picking right values thresholds difficult task vary greatly video video observations indicate todays automatic sbd techniques need reliable used practice perspective end user dbms good data manages bad video shot returned query result would contain incomplete andor extra irrelevant information problem facing todays vdbmss address issue propose detect shot boundaries direct way tracking camera motion background areas video discuss idea detail later major role dbms allow user deal data abstract terms rather form computer stores data although shot serves well basic unit video abstraction recognized many applications scene sometimes better unit convey semantic meaning video viewers support fact several techniques proposed merge semantically related temporally adjacent shots scene 8 9 10 11 similarly also highly desirable complete hierarchy video content allow user browse retrieve video information various semantic levels multilayer abstraction makes convenient reference video information easier comprehend content also simplifies video indexing storage organization one technique presented 12 scheme abstracts video stream structure compound unit sequence scene shot hierarchy authors define scene set shots related time space scenes together give meaning grouped sequence related sequences assembled compound unit arbitrary level multilevel structures considered 13 14 15 16 17 studies however focus modeling issues attempt design best hierarchical structure video representation however provide techniques automate construction structures addressing limitation essential handling large video databases one attempt presented 18 scheme divides video stream multiple segments containing equal number consecutive shots segment divided subsegments process repeated several times construct hierarchy video content drawback approach time considered visual content used constructing browsing hierarchy contrast video content considered 19 20 21 methods first construct priori model particular application domain model specifies scene boundary characteristics based video stream abstracted structured representation theoretical framework approach proposed 19 successfully implemented applications news videos 20 tv soccer programs 21 disadvantage techniques rely explicit models sense application models rather database models two techniques employ models presented 11 22 schemes however focus lowlevel scene construction instance given shots groups scenes structural units video 4level videoscenegroup shot hierarchy used videos 22 paper fix height browsing hierarchy called scene tree order support variety videos shape size scene tree determined semantic complexity video scheme based content video experiments indicate proposed method produce high quality browsing structures make browsing efficient also introduce paper variancebased video similarity model using model build contentbased indexing mechanism serve assistant advise users appropriate scene trees start browsing environment video shot characterized follows compute average colors foreground background areas frames shot calculate statistical variance values values capture much things changing video shot information used build index search video data user write query describe impression degree changes primary video segment experiments indicate simple query model effective supporting browsing environment discuss technique detail summary present paper fully automatic contentbased technique organizing indexing video data contributions follows 1 address reliability problem facing todays video data segmentation techniques introducing cameratracking method 2 fully automate construction browsing hierarchies method general purpose suitable videos 3 provide contentbased indexing mechanism make browsing efficient three techniques interrelated offer integrated framework modeling browsing searching large video databases remainder paper organized follows present sbd technique 23 discuss extensions required support browsing indexing mechanisms section 2 procedure building scene trees described details section 3 section 4 discuss contentbased indexing technique video browsing experimental results examined section 5 finally give concluding remarks section 6 tracking technique sbd extension make paper selfcontained first describe sbd technique 23 extend include new features required browsing indexing techniques 21 camera tracking approach shot boundary detection r c motion b figure 1 background area since shot made one camera operation tracking camera motion direct way identify shot boundaries achieved tracking background areas video frames follows define fixed background area frames illustrated lightly shaded areas figure 1a rationale u shape fba follows ffl bottom part frame usually part objects ffl top bar cover horizontal camera motion ffl two columns cover vertical camera motion ffl combination top bar left column track camera motion one diagonal direction diagonal direction covered combination top bar right column two properties illustrated figure 1b properties suggest detect shot boundary determining two consecutive frames share part fbas requires comparing part one fba every part fba make comparison efficient rotate two vertical columns u shape fba outward form transformed background area tba illustrated figure 2 tba twodimensional array pixels compute signature sign applying modified version image reduction technique called gaussian pyramid 24 idea gaussian pyramid originally introduced reducing image smaller size use technique reduce twodimensional tba single line pixels called signature eventually single pixel called sign complexity procedure o2 logm1 actually om number pixels involved interested reader referred 23 details illustrate procedure figure 3 shows 13 theta 5 tba reduced multiple steps first five pixels column reduced one pixel give one line 13 pixels used signature signature reduced sign denoted sign ba superscript subscript indicate sign background area frame note rather small tba illustrative discuss determine tba shortly tba figure 2 shape transformation fba signature sign tba figure 3 computation signature sign use signs signatures detect shot boundaries illustrated figure 4 first two stages quickanddirty tests used quickly eliminate easy cases two tests fail need track background stage 3 shifting two signatures two frames test toward one pixel time shift compare overlapping pixels determine longest run matching pixels running maximum maintained matching scores end maximum value indicates much two images share common background score larger certain threshold two video frames determined shot sign matching sign sign i1 pixel matching background tracking signature signature cut cut stage 1 stage 2 stage 3 figure 4 shot boundary detection procedure 22 extension camera tracking technique define fixed object area foa foreground area video frame primary objects appear area illustrated figure 1 darkly shaded region video frame facilitate indexing scheme need reduce foa frame one pixel want compute sign sign oa superscript indicates sign foa parameter obtained using gaussian pyramid sign ba computation requires dimensions foa given r c dimensions video frame see figure 1 discuss procedure determining dimensions tba foa follows let dimensions foa h b tba w l illustrated figure 1 first estimate parameters h 0 b 0 w 0 l 0 respectively choose w 0 10 width video frame ie w xi cpi value determined empirically using video clips show value w 0 results tbas foas cover background foreground areas respectively well using w 0 compute estimates follows b order apply gaussian pyramid technique dimensions tba foa must size set f1 5 13 29 61 125 g due fact technique reduces five pixels one pixel 13 pixels five 29 pixels 13 general jth element j size set computed follows using size set proper value w value size set nearest w 0 nearest number determined follows first compute log substituting value j equation 1 gives us desired value w similarly compute l h b approximation scheme illustrated table 1 example let 16 corresponding j value 3 substituting j equation 1 gives us 13 proper value w h b w l nearest value 21 22 44 45 46 9229h b w l529 table 1 approximate dimensions using nearest value size set section described computation two sign values sign ba sign oa procedure determine video shots next two sections discuss shots signs used build browsing hierarchies index structures video databases building scene trees nonlinear browsing video data often accessed exploring browsing mode browsing video using vcr like functions ie fastforward fastreverse 25 however tedious time consuming hierarchical abstraction allowing nonlinear browsing desirable todays techniques automatic construction structures however many limitations rely explicit models focus construction lowlevel scenes ignore content video discuss section scene tree approach addresses drawbacks order automate tree construction process base approach visual content video instead human perception first obtain video shots using cameratracking sbd method discussed last section group adjacent shots related ie sharing similar backgrounds scene similarly scenes related shots considered related assembled higherlevel scene arbitrary level discuss details strategy give example following subsections 31 scene tree construction algorithm let b two shots jaj jbj frames respectively algorithm determine related follows 1 2 compute difference sign ba shot sign ba j shot b using following equation use number 256 since rgb space red green blue colors range 0 255 difference sign ba theta 100 2 3 less 10 stop return two shots related otherwise go next step 4 set ffl jaj stop return two shots related otherwise set j 5 go step 2 convenience refer algorithm relationship used following procedure construct browsing hierarchy called scene tree follows 1 scene node sn 0 lowest level ie level 0 scene tree created shoti subscript indicates shot scene scene node derived superscript denotes level scene node scene tree 2 set 3 3 apply algorithm relationship compare shoti shots shoti2 delta delta delta shot1 descending order sequence comparisons stops related shot say shotj identified related shot found create new empty node connect parent node sn 0 proceed step 5 4 consider sn three scenarios happen ffl sn 0 j currently parent node connect scene nodes sn 0 j new empty node parent node ffl sn 0 share ancestor node connect sn 0 ancestor node ffl sn 0 j currently share ancestor node connect sn 0 current oldest ancestor sn 0 connect current oldest ancestors sn 0 j new empty node parent node 5 shots set go step 3 otherwise connect nodes currently without parent new empty node parent 6 scene node bottom scene tree select corresponding shot repetitive frame representative frame ie frame shares sign number frames shot traverse nodes scene tree level level starting bottom empty node visited identify child node say sn c contains shotm longest sequence frames sign ba value rename empty node sn c1 assign representative frame sn c sn c1 note scene node contains representative frame pointer frame future use browsing navigating criterion selecting representative frame shot find frequent image one image found choose temporally earliest one ex ample let us assume shot5 20 frames sign ba value frame shown table 2 since sign ba actually pixel three numerical values three colors red green blue case use frame 1 representative frame shot5 frame corresponds image longest sequence frames sign ba values ie 219 152 142 although sequence corresponding frames 15 20 also sequence length frame 15 selected appears later shot instead one representative frame per scene also use gs repetitive representative frames scenes shots better convey larger content g function frames sign red green blue 3 219 152 142 4 219 152 142 5 219 152 142 6 219 152 142 7 226 164 172 8 226 164 172 9 213 149 134 table 2 frames shot5 us evaluate complexity two algorithms complexity relationship ojaj theta jbj average computation cost however much less algorithm stops soon finds two related scenes furthermore similarity computation based one pixel ie sign ba video frame making algorithm efficient cost tree construction algorithm derived follows step 3 done 2 theta n f number frames n number shots given video algorithm visits every shot whenever shot visited compared every frame shots step 4 step 6 need traverse tree done ologn therefore whole algorithm completed 2 theta n 32 example explain scene tree shot 1 find relation b b1 related related related d1d2 related b figure 5 video clip ten shots scene tree construction algorithm best illustrated example let us consider video clip ten scenes shown figure 5 convenience label related shots prefix instance shot1 shot3 shot6 related labeled a1 a2 respectively effective algorithm group shots longer unit higher level browsing hierarchy using video clip illustrate tree construction algorithm figure 6 details discussed shot b c sn 8shot shot shot shot shot shot figure building figure first create three scene nodes 2 sn 0 3 shot1 shot2 shot3 respectively applying algorithm relationship shot3 shot1 determine two shots related since related neither currently parent node connect new empty node called en1 according algorithm need compare shot2 shot3 however shot2 connected shot2 two related nodes shot3 shot1 figure applying algorithm relationship shot4 shot2 determine related allows us skip comparison shot4 shot1 case since sn 0and sn 0 3 share ancestor ie en1 also connect shot4 en1 figure comparing shot5 shot3 shot2 shot1 using relationship determine shot5 related three shots thus create sn 0 5 shot5 connect new empty node en2 figure 6d case shot6 determined related shot3 since sn 0 5 sn 0 currently ancestor first connect sn 0to en2 connect en1 en2 new empty node en3 parent node figure 6e case shot7 determined related shot5 since sn 0 7 sn 0 5 share ancestor node en2 simply create sn 0 7 shot7 connect scene node en2 figure case similar case figure 6c shot8 related previous shots create new scene node sn 0 8 shot8 connect scene node new empty node en4 figure shot9 shot10 found related immediate previous node shot8 shot9 respectively case according algorithm shot9 shot10 connected en4 since shot10 last shot video clip create root node connect nodes currently parent node root node need name empty nodes en1 named sn 1 shot1 contains image repeated frequently among images first four level0 scenes superscript 1 indicates 1 scene node level 1 another example en3 named sn 2 shot1 contains image repeated frequently among images first seven level0 scenes superscript 2 indicates sn 2 1 scene node level 2 similarly determine names scene nodes note naming process important determines proper representative frame scene node eg sn 1 7 indicates scene node use representative frame shot7 section 5 show example scene tree built real video clip 4 costeffective indexing section first discuss sign ba sign oa generated sbd technique used characterize video data present video similarity model based two parameters 41 simple feature vector video data illustrate concept techniques use example video clip figure 5 10 shots video clip let us assume sbd technique generates values sign ba sign oa frames shown 4th 5th columns table 3 respectively 6th shots start frame sign ba100170415495550 end frame sign oa var ba var oa76141351416496 oa sign 75 oa var ba var oa ba sign 100 oa sign 100 oa sign 101 ba sign 140 ba sign 101 oa sign 140 oa ba sign 170 ba sign 141 oa sign 170 oa ba sign 290 ba sign 171 oa sign 290 oa sign 191 ba sign 350 ba sign 191 oa sign 350 oa ba sign 415 ba sign 351 oa sign 415 oa sign 416 ba sign 495 ba sign 416 oa sign 495 oa sign 496 ba sign 550 ba sign 496 ba sign 550 ba ba sign 625 ba sign 551 oa sign 625 oa oa oa ba var b1 oa oa ba var a2 oa ba var c1 oa ba var oa oa oa table 3 results shot boundary detection 7th columns table 3 called ar ba ar oa respectively computed using following equations ar ba k l first last frames ith shot respectively sign ba mean value signs computed follows sign ba similarly compute v ar oa follows ar oa sign oa note v ar ba v ar oa statistical variances sign ba sign oa respectively within shot variance values measure degree changes content background object area shot following properties ar ba zero obviously means change sign ba words background fixed shot ar oa zero means change sign oa words change object area ffl either value zero changes background object area larger variance indicates higher degree changes respective area thus v ar ba v ar oa capture spatiotemporal semantics video shot use characterize video shot much like average color color distribution etc used characterize images based discussions may asked two values v ar ba v ar oa enough capture various contents diverse kinds videos answer concern note videos digital library typically classified genre form 133 genres 35 forms listed 26 genres include adaptation adventure biographical com ern etc examples 35 forms anima series classify video appropriate genres forms selected list examples movie brave heart classified adventure biographical feature dr zhivago classified adaptation historical romance feature total least 4655 133 theta 35 possible categories videos assume video retrieval performed within one 4655 classes indexing scheme using v ar ba v ar oa enough characterize contents shot show experimental results next section substantiate claim unlike methods extract keywords key frames videos method extracts v ar ba ar oa indexing retrieval advantage approach fully automated fur thermore reliance domain knowledge 42 video similarity model facilitate video retrieval build index table shown table 4 shows index information relevant two video clips simon birch wag dog convenience denote last column ar ar oa f 6 117 153 3423 1781 1642 9 200 205 1310 1397 088 7 90 96 281 3507 3226 9 104 116 188 1723 1535 simon birch b wag dog search relevant shots user expresses impression much things changing background object areas specifying v ar ba v ar oa q values respectively response system computes v ar ba ar oa q return id shot satisfies following conditions v ar ba ar ba ar ba q since impression expressed query approximate ff fi used similarity computation allow degree tolerance matching video data system set 10 note another common way handle inexact queries matching quantized data general answer query shots instead system return largest scenes share representative frame one matching shots using information user browse appropriate scene trees starting suggested scene nodes search specific scenes lower levels hierarchies sense indexing mechanism makes browsing efficient 5 experimental results experiments designed assess following performance issues ffl camera tracking technique effective sbd ffl algorithm presented section 3 builds reliable scene trees ffl variance values v ar ba v ar oa make good feature vector video data discuss performance results following subsections 51 performance shot boundary detection technique two parameters recall precision commonly used evaluate effectiveness ir information retrieval techniques 27 also use metrics study follows ffl recall ratio number shot changes detected correctly actual number shot changes given video clip ffl precision ratio number shot changes detected correctly total number shot changes detected correctly incorrectly previous study 23 demonstrated camera tracking technique significantly accurate traditional methods based color histograms edge change ratios current study reevaluate technique using many video clips video clips originally digitized avi format framessecond resolution type news commercials name duration minsec shot changes scooby dog show cartoon friends sitcom movies chicago hope drama sports events star trekdeep space nine programs silk stalkings drama documentaries music videos children soap opera kobe bryant flinstone cartoon jerry springer talk show national nbc brave heart atf simon birch tennis 1999 us open mountain bike race football todays vietnam mankind alabama song wag dog recall h p 087096089090085075081084089 094 090 095 093 094 091 095 093 091 090 table 5 test video clips detection results shot changes 160 theta 120 pixels reduce computation time made test video clips extracting frames originals rate 3 framessecond design test video set studied videos used 28 7 9 10 29 30 2 created set 22 video clips represent six different categories shown table 5 total test set lasts 4 hours 30 minutes complete test sets used 28 7 9 10 29 30 2 details test video set shot boundary detection results given table 5 observe recalls precisions consistent obtained previous study 23 52 effectiveness scene tree study run algorithms section 3 build scene tree various videos assess effectiveness algorithms inspected video evaluated structure corresponding tree representative frames since difficult quantify quality scene trees show one representative tree figure 7 scene tree built oneminute segment test video clip friends story follows two women one man conversation restaurant two men come join travel scene tree level 3 level 1 therefore browsing video nonlinearly get story note representative frames serve well summary important events underlying video 53 effectiveness v ar ba v ar qa demonstrate v ar ba v ar qa indeed capture semantics video data select arbitrary shots data set shots compute v ar ba v ar qa use retrieve similar shots data set two parameters indeed good feature values shots returned resemble characteristics shot used retrieval show experimental results figure 8 figure 9 figure 10 figures upper leftmost picture representative frame video short selected arbitrarily retrieval experiment remaining pictures representative frames matching shots label picture indicates shot video clip representative frame belongs instance 12w represents representative frame 12th shot wag dog due space limitation show three similar shots case discussed figure 8 shot 12w wag dog shot closeup person talking v ar ba 12 shot 586 1737 respectively seen table 4b shot 102 wag dog shots 64 154 simon birch retrieved presented figure 8 results quite impressive four shots show closeup view talking person figure 9 shot 33w wag dog content shows two people talking distance v ar ba 33 shot 146 937 respectively seen table 4b shot 11 wag dog shots 93 108 simon birch retrieved presented figure 9 four shots similar content show two people talking distance figure 10 shot 76s simon birch content person running kitchen window v 76 v ar ba 76 shot 078 2355 respectively seen table 4a shot 87 wag dog shots 1 4 simon birch retrieved presented figure 9 two people riding bike shot 1s shot 4w one person running woods shot 87 one person picking book book shelf walking living room shots similar show single moving object changing background figure 7 scene tree friends figure 8 shots similar index values set 1 figure 9 shots similar index values set 2 figure 10 shots similar index values set 3 6 concluding remarks presented paper fully automatic contentbased approach organizing indexing video data three steps methodology cameratracking shot boundary detection technique used segment video basic units called shots step also computes feature vector shot consists two variances v ar ba v ar oa two values capture much things changing background foreground areas shot ffl step 2 video fully automatic method applied shots identified step 1 build browsing hierarchy called scene tree ffl step 3 using v ar ba v ar oa values obtained step 1 index table built support variancebased video similarity model video scenesshots retrieved based given values v ar ba v ar oa actually variancebased similarity model used directly retrieve video scenesshots rather used determine relevant scene nodes information user start browsing nodes look specific scenesshots lower level hierarchy comparing proposed techniques existing methods draw following conclusions ffl cameratracking technique fundamentally different traditional methods based pixel comparison since scheme designed around definition shots offers unprecedented accuracy ffl unlike existing schemes building browsing hier archies limited lowlevel entities ie scenes rely explicit models consider video content technique builds scene tree automatically visual content video size shape browsing structure reflect semantic complexity video clip ffl video retrieval techniques based keywords ex pensive usually application dependent biased problems remain even dialog extracted video using speech recognition methods 31 indexing techniques based spatiotemporal contents available however rely complex image processing techniques therefore expensive variancebased similarity model offers simple inexpensive approach achieve comparable performance uniquely suitable large video databases currently investigating extensions variancebased similarity model make comparison discriminating also studying techniques speed video data segmentation process r video database systems issues comparison automatic shot boundary detection algorithms automating creation digital vidoe library moca workbench support creativity movie content analysis visual search system video image databases featurebased algorithm detecting classifying scene breaks knowledgebased macrosegmentation video sequences shot classification method selecting effective keyframe video browsing extracting story units long programs video browsing navigation clustering methods video browsing annotation modeling querying video data cinematic primitives multimedia object composition playback models handling multimedia data knowledge guided parsing video databases developing power tools video indexing retrieval image indexing retrieval based color histogram constructing tableofcont videos contentbased scene change detection classification technique using background tracking laplacian pyramid compact image code 2psm efficient framework searching video information limitedbandwidth environment moving image genreform guide information retrieval data structures algorithms digital video segmentation videoq automated content based video search system using visual cues exploring video structure beyond shots lessons learned building terabyte digital video library tr information retrieval object composition playback models handling multimedia data digital video segmentation featurebased algorithm detecting classifying scene breaks automating creation digital video library shot classification method selecting effective keyframes video browsing conivas knowledgebased macrosegmentation video sequences lessons learned building terabyte digital video library wvtdba semantic contentbased video database system world wide web modelling querying video data constructing tableofcontent videos visual search system video image databases exploring video structure beyond shots ctr kien hua junghwan oh detecting video shot boundaries 16 times faster poster session proceedings eighth acm international conference multimedia p385387 october 2000 marina del rey california united states junghwan oh maruthi thenneru ning jiang hierarchical video indexing based changes camera object motions proceedings acm symposium applied computing march 0912 2003 melbourne florida zaher aghbari kunihiko kaneko akifumi makinouchi topological mapping dimensionality reduction method efficient video search proceedings 2002 acm symposium applied computing march 1114 2002 madrid spain haoran yi deepu rajan liangtien chia motion based scene tree browsing retrieval compressed videos proceedings 2nd acm international workshop multimedia databases november 1313 2004 washington dc usa mohamed abid michel paindavoine realtime shot cut detector hardware implementation computer standards interfaces v29 n3 p335342 march 2007 jeongkyu lee junghwan oh sae hwang scenario based dynamic video abstractions using graph matching proceedings 13th annual acm international conference multimedia november 0611 2005 hilton singapore aya anerwolf john r kender video summaries crossreferencing mosaicbased representation computer vision image understanding v95 n2 p201237 august 2004 haoran yi deepu rajan liangtien chia motionbased scene tree browsing retrieval compressed videos information systems v31 n7 p638658 november 2006 yulung lo wenling lee linhuang chang true suffix tree approach discovering nontrivial repeating patterns music object multimedia tools applications v37 n2 p169187 april 2008