evaluating novelty textmined rules using lexical knowledge paper present new method estimating novelty rules discovered datamining methods using wordnet lexical knowledgebase english words assess novelty rule average semantic distance knowledge hierarchy words antecedent consequent rule average distance novelty rule novelty rules extracted discotex textmining system amazoncom book descriptions evaluated human subjects algorithm computing correlation coefficients pairs human ratings human automatic ratings found automatic scoring rules based novelty measure correlates human judgments well human judgments correlate one another text mining b introduction datamining system may discover large body rules however relatively may convey useful new knowledge user several metrics evaluating interestingness mined rules proposed ba99 hk01 metrics used lter large percentage less interesting rules thus yielding manageable number higher quality rules presented user however measure simplicity eg rule size certainty eg condence utility eg support another important aspect interestingness novelty rule represent association currently unknown example textmining system developed discovers rules computerscience job announcements posted local newsgroup nm00 induced rule sql database knowledgeable computer scientist may nd rule uninteresting conveys known association evaluating novelty rule requires comparing existing body knowledge user assumed already possess text mining hea99 fel99 mla00 rules consist words natural language relevant body common knowledge basic lexical semantics ie meanings words semantic relationships number lexical knowledge bases available wordnet fel98 semantic network 130000 english words linked 100000 lexical senses synsets interconnected relations antonym generalization hypernym partof holonym present evaluate method measuring novelty textmined rules using lexical knowledge dene measure semantic distance dw words based length shortest path connecting w w j wordnet novelty rule dened average value dw pairs words w antecedent w j consequent rule intuitively semantic dissimilarity terms rules antecedent consequent indication rules novelty example beer diapers would considered novel beer pretzels since beer pretzels food products therefore closer wordnet present experimental evaluation novelty metric applying rules mined book descriptions extracted amazoncom since novelty fundamentally subjective compared metric human judgments developed webbased tool allows human subjects enter estimates novelty rules asked multiple human subjects score random selections mined rules compared results obtained applying metric rules found average correlation scoring algorithm human users using raw score correlation pearsons metric rank correlation spearmans metric comparable average score correlation human users suggests algorithm rule scoring judgment similar human users background 21 text mining traditional data mining algorithms generally applied structured databases text mining algorithms try discover knowledge unstructured semistructured textual data eg webpages text mining relatively new research area intersection natural language processing machine learning information retrieval various new useful techniques developed researchers discovering knowledge large text corpora appropriately integrating methods dierent disciplines discotex nm00 one system discovers prediction rules natural language corpora using combination information extraction data mining learns information extraction system transform text structured data structured data mined interesting relationships experiments used rules mined discotex book descriptions extracted amazoncom science romance literature categories discotex rst extracts structured template amazoncom book description webpages constructs template book description predened slots eg title author subject etc lled words extracted text discotex uses rule mining technique extract prediction rules template database example extracted rule shown figure 1 slot predicted slots purpose use ller words slot ignoring slotnames algorithm rule figure 1 would used form daring love woman romance historical ction story read wonderful daring love woman romance historical fiction story read wonderful figure 1 discotex rule mined amazoncom romance book descriptions 22 wordnet wordnet fel98 online lexical knowledgebase 130000 english words developed princeton university wordnet english nouns adjectives verbs adverbs organized synonym sets synsets representing underlying lexical concept synset contains words similar meaning pertaining common semantic concept since word dierent meanings dierent contexts word present multiple synsets synset contains associated pointers representing relation synsets wordnet supports many pointer types eg antonyms synonyms etc pointer types used algorithm explained 1 synonym pointer implicit since words synset synonymous eg life existence synonym synset 2 antonym pointer type refers another synset quite opposite meaning given synset eg front antonym back 3 attribute pointer type refers another synset implicated synset eg benevolence attribute good 4 pertainym pointer refers relation noun adjective adjective noun adverb adjective indicating morphological relation eg alphabetical pertainym alphabet 5 similar pointers refers another adjective close terms meaning current adjective although enough part synset eg unquestioning similar absolute 6 cause pointer type refers cause eect relation eg kill cause die 7 entailment pointer refers implication another action eg breathe entailment inhale 8 holonym pointer refers part partwhole relation eg chapter holonym text three kinds holonyms member substance part 9 meronym pointer refers whole partwhole relation eg computer meronym cpu three kinds meronyms member substance part 10 hyponym pointer refers specication concept eg fungus hyponym plant 11 hypernym pointer refers generalization concept eg fruit hypernym apple 23 semantic similarity words several measures semantic similarity based distance words wordnet used dierent researchers leacock chodorow lc98 used negative logarithm normalized shortest path length measure similarity two words path length measured number nodes path two words normalizing factor maximum depth taxonomy metric greater semantic distance two words wordnet hierarchy less semantic similarity lee et al lky93 rada et al rmbb89 used conceptual distance based edge counting metric measure similarity query documents resnick res92 observed two words deep wordnet closely related two words higher tree pairs path length number nodes sussna sus93 took account semantic distance measure uses depthrelative scaling hirst et al hso98 classied relations wordnet three broad directional categories used distance measure took account path length also number direction changes semantic relations along path resnick res95 used informationbased measure instead path length measure similarity similarity two words estimated information content least probable class words belong 3 scoring novelty rules 31 semantic distance measure dened semantic distance two words w w j distance along path p according weighting scheme dirp number direction changes relations along path p k suitably chosen constant second component formula derived denition hirst et al hso98 relations wordnet divided three direction classes horizontal depending two words relation lexically related table 1 summarizes direction information relation types use direction changes path one word another greater semantic distance words since changes direction along path ect large changes semantic context path distance component formula based semantic distance de nition sussna sus93 dened shortest weighted path w w j every edge path weighted according wordnet relation corresponding edge normalized depth wordnet tree edge occurs used 15 dierent wordnet relations framework assigned dierent weights dierent link types eg hypernym represents larger semantic change synonym hypernym higher weight synonym weight chosen dierent relations given table 1 one point note sussnas denition semantic distance calculated weight edge two nouns w w j average two relations w corresponding edge relation r 0 inverse relation r made semantic distance two words symmetric measure considered noun hierarchy every relation nouns inverse relation framework considered four types words wordnet nouns adverbs adjectives verbs 15 dierent relation types words relations inverses eg entailment relation direct inverse used weight relation w measure weight edge w w j gives directionality semantic measure also conceptually compatible fact w word antecedent rule w j word consequent rule 32 rule scoring algorithm scoring algorithm rules according novelty outlined figure 2 algorithm calculates semantic distance dw antecedent w j consequent rule based length shortest path relation direction weight synonym attribute pertainym similar horizontal 05 antonym horizontal 25 hypernym memberjpartjsubstance meronym 15 hyponym memberjpartjsubstance holonym 15 cause entailment table 1 direction weight information 15 wordnet relations used connecting w w j wordnet novelty rule calculated average value pairs words w noun hierarchy wordnet disconnected 11 trees distinct root nodes verb hierarchy also disconnected 15 distinct root nodes purpose following method leacock chodorow lc98 connected 11 root nodes noun hierarchy single root node r noun path always found two nouns similarly connected verb root nodes single root node r verb r noun r verb connected toplevel root node r top connects verbs nouns wordnet database adjectives adverbs hierarchically arranged wordnet related corresponding nouns composite connected hierarchy derived wordnet hierarchy nd shortest weighted path two words performing branch bound search composite word hierarchy two words connected path however used 15 dierent wordnet relations searching path two words creates combinatorial explosion performing branch bound search composite hierarchy ecient implementation userspecied timelimit set 3 seconds experiments within try nd shortest path words w w j shortest path cannot found within timelimit algorithm nds default path w w j going hierarchy w w j using hypernym links till common root node reached function pathviaroot figure 2 computes distance default path nouns verbs pathviaroot function calculates distance path two words sum path distances word root r noun r verb node rule rule le set antecedent words set consequent words word w w j valid words wordnet score w elseif w j valid word wordnet score w valid word wordnet score w elseif path found w w j userspecied timelimit score w else score w score rule average w sort scored rules descending order figure 2 rule scoring algorithm part path adds penalty term posrootpenalty 30 path distance r top node part path adds larger penalty toprootpenalty 40 path distance penalty terms ect large semantic jumps paths go root nodes r noun r verb r top one words adjective adverb shortest path method terminate within specied timelimit algorithm nds path adjective adverb nearest noun relations like pertainym attribute etc nds default path noun hierarchy pathviaroot function incorporates distance path adjective adverb noun form path distance measurement words extracted rules valid words wordnet eg abbrevi ations names like philip domain specic terms like booknews etc assigned words average depth word avg figure 2 wordnet hierarchy estimated sampling techniques 6 estimated path distance root combined hierarchy using pathviaroot function 4 experimental results performed experiments compare novelty judgment human users automatic ratings algorithm objective automatic ratings correlate human high score 95 romance love heart midnight medium score 58 author romance characters love low astronomy science space figure 3 examples rules scored novelty measure judgments well human judgments correlate novelty metric considered successful 41 methodology purpose experiments took rules generated discotex 9000 ama zoncom book descriptions 2000 literature category 3000 science category 4000 romance category total set rules selected subset rules less total 10 words antecedent consequent rule done rules large human users rank pruning performed remove duplicate words rules amazoncom book description main also created stoplist commonly occurring words eg book table index content etc removed rules 1258 rules nal pruned ruleset sampled pruned ruleset create 4 sets random rules containing 25 rules created webinterface subjects used rank rules scores range least interesting 100 interesting according judgment 48 subjects randomly divided 4 groups group scored one rulesets rulesets two types average correlation calculated rst average correlation measured human subjects nd correlation judgment novelty human users second average correlation measure measured algorithm users group nd correlation novelty scoring algorithm human subjects used pearsons raw score correlation metric spearmans rank correlation metric compute correlation measures one rulesets used training set tune parameters algorithm results 3 rulesets used test sets experiment summarized table 2 human human algorithm human correlation correlation raw rank raw rank group2 average table 2 summary experimental results 42 results discussion rules scorings generated algorithm shown figure 3 highscoring rule lowscoring rule rated human subjects average high scoring lowscoring results considering raw rank correlation measures see correlation human subjects algorithm comparable human subjects averaging three random rulesets considered average raw correlation values among human subjects human subjects algorithm high rules human subjects diered lot novelty assessment also due fact initial experiments working improving methodology later experiments intend apply method domains expect human users agree novelty judgment rules however important note unlikely correlations due random chance since average raw correlation values minimum signicant r p 01 level signicance determined ttest correlation human subjects algorithm low rst rule set second third rulesets algorithmhuman correlation better humanhuman correlation closer analysis results group1 noticed ruleset contained many rules involving proper names algorithm currently uses semantic information wordnet scoring rules diered human subjects example one rule many users scored uninteresting ieee society science mathematics since wordnet entry ieee algorithm gave overall rule high score another rule users gave low score physics science nature john wiley publisher sons presumably based background knowledge publishing houses case algorithm found name john wordnet hierarchy synset lemma disciple jesus short path john words antecedent rule result algorithm gave rule high score point note names like jesus john james etc entries wordnet others like sandra robert etc makes dicult use kind consistent handling names using lters like name lists training ruleset also noticed rule sea oceanography given large score algorithm subjects group rated rule uninteresting happened short path sea oceanography wordnet two words related thematically wordnet thematic connections issue discussed detail section 6 5 related work soon apriori algorithm extracting association rules proposed researchers data mining area realized even modest settings support condence typically resulted large number rules much eort gone reducing rulesets applying objective subjective criteria klemettinen et al kmr proposed use rule templates describe structure relevant rules constrain search space another notable attempt using objective measures bayardo agrawal ba99 dened partial order terms support condence identify smaller set rules interesting rest sahar sah99 proposed iterative elimination uninteresting rules limiting user interaction simple classication questions hussain et al hlsl00 developed method identifying exception rules interestingness rule estimated relative common sense rules reference rules series papers tuzhilin coresearchers st96 pt98 at99 argued need subjective measures interestingness rules rules actionable also unexpected con icted existing system beliefs user preferred liu et al lhmh99 built theme implementing interactive postprocessing routine also analyzed classication rules extracted c45 dening measure rule interestingness terms syntactic distance rule belief rule belief dierent either consequents rule belief similar antecedents far apart vice versa contrast paper analyzed information extracted unstructured semistructured data webpages extracted rules depicting important relations regularities data nature rules well prior domain knowledge quite dierent extracted say market baskets proposed innovative use wordnet estimate semantic distance antecedents consequents rule used indication novelty rule domainspecic concept hierarchies previously used lter redundant mined rules hf95 fd95 however knowledge used evaluate novelty quantitatively applied rules extracted text data 6 future work important issue want address future selection parameters algorithm eg weights relations values k posrootpenalty top rootpenalty constants chosen experimentally would like learn parameters automatically training data using machine learning technique novelty score could adaptively learnt particular user tailored suit users expectation using average pairwise word similarity measures novelty score rule average measure smoothes skewing eect due large distances two pairs word rule ne rules except special cases eg rule science scientic home distance science scientic small science home large using average gives whole rule medium novelty score ect fact part rule involving words science home highly interesting part involving words science scientic uninteresting case combination method like maximum might useful suitable combination average maximum metrics would hopefully give better novelty scoring unfortunately wordnet fails capture semantic relationships words general thematic connections like pencil paper however approaches lexical semantic similarity statistical methods based word cooccurrence ms99 capture relationships methods word typically represented vector component number times word cooccurs another specied word within particular corpus cooccurrence based appearing within xedsize window words sentence paragraph document similarity two words determined vectorspace metric cosine angle corresponding vectors ms99 techniques latent semantic analysis dimensionality word vectors rst reduced using singular value decomposition svd order produce lexical representations small number highlyrelevant dimensions methods shown accurately model human lexicalsimilarity judgments ld97 utilizing cooccurrencebased metric dw rules could ranked novelty using statistical lexical knowledge end mathematical combination wordnet cooccurrence based metrics may best approach measuring lexical semantic distance extent names relations attributes values traditional database naturallanguage words segmented words approach could also applied traditional data mining well text mining algorithm easily generalized scoring novelty types rules eg association rules derived marketbasket data case would require knowledgebase corresponding domain eg concept hierarchy company products domainspecic concept hierarchies knowledgebases could used nd semantic connections rule antecedents consequents thereby contribute evaluating novelty finally overall interestingness rule might best computed suitable mathematical combination novelty traditional metrics condence support 7 conclusion paper proposes methodology extracting analyzing ltering rules extracted unstructured semistructured data web pages rules underscore novel useful relations regularities textual sources information web pages email usenet postings note nature rules well prior domain knowledge quite dierent extracted say market baskets salient contribution paper new approach measuring novelty rules mined text data based lexical knowledge wordnet algorithm also extended rules domains domainspecic knowledge hierarchy available also introduced systematic method empirically evaluating interestingness measures rules based average correlation statistics successfully shown automatic scoring rules based novelty measure correlates human judgments well human judgments correlate acknowledgments would like thank un yong nahm giving us discotex rules sets ran experiments grateful john didion providing jwnl java interface wordnet used develop software giving us useful feedback package also grateful people volunteered take part experiments rst author supported microelectronics computer development mcd fellowship awarded university texas austin research r user pro bayardo jr indexing latent semantic analysis knowledge discovery textual databases kdt electronic lexical database untangling text data mining discovery multiplelevel association rules large databases data mining concepts techniques exception rule mining relative interestingness measure lexical chains representations context detection correction malapropims finding interesting rules large sets discovered association rules combining local context wordnet similarity word sense identi finding interesting patterns using user expectations information retrieval based conceptual distance isa heirarchy dunja mladeni mutually bene beliefdriven method discovering unexpected patterns wordnet distribution analysis classbased approach lexical discovery using information content evaluate semantic similarity taxon omy development application metric semantic nets interestingness via interesting makes patterns interesting knowledge discovery systems word sense disambiguation freetext indexing using massive semantic network tr word sense disambiguation freetext indexing using massive semantic network finding interesting rules large sets discovered association rules foundations statistical natural language processing mining interesting rules interestingness via interesting data mining makes patterns interesting knowledge discovery systems finding interesting patterns using user expectations discovery multiplelevel association rules large databases exception rule mining relative interestingness measure mutually beneficial integration data mining information extraction ctr xin chen yifang brook wu web mining competitors websites proceeding eleventh acm sigkdd international conference knowledge discovery data mining august 2124 2005 chicago illinois usa raz tamir yehuda singer confidence gain measure association rule discovery scoring vldb journal international journal large data bases v15 n1 p4052 january 2006 b shekar rajesh natarajan framework evaluating knowledgebased interestingness association rules fuzzy optimization decision making v3 n2 p157185 june 2004 combining information extraction genetic algorithms text mining ieee intelligent systems v19 n3 p2230 may 2004