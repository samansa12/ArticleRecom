using application benefit proactive resource allocation asynchronous realtime distributed systems paper presents two proactive resource allocation algorithms called rba oba asynchronous realtime distributed systems algorithms consider application model timeliness requirements expressed using jensens benefit functions propose adaptation functions describe anticipated application workload future time intervals furthermore algorithms consider adaptation model application processes dynamically replicated sharing workload increases switched realtime ethernet network underlying system model given models objective algorithms maximize aggregate application benefit minimize aggregate missed deadline ratio since determining optimal allocation computationally intractable algorithms heuristically compute nearoptimal resource allocations polynomialtime rba analyzes process response times determine resource allocation decisions computationally expensive oba analyzes processor overloads compute decisions much faster way rba incurs quadratic amortized complexity terms process arrivals computationally intensive component dasa used underlying scheduling algorithm whereas oba incurs logarithmic amortized complexity corresponding component benchmarkdriven experimental studies reveal rba produces higher aggregate benefit lower missed deadline ratio oba b set pr p1p2p3 p assume clocks processors synchronized using algorithm 21 furthermore use nonpreemptive version processscheduling algorithm used processors scheduling packets switch done system homogeneity consequent simplicity obtain system model process scheduling packet scheduling consider besteffort realtime scheduling algorithms including ieee transactions computers vol 51 8 august 2002 dasa 15 lbesa 22 red 23 rhd 24 consider besteffort algorithms shown outperform edf 25 overloaded situations perform edf underloaded situations edf optimal 15 22 24 given application adaptation system models described sections 2 3 4 respectively objective maximize aggregate task benefit minimize aggregate task missed deadline ratio future time window task adaptation functions define aggregate task benefit sum benefit accrued execution task future time window define aggregate task missed deadline ratio ratio number task executions future time window missed deadlines total number task executions window note future time window task may execute multiple times thus problem solving paper informally stated follows given adaptation functions task application may arbitrary shapes thus define arbitrary task workload number replicas needed subtask task possible execution furthermore processor assignment executing replicas resulting resource allocation maximize aggregate task benefit minimize aggregate task missed deadline ratio future time window task adaptation functions show problem nphard 13 thus rba oba heuristic algorithms solve problem polynomialtime necessarily determine number subtask replicas processor assignment yield maximum aggregate task benefit minimum aggregate task missed deadline ratio since objective resource allocation maximize aggregate benefit minimize aggregate missed deadline ratio desired properties rba algorithm include 1 allocate resources decreasing order task benefits increase possibility maximizing aggregate benefit task selected next resource allocation always one largest benefit among unallocated tasks 2 allocate resources task deadline satisfied maximize possibility minimizing aggregate task missed deadline ratio furthermore reason allocate resources task deadline satisfied since task benefit functions stepfunctions yield zero benefit deadline 3 deallocate resources task deadline cannot satisfied save system resources potentially used satisfying deadlines hegazy ravindran using application benefit proactive fig 3 rba algorithm lower benefit tasks increase possibility satisfying deadlines greater number lower benefit tasks resulting potential contributions nonzero benefit toward aggregate task benefit 4 deallocate resources task point time resource allocation process timeliness higher benefit task adversely affected observe resources allocated task may reach apointbeforethesatisfactionofthetaskdeadlineafter increase resources task may negatively affect timeliness higher benefit tasks decreasingtheaggregatetaskbenefitthatisaccruedso far points obvious choice whether continue allocation task stop deallocatecan yield higher aggregate benefit example may possible continuing resource allocation task may eventually satisfy deadline expense one higher benefit tasks furthermore may also satisfy deadlines greater number lower benefit tasks resulting greater aggregate task benefit benefit would achieved deallocate task proceed next lower benefit task points diminishing returns rba makes choice deallocating resources allocated task far rationale behindthischoiceisthatsinceitisnotclearhowmany higher benefit tasks pay satisfying task deadline may best disturb aggregate benefit accrued far moreover since resources always allocated decreasing order task benefits chances obtaining higher aggregate benefit higher satisfying many high benefit tasks possible 5 decompose tasklevel resource allocation problem subtasklevel resource allocation problems rationale behind heuristic solving tasklevel resource allocation problem determining replica needs subtasks task endhosts analysis system computationally expensive therefore decomposing problem subproblems solving subproblems seek reduce overhead computing nearoptimal solution since focusing step benefit functions tasks decomposition resource allocation asynchronous realtime 949 donebyassigningdeadlinestosubtasksandmessages task task deadline way subtasks messages task meet respective deadlines task able meet deadline using heuristic determine replica needs task satisfy task deadline determining replica needs subtasks task satisfy subtask deadlines thus rba performs resource allocation according heuristic choices discussed summarize algorithm follows rba performs resource allocation usermodifica tions adaptation functions application tasks detected since anticipated workload may different different task periods time window specified adaptation functions algorithm allocates resources period time window adaptation functions starting earliest period proceeding latest triggered algorithm first sorts tasks according benefits task adaptation period decreasing order task benefits period occurrences respectively rba determines number replicas needed subtask task processor assignment satisfy subtask deadline current period computing number replicas subtask task timeliness higher benefit task affected task found infeasible algorithm deallocates allocated replicas proceeds next adaptation period pseudocode rba highest level abstraction shown fig 3 efficiently determine next task highest benefit resource allocation algorithm initially constructs heap task set task benefit key values heap nodes enables algorithm efficiently determine next task allocation performing extractmax operation heap discuss rba determines number replicas subtask processor assignment subsections follow section 61 discusses rba assigns deadlines subtasks messages task deadline determine number replicas needed subtask satisfy subtask deadline rba analyzes subtask response times discuss steps involved determining subtask response times 950 ieee transactions computers vol 51 8 august 2002 section 62 present response time analysis algorithm xm section 63 finally present algorithm determines number subtask replicas xm processors section 64 eex stkd 61 deadline assignment subtasks 2 3 messages ecd mkd problem subtask message deadline assignment 4p pi 5 task deadlines studied different context ji j ji1 j 26 equal flexibility eqf strategy presented 26 besides assigning deadlines subtasks messages assigns deadlines subtasks messages task task deadline also need map tasklevel deadline way proportional subtask execution benefit benefit values subtasks messagepackets times message communication delays respectively task besteffort scheduling algorithms relative deadline subtask message dasa lbesa red considering simply sum execution time subtask work use benefit values subtasks message communication delay message slack value packets making scheduling decisions thus eqf defines slack value subtask define benefit subtask messagepacket message percentage total available slack simply benefit parent task subtask message total available slack subtask message 62 estimating subtask response time simply difference task deadline response time subtask stji task tj fixed sum execution times communication delays priority schedulers given classical equation subtasks messages succeed subtask rj cj ij rj subtask response time cj message task structure recall assuming subtask execution time ij interference serial structure task execution times subtask experiences subtasks 27 however communication delays subtasks messages equation insufficient besteffort realtime schedulers precede subtask message task structure dasa lbesa considering considered total available slack since workastheymakedecisionsateachschedulingeventthatare latencies would already incurred time subtask functions remaining subtask execution times starts execution message starts transmission event remaining execution time subtask given slack value subtask message time instant difference total execution time defined percentage total available slack subtask time subtask already spent subtask message percentage ratio executed processor time instant subtask execution time message communication determine response time subtask delay sum execution times communication processor need know scheduling events delays subtasks messages succeed subtask time instants scheduler select message task structure thus higher subtask ready queue scheduling events include subtask execution time message communication delay arrival times completion times subtasks higher ratio higher percentage determine subtask arrival times assume higher slack value higher following subtask message deadline rba uses eqf following way algorithm a1 periodic task arrives beginning estimates subtask execution times message commu period nication delays using applicationprofile functions a2 aperiodic task arrives triggering useranticipated workload estimated execution times message triggering periodic task arrives message delays used assign subtask a3 response time subtask longest message deadlines according eqf respectively response time among replicas thus deadline subtask stk workload a4 message assumed arrive destination given processor deadline assigned using eqf a5 first subtask task arrive beginning period parent task every dl stki eex sti dltk eex stkj subtask task arrive elapse interval time since task period xm k equal sum message delays subtask response times predecessor messages predecessor subtasks subtask respectively 4p eex stpki 5 a1 a2 straightforward assumptions directly derived application model recall application model see section 2 assumes aperiodic deadline message mk workload task triggered upon completion execution given triggering periodic task hegazy ravindran using application benefit proactive resource allocation asynchronous realtime 951 assumption a3 reasonable data objects passed algorithm estimates subtask response times subtask processed longest response time determining scheduling events occur replicas subtask time window applying scheduling algorithm a4 pessimistic assumption implies scheduling event determine scheduling decision messages incur worstcase communication delays note impossible determine subtask response arrive deadlines however times without determining scheduling events important observe exact delay incurred decision made event algorithms dasa message depend upon among factors lbesa decisions event depends contention message experiences outgoing remaining subtask execution times event queue sender processor switch 63 subtask response time analysis determine would need determine messages algorithm present sender processor switch time instants message generated pseudocode subtask response time analysis sender processor arrives switch respectively algorithm shown fig 4 would require holistic analysis system procedure rbaanalyzeresponse accepts subtask computationally expensive thus reduce task period p processor q response time computational overhead make simplifying assump needs determined workload subtask tion messages arrive deadlines arguments computes response time assumption a5 straightforward directly subtask period p processor qasa derived precedence relationship subtasks byproduct procedure determines response times messages task see section 2 subtasks assigned processor q thus arrival time subtask determined compares subtasks response times subtasks sum response times subtasks deadlines deadlines subtasks satisfy deadlines messages precede subtask considera procedure returns response time subtask sif tion arrival time parent task subtask subtask found miss deadline algorithm thus given arrival time task ti arrival time returns failure value indicating replicating subtask sti task given subtask processor q either satisfy deadline affect timeliness higher benefit tasks arrivaltime sti note whenever procedure rbaanalyzeresponse invoked subtask processor q existing xj1 subtasks q belong higher benefit tasks arrivaltimeti responsetime stk dl mk task since rba allocates replicas tasks decreasing order benefits arrivaltimexdenotes arrival time subtask task x responsetimexdenotes response time 64 determining number subtask replicas subtask x dlxdenotes deadline message x processors arrival time subtask processor thus determine number replicas needed determined arrival list constructed note subtask processors rba first analyzes algorithm considers subtasks within task response time subtask current processor according precedenceorder therefore subtask response time found less algorithm determines arrival time subtask subtask deadline timeliness subtasks higher response times predecessor subtasks would already benefit tasks found affected algorithm determined concludes single replica subtask eventual goal determine subtask response current processor enough satisfy subtask deadline times examining arrival list increasing order hand subtask response time found arrival times applying scheduling algorithm larger subtask deadline executing arrival time purpose arrival list must sorted subtask current processor found cause one according arrival times accomplished subtasks higher benefit tasks miss dead inserting arrival time subtask integer lines rba reduces workload subtask ordered list integer position corresponds replication algorithm considers second replica subtask arrival time thus subtask arrival times subtask reduce workload existing determined inserted list list auto replica half matically gets ordered according arrival times determine processor executing second arrival times subtasks determined rba replica rba analyzes subtask response time estimates anticipated workload task processing half subtask workload adaptation period using task adaptation functions processors excluding processor first replica aperiodic tasks algorithm uses period using subtask response time analysis algorithm triggering periodic tasks task period anticipated described section 63 processor gives workloads plugged applicationprofile shortest response time selected second replica functions estimate subtask execution times algorithm recomputes response time task periods first replica processor processing half fig 4 rbaanalyzeresponse procedure workload since second replica process half workload response times replicas found less subtask deadline execution replicas respective processors found affect timeliness higher benefit tasks two replicas considered sufficient ieee transactions computers vol 51 8 august 2002 algorithm otherwise algorithm considers third replica repeats process rba repeats process replica able satisfy subtask deadline note number replicas increases workload share replica reduced furthermore every time algorithm considers hegazy ravindran using application benefit proactive fig 5 rbadeterminereplicasprocessors procedure adding new replica checks whether existing ones able satisfy deadlines reduced workload without affecting timeliness higher benefit tasks algorithm determines executing maximum possible number replicas subtask equal number processors system exploiting maximum concurrency satisfy subtask deadline assumes subtask hence task miss deadlines rba deallocates replicas allocated task discussed section 6 fig 5 shows pseudocode algorithm determines number subtask replicas processor assignment procedure rbadeterminerepli casprocessors accepts subtask period anticipated workload l period determines number replicas processors recall procedure rbaalgorithm fig invokes procedure rbadeterminereplicasprocessors subtask executions future adaptation window 7worstcase complexity rba analyze worstcase computational complexity rba consider n tasks p processors maximum subtasks task thus worstcase n tasks subtasks smallest task period k thus worstcase n tasks period k adaptation window length w worstcase complexity rbaalgorithm procedure depends upon complexity procedure resource allocation asynchronous realtime 953 rbadeterminereplicasprocessors complexity rbadeterminereplicasprocessors depends procedure rbaanalyzeresponse determines response time subtask discuss complexity procedures subsections follow 71 complexity rbaanalyzeresponse complexity rbaanalyzeresponse consists two components first given subtask processor subtask response time needs determined procedure rbaanalyzeresponse constructs arrival list subtasks processor second subtask constructed arrival list procedure invokes scheduler arrivals departures within length adaptation function thus cost rbaanalyzeresponse simply sum cost constructing arrival list cost invoking scheduler scheduling event ie arrival termination event subtask 711 arrival list construction since subtask replicated maximum p times since rba assign two replicas subtask processor maximum number subtask replicas assigned rba processor mn ie subtasks task n tasks mn subtasks arrive periods parent task throughout adaptation function window w largest possible number arrivals subtask 954 ieee transactions computers vol 51 8 august 2002 therefore dwke thus largest arrival list p times determine response time replica size mndwke considered step p processors thus construct arrival list rbaanalyzeresponse deter procedure rbadeterminereplicasprocessors invokes mines arrival time replica processor procedure rbaanalyzeresponse p2 number times determine arrival time replica rbaanalyzeresponse complexity p2 om3n3dwke3 examines predecessor subtask message op2m3n3dwke3 replica thus cost determining arrival time 73 complexity rbaalgorithm single replica involves examining predecessor subtasks predecessor messages incurring total cost od complexity rbaalgorithm two compo number predecessor subtasks nents first rbaalgorithm constructs heap subtask consideration uses task benefits key values second invokes arrival time subtask determined rbadeterminereplicasprocessors subtask procedure rbaanalyzeresponse inserts subtask arrival task period time heap using key value corresponds cost building heap n tasks subtask arrival time recall largest list size given n tasks maximum subtasks per task determined mndwke insertion cost heap minimum period k task rbadeterminereplicas ologmndwke thus cost constructing ordered processors invoked mndwke times rbaalgo arrivallistforallthemndwkesubtaskarrivalsonaprocessor rithm invoking rbadeterminereplicasprocessors given mndwkeod logmndwke cost next highest benefit task needs extracted becomes omdndwkemndwke logmndwke heap cost extractmax heap operation olog n therefore cost second component 712 response time analysis response time analysis performed invoking mndwke log n p2m3n3dwke3 scheduler subtask arrival departure cost invoking scheduler obviously dependent scheduling algorithm employed consider worstcase complexity rbaalgorithm dasand algorithm ie dasa subtasks sum cost two components dependencies cost computing scheduling onop2m4n4dwke4 becomes op2m4n4dwke4 decision given r processes ready queue processor or215 13 8amortized complexity since mndwke arrivals processor worstcase cost invoking dasand rbaanalyzeresponse single scheduling event om2n2dwke2 invok analyze amortized complexity rba ing dasand next subtask arrival must extracted analyzeresponse procedure since computa heap costs ologmndwke thus tionally intensive component rba algorithm sequence extracting next subtask arrival consider amortized complexity get realistic heap invoking dasand algorithm repeated sense cost rbaanalyzeresponse procedure 2mndwke times total cost scheduler invoca comparing cost counterpart tions becomes procedure oba algorithm recall rbaanalyzeresponse procedure invokes mndwke logmndwkem2n2dwke2 procedure localscheduler represents underlying scheduling algorithm determining scheduler decisions see fig 4 analyzing amortized complexity rbaanalyzeresponse consider dasa complexity rbaanalyzeresponse sum nd underlying scheduling algorithm cost arrival list construction cost given r processes readyqueue total cost scheduler invocations given dasand algorithm or215 13 omdndwke mndwkelogmndwkeas discussed section 7 cost rbaanalyze response consists two components 1 constructing arrival times key values analyzing subtask response times 72 complexity given n subtask arrivals total number steps rbadeterminereplicasprocessors required constructing subtask arrival time heap procedure rbadeterminereplicasprocessors deter nk1 log k steps costs olog k insert kth mines number replicas processors needed element heap given subtask iterative manner starting foranalyzingsubtaskresponsetimesdasandiscalled single replica incrementing maximum 2n times worstcase occurs none n possible number replicas equal number processes terminate arrive processors p reached iterative step situationthequeuesizeincreaseswheneveraprocessarrives procedure invokes rbaanalyzeresponse maximum becomes n first termination occurs hegazy ravindran using application benefit proactive resource allocation asynchronous realtime 955 time dasand invoked n processes ready whole procedure repeated way similar queue number processes queue decreases rba call new algorithm overload queue becomes empty analysisbased besteffort resource allocation oba cost extracting kth element invoking given n subtask arrivals processor deadline dasand process leaving ready queue ordered perform overload test ontime 23 n processes arrive given n logn k k2 15 thus cost performing overload test k2 cost invoking dasand k processor given mndwke subtask arrivals processor processes logn kis cost extracting worstcase given omndwke assuming kth element heap cost invoking dasa given deadlineordered subtask arrival list recall nd terminations p1 k2 steps thus section 7 complexity rbaanalyzeresponse includes 1 complexity arrival list construction total number steps performed rbaanalyze complexity response time analysis thus response n logn kk21 k2 k1 kn complexity obas counterpart procedure rbaanalyze amortized complexity rbaanalyzeresponse response becomes equal sum cost constructing given 1n times total number steps performed deadlineordered subtask list cost performing becomes overload test xn xn x1 wecaneasilymodifytheprocedurerbaanalyzeresponse constructs subtask arrival list ordered deadlines instead arrival times cost dominant term numerator 1 k2 on3 thus amortized complexity krbnaanalyze cost obas version rbaanalyzeresponse procedure response given 1non3 on2 becomes omndwkelogmndwke cost significantly speed oba respect rba cost om3n3dwke3 procedure rbaanalyzeresponse 9the oba algorithmheuristics dasand used underlying scheduling rationale algorithm endhost processors2 thus highest level abstraction oba follows careful observation rba algorithm reveals exact steps rba pseudocode oba algorithm computationally complex fact procedure highest level abstraction shown fig 6 oba thatcosts rbathemost subtaskresponse time analysis differs rba way determines procedure ie rbaanalyzeresponserecalthatrba number replicas needed subtask task analyzeresponse analyzes response time subtask processor assignment given processor given workload constructing discuss oba performs overload test arrival list subtasks processor invoking determines number subtask replicas scheduling algorithm subtask arrival processor assignment subsections follow completion length adaptation window complexity procedure dominated 91 overload analysis complexity invoking scheduling algorithm determine whether presence subtask scheduling events ie om3n3dwke3 processor result overload processor oba thus would like design much faster first constructs list subtask arrival times similar algorithm achieves objectives rba one constructed rbas rbaanalyzeresponse procedure careful observation reveals avoid section 62 except list deadlineordered schedulerexecution performed rba instead discussed section 62 algorithm constructs dead conduct overload test processor rbas objective lineordered list inserting subtask arrival event invoking scheduler determine subtask feasi integerordered list subtask deadline position bility done determining subtask response determines arrival time subtask time comparing response time subtask deadlineordered arrival list constructed deadline also determine subtask feasibility oba examines subtask deadlines arrival list overload test processor increasing order deadlines subtask deadline di processor underloaded clearly subtask algorithm computes sum remaining execution must able complete execution deadline times subtasks deadlines less di besteffort realtime scheduling algorithms mimic edf compares sum di sum greater underloaded situations edf guarantees deadline di deadline exists overload deadlines processor underloaded processor indicates exists least one conclude processor good candidate subtask processor unable complete subtask workload subtask process deadline ie subtask demand exceeds available hand processor overloaded processortime sum less subtask deadline implies one subtasks miss deadlines deadline processor underloaded reduce workload share subtask subtasks complete deadlines ie total considering replica subtask subtask feasibility determined overload test 2 analyze obas entire complexity later section 10 fig 6 oba algorithm processortime demand subtasks less available processor time fig 7 shows pseudocode obas overloadtest procedure called obaoverloadcheck determines whether executing subtask replica processor q subtask period p cause overload situation q procedure starts constructing subtask arrival list similar way rbaanalyzeresponse constructs arrival list list constructed overload test run single pass list procedure returns success value overload detected otherwise returns failure value 92 determining number subtask replicas processors determine number replicas needed subtask processors oba first checks whether overload processor subtask currently assigned overload detected algorithm concludes single replica subtask process entire subtask workload current processor complete execution subtask deadline since overload detected processor subtasks must able compete deadlines thus cannot affect timeliness higher benefit tasks3 thus detecting underload processor oba makes conclusions made rba regarding subtask feasibility interference timeliness higher benefit tasks hand overload detected processor subtask oba reduces workload subtask replication algorithm considers second replica subtask processor existing subtask replica assigned note considering second replica subtask reduce workload share two replicas thereby reduce execution times replicas may resolve overload situation processors replicas algorithm tests overload processors overload detected processors replicas algorithm concludes two replicas sufficient satisfy subtask deadline otherwise oba considers yet another replica subtask 3 note whenever consider execution subtask replica processor q test overload q existing subtasks q must belong higher benefit tasks task since oba allocates replicas tasks decreasing order benefits ieee transactions computers vol 51 8 august 2002 algorithm thus repeats process replicating overload testing either 1 overload detected processors subtask replicas 2 maximum possible number replicas subtask equal number processors system exploiting maximum concurrency reached executing maximum number replicas subtask resolve overload situation thus satisfy subtask deadline oba deallocates task discussed section 6 fig 8 shows pseudocode procedure oba determinereplicasprocessors determines number replicas necessary subtask processors procedure calls procedure obaoverloadcheck fig 7 test processor overloads resource allocation process recall main procedure oba algorithm obaalgorithm fig invokes procedure obadeterminereplicasprocessors subtask execution future time window analysis worstcase computational complexity oba similar rba obas complexity depends upon complexity procedure obadetermine replicasprocessors complexity obadeterminereplicas processors depends upon complexity procedure obaoverloadcheck discussed section 9 complexity oba overloadcheck equal sum cost constructing heap using subtask deadlines key values cost performing overload test cost constructing subtaskdeadline heap omndwke logmndwke since use approach used procedure rbaanalyzeresponse note term mdndwke appear algorithm need compute arrival times subtasks needs absolute deadlines perform overload test given deadline heap oba tests overload making single pass subtask deadline examined increasing order cumulative sum remaining execution times subtasks lesser deadlines compared current deadline costs logmndwke extract delete earliest deadline subtask heap since process repeated mndwke nodes heap cost overload hegazy ravindran using application benefit proactive resource allocation asynchronous realtime 957 fig 7 obaoverloadcheck procedure test omndwke logmndwke thus total cost cost main procedure obaalgorithm two obaoverloadcheck given components first obaalgorithm constructs heap using task benefits key values second invokes oba omndwkelogmndwkemndwkelogmndwke determinereplicasprocessors subtask task period procedure obadeterminereplicasprocessors deter cost building heap n tasks mines number replicas processors given n tasks maximum subtasks per task needed given subtask iterative manner minimum task period k procedure obadetermine starting single replica incrementing replicasprocessors invoked mndwke times oba maximum possible number replicas equal number algorithm invoking obadeterminereplicasprocessors processors p reached iterative step next highest benefit task needs extracted procedure invokes obaoverloadcheck maximum p heapthecostofanextractmaxheapoperationisolog n times test overload p processors replica therefore cost second component becomes considered step thus procedure obadetermine replicasprocessors invokes procedure obaoverload mndwke log n p2mndwkelogmndwke check p2 number times complexity 2 worstcase complexity obaalgorithm sum cost two components fig 8 obadeterminereplicasprocessors procedure onop2m2n2dwke2 logmndwke becomes op2m2n2dwke2 logmndwke analyze amortized complexity obas obaoverloadcheck procedure recall oba overloadcheck procedure obas counterpart procedure rbas rbaanalyzeresponse procedure found computationally expensive component rba cost obaoverloadcheck consists two compo nents 1 constructing heap subtask deadlines values 2 overload testing given n subtask arrivals total number steps required constructing subtaskdeadline heap log k overload testing process takes total n iterations iteration next earliest deadline subtask needs extracted heap costs ologn k thus overload testing component costs amortized complexity obaoverloadcheck therefore 1n times total number steps performed becomes 1n n log k 1 logn k note terms numerator yield onlog n thus amortized complexity obaoverloadcheck log nn olog n ieee transactions computers vol 51 8 august 2002 thus note oba faster rba though oba faster rba hypothesize oba may perform worse rba especially overload situations conditions clearly interested due asynchronous nature applications consider hypothesis based fact response times subtasks accurately match subtask behavior situations thus rba exploits knowledge determines resource allocations accurately match applicationneeds situations oba hand determines allocations identifying overloaded processors avoiding processors thus underloaded processors algorithm stops allocating resources proceeds next task adaptation period cause algorithm effectively allocate resources smaller range workload situations rba experimentally evaluating rba oba goal determine 1 rba performs different besteffort realtime scheduling algorithms process scheduling packet scheduling dasa red lbesa rhd 2 relative performance rba oba 3 rba oba perform anticipated workloads specified using adaptation functions differ actual workloads hegazy ravindran using application benefit proactive resource allocation asynchronous realtime 959 fig 9 performance rba dasa red schedulers increasing rampramp workloads aggregate accrued benefit b missed deadline ratio conducted applicationdriven simulation studies evaluate performance rba oba details application parameters used experiments derived dynbench realtime benchmark described 28 discuss experiments results subsections follow 121 performance rba different scheduling algorithms evaluate performance rba different scheduling algorithms considered two adaptation functions specified two workload patterns 1 increasing ramp periodic workload increasing ramp aperiodic workload denoted rampramp work load 2 constant periodic workload increasing ramp aperiodic workload denoted con stantramp workload recall workload periodic task task period number data objects generated period workload aperiodic task period triggering periodic task number triggering events generated triggering periodic task period evaluate performance rba ramp ramp workload first defined baseline rampramp adaptation function baseline rampramp function defined particular slope window length thus defining maximum workload periodic aperiodic tasks function conducted experiment baseline rampramp function measured total benefit accrued execution tasks missed deadline ratio rba experiment dasa red underlying schedulers constituted single data point baseline experiment repeated increasing slope baseline rampramp function thus generating increasing rampramp workloads experiment measured aggregate accrued benefit missed deadline ratio results experiments shown fig 9 note data point plots obtained single experiment thus maximum workload individual experiments shown xaxis plots aggregate accrued benefit shown fig 9a missed deadline ratio shown fig 9b fig 10 shows performance rba dasa red increasing constramp workloads data point plots obtained single experiment maximum workload individual experiments shown xaxis figures aggregate accrued benefit shown fig 10a missed deadline ratio shown fig 10b also measured aggregate benefit missed deadline ratio rba increasing rampramp constramp workloads lbesa rhd underlying scheduling algorithms observed performance rba lbesa rhd close red therefore clarity omit performance rba lbesa rhd figures fig 9 fig 10 observe rba dasa produces higher aggregate benefit lower missed deadline ratio red lbesa rhd thus experimental results illustrate superiority rba dasa algorithm believe due two reasons 1 rba determines resource allocation decisions significantly relying behavior underlying scheduling algorithm example rba computes allocations determining subtask response times clearly depends upon scheduler makes scheduling decisions thus conjecture performance rba depends upon large extent performance underlying scheduling algorithm verify hypothesis conducted several experiments study relative performance dasa red rhd 134 experiments revealed dasa outperforms red rhd thereby validating intuition thus rba performs better dasa scheduling algorithms 2 rba mimics dasa higher level abstraction resource allocation example rba allocates resources tasks tests feasibility tasks decreasing order task benefits dasa also examines processphases subtasks tests schedulefeasibility decreasing order benefit densities process phases symmetry behavior contributes better performance rba dasa algorithms 4 dasa shown outperform edf lbesa 15 960 ieee transactions computers vol 51 8 august 2002 fig 10 performance rba dasa red schedulers increasing constramp workloads aggregate accrued benefit b missed deadline ratio fig 11 performance rba oba dasa increasing rampramp workloads aggregate accrued benefit b missed deadline ratio 122 relative performance rba oba since dasa performed best among scheduling algorithms considered compared performance rba oba dasa experiments rba described section 121 repeated oba using dasa underlying scheduling algorithm processors switch fig 11 fig 12 show performance obadasa rbadasa increasing rampramp workloads constramp workloads respectively observe rbadasa produces higher aggregate benefit lower missed deadline ratio obadasa results shown fig 11 fig 12 thus validate hypothesis described section 11 although oba faster rba oba may perform worse rba 123 performance rba oba error anticipated workloads study rba oba perform actual workloads differ anticipated workloads specified adaptation functions define relative load error term relative load error term defined er actual load anticipated loadanticipated load fig 13a shows performance rba range relative load errors 09 09 fixed anticipated workload load error 09 means actual load 190 percent anticipated load yaxis shows relative change aggregate benefit define change aggregate benefit certain value er difference aggregate benefit value er aggregate benefit zero relative load error relative change aggregate benefit defined ratio change aggregate benefit aggregate benefit zero relative load error figure shows rba generally performs better error dasa used underlying scheduling algorithm red used attribute better performance rbadasa errors reasons described section 121 fig 13b shows obadasa performs respect rbadasa actual workloads differ anticipated workloads figure observe rba performs better errors anticipated workloads oba regard better performance rba errors validation hypothesis discussed section 11 hegazy ravindran using application benefit proactive resource allocation asynchronous realtime 961 fig 12 performance rba oba dasa increasing constramp workloads aggregate accrued benefit b missed deadline ratio fig 13 effect error anticipated load performance rba oba rba error b oba error 13 conclusions future work paper present two resource allocation algo rithms called rba oba proactive resource allocation asynchronous realtime distributed systems algorithms proactive sense allow usertriggered resource allocation userspecified arbitrary application workload patterns algorithms consider application model application timeliness requirements expressed using jensens benefit functions propose adaptation functions describe anticipated application workload future time intervals furthermore consider adaptation model subtasks application tasks replicated runtime sharing workload increases switched realtime ethernet network given applica tion adaptation system models objective maximize aggregate application benefit minimize aggregate missed deadline ratio 13 show problem nphard thus rba oba heuristically compute nearoptimal resource allocation decisions polynomialtime heuristics employed algorithms include allocating resources higher benefit tasks lower benefit tasks allowing lower benefit tasks affect timeliness higher benefit tasks decomposing tasklevel allocation problem subtask level allocation problems algorithms differ way solve subtasklevel allocation problem whilerbasolvesthesubtasklevelallocationproblemby analyzing subtask response times oba solves problem testing processor overloads rba incurs worstcase computational complexity op2m4n4dwke4 dasa scheduling algorithm amortized complexity on2 computationally expensive component obaontheotherhandincursabetterworstcasecomplexity op2m2n2dwke2 logmndwke amortized complexity olog n procedure corresponds rbas computationally expensive component study performance algorithms conduct benchmarkdriven experiments experimental results reveal rba produces higher aggregate benefit lower missed deadline ratio dasa used processscheduling packetscheduling scheduling algorithms used furthermore observe rba produces higher aggregate benefit lower missed deadline ratio oba thus major contribution paper rba oba algorithms seek maximize aggregate benefit minimize aggregate missed deadline ratio asynchronous realtime distributed systems proactive resource allocation best knowledge aware efforts solve problem solved rba oba several aspects work investiga tion rba oba centralized resource allocation algorithms may potentially affect scalability furthermore adaptation functions propose deterministic sense user anticipates future workload without uncertainties though experimentally study algorithms performance presence uncertainties may possible define adaptation functions probabilistic setting thereby enabling probabilistic decisionmaking adaptation furthermore fault tolerance key requirement asynchronous realtime distributed systems besides timeliness issues currently studied acknowledgments work supported us office naval research grant n000149910158 n000140010549 r ieee trans us naval surface warfare center hard realtime computing systems predictable scheduling algorithms applications tr improved algorithms synchronizing computer network clocks scheduling algorithms multiprogramming hardrealtime environment resource management middleware dynamic dependable realtime systems engineering dynamic realtime distributed systems hard realtime computing systems guest editors introduction special section asynchronous realtime distributed systems deadline assignment distributed soft realtime system adaptive distributed airborne tracking system process right tracks right time endhost architecture qosadaptive communication dynamic realtime benchmark assessment qos resource management technology quality service optimization discrete qos options automated profiling subsystem qosaware services adaptive resource allocation complex realtime applications dynamic quality service middleware agent mediating application resource usage specification modeling dynamic distributed realtime systems decisionmaking realtime scheduling scheduling dependent realtime activities quality service management resource allocation ctr robust resource allocation dynamic realtime systems journal systems software v77 n1 p5565 july 2005 peng li binoy ravindran proactive qos negotiation asynchronous realtime distributed systems journal systems software v73 n1 p7588 september 2004 peng li binoy ravindran efficiently tolerating failures asynchronous realtime distributed systems journal systems architecture euromicro journal v50 n10 p607621 october 2004 peng li binoy ravindran fast besteffort realtime scheduling algorithms ieee transactions computers v53 n9 p11591175 september 2004 lin wujuan bharadwaj veeravalli object replication algorithm realtime distributed databases distributed parallel databases v19 n23 p125146 may 2006