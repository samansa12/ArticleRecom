improving accuracy performance memory communication renaming processors continue exploit instructionlevel parallelism greater demand placed reducing effects memory access latency paper introduce novel modification processor pipeline called memory renaming memory renaming applies register access techniques load instructions reducing effect delays caused need calculate effective addresses load preceding stores data fetched memory renaming allows processor speculatively fetch values producer data reliably determined without need effective address work extends previous studies data value dependence speculation memory renaming added processor pipeline renaming applied 30 50 memory references translating overall improvement execution time 41 furthermore improvement seen across memory segmentsincluding heap segment often difficult manage efficiently b introduction two trends design microprocessors combine place increased burden implementation memory system aggressive wider instruction issue higher clock speeds instructions pushed pipeline per cycle proportionate increase processing memory operations account approximately 13 instructions time gap processor dram clock speeds dramatically increased latency memory operations caches universally adopted reduce average memory access latency aggressive outoforder pipeline execution along nonblocking cache designs employed alleviate remaining latency bypassing stalled instructions unfortunately instruction reordering complicated necessity calculating effective addresses memory operations whereas dependencies registerregister instructions identified examining operand fields memory dependencies cannot determined much later pipeline effective address calculated result mechanisms specific loads stores eg mob pentium pro 1 required resolve memory dependencies later pipeline enforce memory access semantics date effective solution dealing ambiguous memory dependencies requires stalling loads earlier unknown store address exists approach however overly conservative since many loads stall awaiting addresses stores depend resulting increased load instruction latency reduced program performance paper proposes technique called memory renaming effectively predicts memory dependencies store load instructions allowing dynamic instruction scheduler accurately determine loads commence execution addition reordering independent memory ref erences flexibility developing improved dynamic schedule achieved tech nique memory renaming enables load instructions retrieve data effective address calculated achieved identifying relationship load previous store instruction generated data new mechanism employed uses identifier associated storeload pair address value bypassing normal addressing mechanism term memory renaming comes similarity approach abstraction operand specifiers performed register renaming 7 paper examine characteristics memory reference stream propose novel architectural modification pipeline enable speculative execution load instructions early pipeline address calculation true dependencies eliminated particular true dependencies supporting complex address calculations used access program data shown significant impact overall performance much 41 speedup experiments presented remainder paper organized follows section 2 examines previous approaches speculating load instructions section 3 introduces memory reordering approach speculative load execution evaluates regularity memory activity order identify successful strategy executing loads speculatively section 4 show one possible integration memory renaming outoforder pipeline implementation section 5 provides performance analysis cycle level simulation tech niques section 6 state conclusions identify future research directions work background number studies targeted reduction memory latency austin sohi 2 employed sim ple fast address calculation early pipeline effectively hide memory latency achieved targeting simple baseoffset addressing modes used references global stack data dahl okeefe 5 incorporated address bits associated register provide hardware mechanism disambiguate memory references dynamically allowed compiler aggressive placing frequently referenced data register file even aliasing may present dramatically reduce number memory operations must executed lipasti shen 8 described mechanism value load instruction predicted based previous values loaded instruction work used load value prediction unit hold predicted value along load classification table deciding whether value likely correct based past performance predictor observed large number load instructions bringing value time time speculatively using data value last loaded instruction dependencies resolved able remove dependencies critical path speculation accurate using approach able achieve speedup execution 3 simple implementation 16 infinite resources perfect prediction sazeides vassiliadis smith 10 used address speculation load instructions remove dependency caused calculation effective address enables load instructions proceed speculatively without address operands effective address computation particular load instruction remains constant global variable references finally moshovos breach vijaykumar sohi 9 used memory reorder buffer incorporating data dependence speculation data dependence speculation allows load instructions bypass preceding stores ambiguous dependencies resolved greatly increases flexibility dynamic instruction scheduling find memory instruction ready exe cute however speculative bypass violates true dependency load store instructions flight state machine must restored point load instruction misspeculated instructions load must aborted reduce number times misspeculation occurs prediction confidence circuit included controlling bypass allowed confidence mechanism differs used value prediction locating dependencies pairs store load instructions instead basing confidence history load instruction reference prediction added multiscalar architecture execution performance improved average 510 approach speculation extends value prediction dependence prediction perform targeted speculation load instructions early architectural pipeline renaming memory operations memory renaming extension processor pipeline designed initiate load instructions early possible combines dependence prediction value prediction achieve greater performance possible either technique alone basic idea behind memory renaming make load instruction look like register reference thereby process load similar manner difficult achieve memory reference instructions unlike simple operand specifiers used access register require effective address calculations dependence analysis performed eliminate need generate effective address critical path accessing load data perform load speculatively using program counter pc load instruction index retrieve speculative value similar approach used lipasti shens value prediction except memory renaming performed indirectly load instruction en countered pc address associated load ldpc used index dependence table called storeload cache determine likely producer data generally store instruction recog value file storeload cache speculative load data figure 1 support memory renaming nized data referenced load instruction likely produced single store instruction data last execution store retrieved value file accessing value file entry performed speculatively without need know effective address load store instruction instead value file indexed unique identifier associated storeload pairing mechanism described next section store instructions also use storeload cache locate entries value file likely referenced future loads store load instruction pair determined reference locations map value file index figure 1 shows overview memory renaming mechanism approach advantage pro ducerconsumer relationship exists load proceed early pipeline effective address calculation proceed usual memory operation retrieve value dcache done validate speculative value brought value file data loaded dcache matches value file speculation successful processing continues unfettered values differ state processor must corrected order memory renaming improve processor performance may prudent include prediction confidence mechanism capable identifying speculation warranted value prediction dependence prediction use history based scheme identify speculation likely succeed unlike value renaming chose identify stable storeload pairings instead relying static value references see advantage using producerconsumer relationship confidence mechanism analysis shown spec95 benchmarks programs compiled gnu gcc ver sion 262 gnu gas version 25 gnu gld version 25 maximum optimization o3 loop unrolling enabled funrollloops fortran codes first converted c using att f2c version 19940927 experiments performed extended version simplescalar 3 tool set tool set employs simplescalar instruction set virtual mipslike architecture 6 table 1 benchmark application descriptions bench instr loads value addr prod mark mil mil locality loc loc go 548 157 25 28 62 gcc 264 97 compress 35 13 15 37 50 li 956 454 24 23 55 tomcatv 2687 772 43 48 66 su2cor hydro2d 967 250 mgrid 4422 1625 42 several approaches improving processing memory operations exploiting regularity reference stream regularity found stream values loaded memory effective address calculations performed dependence chains created store load instructions table 1 shows regularity found differing characteristics memory traffic first three column show benchmark name total number instructions executed total number loads forth column shows percentage load executions con stant near constant values percentage shown often load instruction fetches data value two successive executions measure value locality shown table surprising number load instruction executions bring values last time averaging 29 spec integer benchmarks 44 specfp benchmarks surprising much regularity exists value reuse percentages cover third loads column 5 shows percentage load executions reference effective address last time shows regularity effective address reuse final column shows percentage time producer value remains unchanged successive instances load instruction means store instruction generated data load see relationship far stable even values transferred change different memory location used transfer relationship sourcing store load remains stable statistics led us use dependence pairings store load instructions identify speculation would profitable 4 experimental pipeline design support memory renaming pipeline must extended identify storeload communication pairs promote communications register communication infrastructure verify speculatively forwarded values recover pipeline speculative storeload forward unsuccessful following text detail enhancements made baseline outoforder issue processor pipeline overview extensions processor pipeline loadstore queue entries shown figure 2 41 promoting memory communication registers memory dependence predictor integrated front end processor pipeline de code storeload cache probed stores loads index value file entry assigned dependence edge access hits storeload cache value file index returned propagated rename stage otherwise entry allocated storeload cache instruction addition value file entry allocated index entry stored storeload cache may seem odd allocate entry load value file however found simulations beneficial optimization promotes constants rarely stored variables value file permitting accesses also benefit faster accurate communication synchronization addition decode stage holds confidence counters renamed loads counters incremented loads sourcing stores predicted correctly decremented reset predicted incorrectly rename stage pipeline loads use value file index passed decode stage access entry value file value file returns either value last stored predicted dependence edge value process computed ie flight loadstore queue reservation station index returned reservation station index returned load stall sourcing store data written stores reservation station renamed load completes broadcasts result dependent instructions register memory scheduler operate speculative load result without modification loads speculative otherwise access memory system renamed loads value returns memory system compared predicted value values match load data misspeculation occurred pipeline recovery initiated unlike loads store instructions access value file retirement time stores deposit store data value file memory sys tem later renamed loads reference value able access directly value file attempt made maintain coherence value file main memory contents diverge due example external dmas pipeline continue operate correctly incoherence detected renamed load values compared actual memory contents initial binding stores loads created load renamed references data produces renamed store explored two approaches detecting new dependence edges simplest approach looks renamed stores forward loads loadstore queue forwarding network ie communications instructions flight edges detected storeload cache entry loads updated accordingly slightly capable approach attach value file indices renamed store data propagate indices memory hierarchy approach performs better detect longerlived dependence edges however extra storage value file indices makes approach expensive 42 recovering misspeculations renamed load injects incorrect value program computation correct program execution requires minimally instructions used incorrect value dependent instructions reexecuted end explored two approaches recovering pipeline data misspeculations squash reexecution recovery two approaches exhibit varying cost complexity later see lower cost misspeculation recovery mechanisms enable higher levels performance since permit pipeline promote memory communication register infrastructure squash recovery expensive performance penalty simplest approach implement approach works throwing away instructions misspeculated load instruction since dependent instructions follow load instruction restriction dependent instructions reexecuted indeed met unfortunately approach decode rename schedule writeback loadstore queue entry storeload cache value id conf rename writeback value file lsq entry lru opt value id schedule lru logic resv stations loads stores insts speculative forwards resv stations loadstore queue ld pred ldd st std loadstore data stdldd faults loadstore address value file index loadstore queue ld pred ldd st std speculative std forward result nonspeculative ldd lsq mem pred nonspec recover loadstore addrs commit loadstore queue ld pred ldd st std memory system value file figure 2 pipeline support memory renaming shown additions made baseline pipeline support memory renaming solid edges writeback stage represent forwarding reservation stations dashed lines represent forwarding loadstore queue also shown fields added shown gray instruction reorder buffer entries throw away many instructions independent mis speculated load result requiring many unnecessary executions advantage approach requires little support implemented today misspeculated loads may treated misspeculated branches reexecution recovery complex significantly lower cost squash recovery approach leverages dependence information stored reservation stations notyet retired instruction permit reexecution instructions dependent speculative load value cost approach added pipeline complexity implemented reexecution injecting correct result misspeculated loads onto result bus dependent instructions receiving correct load result reexecute rebroadcast results forcing dependent instructions reexecute since nontrivial instruction know many operands regenerated execution instruction may possibly reexecute multiple times every regenerated operand arrives addition dependencies memory may require load instructions reexecute accommodate dependencies loadstore queue also rechecks memory dependencies stores reexecute reissuing dependent load instructions additionally loads may forced reexecute receive new address via instruction reexecution retirement reexecuted instruction oldest instruction machine thus cannot receive regenerated values instruction may safely retired section 5 demonstrate simulation reexecution much less expensive approach implementing load misspeculation recovery 5 experimental evaluation evaluated merits memory renaming designs extending detailed timing simulator support proposed designs examining performance programs running extended sim ulator varied confidence mechanism misspeculation recovery mechanism key system parameters see affect parameters performance 51 methodology baseline simulator detailed table 2 simplescalar simulation suite simulator simoutorder 3 simulator executes userlevel instructions performing detailed timing simulation 4way superscalar microprocessor two levels instruction data cache memory simulator implements outoforder issue execution model simulation executiondriven including execution speculative path detection fault tlb miss misprediction model employs 256 entry reorder buffer implements renamed register storage holds results pending structions loads stores placed 128 entry loadstore queue baseline simulator stores execute operands ready values spec ulative placed loadstore queue loads may execute prior store addresses computed values come matching earlier store store queue ie store forward data cache speculative loads may initiate cache misses address hits tlb load subsequently squashed cache miss still com plete however speculative tlb misses per mitted speculative cache access misses tlb instruction dispatch stalled instruction detected tlb miss squashed committed cycle reorder buffer issues 8 ready instructions commits 8 results inorder architected register file stores committed store value written data cache data cache modeled fourported 32k twoway setassociative nonblocking cache found early instruction fetch bandwidth critical performance bottleneck mitigate problem implemented limited variant collapsing buffer described 4 implementation supports two predictions per cycle within instruction cache block provides significantly instruction fetch bandwidth better pipeline resource utilization selecting benchmarks looked programs varying memory system performance ie programs large small data sets well high low reference locality analyzed 10 programs spec95 benchmark suite 6 integer codes 4 floating point suite memory renaming experiments performed 1024 entry 2way set associative storeload cache 512 entry value file lru replacement detect initial dependence edge bindings propagate value file indices renamed store data toplevel data cache loads renamed access renamed store data value file index stored data cache used update loads storeload cache entry 1 52 predictor performance figure 3 shows performance memory dependence predictor graph shows hit rate 1 due space restrictions omitted experiments explore predictor performance sensitivity structure sizes structure sizes selected eliminates capacity problems predictor allowing us concentrate effectively leverage predictions improve program performance 10305070cc1 comp go hydro2d mgrid su2cor tomcatv hit rate hit rate figure 3 memory dependence predictor performance memory dependence predictor benchmark hit rate computed number loads whose sourcing store value correctly identified probing value file predictor works quite well predicting correctly many 76 pro grams memory dependencies average 62 programs unlike many value predictor mechanisms 8 dependence predictors work well even better floating point programs better understand dependence predictor finding dependence locality broke correct predictions segment reference data resided figure 4 shows breakdown correct predictions data residing global stack heap segments large fraction correct dependence predictions much 70 mgrid 41 overall average came stack references result surprising considering frequency stack segment references semistatic na ture ie loads stores stack often reference variable many times later leverage property improve performance confidence mechanisms global accesses also account many correct predictions much 86 tomcatv 43 overall average finally significant number correct predictions come heap seg ment much 40 go 15 overall average better understand aspects program resulted correct predictions profiled top loads examined sourcing stores found number common cases heap accesses exhibited dependence locality examples typical program constructs challenge even sophisticated register allocators result significant advances compiler technology eliminate memory accesses assertion holds global ac fetch interface fetches 4 instructions two cache block per cycle separated two branches instruction cache 32k 2way setassociative latency branch predictor 8 bit global history indexing 4096 entry pattern history table gap 11 2bit saturating counters 8 cycle misprediction penalty outoforder issue outoforder issue 8 operations per cycle 256 entry reorder buffer 128 entry mechanism loadstore queue loads may execute prior store addresses known architected registers floating point functional units 8integer alu 4loadstore units 4fp adders 1integer multdiv 1fp multdiv functional unit latency integer alu11 loadstore21 integer mult31 integer div1212 fp adder21 data cache 32k 2way setassociative writeback writeallocate latency fourported nonblocking interface supporting one outstanding miss per physical register 4way setassociative unified l2 cache 64 byte blocks virtual memory 4k byte pages fixed tlb miss latency earlierissued instructions complete table 2 baseline simulation model 10 20 30 40 50 70 80 90 100 cc1 comp go hydro2d mgrid su2cor tomcatv breakdown segment global stack heap figure 4 predictor hits memory segment repeated accesses aliased data cannot allocated registers ffl accesses loop data loop dependence distance one 3 ffl accesses singleinstance dynamic storage eg variable allocated beginning program pointed immutable global pointers discussed section 3 pipeline implementation also benefit confidence mechanism figure 5 shows results experiments exploring efficacy attaching confidence counters load instruc cesses compiler must assume aliased stack accesses hand effectively register allocated thereby eliminating memory accesses given processor enough registers 3 note since always predict sourcing store last previous one predictors work loop dependence distances greater one even regular accesses support cases currently investigation tions graphs show confidence coverage number predictors confidence success rate highconfidence loads coverage fraction correctly predicted loads without confidence covered highconfidence predictions particular predictor confidence coverage shown 6 pre dictors notation used follows xyz x count must reached predictor considers load highconfidence load default count incremented one predictor correctly predicts sourcing store value reset zero predictor fails count increment used opcode load indicates access stack pointer z count increment used opcode load indicates access global pointer analyses showed stack global accesses well behaved thus increase coverage without sacrificing much confidence incrementing confidence counters value greater one shown figure 5 confidence high configurations examined much 9902 hydro2d least 6922 experiments use confidence mechanisms experiments tried increasing increments stack global accesses half confidence counter performed best configuration usually degrades confidence baseline case increment one accesses coverage improved enough improve program performance coverage varies significantly number programs eg compress hydro 2d high coverage others cc1 perl gain higher coverage significant amount confidence sacrificed another interesting feature confidence measurements relative insensitivity coverage counter threshold confidence thresholds levels rise 2 rein 4coverage loads cc1 comp go perl hydro2d507090000 111 211 411 422 844 confidence loads cc1 comp go perl hydro2d figure 5 confidence coverage predictors confidence counters 2261014cc1 comp go hydro2d mgrid su2cor tomcatv sq422 sq844 re422 re211 figure performance varied predic torrecovery configuration forces earlier observation memory dependencies program relatively static occur times often occur fashion much program execution 53 pipeline performance predictor hit rates insufficient tool evaluating usefulness memory dependence predictor order fully evaluate must integrate modern processor pipeline leverage predictions produces correctly handle cases predictor fails figure 6 details performance memory dependence predictor integrated baseline outoforder issue performance simulator experiment figure shows speedup percent measured cycles execute entire program respect baseline simulator four experiments shown benchmark figure 6 first experiment labeled sq422 shows speedup found dependence predictor utilizing 422 confidence configuration squash recovery load misspeculations experiment sq844 experiment except 844 confidence mecha nism re422 configuration employs 422 confidence configuration utilizes reexecution mechanism described section 3 recover load mis speculations finally re211 configuration also employs reexecution recovery mechanism utilizes lowerconfidence 211 confidence configuration configuration squash recovery 422 confidence mechanism ie sq422 shows small speedups many programs falls short others cc1 saw slowdown 5 little investigations slowdowns quickly revealed highcost squash recovery ie throwing away instructions misspeculated load often completely outweighs benefits memory renaming many programs data misspeculations branch mispredictions one remedy highcost misspeculation permit renaming higher confidence loads experiment labeled sq844 renames higherconfidence loads configuration performs better suffers less misspeculation however exper iments eg cc1 show little speedup still plagued many highcost load mis speculations better remedy high misspeculation recovery costs lower cost misspeculation recovery mech anism experiment labeled re422 adds reexecution support pipeline memory renaming support 422 confidence mechanism design lower misspeculation costs allowing show speedups experiments run much 14 m88ksim average overall speedup 6 confirm intuitions lower cost reexecution measured directly cost squash recovery reexecution runs counting number instructions thrown away due load misspeculations found overall reexecution consumes less 13 execution bandwidth required squash recovery words less 13 instructions flight load misspeculation dependent misspeculated load average additionally reexecution benefits refetch decode issue instructions misspeculated load given lower cost cost reexecution explored whether speedups would improved also renamed lowerconfidence loads experiment labeled re211 employs reexecution recovery lowerconfidence 211 confidence configuration configuration found better performance experiments supporting benefits reexecution also explored use yet even lowerconfidence 111 noconfidence 000 config urations however misspeculation rates rise quickly configurations performance suffered accordingly experiments figure 7 takes bestperforming configuration ie re211 varies two key system parameters see effect efficacy memory renaming first experiment labeled fe2 cuts peak instruction delivery bandwidth fetch stage half configuration deliver four instructions one basic block per cycle many experiments cuts average instruction delivery bw nearly half shown results effects memory renaming severely attenuated half instruction delivery bandwidth machine becomes fetch bottlenecked many experiments fetch bottlenecked improving execution performance memory renaming little improve performance program especially true integer codes fetch bandwidth limited due many small basic blocks second experiment figure 7 labeled sf3 increases store forward latency threefold three cy cles store forward latency minimumlatency cycles two operations communicate value memory baseline experiments figure 6 minimum store forward latency one cycle shown graph performance improvements due renaming rise sharply much 41 m88ksim 16 overall sharp rise due increased latency communicationthrough memory latency must cc1 comp go hydro2d mgrid su2cor tomcatv figure 7 program performance varied system configuration tolerated consumes precious parallelism renamed memory accesses however may communication register file potentially zero cycles via bypass resulting significantly lower communication latencies given complexity loadstore queue dataflow analysis requirement performed one cycle onecycle store forwards since addresses computation may arrive previous cycle designers may soon resort larger loadstore queues longer latency store forwards trend make memory renaming attractive fitting conclusion evaluation grade goal set forth beginning paper build renaming mechanism maps memory communication register communication synchronization infrastructure hoisting memory communication registers permits accurate faster memory communication see successful goal measured breakdown communication handled loadstore queue data cache memory communications handled loadstore queue handled flight thus communication benefit renaming figure 8 shows benchmark fraction references serviced loadstore queue base configu ration labeled base fraction references serviced loadstore queue pipeline renaming support labeled re422 shown figure significant amount communication handled register communication frastructure clearly much shortterm communication able benefit renamer support however number benchmarks eg cc1 xlisp tomcatv still nontrivial amount cc1 comp go hydro2d mgrid su2cor tomcatv loads base re422 figure 8 percent memory dependencies serviced loadstore queue shortterm communication identified dependence predictor programs execution benefits loadstore queues ability quickly compute loadstore dependencies addresses available one goal work improve performance dependence predictor virtually shortterm communication captured highconfidence predictions continue improve performance memory communication goal attained performance loadstore queue become less important overall program performance sult less resources devoted loadstore queue design implementation 6 conclusions paper described new mechanism designed improve memory performance accomplished restructuring processor pipeline incorporate speculative value dependence predictor enable load instructions proceed much earlier pipeline introduce prediction confidence mechanism based storeload dependence history control speculation value file containing load store data efficiently accessed without performing complex address calculations simulation results validate approach improving memory performance showing average application speedup 16 intend extend study number ways obvious extension work identify new mechanisms improve confidence mechanism increase applicability scheme load instructions exploring integrating control flow information confidence mecha nism another architectural modification improve efficiency squashing instructions effected misprediction starting become important branch prediction becomes important value prediction lower confidence mechanism also number instructions directly effected misprediction load value less branch prediction allowing greater benefit improvement identifying instructions need squashed acknowledgments finally would like acknowledge help haitham akkary offered numerous suggestions greatly improved quality work also grateful intel corporation support research intel technology education 2000 grant r intel boosts pentium pro 200 mhz evaluating future microprocessors simplescalar tool set optimization instruction fetch mechanisms high issue rates reducing memory traffic cregs mips risc architecture value locality load value prediction dynamic speculation synchronization data dependences performance potential data dependence speculation collapsing tr mips risc architectures twolevel adaptive training branch prediction reducing memory traffic cregs optimization instruction fetch mechanisms high issue rates zerocycle loads value locality load value prediction performance potential data dependence speculation myampersandamp collapsing dynamic speculation synchronization data dependences lookahead processors ctr adi yoaz mattan erez ronny ronen stephan jourdan speculation techniques improving load related instruction scheduling acm sigarch computer architecture news v27 n2 p4253 may 1999 daniel ortega eduard ayguad mateo valero dynamic memory instruction bypassing proceedings 17th annual international conference supercomputing june 2326 2003 san francisco ca usa benchung cheng daniel connors wenmei w hwu compilerdirected early loadaddress generation proceedings 31st annual acmieee international symposium microarchitecture p138147 november 1998 dallas texas united states george z chrysos joel emer memory dependence prediction using store sets acm sigarch computer architecture news v26 n3 p142153 june 1998 andreas moshovos gurindar sohi speculative memory cloaking bypassing international journal parallel programming v27 n6 p427456 1999 daniel ortega mateo valero eduard ayguad dynamic memory instruction bypassing international journal parallel programming v32 n3 p199224 june 2004 gokhan memik mahmut kandemir arindam mallik load elimination lowpower embedded processors proceedings 15th acm great lakes symposium vlsi april 1719 2005 chicago illinois usa jinsuo zhang predictability load address acm sigarch computer architecture news v29 n4 september 2001 matt yourst kanad ghose incremental commit groups nonatomic trace processing proceedings 38th annual ieeeacm international symposium microarchitecture p6780 november 1216 2005 barcelona spain anastas misev marjan gusev visual simulator ilp dynamic ooo processor proceedings 2004 workshop computer architecture education held conjunction 31st international symposium computer architecture june 19 2004 munich germany sanjay jeram patel marius evers yale n patt improving trace cache effectiveness branch promotion trace packing acm sigarch computer architecture news v26 n3 p262271 june 1998 vlad petric anne bracy amir roth three extensions register integration proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey dean tullsen john seng storageless value prediction using prior register values acm sigarch computer architecture news v27 n2 p270279 may 1999 enric morancho jos mara llabera ngel oliv comparison two policies issuing instructions speculatively journal systems architecture euromicro journal v53 n4 p170183 april 2007 jian huang david j lilja extending value reuse basic blocks compiler support ieee transactions computers v49 n4 p331347 april 2000 andreas moshovos gurindar sohi readafterread memory dependence prediction proceedings 32nd annual acmieee international symposium microarchitecture p177185 november 1618 1999 haifa israel glenn reinman brad calder dean tullsen gary tyson todd austin classifying load store instructions memory renaming proceedings 13th international conference supercomputing p399407 june 2025 1999 rhodes greece daniel ortega mateo valero eduard ayguad novel renaming mechanism boosts software prefetching proceedings 15th international conference supercomputing p501510 june 2001 sorrento italy jos gonzlez antonio gonzlez potential data value speculation boost ilp proceedings 12th international conference supercomputing p2128 july 1998 melbourne australia tingting sha milo k martin amir roth scalable storeload forwarding via store queue index prediction proceedings 38th annual ieeeacm international symposium microarchitecture p159170 november 1216 2005 barcelona spain stephen jourdan ronny ronen michael bekerman bishara shomar adi yoaz novel renaming scheme exploit value temporal locality physical register reuse unification proceedings 31st annual acmieee international symposium microarchitecture p216225 november 1998 dallas texas united states amir roth andreas moshovos gurindar sohi dependence based prefetching linked data structures acm sigops operating systems review v32 n5 p115126 dec 1998 gabriel loh timestamping algorithm efficient performance estimation superscalar processors acm sigmetrics performance evaluation review v29 n1 p7281 june 2001 stone kevin woley matthew frank addressindexed memory disambiguation storetoload forwarding proceedings 38th annual ieeeacm international symposium microarchitecture p171182 november 1216 2005 barcelona spain peng jihkwon peir qianrong konrad lai addressfree memory access based program syntax correlation loads stores ieee transactions large scale integration vlsi systems v11 n3 p314324 june tingting sha milo k martin amir roth nosq storeload communication without store queue proceedings 39th annual ieeeacm international symposium microarchitecture p285296 december 0913 2006 glenn reinman brad calder predictive techniques aggressive load speculation proceedings 31st annual acmieee international symposium microarchitecture p127137 november 1998 dallas texas united states craig b zilles gurindar sohi understanding backward slices performance degrading instructions acm sigarch computer architecture news v28 n2 p172181 may 2000 pedro marcuello antonio gonzlez jordi tubella speculative multithreaded processors proceedings 12th international conference supercomputing p7784 july 1998 melbourne australia sangyeun cho penchung yew gyungho lee access region locality highbandwidth processor memory system design proceedings 32nd annual acmieee international symposium microarchitecture p136146 november 1618 1999 haifa israel v krishna nandivada jens palsberg efficient spill code sdram proceedings international conference compilers architecture synthesis embedded systems october 30november 01 2003 san jose california usa andreas moshovos gurindar sohi reducing memory latency via readafterread memory dependence prediction ieee transactions computers v51 n3 p313326 march 2002 sangyeun cho penchung yew gyungho lee decoupling local variable accesses wideissue superscalar processor acm sigarch computer architecture news v27 n2 p100110 may 1999 j gonzlez gonzlez controlflow speculation value prediction ieee transactions computers v50 n12 p13621376 december 2001 sangyeun cho penchung yew gyungho lee highbandwidth memory pipeline wide issue processors ieee transactions computers v50 n7 p709723 july 2001 lieven eeckhout koen de bosschere quantifying behavioral differences multimedia generalpurpose workloads journal systems architecture euromicro journal v48 n67 p199220 january