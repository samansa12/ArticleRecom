optimal algorithm monte carlo estimation typical approach estimate unknown quantity mu design experiment produces random variable z distributed 01 ezmu run experiment independently number times use average outcomes estimate paper consider case priori information z known except distributed 01 describe approximation algorithm cal acal given epsilon delta running independent experiments respect z produces estimate within factor 1epsilon mu probability least 1delta prove expected number experiments run cal acal depends z optimal within constant factor every z b introduction choice experiment experimental design forms important aspect statistics one simplest design problems problem deciding stop sampling example suppose z independently identically distributed according z interval 0 1 mean z bernsteins inequality know n fixed proportional ln1ffiffl 2 probability least approximates z absolute error ffl often however z small good absolute error estimate z typically poor relative error approximation z say z ffl ffiapproximation z engineering computer science applications often desire ffl ffiapproximation z problems exact computation z nphard example many researchers devoted substantial effort important difficult problem approximating permanent valued matrices 1 4 5 9 10 13 14 researchers also used ffl ffiapproximations tackle many difficult problems approximating probabilistic inference bayesian networks 6 approximating volume convex bodies 7 solving ising model statistical mechanics 11 solving network reliability planar multiterminal networks 15 16 approximating number solutions dnf formula 17 generally gf2 formula 18 approximating number eulerian orientations graph 19 let oe 2 z denote variance z define first prove slight generalization zeroone estimator theorem 12 15 16 17 new theorem generalized zeroone estimator theorem proves z 1 sn ffl ffiapproximation z apply generalized zeroone estimator theorem require values unknown quantities z oe 2 z researchers circumvent problem computing upper bound ae z 2 z using place ae z 2 z determine value n equation 1 priori upper bound ae z 2 z close ae z 2 z often difficult obtain poor bound leads prohibitive large bound n avoid problem encountered generalized zeroone estimator theo rem use outcomes previous experiments decide stop iterating approach known sequential analysis originated work wald statistical decision theory 22 related research applied sequential analysis specific monte carlo approximation problems estimating number points union sets 17 estimating number selfavoiding walks 20 related work dyer et al describe stopping rule based algorithm provides upper bound estimate z 8 probability estimate 1 estimate arbitrarily smaller challenging case small first describe approximation algorithm based simple stopping rule using stopping rule approximation algorithm outputs ffl ffiapproximation z expected number experiments proportional upsilon z variance random variable z maximized subject fixed mean z z takes value 1 probability z 0 probability case oe 2 expected number experiments run stoppingrule based algorithm within constant factor optimal general however oe z significantly smaller z small values oe 2 z stoppingrule based algorithm performs 1ffl times many experiments optimal number describe powerful algorithm aa algorithm inputs ffl ffi independently identically distributed outcomes z generated random variable z distributed 0 1 outputs ffl ffiapproximation z expected number experiments proportional upsilon delta ae z 2 z unlike simple stoppingrule based algorithm prove z aa runs optimal number experiments within constant factor specifically prove bb algorithm produces ffl ffiapproximation z using inputs ffl ffi z 1 runs expected number experiments proportional least upsilon delta ae z 2 z canetti evan goldreich prove related lower bound omegagammand 1ffiffl 2 number experiments required approximate z absolute error ffl probability least 1 gamma ffi 2 thus show random variable z aa runs expected number experiments within constant factor minimum expected number aa algorithm general method optimally using outcomes montecarlo experiments approximationthat within constant factor algorithm uses minimum possible number experiments output ffl ffiapproximation problem instance thus aa provides substantial computational savings applications employ poor upper bound ae z 2 z example best known priori bound problem approximating permanent size n superpolynomial n 13 yet many problem instances size n number experiments run aa significantly smaller bound examples exist bounds also extremely loose many typical problem instances 7 10 11 applica tions expect aa provide substantial computational savings possibly render problems intractable poor upper bounds ae z 2 z amenable efficient approximation approximation algorithm subsection 21 describe stopping rule algorithm estimating z algorithm used first step approximation algorithm aa describe subsection 22 21 stopping rule algorithm let z random variable distributed interval 0 1 mean z let z independently identically distributed according z stopping rule algorithm input parameters ffl ffi initialize n 0 0 output stopping rule theorem let z random variable distributed 0 1 z estimate produced let nz number experiments stopping rule algorithm runs respect z input ffl ffi proof theorem found section 5 22 approximation algorithm aa ffl ffiapproximation algorithm aa consists three main steps first step uses stopping rule based algorithm produce estimate z within constant factor z probability least 1 gamma ffi second step uses value z set number experiments run order produce estimate ae z within constant factor ae probability least 1 gamma ffi third step uses values z ae z produced first two steps set number experiments runs number experiments produce ffl ffiestimate z z let z random variable distributed interval 0 1 mean z variance z let z two sets random variables independently identically distributed according z approximation algorithm aa input parameters ffl ffi 1 run stopping rule algorithm using z parameters fflg ffi3 produces estimate z z step 2 set z initialize 0 ae z maxfsn ffl z g step 3 set ae z 2 z initialize 0 z sn output z aa theorem let z random variable distributed 0 1 let mean z oe 2 z variance z ae g let z approximation produced aa let nz number experiments run aa respect z input parameters ffl ffi 2 universal constant c 0 prnz c 0 upsilon 3 universal constant c 0 enz z prove aa theorem section 6 3 lower bound algorithm aa able produce good estimate z using priori information z interesting question inherent number experiments needed able produce ffl ffiapproximation z section state lower bound number experiments needed ffl ffiapproximation algorithm estimate z priori information z lower bound shows within constant factor aa runs minimum number experiments every random variable z formalize lower bound introduce following natural model let bb algorithm input ffl ffi works follows respect z let z independently identically distributed according z values interval 0 1 bb runs experiment n th run bb receives value zn measure running time bb number experments runs ie time computations performed bb counted running time bb allowed use criteria wants decide stop running experiments produce estimate particular bb use outcome previous experiments estimate bb produces stops function outcomes experiments run point requirement bb produces ffl ffiapproximation z z model captures situation algorithm gather information z running random experiments algorithm priori knowledge value z starting reasonable pair assumptions practical situations turns assumption priori knowledge substantially relaxed algorithm may know priori outcomes generated according known random variable z closely related random variable z 0 still lower bound number experiments applies note approximation algorithm aa fits model thus average number experiments runs respect z minimal z within constant factor among approximation algorithms lower bound theorem let bb algorithm works described input ffl ffi let z random variable distributed 0 1 let z mean z oe 2 z variance z ae g let z approximation produced bb let nz number experiments run bb respect z suppose bb following properties 1 z z 0 enz 2 z z 0 universal constant c 0 z enz z prove theorem section 7 4 preliminaries proofs begin notation used hereafter let fixed ff fi 0 define random variables main lemma use prove first part stopping rule theorem provides bounds probabilities random variables k greater zero first form sequences random variables e di real valued prove sequences supermartingales 0 1 z ie k 0 similarly use properties supermartingales bound probabilities random k greater zero subsequent proofs use following two inequalities inequality 41 ff e ff inequality 42 let 72 ff jffj 1 lemma 43 jdj 1 ee dz z proof observe ee dz inequality 42 taking expectations applying inequality 41 completes proof 2 lemma 44 0 1 fi doe 2 z sequences random variables supermartingales proof k 1 thus similarly k 1 thus lemma 43 thus fi doe 2 z directly properties conditional expectations martingales lemma 45 j supermartingale lemma key proof first part stopping rule theorem addition lemma easily prove slightly general version zeroone estimator theorem lemma 46 fixed n 0 fi 2ae z gamman gamman proof recall definitions n equations 3 4 let lefthand side equation 5 equivalent pri lefthand side equation 6 equivalent pri gamma n 0gamma n give remainder proof equation 5 using 0 n omit remainder analogous proof equation 6 uses 0gamma n place 0 n implies 1 note also since ae z oe 2 z thus lemma 44 e di 0 n supermartingale thus lemma 45 ee di 0 gamman since e di 0 0 constant ee di 0 completing proof equation 5 2 use lemma 46 generalize zeroone estimator theorem 17 f0 1gvalued random variables random variables interval 0 1 generalized zeroone estimator theorem let z variables independent identically distributed according z ffl 1 pr proof proof follows directly lemma 46 using noting ffl z 2ae z n delta ffl z 5 proof stopping rule theorem next prove stopping rule theorem first part proof also follows directly lemma 46 recall stopping rule theorem let z random variable distributed 0 1 z estimate produced let nz number experiments stopping rule algorithm runs respect z input ffl ffi proof part 1 recall suffices show first show prnz upsilon 1 z 1 ffl ffi2 let assuming z 1 definition upsilon 1 l implies since nz integer nz nz l nz l sl upsilon 1 thus noting ffl z fi 2ae z lemma 46 implies using inequality 7 noting ae z z follows ffi2 proof prnz upsilon 1 z proof part 2 random variable nz stopping time using walds equation 22 enz thus similar proof first part stopping rule theorem show therefore probability least 1 gamma ffi2 require 1 experiments generate approximation following lemma used proof aa theorem section 6 stopping rule lemma proof stopping rule lemma e1 z directly part 2 stopping rule theorem definition nz e1 2 easily proved based ideas used proof part 2 stopping rule theorem 2 6 proof aa theorem aa theorem let z random variable distributed 0 1 let z mean z oe 2 z variance z ae g let z approximation produced aa let nz number experiments run aa respect z input parameters ffl ffi 2 universal constant c 0 prnz c 0 upsilon 3 universal constant c 0 enz z proof part 1 stopping rule theorem step 1 aa z ffl holds probability least 1 gamma ffi3 let show next z ffl step 2 choice upsilon 2 guarantees ae z ae z 2 thus steps 1 2 phi ae z 2 z probability least 1 gamma ffi3 generalized zeroone estimator theorem ae z 2 ae z 2 z step 3 guarantees output z aa satisfies prz let observe z first assume z oe 2 fflffl z generalized zeroone estimator theorem 21 gamma experiments ae z 2 sn 3ae z 2 probability least 1 gamma 2ffi3 thus ae z ae z 2 ffl z oe 2 fflffl z ffl z oe 2 ffl therefore ae z ffl z ae z 2 next assume oe 2 steps 1 2 guarantee ae z ffl ffl probability least 1 gamma ffi3 proof part 2 aa may fail terminate oupsilon delta ae z 2 experiments either step 1 failed probability least ffi2 produce estimate z z 1 gamma ffl step 2 oe 2 fflffl z sn offl z probability least 1 gamma ffi2 equation 8 guarantees step 1 aa terminates oupsilon delta ae z 2 probability least 1 gamma ffi2 addition show similarly lemma 46 oe 2 thus n 2upsilon delta ffl z prsn 4ffl z proof part 3 observe stopping rule theorem expected number experiments step 1 oln1ffiffl z stopping rule lemma expected number experiments step 2 oln1ffiffl z finally step 3 observe eae z 2 z ae z z computed disjoint sets independently identically distributed random variables stopping rule lemma z oln1ffi 2 furthermore observe eae z z effl z z thus expected number experiments step 3 oln1ffi 2 7 proof lower bound theorem lower bound theorem let bb algorithm works described input ffl ffi let z random variable distributed 0 1 let z mean z oe 2 z variance z ae g let z approximation produced bb let nz number experiments run bb respect z suppose bb following properties 1 z z 0 enz 2 z z 0 prz universal constant c 0 z enz z let f z x f z 0 x denote two given distinct probability mass continuous case density functions let z independent identically distributed random variables probability density fx let hz denote hypothesis let h z 0 denote hypothesis denote probability reject hz f z let fi denote probability accept h z 0 f z 0 sequential probability ratio test minimizes number expected sample size hz h z 0 among tests error probabilities ff fi theorem 71 states result sequential probability ratio test prove result completeness although similar proofs exist 21 theorem 71 stopping time test hz h z 0 error probabilities ff fi ez ff ff proof independent identically distributed random variables z 1 k stopping time get walds first identity next letomega denote space inputs test rejects hz denotes complement thus definition require similarly require pr z properties expectations show zomega c decompose jomegagamma observe inequality 41 ez iomega pr iomega denotes characteristic function setomegagamma thus since show finally ff similarly show thus ff prove first part lemma similarly proves second part lemma 2 corollary 72 stopping time test hz h z 0 error probabilities ff fi ff proof ff ff ff achieves minimum substitution completes proof lemma 75 proves lower bound theorem oe 2 begin definitions let z use inequality 42 show taking expectations completes proof 2 lemma 74 2doe 2 z denotes derivative respect proof follows directly lemma 73 2 lemma 75 oe 2 proof let denote stopping time test hz h z 0 note z lemmas 73 thus test hz h 0 z use bb input ffl z 1 ffl obtain ffl ffl22 ffl corollary 72 gives lower bound expected number experiments en run bb respect z observe inequality follows lemma 73 let z substitute complete proof 2 prove lower bound theorem holds also oe 2 define density lemma 76 z 14 proof observe e z 0 lemma 77 gammae z proof observe taking expectations completes proof 2 lemma 78 z 14 enz proof let denote stopping time test hz h z 0 lemma 76 since z 1 4 thus test hz h 0 z use bb input ffl z 1 ffl solving ffl obtain ffl ffl8 ffl corollary 72 gives lower bound expected number experiments en run bb respect z next observe lemma 77 gamma z corollary 72 2ffl z substitution completes proof 2 proof lower bound theorem follows lemma 75 lemma 78 2 r hard marry random approximation permanent lower bounds sampling algorithms estimating average optimal algorithm montecarlo estimation extended abstract polytopes permanents graphs large factors approximating permanent graphs large factors optimal approximation algorithm bayesian inference random polynomial time algorithm approximating volume convex bodies mildly exponential time algorithm approximating number solutions multidimensional knapsack problem analysis monte carlo algorithm estimating permanent conductance rapid mixing property markov chains approximation permanent resolved polynomialtime approximation algorithms ising model random generation combinatorial structures uniform distribution mildly exponential approximation algorithm permanent montecarlo algorithm estimating permanent monte carlo algorithms planar multiterminal network reliability problems monte carlo algorithms enumeration reliability problems monte carlo approximation algorithms enumeration problems approximating number solutions gf2 mula number eulerian orientations graph testable algorithms selfavoiding walks sequential analysis sequential analysis tr ctr michael luby vivek k goyal simon skaria gavin b horn wave equation based rate control using multicast round trip time acm sigcomm computer communication review v32 n4 october 2002 ronald fagin amnon lotem moni naor optimal aggregation algorithms middleware journal computer system sciences v66 n4 p614656 1 june fast approximate probabilistically checkable proofs information computation v189 n2 p135159 march 15 2004