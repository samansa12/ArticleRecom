properties quadratic programs convex quadratic constraint paper consider problem minimizing possibly nonconvex quadratic function quadratic constraint point new properties problem particular first part paper show given kkt point global minimizer easy find better feasible point ii strict complementarity holds localnonglobal minimizer second part paper show original constrained problem equivalent unconstrained minimization piecewise quartic merit function using unconstrained formulation give nonconvex case new second order necessary condition global minimizers third part paper algorithmic applications preceding results briefly outlined preliminary numerical experiments reported b introduction paper study problem minimizing general quadratic function q subject ellipsoidal constraint h symmetric positive definite n theta n matrix positive scalar interest problem initially arose context trust region methods solving unconstrained optimization problems fact methods require iteration approximate solution problem 1 qx local quadratic model objective function restricted ellipsoidal region centered around current iterate however recently shown problems structure work partially supported agenzia spaziale italiana roma italy z universita di roma la sapienza dipartimento di informatica e sistemistica via buonarroti 12 italy gruppo nazionale per lanalisi funzionale e le sue applicazioni del consiglio nazionale delle ricerche 1 play important role field unconstrained minimization fact solution problem 1 basis algorithms solving general constrained nonlinear problems eg 3 42 20 27 integer programming problems eg 21 41 22 31 19 many papers devoted point specific features problem 1 among important results necessary sufficient conditions point x global minimizer due gay 12 sorensen 35 characterization uniqueness localnonglobal minimizer due martinez 26 particular structure problem 1 led development algorithms finding global solution first algorithms proposed literature gay sorensen 12 35 sorensen 29 developed algorithm produces approximate global minimizer finite number steps recently proved approximation global solution computed polynomial time see example 39 38 40 41 21 furthermore 28 considered general case allowing problem 1 general quadratic constraint extended results 12 35 29 spite results still interest studying problem 1 fact mentioned growing use problem 1 tool tackling large nonlinear programming problems combinatorial optimization problems leads necessity solving efficiently large scale problems type 1 motivates research theoretical properties problem 1 definition efficient methods locating global minimizers recently interesting algorithms tackling large scale trust region problems proposed 36 34 33 basic idea behind algorithms recast trust region problem term parametrized eigenvalue problem adjust parameter find optimal solution paper point theoretical properties problem 1 par ticular research develops along two lines study new properties karushkuhntucker points equivalence unconstrained minimization problem besides theorical interest results allows us define new classes algorithms solving large scale case trust region problems algorithms use matrixvector product require solution eigenvalue problem iteration see 24 details paper organized follows section 2 recall preliminary results section 3 show given kkt point x global minimizer possible find new feasible point x objective function strictly decreased ie ii strict complementarity condition holds local minimizer hence nonconvex case strict complementarity holds local global minimizers section 4 show one one correspondence kkt points global minimizers problem 1 stationary points global minimizers piecewise quartic merit function therefore problem 1 equivalent unconstrained problem p ir n section 5 exploiting results preceding sections give new second order necessary condition global minimizers problem 1 finally section 6 sketch possible applications results section 3 section 4 defining new classes algorithms solving large scale trust region problems sequel use following notation given vector x 2 ir n denote kxk 2 norm ir n 2 norm n theta n matrix q defined 1g moreover denote 1 2 n eigenvalues q preliminaries without loss generality assume feasible set f defined problem consideration q n theta n symmetric matrix c 2 ir n fact since h positive definite reduce problem 1 form 2 employing transformation refer 25 direct treatment problem 1 lagrangian function associated problem 2 function karushkuhntucker point problem 2 pair x 2 ir n theta ir furthermore say strict complementarity holds kkt pair x well known possible completely characterize global solutions problem 2 without requiring convexity assumption objective function fact following result due gay 12 sorensen 35 holds see also vavasis proposition 21 point x kx k 2 2 global solution problem 2 exists unique 0 pair x satisfies kkt conditions matrix q positive semidefinite q positive definite problem 2 unique global solution moreover martinez 26 gave following characterization localnonglobal minimizer problem 2 proposition 22 exists one localnonglobal minimizer x problem 2 moreover kkt necessary conditions holds 2 two smallest eigenvalues q 3 features kkt points section give new properties kkt points problem 2 interest characterization kkt points due fact general algorithms solution constrained problems converge towards kkt points show number different values objective function take kkt points bounded number negative eigenvalues matrix q first state preliminary result extends one given 38 lemma 31 let b x x kkt pairs problem 2 kkt multiplier qb proof observe function qx rewritten every kkt pair x follows using kkt conditions obtain state following proposition whose proof follows result forsythe golub 11 number stationary values second degree polynomial unit sphere sake completeness give sketch proof proposition 32 exist minf2m points distinct multipliers number negative distinct eigenvalues q proof first observe every kkt point x kxk 2 2 value objective function q constant easily follows lemma 31 observing pairs characterized fact consider values function qx points kxk exists orthogonal matrix v v diag eigenvalues q considering transformation ff write first equation kkt condition 4 premultiplied v follows diag recalling kxk kkt multipliers must satisfy system function g poles gamma2 convex subintervals gamma2 thus exists 2 roots subinterval moreover since 2 one root exteme subinterval eigenvalues positive exists one non negative root eigenvalues negative 2n non negative roots case n negative eigenvalues 2m negative roots hence number solutions system 6 minf2m finally summarizing two cases conclude number distinct kkt multipliers bounded minf2m recalling lemma 31 get directly following corollary corollary 33 number distinct values objective function qx kkt points bounded minf2m 1g state main result section particular show peculiarity problem 2 exploited escape kkt points global solutions sense whenever kkt point x either x global minimizer problem 2 possible compute expression feasible point strictly lower value objective function results appealing computational point view discussed section 6 proposition 34 let x kkt point problem 2 let us define point x following way c x b c x 0 vector z 2 ir n z q z z iz qx qx kxk 2 2 proof case point x still feasible consider case b case kkt conditions hence z vector negative curvature qx therefore every satisfies inequality particular take ff ff kxk 2 2 let us consider case ii let x vector defined follows z consider quadratic function note kxk z negative curvature direction quadratic function lx simple calculation taking account q get iz hence lx lx hence recalling expression 8 write hence get result case ii let us consider case iii let us define vector 0 find value ff negative curvature direction lx x 6 0 proceed case ii fact simple calculation using kkt conditions xj solving quadratic equation respect ff get ff gammac hence proceeding case ii get result introducing point ff ff remark note localnonglobal minimizer corresponds either case kxk case bii preceding proposition shows kkt point x global minimizer possible determine feasible point x qx qx computing direction z z q existence direction guaranteed proposition 21 numerical point view computation expensive task fact obtain direction using example bunchparlett decomposition 2 30 modified cholesky factorizations 10 large scale problem methods based lanczos algorithms 4 last result section investigate regularity property local global minimizers particular focus attention strict complementarity property roughly speaking indicates points really constrained also property interesting algorithmic point view proposition 35 localnonglobal minimizer problem 2 strict complementarity condition holds proof since x local minimizer kkt conditions 4 hold moreover second order necessary conditions require z proposition 22 localnonglobal minimizer furthermore necessarily restrict case since case 0 2 us assume contradiction 4 proposition 22 z x global minimizer proposition 21 exists direction qy 0 second order necessary conditions x 6 0 assume without loss generality us consider point ffy prove sufficiently small values ff point xff feasible produces smaller value objective function thus contradicting assumption local optimality fact hence obtain kxffk 2 2 moreover proposition proposition 21 directly obtain following result proposition 36 nonconvex case every local global minimizer strict complementarity holds unconstrained formulation section show problem 2 equivalent unconstrained minimization problem piecewise quartic merit function general constrained optimization problem transformed unconstrained problem defining continuously differentiable exact penalty function following example approach proposed 6 7 however special case minimization quadratic function box constraints shown 16 23 possible define simpler penalty functions exploiting particular structure problem spirit papers show also problem 2 possible construct particular continuously differentiable penalty function new penalty function takes full advantage peculiarities trust region problem enjoys distinguishing features make unconstrained minimization significantly simpler comparison unconstrained minimization penalty functions proposed 6 7 main properties penalty function proposed section ffl globally exact according definition 7 ffl require shifted barrier term hence defined whole space ffl simple expression piecewise quartic ffl known priori values penalty parameter correspondence constrained problem unconstrained one holds first step definition exact penalty function recall hestenes powellrockafellar augmented lagrangian function 32 18 l x ae given positive parameter according classical approach replace multiplier vector function l x multiplier function yields estimate multiplier vector associated problem 2 function variables x literature different multiplier functions proposed see eg 9 13 6 7 23 however expression multiplier functions given 9 13 6 7 defined origin space define new simpler multiplier function defined whole space ir n whose expression following properties summarized following proposition proposition 41 x continuosly differentiable gradient ii x kkt point problem 2 iii every x 2 ir n x proof part easily follows definition multiplier function 10 regards part ii 4 pair x easy see kxk corresponds exactly definition multiplier function 10 otherwise kxk 2 2 4 imply hence comparing 11 10 let us consider part iii simple calculations 2 basis previous considerations replace vector function l multiplier function x furthermore regards penalty parameter select priori interval suitable values depending problem data q c therefore ready define merit function p l x x q c ae x quadratic function given 10 parameter satisfies following inequality first show immediate properties merit function p proposition 42 p x continuosly differentiable gradient ae ii p x twice continuosly differentiable except points iii p x twice continuosly differentiable neighborhood kkt point x strict complementarity holds iv every x kxk 2 2 p x qx v penalty function p x coercive hence admits global minimizer proof part ii iii directly follows expression penalty function p regards part iv follows classical results penalty functions see theorem 2 7 regards part v want show kxk 1 function p x goes infinity first observe hence sufficiently large values kxk leading term preceding inequality strictly positive since recalling satisfies 13 sufficiently large values kxk assume ae oe simple calculation expression penalty function becomes case following inequalities hold satisfies 13 hence get lim 1 existence global minimizer immediately follows continuity p compactness level sets state first result exactness properties penalty function p since proof technical lenghty report appendix proposition 43 point stationary point p x x x kkt pair problem 2 furthermore point p prove one one correspondence betweeen global minimizers problem 2 global minimizers penalty function p proposition 44 every global minimizer problem 2 global minimizer p x conversely proof proposition 43 penalty function p admits global minimizer obviously stationary point p hence preceding proposition hand x global minimizer problem 2 also kkt point hence preceding proposition implies p x proceed contradiction assume global minimizer x p x global minimizer problem 2 exists point x global minimizer problem 2 contradicts assumption x global minimizer p converse true analogous considerations order complete correspondence solution problem 2 unconstrained minimization penalty function p prove following result considers corrispondence local minimizers proposition 45 function p x admits localnonglobal minimizer x local minimizer problem 2 x associated kkt multiplier proof first prove x local minimizer p x pair x x satisfies kkt conditions problem 2 moreover proposition 43 x local minimizer p exists neighbourhood x thus using iv proposition 42 obtain hence x local minimizer problem 2 proof easily completed recalling proposition 22 5 new second order optimality condition results given section 3 section 4 combined state new theoretical properties problem 2 section introduce new second order necessary optimality condition problem 2 nonconvex case follows unconstrained formulation proposition 51 assume q positive semidefinite x global local minimizer problem 2 exists unique kkt conditions hold 2 2 positive semidefinite every satisfying 13 proof x global minimizer problem 2 proposition 36 exists neighborhood omegagamma x x thus ii proposition 42 function p x twice continuously differentiable omegagamma x hessian matrix evaluated x given 2 proposition 44 x also global minimizer p x therefore x satisfies second order necessary conditions global unconstrained minimizer p positive semidefinite result follows recalling point proposition 34 global minimizer x results hence matrixa 2 2 necessarily positive semidefinite similar second order necessary condition given 1 proved without requiring assumptions matrix q global minimum boundary matrix 2 positive semidefinite matrix 1 2 xxx necessarily positive semidefinite 6 algorithmic application besides theorical interest results preceding sections appealing also computational point view although study numerical algorithm solution problem 2 aim paper section give hint possible algorithmic applications results section 3 section 4 recall proposition 34 ensures given kkt point global solution problem 2 possible find new feasible point lower value objective function proposition 32 states number kkt points different value objective function finite results indicate new possibility tackle large scale trust region problems fact show global minimum point problem 2 could efficiently computed applying finite number times constrained optimization algorithm presents following features given feasible starting point able locate kkt point lower value objective function ii presents good least superlinearly rate convergence iii require heavy computational burden possibility ensure property use feasible method forces decrease objective function following example approach 37 17 another possibility exploit unconstrained reformulation problem 2 described section 4 allows us use unconstrained method minimization penalty function p fact starting point x 0 algorithm obtains stationary point x p proposition 43 ensures x kkt point problem 2 p qx hand x 0 feasible point part iv proposition 42 yields conclusion using unconstrained algorithm get kkt point problem 2 value objective function lower value starting point furthermore possibility transforming trust region problem unconstrained one seems quite appealing also regards properties ii iii fact proposition 36 iii proposition 42 guarantees nonconvex case penalty function twice continuosly differentiable every local global minimizer problem therefore case unconstrained truncated newton algorithm see example 5 37 15 easily adapted order define globally convergent methods show superlinear rate convergence neighbourhood every global local minimizer nevertheless define algorithm superlinear rate convergence without requiring penalty function twice continuosly differentiable neighbourhood points interest without requiring strict complementarity points fact drawn inspiration results 8 particular define search direction k follows z k results 8 ensure algorithm x locally superlinearly convergent without requiring strict complementarity following approach truncated newton method see example 5 15 24 shown approximate solution k 1516 able preserve local superlinear rate convergence algorithmic scheme furthermore also proved direction suitable descent conditions respect penalty function p strict connection direction k penalty function p x allow us define globally superlinearly convergent algorithms type ff k determined every stabilization technique k computed using conjugate gradient based iterative method solving approximately linear system 1516 paper 24 devoted complete description approach analysis theoretical properties definition efficient algorithm order preliminary idea viability unconstrained approach solving problem 2 performed numerical experiments rough implementation algorithm 17 ff k determined linesearch technique 14 k computed conjugate gradient algorithm similar one proposed 5 coded algorithm matlab run experiments ibmrisc 6000 run two sets problems randomly generated take collection 34 solved ten related problems two classes easy hard case according 34 hard case occurs vector c orthogonal subspace generated smallest eigenvalue matrix q table 1 report results terms average number iterations problems increasing dimension run also set near hardcase problems c nearly orthogonal subspace smallest eigenvalue q results first set second set 100 113 219 107 256 table 1 average number iterations near hard case mult min table 2 average number iterations reported table 2 tested invariance respect multiplicity smallest eigenvalue mult results obtained encouraging number iteration almost constant dimension increases feature appealing solving large scale problems taking account iteration main effort due approximate solution linear system dimension n n gamma 1 requires matrixvector products furthermore efficiency algorithm seems seriously affected occurrence hard case completely insensible nearhard case course even final conclusion drawn limited numerical exper iments results obtained encourage research defining new algorithms solving large scale trust region problems use results described paper particular said possibility defining efficient algorithms based unconstrained reformulation investigated 24 acknowledgments wish thank santos sorensen f rendl h wolkowiz providing us matlab codes test problems moreover thank anonymous referees helpful suggestions led improve paper r new optimality conditions algorithms homogeneous polynomial optimization spheres direct methods solving symmetric indefinite systems linear equations computing trust region step penalty function lanczos algorithms large symmetric eigenvalue computation exact penalty method global convergence properties nonlinear programming problems exact penalty functions constrained optimization quadratically superlinear convergent algorithms solution inequality constrained optimization problems class methods nonlinear programming termination convergence properties computing modified newton directions using partial cholesky factorization stationary values seconddegree polynomial unit sphere computing optimal locally constrained steps multiplier method automatic limitation penalty growth nonmonotone line search technique newtons method truncated newton method nonmonotone linesearch unconstrained optimization differentiable exact penalty function bound constrained quadratic programming problems solution two ball trust region subproblem multiplier gradient methods continuous approach compute upper bounds quadratic maximization problems integer constraints fast algorithms convex quadratic programming multicommodity flows interiorpoint approach npcomplete problems interior point algorithm solve computationally difficult set covering problems differentiable piecewise quadratic exact penalty functions quadratic programs simple bound constraints la sapienza la sapienza local minimizers quadratic functions euclidean balls spheres trust region algorithms arbitrary domains generalization trust region problem computing trust region step use directions negative curvature modified newton method algorithms solution quadratic knapsack problems method nonlinear constraints minimization problem semidefinite framework trust region subproblems applications large scale minimization new matrixfree large scale trust region subproblem newtons method model trust region modification minimization large scale quadratic function subject ellipsoidal constraint towards efficient sparsity exploiting newton method minimiza tion nonlinear optimization proving polynomialtime sphereconstrained quadratic programming new complexity result minimization quadratic function sphere constraint affine scaling algorithms nonconvex quadratic programming extension karmarkars projective algorithm convex quadratic programming tr ctr pasquale l de angelis immanuel bomze gerardo toraldo ellipsoidal approach boxconstrained quadratic problems journal global optimization v28 n1 p115 january 2004 g birgin jos mario martnez marcos raydan algorithm 813 spgsoftware convexconstrained optimization acm transactions mathematical software toms v27 n3 p340349 september 2001 immanuel bomze laura palagi quartic formulation standard quadratic optimization problems journal global optimization v32 n2 p181205 june 2005 le thi hoai pham dinh tao branch bound method via dc optimization algorithms andellipsoidal technique box constrained nonconvex quadratic problems journal global optimization v13 n2 p171206 september 1998