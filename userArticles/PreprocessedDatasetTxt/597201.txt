audio partitioning transcription broadcast data indexation work addresses automatic transcription television radio broadcasts multiple languages transcription types data major step developing automatic tools indexation retrieval vast amounts information generated daily basis radio television broadcasts consist continuous data stream made segments different linguistic acoustic natures poses challenges transcription prior word recognition data partitioned homogeneous acoustic segments nonspeech segments identified removed speech segments clustered labeled according bandwidth gender word recognition carried speakerindependent large vocabulary continuous speech recognizer makes use ngram statistics language modeling continuous density hmms gaussian mixtures acoustic modeling system consistently obtained toplevel performance darpa evaluations 500 hours unpartitioned unrestricted american english broadcast data partitioned transcribed indexed average word error 20 current ir technology essentially degradation information retrieval performance automatic manual transcriptions data set b introduction rapid expansion different media sources information dissemination need automatic processing data part todays methods transcription indexation manual humans reading listening watching annotating topics selecting items interest user automation c publishers printed netherlands activities allow information sources covered significantly reduce processing costs eliminating tedious work radio television broadcast shows challenging transcribe contain signal segments various acoustic linguistic natures signal may studio quality transmitted telephone noisy channel ie corrupted additive noise nonlinear distortions contain speech presence background music pure music segments gradual transitions segments occur background music noise changing volume whereas abrupt changes common switching speakers different locations speech produced wide variety speakers news anchors talk show hosts reporters remote locations interviews politicians common people unknown speakers new dialects nonnative speakers etc speech speaker may occur different parts broadcast different channel conditions linguistic style ranges prepared speech spontaneous speech two principle types problems encountered transcribing broadcast news data relating varied acoustic properties signal related linguistic properties speech problems associated acoustic signal properties handled using appropriate signal analyses classifying signal according segment type training specific acoustic models different acoustic conditions process known audio partitioning described next section section 3 describes process automatically transcribing speech data section 4 presents evaluation word transcription quality performance information retrieval system using automatic transcriptions data 1999 trec8 spoken document retrieval task 5 2 data partitioning evidently possible transcribe continuous stream audio data without prior segmentation partitioning offers several advantages straightforward solution first addition audio partitioning transcription broadcast data indexation 3 segmentation energy constraint fewer clusters change segmentation audio stream music background segments chop small segments speechmusicbackgd reestimation bandwidth gender speech partition map gmm clustering 3 gmms segmentation train gmm segment unpartionned figure 1 partitioning algorithm transcription said interesting information extracted division speaker turns speaker identities prior segmentation avoid problems caused linguistic discontinuity speaker changes using acoustic models trained particular acoustic conditions overall performance significantly improved particularly clusterbased adaptation performed finally eliminating nonspeech segments dividing data shorter segments still several minutes long reduces computation time simplifies decoding 4 gauvain lamel adda segmentation labeling procedure introduced 9 shown figure 1 first nonspeech segments detected rejected using gaussian mixture models gmms 64 gaussians serve detect speech puremusic background acoustic feature vector used segmentation contains 38 parameters recognition feature vector described next section except include energy although delta energy parameters included gmms trained 1h acoustic data extracted training data segmentation transcriptions speech model trained data types exception pure music segments silence portions segments transcribed speech music order detect speech noisy conditions second speech gmm trained noisy speech segments model expected match speech seg ments music model trained portions data labeled pure music avoid mistakenly detecting speech music segments silence model trained segments labeled silence forced alignment excluding silences segments labeled containing speech presence background music test segments labeled music silence removed prior processing maximum likelihood segmentationclustering iterative procedure applied speech segments using gmms agglomerative clustering algorithm given sequence cepstral vectors corresponding show goal find number sources homogeneous data modeled pdf fdeltaj k known number parameters places source changes result procedure sequence nonoverlapping segments associated segment cluster labels segment cluster assumed represent one speaker particular acoustic environment absence prior knowledge stochastic process governing k n segment lengths use objective function penalized loglikelihood form audio partitioning transcription broadcast data indexation 5 log fs terms ffn fik seen segment cluster penalties correspond parameters exponential prior distributions n k easy prove starting overestimates n k alternate viterbi reestimation agglomerative clustering gives sequence estimates k non decreasing values objective function viterbi step reestimate n k increase gammaffn ie adding segment penalty ff viterbi search whereas clustering step two clusters merged long resulting loglikelihood loss per merge less fi 1 since merging two models reduce number segments change segment penalty taken account clustering process initialized using simple segmentation algorithm based detection spectral change similar first step used 17 threshold set overgenerate segments roughly 5 times many segments true speaker turns initially cluster set consists cluster per segment followed viterbi training set gmms one 8component gmm per cluster procedure controlled 3 parameters minimum cluster size 10s maximum loglikelihood loss merge ff segment boundary penalty fi merges possible segment boundaries refined using last set gmms additional relative energybased boundary penalty within 1s interval done locate segment boundaries silence portions attempting avoid cutting words sometimes still occurs speakerindependent gmms corresponding wideband speech telephone speech 64 gaussians used identify telephone segments followed segmentbased gender identi fication using 2 sets gmms 64 gaussians one band width result partitioning process set speech segments clustering criterion closely related mdl bic criterion 6 gauvain lamel adda figure 2 spectrograms illustrating results data partitioning sequences extracted broadcasts upper transcript automatically generated segment type speech music noise lower transcript shows clustering results speech segments bandwidth ttelephonebandswideband gender mmaleffemale identification number identifies cluster cluster gender telephonewideband labels illustrated figure 2 evaluated frame level segmentation error similar 11 4 halfhour shows darpa hub4e eval96 test data 4 using manual segmentation found reference transcriptions nist transcriptions test data contain segments scored since contain overlapping foreign speech occasionally small gaps consecutive transcribed segments since consider partitioner also work correctly portions relabeled excluded segments speech music background table itop shows segmentation frame error rate speechnon speech errors 4 shows average frame error 37 much higher show 1 others due long noisy segment deleted averaged across shows gender labeling 1 frame error bottom table shows measures cluster homogeneity first entry gives total number speakers identified clusters per file general clusters speakers cluster represent speaker audio partitioning transcription broadcast data indexation 7 table top speechnonspeech frame segmentation error using nist labels missing excluded segments manually labeled speech nonspeech bottom best cluster coverage show frame error 79 23 33 23 37 spkrsclusters 710 1317 1521 2021 coverage 876 710 780 811 787 given acoustic environment second measure cluster purity defined percentage frames given cluster associated represented speaker cluster similar measure proposed 3 segment level table shows weighted average cluster purities 4 shows average 96 data cluster comes single speaker clusters impure tend include speakers similar acoustic conditions best cluster coverage measure dispersion given speakers data across clusters averaged percentage data speaker cluster hisher data average 80 speakers data goes cluster fact average value bit misleading large variance best cluster coverage across speakers speakers cluster coverage close 100 ie single cluster covers essentially frames data however speakers lot data speaker covered two clusters containing comparable amounts data 3 transcribing partitioned broadcast data speech recognizer uses continuous density hidden markov models cdhmms gaussian mixture acoustic modeling ngram 8 gauvain lamel adda statistics estimated large text corpora language modeling 8 acoustic modeling 39 cepstral parameters derived mel frequency spectrum estimated 08khz band 035khz telephone speech models every 10 ms lpcbased cepstrum coefficients normalized segment cluster basis using cepstral mean removal variance normalization resulting cepstral coefficient cluster zero mean unity variance contextdependent phone model tiedstate lefttoright cdhmm gaussian mixture observation densities tied states obtained means phonemic decision tree genderdependent acoustic models built using map adaptation speakerindependent seed models wideband telephone band speech 6 acoustic models american english trained 150 hours broadcast news data language models lms obtained interpolation backoff ngram language models trained different data sets broadcast news transcriptions north american business newspapers associated press wordstream texts transcriptions broadcast news acoustic training data interpolation coefficients 4 lms chosen minimize perplexity set development texts recognition vocabulary contains 65122 words lexical coverage 99 development test data pronunciations based 48 phone set 3 used silence filler words breath noises pronunciation graph associated word allow alternate pronunciations including optional phones compound words 300 frequent word sequences subject reduced pronunciations included lexicon well representation frequent acronyms words order address variability observed linguistic properties analyzed differences read spontaneous speech regard lexical items word word sequence pronunciations frequencies distribution hesitations filler words respiration noises result analysis phenomena explicitly modeled acoustic language models described 8 word decoding procedure shown figure 3 prior decod ing segments longer 30s chopped smaller pieces audio partitioning transcription broadcast data indexation 9 chop segments smaller 30s segment cluster variance normalization cepstral mean audio stream final transcription word graph generation mllr adaptation decoding mllr adaptation initial hypotheses generate partition map figure 3 word decoding limit memory required 4gram decoding pass 8 bimodal distribution estimated fitting mixture 2 gaussians logrms power frames segment distribution used determine locations likely correspond pauses thus reasonable places cut segment cuts made probable pause 15s 30s previous cut word recognition performed three steps 1 initial hypothesis generation graph generation final hypothesis generation initial hypothesis used clusterbased acoustic model adaptation using mllr technique 14 prior 2nd 3rd decoding passes final hypothesis generated using 4gram language model first step generates initial hypotheses used clusterbased acoustic model adaptation single pass decoding makes use trigram backoff language model 8m trigrams 17m bi grams genderspecific sets 5416 positiondependent cross word triphones 11500 tied states bandlimited acoustic models used telephone speech segments second decoding step generates accurate word graphs unsupervised acoustic model adaptation means variances performed segment cluster using mllr technique 14 mean vectors adapted using single blockdiagonal regression trix diagonal matrix used adapt variances segment decoded trigram language model adapted version larger set acoustic models 28000 positiondependent cross word triphones 11500 tied states 350k gaussians final hypothesis generated using 4gram language model large set acoustic models adapted hypothesis second decoding step broadcast news transcription systems also developed french german languages partially supported le4 olive project partitioning recognition algorithms successfully applied conjunction languagespecific lexicons acoustic language models french german lexicons represented 37 51 phones respectively including specific phones silence breath fillers acoustic models language trained 20 hours audio data radio television broadcasts trigram backoff language models formed interpolation individual lms estimated transcriptions acoustic training data texts newspapers newswires outofvocabulary oov rate 115 french 65k lexicon 45 german 65k lexicon lower lexical coverages english due large number verb forms number gender agreement french german case declension compounding german audio partitioning transcription broadcast data indexation 11 table ii summary broadcast news transcription word error rates 3 test sets 1996 system used manual partition results automatic partition test set system 18 hours 3 hours 3 hours 1996 system 271 1997 system 253 183 1998 system 198 139 136 4 evaluation section presents evaluation broadcast news transcription system terms transcription accuracy potential using automatic transcription information indexing retrieval 41 speech recognizer word accuracy table ii reports word recognition results darpa evaluation test sets last three years data set contains hours broadcast audio data selected nist 4 commonly used error metric word error rate defined word error substitutions insertions deletions results shown bold official nist scores obtained different systems 1997 system main development effort devoted moving manual automatic partitioning process system nevertheless achieved performance improvement 6 eval96 test data 1998 system 10 accurate acoustic language models achieves relative word error reduction 20 compared 1997 system tests carried without restriction computation time required 100 hours process hour data even though usually assumed processing time major issue since computer processing power increase continuously 2 also known amount data appearing information channels increasing close rate therefore processing time important factor making speech transcription system viable audio data mining transcribing found data requires significantly higher processing power needed transcribed read speech data speaker adapted dictation systems due lack control recordings linguistic content average results lower snr ratios poorer fit acoustic language models data consequence need larger models processing time constraints significantly change way select models operating point right balance model complexity search pruning level must found two fast systems optimized decoding 10 14 times realtime rt including audio par titioning eval98 data set word error rates 142 10xrt system 247 14xrt compaq xp1000 500mhz machine figure 4 shows example portion sgml file created automatically generated word transcription taking account information available partitioning process audio segment starts segment tag start end times well labels signal type gender speaker word transcription given illustration word time codes although shown word level confidence score optionally associated word french german transcription systems evaluated 15 hours data french data come television news shows arte radio station france inter german data consist tv news documentaries arte average word error french data 20 average word error german news data 20 lower error documentaries closer 35 difference partially 2 common practice develop systems run 100 times realtime especially evaluate absolute quality acoustic language models audio partitioning transcription broadcast data indexation 13 audiofile filenamecspanwj960917 languageenglish segment typewideband genderfemale spkr5 stime816 etime842 know mr naders ballot florida segment typetelephone gendermale spkr1 stime8472 etime8609 wtime stime8472 etime8497 wtime stime8497 etime8522 dont wtime stime8522 etime8547 know wtime stime8547 etime8563 im wtime stime8563 etime8609 sorry segment typewideband genderfemale spkr5 stime8609 etime8759 wtime stime8609 etime8621 wtime stime8621 etime8641 wtime stime8641 etime8667 wtime stime8667 etime8679 wtime stime8679 etime8694 wtime stime8694 etime8716 vote wtime stime8716 etime8732 wtime stime8732 etime8759 segment typetelephone gendermale spkr1 stime8759 etime10622 would figure 4 example sgml format system output segment signal type gender speaker labels start end times given well word transcription simplicity time codes shown attributed better language model representivity news data 42 experiments spoken document retrieval one main motivations automatic processing audio channels broadcast data serve basis automatic disclosure indexation information retrieval ir purposes aim 14 gauvain lamel adda olive project 3 develop archiving retrieval system broadcast data enable efficient access large multimedia libraries french ina audiovisual archive 13 disclosure video material plays important role user organizations costly carry manually broadcast data result vast majority data archived minimal annotations audio stream automatically partitioned speech segments transcribed timecoded using methods described transcription used generate index linked appropriate portions audio video data olive also developed tools users query database well crosslingual access based offline machine translation archived documents online query translation assessed performance spoken document retrieval sdr 600 hours audio data 100 hours trec7 sdr98 500 hours trec8 sdr98 although ir purposes story boundaries assumed known information used speech recognizer development work carried using sdr98 test data 100h consisting 2800 documents associated 23 queries sdr99 test data 500h consists 21750 documents associated set 50 queries noted reference transcripts sdr98 data detailed manual transcriptions whereas sdr99 data closed captions order ir system applied different text data types automatic transcriptions closed captions additional texts newspapers newswires documents preprocessed homogeneous manner preprocessing tokenization text source preparation training speech recognizer language models 7 attempts transform closer observed american speaking style basic operations include translating numbers sums words removing punctuation symbols removing case distinctions detecting acronyms 3 le48364 olive project httptwentyonetpdtnonlolive funded european commission telematics application programme sector language engineering audio partitioning transcription broadcast data indexation 15 spelled names however removing punctuations implies certain hyphenated words anticommunist nonprofit rewritten anti communist non profit offers advantages speech recognition lead ir errors avoid ir problems due transformation output tokenizer recognizer checked common prefixes order rewrite sequence words single word prefixes handled include anti co bi counter set rewrite rules covering compound words formed prefixes limited number named entities losangeles used transform texts similarly numbers less one hundred treated single entity twentyseven order reduce number lexical items given word sense word mapped stem defined 2 16 generally form chosen representative semantic family text query may may include index terms associated relevant documents one way cope problem query expansion based terms present retrieved documents blind relevance feedback parallel blind relevance data collections 19 combined two approaches system latter 6 months commercially available broadcast news transcripts period june december 1997 1 used corpus contains 50 000 stories 495 words given query terms found top 15 documents baseline search ranked offer weight 18 top 10 terms added query since terms best offer weights kept terms filtered using stop list 144 common words order increase likelihood resulting terms relevant information retrieval system relies unigram model per story score story obtained summing query term weights log probabilities terms given story model interpolated general english model term weighting shown perform well popular tflambdaidf weighting scheme 12 15 table iii gives ir results terms mean average precision map done trec benchmarks four experimental con figurations reported baseline search base query expansion using blind relevance feedback brf query expansion parallel blind relevance feedback pbrf query expansion using brf pbrf results clearly demonstrate interest using brf pbrf expansion techniques consistent improvements obtained baseline system two conditions r1 s1 average precisions 57 54 respectively obtained sdr98 sdr99 test sets using automatic transcriptions values quite close average precisions obtained manual transcripts even though 10xrt recognizer transcripts estimated 205 word error rate using transcriptions generated system word error rate 32 baseline map 41 map query expansion 49 sdr99 test conditions table iii mean average precision sdr98 data sets using unigram term weightings r1 reference transcript s1 automatic speech transcription obtained 10xrt system dataset base brf pbrf brfpbrf 98s1 4558 5121 5884 5745 99s1 4412 5302 4943 5398 5 conclusions paper presented recent research partitioning transcribing television radio broadcasts necessary steps enable automated processing vast amounts audio video data produced daily basis data partitioning algorithm makes use gaussian mixture models iterative segmentation audio partitioning transcription broadcast data indexation 17 clustering procedure resulting segments labeled according gender bandwidth using 64component gmms speech detection frame error less 4 gender identification frame error 1 many errors occur boundary seg ments involve silence segments considered speech nonspeech without influencing transcription performance word recognition carried multiple passes speech segment progressively using accurate models generation word graphs adapted acoustic models essential obtaining word graphs low word error rates particularly light variety talkers acoustic conditions unrestricted american english broadcast news shows word error rate 20 due availability large transcribed corpora available ldc initial work focused american english however context le4 olive project transcription system system sucessfully ported french german languages word error rates 20 news shows experience radio news shows usually easier transcribe television news shows probably due fact audio channel used transmit information whereas television audio stream supported visual data broadcast news data also easier transcribe documentaries complete indexing system built applying text ir techniques output broadcast news speech recognizer quite comparable average precisions obtained manual reference transcriptions sdr99 data closed captions indicating transcription quality limiting factor performance current ir techniques existing applications could greatly benefit technology creation access digital multimedia libraries dis closure information content contentbased indexation media monitoring services selective dissemination information based automatic detection topics interest well new emerging applications newsondemand internet watch services acknowledgements work partially financed european commission french ministry defense authors gratefully acknowledge participation martine addadecker development recognition systems michele jardino yannick de kercadio remi lejeune patrick paroubek sdr work r environment channel change detection clustering via bayesian information criterion design preparation trec spoken document retrieval track success story maximum posteriori estimation multivariate gaussain mixture observation markov chains limsi nov93 wsj system limsi nov96 hub4 system limsi segment generation clustering htk broadcast news transcription sys audio partitioning transcription broadcast data indexation 19 tem olive speech based video retrieval maximum likelihood linear regression speaker adaptation continuous density hidden markov models bbn trec7 using hidden markov models information retrieval algorithm suffix stripping automatic segmentation probabilistic model information retrieval development status improving subject retrieval online catalogues 2 tr ctr alexander haubold john r kender augmented segmentation visualization presentation videos proceedings 13th annual acm international conference multimedia november 0611 2005 hilton singapore