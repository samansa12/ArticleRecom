direct recovery planarparallax multiple frames abstractin paper present algorithm estimates dense planarparallax motion multiple uncalibrated views 3d scene generalizes planeparallax recovery methods two frames parallax motion pixels across multiple frames relative planar surface related 3d scene structure camera epipoles parallax field epipoles 3d scene structure estimated directly image brightness variations across multiple frames without precomputing correspondences b introduction recovery 3d structure scene camera epipolargeometries camera motion multiple views topic considerable research large majority work structurefrommotion sfm assumed correspondences image features typically sparse set image points given focused problem recovering sfm based input another class methods focused recovering dense 3d structure set dense correspondences optical flow field advantage recovering dense 3d structure require correspondences known however correspondence flow estimation notoriously difficult problem small set techniques attempted combine correspondence estimation step together sfm recovery methods obtain dense correspondences simultaneously estimating 3d structure camera geometries motion 3 11 13 16 15 interweaving two processes local correspondence estimation process constrained current estimate global epipolar geometry camera motion viceversa techniques minimize violation brightness gradient constraint respect unknown structure motion parameters typically leads significant improvement estimated correspondences attendant 3d structure improvement recovered camera geometries motion methods sometimes referred direct methods 3 since directly use image brightness information recover 3d structure motion without explicitly computing correspondences intermediate step 3 16 15 recover 3d information relative cameracentered coordinate system alternative approach proposed recovering 3d structure scenecentered coordinate system particular planeparallax approach 14 11 13 7 9 8 analyzes parallax displacements points relative real virtual physical planar surface scene refer ence plane underlying concept alignment reference plane residual image motion due translational motion camera deviations scene structure planar surface effects camera rotation changes camera calibration eliminated plane stabilization hence residual image motion planarparallax displacements form radial flow field centered epipole planeparallax representation several benefits traditional cameracentered representation make attractive framework correspondence estimation 3d shape recovery 1 reduced search space parametrically aligning visible image structure usually corresponds planar surface scene search space unknowns significantly reduced globally effects unknown rotation calibration parameters folded homographies used patch alignment remaining unknown global camera parameters need estimated epipoles ie 3 global unknowns per frame gauge ambiguity reduced single global scale factor epipoles across frames locally plane alignment unknown displacements constrained lie along radial lines emerging epipoles local correspondence estimation reduces 2d search problem simpler 1d search problem pixel 1d search problem additional benefit uniquely resolve correspondences even pixels suffer aperture problem ie pixels lie line structures 2 provides shape relative plane scene many applications distances camera useful information fluctuations respect plane scene example robot navigation heights scene points ground plane immediately translated obstacles holes used obstacle avoidance opposed distances camera 3 compact representation removing mutual global component plane homography residual parallax displacements usually small hence require significantly fewer bits encode shape fluctuations relative number bits required encode distances camera therefore compact representation also supports progressive encoding high resolution display data 4 stratified 2d3d representation work motion analysis roughly classified two classes techniques 2d algorithms handle cases 3d parallax eg estimating homographies 2d affine transforma tions etc 3d algorithms handle cases dense 3d parallax eg estimating fundamental matrices trifocal tensors 3d shape etc prior model selection 17 usually required decide set algorithms apply depending underlying scenario planeparallax representation provides unified approach 2d 3d scene analysis strategy gracefully bridge gap two extremes 10 within planeparallax framework analysis always starts 2d estimation ie homography estimation information available image sequence analysis stops 3d analysis gradually builds top 2d analysis gradual increase 3d information form planarparallax displacements shapefluctuations wrt planar surface 11 13 used planeparallax framework recover dense structure relative reference plane two uncalibrated views algorithm linearly solves structure directly brightness measurements two frames naturally extend multiple frames paper show dense planarparallax displacements relative structure recovered directly brightness measurements multiple frames furthermore show many ambiguities existing twoframe case 11 13 resolved extending analysis multiple frames algorithm assumes input sequence images planar surface previously aligned respect reference image eg via one 2d parametric estimation techniques 1 6 assume camera calibration information known output algorithm epipoles images respect reference image ii dense 3d structure scene relative planar surface iii correspondences pixels across frames must consistent ii estimation process uses exact equations opposed instantaneous equations 4 15 relating residual parallax motion pixels across multiple frames relative 3d structure camera epipoles 3d scene structure camera epipoles computed directly image measurements minimizing variation image brightness across views without precomputing correspondence map current implementation technique relies prior alignment video frames respect planar surface similar planeparallax methods requires real physical plane exists scene visible video frames however approach extended arbitrary scenes folding plane homography computation also simultaneous estimation camera motion scene structure image displacements done 11 case two frames remainder paper describes algorithm shows performance real synthetic data section 2 shows 3d structure relates 2d image displacement planeparallax decomposition section 3 outlines major steps algorithm benefits applying algorithm multiple frames opposed two frames discussed section 4 section 5 shows results applying algorithm real data section 6 concludes paper 2 planeparallax decomposition induced 2d image motion 3d scene point two images decomposed two components 9 7 10 11 13 14 8 2 image motion reference planar surface pi ie homography ii residual image motion known planar parallax decomposition described set stage algorithm described paper begin derivation planeparallax motion equations shown 10 let denote image location homogeneous coordinates point one view called reference view let coordinates another view let b denote homography plane pi two views let inverse homography b gamma1 3 third row b gamma1 let namely second image warped towards first image using inverse homography b gamma1 point p 0 move point pw warped image 3d points plane pi 3d points plane pw 6 p shown 10 represents 3d structure point p h perpendicular distance height point reference plane pi 1 notation use slightly different one used 10 change projective notation used unify two separate expressions provided 10 one case finite epipole case infinite epipole z depth respect reference camera unknown calibration parameters folded terms parenthesis denotes epipole projective coordinates 3 denotes third component current form expression cannot directly used estimating unknown correspondence pw given pixel p reference image since pw appears sides expression however pw eliminated right hand side expression obtain following expression last expression used direct estimation algorithm 3 multiframe parallax estimation let fphi j g l j0 l 1 images rigid scene taken using cameras unknown calibration parameters without loss generality choose phi 0 reference frame practice usually middle frame sequence let pi plane scene visible l images reference plane using technique similar 1 6 estimate image motion homography pi reference frame phi 0 frames phi j j warping images homographies fb j g l yields new sequence l images fi j g l image pi aligned across frames also sake notational simplicity let us rename reference image ie residual image motion reference frame warped images fi j g l residual planarparallax displacement p j due 3d scene points located reference plane pi residual planar parallax motion remains estimated let first two coordinates p j coordinate 0 eq 2 know residual parallax superscripts j denote parameters associated jth frame twoframe case one define 1flt3 problem posed eq 3 becomes bilinear problem ff solved using standard iterative method ff known fl recovered similar approach used 11 shape recovery twoframes however approach extend multiple 2 frames ff shape invariant depends 3 hence varies frame frame contrast fl shape invariant shared image frames multiframe process directly recovers fl multiframe brightness quantities basic idea behind direct estimation algorithm rather estimating l separate u j vectors corresponding frame pixel simply estimate single fl shape parameter particular pixel common frames single frame j common image pixels two advantages 1 n pixels l frames reduce number unknowns 2nl 2 importantly recovered flow vector constrained satisfy epipolar structure implicitly captured eq 2 expected significantly improve quality recovered parallax flow vectors direct estimation algorithm follows computational framework outlined 1 quasiparametric class models basic components framework pyramid construction ii iterative estimation global motion local structure parameters iii coarsetofine refinement overall control loop algorithm therefore follows 1 construct pyramids images j reference frame 2 initialize structure parameter fl pixel motion parameter j frame usually start frames 3 starting coarsest pyramid level level refine structure motion using method outlined section 31 4 repeat step several times usually 4 5 times per level 5 project final value structure parameter next finer pyramid level propagate motion parameters also next level use initial estimates processing next level 6 final output structure motion parameters finest pyramid level corresponds resolution input images residual parallax flow field synthesized various steps outline pyramid construction projection parameters common many techniques motion estimation eg see 1 hence omit description steps hand refinement step specific current problem described next 31 estimation process inner loop estimation process involves refining current values structure parameters fl one per pixel motion parameters j 3 parameters per frame let us denote true unknown values parameters flx location x reference frame j let denote corresponding unknown true parallax flow vector let c denote current estimates quantities let c ffiu c ffi quantities refinements estimated iteration assuming brightness constancy namely corresponding image points across frames similar brightness value 2 small ffiu j make approximation c expanding first order taylor series around x denote image intensity derivatives reference image pixel location x get brightness constraint equation substituting c yields compactly c substitute expression local parallax flow vector u j given eq 3 obtain following equation relates structure motion parameters directly image brightness information 1flxyt ji x j refer equation epipolar brightness constraint 2 note multiple frames brightness change somewhat least due global illumination variation handle using laplacian pyramid opposed gaussian pyramid otherwise prefiltering images eg normalize remove global mean contrast changes applying brightness constraint filtered images pixel frame contributes one equation unknowns relative scene structure pixel x epipoles j frame j unknowns computed two phases first phase local phase relative scene structure fl estimated separately pixel via least squares minimization multiple frames simultaneously followed global phase epipoles j estimated reference frame frames using least squares minimization pixels two phases described detail local phase local phase assume epipoles given eg previous iteration estimate unknown scene structure fl images fl local quantity common images point epipoles known eg previous iteration frame j provides one constraint eq 5 fl therefore theoretically sufficient geometric information solving fl however increased numerical stability locally assume fl constant small window around pixel reference frame experiments used 5 theta 5 window pixel x use error function x j j winx 5theta5 window around x differentiating errfl respect fl equating zero yields single linear equation solved estimate flx error term obtained multiplying eq 5 denominator 3 yield linear expression fl note without multiplying denominator local estimation process differentiation would require solving polynomial equation fl whose order increases l number frames minimizing errfl practice equivalent applying weighted least squares minimization collection original eqs 5 weights equal denominators could apply normalization weights 1 estimate shape pixel x previous iteration linearized expression order assure minimization meaningful quantities done 18 practice examples used found necessary local phase however normalization weight important global phase see global phase global phase assume structure fl given eg previous iteration estimate image j position respect reference frame estimate set epipoles minimizing following error respect epipoles x j flx fixed minimization problem decouples set separate individual minimization problems function one epipole j jth frame inside portion error term similar one used local phase addition scalar weight w j x scalar weight used serve two purposes first eq 7 contain weights would equivalent weighted least squares minimization eq 5 weights equal denominators 1 3 provides convenient linear expression unknown j weights physically meaningful tend skew estimate recovered epipole therefore fashion similar 18 choose weights w j x fl updated estimate local phase whereas j 3c based current estimate j previous itera tion scalar weight also provides us easy way introduce additional robustness estimation process order reduce contribution pixels potentially outliers example use weights based residual misalignment kind used 6 4 multiframe vs twoframe estimation algorithm described section 3 extends planeparallax estimation multiple frames obvious benefit multiframe processing improved signaltonoise performance obtained due larger set independent samples however two additional benefits multiframe estimation overcoming aperture problem twoframe estimation often suffers ii resolving singularity shape recovery vicinity epipole refer epipole singularity 41 eliminating aperture problem two images used 11 13 exists one epipole residual parallax lies along epipolar lines centered epipole see eq 3 epipolar field provides one line constraint parallax displacement brightness constancy constraint forms another line constraint eq 4 lines parallel intersection uniquely defines parallax displacement however image gradient image point parallel line passing point parallax displacement hence structure uniquely determined however multiple images multiple epipoles used ambiguity resolved image gradient point parallel one epipolar lines associated observation also made 4 15 demonstrate used sequence composed 9 images 105 theta 105 pixels 4 squares 30theta30 pixels moving stationary textured background plays role aligned reference plane 4 squares motion first shifted right one pixel per frame generate first 5 images shifted one pixel per frame generate next 4 images width stripes squares 5 pixels sample frame shown fig 1a fifth frame epipoles correspond motion infinity horizontal motion epipole 1 525 vertical motion epipole 525 1 texture squares selected spatial gradients one square parallel direction horizontal motion another square spatial gradients parallel direction vertical motion two squares spatial gradients multiple directions tested algorithm three cases pure vertical motion ii pure horizontal motion iii mixed motions fig 1b typical depth map results applying algorithm sequences purely vertical motion dark grey corresponds reference plane light grey corresponds elevated scene parts ie squares structure square vertical bars estimated well expected epipolar constraints parallel bars true even algorithm applied multiple frames epipole fig 1c typical depth map results applying algorithm sequences purely horizontal motion note structure square horizontal bars estimated well fig 1d typical depth map results applying algorithm multiple images mixed motions ie one distinct epipole note shape recovery suffer aperture problem 42 epipole singularity planar parallax eq 3 clear structure fl cannot determined epipole epipole j 0 reason recovered structure vicinity epipole highly sensitive noise unreliable however multiple b c fig 1 resolving aperture problem sample image b shape recovery pure vertical motion ambiguity along vertical bars c shape recovery pure horizontal motion ambiguity along horizontal bars shape recovery sequence mixed motions ambiguity epipoles ambiguity disappears singularity one epipole resolved information another epipole test behavior compared results case one epipole ie twoframes cases multiple epipoles different locations results shown fig 2 sequence used composed images square elevated reference plane simulated motion plane alignment looming motion ie forward motion fig 2abc show three sample images sequence fig 2d shows singularity around epipole twoframe case figs 2ehij show singularity epipoles eliminated one epipole using images also increases signal noise ratio improves shape reconstruction 5 real world examples section provides experimental results applying algorithm real world sequences fig 3 shows example shape recovery indoor sequence block sequence 11 reference plane carpet fig 3a shows one frame sequence fig 3b shows recovered structure brighter grey levels correspond taller points relative carpet note fine structure toys carpet fig 4 shows example shape recovery sequence five frames part flower garden sequence reference plane house fig 4a shows reference frame sequence fig 4b shows recovered structure note gradual change depth field fig 5 shows example shape recovery sequence 5 frames reference plane flat region front building fig 5a show one fig 2 resolving epipole singularity case multiple epipoles ac sample images 9frame sequence multiple epipoles df shape recovery using 2 images epipole singularity exist case eg using 3 images 2 different epipoles using 5 images multiple epipoles il using 7 images multiple epipoles using 9 images multiple epipoles note epipole singularity disappears multiple epipoles exist fgklm show enlarge view depth image vicinity epipoles box shows region epipoles visibility purposes different images shown different scales reference coordinate rulers attached image 12 b fig 3 blocks sequence one frame sequence b recovered shape relative carpet brighter values correspond taller points b fig 4 flowergarden sequence one frame sequence b recovered shape relative facade house brighter values correspond points farther house frame sequence fig 5b shows recovered structure brightness reflects magnitude structure parameter fl brighter values correspond scene points reference plane darker values correspond scene points reference plane note fine structure stairs lamppole shape building wall fully recovered lack texture region b fig 5 stairs sequence one frame sequence b recovered shape relative ground surface front building brighter values correspond points ground surface darker values correspond points ground surface 6 conclusion presented algorithm estimating dense planarparallax displacements multiple uncalibrated views image displacements 3d structure camera epipoles estimated directly image brightness variations across multiple frames algorithm extends twoframes planeparallax estimation algorithm 11 13 multiple frames current algorithm relies prior plane alignment natural extension algorithm would fold homography estimation simultaneous estimation image displacements scene structure camera motion done 11 two frames r european conference computer vision direct multiresolution estimation egomotion structure motion okamoto n defense eightpoint algorithm computing occluding transparent motions parallax geometry pairs points 3d scene analysis recovery egomotion using region alignment reference frames reference planes multiview parallax geometry applications unified approach moving object detection 2d 3d scenes direct recovery shape multiple views parallax based approach prazdny k 3d geometry theory application 3d reconstruction perspective views direct methods visual scene reconstruction geometric motion segmentation model selection determining epipolar geometry uncertainty review tr ctr han takeo kanade reconstruction scene multiple linearly moving objects international journal computer vision v59 n3 p285300 septemberoctober 2004