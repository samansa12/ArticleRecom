distributing streaming media content using cooperative networking paper discuss problem distributing streaming media content live ondemand large number hosts scalable way work set context traditional clientserver framework specifically consider problem arises server overwhelmed volume requests clients solution propose cooperative networking coopnet clients cooperate distribute content thereby alleviating load server discuss proposed solution detail pointing interesting research issues arise present preliminary evaluation using traces gathered busy news site flash crowd occurred september 11 2001 b introduction much work recent years topic content distribution work largely fallen two cat egories infrastructurebased content distribution b peertopeer content distribution infrastructurebased content distribution network cdn eg akamai complements server traditional clientserver framework employs dedicated set machines store distribute content clients behalf server dedicated frastructure including machines networks links engineered provide high level performance guarantees hand peertopeer content distribution relies clients host content distribute clients p2p model replaces rather complements clientserver framework typically central server holds content examples p2p content distribution systems include napster gnutella paper discuss cooperative networking coop net approach content distribution combines aspects infrastructurebased peertopeer content distri bution focus distributing streaming media content live ondemand like infrastructurebased content distribution seek complement rather replace traditional clientserver framework specically consider problem arises server overwhelmed volume requests clients instance news site may overwhelmed large ash crowd caused event widespread interest sports event earthquake home computer webcasting birthday information please visit coopnet project web page httpwwwresearchmicrosoftcom e padmanabpro jectscoopnet party live friends family might overwhelmed even small number clients limited network bandwidth fact large volume data relatively high bandwidth requirement associated streaming media content increases likelihood server overwhelmed general server overload cause signicant degradation quality streaming media content received clients coopnet addresses problem clients cooperate distribute content thereby alleviating load server case ondemand content clients cache audiovideo clips viewed recent past period overload server redirects new clients clients downloaded content previously case live streaming clients form distribution tree rooted server clients receive streaming content server turn stream one peers key distinction coopnet pure p2p systems like gnutella coopnet complements rather replaces clientserver framework web still server hosts content directly serves clients coopnet invoked server unable handle load imposed clients presence central server simplies task locating content contrast searching content pure p2p system entails often expensive distributed search 20 21 24 individual clients may participate coopnet short period time say minutes contrast much longer participation times reported systems napster gnutella 23 instance case live streaming client may tune minutes time may willing help distribute con tent client tunes may longer willing participate coopnet calls content distribution mechanism robust interruptions caused frequent joining leaving individual peers address problem coopnet employs multiple description coding mdc streaming media content whether live ondemand divided multiple substreams using mdc substream delivered requesting client via dierent peer improves robustness also helps balance load amongst peers rest paper organized follows section 2 discuss related work section 3 discuss operation coopnet live ondemand content present outline multiple description coding section 4 use traces ash crowd occurred september 11 2001 evaluate well coopnet would performed live ondemand content present conclusions section 5 2 related work noted section 1 two areas related work infrastructurebased cdns peertopeer systems infrastructurebased cdns akamai employ dedicated network thousands machines distributed locations often leased links interconnecting serve content behalf servers client request arrives streaming media content cdn redirects client nearby replica server main limitation infrastructurebased cdns cost scale appropriate large commercial sites cnn msnbc second issue unclear cdn would fare face large ash crowd causes simultaneous spike trac many sites hosted cdn peertopeer systems napster gnutella depend little dedicated infrastructure 1 however implicit assumption individual peers participate signicant length time instance 23 reports median session duration hour napster gnutella contrast coopnet seeks operate highly dynamic situation ash crowd individual client may participate minutes disruption might cause especially challenging streaming media compared static le downloads primary focus napster gnutella short lifetime individual nodes poses challenge distributed search schemes 20 chord 24 pastry 21 tapestry 29 work applicationlevel multicast eg almi 17 end system multicast 3 scattercast 2 directly relevant live streaming aspect coopnet coopnet could benet ecient tree construction algorithms developed previous work focus however using real traces evaluate ecacy coopnet thus view work complementing existing work applicationlevel multicast also consider ondemand streaming case quite applicationlevel multicast framework existing work distributed streaming eg 13 also directly relevant coopnet key distinction work focus distruption packet loss caused node arrivals departures likely signi cant highly dynamic environment using traces september 11 ash crowd able evaluate issue realistic setting systems spreadit 5 allcast 31 vtrails 33 perhaps closest spirit work like coopnet attempt deliver streaming content using peertopeer ap proach spreadit diers coopnet couple ways first uses single distribution tree hence vulnerable disruptions due node departures second tree management algorithm nodes orphaned departure parent might bounced around multiple potential parents settling new parent contrast coopnet uses centralized protocol sec tion 33 enables much quicker repairs hard us specic comparison allcast 1 napster central servers hold indices content vtrails absence published information 3 cooperative networking coopnet section present details coopnet applies distribution streaming media content rst consider live streaming case discuss analyze multiple description coding mdc distribution tree management turn ondemand streaming case 31 live streaming live streaming refers synchronized distribution streaming media content one clients content may either truly live prerecorded therefore multicast natural paradigm distributing content since ip multicast widely deployed especially interdomain level coopnet uses applicationlevel multicast instead distribution tree rooted server formed clients members node tree transmits received stream children using unicast outdegree node constrained available outgoing bandwidth node general degree root node ie server likely much larger nodes server likely much higher bandwidth individual client nodes one issue peers coopnet far dedicated servers ability willingness participate coopnet may uctuate time instance clients participation may terminate user tunes live stream fact even user tuned live stream coopnetrelated activity hisher machine may scaled stopped immediately user initiates unrelated network communication machines also crash become disconnected network single distribution tree departure reduced availability node severe impact descendants descendants may receive stream tree repaired especially problematic node arrivals departures may quite frequent ash crowd situations reduce disruption caused node departures advocate multiple distribution trees spanning given set nodes transmitting dierent mdc description tree would diminish chances node losing entire stream even temporarily departure another node discuss section 32 distribution trees need constantly maintained new clients join existing ones leave section 33 advocate centralized approach tree management exploits availability resourceful server node coupled client cooperation greatly simplify problem 32 multiple description coding mdc multiple description coding method encoding audio andor video signal 1 separate streams descriptions subset descriptions received decoded signal distortion respect original signal commensurate number descriptions received descriptions ceived lower distortion ie higher quality encoder decoder encoder decoder base layer figure 1 multiple description coding b layered coding bits distortion r packet 3 packet 4 packet rs bit stream figure 2 priority encoded packetization group frames gof packets recover initial rm bits bit stream gof reconstructed signal diers layered coding 2 mdc every subset descriptions must decodable whereas layered coding nested sequence subsets must decodable illustrated figure 1 extra exibility mdc incurs modest performance penalty relative layered coding turn incurs slight performance penalty relative single description coding simple mdc system video might following original video picture sequence demultiplexed subsequences putting every mth picture mth subsequence subsequences independently encoded form de scriptions subset descriptions decoded pictures remultiplexed reconstruct video sequence whose frame rate essentially proportional number descriptions received sophisticated forms multiple description coding investigated years highlights 25 26 27 6 overview see 7 particularly ecient practical system based layered audio video coding 18 reedsolomon coding 28 priority encoded transmission 1 optimized bit allocation 4 19 11 12 system audio andor video signal partitioned groups frames gofs group duration gof independently encoded error protected packetized packets shown figure 2 packets received initial rm bits bit stream gof recovered layered coding also known embedded progressive scalable coding description description description gof i1 gof i1 figure 3 construction mdc streams packetized gofs sulting distortion drm consequently dr0 dr1 drm thus packets equally important number received packets determines reconstruction quality gof expected distortion pm probability packets ceived given pm operational distortionrate function dr expected distortion minimized using simple procedure adjusts rate points subject constraint packet length 4 19 11 12 sending mth packet gof mth descrip tion entire audio andor video signal represented descriptions description sequence packets transmitted rate 1 packet per gof illustrated figure 3 simple matter generate optimized descriptions assuming signal already coded layered codec 321 coopnet analysis quality multiple failures let us consider multiple description coding achieves robustness coopnet suppose server encodes av signal descriptions described transmits descriptions dierent distribution trees rooted server distribution trees conveys description n destination hosts ordinarily destination hosts receive descriptions however destination hosts fail leave session hosts descendents failed hosts mth distribution tree receive mth descrip tion number descriptions particular host receive depends location tree relative failed hosts specically host n receive mth description none ancestors mth tree fail happens probability 1 number hosts ancestors probability host fails assuming independent failures hosts placed random sites tree unconditional probability given host receive mth description average hosts tree thus number descriptions particular host receive randomly distributed according binomialm n distri bution ie hence large fraction descriptions received approximately gaussian mean n variance n 1 n seen figure 4 shows bars distribution pm various values gure compute n assumed balanced binary trees n nodes probability host failure n grows large performance slowly degrades depth tree hence 1 n grows like log 2 n distribution pm used optimize multiple description code choosing rate points r0 figure 4 snr db line probabililty distribution bars function number descriptions received probability host failure minimize expected distortion p subject packet length constraint figure 4 shows lines quality associated pm measured snr function number received descriptions gure compute rate points r0 assumed operational distortionrate function asymptotically typical source variance 2 r expressed bits per symbol assumed packet length constraint given 322 coopnet analysis quality single failure time takes repair trees called repair time hosts fail repair time average length time host participates session 1 repair times number hosts small compared 1 many repair times may pass single failures case time hosts receive descriptions quality excellent degradation occurs single host fails thus may preferable optimize mdc system minimizing distortion expected repair interval single host fails rather minimizing expected distortion time analyze case suppose single host fails randomly remaining host n receive mth description failed host ancestor host n mth tree happens probability ann 1 number ancestors host n since hosts place random sites tree unconditional probability given host receive mth description average 1 thus number descriptions particular host receive randomly distributed according binomialm n distri bution equivalently expected number hosts receive descriptions failure n 1pm distribution used optimize multiple description code failure single host figure 5 illustrates distribution corresponding optimized quality function number descriptions received note increases xed n distribution becomes gaussian one implication expected number hosts receive 100 descriptions figure 5 snr db line probabililty distribution bars function number descriptions received failure single host decreases however also case expected number hosts receive fewer 50 descriptions decreases resulting increase quality average fur ther n increases xed performance becomes nearly perfect since n 1 log 2 nn goes 1 however large n becomes increasingly dicult repair trees second failure occurs 323 analyses analyses extended dary trees dicult see 2 dary trees log 2 n nodes height hence performance binary tree n nodes thus node large outdegree ie host large uplink bandwidth much larger populations han dled interestingly analysis also applies host devote much uplink bandwidth downlink video bandwidth typically case modem users descriptions still distributed peertopeer arranging hosts chain like bucket brigade shown order hosts chain random independent description single failure number hosts receiving descriptions binomially distributed parameters n although holds n suitable smaller n larger n may possible repair chains failures occur fact n goes innity probability host receives descriptions goes zero section proposed optimizing mdc system unconditional distribution pm derived averaging trees hosts given set trees however distribution number received descriptions varies widely across set hosts function upstream connectivity optimizing mdc system unconditional distribution pm minimizing expected distortion given host rather minimizing sum expected distortions across hosts equivalently minimizing expected sum distortions hosts 33 tree management discuss problem constructing maintaining distribution trees face frequent node arrivals departures many sometimes con tree management algorithm 1 short wide tree trees short possible minimize latency path root deepest leaf node minimize probability disruption due departure ancestor node short tree balanced wide possible ie outdegree node much bandwidth allow however making outdegree large may leave little bandwidth noncoopnet higher priority trac emanating node interference due trac could cause high packet loss rate coopnet streams 2 eciency versus tree diversity distribution trees ecient structure closely ect underlying network topology instance wish connect three nodes one located new york ny san francisco sf los angeles la structure nysfla would likely far ecient sfnyla denotes parentchild relationship however striving eciency may interfere equally important goal diverse distribution trees eectiveness mdcbased distribution scheme described section 32 depends critically diversity distribution trees 3 quick join leave processing node joins leaves quick would ensure interested nodes would receive streaming content quickly possible case join minimal interruption case leave however quick processing joins leaves may interfere eciency balanced tree goals listed 4 scalability tree management algorithm scale large number nodes correspondingly high rate node arrivals departures instance extreme case ash crowd msnbc september 11 average rate node arrivals de parturtes 180 per second peak rate 1000 per second requirements mind describe approach tree construction management rst describe basic protocol discuss optimizations 331 basic protocol exploit presence resourceful server node build simple ecient protocol process node joins leaves centralized argue protocol scale work well face extreme ash crowd situations one occurred september 11 despite ash crowd server overloaded since burden distributing content shared peers centralization also simplies protocol greatly consequently makes joins leaves quick general criticism centralization introduces single point failure however context coopnet point centralization server also source data source server fails may really matter tree management also breaks also recall section 1 goal coopnet complement replace clientserver system server full knowledge topology distribution trees new node wishes join sys tem rst contacts server new node also informs server available network bandwidth serve furture downstream nodes server responds list designated parent nodes one per distribution tree designated parent node tree chosen follows starting server work way tree get level one nodes necessary spare capacity primarily network bandwidth serve parent new node server could new parent sucient spare capacity likely early stages tree construction server picks one node random designated parent new node topdown procedure ensures short largely balanced tree randomization helps make trees diverse upon receiving servers message new node sends concurrent messages designated parent nodes get linked child distribution tree terms messaging costs server receives one message sends one designated parent receives one message sends one acknowledgement new node sends receives number mdc descriptions hence distribution trees used node departures two kinds graceful departures node failures former case departing node informs server intention leave distribution tree server identies children departing node executes join operation child implicitly subtree rooted child using topdown procedure described messaging cost server would p receives number children departing node ith distribution tree note cost would somewhat lower general children may common across multiple trees child sends receives messages reduce messaging load server could make determination designated parent child tree leave another node departing node still available convey information child case server would send receive one message node failure corresponds case departing node leaves suddenly unable notify either server node departure may happen computer crashing turned becoming disconnected network present general approach dealing quality degradation due packet loss node failure special case packet loss rate experienced descendants failed node 100 node monitors packet loss rate experiencing distribution tree packet loss rate reaches unacceptable level threshold needs netuned based search node contacts parent check parent experiencing problem source problem network congestion node failure etc upstream parent node leaves parent deal node also sets suciently long timer take action case parent resolved problem within reasonable period time parent experiencing problem respond aected node contact server execute fresh join operation subtree moved new location distribution tree 332 optimizations discuss optimizations basic protocol rst optimization seeks make distribution trees ecient discussed basic idea preferentially attach new node child existing node nearby terms network distance ie latency denition nearby needs broad enough accomodate signicant tree diversity trying insert new node server rst identies suciently large subset nodes close new node using randomized topdown procedure discussed section 331 tries nd parent new node tree among set nearby nodes using procedure quite likely many parents new node various distribution trees vicinity ben ecial eciency viewpoint argue also provides sucient diversity since primary failure mode concerned node departures node failures matter much parents may located vicinity eg metropolitan area determine network distance two nodes use procedure based previous work network distance estimation 14 geographic location estimation 16 overlay construction 20 nding nearby hosts 8 node determines network coodinates measuring network latency say using ping set landmark hosts welldistributed landmark hosts suce practice coordinate node ntuple d1 n number landmarks server keeps track coordinates nodes currently system information may need updated time time new node contacts server nds nearby nodes comparing coordinates new node existing nodes comparison could involve computing eucledian distance coordinates two nodes 16 computing dierent distance metric manhattan distance simply comparing relative ordering various landmarks based measured latency 20 second optimization motivated observation would benecial stable nodes close root tree context stable nodes ones likely participate coopnet long duration good network connectivity eg dis truptions due competing trac applications nodes close root tree would benet many descendants background process server could identify stable nodes monitoring past behavior migrate tree research needed determine feasibility identifying stable nodes ben ets migrating nodes tree impact might tree diversity 333 feasibility centralized protocol main question regarding feasibility centralized tree management protocol whether server keep answer question consider september 11 ash crowd msnbc arguably extreme ash crowd sit uation peak 18000 nodes system rate node arrivals departures 1000 per second 3 average numbers 10000 nodes 180 arrivals departures per second calculations assume number distribution trees ie number mdc descriptions 16 average node 4 children tree consider various resources could become bottleneck server focus impact tree management server memory store entire topology one tree memory server would need store many pointers nodes system assuming pointer size 8 bytes ie 64bit machine auxiliary data 24 bytes per node memory requirement would 576 kb since 16 trees memory requirement trees would 92 mb addition node server needs store network coordinates assuming 10dimensional vector delay values bytes additional memory requirement would 360 kb total memory requirement server would 10 mb trivial amount modern machine network departures expensive node arrivals focus departures server needs designate new parent distribution tree child departing node assuming nodes identied ip addresses bytes assuming ipv6 4 children per tree average total amount data server would need send 1 kb 1000 departures per second bandwidth requirement would 8 mbps likely small fraction network bandwidth large server site msnbc cpu node departure involves nding new set parents child departing node cpu cost roughly equal number children departing node times cost node insertion insert node server scan tree levels starting root reaches level containing one nodes spare capacity support new child server picks one node random new parent using simple array data structure keep track nodes level tree capacity cost picking parent random made small constant since number levels tree logn n number nodes system node insertion cost per tree ologn average 4 children per node depth tree 9 departure rate 1000 per second would result 64000 insertions per second 1000 departures times 4 children per departing node times 16 trees given memory speed far lags cpu speed focus many memory lookups per insertion assuming 40 ns memory cycle allowed memory accesses per insertion likely sucient 3 one reason high rate churn may users discouraged degradation audiovideo quality caused ash crowd stay long however position conrm case general centralized approach scaled least terms cpu memory resources cluster servers partitioning set clients across set server nodes process benchmarking implementation conrm rough calculations made 334 distributed protocol centralized tree management protocol appears adequate large ash crowd situations experienced msnbc september 11 clear limits scalability instance future conceivable ash crowds streaming media content web cases large television audiences highly popular events hundreds millions even billions clients centralized solution may break situation necessitating alternative approach tree management could leverage recent work distributed hash tables dhts 20 chord 24 pastry 21 tapestry 29 build construct maintain trees distributed fashion brie dhts provide scalable unicast routing framework peertopeer systems multicast distribution tree constructed using reversepath forwarding systems bayeux 30 scribe 22 construct multiple diverse distribution trees node could assigned multiple ids one per tree number open research issues first exist algorithms support node joins leaves dynamic behavior dhts poorly understood second unclear incorporate constraints limited node bandwidth dht framework systems pastry maintain multiple alternate routes hop make easier construct multicast trees accomodating node capacity constraints 34 ondemand streaming turn ondemand streaming refers distribution prerecorded streaming media content demand eg user clicks corresponding link streams corresponding dierent users syn chronized server receives request starts streaming data response current load condition per mits however server overloaded say ash crowd instead sends back response including short list ip addresses clients peers downloaded part requested stream expressed willingness participate coopnet requesting client turns one peers download desired content given large volume streaming media content burden server terms cpu disk network bandwidth redirection quite minimal compared actually serving content believe redirection procedure help reduce server load several orders magnitude procedure described similar one might apply static le content couple important dierences arising streaming nature content first peer may part requested content instance user may stopped stream halfway skipped portions initial handshake peer client nds part requested content available peer accordingly plans make requests peers missing content second issue live streaming case peers may fail depart scale back participation coopnet time contrast le download timesensitive nature streaming media content makes especially susceptible disruptions solution propose use distributed streaming stream divided number substreams may served dierent peer substream corresponds description created using mdc section 32 distributed streaming improves robustness disruptions caused untimely departure peer nodes andor network connectivity problems respect one peers also helps distribute load evenly among peers 4 performance evaluation present performance evaluation coopnet based simulations driven traces live ondemand content served msnbc september 11 2001 41 live streaming evaluate mdcbased live streaming design using traces 100kbps live stream trace started 1825 gmt 1425 est lasted one hour 4000 seconds 411 trace characteristics figure 6 shows time series number clients simultaneously tuned live stream peak number simultaneous clients exceeds 17000 average 84 clients departing every second unable denitely explain dip around 1000seond mark possibly due glitch logging process figure 7 shows distribution client lifetimes 70 clients remain tuned live stream less minute suspect short lifetimes could users frustrated poor quality video stream ash crowd quality improved say using coopnet relieve server client lifetimes may well become longer turn would increase eectiveness coopnet 412 effectiveness mdc evaluate impact mdcbased distribution sec tion 32 quality stream received clients face client departures departures clients receive mdc descriptions hence perceive full quality live stream conducted two simulation experiments rst experiment construct completely random distribution trees end repair interval following client departure analyze stream quality received remaining clients random trees likely diverse ie uncorrelated improves eectiveness mdcbased distribution second experiment simulate tree management algorithm described section 33 thus distribution trees evolved based node arrivals departures recorded trace compare results two experiments end section detail conducted random tree experiment follows repair interval construct distribution trees corresponding descriptions mdc coder spanning n nodes system beginning interval based number departing clients node arrivals departures200060001000014000180000 500 1000 1500 2000 2500 3000 3500 4000 time seconds nodes figure number clients departures duration minutes percentage nodes figure 7 duration distribution table 1 random tree experiment probability distribution descriptions received vs number distribution trees recorded end repair interval randomly remove nodes tree compute number descriptions received remaining nodes perceived quality stream client determined fraction descriptions received client set distribution trees characterized three parameters number trees equivalently descriptions maximum outdegree nodes tree outdegree root ie live streaming server outdegree node typically function bandwidth capacity root ie server tends much larger outdegree bandwidthconstrained clients random tree construc tion client assigned random degree subject maximum varied degree root number descriptions study impact received stream qual ity set repair time 1 second investigate impact repair time section 413 table shows number distribution trees affects fraction descriptions received expressed per centage p compute distribution p averaged across client departures set maximum outdegree figure 8 random tree experiment snr db line probabililty distribution bars function number descriptions received quality snr time seconds random trees multiple descriptions m16 single description m1 figure 9 random tree experiment snr time mdc sdc cases time stant compute average snr clients client 4 root degree 100 vary number descriptions among 1 2 4 8 16 column represents range values p pair range number descriptions list average percentage clients receive level quality example rst table entry indicates using 2 descriptions 9480 clients receive 100 descriptions ie descriptions number descriptions increases percentage clients receive descriptions ie decreases nonetheless percentage clients corresponding small values p decreases dramatically 8 de scriptions 96 8207 1402 clients receive 875 descriptions 8 tions clients receive least one description figure 8 shows corresponding snr figure 9 compares snr time 16description case single description case mdc demonstrates clear advantage sdc table shows root degree aects distribution descriptions received set number descriptions 8 maximum outdegree client 4 root degree increases distribution shows improvement figure shows snr probability distribution compared case nodes including root degree root degree r shortens tree log r means fewer ancestors nodes tree discussed section 32 increases probability node receive particular description r 100 875100 75875 5075 2550 0 table 2 random tree experiment probability distribution descriptions received vs root degree figure 10 random tree experiment snr db line probabililty distribution bars function number descriptions received root degree table 3 evolving tree experiment probability distribution descriptions received vs number distribution trees second experiment evolved distribution trees simulating tree management algorithm section 33 set root ie server outdegree 100 maximum outdegree client set 4 table 3 shows probability distribution descriptions received upon client departures figure 11 shows corresponding snr results comparable random tree ex periment suggests tree management algorithm able preserve signicant tree diversity even long period time hour case 413 impact repair time finally evaluate impact time takes repair tree following node departure clearly longer repair time greater impact aected nodes also longer repair time increase chances nodes departing repair completed thereby causing disruption divide time nonoverlapping repair intervals assume leaves happen beginning interval compute fraction descriptions received averaged nodes quantity n discussed section 32 section 32 assume balanced binary tree times figure 12 shows average number descriptions received function time four dierent settings repair time seconds repair time 1 second clients would receive 90 descriptions average 10 second repair time fraction drops 30 believe results encouraging since practice tree repair done quickly especially given tree management algorithm centralized section 31 even 1second figure evolving tree experiment snr db line probabililty distribution bars function number descriptions received01030507090 500 1000 1500 2000 2500 3000 3500 4000 time seconds average fraction descriptions received figure 12 average fraction descriptions received various repair times repair interval would permit multiple roundtrips server nodes aected repair eg children departed node 42 ondemand streaming evaluate potential coopnet case ondemand streaming goals evaluation study eects client cooperation reduction load server additional load incurred cooperating peers amount storage provided cooperating peers likelihood cooperating proximate peers improve performance cooperation protocol used simulations based server redirection 15 server maintains xed size list ip addresses per url coopnet clients recently contacted get content client initially sends request server client willing co operate server redirects request returning short list ip addresses coopnet clients recently requested le turn client contacts coopnet peers arranges retrieve content directly peer may dierent portion le may necessary contact multiple peers content order select peer set peers using distributed streaming download content peers run greedy algorithm picks peers longest portion le list returned server client cannot retrieve content peer retrieves entire content server note server provides means discovering coopnet peers peers independently decide cooperate server maintains list 100 ip addresses per url returns list 10 ip addresses redirection messages simulations use traces collected msnbc ash crowd sep 11 2001 evaluation ash crowd started around 100 pm gmt 900 edt persisted rest day peak request rate three orders magnitudes average report simulation results beginning ash crowd 100 pm 300 pm gmt 300000 requests 2hour period however 6 18000 requests time day average bandwidth bps server server coopnet clients coopnet average bandwidth server cooperating peers degree parallelism average bandwidth coopnet clients bps b average bandwidth peers using distributed streaming 100103050709bandwidth active peers bps cumulative distribution least loaded c distribution bandwidth active peers figure 13 performance coopnet ondemand streaming successfully served average rate 20 mbps mean session duration 20 minutes unsuccessful requests used analysis lack content byte range session duration information 421 bandwidth load evaluation load measured bandwidth usage model available bandwidth peers assume peers support full bit rate 56 kbps 100 kbps encoded stream also place bound number concurrent connections peer practice nding peers sucient available bandwidth overloading one peer important considerations investigating issues ongoing work figure 13a depicts bandwidth usage 2hour period two systems traditional clientserver system coopnet system vertical axis average bandwidth horizontal axis time two peaks around 140 pm 210 pm two new streams added server clientserver system server distributing content average 20 mbps however client cooperation reduce bandwidth orders magnitude average 300 kbps result server available serve client requests average bandwidth contribution coopnet clients need make system 45 kbps although average bandwidth contribution reasonably small peers actively serving content time nd typically less 10 peers active second average bandwidth contribution active coopnet peers need make system high 465 kbps average bandwidth active peers computed total number bits served total length peers active periods reduce load individual coopnet clients disjoint portions content retrieved parallel multiple peers using distributed streaming section 34 bandwidth requirement placed peer correspondingly reduced figure 13b depicts average bandwidth contributed versus degree parallelism degree parallelism upperbound number peers used parallel example clients retrieve content 5 peers parallel simulation degree parallelism 5 actual number peers used parallel may less 5 depending many peers provide content byterange needed client load active peer reduced degree parallelism creases degree parallelism 5 peers serving content 35 kbps however bandwidth active peers depicted gure slightly reduced 400 kbps large amount bandwidth required serve content two surges 140 pm 210 pm uence average bandwidth cumulative distribution bandwidth contributed active coopnet peers depicted figure 13c illustrates impact distributed streaming bandwidth utiliza tion solid line represents amount bandwidth peers contribute using 1 5 10 degrees paral lelism median bandwidth requirement 390 kbps content streamed one peer 66 bps degrees parallelism bandwidth requirement imposed peer reduced degree parallelism increases although reduction signicant small portion peers still contribute 1 mbps even using 10 degrees parallelism believe combination following two factors contribute wide range bandwidth usage greedy algorithm client uses select peers algorithm server uses select set ip addresses give clients better load distribution server run loadaware algorithm redirects clients recently seen peers least loaded terms network bandwidth usage order implement algorithm server needs know load individual peers therefore peers constantly report current load status server use report interval every second simulations server caches xedsize list ip addresses peers currently servers list need send status dates given information server selects 10 least loaded peers recently accessed url requesting client return redirection message algorithm replaces one described earlier section server redirects clients peers re020406081 storage allocated peer bytes cumulative distribution figure 14 storage requirement coopnet peers cently seen clients however use greedy algorithm select peers nd using new algorithm active clients serve content 385 kbps dashed line figure 13c depicts cumulative distribution bandwidth contributed coopnet clients loadaware algorithm used server simulation clients stream content one peer degree parallelism 1 part distribution similar one observed server redirects request recently seen peers dierence lies tail end distribution 6 peers contributed 500 kbps bandwidth server runs original algorithm compared 2 server runs loadaware algorithm addition total number active peers system doubles loadaware algorithm used nd client cooperation signicantly reduces server load freeing bandwidth support client connec tions addition combination distributed streaming loadaware algorithm used server reduces load individual peers 422 storage requirement order facilitate cooperation clients also contribute storage caching content simulations peers cache streams downloaded entire duration simulation figure 14 depicts cumulative distribution amount storage peer needs provide storage sizes range 200 b 100 mb half peers store less 1 mb content 5 peers store 6mb content storage requirement reasonable modern computers 423 nearby peers next look likelihood cooperating nearby peers finding nearby peers greatly increase eciency peertopeer communications evaluation peers close belong bgp prex domain 9 cluster 9000 ip addresses clients successfully received content 2hour trace based bgp tables obtained bbnplanet router 32 jan 24 2001 trace sampled randomly drawing ten 5minute windows look probability nding least n peers domain n degree parallelism ranging 1 10 sampling repeated window sizes 10 minutes window 5 minutes probability nding least one peer requested content belongs bgp prex cluster 12 window size increases 10 15 minutes probability slightly increases 16 17 accordingly distributed streaming degree parallelism increases probability nding nearby peers decreases using 10minute window probability nding least 5 peers 10 peers bgp prex cluster low 5 2 better understand whether small number ip addresses aects probabilities nding proximate peers also clustered 90000 ip addresses entire 2hour trace including unsuccessful requests part probabilities 12 higher reported successful requests finding proximate peer sucient available bandwidth part ongoing work summary initial results suggest client cooperation improve overall system performance distributed streaming loadaware server promising solutions reduce load individual peers improving robustness 5 conclusions paper presented coopnet peertopeer content distribution scheme helps servers tide crisis situations ash crowds focussed application coopnet distribution streaming median content live ondemand one challenge clients may participate coopnet extended length time coopnet employs distributed streaming multiple description coding improve robustness distributed streaming content face client departures evaluated feasibility potential performance coopnet using traces gathered msnbc ash crowd occurred september 11 2001 extreme event even ash crowd standards using traces helps us stress test coopnet design results suggest coopnet able reduce server load significantly without placing unreasonable burden clients live streams using multiple independent distribution trees coupled mdc improves robustness signicantly currently building prototype implementation coopnet streaming media distribution acknowledgements grateful steven lautenschlager ted mcconville dave roth providing us msnbc streaming media logs september 11 would also like thank anonymous nossdav reviewers insightful comments 6 r joint source channel coding image transmission lossy packet multiple description coding compression meets network unequal loss protection graceful degradation image quality packet erasure channels forward error correction approximately optimal assignment unequal loss protection embedded video subband coding 3d spiht multiple description source coding forward error correction codes design multiple description scalar quantizers design entropyconstrained multiple description scalar quantizers optimal pairwise correlating transforms multiple description coding control systems digital communication storage bbnplanet publically available route server tr systems digital communication storage enabling conferencing applications internet using overlay muilticast architecture chord scalable contentaddressable network investigation geographic mapping techniques internet hosts storage management caching past largescale persistent peertopeer storage utility towards global network positioning case cooperative networking tapestry infrastructure faulttolerant widearea location scattercast ctr xinyan zhang jiangchuan liu gossip based streaming proceedings 13th international world wide web conference alternate track papers posters may 1921 2004 new york ny usa duc tran kien hua tai scalable media streaming large peertopeer networks proceedings tenth acm international conference multimedia december 0106 2002 juanlespins france mubashar mushtaq toufik ahmed djamaleddine meddour adaptive packet video streaming p2p networks proceedings 1st international conference scalable information systems may 30june 01 2006 hong kong meng zhang li zhao yun tang jianguang luo shiqiang yang largescale live media streaming peertopeer networks global internet proceedings acm workshop advances peertopeer multimedia streaming november 1111 2005 hilton singapore guang tan stephen jarvis xinuo chen daniel p spooner performance analysis improvement overlay construction peertopeer live streaming simulation v82 n2 p93106 february 2006 reza rejaie antonio ortega pals peertopeer adaptive layered streaming proceedings 13th international workshop network operating systems support digital audio video june 0103 2003 monterey ca usa karthik lakshminarayanan venkata n padmanabhan findings network performance broadband hosts proceedings 3rd acm sigcomm conference internet measurement october 2729 2003 miami beach fl usa chuan wu baochun li rstream resilient peertopeer streaming rateless codes proceedings 13th annual acm international conference multimedia november 0611 2005 hilton singapore zongpeng li baochun li lap chi lau achieving maximum multicast throughput undirected networks ieeeacm transactions networking ton v14 nsi p24672485 june 2006 sachin agarwal jatinder pal singh shruti dube analysis implementation gossipbased p2p streaming distributed incentive mechanisms peer cooperation advances multimedia v2007 n2 p112 april 2007 song ye fillia makedon collaborationaware peertopeer media streaming proceedings 12th annual acm international conference multimedia october 1016 2004 new york ny usa thorsten strufe jens wildhagen gnter schfer towards construction attack resistant efficient overlay streaming topologies electronic notes theoretical computer science entcs 179 p111121 july 2007 dan rubenstein sambit sahu unstructured p2p protocols survive flash crowds ieeeacm transactions networking ton v13 n3 p501512 june 2005 chowsing lin yichi cheng p2mcmd scalable approach vod service peertopeer networks journal parallel distributed computing v67 n8 p903921 august 2007 yi cui klara nahrstedt layered peertopeer streaming proceedings 13th international workshop network operating systems support digital audio video june 0103 2003 monterey ca usa raj kumar rajendran dan rubenstein optimizing quality scalable video streams p2p networks computer networks international journal computer telecommunications networking v50 n15 p26412658 october 2006 chuan wu baochun li optimal peer selection minimumdelay peertopeer streaming rateless codes proceedings acm workshop advances peertopeer multimedia streaming november 1111 2005 hilton singapore chunchao yeh lin siong pui frame forwarding peertopeer multimedia streaming proceedings acm workshop advances peertopeer multimedia streaming november 1111 2005 hilton singapore yuwei sung michael bishop sanjay rao enabling contribution awareness overlay broadcasting system acm sigcomm computer communication review v36 n4 october 2006 yohei okada masato oguro jiro katto sakae okubo new approach construction alm trees using layered video coding proceedings acm workshop advances peertopeer multimedia streaming november 1111 2005 hilton singapore yang guo kyoungwon suh jim kurose towsley p2cast peertopeer patching video demand service multimedia tools applications v33 n2 p109129 may 2007 yicheng tu jianzhong sun mohamed hefeeda sunil prabhakar analytical study peertopeer media streaming systems acm transactions multimedia computing communications applications tomccap v1 n4 p354376 november 2005 shiwen mao xiaolin cheng thomas hou hanif sherali multiple description video multicast wireless ad hoc networks mobile networks applications v11 n1 p6373 february 2006 kunwadee sripanidkulchai aditya ganjam bruce maggs hui zhang feasibility supporting largescale live streaming applications dynamic application endpoints acm sigcomm computer communication review v34 n4 october 2004 zhichen xu chunqiang tang sujata banerjee sungju lee rita receiver initiated justintime tree adaptation rich media distribution proceedings 13th international workshop network operating systems support digital audio video june 0103 2003 monterey ca usa leonardo bidese de pinho claudio luis de amorim assessing efficiency stream reuse techniques p2p videoondemand systems journal network computer applications v29 n1 p2545 january 2006 yi cui baochun li klara nahrstedt achieving optimized capacity utilization application overlay networks multiple competing sessions proceedings sixteenth annual acm symposium parallelism algorithms architectures june 2730 2004 barcelona spain kunwadee sripanidkulchai bruce maggs hui zhang analysis live streaming workloads internet proceedings 4th acm sigcomm conference internet measurement october 2527 2004 taormina sicily italy yang guo kyoungwon suh jim kurose towsley p2cast peertopeer patching scheme vod service proceedings 12th international conference world wide web may 2024 2003 budapest hungary padmavathi mundur poorva arankalle optimal server allocations streaming multimedia applications internet computer networks international journal computer telecommunications networking v50 n18 p36083621 21 december 2006 daria antonova arvind krishnamurthy zheng ravi sundaram managing portfolio overlay paths proceedings 14th international workshop network operating systems support digital audio video june 1618 2004 cork ireland mohamed hefeeda ahsan habib boyan botev dongyan xu bharat bhargava promise peertopeer media streaming using collectcast proceedings eleventh acm international conference multimedia november 0208 2003 berkeley ca usa mohamed hefeeda bharat k bhargava david k yau hybrid architecture costeffective ondemand media streaming computer networks international journal computer telecommunications networking v44 n3 p353382 20 february 2004 zongpeng li anirban mahanti progressive flow auction approach lowcost ondemand p2p media streaming proceedings 3rd international conference quality service heterogeneous wiredwireless networks august 0709 2006 waterloo ontario canada ji li karen sollins dahyoh lim implementing aggregation broadcast distributed hash tables acm sigcomm computer communication review v35 n1 p8192 january 2005 alan kin wah yim rajkumar buyya decentralized media streaming infrastructure demsi adaptive highperformance peertopeer content delivery network journal systems architecture euromicro journal v52 n12 p737772 december 2006 dejan kosti adolfo rodriguez jeannie albrecht amin vahdat bullet high bandwidth data dissemination using overlay mesh proceedings nineteenth acm symposium operating systems principles october 1922 2003 bolton landing ny usa miguel castro peter druschel annemarie kermarrec animesh nandi antony rowstron atul singh splitstream highbandwidth multicast cooperative environments proceedings nineteenth acm symposium operating systems principles october 1922 2003 bolton landing ny usa konstantin andreev bruce maggs adam meyerson ramesh k sitaraman designing overlay multicast networks streaming proceedings fifteenth annual acm symposium parallel algorithms architectures june 0709 2003 san diego california usa toufik ahmed mubashar mushtaq p2p objectbased adaptive multimedia streaming poems journal network systems management v15 n3 p289310 september 2007 karthik lakshminarayanan ananth rao ion stoica scott shenker endhost controlled multicast routing computer networks international journal computer telecommunications networking v50 n6 p807825 13 april 2006 zongming fei mengkun yang proactive tree recovery mechanism resilient overlay multicast ieeeacm transactions networking ton v15 n1 p173186 february 2007 mojtaba hosseini nicolas georganas end system multicast protocol collaborative virtual environments presence teleoperators virtual environments v13 n3 p263278 june 2004 ying cai zhan chen wallapak tavanapong caching collaboration cache allocation peertopeer video systems multimedia tools applications v37 n2 p117134 april 2008