speculative versioning cache dependences among loads stores whose addresses unknown hinder extraction instruction level parallelism execution sequential program ambiguous memory dependences overcome memory dependence speculation enables load store speculatively executed addresses preceding loads stores known furthermore multiple speculative stores memory location create multiple speculative versions location program order among speculative versions must tracked maintain sequential semantics previously proposed approach address resolution buffer arb uses centralized buffer support speculative versions proposal called speculative versioning cache svc uses distributed caches eliminate latency bandwidth problems arb svc conceptually unifies cache coherence speculative versioning using organization similar snooping busbased coherent caches evaluation multiscalar architecture shows hit latency important factor affecting performance private cache solutions tradeoff hit rate hit latency b introduction modern microprocessors extract instruction level parallelism ilp sequential programs issuing instructions active instruction window data dependences among instructions original program order determine instruction may issued win dow dependences involving register data detected easily register designators completely specified within instructions however dependences involving memory data eg load store two stores ambiguous memory addresses computed straightforward solution problem ambiguous memory dependences issue loads stores addresses determined furthermore store allowed complete commit result memory preceding instructions known free ex ceptions store memory location creates speculative version location speculative versions held buffers committed multiple speculative stores location create multiple versions location improve performance loads allowed bypass buffered stores long different addresses load address buffered store use data bypassed store data becomes available important constraint approach load instruction cannot issued addresses preceding stores determined approach may diminish ilp unnecessarily especially common case load dependent preceding stores aggressive uniprocessor implementations issue load instructions soon addresses known even addresses previous stores may known implementations employ memory dependence speculation 8 predict load depend previous stores furthermore one also envision issuing computing store addresses order memory dependence speculation enables higher levels ilp advanced mechanisms needed support specula tion aggressive uniprocessors dispatch instructions single instruction stream issue load store instructions common set hardware buffers eg reservation stations using common set buffers allows hardware maintain program order loads stores via simple queue mechanisms coupled address comparison logic presence queues provides support simple form speculative versioning however proposed next generation processor designs use replicated processing units dispatch andor issue instructions distributed manner future approaches partition instruction stream sub streams called tasks 11 traces 10 higher level instruction control units distribute tasks processors execution processors execute instructions within task leading hierarchical execution model proposed next generation multiprocessors 9 12 provide hardware support dependence speculation also use execution models hierarchical execution model naturally leads memory address streams similar hierarchical structure particular individual task generates address stream properly ordered dis ambiguated within processor generates higher level multiple address streams produced processors must also properly ordered challenging support speculative versioning execution model superscalar execution model processor executes loads stores without knowing executed processors address resolution buffer 3 arb provides speculative versioning support hierarchical execution models entry arb buffers versions memory location however two significant performance limitations arb 1 arb single shared buffer connected multiple processors hence every load store incurs latency interconnection network also arb provide sufficient bandwidth processors 2 task completes instructions arb commits speculative state architected storage copies versions created task data cache write backs generate bursty traffic increase time commit task delays issue new task processor lowers overall performance propose new solution speculative versioning called speculative versioning cache 2 5 svc hierarchical execution models svc comprises private cache processor system organized similar snooping busbased cache coherent symmetric multiprocessor smp memory references hit private cache use bus smp task commits write back speculative versions en masse cache line individually handled accessed next time section 2 introduces hierarchical execution model briefly identifies issues providing support speculative versioning execution models section 3 presents svc progression designs ease standing section 4 gives preliminary performance evaluation svc highlight importance private cache solution speculative versioning derive conclusions section 5 2 speculative versioning first discuss issues involved providing support speculative versioning current generation processors second describe hierarchical execution model used proposed next generation processors third discuss issues providing support speculative versioning execution model use examples illustrate finally present similarities multiprocessor cache coherence speculative versioning hierarchical execution model use unification motivate new design speculative versioning cache speculative versioning involves tracking program order among multiple buffered versions location guarantee following sequential program semantics ffl load must eventually read value created recent store location requires load must squashed reexecuted executes store incorrectly reads previous version ii stores location follow load program order must buffered load executed ffl memory location must eventually correct version independent order creation ver sions consequently speculative versions location must committed architected storage program order 21 hierarchical execution model execution model dynamic instruction stream program partitioned fragments called tasks tasks form sequence corresponding order dynamic instruction stream higher level control unit predicts next task sequence assigns execution free processor processor executes instructions task assigned buffers speculative state created task wisconsin multiscalar 11 example architecture uses hierarchical execution model task misprediction detected speculative state tasks sequence including incorrectly predicted task invalidated 1 corresponding processors freed called task squash correct tasks sequence assigned exe cution task prediction validated commits copying speculative buffered state architected storage tasks commit one one order sequence task commits processor free execute new task since tasks commit program order tasks assigned processors program order alternative model recovery invalidates dependent b figure 1 task commits squashes example figure commits task squashes ini tially tasks 0 1 99 3 predicted speculatively executed parallel four processors shown figure 1a misprediction task 99 detected tasks 99 3 squashed buffered states invalidated new tasks 2 3 executed processors show figure 1b tasks currently executing said active task 0 completes exe cution corresponding processor freed task 4 assigned execution shown figure 1c program order represented sequence among tasks enforces implicit total order among processors arrows show order tasks speculatively executed parallel multiple speculative loadstore streams processors merged arbitrary order providing support speculative versioning execution models requires mechanisms establish program order among streams following subsections outline order established using sequence among tasks 211 loads task executes load soon address available speculating stores previous tasks sequence write location closest previous version location supplied load version could created either task previous task load supplied version previous task recorded indicate use potential definition definition store location previous task occurs load supplied incorrect version memory dependence violated 212 stores task executes store memory location communicated later active tasks sequence 2 task receives new version location previous task squashes use definition recorded location memory dependence violation detected tasks squashed task also squashed task misprediction simple squash model 213 task commits squashes oldest active task nonspeculative commit speculative memory state versions created stores task ar chains instructions maintaining information finer granularity paper assumes simpler model reality store communicated task created next version location chitected storage committing version involves logically copying versions speculative buffers architected storage data cache assume simple task squash model speculative state associated task invalidated squashed 22 examples speculative versioning figure 2 illustrates issues involved speculative versioning using example program sample execution program four processor hierarchical system use example later sections explain svc design figure 2a shows loads stores example program task partitioning instructions direct relevance figure 2b shows two snapshots memory system sample execution program snapshot contains four boxes one active task shows load store executed corresponding task program order among instructions translates sequence among tasks imposes total order among processors executing solid arrowheads show program order hollow arrowheads show execution time order examples example program b sample execution st 3 ld r st 0 a23 st 0 st 1 st 0 st 1 st 3 st 5 ld r ld r program order31st 1 dependence violation23 figure 2 speculative versioning example first snapshot taken task 1 executes store address tasks 0 3 already stored 3 task 2 executed load load supplied version created buffered task according original program load must supplied value 1 created store task 1 ie store load dependence violated violation detected task 1 stores address tasks including task 2 squashed executed second snapshot taken tasks squashed restarted 23 coherence speculative versioning actions performed memory accesses task commits squashes summarized table 1 functionality table requires hardware track active tasks processors executed loadstore location order among different copiesversions location cache coherent symmetric multiprocessors use similar functionality track caches copy every memory location smps however need track order among copies since copies single version event actions load record use definition task supply closest previous version store communicate store later tasks later tasks look memory dependence violations commit write back buffered versions created task main memory squash invalidate buffered versions created task table 1 versioning events actions smps typically use snooping 4 implement multiple readersingle writer protocol uses coherence directory collection sets tracks sharers line snooping bus based smp directory typically implemented distributed fashion comprising state bits associated cache line hand speculative versioning cache svc implements multiple readermultiple writer protocol tracks copies multiple speculative versions memory location protocol uses version directory maintains ordered sets line tracks program order among multiple speculative versions line ordered set list called version ordering list vol implemented several different ways svc proposed paper uses explicit pointers line implement linked list like sci 1 following sections elaborate design uses pointers cache line maintain vol private cache organization svc makes feasible memory system proposed next generation single chip multiprocessors execute sequential programs tightly coupled processors using automatic parallelization 9 12 previously ambiguous memory dependences limited range programs chosen automatic parallelization svc provides hardware support overcome ambiguous memory dependences enables aggressive automatic parallelization sequential programs 3 svc design section present speculative versioning cache svc progression designs ease standing design improves performance previous one tracking information begin brief review snooping busbased cache coherence present base svc design provides support speculative versioning minimal modifications cache coherence scheme highlight performance bottlenecks base design introduce optimizations one one rest designs 31 snooping bus based cache coherence figure 3 shows 4processor smp private l1 caches uses snooping bus keep caches consis tent cache line comprises address tag identifies data cached data cached two bits valid store representing state line valid v bit set line valid store dirty bit set processor stores line bus arbiter v valid store dirty tag v data next level memory snooping bus figure 3 smp coherent cache cache line one three states invalid clean dirty request load store processor l1 cache hits valid line requested tag appropriate state otherwise misses cache misses issue bus requests cache hits specifically load clean dirty line store dirty line result cache hits otherwise loadstore misses cache issues busreadbuswrite request l1 caches next level memory snoop bus every request cache valid line requested tag issues appropriate response according coherence protocol store clean line misses cache issues buswrite request invalidationbased coherence protocol invalidates copies line caches protocol allows dirty line present one caches however clean line present multiple caches simultaneously cache dirty line supplies data busread request cache issues buswback request cast dirty line replacement simple protocol extended adding exclusive bit state line cut traffic shared bus cache line exclusive bit set valid copy line perform store line locally svc designs discuss following sections also use invalidationbased protocol z z z z buswback flush replace buswrite invalidate ld r busread flush st 1 0state data wz caches figure 4 cache coherence example figure 4 shows snapshots cache lines tag address smp four processors w x z state cache line shown box corresponding cache empty box corresponding cache represents line present cache first snapshot taken processor z issues load misses private cache cache issues busread request cache x supplies data bus second snapshot shows final state lines clean later processor issues buswrite request perform store clean copies caches x z invalidated third snapshot shows final state chooses replace line casts line memory issuing buswback request final state shown fourth snapshot next level memory contains valid copy line 32 base svc design organization private l1 caches svc design shown figure 5 svc designs use organization base design minimally modifies memory system snooping busbased cache coherent smp support speculative versioning processors based hierarchical execution model assume memory dependences among loads stores executed individual processor ensured conventional loadstore queue design guarantees program order among loads stores different processors base design also assumes cache line size one word later design relaxes assumption first introduce modifications smp coherent cache discuss individual operations listed table 1 performed 1 cache line maintains extra state bit called load l bit shown figure 6 l bit set task loads line storing line potential bus arbiter version control logic next level memory snooping bus version control logic task assignment information vcl responses cache states snooped lines cache figure 5 speculative versioning cache v valid store l load tag pointer data figure base svc design structure line violation memory dependence case previous task stores line 2 cache line maintains pointer identifies processor l1 cache next copyversion version ordering list vol line thus vol line stored distributed fashion among private l1 cache lines important note pointer identifies processor rather task storing vol explicitly cache lines using pointers may necessary base design however necessary explicitly store vol advanced designs introduce base design ease transition advanced designs 3 svc uses combinational logic called version control logic vcl provides support speculative versioning using vol processor request hits private l1 cache need consult vol hence issue bus request vcl also used cache misses issue bus request snooped l1 caches next level memory states requested line l1 cache vol supplied vcl vcl uses bus quest program order among tasks vol compute appropriate responses cache cache line updated based initial state bus request vcl response block diagram version control logic shown figure 5 base design vcl responses similar disambiguation logic arb 3 disambiguation logic searches previous succeeding stages line execute load store respectively 321 loads loads handled way smp except l bit set line initially valid busread request vcl locates closest previous version searching vol reverse order beginning requestor version supplied requestor previous version buffered l1 caches next level memory supplies data task assignment information used determine position requestor vol vcl search vol reverse order entire list available list short 03 tasks data pointer state wz caches z ld r execution time order program order figure 7 base svc design example load illustrate load executed task 2 address example program figure 7 shows two snapshots one load executes one load completes box shows line tag address l1 cache valid bit explicitly shown number adjacent box gives processorcache identifier task identifier processor identifiers used explicit pointers line represent vol whereas task identifiers serve ease explanation examples task 2 executes load misses cache z results bus request vcl locates cache z vol address using program order searches vol reverse order find correct version supply version cache version created task 1 322 stores svc performs operations store miss compared cache coherent smp buswrite request issued store miss vcl sends invalidation responses caches beginning questors immediate successor task assignment order cache next version including l bit set invalidation response allows multiple versions line exist also serves detect memory dependence violations cache sends task squash signal processor receives invalidation response vcl l bit set line z z z st 3 st 1 w figure 8 base svc design example stores illustrate stores executed tasks 1 3 example program figure 8 shows four snapshots cache lines address first snapshot taken task 3 executes store results buswrite quest since task 3 recent program order store task 3 result invalidations note store line invalidate cache lines unlike smp allow multiple versions line second snapshot taken store task 3 completes task 1 executes store based task assignment information vcl sends invalidation response cache one cache one cache w next version line cache w included since l bit set sends invalidation response cache z load executed task 2 follows store task 1 program order already executed cache z detects memory dependence violation since l bit set receives invalidation response vcl tasks 2 3 squashed shown third snapshot shaded boxes final snapshot taken store task 1 completed 323 task commits squashes base svc design handles task commits squashes naive man ner processor commits task dirty lines l1 cache immediately written back next level memory lines invalidated write back dirty lines immediately list stores executed task maintained processor task squashed lines corresponding cache invalidated 33 base design performance drawbacks base design described two significant performance limitations make less desirable write backs performed processor commits task lead bursty bus traffic may increase time commit task delay issuing new task processor ii clean lines also invalidated task commits squashes buffered versions could stale new task allocated processor correct version may present caches consequently every task begins execution cold l1 cache increasing bandwidth demand following advanced designs eliminate problems tracking additional information 1 first advanced design ecs design section 35 makes task commits squashes efficient ease understanding design first present intermediate design ec design section 34 makes task commits efficient distributing write backs dirty lines time also retains readonly data l1 caches across task commits careful bookkeeping however assumes mispredictions occur present ecs design extends ec design allow task squashes task squashes simple base design efficient retain nonspeculative data caches across task squashes 2 second advanced design section 36 boosts hitrate ecs design allowing requests snarf 6 bus account reference spreading snarfing involves copying data supplied bus request issued another processor attempt combine bus requests indirectly 3 final design section 37 realistic allows size cache line one word 34 implementing efficient task commits ec ec design avoids expensive cache flushes task commits maintaining extra state bit called commit bit cache line task commits stall lines speculative versions written back ec design eliminates write back bursts bus task commits also extra hardware necessary maintain list stores performed task ec design improves cache utilization keeping l1 caches warm across tasks tag l v data v valid l load c commit store stale figure 9 ec design structure line structure cache line ec design shown figure 9 processor commits task c bit set cache lines operation entirely local l1 cache issue bus request dirty committed line written back necessary accessed next time either processor request bus request therefore committed versions could remain caches much later time since task created version committed order among committed uncommitted versions still maintained explicit pointers line order among versions necessary write back correct committed version supply correct version bus request ec design uses additional state bit stale bit retain readonly data across tasks first discuss loads stores handled caches committed uncommitted versions discuss stale bit 341 loads stores loads committed lines handled like cache misses issue bus request vcl searches vol reverse order beginning requestor closest previous uncommitted version version supplied requestor version found vcl supplies recent committed version version first committed version encountered reverse search committed versions need written back invalidated store miss committed versions purged similar fashion ld r figure 10 ec design example load illustrate load executed task 2 example program figure 10 shows two snapshots one load executes one load completes versions 0 1 committed c bit set lines caches x task 2 executes load misses cache z results bus request vcl knows task 2 head task determines cache x recent committed version cache x supplies data also written back next level memory committed versions version invalidated never written back memory vcl also inserts new copy version 1 vol modifying pointers lines accordingly second snapshot shows modified vol figure 11 illustrates actions performed store miss first snapshot taken store executed task 5 versions 0 1 committed task 5 executes store misses cache results buswrite request even though line committed ver sion vcl purges committed versions line determines version 1 written back next level memory versions version invalidated purging committed versions also makes space new version version 5 modified vol shown second snapshot contains two uncommitted versions st 5 figure 11 ec design example store 342 stale copies ec design makes task commits efficient delaying commit cache line later time therefore cache line could stale copy versions recent version buffered committed task could present caches base svc design introduce stale copies invalidates nondirty lines whenever task commits ec design uses stale bit distinguish stale copies correct copies avoids issuing bus request accesses correct copies additional information allows ec design retain readonly data correct copies across task commits first illustrate stale correct copies indistinguishable without bit show bit used ld r z cs cl ld r cl w3 y5 cs cs css w7z z figure 12 ec design correct stale copies figure 12 shows two execution time lines one leaves correct copy address shown using solid lines cache z another leaves stale copy address cache shown using dashed lines first time line shows sample execution modified version example program task 3 figure 2 execute store second time line shows execution original program first snapshot time lines second snapshot second time line taken tasks 0 1 committed c bit set caches new tasks 4 5 allocated final snapshot time lines taken tasks 4 7 active task 6 executes load first time line data cache z correct copy since versions created version 1 load supplied data resetting c bit without issuing bus request second time line copy cache z stale since creation version 3 hence load misses resulting bus request however cache z cannot distinguish two scenarios issue request cases consult vol obtain copy correct version ec design uses stale bit distinguish two scenarios avoids bus request whenever copy stale design maintains invariant recent version address copies bit reset copies versions bit set invariant easily guaranteed resetting bit recent version copy thereof created setting bit previous versions bits updated buswrite request issued create version busread request issued copy version hence generate additional bus traffic since stores different tasks executed program order active task could execute store copy bit set copy stale task stale next task allocated processor figure 13 shows two time lines example status bit cache z distinguish correct copy bit set stale copy bit set load hits correct copy present bus request issued ld r cstcl ld r z cst cst clt figure 13 ec design using stale bit ec design eliminates serial bottleneck flushing l1 cache task commits using commit c bit also design retains nondirty lines task commits long stale generally readonly data used program fetched l1 caches never invalidated unless chosen replaced cache miss task commits setting c bit lines l1 cache 35 implementing efficient task squashes ecs ecs design extends ec design allow task squashes ec design also ecs design makes task squashes efficient base design retaining nonspeculative data caches across squashes using another state bit architectural bit structure line ecs design shown figure 14 v valid store l load c commit stale architectural tag l figure 14 ecs design structure line task squashes uncommitted lines lines c bit reset invalidated resetting valid v bit invalidation makes pointers lines vols inexact vol dangling pointer last valid unsquashed copy version line status bit lines incorrect ecs design repairs vol line line accessed later either processor request bus request updating bits necessary hint avoid bus request squash would incorrectly reset stale version correct however ecs design updates bit bus request consulting repaired vol w cst st st w wz figure 15 ecs design vol repair figure repair example time line three snapshots first snapshot taken task squash occurs tasks 3 4 squashed version 3 invalidated vol incorrect bits dangling pointer shown second snapshot executes load misses cache w results bus request vcl resets dangling pointer bit cache vcl determines version supply load also recent committed version version back next level memory third snapshot taken load completed 351 squash invalidations base design invalidates nondirty lines l1 cache task squashes includes speculative data previous tasks architectural data next level memory committed tasks base design invalidates lines track creator speculative versions line hence cannot determine whether version line committed squashed squashing nonspeculative data leads higher miss rates tasks squashed restarted multiple times distinguish copies speculative architectural versions add architectural bit cache line shown figure 14 bit set copy either next level memory committed version supplies data bus request issued obtain copy else bit reset one vcl responses bus request specifies whether bit set reset copies architectural versions invalidated task squashes ie ecs design invalidates lines c bits reset copy speculative version used task becomes architectural copy task commits however bit set line accessed later task c bit reset bit set 36 hit rate optimizations base ecs designs incur severe performance penalties due reference spreading uniprocessor program executed multiple processors private l1 caches successive accesses line hit missing shared l1 cache could result series misses phenomenon also observed parallel programs miss rate readonly shared data private caches higher shared cache use snarfing 6 mitigate problem svc implementation snarfs data bus corresponding cache set free line available however active tasks cache snarf version task use unlike coherent cache vcl determines whether task copy particular version informs caches opportunity snarf data bus request 37 realistic line size base ecs designs assume line size l1 caches one word final svc design however allows lines longer word similar smp coherent cache observe effects due false sharing addition causing higher bus traffic false sharing leads squashes store cache line task executed outoforder load different byte word line later task mitigate effects false sharing using technique similar sector cache 7 line divided subblocks l bits maintained subblock size subblock versioning block less address block storage unit address tag maintained also store miss results buswrite request mask bits indicate versioning blocks modified store also made available bus 4 performance evaluation report preliminary performance results svc using spec95 benchmarks goal implementation evaluation prove svc design analyze performance underline importance private cache solution first showing performance degrades rapidly hit latency shared cache solution increased address resolution buffer arb shared cache solution use evaluation mitigate commit time bottlenecks arb using extra stage contains architectural data isolate effects pure hit latency performance bottlenecks 41 methodology configuration results paper collected simulator faithfully models multiscalar processor simulator dynamically switches functional detailed cyclebycycle model provide accurate fast simulation program memory system model includes fair amount detail including chip cache dram banks interconnects different levels memory hierarchy multiscalar processor used experiments 4 processors issue 2 instructions outoforder processor 2 simple integer alus 1 complex integer unit 1 floating point unit 1 branch unit 1 address calculation unit assumed completely pipelined interprocessor register communication latency 1 cycle processor send many two registers neighbor every cycle loads stores processor executed program order using loadstore queue 16 entries arb fullyassociative set 32byte lines total 8kb storage per stage five stages shared data cache backs arb 2way set associative 64kb size chip cache 4mb size total peak bandwidth 16 bytes per processor clock l1 data instruction task caches main memory access time first word 24 processor clocks rambuslike interface operates half speed processors provide peak bandwidth 8 bytes every bus clock caches memory 4way terleaved arb l1 data cache mshrswritebuffers buffer combine 8 accesses line disambiguation performed bytelevel base arb hit time varied 1 3 cycles experiments tags data rams single ported caches private caches comprise svc connected together chip cache 8word splittransaction snooping bus typical transaction requires 3 processor cycles 3 processor private l1 cache 16kb 4way setassociative storage lines loads stores nonblocking 8 mshrswritebuffers per cache buffer combine 4 accesses line disambiguation performed bytelevel l1 cache hit time fixed 1 cy cle tag ram dual ported support snooping data ram single ported 42 benchmarks used following programs spec95 benchmark suite train inputs except cases listed compress gcc refjumpi vortex perl ijpeg testspecmunppm mgrid testmgridin apsi fpppp turb3d programs stopped executing 1 billion instructions past experience know programs performance change significant beyond 1 billion instructions 43 experiments figure presents instructions per cycle ipc multiscalar processor either arb svc configurations keep total data storage svc arbcache storage roughly percentage miss rates arb svc shown top ipc bar clusters order svc access counted miss data supplied next level mem data transfers l1 caches counted misses preliminary experiments make three ob servations hit latency data memory significantly affects arb performance ii svc tradesoff hit rate hit latency arb tradesoff hit latency hit rate achieve performance iii total data storage svc performs better arb hit latency 2 cycles shown figure 16 graphs figures show performance improves range 5 20 decreasing hit latency arb 3 cycles 1 cycle improvement indicates techniques use private caches improve hit latency important factor increasing overall per formance even latency tolerant processors like multiscalar processor 3 bus arbitration occurs cache cache data transfers extra cycle used flush committed version next level memory compress gcc vortex perl ijpeg mgrid apsi turb3d ipc 3175 2136 2624 8193 2334 1122 6981 arb 3 cycle figure distribution storage svc produces higher miss rates arb attribute increase miss rates svc two factors first distributing available storage results reference spreading 6 replication data reduces available storage second latest version line caches finegrain shared data multiscalar tasks constantly moves one l1 cache another migratory data finegrain communication may increase number total misses well 5 conclusion speculative versioning important overcome limits instruction level parallelism ilp due ambiguous memory dependences sequential program pro posal called speculative versioning cachesvc uses distributed caches eliminate latency bandwidth problems previous solution address resolution buffer uses centralized buffer svc conceptually unifies cache coherence speculative versioning using organization similar snooping busbased coherent caches preliminary evaluation multiscalar architecture shows hit latency important factor affecting performance private cache solutions tradeoff hit rate hit latency svc provides hardware support break ambiguous memory dependences allowing proposed next generation multiprocessors use aggressive parallelizing software sequential programs acknowledgements thank scott breach andreas moshovos subbarao palacharla anonymous referees comments valuable suggestions earlier drafts paper work supported part nsf grants ccr 9303030 mip9505853 onr grant n00014931 0465 us army intelligence center fort huachuca contract dabt6395c0127 arpa order d346 donation intel corp views conclusions contained herein authors interpreted necessarily representing official policies endorsements either expressed implied u army intelligence center fort huachuca us government r ieee standard scalable coherent interface sci 1596 1992 data memory alternatives multiscalar pro cessors arb hardware mechanism dynamic reordering memory references using cache memory reduce processormemory traffic speculative versioning cache memory reference behavior cache performance shared memory multi processor structural aspects system360 model 85 part ii cache dynamic speculation synchronization data de pendences case singlechip multiprocessor trace processors moving fourthgeneration microarchitectures multiscalar processors potential threadlevel data speculation tightlycoupled multiprocessors tr wisconsin multicube new largescale cachecoherent multiprocessor expandable split window paradigm exploiting finegrain parallelsim boosting performance hybrid snooping cache protocols multiscalar processors case singlechip multiprocessor improving superscalar instruction dispatch issue exploiting dynamic code sequences dynamic speculation synchronization data dependences complexityeffective superscalar processors trace processors data speculation support chip multiprocessor scalable approach threadlevel speculation architectural support scalable speculative parallelization sharedmemory multiprocessors ieee standard scalable coherent interface science using cache memory reduce processormemory traffic potential using threadlevel data speculation facilitate automatic parallelization speculative versioning cache hardware speculative parallelization partiallyparallel loops dsm multiprocessors ctr arun kejariwal xinmin tian wei li milind girkar sergey kozhukhov hideki saito utpal banerjee alexandru nicolau alexander v veidenbaum constantine polychronopoulos performance potential different types speculative threadlevel parallelism dl version paper includes corrections made available printed proceedings proceedings 20th annual international conference supercomputing june 28july 01 2006 cairns queensland australia