high performance olap data mining parallel computers online analytical processing olap techniques increasingly used decision support systems provide analysis data queries posed systems quite complex require different views data analytical models need capture multidimensionality underlying data task multidimensional databases well suited multidimensional olap systems store data multidimensional arrays analytical operations performed knowledge discovery data mining requires complex operations underlying data expensive terms computation time high performance parallel systems reduce analysis timeprecomputed aggregate calculations data cube provide efficient query processing olap applications article present algorithms construction data cubes distributedmemory parallel computers data loaded relational database multidimensional array present two methods sortbased hashbased loading base cube compare performances data cubes used perform consolidation queries used rollup operations using dimension hierarchies finally show data cubes used data mining using attribute focusing techniques present results ibmsp2 parallel machine results show algorithms techniques olap data mining parallel systems scalable large number processors providing high performance platform applications b introduction online analytical processing olap 1 systems enable analysts managers gain insight performance enterprise wide variety views data organized reflect multidimensional nature enterprise data olap gives insight data fast consistent interactive access wide variety possible views information contrast traditional databases answers questions like addition olap used build decision support systems help extracting knowledge data olap used summarize consolidate view apply formulae synthesize data according multiple dimensions queries posed systems quite complex require different views data traditionally relational approach relational olap taken build systems relational databases used build query systems complex analytical query cumbersome express sql might efficient execute recently multidimensional database techniques multidimensional olap applied decisionsupport applications data stored multidimensional arrays natural way express multidimensionality enterprise data suited analysis cell multidimensional space represents tuple attributes tuple identifying location tuple multidimensional space measure values represent content cell data mining viewed automated application algorithms detect patterns extract knowledge data 2 algorithm enumerates patterns fits models data data mining algorithm data mining step overall concept knowledge discovery databases kdd large data sets analyzed searching patterns discovering rules automated techniques data mining make olap useful easier apply overall scheme decision support systems data mining techniques like associations classification clustering trend analysis 2 used together olap discover knowledge data approach data mining called attribute focusing targets consumer using algorithms lead user analysis data attribute focusing successfully applied discovering interesting patterns nba 5 applications earlier applications technique software process engineering 4 since data cubes aggregation values combinations attributes already calculated computations attribute focusing greatly facilitated data cubes present parallel algorithm calculate interestingness function used attribute focusing data cube typically large amounts data analyzed olap data mining applications adhoc analytical queries posed analysts expect system provide realtime performance parallel computers used scenario variety reasons scalable solutions build highly accurate data mining model quicker mining large databases constructing complex models take large amount computing power take hours valuable time scalable parallel systems reduce wait time minutes even seconds thus increasing productivity better understanding knowledge discovery process use many processors enables use memory larger database handled main memory attached processors currently considered mainmemory databases extensions disks using parallel io future work article present scalable parallel algorithm techniques olap multidimensional databases parallel construction maintenance data cubes use olap queries shown results show implementations scalable large number processors consolidation queries make use hi category examples distributive sum count minimum maximum algebraic average standard deviation maxnn largest values smallest values center mass holistic median mostfrequentie mode rank table 1 categories aggregate functions erarchies dimensions make olap queries possible different levels detail show performance algorithms olap council benchmark 15 models real olap environment ibm parallel machine ibm sp2 network rs6000 workstations connected together high speed communication switch fast getting popular parallel computing platform show use data cubes perform data mining using attribute focusing find twoway associations attributes easily extended nway associations best knowledge first effort high performance parallel computation data cubes molap data mining using rest paper organized follows section 2 gives overview data cube operators model parallel computation used given section 3 section 4 presents issues data cube construction section 5 presents parallel data cube construction molap section 6 gives results olap council benchmark suite ibmsp2 parallel machine section 7 presents consolidation queries use hierarchies defined various dimensions section 8 describes data mining data cubes results ibmsp2 section 9 concludes article 2 data cube data cube operator introduced recently gray et al 7 support multiple aggregates data cube computes aggregates along possible combinations dimensions operation useful answering olap queries use aggregation different combinations attributes data organized data cube calculating possible combinations groupbys data set k attributes would lead 2 k groupby calculations article present algorithms calculating data cube using multidimensional arrays distributed memory parallel computer cube treats k aggregation attributes dimension kspace aggregate particular set attribute values point space set points form kdimensional cube aggregate functions classified three categories shown table 1 distributive functions allow partitions input set aggregated separately later combined algebraic functions expressed terms distributive functions eg average expressed ratio sum count holistic functions median cannot computed parts combined 21 operations data cube data cube operators generalize histogram crosstabulation rollup drilldown subtotal constructs required financial databases following operations defined data cube ffl pivoting also called rotating involves rotating cube change dimensional orientation report page display may consist swapping two dimensions row column 2dcube introducing another dimension instead dimension already present cube slicingdicing operation involves selecting subset cube fixed attribute value given dimension reports values dimensions visualized slice data 3dcube dimensions hierarchy defined aggregations done different levels hierarchy going hierarchy higher levels generalization known rollup example aggregating dimension hierarchy day month quarter rollup operation ffl drilldown operation traverses hierarchy lower higher levels detail drilldown displays detail information aggregated point ffl trend analysis sequential time periods product date supplier d2 p3 d5 d4 d3 figure 1 example database sales data figure 1 shows multidimensional database product date supplier dimensions sales measure partitioning data set dimensions measures design choice dimensions usually hierarchy associated specify aggregation levels granularity viewing data example day month quarter year hierarchy date aggregate attribute represented introducing new value right hand side table figure 2 illustrates data cube set tuples given left hand side 7 22 olap alternatives traditionally olap systems build top relational database system referred relational olap rolap olap engine built top relational database generates analytical queries sql may become cumbersome complex queries affect performance relational systems embed multidimensional view underlying data alternatively multidimensional olap molap systems appeared recently use multidimensional databases modeled model year color sales chevy 1990 red 5 chevy 1990 blue 87 ford 1990 green 64 ford 1990 blue 99 ford 1991 red 8 ford 1991 blue 7 model year color sales chevy 1990 blue 87 chevy 1990 red 5 chevy 1990 92 chevy blue 87 chevy red 5 chevy 92 ford 1990 blue 99 ford 1990 green 64 ford 1990 163 ford 1991 blue 7 ford 1991 red 8 ford 1991 15 ford blue 106 ford green 64 ford red 8 1990 blue 186 1990 green 64 1991 blue 7 1991 red 8 ford 178 1990 255 1991 15 blue 193 green 64 red 13 270 figure 2 data cube illustration using relation multidimensional arrays olap operations intuitive view data provides sophisticated analytical functionality support complex queries data relationships modeled naturally intuitively spatial databases 8 represent model geometric objects points lines polygons etc multidimensional space molap data considered points multidimensional space attributes benefit spatial database techniques operations olap although different operations overlap containment etc used spatial databases benefit spatial indexing structures developed spatial databases 3 communication costs distributed memory parallel computers sharednothing machines consist set processors tens hundred connected interconnection network memory physically distributed across processors interaction processors message passing popular interconnection topologies 2d meshes paragon delta 3d meshes cray t3d hypercubes ncube fat tree cm5 multistage networks ibmsp2 machines cutthrough routed networks used modeling communication cost algorithms lightly loaded network message size traversing hops cutthrough ct routed network incurs communication delay given represents handshaking costs h represents signal propagation switching delays w represents inverse bandwidth communication network startup time often large several primitive running time p processors broadcast ots reduce ots parallel prefix ots gather ots log alltoall communication ots log p table 2 running times various parallel primitives multistaged network hundred machine cycles perword transfer time w determined link bandwidth w often higher order two orders magnitude typical c time unit computation data available cache parallelization applications requires distributing data structures among processors processor needs access nonlocal data required local computation generates aggregate collective communication structures several algorithms described literature primitives part standard textbooks 12 use collective communication provides level architecture independence algorithm design also allows precise analysis algorithm replacing cost primitive targeted architecture table 2 provides complexity analysis operations multistaged network costs used analysis algorithms presented next section 1 broadcast broadcast operation one processor message size broadcast processors 2 reduce given vector size processor binary associative operation reduce operation computes resultant vector size stores every processor th element resultant vector result combining th element vectors stored processors using binary associative operation 3 parallel prefix suppose x p data elements processor p containing x let omega binary associative operation parallel prefix operation stores value x processor p 4 gather given vector size processor gather operation collects data stores resulting vector size mp one processors 5 alltoall communication operation processor sends distinct message size every processor 4 data cube construction data cube operator ndimensional generalization groupby operator consider following query uses cube operator select model year color sumsales sales sales model ford chevy year 1990 1992 group cubemodel year color aggregate calculations needed ndimensional data cube example calculated query fmodel year colorg fmodel yearg fmodel colorg fyear colorg fmodelg fyearg fcolorg shown figure 2 abcd groupbys44431 figure 3 lattice cube operator several optimizations done naive method calculating aggregate separately initial data 7 optimizations 1 2 normally considered uniprocessor model optimization 3 added important consideration parallel implementation reduce overheads communication costs 1 smallest parent computing groupby selects smallest previously computed groupbys possible compute groupby consider four attribute cube abcd groupby ab calculated abcd abd abc clearly sizes abc abd smaller abcd better candidates actual choice made picking smaller abc abd 2 effective use cache aims using cache effectively computing groupbys order next groupby calculation benefit cached results previous calculation extended disk based data cubes reducing disk io caching main memory example computing abc abcd compute ab followed molap systems sizes intermediate levels fixed order determined easily 3 minimize interprocessor communication communication involved among processors calculate aggregates order computation minimize communication among processors interprocessor communication costs typically higher computation costs example higher communication cost first aggregate along b divide c among processors comparison cd c local aggregation processor along sufficient lattice framework represent hierarchy groupbys introduced 11 elegant model representing dependencies calculations also model costs aggregate calculations scheduling algorithm applied framework substituting appropriate costs computation communication lattice groupby calculations fourdimensional cube abcd shown figure 3 node represents aggregate arrow represents possible aggregate calculation also used represent cost calculation calculation order groupbys created depends cost deriving lower order one lower number attributes groupby higher order also called parent groupby example abd bd bcd bd one needs select one lower cost cost estimation aggregation operations done establishing cost model described later section aggregation assume total available memory processors large enough hold data sets memory reasonable assumption since parallel machines days 128256 mb main memory per node 16 nodes handle databases size 2gb larger data sets handled increasing number processors hence important develop scalable algorithms handle larger databases article develop inmemory algorithms calculate data cube external algorithms also explored part research 5 parallel data cube construction molap assume data provided set tuples stored file number distinct elements given attribute illustration purposes let b c attributes data set b c number distinct values respectively assume number distinct values dimension known however values determined database algorithm without loss generality let b c case made true simple renaming attributes let p number processors numbered n number tuples figure 4 shows various steps data cube construction algorithm step explained next subsections algorithm 1 parallel data cube construction operations step 1 partition tuples processors partitioning step 2 load tuples multidimensional array loading step 3 generate schedule order groupby calculations step 4 perform aggregation calculations aggregation step 5 redistributeassign subcubes processors query processing step 6 define local distributed hierarchies dimensions figure 4 steps parallel data cube construction first tuples partitioned p processors partitioning step partitioning phase followed loading phase multidimensional array loaded processor tuples acquired partitioning phase creates base cube loading either done hashbased method sortbased method implemented compared scalability properties followed aggregation phase calculates various aggregate subcubes describe phase next subsections 51 partitioning sample based partitioning algorithm used partition tuples among processors attribute used partitioning done ensure partitioning data coarsest grain possible divides nearly equally onto processors also establishes order x 2 p 2 p j x fact partitioning scheme used tuples end sorted locally processor algorithm illustrated figure 5 communication steps shown bold algorithm 2 sample based partitioning number processors step 1 sort tuples attribute locally processor step 2 pick sample size p attribute processor gather sample processor 0 sort locally step 3 pick splitters list processor 0 broadcast step 4 using splitters processor divides tuples p sorted partitions values attribute lower partition lower higher numbered partition step 5 using alltoall communication partition sent destination processor step 6 processor merges sorted partitions obtained processors resulting set tuples sorted globally attribute figure 5 sample based partitioning 52 loading tuples partitioned processors loaded multidimensional array mdarray size mdarray dimension number unique values attribute represented dimension tuple represented cell mdarray indexed values attributes hence measure needs loaded mdarray tuples describe two methods perform task hash based method sortbased method 521 hashbased method figure 6 describes hashbased cube loading algorithm attribute hashed get hash table unique values sort attributes hash table index dimension base cube corresponding attribute hash tables probed fill measure values base cube hashing techniques known provide good performance average though heavily depends choice good hash function 522 sortbased method figure 7 describes sortbased cube loading algorithm method provides regularity access sorted hash tables since attributes probing sorted unlike hashbased method algorithm 3 hashbased data cube loading algorithm number attributesdimensions step 1 tuple hash attributes separate hash table one attribute k hash tables created result hash phase step 2 compress sort hash table step 3 update index hash table order corresponding sorted list step 4a pick tuple probe hash tables attributes obtain indices dimension probe phase step 4b update cell index mdarray measure values tuple figure hashbased algorithm multidimensional data cube loading accesses hash table order sorted hashtables scanned one direction tuples value attributes dimensions come earlier ie unique values since order attributes sorted respect number unique values example two consecutive records table scanned current position get index however tables c need scanned beginning algorithm 4 sortbased data cube loading algorithm number attributesdimensions step 1 sort tuples locally processor way b sorted unique value c sorted unique value b note already sorted processor step 2 tuple hash attributes separate hash table one attribute k hash tables created result hash phase step 3 compress sort hash table step 4 pick tuple calculate indices attribute mdarray following way assume sorting order b c step 4a pick attribute innermost level sort linearly scan sorted hashed list pick index step 4b long values higher levels scan past point scan stopped last find index attribute value changes scan sorted hash lists start inner attributes step 4c update cell index mdarray measure values tuple figure 7 sortbased algorithm multidimensional data cube loading 53 aggregation example base cube shown figure 8 2 hence processor da portion illustrate costs calculating various groupbys base cube three attribute 3d cube table 3 let op cost addition copy cost copying byte communication modeled collective communication operations described previous section costs used scheduling algorithm generates schedule calculating various groupbys calculations local nonlocal need multiple processors exchange data leading communication among processors example local aggregate calculation abcd abd shown figure 9 even local calculations costs differ depending calculation made calculating ac abc requires summing b dimension calculating ac acd requires aggregation depending multidimensional array stored costs could different since stride access affect cache performance cost calculations shown table 3 see cost calculating aggregates parent lower order attributes aggregate prefix parent calculating abc ab local calculation node cube distributed across processors since dimension distributed intermediate cubes resulting aggregation parent cubes also distributed among processors results good load balancing among processors calculations involving multiple cubes also distributed across processors result first attribute aggregate cube always distributed among processors result distributed abcd abc ab b distributed bcd bc b c distributed cd c distributed figure 8 shows distributed abcd source target cost table 3 calculation groupbys three attribute data cube theta b theta c p processors figures 11 illustrate global aggregate calculation calculating abcd bcd first local aggregation done along dimension figure 10 followed reduce operation bcd figure 11 processor keeps corresponding portion bcd distributing b evenly among processors clearly observed aggregation calculations shown table multiple ways calculating group calculating aggregate level aggregates calculated multiple parents need pick assignment cost minimized 13 solved posing graph problem using minimum cost matching bipartite graph augmented cost model optimizations needed refer figure 3 suppose want calculate aggregates level k parent level k 1 bipartite graph e defined follows group nodes x nodes level k clearly jx another group nodes jy j nodes level k edges connecting nodes level k k belong e edge weights costs calculating particular aggregate level k parent level k 1 costs described table 3 used node level k possibly calculate aggregates level k hence nodes replicated many times level k added seek match d2 12345678 b b1b2b3b4 c c1c2 figure 8 basecube 4 attributes 4 processors 12 b b1b2b3b4 c c1c2 d2 d2 abcd abd op op figure 9 local aggregation calculation abcd abd processor p0 abcd bcd 12345678 b b1b2b3b4 c c1c2 d2 figure 10 global aggregation calculation local phase abcd bcd 12345678 b b1b2b3b4 c c1c2 abcd bcd reduce operation d2 d2 d2 d2 d2 figure 11 global aggregation calculation global phase abcd bcd nodes level k level k minimizes total edge costs figure 12 shows example calculating level 2 level 3 lattice figure 3 done level resulting order calculations level picked creates directed acyclic graph traversed base cube root child depth first search manner calculating aggregation results preserving three optimizations multiple groupbys described earlier section ad ac bd cd abd ab 15 bd ad ad ac bd cd bd figure 12 minimum cost matching calculation level 2 aggregates level 3 6 results implemented algorithms presented previous section using c message passing using message passing interface mpi ibm sp2 parallel machine node sp2 rs6000 processor 128mb memory interconnection network multistage network connected high speed switch use c mpi makes programs portable across wide variety parallel platforms little effort 61 data sets used olap council benchmark 15 simulates realistic online analytical processing business situation data sets attributes taken following set attributes product 9000 customer 900 time 24 channel 9 scenario 2 values brackets following attribute number unique values attribute taken size dimensions resulting multidimensional arrays subcubes data cube history sales data picked 1000 101 100 10 distinct values 4 attributes benchmark data generated records picking attribute randomly set distinct values attribute product customer channel character strings 12 characters time integer depicting year month eg 199704 april 1997 scenario 6 character string showing actual budget value measure stored cell array float value depicting sales figure particular combination attributes potentially contain many values used sum function compute aggregates results presented characteristics data sets summarized table 4 data set dimensions number records base cube dimensions data size shipping cost customer time scenario 27000 900 theta 24 theta 2 1mb production cost product time scenario 270000 9000 theta 24 theta 2 10mb current sales product customer channel 81000 608866 9000 theta 900 theta 9 320mb budget product customer time 951720 9000 theta 900 theta 12 420mb history sales product customer time channel 1010000 1000 theta 101 theta 100 theta 10 500 mb table 4 olap benchmark data sets used data cube construction 62 data cube construction present results different phases data cube construction data sets described figure 13 shows performance hashbased sortbased methods shipping cost data 27000 records observe algorithm scales well small data size individual component scales well also two methods take almost time data cube construction processors003008012018time sec shipping cost customer scenario time partition hash load aggregate total processors003008012018time sec shipping cost customer scenario time partition hash load aggregate total figure 13 various phases cube construction using hashbased b sortbased method shipping cost data production cost data contains 270000 records performance two methods data set shown figure 14 increase number processor component construction algorithm scales well resulting good overall scalability methods figure 15 shows performance hashbased sortbased methods current sales data 81000 records data density 011 aggregation time main component total time large cube size data set figure shows performance hashbased sortbased methods current sales data records data density 084 individual components increased except aggregation component number tuples increased data set affects components till loading phase aggregation times dependent cube size changed figure 17 gives performance budget data nearly million records 8 16 32 64 128 processors observed large data sets methods perform well increase number processors processors0208121822 time sec production cost product scenario time partition hash load aggregate total processors0208121822 time sec production cost product scenario time partition hash load aggregate total figure 14 various phases cube construction using hashbased b sortbased method production cost data n 270000 records processors0515253545556575time sec hashbased current sales customer product channel partition hash load aggregate total processors1030507090 time sec sortbased current sales customer product channel partition hash load aggregate total figure 15 various phases cube construction using hashbased b sortbased method current sale data processors1030507090110130 time sec hashbased customer product channel partition hash load aggregate total processors1030507090110130time sec sortbased customer product channel partition hash load aggregate total figure various phases cube construction using hashbased b sortbased method current sale data processors1030507090 time sec budget product customer time partition hash load aggregate total processors1030507090 time sec budget product customer time partition hash load aggregate total figure 17 various phases cube construction using hashbased b sortbased method budget data figure gives performance history sales data containing 4 attributes 4 dimensional base cube million records 8 16 32 64 processors density cube 1 hashbased method performs better sortbased method case addition dimension increases stride factor accesses sortbased loading algorithm deteriorating cache performance hashbased method particular order reference multidimensional array benefits better cache performance observed large data component cube construction scales well increase number processors processors1030507090110 time sec histsaleproduct customer time channel partition hash load aggregate total processors1030507090110 time sec histsaleproduct customer time channel partition hash load aggregate total figure various phases cube construction using hashbased b sortbased method history sales data next compare effect density data sets data cube construction algorithm size multidimensional array determined number unique values dimensions hence aggregation costs use multidimensional array affected change density seen figure 19 figure 20 phases data cube construction deal tuples number tuples increase density data set increases costs partition sort hash load phases increase number tuples processor increases scalability densities hashbased sortbased methods good observed figures comparing sortbased methods hashbased methods observe hashbased method performs slightly better 3d cubes lot better 4d case used multidimensional partition hash load aggregate total1030507090110130 time sec current sales customer product channel partition hash load aggregate total10305070 time sec current sales customer product channel partition hash load aggregate total05152535time sec current sales customer product channel figure 19 comparison cube construction components two different densities hash based method partition sort hash load aggregate total1030507090110130150 time sec current sales customer product channel partition sort hash load aggregate total0515253545556575time sec current sales customer product channel partition sort hash load aggregate total0515253545 time sec current sales customer product channel figure 20 comparison cube construction components two different densities sort based method array outermost dimension array one changing slowest match innermost sorteddimension innermost dimension used attribute largest number unique values make aggregate calculations efficient sortbased loading algorithm starts innermost attribute sorted order also smallest dimension also happens outermost dimension array maximum stride done make accesses aggregate calculation regular largest dimension innermost dimension chunking arrays 14 make memory accesses sortbased method regular since favor particular dimension contiguous storage 7 aggregate query processing data dimensions hierarchies defined typical olap queries probe summaries data different levels hierarchy consolidation widely used method provide rollup drilldown functions olap systems hierarchies used data mining multiple levels attribute oriented approaches discussed later section attributeoriented induction 9 performed association rule discovery ascending predefined concept hierarchy dimension cube potentially hierarchy defined hierarchy applied subcubes data cube discuss following subsections 71 hierarchies figure shows example hierarchy 3d base cube location time person attributes dimensions assume hierarchies city quarter group defined dimensions dimension represents attribute value dimension distinct value attribute hierarchy describing grouping attribute values defined dimension hierarchy hierarchy several levels figure 21 defines first level hierarchy dimension b distributed dimension hierarchy distributed processor boundary global index hierarchy maintained processor example cities c3 distributed across p 0 p 1 figure containing indices 7 8 9 consolidation operation would need interprocessor communication consolidated value c3 required hierarchy higher levels defined similarly support roll operations using consolidation provided along dimension drill downs use index appropriate dimension index provide higher level detail hierarchy defined dimension base cube hence subcubes data cube use hierarchy since dimensions subcubes subset dimensions base cube additionally dimensions get distributed processors distributed hierarchy needs maintained dimensions well example cube time person 2d cube calculated location time person time distributed dimension distributed hierarchy needs maintained result dimension two hierarchies one local one distributed queries choose appropriate hierarchies performing operations cubes person c c c c c c c c c3 c4 c5 q3 q3 location time figure 21 example hierarchy defined dimensions two processor case 72 consolidation consolidation provides aggregate hierarchies defined dimension example desired report value group g1 city c1 quarter q1 corresponding values aggregated using dimension hierarchy defined previous section consolidation operations local performed single processor like c4 figure however operations nonlocal like values city c3 quarter need aggregates values processors shown figure 22 interprocessor communication needed aggregate data get correct result local q3 q3 location time person nonlocal figure 22 consolidation level 1 hierarchy defined cube figure 21 73 results use olap council benchmarks described earlier define sample hierarchies dimension table 5 defines sample hierarchy first two levels experiments divided dimension hierarchy level 1 level 2 customer 9 4 product 8 3 channel time 8 2 table 5 sample level 1 level 2 number groups hierarchies defined dimensions size dimension equally among number groups defined hierarchy level allocation actual attribute values groups higher level contiguous experiments however arbitrarily assigned desired figure 23 shows times performing consolidation operation using hierarchies dimensions current sales used level 1 hierarchy product customer history sales data hierarchy used dimensions ie product customer time channel figure budget also includes hierarchies along dimensions product customer time see good scaling properties data set number processors increased comparing consolidation time current sales budget observe time budget data lower even though base cubes similar size presence hierarchy along time dimension outermost dimension multidimensional array improves cache performance chunks size 12 9 theta 9000 8 outermost innermost dimension consolidated budget whereas chunks size 9 theta 900 9 theta 9000 8 consolidated current sales however scale well number processors increased time sec currsale consolidation query time sec histsale consolidation query processors012038062088112time sec budget consolidation query figure 23 time consolidation query using hierarchies defined table 5 current sales history sales budget data sets 8 data mining data cubes data mining techniques used discover patterns relationships data enhance understanding underlying domain data mining tool understood along following components data analyzed statistics kind patterns searched tool filtering many patterns presented user selection patterns visualization visual representation used present patterns user interpretation user think studying pattern exploration order patterns considered user process support one support data mining process opposed exercise done attribute focusingaf data mining method particular relies exploration interpretation 5 discovery quantitative rules associated quantitative information database data cube represents quantitative summary information subset attributes attributeoriented approaches 5 9 10 data mining datadriven use summary information discover association rules transaction data used mine association rules associating support confidence rule support pattern set ratio number transactions containing total number transactions confidence rule b probability pattern b occurs pattern occurs defined ratio support ab support rule described bsupport confidence strong association rule support greater predetermined minimum support confidence greater predetermined minimum confidence also taken measure interestingness rule calculation support confidence rule b involve aggregates cube ab additionally dimension hierarchies utilized provide multiple level data mining progressive generalization rollup deepening drilldown useful data mining multiple concept levels interesting information potentially obtained different levels attribute focusing calculates associations attributes using notion percentages sub populations overall distribution attribute compared distribution various subsets data certain subset data characteristically different distribution focus attribute combination attributes marked interesting event e string x j possible value attribute x k value different attribute underlying data e interesting x j occurrence depends x occurrence interestingness measure size j e difference probability e among events data set b probability x 1 occurred independently condition interestingness defined j e ffi ffi fixed threshold another condition interestingness attribute focusing depends finding optimal number attribute values n formally described j en af seeks eliminate interesting events keeping e number attribute values n right eliminate one x j decreases include one ore new x string j gets larger convergence n removes patterns like engamma1 en1 less interesting en information already contained en hence result user drill roll highlighted pattern since event descriptions returned interesting level 81 attribute focusing data cubes section present algorithm compute first measure interestingness attribute focusing method using data cubes figure 24 shows algorithm algorithm 5 calculation interestingness using data cubes step 1 replicate single attribute subcubes processors using gather followed broadcast step 2 perform reduce operation 0d cube followed broadcast get correct value processors step 3 take ratio element ab subcube get p ab similarly calculate p p b using replicated subcubes b step 4 element ab calculate jp compare threshold ffi setting abi 1 greater else set 0 figure 24 algorithm calculating interestingness attributes b data cubes consider 3 attribute data cube attributes b c defining showing 2way associations calculate interestingness function b c finally b c calculating associations b probability e denoted p ab ratio aggregation values subcube ab similarly independent probability p obtained values subcube dividing p b similarly calculated b calculation threshold ffi performed parallel since cubes ab distributed along dimension replication needed however since b distributed subcube b b local processor ab b needs replicated processors ab cubes distributed b replicated processors figure 25 shows sample calculation pab pa pb three processors sample calculation highlighted figure greater ffi values 0001 001 corresponding attribute values associated within threshold figure 25 use aggregate subcubes ab b calculating interestingness three processors 82 results used data sets olap council benchmark particular current sales 3d bud get3d history sales 4das described previous sections perform 2way association calculations performing attribute focusing combinations two attributes example 3d cube abc interestingness measure calculated b c b c typically different ffi values used analysis data vary degree association attributes run calculation 20 different ffi values ranging 0001 002 steps 001 figure 26 shows time calculations current sales data 4 8 16 32 processors observe good speedups number processors increased also communication time increases number processors increased replication 1d cubes involve communication larger number processors terms involving p complexity collective communication operations refer table 2 increase however since communication time marginal compared computation times increase affect overall scalability processors1030507090110time sec currsale attribute focusing processors2060100140 time msec currsale communication time af figure 26 time attribute focusing time 20 different ffi values current sales data b associated communication cost milliseconds 4 8 16 processors figure shows attribute focusing calculation time history sales data associated communication time slightly higher case since 4 1d arrays replicated instead 3 3d case communication time shown milliseconds still least order magnitude smaller computation time size cubes smaller current sales data hence magnitudes time much smaller hence speedups modest increase number processors processors003008012018time sec histsale attribute focusing processors2060100140180time msec histsale communication time af figure 27 time attribute focusing 20 different ffi values history sales data b associated communication cost milliseconds 8 16 processors figure 28 shows speedups observe budget data attribute focusing calculations communication costs similar ones observed current sales data since involve similar sized arrays processors050150250350450550650time sec budget attribute focusing time processors1030507090110130150170190210 time msec budget communication time af figure 28 time attribute focusing 20 different ffi values budget data b associated communication cost milliseconds 8 16 32 64 processors 9 conclusions online analytical processing fast gaining importance business data analysis using large amounts data high performance computing required provide efficient analytical query processing olap systems aggregations important function olap queries benefit data cube operator introduced 7 multidimensional databases recently gained importance since model multidimensionality data intuitively easy visualize provide support complex analytical queries amenable parallelization data analyzed comes relational data warehouses hence multidimensional databases need interface relational systems article presented algorithms techniques constructing multidimensional data cubes distributed memory parallel computers perform olap data mining operations two methods base cube loading sortbased hashbased perform equally well small data sets hashbased method better larger data sets increase number dimensions would expect sortbased method outperform hashbased method large amounts data due regularity accesses cube loading sorted data provides mismatch order dimensions using multidimensional array make memory usage sortmethod efficient sortbased method expected better external memory algorithms result reduced disk io hashbased method since olap operations frequently require information varying degree detail developed methods perform consolidation queries defining levels hierarchies dimension results show techniques scalable large number processors finally shown implementation scalable data mining algorithm using attribute focusing techniques platform independent portable across wide variety parallel platforms without much effort currently investigating efficient sparse methods multidimensional sparse arrays diskbased algorithms techniques apply parallel io optimizations perform olap data mining acknowledgments would like thank inderpal bhandari ibm tj watson research center discussions helpful comments r providing olap useranalysts mandate data mining knowledge discovery overview advanced scout data mining knowledge discovery nba data case study software process improvement development attribute focusing data mining layman parallel data cube construction high performance online analytical process ing data cube relational aggregation operator generalizing groupby crosstab subtotals introduction spatial databases discovery multiplelevel association rules large databases implementing data cubes efficiently introduction parallel computing design analysis algorithms computing data cube efficient organization large multidimensional arrays olap council benchmark performance arraybased adt olap workloads tr ctr sanjay goil alok choudhary high performance multidimensional analysis large datasets proceedings 1st acm international workshop data warehousing olap p3439 november 0207 1998 washington dc united states sanjay goil alok choudhary high performance multidimensional analysis data mining proceedings 1998 acmieee conference supercomputing cdrom p12 november 0713 1998 san jose ca raymond ng alan wagner yu yin icebergcube computation pc clusters acm sigmod record v30 n2 p2536 june 2001 muto masaru kitsuregawa dynamic load balancing strategy parallel datacube computation proceedings 2nd acm international workshop data warehousing olap p6772 november 0206 1999 kansas city missouri united states ying chen frank dehne todd eavis andrew rauchaplin parallel rolap data cube construction sharednothing multiprocessors distributed parallel databases v15 n3 p219236 may 2004 lixin fu joachim hammer cubist new algorithm improving performance adhoc olap queries proceedings 3rd acm international workshop data warehousing olap p7279 november 0611 2000 mclean virginia united states ying chen frank dehne todd eavis andrew rauchaplin pnp sequential external memory parallel iceberg cube computation distributed parallel databases v23 n2 p99126 april 2008 frank dehne todd eavis susanne hambrusch andrew rauchaplin parallelizing data cube distributed parallel databases v11 n2 p181201 march 2002 hammer lixin fu cubist evaluating adhoc cube queries using statistics trees distributed parallel databases v14 n3 p221254 november frank dehne todd eavis andrew rauchaplin cgmcube project optimizing parallel data cube generation rolap distributed parallel databases v19 n1 p2962 january 2006 alex freitas understanding crucial role attributeinteraction data mining artificial intelligence review v16 n3 p177199 november 2001