jacobidavidson style qr qz algorithms reduction matrix pencils recently jacobidavidson subspace iteration method introduced new powerful technique solving variety eigenproblems paper exploit method enhance several techniques practical accurate algorithms obtained present two algorithms jdqz generalized eigenproblem jdqr standard eigenproblem based iterative construction generalized partial schur form algorithms suitable efficient computation several even multiple eigenvalues corresponding eigenvectors near userspecified target value complex plane attractive property algorithms explicit inversion operators avoided makes potentially attractive large sparse matrix problemswe show effective restarts incorporated jacobidavidson methods similar implicit restart procedure arnoldi process discuss use preconditioning finally illustrate behavior algorithms number wellchosen numerical experiments b introduction paper expand usage jacobidavidson method 26 24 computation several solutions generalized eigenproblem 1 b large sparse n nmatrices may complex andor nonnormal also discuss standard eigenproblem 2 course generalized eigenproblem reduces standard eigen problem could restricted generalized eigenproblem case however simplifications possible help reduce memory requirements computational complexity phenomena easier explain algorithms based jacobidavidson method described 26 adapted generalized eigenproblems polynomial eigenproblems 24 modified jacobidavidson approach partial general ized schur forms computed partial schur forms chosen mainly received editors march 4 1996 accepted publication revised form march 5 1997 published electronically august 7 1998 httpwwwsiamorgjournalssisc20130007html department mathematics utrecht university po box 80010 nl3508 utrecht netherlands sleijpenmathruunl vorstmathruunl current address ise integrated systems engineering ag technopark zurich technopark strasse 1 ch8005 zurich switzerland fokkemaisech 1 family b called matrix pencil generalized eigenvalues solutions 1 also called eigenvalues matrix pencil cf eg 30 numerical stability since involve orthogonal bases bases also useful deflation another ingredient algorithms jacobidavidson approach lowdimensional search subspace generated onto given eigenproblem projected standard rayleigh ritz procedure also underlies lanczos arnoldi davidson methods small projected eigenproblem solved standard techniques leads approximations wanted eigenvectors eigenvalues given large problem davidson method 5 solution simplified correction equation used expansion search subspace following old idea jacobi 11 also set correction equation acting subspace orthogonal current eigenvector approximation defines optimal orthogonal expansion search subspace precise exact value eigenvalue known correction equation defines exact eigenvector modification davidsons method referred jacobidavidson method note nothing diagonal preconditioning popular combination davidsons method jacobi correction equation may solved method choice large problems often ecient solve equation approximately iterative method speed convergence iterative method may improved preconditioning place preconditioning exploited jacobidavidson method noted preconditioning aect given eigenproblem including shifts jacobidavidson method proper selection approximate eigenpair correction equation process tailored find eigenpairs close given target value details given sections 22 3 small projected problem reduced generalized schur form qz method 15 qr 8 construction subspace projected system may viewed iterative inexact forms qz qr reason named new methods jdqz jdqr respectively jdqz produces partial generalized schur form generalized eigenproblem partial qzdecomposition jdqr generates partial schur form standard eigen problem partial qrdecomposition restarts form essential ingredient almost iterative method also jacobidavidson method either computation eigenpairs one eigenpair converged limits dimension subspaces memory limitations case usual restart procedure disadvantage subspace may contain useful information replaced one single vector much valuable information may lost problem solved elegantly arnoldi method 28 see also 17 approach cf section 23 related see also 26 section 53 approach subspace suitably filtered retain much relevant information possible expansion filtering used repetitive way generalized eigenproblem section 2 forms heart paper shown implicit restart techniques preconditioning used order get inversefree computationally ecient algorithms resulting algorithm jdqz enhanced deflation technique several solutions eigenproblem computed computation interior eigenvalues normally risky aair want avoid shiftandinvert operations discuss rather robust technique based idea harmonic ritz values 16 19 26 r fokkema g l g sleijpen h van der vorst section 3 focuses standard eigenproblem course standard eigenproblem viewed simplification generalized eigenproblem obvious way jdqz simplifies jdqr method standard eigenproblems however chosen pay slightly attention standard eigenproblem since simplification makes easier discuss computational aspects algorithms particular consider problem preconditioning detail ponder observed speed convergence using wellknown arguments section 4 illustrate convergence behavior jdqz jdqr numerical experiments number eigenproblems aspects investigated concern among others eect approximation errors solution correction equation section 41 eect preconditioning section 42 multiple eigenvalues section 46 interior eigenvalues sections 43 47 dierent approaches construction projected deflated problem sections 43 47 implicit versus explicit deflation section 45 section 5 collected conclusions remark 1 computations done complex arithmetic necessary alternative real matrices would use quasischur forms 2 2 blocks diagonal computed real arithmetic real matrices possible derive variant jacobidavidson based blocked form discuss alternative variant remark 2 boldface letters indicate variables associated large ndimensional space lowdimensional spaces use italic letters use tilde indicate quantity approximates corresponding quantity without tilde q approximates q etc algorithms given matlab style use matlab conventions refer entries matrices vectors particular algorithms new values overwrite old ones tildes deleted 2 generalized eigenproblem 21 preliminaries convention 1 denote generalized eigenvalue matrix pair b pair approach preferred underflow overflow finite precision arithmetic may occur andor zero close zero case pair still meaning useful 15 21 30 chvi remark 3 observe 0 pairs correspond generalized eigenvalue rather scaling coecients algorithms instance 0 1 follow advise 15 show results produced qz algorithm size may give valuable information conditioning computed eigenpair however construction algorithm choice parameters leads implicit scaling generalized eigenproblems partial generalized schur form defined follows definition 1 partial generalized schur form dimension k matrix pair b decomposition orthogonal nkmatrices k k upper triangular kmatrices column q q k referred generalized schur vector jacobidavidson style qr 97 refer pair q k k generalized schur formulation 3 equivalent furthermore x generalized eigenpair k k q k x generalized eigenpair b 22 jacobidavidson briefly describe jacobidavidson generalized eigenproblem 1 details refer 24 similar subspace approaches standard eigenproblems step approximate eigenvector q selected search subspace spanv galerkin condition associated approximate generalized eigenvalue requires orthogonality respect test subspace spanw generalized case view 3 4 natural take test subspace spanw dierent search subspace petrovgalerkin approach search subspace test subspace dimension say j equation 5 leads projected eigenproblem solved conventional techniques solution u selected note 6 jdimensional problem petrov vector residual r q associated petrov value computed subspaces spanv spanw expanded step iterative process variant jacobi davidson method used paper search subspace expanded vector v orthogonal q solves approximately jacobi correction equation z essential dierence davidson approach inclusion left right orthogonal projections correction equation shown nonzero z spana q b q 7 solved exactly convergence generalized eigenvalue quadratic see 24 th 32 next iteration algorithm spanv v defines new search subspace explain expand w appropriately since prefer orthogonal matrices v w similar z q 3 new columns v w orthonormalized modified gramschmidt stable variant gram schmidt use qz algorithm 15 reduce 6 generalized schur form j dimension spanv algorithm yields orthogonal j jmatrices u r u l upper triangular j jmatrices b decomposition reordered first column u r 1 1 entries b represent wanted petrov solution 6 33 34 7 matlab version reordering algorithm see 7 ch 6c r fokkema g l g sleijpen h van der vorst decomposition 8 construct approximate partial generalized schur form cf 3 vu r approximates q k wu l approximates associated z k since spanz k makes sense choose w scalars 0 0 say 0 space spanw coincides span choice also line restriction z quadratic convergence summary proposed method following main ingredients form projected system 6 reduce ordered generalized schur form 8 select approximate generalized eigenpair vu r 1 1 1 b 1 1 form jacobi correction equation b q normalization constant choice 0 0 discussed later section 24 compute approximate solution v q 9 note vur 1 normalized expand v orthonormal complement v w orthonormal complement w modified gramschmidt used computation orthonormal complements shown choices z w approach relation partial generalized schur form large problem complete generalized schur form small problem 6 via right vectors similar relation via left vectors fact also convenient restart purposes see section 23 convergence expand partial schur form converged schur vector repeat algorithm deflated pencil eigenpairs details deflation see section 25 23 practical selection implicit restart reduced projected eigenproblem 6 generalized schur form qz algorithm 15 exploit generalized schur form various purposes selection petrov pair q selection corresponding left vector z cf 12 restriction dimension subspaces spanv spanw necessary deflation convergence petrov pair explain first third points detail section jacobidavidson style qr 99 suppose generalized schur form pencil given ordered respect j dimension spanv vu r 1 1 1 b 1 1 petrov approximation corresponding projected system 6 petrov value closest target corresponding left vector given furthermore vu r spans subspace contains promising petrov vectors corresponding test subspace given wu l therefore want reduce dimension subspace implicit restart j min j min j simply discard columns v j min1 v j w j min1 w j continue jacobidavidson algorithm cf 26 section 53 remark 4 restart strategy follows similar ideas implicitly restarted arnoldi ira 28 however 28 implicit shifts used delete unwanted part instead explicitly selecting wanted portion krylov subspace situation ira complicated reduced search subspace krylov subspace details see 28 13 24 values 0 0 explain select scalars 0 0 10 restriction 0 scaling avoids trivial expansions discuss two approaches first one section 241 viewed generalization approach ritz values standard eigenproblems optimal expansion test subspace second one section 242 related approach harmonic ritz values aims optimal selection petrov pairs 241 fixed values 0 0 v expansion vector search subspace general setting expand test subspace 0 av 0 bv note q new approximate eigenvector expanding old search subspace v equivalent expanding q new test subspace also obtained expanding 0 q obvious choice would obvious choice would case although b q direction q close eigenvector q multiplication b may diminish important eigenvector components q eigenvalue b associated q small therefore expanding test space b q may much less optimal expanding q presence rounding errors eect may even prominent 100 r fokkema g l g sleijpen h van der vorst value function maximal denotes complex conjugate approach seen attempt expand test subspace spanw optimally direction z z normalized vector aq bq since choose 0 0 know generalized eigenvalue best particular initial phase process select 0 target value approach choice scalars made adaptively see 7 ch 6 section 31 practice seen much advantage approach compared approach discussed section 242 242 values 0 0 based harmonic petrov values section introduce harmonic petrov values see harmonic petrov values closest target considered extremal ritz values specific test subspace also target interior spectrum particular computation interior eigenvalues harmonic petrov values appear attractive competitors standard petrov values approaches section 241 generalized eigenproblems costs computation harmonic petrov values standard petrov values extremality property harmonic petrov values closest target appear best choices also early stages process line observations standard eigenproblems made 16 26 first consider computation eigenvalues standard eigenproblem close target value interior convex hull spectrum transformation 1 maps eigenvalues extremal eigenvalues case correct eigenpair approximations obtained easily however want avoid matrix inversion formula manipulation shown achieved taking search subspace test subspace equal spana iv cf 26 section 51 resulting eigenvalue approximations solutions solutions called harmonic ritz values respect cf 19 26 also used 16 vu associated harmonic ritz vector since w w 1 span space harmonic ritz values appear petrov values test subspace generated 11 0 jacobidavidson style qr 101 generalized problems 0 0 17 petrov values closest target value correspond absolute largest ritz values standard eigenproblem matrix therefore generalized case also better selection appropriate eigenpair approximations may expected refer petrov values associated choice test subspace harmonic petrov values 25 expansion schur form deflation section focus ecient computation set generalized eigenpairs idea use jacobidavidson method computation partial generalized schur form major step solving generalized eigenproblems suppose partial generalized schur form aq bq want expand partial generalized schur form suitable q z deduce generalized schur pair q satisfies leads hence q satisfies generalized schur pair q therefore also eigenpair deflated matrix pair jdqz solve eigenproblem jacobidavidson method detail procedure follows let v w orthogonal n j matrices v q denote generalized schur form matrix pair b 2 note jacobi correction equation 7 similar structure derived similar way r fokkema g l g sleijpen h van der vorst generalized schur form ordered respect target value vu r 1 1 1 b 1 1 petrov pair approximation solution 20 corresponding left vector given jacobidavidson method expands v orthogonal complement v approximate solution generalized deflated jacobi correction equation q note q also expand w expand complement z k1 z q orthogonal respect w generalized schur pair q suciently close q may continue still another generalized schur pair case v w replaced vu r order obtain new search subspace orthogonal spanq k1 q new test subspace orthogonal spanz k1 respectively continue process 26 solution deflated correction equation section discuss generalized deflated jacobi correction equation solved preconditioning involved correction equation 20 involves operator domain image space dier means krylov subspace methods cannot applied right away fortunately fixed easily incorporating preconditioning preconditioning correction equation 20 propose use preconditioner k b introduce following notation notation 1 q matrix q k1 expanded z matrix z k1 expanded z k expanded matrix preconditioned vectors k projected preconditioner z k notation left preconditioned correction equation generalized correction equation 24 written section 32 give details simpler standard eigenproblem jacobidavidson style qr 103 course right preconditioned generalized correction equations derived well v note operators preconditioned correction equation 26 domain image space coincide krylov subspace methods used pseudocode preconditioned jacobidavidson qz algorithm harmonic petrov values discussed section 242 given algorithm 1 table 1 listed main computational ingredients per iteration jdqz table computational costs jdqz per iteration integers j k denote dimensions spanv spanq respectively part dots axpys mvs k correction equation variable costs projected problem 6j petrov approximation 2k krylov subspace methods used solve correction equation products av bv often already available side products mvs needed part b instead computing residual r bq r may also computed algorithm 1 depending number nonzeros b value j may ecient 3 jacobidavidson standard eigenproblem jdqz algorithm simplifies greatly used improve computational eciency also consider situation order discuss specific aspects preconditioning noted simplifications lead memory ecient algorithm give working harmonic ritz values since involve skew instead orthogonal projections standard setting 26 computation exterior eigenvalues pose serious problems interior eigenvalues prefer robust harmonic eigenvalue approximations section 242 orthogonal projections means prefer jdqz instead algorithm discussed section natural choice projected eigenproblem reduces cf 6 lowdimensional problem select solution u standard computational techniques ritz value ritz vector approximate 104 r fokkema g l g sleijpen h van der vorst algorithm 1 preconditioned jdqz using harmonic petrov values function qzra rb k k max else correction equation solve v approximately projected problem found found implicit restart part see algorithm 2 jdqz returns partial generalized schur form q z ra rb dimension kmax matrix pair b generalized eigenvalues near target k preconditioner b v 0 initial guess stopping tolerance jmax j min specify dimension search subspace implicit restart respectively qz matlab function computes generalized schur decomposition function mgs performs modified gramschmidt qzsort sorts generalized schur form matlab implementations mgs qzsort found 7 ch 6ac jacobidavidson style qr 105 algorithm 2 found implicit restart part preconditioned jdqz harmonic petrov values found eigenvalue eigenvector respectively residual r q assume q expansion v take vector v q solves approximately correction equation expanded search subspace spanv v exact arithmetic v orthonormal used modified gramschmidt computations construction orthonormal basis search subspace mentioned introduction replaced correction equation 29 eigenvalue associated eigenvector contained space spanned v exact solution jacobicorrection equation correction equation 29 solved exactly speed convergence selected ritz values asymptotically quadratical cf 26 24 reduce projected eigenproblem 28 schur form qr algorithm 8 exploit schur form selection ritz pair q restriction dimension subspace spanv way explained section 23 note case reordering algorithm schur form found instance 29 9 20 fortran implementation available lapack 1 simple matlab implementation reordering respect target value given 7 ch 6b 31 jdqr standard eigenproblem use jd algorithm computation partial schur form written cf 22 106 r fokkema g l g sleijpen h van der vorst orthogonal n kmatrix r k upper triangular k k matrix column q matrix q k schur vector pair q schur pair diagonal entries matrix r k represent eigenvalues x eigenpair r k q k x eigenpair resulting simplification jdqz referred jdqr although simplifications obvious give main expressions jdqr ease reference suppose k 1 schur pairs detected ie already partial schur form aq new schur pair q eigenpair deflated matrix solve eigenproblem deflated matrix 30 precisely jd algorithm deflated matrix 30 constructs subspace spanv finding approximate eigenpairs v orthogonal matrix v q deflated interaction matrix ordered schur form gives approximation q wanted eigenpair deflated matrix 30 according jacobi davidson approach search subspace spanv expanded orthonormal complement v v v approximate solution deflated jacobi correction equation q note projections 32 subdivided two parts part associated jacobidavidson deflation part observe also q k1 remark 5 two deflation techniques found literature subspace methods like arnoldis method referred explicit implicit deflation cf eg 22 ch vi section 23 explicit deflation computation continued deflated matrix detection schur vectors eciency reasons qrq used schurwielandt deflation rather stable representation implicit deflation new vector search subspace generated made orthogonal detected schur vectors adding search subspace approach mixture techniques jacobi correction equation use explicitly deflated matrix since solutions deflated correction equations orthogonal detected schur vectors need use deflated matrix computing deflated interaction matrix compute similar observations hold interaction matrices mb generalized case cf 22 exclusively implicit deflation possible well solve correction equation approximately nondeflated make resulting solution orthogonal jacobidavidson style qr 107 detected schur vectors approach avoid expensive matrixvector multiplications explicit deflation appears improve condition number linear system leads faster converging process jacobi correction equation 29 decrease number iteration steps correction equation appears often compensate expensive multiplications numerical illustration see section 45 moreover explicitly deflated correction equation 32 appears lead stable results understood follows without deflation resulting solution correction equation may significant component space spanned detected schur vectors subtracting component implicit cancellation may occur work explicitly deflated matrix cancellation avoided remark 6 implicitly deflated arnoldi methods accuracy approximate schur pair method depends norm residual condition number pair also approximation errors previously detected schur pairs cf eg 22 ch iv section 25 13 section 641 derivation algorithms assumed v true exact schur vectors practice spanaq contained spanq 32 preconditioning section discuss preconditioning correction equation preconditioning straightforward projections involved derive explicit expressions left right preconditioned correction equations iteration step need solve deflated jacobi correction equation 32 given q cf 32 approximate solution equation may use krylov subspace method eg gmres 23 bicgstab 25 rate convergence eciency krylov subspace methods often improved preconditioning identification eective preconditioner may prob lem instance interior eigenvalues construction eective incomplete lufactorization 14 10 may require much fillin 3 makes construction expensive argue section 33 may good strategy compute good possibly expensive preconditioner k one fixed value use preconditioner various q note projections k necessary let k operate proper subspace cf 24 give details derivation expressions preconditioned correction equation use notation notation 1 typical usage preconditioner krylov subspace method would look like solve 3 incomplete factorizations designed linear systems related eigenprob lems solutions factorizations eective usually rather smooth means components slowly varying eigenvectors favored preconditioning 108 r fokkema g l g sleijpen h van der vorst following lemma gives us explicit expression solution 34 terms easily computable matrixvector products k k 1 lemma generalizes proposition 75 24 proof runs along lines details see 7 ch 6 section 24 note h k small dimension cheaply inverted need invert k explicitly instead computed solving v lemma 1 h k nonsingular solution equation 34 given remark 7 one stores matrix k1 k preconditioned schur vectors one compute last column k 1 q matrix q iteration step furthermore storing projected preconditioner last column last row computed iteration step remark 8 preconditioner k indefinite matrix may become singular unlucky choice approximate ritz pair q causes breakdown never happened experiments breakdown may cured selecting dierent nearby approximating ritz pair q temporarily current jacobidavidson iteration preconditioning lemma 1 follows left preconditioned correction equation equivalent note projection applied explicitly residual unpreconditioned case need explicit projection since fact residual associated deflated matrix ritz pair implied orthogonality observe equation 36 equivalent one 32 course right preconditioned correction equations similar 27 derived corresponding manner details see 7 ch 6 section 24 remark 9 one uses krylov subspace methods solving second equation 36 one encounters matrixvector products form form obviously approximate solution v provided case initial guess well moreover projection k front 37 redundant 37 reduces jacobidavidson style qr 109 algorithm 3 preconditioned jdqr function k k max else correction equation solve v approximately projected problem found found implicit restart part see algorithm 4 jdqr returns partial schur form q r matrix dimension kmax eigenvalues near target k preconditioner v 0 initial guess stopping tolerance jmax j min specify dimension subspaces v implicit restart respectively schur matlab function computes schur decomposition function mgs performs modified gramschmidt qrsort sorts schur form matlab implementations mgs qrsort see 7 ch 6ab pseudocode preconditioned jacobidavidson qr algorithm given algorithm 3 table 2 listed main computational ingredients per iteration jdqr r fokkema g l g sleijpen h van der vorst algorithm 4 found implicit restart part jdqr found table computational costs jdqr per iteration integers j k denote dimensions spanv spanq respectively part dots axpys mvs k correction equation variable costs projected problem 3j krylov subspace methods used solve correction equation product av often already available side product mv needed part b instead computing residual r aqq r may also computed q v av cf algorithm 3 depending number nonzeros value j may ecient 33 quality deflated preconditioner even preconditioner k constructed fixed correction equation still involves projections become expensive schur pair detected necessarily lead expensive computational process com pared explicit restart iterative solvers used may converge faster field values projected operator contained field values may smaller especially exterior eigenvalues detected projections may also positive eect preconditioner jacobidavidson style qr 111 see one hand preconditioning error enlarged small shift hand projections diminish error filtering detected schur vectors error r large respect eigenvectors corresponding eigenvalues near projected error significantly smaller penalty small shift due seems plausible cf 32 ch iv lead significantly less eective preconditioner may help explain eectiveness fixed preconditioner jdqr experiments 34 notes speed convergence section make comments respect convergence behavior jdqr use wellknown arguments jdqr algorithm nice properties respect overall performance adjusting one schur pair subspace spanv also accumulates components schur pairs result one schur pair detected schur pairs may follow quickly complete restart components appear similar way shiftandinvert arnoldi 22 process shift deflated eigenproblem understood follows simplicity suppose complete set eigenpairs trying find approximation q exact solution 29 given cf 26 section 41 writing q may assume without loss generality 0 q ritz vector means 2 latter case unlikely happen due rounding errors first case indicates full convergence hence eigenvector components corresponding eigenvalues closer amplified q component orthogonal q used expansion v thus soon q large component direction x 1 say angle less 4 necessarily components x 1 become dominant fig 1 illustrated phenomenon bullets represent amplification factors 1 components direction x 112 r fokkema g l g sleijpen h van der vorst theta3fig 1 amplification factors eigenvectors subsequent iterations similar amplifications occur closer rapid angle argument repetitive angle small corresponding 2 small components due orthogonalization become dominant consequently process converges schur pair search subspace v provide good initial approximations nearby schur pairs moreover slow convergence one stage may compensated faster convergence next stage subspace spanv enriched components schur pairs due repeated amplifications observed numerical experiments see section 4 4 numerical experiments section present numerical results obtained jdqz jdqr several generalized eigenproblems standard eigenproblems purpose experiments get impression actual behavior methods tried find ecient parameter choices particular problem illustrate eect accurately solving correction equation eect including appropriate precondition ing show harmonic petrov value choice test subspace may lead superior convergence behavior generalized eigenproblem also standard eigenproblem demonstrate projections correction equation 32 involving detected schur vectors essential components algorithms also consider eigenproblems multiple eigenvalues involved computations done double complex precision 15 digits sun workstation facilitate comparison selected cases j dimension subspace implicit restart respectively fixed random real vector v 0 initial guess cf algorithms 3 1 iterative solvers correction equation considered full gmres 23 maximum steps denoted gmresm bicgstab2 25 bicgstab2 maximum 100 matrix multiplications allowed course comparing apples pears main purpose mimic two realis jacobidavidson style qr 113 tic scenarios one fixed number matrixvector multiplications gmresm one iterative method satisfy stopping criterion bicgstab2 stopping criterion iterative methods correction equation also gmresm used r initial residual residual corresponding approximate solution produced inner method j iteration number current eigenvalue approximation outer iteration hence outer iterations proceed inner iterations solved accurately choice inspired fact jacobidavidson method may viewed newton process 24 27 newton processes stopping criterion may lead ecient algorithms 6 initial guess inner iteration method always took null vector figures convergence behavior jdqz jdqr performance plotted terms actual amount work millions floating point operations flops versus log 10 residual norm reason computational work jdqz jdqr consists two parts dierent nature one part inner iteration process correction equation approximately solved part outer iteration approximation generalized schur pair constructed inner iteration correction equation solved accurately number outer iterations may decrease therefore would misleading monitor total number matrix multiplications might give bad impression total costs matrices sparse therefore dot products vector updates outer inner iteration represent substantial costs jdqz jdqr furthermore plotted entire convergence behavior means convergence history residuals subsequentially selected approximate eigenpairs plotted whenever residual norm curve drops acceptation level indicated dotted horizontal line eigenvalue accepted search process next one continued large residual norm step immediately acceptance marks start new search 401 construction suitable initial subspaces specifically first steps process ritz petrov vectors usually poor approximations wanted eigenvectors target value may relatively much closer wanted eigenvalues approximate eigenvalues cases correction equations 26 36 lead relatively poor expansions search subspace see recall wanted eigenvector would new search subspace space would expanded exact solution correction equation wanted eigenvalue instead cf section 3 observation indicates improve expansion first steps take correction equation instead detect whether close enough replace monitor norm residual take instead 1 correction equation soon first residual norm drops threshold value tr similar switch proposed 18 moreover experiments used gmres 1 first j min iterations order build search subspace spanv relatively inexpensive way especially preconditioner involved approach justified arguments similar preceding paragraph cf 24 section 94 402 stopping criterion experiments considered approximate eigenpair converged residual r suciently small r q 114 r fokkema g l g sleijpen h van der vorst table four eigenvalues dw1024 computed jdqr cf section 41 96473e 01 96551e 01 97780e 01 97880e 01 log10 residual norm number flops x 1e6 fig 2 convergence history dw1024 showing eect solving correction equations accurately cf section 41 detected eigenpair algorithms weighted residuals eg ra sophisticated stopping criteria employed well cf 4 experiments varied values parameters jdqz jdqr easy reference recall meaning parameter description target value k max number wanted schur pairs stopping tolerance outer iteration tr threshold used building initial subspaces 41 influence correction equation purpose example show eect accurate solution correction equation consider square dielectric waveguide standard eigenproblem dw1024 order 2048 2 problem comes integrated circuit application rightmost eigenvalues eigenvectors wanted used jdqr standard ritz values took used preconditioning computed eigenvalues given table 3 convergence history plotted fig 2 jdqr gmres 1 gmres 10 summary number iterations number matrix multiplications mvs number flops given table 4 jacobidavidson style qr 115 table summary results dw1024 cf section 41 method correction equation jdqr iterations mvs flops table five eigenvalues bwm2000 computed jdqr cf section 42 24427e 07 21395e 24427e solving correction equation accurately number mvs increased number outer iterations reduced significantly see table 4 resulting much better overall performance gmres 1 search subspace span residuals case jd implicit restart generates subspaces ira 28 eigenvalues well separated case therefore arnoldi converges slowly explains poor convergence jdqr gmres 1 note initial phase two small bumps jdqr converges quite fast next eigenvalues initial stagnation apparently iterations first eigenvalue components next schur vectors already collected spanv cf section 34 42 eect preconditioning increasing number steps gmres correction equation solved accurately number outer iterations may decrease seen sometimes need many inner iterations gmres acceptable convergence outer iterations appropriate preconditioning may see dramatic improvement see example consider standard eigenproblem bwm2000 order 2000 brusse lator wave model 2 22 problem models concentration waves reaction transport interaction chemical solutions tubular reactor task determine eigenvalues largest real part order verify whether real parts positive negative corresponding stable unstable modes used jdqr standard ritz values problem selected computed eigenvalues listed table 5 convergence history plotted fig 3 jdqr unpreconditioned gmres 10 preconditioning summary results given table 6 fig 3 see jdqr gmres 10 converge checked even gmres 50 little improvement preconditioning jdqr performs rather well see speed convergence first eigenvalue somewhat slower speed convergence eigenvalues note although projections correction equation become expen r fokkema g l g sleijpen h van der vorst log10 residual norm number flops x 1e6 gmres ilu0fig 3 convergence history bwm2000 illustrating eect including preconditioning solver correction equation cf section 42 table summary results bwm2000 cf section 42 method correction equation jdqr iterations mvs flops sive detected eigenvalue computational work eigenvalue roughly constant except first eigenvalue noted popular software packages solving eigenproblems reported fail problem bwm2000 12 preconditioned correction equation 26 requires computation storage term notation 1 k good approximation spans invariant subspace nearly ideal case reason tempting use 26 instead k however approach work well may even lead slower convergence experiments instance qh882 discussed section 43 lost convergence completely experiments little eect 43 harmonic ritz values jdqr algorithm computes partial schur form standard eigenproblem standard ritz pairs schur pairs however jdqz also compute partial schur form standard eigenproblem harmonic ritz pairs give example illustrates improved convergence behavior harmonic ritz values consider quebec hydroelectric power system problem qh882 order 882 2 matrix represents hydroquebec power systems smallsignal model jacobidavidson style qr 117 table five eigenvalues qh882 computed jdqr cf section 43 4e06 2e062e068e06 6e06 4e06 2e06 0 imaginary axis real axis fig 4 spectrum qh882 cf section imaginary axis real axis eigenvalues target fig 5 part spectrum qh882 eigenvalues interest eigenvalues box 300 100 complex plane problem selected computed eigenvalues given table 7 convergence history plotted fig 7 jdqr standard ritz values jdqz harmonic choice cf section 242 problem rather dicult eigenvalues neighborhood interior spectrum see figs 4 5 three methods correction equation solved gmres 20 preconditioned exact inverse summary results given table 7 although computational complexity jdqr less computational complexity jdqz cf tables 1 2 ecient method irregular convergence behavior jdqr fig 6 may conclude jdqr problems selecting correct ritz pairs result convergence delayed eventually jdqr loses track completely stagnates peaks convergence behavior show sometimes ritz pair selected jdqr process correspond closeby schur pair result search subspace expanded poor direction clearly example may lead failure convergence anticipated cf section 22 jdqz harmonic choice test subspace makes better selections indicated smooth convergence hence performance much better 44 identification suitable ritz values tracking computational point view jdqr less complex jdqz even savings standard eigenproblems problem allow exploited jdqz therefore may attractive identify ecient strategies avoiding incorrect selection ritz r fokkema g l g sleijpen h van der vorst residual norm jdqr number flops x 1e6 jdqz harmonic fig 6 convergence history qh882 although qh882 standard eigenproblem computing interior eigenvalues ecient use jdqz test subspaces dierent search subspaces bottom picture better selection harmonic ritz values bottom picture appears compensate less optimal expansion test subspace cf section 43 pairs correctly selected ritz pairs convergence may expected less irregular stagnation may completely avoided discuss strategy ritz vector previous iteration already fair approximation norm residual gives information selected ritz vector current step case poor selection new residual much larger previous one would require additional computational work find ritz pair small residual norm still close enough target cheap alternative case select ritz value close previously accepted one forget experiment discuss replaced cases target ritz value selected accepted previous step consider ritz value acceptable associated residual smaller specified threshold example took threshold equal tr value used criterion leaving initialization stage see section 401 convergence ritz pair original target value restored start computation next eigenpair tracking strategy require additional computational costs per step appears reduce number steps significantly see rather regular convergence ritz values exterior eigenvalues improvement eigenvalues may expected tracking strategy standard problems illustrate fig 7 eects one may see including tracking jdqr applied jdqr example section 43 choice parameters nevertheless see convergence behavior jdqz harmonic choice test subspace still superior see also table 8 45 influence q k z k correction equation example show projections detected schur vectors cf 24 jacobidavidson style qr 119 residual norm jdqr number flops x 1e6 jdqz harmonic fig 7 convergence history qh882 obtained tracking strategy variants interior eigenvalues tracking strategy improves jdqr significantly compare present upper picture upper picture fig 7 improvement jdqz compare two bottom pictures present figure fig 7 cf section 44 table summary results qh882 cf sections 43 44 method iterations mvs flops jdqr tracking cf section 44 99 1482 1221e jdqz harmonic 57 essential correction equation cf section 34 show happens projections neglected note still take jacobi projections q z account consider bounded fineline dielectric waveguide generalized eigenproblem bfw782 2 order 782 problem stems finite element discretization maxwell equation propagating modes magnetic field profiles rectangular waveguide filled dielectric pec structures resulting matrix nonsymmetric matrix b positive definite special interest generalized eigenvalues positive real part ie 0 corresponding eigenvectors problem parameters set spectrum matrix pair shown fig 8 magnification region interest plotted fig 9 computed generalized eigenvalues represented given table 9 jdqz discovered four positive generalized eigenvalues convergence history harmonic version jdqz gmres 10 plotted upper picture fig 10 summary results given table 10 see jdqz converges quite nicely bottom picture fig 10 convergence behavior jdqz given case correction equation 24 solved without taking account projections involving q k z k course correction equations used 120 r fokkema g l g sleijpen h van der vorst 8000 6000 4000 2000200060003e06 2e06 1e06 0e00 imaginary axis real axis fig 8 spectrum bfw782 cf section 45 04 imaginary axis real axis eigenvalues target fig 9 part spectrum bfw782 table five generalized eigenvalues bfw782 computed jdqz cf section 45 25233e residual norm gmres harmonic10 number flops x 1e6 gmres harmonic without q zfig 10 convergence history bfw782 upper picture without bottom picture deflating matrices correction equations respect detected schur vectors cf section 45 table summary results bfw782 cf section 45 method correction equation jdqz iterations mvs flops jacobidavidson style qr 121 table generalized eigenvalues ac1331 computed jdqz cf section 46 include rankone projections involving q z projections essential jacobidavidson furthermore deflation case realized making approximate solution correction equation orthogonal detected schur vectors modified gramschmidt latter twice overall performance improved significantly results shown cf fig 10 modified gramschmidt applied twice however explained section 34 benefit improved operator inner iteration although resulting algorithm computationally cheaper fig 10 shows lead overall better performance speed convergence becomes increasingly slower even stagnates eventually 46 multiple eigenvalues consider eigenproblem neumann boundary conditions cube 0 4 3 finite element discretization equation 11 11 11 regular grid tetrahedral elements linear interpolation functions leads generalized eigenproblem order 1331 ac1331 one positive generalized eigenvalue relatively close zero ie 0 generalized eigenvalues also positive may doublets even triplets problem parameters set computed 15 leftmost generalized eigenvalues represented given table 11 residual norm versus number flops plotted fig 11 harmonic version jdqz gmres 10 bicgstab2 respectively summary results given table 12 plots see eect multiple generalized eigenvalues may convergence behavior jdqz converges initially quite fast point discovers generalized eigenvalue actually double triple convergence speed stagnates iterations two three peaks plot gmres plateau plot bicgstab2 eigenvalues discovered quickly one another behavior agreement section 34 stagnation phase components schur vectors amplified inner iteration collected search subspace leading faster convergence next schur pairs stagnation explained fact rankone jacobi projections correction equation may become nearly singular selecting petrov approximations multiple generalized eigenvalues iterative methods used solving correction equation often suer see also 31 variable block versions correction equation take multiplicity account may preferable cases falls outside scope paper 122 r fokkema g l g sleijpen h van der vorst residual norm gmres harmonic10 log10 residual norm number flops x 1e6 harmonic fig 11 convergence history ac1331 stagnation followed fast detection triple generalized eigenvalues cf section 46 table summary results ac1331 cf section 46 method correction equation jdqz iterations mvs flops 47 harmonic petrov values generalized problems last example shows interior generalized eigenvalues harmonic version jdqz quite powerful consider mhd416 generalized eigenproblem order 416 2 24 3 problem stems magnetohydrodynamics mhd model interaction hot plasma magnetic field studied matrix nonhermitian matrix b hermitian positive definite goal compute interior generalized eigenvalues corresponding socalled alfven branch spectrum see figs 12 13 problem parameters set computed generalized eigenvalues plotted fig 14 convergence history harmonic version jdqz gmres 1 plotted fig 15 exact inverse b fixed used preconditioner eigenvalues generalized eigenvalues rate convergence almost computation one schur pair search subspace apparently accumulates components next schur pairs well jacobidavidson style qr 123 imaginary axis real axis fig 12 spectrum mhd416 cf section 4702061 imaginary axis real axis fig 13 alfven branch mhd416 cf section 47050607 imaginary axis real axis eigenvalues target fig 14 20 generalized eigenvalues computed jdqz mhd416 cf section 47 5 conclusions proposed two algorithms jdqz jdqr computing several selected eigenpair approximations generalized standard eigen problems respectively methods based jacobidavidson method compute iteratively partial generalized schur form generalized eigenvalues near userspecified target value methods exact inversion matrix strictly necessary suitable solving large eigenproblems fast convergence obtained projected correction equation solved approximately iterative methods appropriate preconditioning convergence jdqz jdqr asymptotically quadratical correction equation solved exactly furthermore converging particular schur pair search subspace accumulates components schur pairs generalized eigenvalues near target well usually leads faster convergence next eigenpairs dimension involved subspaces controlled ecient implicit restart technique way relevant part subspace maintained restart 124 r fokkema g l g sleijpen h van der vorst 5 log10 residual norm number flops x 1e6 gmres harmonicfig 15 convergence history jdqz mhd416 harmonic petrov values allow good selection petrov pairs computing interior generalized eigenvalues also generalized problems cf section 47 algorithms incorporate simple mechanisms selecting wanted eigenpair approximations also multiple generalized eigenvalues detected whereas jacobidavidson method test subspace chosen arbi trarily jdqz algorithm essentially two choices test subspace remain standard petrov value choice harmonic petrov value choice argued confirmed experiments especially interior eigenvalues harmonic approach also superior generalized eigenproblems acknowledgments acknowledge helpful discussions rich lehoucq beresford parlett naming conventions also appreciate helpful comments referees r test matrix collection nonhermitian eigenvalue problems iterative calculation lowest eigenvalues corresponding eigenvectors large real symmetric matrices subspace methods linear qr transformation unitary analogue lr transformation matrix computations class first order factorizations methods ueber ein leichtes verfahren evaluation software computing eigenvalues sparse nonsymmetric matrices deflation techniques within implicitly restarted iter ation iterative solution method linear systems coe algorithm generalized matrix eigenvalue problems computing interior eigenvalues large matrices generalizations davidsons method computing eigenvalues sparse symmetric matrices approximate solutions eigenvalue bounds krylov subspaces perturbation bounds means eigenvalues invariant subspaces rational krylov algorithms nonsymmetric eigenvalue problems ii numerical methods large eigenvalue problems gmres generalized minimum residual algorithm solving nonsymmetric linear systems jacobidavidson iteration method linear eigenvalue problems jacobidavidson method eigenvalue problems relation accelerated inexact newton schemes implicit application polynomial filters kstep arnoldi method algorithm 406 hqr3 exchng fortran subroutines calculating ordering eigenvalues real upper hessenberg matrix matrix perturbation theory rate convergence conjugate gradients preconditioning incomplete decompositions generalized eigenvalue approach solving ricatti equations algorithm 590 tr ctr james h money qiang ye algorithm 845 eigifp matlab program solving large symmetric generalized eigenvalue problems acm transactions mathematical software toms v31 n2 p270279 june 2005 ivo bleylevens ralf peeters bernard hanzon efficiency improvement nd systems approach polynomial optimization journal symbolic computation v42 n12 p3053 january 2007 lorenzo valdettaro michel rieutord thierry braconnier valrie frayss convergence roundoff errors twodimensional eigenvalue problem using spectral methods arnoldichebyshev algorithm journal computational applied mathematics v205 n1 p382393 august 2007 peter arbenz martin beka roman geus ulrich hetmaniuk tiziano mengotti parallel multilevel preconditioned maxwell eigensolver parallel computing v32 n2 p157165 february 2006 peter arbenz roman geus multilevel preconditioned iterative eigensolvers maxwell eigenvalue problems applied numerical mathematics v54 n2 p107121 july 2005 daniel kressner block algorithms reordering standard generalized schur forms acm transactions mathematical software toms v32 n4 p521532 december 2006 richard tran mills andreas stathopoulos evgenia smirni algorithmic modifications jacobidavidson parallel eigensolver dynamically balance external cpu memory load proceedings 15th international conference supercomputing p454463 june 2001 sorrento italy pa absil c g baker k gallivan truncatedcg style method symmetric generalized eigenvalue problems journal computational applied mathematics v189 n1 p274285 1 may 2006 computing smallest singular triplets implicitly restarted lanczos bidiagonalization applied numerical mathematics v49 n1 p3961 april 2004 lawrence k saul sam roweis think globally fit locally unsupervised learning low dimensional manifolds journal machine learning research 4 p119155 1212003 james r mccombs andreas stathopoulos parallel multigrain iterative solvers hiding network latencies mpps networks clusters parallel computing v29 n9 p12371259 september