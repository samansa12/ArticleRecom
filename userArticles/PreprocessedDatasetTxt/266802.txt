pathbased next trace prediction trace cache proposed mechanism providing increased fetch bandwidth allowing processor fetch across multiple branches single cycle date predicting multiple branches per cycle meant paying penalty prediction accuracy propose next trace predictor treats traces basic units explicitly predicts sequences traces predictor collects histories trace sequences paths makes predictions based histories basic predictor enhanced hybrid configuration reduces performance losses due cold starts aliasing prediction table return history stack introduced increase predictor performance saving path history information across procedure callreturns overall predictor yields 26 reduction misprediction rates compared aggressive previously proposed multiplebranchprediction methods b introduction current superscalar processors fetch issue four six instructions per cycle number average basic block integer programs obvious designers reach higher levels instruction level parallelism become necessary fetch one basic block per cycle recent years several proposals put forward 3412 one promising trace cache 910 dynamic sequences instructions containing embedded predicted branches assembled sequential trace saved special cache fetched unit trace cache operation best understood via example figure 1 shows programs control flow graph cfg node basic block arcs represent potential transfers control figure arcs corresponding branches labeled indicate taken taken n paths sequence abd represents one possible trace holds instructions basic blocks b would sequence instructions beginning basic block next two branches taken taken respectively basic blocks contiguous original program would stored contiguous block trace cache number traces extracted cfg four possible traces 1 abd 2 acd 3 efg 4 eg course many traces could also chosen cfg fact trace necessarily begin end basic block boundary increases possibilities also note trace cache instructions may appear one trace example blocks e g appear twice list traces however mechanism builds traces use heuristic reduce amount redundancy trace cache beginning ending basic block boundaries good heuristic f g figure associated trace cache trace fetch unit fetches trace cache cycle timely fashion necessary predict next trace straightforward method one used 910 predict simultaneously multiple branches within trace armed last pc preceding trace multiple predictions fetch unit access next trace example trace 1 abd recently fetched trace multiple branch predictor predicts next three branch outcomes ttn next trace implicitly acd paper take different approach next trace prediction treat traces basic units explicitly predict sequences traces example referring list traces recent trace trace 1 next trace predictor might explicitly output trace 2 individual branch predictions ttn implicit propose study next trace predictors collect histories trace sequences make predictions based histories similar conditional branch prediction predictions made using histories branch outcomes however trace typically two successors often many consequently next trace predictor keeps track sequences trace identifiers identifier containing multiple bits propose basic predictor add enhancements reduce performance losses due cold starts procedure callreturns interference due aliasing prediction table proposed predictor yields substantial performance improvement previously proposed multiplebranchprediction methods six benchmarks studied average misprediction rate 26 lower proposed predictor aggressive previously proposed multiplebranch predictor 2 previous work number methods fetching multiple basic blocks per cycle proposed yeh et al 12 proposed branch address cache predicted multiple branch target addresses every cycle conte et al 3 proposed interleaved branch target buffer predict multiple branch targets detect short forward branches stay within cache line methods use conventional instruction caches fetch multiple lines based multiple branch predictions fetching blocks instructions different lines selected aligned combined lead considerable delay following instruction fetch complex logic delay primary pipeline trace cache intended remove trace caches 910 combine blocks instructions prior storing cache read block fed pipeline without pass complex steering logic branch prediction form fundamental part next trace prediction either implicitly explicitly hardware branch predictors predict outcome branches based previous branch behavior heart branch predictors pattern history table pht typically containing twobit saturating counters 11 simplest way associate counter branch instruction use bits pc address branch typically least significant bits index pht 11 counters value two three branch predicted taken otherwise branch predicted taken correlated predictors increase accuracy branch prediction outcome branch tends correlated outcome previous branches 813 correlated predictor uses branch history register bhr bhr shift register usually updated shifting outcome branch instructions one taken zero taken global correlated predictor single bhr updated branches bhr combined bits possibly zero branchs pc address either concatenating using exclusiveor function form index pht correlated predictor pht entry associated branch instruction branch instruction context specific bhr value bhr alone used index pht predictor gag predictor 13 exclusiveor function used combine equal number bits bhr branch pc address predictor gshare predictor 6 gshare shown offer consistently good prediction accuracy mapping instructions pht entries essentially implemented simple hashing function detect avoid collisions aliasing occurs two unrelated branch instructions hash pht entry aliasing especially problem correlated predictors single branch may use many pht entries depending value bhr thus increasing contention order support simultaneous fetching multiple basic blocks multiple branches must predicted single cycle number modifications correlated predictor discussed proposed support predicting multiple branches franklin dutta proposed subgraph oriented branch prediction mechanisms uses local history form prediction encodes multiple branches yeh et al 13 proposed modifications gag predictor multiport predictor produce multiple branch predictions per cycle rotenberg et al 10 also used modified gag trace cache study recently patel et al 9 proposed multiple branch predictor tailored work trace cache predictor attempts achieve advantages gshare predictor providing multiple predictions predictor uses bhr address first instruction trace exclusiveored together index pht entries pht modified contain multiple twobit saturating counters allow simultaneous prediction multiple branches predictor offers superior accuracy compared multiported gag predictor quite achieve overall accuracy single branch gshare predictor nair proposed pathbased prediction form correlated branch prediction single branch history register prediction history table innovation information stored branch history register outcome previous branches truncated pc addresses make prediction bits address history register well bits current pc address concatenated form index pht hence branch predicted using knowledge sequence path instructions led gives predictor specific information prior control flow takennot taken history branch outcomes jacobson et al 5 refined pathbased scheme applied next task prediction multiscalar processors adaptation multiscalar predictor forms core pathbased next trace predictor presented 3 pathbased next trace predictors consider predictors designed specifically work trace caches predict traces explicitly implicitly predict control instructions within trace next trace predictors replace conventional branch predictor branch target buffer btb return address stack ras low latency capable making trace prediction every cycle show also offer better accuracy conventional correlated branch predictors 31 naming traces theory trace identified pcs trace would obviously expensive cheaper practical method use pc value first instruction trace combined outcomes conditional branches embedded trace means indirect jumps internal trace use traces maximum length 16 instructions accessing trace cache use following method assume 36 bit identifier identify starting pc six bits encode six conditional branches limit six branches somewhat arbitrary chosen observed length 16 traces almost never six branches important note limit branches required simplify simultaneous multiple branch prediction case trace predictors using explicit branch prediction 32 correlated predictor core next trace predictor uses correlation based history previous traces identifiers previous traces represent path history used form index prediction table see figure 2 entry table consists identifier predicted trace pc branch outcomes twobit saturating counter prediction correct counter incremented one prediction incorrect counter zero predicted trace replaced actual trace otherwise counter decremented two predicted trace entry unchanged found incrementby1 decrementby2 counter gives slightly better performance either one bit conventional twobit counter history register predicted trace id trace id cnt hashed id hashed id hashed id hashed id generation hashing function figure correlated predictor path history maintained shift register contains hashed trace identifiers figure 2 hashing function uses outcome first two conditional branches trace identifier least significant two bits two least significant bits starting pc next two bits upper bits formed taking outcomes additional conditional branch outcomes exclusiveoring next least significant bits starting pc beyond last conditional branch value zero used remaining branch outcome bits history register updated speculatively new prediction case incorrect prediction history backed state bad prediction prediction table updated last instruction trace retired speculatively updated bits back id width bits figure 3 index generation mechanism ideally index generation mechanism would simply concatenate hashed identifiers history register form index unfortunately sometimes practical prediction table relatively small index must restricted limited number bits index generation mechanism based method developed intertask prediction multiscalar processors 5 index generation mechanism uses bits hashed trace identifiers form index low order bits hashed trace identifiers used bits used recent traces collection selected bits traces may longer allowable index case collection bits folded onto using exclusiveor function form index 5 dolc naming convention developed specifying specific parameters index generation mechanism first variable depth number traces besides last trace used forming index three variables number bits older traces number bits last trace number bits current example shown figure 3 collection bits trace identifiers twice long index folded half two halves combined exclusive cases bits may folded three parts may need folded 33 hybrid predictor index prediction table reads entry unrelated current path history prediction almost certainly incorrect occur particular path never occurred table entry overwritten unrelated path history due aliasing observed significant realistically sized tables aliasing usually important branch prediction even randomly selected table entry typically 50 chance correct case next trace prediction chances correct random table entry low address issue operate second smaller predictor parallel first figure 4 secondary predictor requires shorter learning time suffers less aliasing pressure secondary predictor uses hashed identifier last trace index table prediction table entry similar one correlated predictor except 4 bit saturating counter used decrements 8 misprediction reason larger counter discussed end section correlating table history register prediction trace id cnt hashed id hashed id hashed id hashed id hashing function figure 4 hybrid predictor decide predictor use given prediction tag added table entry correlated predictor tag set low 10 bits hashed identifier immediately preceding trace time entry updated ten bit tag sofficient eliminate practically unintended aliasing prediction made tag checked hashed identifier preceding trace match correlated predictor used otherwise secondary predictor used method increases likelihood correlated predictor corresponds correct context used method also allows secondary table make prediction context limited ie startup conditions hybrid predictor naturally reduces aliasing pressure somewhat modifying slightly aliasing pressure reduced 4bit counter secondary predictor saturated prediction used importantly correct correlated predictor updated means trace always followed successor secondary predictor captures behavior correlated predictor polluted reduces number updates correlated predictor therefore chances aliasing relatively large counter 4bits used avoid giving opportunity use correlated predictor unless high probability trace single successor 34 return history stack rhs accuracy predictor increased new mechanism return history stack rhs field added trace indicating number calls contains trace ends return number calls decremented one path history updated calls new trace copy recent history made call copies pushed onto special hardware stack trace ends return contains calls top stack popped substituted part history one two recent entries current history within subroutine preserved entries stack replace remaining older entries history five fewer entries history recent hashed identifier kept five entries two recent hashed identifiers kept history register hashed id hashed id hashed id hashed id pop figure 5 return history stack implementation rhs subroutine called returned history contains information happened call well knowledge last one two traces subroutine found rhs significantly increase overall predictor accuracy reason increased accuracy control flow program subroutine often tightly correlated behavior call without rhs information call often overflowed control flow within subroutine trying achieve careful balance history information call versus history information within call different benchmarks optimal point varies found configurations using one two entries subroutine provide consistently good behavior predictor use return address stack ras requires information instruction level granularity trace predictor trying avoid rhs partly compensate absence ras helping initial prediction return subroutine significantly long force pre call information history register hence determining calling routine therefor return would much harder without rhs 4 simulation methodology 41 simulator study predictor performance trace driven simulation simplescalar tool set used 1 simplescalar uses instruction set largely based mips major deviation delayed branches replaced conventional branches use gnu c compiler targets simplescalar functional simulator simplescalar instruction set used produce dynamic stream instructions fed prediction simulator work considered predictor isolation using immediate updates prediction next trace made predictor updated actual outcome next prediction made also simulations execution engine allows updates performed taking execution latency account modeled 8way outoforder issue superscalar processor 64 instruction window processor 128kb trace cache 64kb instruction cache 4ported 64kb data cache processor 8 symmetric functional units supports speculative memory operations 42 trace selection study used traces maximum instructions length contain six branches limit number branches imposed naming convention traces control instruction indirect target embedded trace must end trace means traces shorter maximum length mentioned earlier instructions indirect targets embedded allow traces uniquely identified starting address outcomes conditional branches used simple trace selection heuristics sophisticated trace selection heuristics possible would significantly impact behavior trace predictor study relation trace selection trace predictability beyond scope paper 43 benchmarks present results six specint95 benchmarks compress gcc go jpeg m88ksim xlisp results based runs least 100 million instructions table summary benchmark input number instr avg trace length traces compress 400000 queens 7 first 100 million 124 1393 5 performance 51 sequential branch predictor reference first determined trace prediction accuracy could achieved taking proven control flow prediction components predicting control instruction sequentially sequential prediction branch explicitly predicted time prediction outcomes previous branches known useful comparisons although realizable would require multiple accesses predict single trace requires knowledge branch addresses within trace best multiple branch predictors date attempted approximate behavior conceptual sequential predictor used 16bit gshare branch predictor perfect branch target buffer branches pcrelative absolute address targets 64k entry correlated branch target buffer branches indirect targets 2 perfect return address predictor predictors ideal immediate updates simulating mechanism one predictions within trace incorrect counted one trace misprediction configuration represents aggressive ideal predictor prediction accuracy idealized sequential prediction given table 2 mean trace misprediction rate 121 show later proposed predictor achieve levels prediction accuracy significantly better achievable idealized sequential predictor results section refer trace prediction accuracy idealized sequential predictor sequential misprediction rate traces tends lower obtained simply multiplying branch misprediction rate number branches branch mispredictions tend clustered trace mispredicted multiple branches within trace often mispredicted xlisp exception hard predict branches tending different traces aggressive target prediction mechanisms none benchmarks showed substantial target misprediction table prediction accuracy sequential predictors benchmark 16bit gshare branch misprediction number branches per trace mispredic tion traces compress 92 21 179 gcc 80 21 140 go 166 18 245 jpeg 69 10 67 xlisp 32 19 65 52 performance unbounded tables determine potential pathbased next trace prediction first studied performance assuming unbounded tables study unique sequence trace identifiers maps table entry ie aliasing consider varying depths trace history depth number traces besides recent trace combined index prediction table depth zero identifier recent trace used study history depths zero seven figure 6 presents results unbounded tables mean misprediction rate 80 rhs predictor maximum depth comparisons sequential predictor based 16bit gshare predictor predicts conditional branches sequentially benchmarks proposed pathbased predictor better idealized sequential predictor average misprediction rate 34 lower proposed predictor cases gcc go predictor less half misprediction rate idealized sequential predictor e correlated hybrid rhs sequential depth history misprediction rate correlated hybrid rhs sequential go14182226 depth history misprediction rate correlated hybrid rhs sequential depth history misprediction rate correlated hybrid rhs sequential depth history misprediction rate correlated hybrid rhs sequential depth history misprediction rate correlated hybrid rhs sequential figure 6 next trace prediction unbounded tables benchmarks hybrid predictor higher prediction accuracy using correlated predictor alone benchmarks static traces see larger advantage hybrid predictor contain unique sequences traces table size unbounded hybrid predictor important aliasing important making predictions correlated predictor entry cold four six benchmarks adding return history stack rhs increases prediction accuracy furthermore four improved benchmarks see significant increase due rhs two benchmarks hurt rhs see decrease benchmark compress predictor better without rhs compress information subroutine thrown away rhs important information subroutine saved xlisp extensively uses recursion minimize overhead uses unusual control flow backup quickly point recursion without iteratively performing returns behavior confuses return history stack number calls corresponding returns however hard determine much performance loss rhs xlisp caused problem much caused loss information control flow within subroutines 53 performance bounded tables consider finite sized predictors table correlated predictor significant component respect size study correlated predictors tables 2 14 2 15 2 16 entries size consider number configurations different history depths configurations index generation function chosen based trialanderror although better configurations doubt possible believe differences would significant 214 entries entries entries infinite sequential depth history misprediction rate 214 entries entries entries infinite sequential depth history misprediction rate 214 entries entries entries infinite sequential depth history misprediction rate 214 entries entries entries infinite sequential depth history misprediction rate 214 entries entries entries infinite sequential depth history misprediction rate 214 entries entries entries infinite sequential figure 7 next trace prediction use rhs maximum depth 128 depth sufficient handle benchmarks except recursive section xlisp predictor little use anyway performance results figure 7 three benchmarks stress finitesized predictors gcc go jpeg predictors deviation unbounded tables pronounced deviation different table sizes expected deviation becomes pronounced longer histories unique sequences trace identifiers used therefore aliasing go largest number unique sequences trace identifiers apparently suffers aliasing pressure first history depth increased miss rate goes history depth continues increase number sequences competing finite size table increases aliasing detrimental effects aliasing eventually starts counter gain going deeper histories point dominates causes negative effect increased history depth smaller table size sooner effects aliasing start become problem important focus behavior benchmark two larger benchmarks gcc jpeg general benchmarks probably relatively small working sets compared realistic programs see realistic tables predictor achieve high prediction accuracies cases predictor achieves miss rates significantly idealized sequential predictor benchmark predictor better sequential prediction small 2 14 entry table jpeg even case achieve performance close sequential probably closer realistic implementation gshare modified multiple branches per cycle throughput predictor means mispredict rates 100 95 89 maximum depth configuration 2 14 2 15 2 tables respectively significantly 121 misprediction rate sequential predictor 26 lower 2 predictor table 3 index generation configurations used depth dolc thus far simulation results used immediate updates real processor history register would updated predicted trace history would corrected predictor backs due misprediction table entry would updated last instruction trace retired table 4 impact real updates benchmark misprediction ideal updates misprediction real update compress 58 58 go 93 93 jpeg 35 36 24 21 xlisp 47 48 make sure make significant impact prediction accuracy ran set simulations execution engine simulated configuration execution engine discussed section 41 predictor modeled 2 16 entries 7368 dolc configuration table 4 shows impact delayed updates apparent delayed updates significant performance predictor one case m88ksim delayed updates actually increased prediction accuracy delayed updates effect increasing amount hysteresis prediction table cases increase performance 55 costreduced predictor cost proposed predictor primarily function size correlated predictors table size correlated predictors table number entries multiplied size entry size entry 48 bits 36 bits encode trace identifier two bits counter plus 10 bits tag much less expensive predictor constructed however observing trace cache accessed trace identifier read prediction table must hashed form trace cache index practical sized trace caches index range 10 bits rather storing full trace identifier hashed cache index stored table instead hashed index hashed identifier fed history register figure 2 hashing function moved input side prediction table hash trace identifier placed table modification affect prediction accuracy significant way reduces size trace identifier field 36 bits bits full trace identifier still stored trace cache part entry read part trace cache access full trace identifier used execution validate control flow implied trace correct 6 predicting alternate trace along predicting next trace alternate trace predicted time alternate trace simplify reduce latency recovering determined prediction incorrect implementations may allow processor find fetch alternate trace instead resorting building trace scratch alternate trace prediction implemented adding another field correlated predictor new field contains identifier alternate prediction prediction correlated predictor incorrect alternate prediction field updated saturating counter zero identifier prediction field moved alternate field prediction field updated actual outcome saturating counter nonzero identifier actual outcome written alternate field figure 8 shows performance alternate trace predictor two representative benchmarks graphs show misprediction rate primary 2 16 entry table predictor well rate primary alternate mispredicted large percent mispredictions predictor caught alternate prediction compress 23 mispredictions caught alternate gcc slightly less half notable alternate prediction aliasing effect quickly dominates benefit history require much history make prediction two likely traces benefit history significantly smaller two reasons alternate trace prediction works well first cases branch heavily biased may two traces similar likelihood second two sequences traces aliased prediction entry one sequence displaces moves others likely prediction alternate slot prediction made displaced sequence traces secondary predictor wrong alternate likely correct depth history misprediction rate primary alternate depth history misprediction rate primary alternate figure alternate trace prediction accuracy 7 summary proposed next trace predictor treats traces basic units explicitly predicts sequences traces predictor collects histories trace sequences makes predictions based histories addition basic predictor proposed enhancements reduce performance losses due cold starts procedure callreturns interference prediction table predictor yields consistent substantial improvement previously proposed multiplebranchprediction methods average predictor 26 lower mispredict rate aggressive previously proposed multiplebranch predictor acknowledgments work supported part nsf grant mip 9505853 us army intelligence center fort huachuca contract dapt6395c0127 arpa order d346 views conclusions contained herein authors interpreted necessarily representing official policies endorsement either expressed implied us army intelligence center huachuca us government r evaluating future microprocessors simplescalar tool set target prediction indirect jumps optimization instruction fetch mechanisms high issue rates control flow prediction treelike subgraphs superscalar processors control flow speculation multiscalar processors combining branch predictors dynamic pathbased branch correlation improving accuracy dynamic branch prediction using branch correlation critical issues regarding trace cache fetch mechanism trace cache low latency approach high bandwidth instruction fetching study branch prediction strategies increasing instruction fetch rate via multiple branch prediction branch address cache twolevel adaptive branch prediction tr twolevel adaptive training branch prediction improving accuracy dynamic branch prediction using branch correlation increasing instruction fetch rate via multiple branch prediction branch address cache optimization instruction fetch mechanisms high issue rates dynamic pathbased branch correlation control flow prediction treelike subgraphs superscalar processors trace cache target prediction indirect jumps study branch prediction strategies control flow speculation multiscalar processors ctr trace processors proceedings 30th annual acmieee international symposium microarchitecture p138148 december 0103 1997 research triangle park north carolina united states independence trace processors proceedings 32nd annual acmieee international symposium microarchitecture p415 november 1618 1999 haifa israel juan c moure domingo bentez dolores rexachs emilio luque wide efficient trace prediction using local trace predictor proceedings 20th annual international conference supercomputing june 28july 01 2006 cairns queensland australia michael behar avi mendelson avinoam kolodny trace cache sampling filter acm transactions computer systems tocs v25 n1 p3es february 2007 quinn jacobson james e smith trace preconstruction acm sigarch computer architecture news v28 n2 p3746 may 2000 ryan rakvic bryan black john paul shen completion time multiple branch prediction enhancing trace cache performance acm sigarch computer architecture news v28 n2 p4758 may 2000 bryan black bohuslav rychlik john paul shen blockbased trace cache acm sigarch computer architecture news v27 n2 p196207 may 1999 oliverio j santana alex ramirez josep l larribapey mateo valero lowcomplexity fetch architecture highperformance superscalar processors acm transactions architecture code optimization taco v1 n2 p220245 june 2004 young michael smith better global scheduling using path profiles proceedings 31st annual acmieee international symposium microarchitecture p115123 november 1998 dallas texas united states jared stark marius evers yale n patt variable length path branch prediction acm sigplan notices v33 n11 p170179 nov 1998 bryan black brian mueller stephanie postal ryan rakvic noppanunt utamaphethai john paul shen load execution latency reduction proceedings 12th international conference supercomputing p2936 july 1998 melbourne australia paramjit oberoi gurindar sohi parallelism frontend acm sigarch computer architecture news v31 n2 may zhang rajiv gupta whole execution traces proceedings 37th annual ieeeacm international symposium microarchitecture p105116 december 0408 2004 portland oregon yoav almog roni rosner naftali schwartz ari schmorak specialized dynamic optimizations highperformance energyefficient microarchitecture proceedings international symposium code generation optimization feedbackdirected runtime optimization p137 march 2024 2004 palo alto california sangjeong lee penchung yew augmenting trace cache highbandwidth value prediction ieee transactions computers v51 n9 p10741088 september 2002 oliverio j santana ayose falcn alex ramirez mateo valero branch predictor guided instruction decoding proceedings 15th international conference parallel architectures compilation techniques september 1620 2006 seattle washington usa pedro marcuello antonio gonzlez clustered speculative multithreaded processors proceedings 13th international conference supercomputing p365372 june 2025 1999 rhodes greece karthik sundaramoorthy zach purser eric rotenburg slipstream processors improving performance fault tolerance acm sigarch computer architecture news v28 n5 p257268 dec 2000 kapil vaswani matthew j thazhuthaveetil n srikant programmable hardware path profiler proceedings international symposium code generation optimization p217228 march 2023 2005 karthik sundaramoorthy zach purser eric rotenberg slipstream processors improving performance fault tolerance acm sigplan notices v35 n11 p257268 nov 2000 roni rosner micha moffie yiannakis sazeides ronny ronen selecting long atomic traces high coverage proceedings 17th annual international conference supercomputing june 2326 2003 san francisco ca usa trace cache microarchitecture evaluation ieee transactions computers v48 n2 p111120 february 1999 michele co dee b weikle kevin skadron evaluating trace cache energy efficiency acm transactions architecture code optimization taco v3 n4 p450476 december 2006 roni rosner yoav almog micha moffie naftali schwartz avi mendelson power awareness selective dynamically optimized traces acm sigarch computer architecture news v32 n2 p162 march 2004 james r larus whole program paths acm sigplan notices v34 n5 p259269 may 1999 zhang rajiv gupta whole execution traces applications acm transactions architecture code optimization taco v2 n3 p301334 september 2005 lucian codrescu scott wills james meindl architecture atlas chipmultiprocessor dynamically parallelizing irregular applications ieee transactions computers v50 n1 p6782 january 2001 alex ramirez oliverio j santana josep l larribapey mateo valero fetching instruction streams proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey ahmad zmily christos kozyrakis blockaware instruction set architecture acm transactions architecture code optimization taco v3 n3 p327357 september 2006 kevin skadron pritpal ahuja margaret martonosi douglas w clark improving prediction procedure returns returnaddressstack repair mechanisms proceedings 31st annual acmieee international symposium microarchitecture p259271 november 1998 dallas texas united states kevin skadron pritpal ahuja margaret martonosi douglas w clark branch prediction instructionwindow size cache size performance tradeoffs simulation techniques ieee transactions computers v48 n11 p12601281 november 1999 mahjur h jahangir h gholamipour performance trace locality reference performance evaluation v60 n14 p5172 may 2005 shashidhar mysore banit agrawal timothy sherwood nisheeth shrivastava subhash suri profiling adaptive ranges proceedings international symposium code generation optimization p147158 march 2629 2006 matt yourst kanad ghose incremental commit groups nonatomic trace processing proceedings 38th annual ieeeacm international symposium microarchitecture p6780 november 1216 2005 barcelona spain hao poyung chang marius evers yale n patt increasing instruction fetch rate via blockstructured instruction set architectures international journal parallel programming v26 n4 p449478 august 1998