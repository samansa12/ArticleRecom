declustering loadbalancing methods parallelizing geographic information systems abstractdeclustering loadbalancing important issues designing highperformance geographic information system hpgis central component many interactive applicationssuch realtime terrain visualization current literature provides efficient methods declustering spatial pointdata however little work toward developing efficient declustering methods collections extended objects like chains linesegments polygons paper focus datapartitioning approach parallelizing gis operations provide framework declustering collections extended spatial objects identifying following key issues 1 workload metric 2 spatialextent workload 3 distribution workload spatialextent 4 declustering method identify experimentally evaluate alternatives issues addition also provide framework dynamically balancing load different processors experimentally evaluate proposed declustering loadbalancing methods distributed memory mimd machine cray t3d experimental results show spatialextent workload metric important issues developing declustering method experiments also show replication data usually needed facilitate dynamic loadbalancing since cost local processing often less cost data transfer extended spatial objects addition also show effectiveness dynamic loadbalancing techniques improved using declustering methods determine subsets spatial objects transferred runtime b introduction high performance geographic information system hpgis central component many interactive applications like realtime terrain visualization situation assessment spatial decision making geographic information system gis often contains large amounts geometric feature data eg location elevation soil type etc represented large sets points chains linesegments polygons data often accessed via range queries mapoverlay queries existing sequential methods supporting gis operations meet realtime requirements imposed many interactive applications hence parallelization gis essential meeting high performance requirements several realtime applications gis operation parallelized either functionpartitioning 2 3 5 30 data partitioning 4 8 13 17 19 25 32 33 functionpartitioning uses specialized data structures eg distributed data structures algorithms may different sequential counterparts datapartitioning techniques divide data among different processors independently execute sequential algorithm processor datapartitioning turn achieved declustering 11 27 spatial data static declustering methods fail equally distribute load among different processors loadbalance may improved redistributing parts data idle processors using dynamic loadbalancing dlb techniques paper focus parallelizing rangequery operation gis data using datapartitioning approach 11 application domain realtime terrain visualization realtime terrainvisualization system environment lets users navigate interact threedimensional computer generated geographic environment realtime like virtual environments 16 visualization systems 28 distributed interactive simulation systems 1 type system three major components interaction 3d graphics gis figure 1 shows different components terrain visualization system typical flight simulator hpgis component system contains secondary storage unit storing entire geographic database main memory storing data related current location simulator graphics engine receives spatial data hpgis component transforms data 3d objects sent display unit user moves terrain part map visible user changes time graphics engine fed visible subset spatial objects given location users viewport graphics engine transforms users viewport range query sends hpgis unit example figure 2 shows polygonal map range query polygons map shown dotted lines range query represented rectangle result range query shown solid lines hpgis unit retrieves visible subset spatial data main memory computes geometric intersection current viewport user sends results back graphics engine frequency operation depends speed user moving terrain example terrain visualization flight simulator new range query may generated twice second leaves less half second intersection computation typical map used application contains tens thousands polygons ie millions edges rangequery size 2030 total map requires millions intersectionpoint computations less half second order meet responsetime constraints hpgis often caches subset spatial data main memory mainmemory database may turn query secondarystorage database get subset data cached frequency operation small caching effective secondary storage main memory graphics analysis display 30sec feed back view rangequery 2sec 8kmx8km set polygons secondary storage range query set polygons engine high performance gis component database database figure 1 components terrainvisualization system figure 2 sample polygonal map rangequery 12 problem formulation rangequery problem gis stated follows given rectangular query box b set sp extended spatial objects eg polygons chains line segments result range query sp given set whereomega gives geometric intersection two extended objects call problem gisrangequery problem gisrangequery problem three main components approximate filtering polygon level ii intersection computations iii polygonization result see 29 detailed discussion sequential algorithm note problem different traditional range query objects given range retrieved secondary memory disk main memory without clipping objects similar polygonclipping problem 26 computer graphics existing sequential solutions 6 15 31 rangequery problem cannot always directly used solution gisrangequery problem due high performance requirements many applications example limit response time ie half second shown figure 1 solving gisrangequery problem allows processing maps 1500 polygons 100000 edges many latest processors available today like ibm rs6000590 dec alpha 150hz processors however maps used many hpgis applications least order magnitude larger simple maps hence need consider parallel processing deliver required performance paper focus parallelizing gisrangequery problem set processors meet high performance requirements imposed typical hpgis application goal parallelization achieve minimum possible response time set range queries use data partitioning declustering dynamic loadbalancing parallelizing sequential algorithm gisrangequery problem figure 3 describes steps scheme bounding box initially broadcast processors processor executes sequential gisrangequery algorithm local set polygons processing local data processor checks load imbalances seeks work another processor yet finished work dlb methods used transferring work processors runtime partition apprx filtering computation apprx filtering computation polygonization result polygonization result intersection computation intersection computation get next bbox figure 3 different modules parallel formulations 13 related work contributions declustering loadbalancing important issues parallelization typical hpgis operations like rangequery mapoverlay operations several researchers used declustering loadbalancing towards parallelization traditional rangequery problems kamel faloutsos 22 used local loadbalancingbased data declustering maximize throughput range queries datasets consisting twodimensional rectangles zhou et al 33 describe mappingfunctionbased declustering methods parallelizing grid files context traditional range queries brunetti et al 8 used rowwise division twodimensional regular grids parallel algorithms characterizing terrain data armstrong et al 4 used rowwise partitioning 2d grids parallelizing algorithm determine spatial association measures point data shown customized declustering techniques based spacedivision mapping functions 9 33 proximitybased local loadbalance 17 19 22 27 similarity graphpartitioning 27 needed effectively partition spatial data case uniformly distributed point data shown static declustering often adequate achieving good loadbalance formal methods 33 well experimental studies 4 8 33 however effective declustering sets extended objects received adequate attention literature case extended spatial objects staticdeclustering methods alone might enough achieve good loadbalance case static partitioning dlb techniques used wang 32 used dynamic allocation work different levels eg polygons edges mapoverlay computation addition several dynamic loadbalancing methods developed 12 20 23 25 loadbalancing different applications datapartitioning mapoverlay 32 spatialjoin access methods 18 19 related work presented paper declustering dynamic loadbalancing extended spatialdata received adequate attention literature paper focus static datadeclustering dynamic loadbalancing methods parallelizing gisrangequery problem sets extended objects like linesegments polygons provide framework declustering collections extended spatial objects identifying following issues workload metric ii spatial extent objects workload iii distribution workload spatial extent object iv declustering method addition also provide framework dynamic loadbalancing gis operations identifying issues work transfer methods ii identifying donor processor iii granularity work transfer identify experimentally evaluate alternatives issues range query operation using vector data killeen texas experiments carried cray t3d distributed memory mimd machine consisting decalpha 150hz processors interconnected 3d torus network show traditional declustering methods 27 multidimensional point data need significant extensions applicable extended spatial data also show neither declustering dynamic loadbalancing alone sufficient achieving good speedups beyond 8 proces sors static declustering extended spatial data hard due highly nonuniform data distribution well great variation size extent spatial data experiments show spatialextent workload metric important measures developing declustering method show data replication often needed dynamic loadbalancing cost local processing usually less cost data transfer extended objects addition experimental results also show effectiveness dynamic loadbalancing techniques improved using declustering methods determine subsets spatial objects transferred runtime 14 scope outline paper figure 1 shows two types queries first query retrieve data secondary storage main memory second query 8kmx8km retrieve data main memory graphics engine paper focus latter type rangequeries data assumed main memory several techniques like preprocessing spatial data used reduce sequential cost gisrangequery problem cost rangequery processing also reduced noting consecutive rangequeries may spatially overlap previous rangequeries case new range query considered increment previous range query hence incremental range query methods used solve problem incremental rangequery expressed combination one smaller rangequeries gisrangequery problem also solved using precomputation results fine grid laid top data intersections spatial objects grid cells computed stored main memory since every rangequery combination grid cells intersection results gridcells make rangequery retrieved sent graphics engine hand case datapartitioning approaches large objects may decomposed smaller objects improve loadbalance among different processors thus increasing efficiency solution two approaches result increased total work graphics engine process objects amount time cost rendering graphics engine also increases increased number polygons addition decomposition objects requires memory store objects hand smaller pieces merged single object rangequery operation merging result increased total work hpgis component merging smaller objects increases total work example figure 4 shows different combinations partitioning polygonal data smaller sets combinations grouped four types type division data type ii divides set polygons subsets polygons however polygon treated atomic unit subdivision polygon level allowed contrast type iii divides areas individual polygonsboundingboxes among different processors type iv schemes divide areas edges individual polygons bounding box potential advantage type iii iv schemes type ii scheme possibility better loadbalance less processor idling resulting reduced parallel computation time 32 however note types iii iv schemes result either increased total work increased work polygonization result options dividing bounding subsets subsets division divide divide edges ivd iiia iiid ive ivc small boxes polygons small polygons subsets edges ii iva iiic iiib ivb ivf options dividing polygon data figure 4 alternatives polygonboundingbox division among processors let tcomm responsetime overhead due additional communication cost increased cost polygonization resulting polygons type iii iv schemes gain parallel computation time due improved loadbalancing bounded difference ideal value seq p actual tp value achieved type ii scheme net gain response time type iii iv scheme type ii scheme bounded p scheme ii tseq gain positive polygonsize distributions extremely skewed leading high load imbalances type ii schemes even though techniques potentially increase loadbalance response time gisrangequery consider techniques paper rest paper focus type ii schemes rest paper organized follows section 2 discuss issues declustering extended spatial data section 3 present experimental results different issues declustering spatial data section 4 discuss dynamic loadbalancing issues gis section 5 present experimental results dlb issues gis finally section 6 present conclusions future work declustering spatial data goal declustering method partition data partition imposes exactly load range query intuitively polygons close scattered among different processors range query every processor equal amount work example consider raster representation set spatial vector objects 2d plane suppose point raster representation associated workload vector objects pass point consider distribution workload associated point example distribution might look like surface shown figure 5 consider another distribution dp scaled version distribution factor p suppose set declustered p subsets subset assigned different processor p subsets workload distribution dp workload imposed query equal processors hence datapartitioning achieves goal optimally declustering p subsets distribution d515 0102050150250distributions dp figure 5 example workload distributions p2 optimal declustering achievable cases due nonuniform distribution variable sizes polygons chains linesegments addition load imposed polygon chain query operation function size location query since location query known priori hard develop strategy optimal queries general exists algorithm achieve ideal declustering 2d rangequeries 5 processors 33 even cases possible achieve ideal declustering hard determine partitioning since declustering problem nphard shown definition 1 optimization version gisdeclustering problem given set extended objects p processors set n rangequeries partition set among p processors load processor balanced q q load object x 2 given rangequery q given function f set nonnegative integers definition 2 decision version gisdeclustering problem given set extended objects p processors set n queries partition set p subsets theorem gisdeclustering problem nphard proof reduce partition problem 14 gisdeclustering problem instance partition problem defined follows given finite set size sa 2 subset 0 sa 2 problem transformed polynomial time instance decision version gisdeclustering problem hence conclude gisdeclustering problem nphard 2 since declustering problem nphard heuristic methods used practice declustering extended spatial data section identify issues declustering sets extended spatial objects develop heuristic methods declustering maps extended objects 21 issues declustering spatialdata three major issues declustering sets extended spatial objects workload metric spatialextent workload loaddensity spatialextent workload metric load imposed spatial object function shape extent object case point data load may uniform ie spatial points case chains linesegments load may function number edges case polygon load may function number edges andor area polygon example number edges increases work range query also increases due increase intersection point computations increase size result similarly increase area polygon number edges fixed results range queries intersecting polygon case extended spatial object either area number edges actual intersection points query boundary used estimating workload denoted loada note extended spatial data accurate method estimating amount work actually solve problem number edgespoints spatial object may accurately reflect amount work required object particular range query get rough estimate work workload metric spatial extent workload spatial extent workload defined region ra space affected object ie query q overlaps ra work required process q influenced object usually ra depends space occupied object however often expensive use exact geometry spatial object estimating extent object thus approximate geometries considered estimating spatial extent spatialextent ra often approximated approximated point approximated box approximated n boxes example bba smallest rectangular box enclosing object represented two corners function may defined figure 6 shows example polygons different approximations extent workload figure also shows sample range query dotted lines polygon approximated point shown middle polygon main drawback point approximation even though object region interest eg q 1 might still considered outside point lies outside region shown case polygon alternatively bounding box approximation used shown figure 6 polygons b c e drawback approximation even though polygon region interest bounding box might still region interest shown polygon e alternatively multiple bounding boxes may used represent polygon shown polygon note even though greater number bounding boxes gives better representation spatial extent work also expensive construct kind representation c query q1 figure examples approximations extent workload load density spatial extent case extended objects distribution density workload spatial extent affects declustering decisions expensive determine actual workload distribution approximate distribution uniform distribution may used instead actual distribution approximate distribution work determined considering multiple bounding boxes dividing region small cells counting work cells example case polygon b shown figure 6 clipped load denoted clipped loadb corresponding query q 1 shown dotted line estimated different ways assume workload distribution polygon uniform bounding box polygon b compute clipped load clipped loadb areabbb theta loadb 4 note work estimate may inaccurate cases example edgebased workload metric coupled assumed uniform workload distribution overestimates work required polygon c rangequery q 1 areabased workload metric coupled uniform workload distribution overestimates work required polygon e rangequery q 1 22 declustering methods since declustering problem nphard heuristic methods used declustering spatial data describe three heuristic methods based ideas spacepartitioning mapping local loadbalance similaritygraph addition propose new population distributionbased declustering method declustering spatial data simplicity describe methods polygon data applied extended spatial objects well 221 spacepartitioning mapping functions spacepartitioning mappingfunctionbased methods provides mapping function domain data items set processor ids example mapping function based hilbert spacefilling curve 7 21 see 10 survey mapping functions hilbert curve gives total ordering points 2dimensional space polygons declustered using hilbert method follows let l set input objects let l p ordered list polygons corresponding hilbert order set let n number polygons list polygons list assigned processor cyclic manner polygons list l p indices assigned ith processor 222 local loadbalance llb method local loadbalancing methods 22 consider sample window space based frequent range queries try equally distribute load window processors local loadbalance method parameter window w following steps set polygons assign first p polygons p processors ii next polygon list consider load corresponding window w processor select processor minimum load iii assign next polygon processor repeat steps ii iii polygons assigned step ii method processor minimum load selected follows let clipped loadp j w p j processor select processor k weightw minimum 223 similaritygraph method similaritygraph declustering method 27 shown outperform methods declustering nonuniformly distributed data heuristic method based maxcut graphpartitioning weighted similaritygraph wsg wsg models data properties queries case llb method rectangular window w used sample query efficiency wsg constructed wrt window w assigning clipped loadv w tv object v input experimental study use incremental maxcut partitioning 27 approach declustering spatial data see appendix details similaritygraph declustering method applied extended spatialdata 224 population distributionbased pdb method goal populationdistributionbased declustering method achieve identical load distribution partition data discuss example populationdistributionbased method declustering polygonal data basic idea behind method partition data sets groups similar workload distribution entire space shown figure 5 workload distributions group entire space compared allocating new object group new object allocated group statistical difference different groups minimal however tracking comparing two distributions statistical differences expensive economical less accurate method use approximate distribution instead actual workload distribution use pair discrete 1d distributions approximate actual 2d distribution method uses actual intersection points polygons grid consisting vertical horizontal scanlines imposed top polygonal data shown figure 7 assume scanlines parallel xaxis scanlines parallel yaxis let fx number intersection points line polygons input similarly let n number intersection points line without loss generality let polygons input distribute polygons among processors allocate first p polygons p processors polygon p assigned ith processor next polygon pw determine distribution intersection points assigned polygons plus current polygon scale distribution p let distribution basedistribution base distributions f w similar fx gy figure 7 distributionbased method base distributions contain intersection points polygons different assignments polygon pw p processors estimate total population mismatch due assignment total population mismatch assignment estimated sum squared differences distributions processor basedistribution select processor corresponding minimum population mismatch processor assigning current polygon minimization function assigning polygon pw given min current polygon pw temporarily assigned lth processor iteration minimization function f g distribution functions corresponding f g respectively ith processor note f g contain intersection points polygons assigned ith processor complexity pdb method allocating 1 polygon innermost sum equation 5 takes thetanm time since sum computed processor takes thetap n double summation since p iterations double sum ie p iterations minimization function takes total thetap 2 n time brute force implementation method note two iterations minimization function four terms innermost summation change processor hence need compute entire sum iteration minimization function reuse rest terms previous iteration hence first iteration minimization function iteration takes constant amount time reduces overall complexity pdb method 3 experimental evaluation declustering issues compare performance different alternatives issues declustering extended spatial objects range map sizes different number processors via experiments carried cray t3d parallel computer use spatial vector data killeen texas experimental study data divided seven themes representing attributes slope vegetation surface material hydrology etc used slope attributedata map 729 polygons 41162 edges base map experiments denoted 1x map studying effect increased map size derived new maps base map using following method scaling base map along xaxis two combining two scaleddown maps translating one scaleddown maps along xaxis results map 1458 polygons 82324 edges 2x map similar technique used alternately scaling along yaxis xaxis get maps different sizes also use chain data fort sill 9667 creeks 188678 edges shown figure 8 table 1 shows details maps range queries figure 8 creek data map sample range query table 1 maps range queries used experiments map objects edges rangequery size number polygons 41162 25 75 polygons 82324 25 75 polygons 164648 25 75 8x 5832 polygons 329296 25 75 creek 9667 chains 188678 20 75 31 experimental methodology issues declustering studied comparing performance different methods set range queries sequence 75 range queries constructed sequence center points range query represents random walk data set postprocessing done sequence ensure range queries unique rangequery lies completely within map size range query approximately 25 total area map measurements obtain run time program 75 queries report observed mean 75 values figure 9 shows experimental methodology number different options tried parameter shown parentheses number possible combinations module also shown figure restrict experiments due memory limitation individual nodes cray t3d 64 mbytes main memory limiting size map 4x sequential runtime measured directly map 4x adequate work processor beyond p16 evident absolute runtimes 005 sec shown tables 2 5 generator workload g spatialextent bboxpoint map generator size sample window 30100 loaddensity uniform apprx range queries rangequeries desired size rangequery decluster workload edges area 124 size map 1x2x 4x8x base declusteringmethod options measurements analysis data collection5 maps figure 9 experimental method evaluating declustering methods experiments measure analyze cost per rangequery exclude preprocessing cost preprocessing cost includes cost loading data main memory cost declustering data among different processors note preprocessing cost paid data set corresponds current window interest query range moves current window new data fetched disk discarding data old window since next location window often predetermined preprocessing new data need affect performance rest system moreover new data set loaded main memory would active several minutes window move current range thus would leave several minutes preprocessing next data set hence study interested measuring performance algorithm terms variable cost per range query preprocessed data 32 experimental results conduct experiments study alternatives following issues workload metric spatial extent workload load density spatial extent addition compare different declustering methods local loadbalance similaritygraph pdb experiments data initially distributed among different processors processor acts leader processor responsible broadcasting range query rest processors receiving rangequery information processor works local data local data exhausted local data processed processor waits next range query processed lead processor waits processors finish work broadcasting next range query note communication required bounding box broadcast parameters range query 321 comparison alternatives workload metrics compare area number edges alternatives workload metric case polygonal data spatial extent workload based boundingbox approximation load density spatial extent assumed uniform thus clipped loadpolygonp windoww estimated using equation 4 used llb method sample window 30 declustering metric number processors p varies 2 16 4x map used data set results experiment shown figure 10a xaxis gives number processors yaxis gives average speedups 75 range queries main trends observed graph number edges workload metric results better speedups hence appears accurate workload metric 4 difference two workload metrics negligible 322 comparison alternatives spatialextent workload compare point boundingbox approximators alternatives spatialextent workload case polygonal data workload metric fixed number edges load density spatial extent assumed uniform used llb method sample window number processors llbedgebox llbareabox2468 number processors llbedgebox llbedgepoint b figure 10 speedups llb method 4x map 30 declustering method number processors p ranges 2 16 4x map used data set results experiment shown figure 10b xaxis gives number processors yaxis gives average speedups 75 rangequeries main trends observed graph boundingbox approximator spatial extent results better speedups hence appears accurate estimator 4 difference two estimators negligible 323 comparison different declustering methods compare performance different declustering methods hilbert llb similaritygraph pdb addition compare effect size sample window performance similaritygraph llb methods simplicity workload metric fixed number edges spatial extent assumed point loaddensity spatial extent assumed uniform case llb similaritygraph methods figure 11 gives results showing effect sample window size llb similaritygraph methods xaxis gives number processors yaxis gives average speedups 75 rangequeries figure 11 llb30 sim30 refers llb similaritygraph method sample window 30 total area map similar notation used 100 window methods main trends observed graphs increased window sizes gives increasing speedups ii llb method increase speedup 30 window 100 window negligible figures 12 13 show comparison different declustering methods polygon chain data respectively figures xaxis gives number processors yaxis gives speedup number proceccors sim100 llb100 llb30 sim3024681012 number proceccors sim100 lldb100 lldb30 sim30 b figure 11 speedups llb similaritygraph methods different window sizes speedups maps 2x 4x given b respectively value main trends observed graphs bigger maps lead better speedups schemes probably due improved loadbalance ii similaritygraph pdb methods give best speedups among different methods iii speedups better chain data polygon data may due less variance workloads line data compared polygon data iv mappingfunctionbased methods like hilbert provide inferior speedups beyond 8 processors v even best declustering method provide good speedups 8 processors maps used experiments 33 comparison static loadbalancing effectiveness declustering methods achieving loadbalance shown table 2 data shown table 2 represented mean sigma sd 75 range queries used experiment column avg static gives average static execution time 16 processors 75 range queries column max static gives maximum static execution time 16 processors averaged 75 range queries experiment observe static declustering alone achieve good loadbalance static methods need augmented dynamic loadbalancing table 2 performance evaluation slb method avg static max static speedup sim 00454 sigma 0003 00621 sigma 0004 1170 pdb 00454 sigma 0003 00626 sigma 0004 1160 llb 00454 sigma 0003 00660 sigma 0003 1100 speedup number proceccors hilbert sim100 llb100 number proceccors hilbert sim100 llb100 pdb b figure 12 speedups different staticdeclustering methods speedups maps 2x 4x given b respectively 4 dynamic loadbalancing dlb techniques static declustering methods fail equally distribute load among different processors loadbalance may improved transferring spatial objects idle processors using dynamic loadbalancing techniques 41 dlb issues gis typical dynamic loadbalancing technique addresses three issues methods good transferring work spatial objects two processors ii much work idle processor fetch iii processor idle processor ask work 411 methods transferring work extended spatial objects large eg 50 edges average maps killeen texas size require special data structures solving rangequery problem hence sometimes may expensive send complete object data corresponding data structures another processor solve problem locally compare relative costs local processing data transfer develop cost models two operations cost computing intersection range query q polygon depends whether intersects q example completely inside q detected constant amount time hand intersects q cost intersection computation polygonization depends number intersection points size result let p 0 probability speedup number proceccors hilbert sim llb pdb figure 13 speedups different staticdeclustering methods line data polygon intersects least one edges range query let x number edges sequential cost given ff 0 fraction edges actually intersect q c cost one step com putation simplicity assume cost intersection computation polygonization result linear function ff 0 p 0 x constant c 2 accounts checking boundingbox polygon completely inside completely outside query box q since test performed using 8 comparisons c typically data used experiments similarly transfer cost modelled linear function number edges x constant c 3 included account transfer packing unpacking datastructures data associated typically c 3 2 assuming cost local processing cost gisrangequery computation value x small close 1 implies even small objects transfer cost local processing cost note even 0 relation remains drawback may overcome selectively duplicating data different processors exchanging object ids since object id word data result minimum communication overhead data transfer note replication data different processors results memory overhead 412 partitioning method granularity transfers granularity work division determines much work transferred donor processor idle processor granularity may depend size remaining work number processors cost work transfer accuracy estimating remaining work several strategies like selfscheduling 12 factoring scheduling 20 chunk scheduling 23 exist determining amount work transferred also simplest case transferring one piece work time also considered cases communication cost negligible small compared average cost solving rangequery problem set objects chunks single objects may yield best possible load balance hand chunks one object suitable communication cost comparable average cost solving rangequery problem set objects true distributed memory systems case chunks one object desirable keep comparable amount work chunk loadimbalance kept low note problem dividing work chunks equal work similar static declustering problem even though traditional dlb methods use simple methods like random partitioning round robin etc hypothesize loadbalance dlb method improved using systematic declustering method dividing work chunks since declustering operation expensive chunking done statically also note simplicity consider dynamically variable size chunks paper 413 processor idle processor ask work methods decide processors idle processor ask work discussed analyzed 24 25 methods divided two categories 1 poolbased method pbm fixed processor available work idle processor asks fixed processor work 2 peerbased method work initially distributed among different processors idle processor selects peer processor work donor using random polling nearest neighbor global round robin grr asynchronous local round robin arr poolbased method structure gisrangequery problem imposes limitation amount work kept shared pool work initially single processor approximate filtering computation range query cannot parallelized result nonparallelizable work rest processors wait single processor finish filtering computation fetching objects intersection computation processor idling avoided initially partitioning data two parts static pool initially static part data declustered p sets ith processor pool part data assigned leader processor processor 1 range query processor leader processor starts working local data corresponding static part leader processor first completes filtering pool starts working local data corresponds static part situation shown figure 14 process s2 dlb process sp dlb process s2 process sp dlb apprxfilpool process s1 dlb apprxfilpool process s1 dlb small pool large pool b figure 14 small pool may result high static load imbalance large pool may result processor idling processors finish work local data filtering step pool part finished processor would wait lead processor finish filtering work pool part data shown figure 14b idling turn results increased run time decreases performance algorithm hence enough work processor filtering step pool completed without leading processor idling hand static work processor much static loadimbalance high high static loadimbalance also result processor idling shown figure 14a let w total work required solve rangequery problem let j fraction total time spent approximate filtering ie stage rangequery computation also let load imbalance due static declustering data total work w declustered among p processors maximum time taken processor w 1 minimum time taken w assume p overhead incurred due parallelization increase total runtime due communication overhead processor idling suppose x fraction total work taken pool data p ool large enough overcome static load imbalance incurred due static part data figure 14a also filtering cost jxw p ool less maximum time corresponding static work figure 14b combining equations 7 8 get lower upper bounds pool size table 3 gives sample upper lower bounds x estimated using equation 9 parallel overhead assumed zero j assumed 005 table 3 estimated lower upper bounds pool size lowerbound upperbound 080 078 066 063 048 046 peerbased methods peerbased methods data divided among processors common pool idle processor asks another peerprocessor work paper evaluate global round robin grr asynchronous round robin arr methods gisrangequery problem see 24 complete discussion two algorithms grr single processor acts scheduler responsible sending id next available processor work requesting idle processor idle processor requests work processor work main drawback scheme scheduler processor may become bottleneck number processors increases experimental study bottleneck significant number processors relatively small ie less 32 arr every processor maintains local target pointer whenever processor runs work uses target pointer label donor processor sends work request target value incremented modulo p time work request sent processors receives request work sends work requesting processor otherwise requesting processor sends another request next processor given target pointer work received donor processor note two methods arr method single processor bottleneck case grr arr method needs extra work check termination detection since single source information remaining work range query hence advantage method grr may offset due terminationdetection overhead gisrangequery problem performance two methods may comparable 16 processors 42 framework parallel formulations approach use declustering static dynamic loadbalancing levels present general framework method used declustering dlb methods discussed far twophase scheme since use initial static declustering data use additional loadbalancing run time pseudocode general method given figure 15 following discussion let p number processors used system initially data declustered two sets b set used static data objects set allocated processor processor alone responsible processing objects objects set never transferred processors dlb phase similarly set b used dynamic data objects set transferred processors dlb phase call set b shared pool data since objects set shared processors dlb phase initial declustering data two sets done depending desired size shared pool polygons number processors following section experimentally show variation size across different number processors data statically declustered p sets processor p assigned set 1 choice declustering method determined number processors type data data distribution data b also statically declustered x buckets replicated processors note staticdeclustering methods discussed far used static declustering purpose value x dependent size b number processors communication cost hence parameter tuned depending data bounding box next range query received designated lead processor example processor broadcasts boundingbox parameters processors group receiving boundingbox parameters processor p performs approximate polygonlevel filtering retrieves candidate polygons local data set places result set l addition processors performs approximate filtering data set b keeps resulting object ids dynamic set set object ids x buckets separate bin processor p independently works data set l objects left set processor p finishes work data l goes dlb mode mode data dynamic set used dynamic loadbalancing work transferred transferring bin object ids processors algorithm terminates dlb method terminates var local data array pidset objects mapi processor using decluster corresponding data var global data array pidset objects mapi processor using decluster corresponding data b begin one broadcast0 pidset bbox phase parallel forpid pidset sequential algorithmlocal datapid goto dlb phase parallel work object nextobject ids next unprocessed bucket id sequential algorithmobject ids end figure 15 pseudocode parallel formulation 5 experimental evaluation dlb methods compare different dlb methods applied rangequery problem set extended spatial objects use framework given figure 15 implementing parallel rangequery algorithm experiments carried cray t3d parallel computer using polygonal data described table 1 alternatives dlb issues evaluated comparing average performance set 75 range queries experiments similaritygraph method 100 window used static declustering method unless mentioned otherwise simplicity number edges used workload metric static declustering data similarly spatial extent assumed point loaddensity assumed uniform figure 16 shows experimental methodology evaluating dlb issues number different options tried parameter shown parentheses number possible combinations module also shown figure message startup time cray t3d 100 nano seconds ie 01 micro seconds study effect parallel formulations different communication networks simulate different networks increasing value 01 101 1001 sec 51 evaluation worktransfer strategies worktransfer strategies compared basis following two parameters average cost transferring complete object data including data structures one processor another processor ii average cost solving gisrangequery polygonlevel filtering single processor includes cost packing unpacking data structures related polygons filtering cost sending packed data one processor another processor table 4 shows actual experimental values 5 randomly chosen range queries analysis data collection map generator map base size 4 maps range queries size rangequery measurements decluster pool size 124 methods grrarrpbm options partitioningdeclustering method parallel hpgis generator workload rangequeries desired75 figure experimental method evaluating dlb methods parallel gisrangequery polygonal data 2x map table also shows average values rangequeries 2x map shown equation 7 note consistently cases gap parallel computers cm5 ibm sp2 substantially higher machines result consistent analysis shown equation 7 conclude desirable transfer complete polygon data processors run time instead polygon ids transferred run time facilitated selectively duplicating polygon data processors rest experiments work transfers always done transferring object ids unless otherwise stated table 4 cost transfer vs cost solving problem single processor cost seconds time sec avg 75 queries 52 declustering dlb methods experiment effect chunking based systematic declustering compared random declustering dlb method used grr dlb method compared random similarity graph llb methods declustering dynamic data declustered polygons per chunk figure 17 shows experimental results seconds xaxis gives number processors yaxis gives average speedup 75 queries data clear random declustering data effective systematic declustering achieving good loadbalance gisrangequery problem moreover ordering methods remains static case shows systematic declustering data improves loadbalance also loadbalance improved using information number processors ts0 sim llb number processors ts100 sim llb rand b figure 17 speedups different declustering methods grr method map4x declustering phase 53 evaluation granularity workallocation dlb compare effect different chunk sizes number polygons chunks ranging 1 30 using grr dlb method similaritygraph100 declustering method addition compared effect increasing value decreasing size chunk ie increasing number chunks experiment conducted using 4x map replicated data 40 total data chunks single polygons usually result best possible loadbalance also results maximum overhead due increased number chunks figure 18 shows graph experiment value low chunks single polygons result best possible speedups value increased maximum speedup achieved chunk size single polygon chunks due increased communication overhead increased number chunks requires exchange messages processors note 100 seconds typical value seen mimd message passing computer like ibm sp2 54 effect pool size evaluate effect pool size using poolbased method varying number processors varying data files number processors varied 4 16 data files varied 1x map 4x map pool size varied 0 100 total data note 0 polygons per chunk ts01 ts101 ts1001 figure 18 granularity worktransfers pool refers static declustering dlb work transfers done transferring polygon ids used one polygon per chunk481216 speedups map4x p4 p8 speedups p16 map1x map2x map4x b figure 19 speedups different pool sizes poolbased method figure 19 shows results experiment xaxis gives size pool percentage total data yaxis gives average speedups 75 range queries expected speedups increase increase pool size point start decreasing initial increase speedup may due increased loadbalance decrease speedup achieving maximum value due nonparallelizable overhead approximate filtering shown equation 8 note decrease greater p increases due increase non parallelizable overhead increasing p maximum speedup occurs different pool sizes different number processors different data sets also note maximum speedups occur ranges predicted table 3 55 comparison dlb methods compare performance three dlb methods grr arr pbm 1001 number processors varied 4 16 4x map used input data number polygons per chunk 1 1001 work transferred transferring polygon ids similaritygraph100 used declustering data481216 number processors pbm arr number processors pbm arr grr figure 20 speedups different dlb methods figure 20 shows speedups three methods xaxis gives number processors yaxis gives average speedups 75 range queries grr arr comparable performance pbm performs better two methods shown figure 20a however grr inferior speedups relative methods shown figure 20b may attributed centralized overhead maintaining list possible donor processors grr 56 effectivness dynamic loadbalancing effectiveness dlb methods achieving good loadbalance shown table 5 data collected 40 pool pbm 40 replicated data grr arr similaritygraph100 used declustering method one polygon per chunk shared data work transfers done transferring polygon ids data shown table 5 represented mean sigma sd 75 range queries used experiment column avg static gives static execution time averaged 16 processors 75 range queries column max static gives maximum static execution time 16 processors averaged 75 range queries similarly avg otal time average total time 16 processors 75 queries otal total parallel run time averaged 75 range queries experiment observe dlb methods achieved good loadbalance ie percentage difference avg total even though high loadimbalance static part table 5 performance evaluation dlb method avg static max static avg total max total speedup pbm 00307 sigma 0004 00492 sigma 0007 00484 sigma 0006 00518 sigma 0007 1404 sigma 069 grr 00329 sigma 0004 00518 sigma 0008 00543 sigma 0008 00557 sigma 0008 1307 sigma 064 arr 00241 sigma 0003 00422 sigma 0006 00508 sigma 0006 00556 sigma 0006 1303 sigma 059 6 conclusions future work datapartitioning effective approach towards achieving high performance gis parallelize gisrangequery problem using data partitioning dynamic loadbalancing techniques partitioning extended spatialdata maps difficult due varying sizes extents polygons difficulty estimating work load hence special techniques needed parallelize gisrange query problem identify main issues declustering collections extended spatial objects like chains linesegments polygons experimentally evaluate several alternatives issues distributed memory mimd machine rangequery operation experimental results show number edges better load estimator area object bounding box approximator spatial extent object gives information point estimator going higher order estimator like multiple bounding boxes practical estimators expensive obtain expensive use declustering extended spatial data results also show among static declustering methods similaritygraph distribution based methods outperform static declustering methods also show performance dlb methods improved using declustering methods determining subsets polygons transferred runtime proposed approach use ideas declustering hierarchical fashion increasing load balance purely static methods decreasing communication cost purely dynamic methods future work planning scale methods larger numbers processors larger maps queries also plan extend work mapoverlay problems computationally intensive hpgis operations another major effort would focus high performance techniques secondary tertiarystorage terrain mapping effect io eg swapping indexing methods finally would like evaluate techniques workstation clusters common many gis applications acknowledgments work sponsored army high performance computing research center auspices department army army research laboratory cooperative agreement number daah04 9520003contract number daah0495c0008 aro contract number dadaah049510538 content necessarily reflect position policy government official endorsement inferred work also supported federal highway authority minnesota department transportation would like thank ahpcrc university minnesota pittsburgh super computing center providing us access cray t3d would also like thank minesh amin christiane mccarthy improving readability technical accuracy paper r page httpdis parallel computational geometry parallel computational geometry experiments measurement spatial association using parallel supercomputer efficient plane sweeping parallel algorithms reporting counting geometric intersections parallel processing spatial data terrain characterization disk allocation product files multiple disk systems allocation methods using error correcting codes idea declustering applications dynamic processor selfscheduling general parallel nested loops uniform grids technique intersection detection serial parallel machines computers intractability guide theory npcompleteness dynamic index structure spatial searching visualizing large data sets earth sciences data parallel rtree algorithms data parallel spatial join algorithms performance dataparallel spatial operations linear clustering objects multiple attributes parallel rtrees allocating independent subtasks parallel processors introduction parallel computing design analysis algorithms scalable load balancing techniques parallel computers analysis algorithm polygon clipping similarity graphbased approach declustering problem applications range search parallel using distributed data structures generic solution polygon clipping parallel intersection algorithm vector polygon overlay allocation methods parallelizing grid files tr ctr shashi shekhar sivakumar ravada vipin kumar douglas chubb greg turner parallelizing gis shared address space architecture computer v29 n12 p4248 december 1996 mehmet koyutrk cevdet aykanat iterativeimprovementbased declustering heuristics multidisk databases information systems v30 n1 p4770 march 2005 thu nguyen john zahorjan scheduling policies support distributed 3d multimedia applications acm sigmetrics performance evaluation review v26 n1 p244253 june 1998 jignesh patel david j dewitt clone join shadow join two parallel spatial join algorithms proceedings 8th acm international symposium advances geographic information systems p5461 november 0611 2000 washington dc united states n r lu l qian sivasubramaniam keefe storing spatial data network workstations cluster computing v2 n4 p259270 1999 hakan ferhatosmanoglu aravind ramachandran divyakant agrawal amr el abbadi data space mapping efficient io large multidimensional databases information systems v32 n1 p83103 march 2007 hakan ferhatosmanoglu ali aman tosun guadalupe canahuate aravind ramachandran efficient parallel processing range queries replicated declustering distributed parallel databases v20 n2 p117147 september 2006