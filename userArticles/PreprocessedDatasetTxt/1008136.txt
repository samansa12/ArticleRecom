computing smallest singular triplets implicitly restarted lanczos bidiagonalization matrixfree algorithm irlanb efficient computation smallest singular triplets large possibly sparse matrices described key characteristics approach use lanczos bidiagonalization implicit restarting harmonic ritz values algorithm also uses deflation strategy applied directly lanczos bidiagonalization refinement postprocessing phase applied converged singular vectors computational costs techniques kept small make direct use bidiagonal form obtained course lanczos factorization several numerical experiments method presented illustrate effectiveness indicate performs well compared existing codes b introduction consider singular value decomposition svd matrix loss generality denote singular triplets paper interested computing say k smallest singular triplets general large sparse matrix problem arises several important applications including image signal processing 38 control 6 matrix pseudospectra 37 computation extremal singular triplets large sparse matrices focus many research eorts see 392221303335 well preprint submitted elsevier science 210293615 numerous references therein recent needs applications ones mentioned earlier however motivated research oriented towards development algorithms computation smallest singular triplets problem acknowledged challenge capabilities current stateoftheart software eg see 15711131424 common practice approximate singular values computing eigenvalues equivalent hermitian eigenproblems furthermore since computing smallest eigenvalues values matrix equivalent computing largest eigenvalues values inverse significant work done shiftandinvert techniques example approach adopted matlab version svds routine based arpack 22 latter implements one successful theoretical frameworks eective implicitly restarted arnoldi technique based seminal work sorensen lehoucq collaborators however size matrices increases approach becomes expensive terms storage computational costs requires factorization solution large sparse possibly indefinite matrices developments attempt remedy problem concern inexact inverse iteration inexact inverse lanczos methods see example 19 2 sec 112 alternative approach avoids solves frequently eective based use harmonic ritz values 2633 paper propose investigate algorithm call irlanb based lanczos bidiagonalization lbd method computing singular values originally due golub kahan 8 matrixfree method computation singular triplets thus operations matrix vector multiplications hermitian adjoint enhance lbd algorithm stateoftheart technology eective computation small singular triplets large possibly sparse trices improvements described paper whose structure follows section 2 review lanczos bidiagonalization describe limitations deployed compute smallest singular triplets section 3 show incorporate implicit restarts introduced 35 permit lanczos bidiagonalization maintain limited storage computational requirements per restart section 4 study use ritz harmonic ritz values implicit shifts section 5 show apply orthogonal deflation transformation proposed 34 context lanczos bidiago nalization also make eective singular values clustered singular section 6 show use refinement originally proposed eigenvectors 16 enhance computation singular pairs section 7 describe overall structure irlanb finally section 8 describe numerical experiments illustrate behavior irlanb various cases compares performance related methods 11 definitions equivalent symmetric eigenproblems following well known connections see eg 10 sec 86 svd eigendecompositions following hermitian matrices fundamental discussion z nm partitioning u columns setting orthonormal eigenbasis augmented matrix c z nm equivalences provide convenient framework seeking singular values large matrices permit computation singular triplets using symmetric eigensolvers black box problem studied literature exist several software packages solution nevertheless seeking small singular triplets paper several complications arise must addressed 28 33 particular since interested smallest singular values equivalent targets smallest eigenvalues either aa interior eigenvalues c latter two excluding spurious zeroes observe squaring singular values induce increase separation largest ones also cause corresponding clustering smallest ones cause problems symmetric eigensolvers 27 furthermore illconditioned denote condition number respect 2norm squaring condition number likely cause significant loss accuracy small singular values note algorithm lanczos bidiagonalization input c mn starting vector p 0 c scalar k output bidiagonal matrix b k r k1k orthogonal bases 1 2 3 r 4 5 7 8 9 end table lanczos bidiagonalization cf 2821 real scalars diagonal subdiagonal elements respectively bidiagonal matrix b k nonsquare matrices analysis holds refer instead eective denotes pseudoiverse see 13 14 basis relation 3 select instead recover singular triplets eigenvalues augmented matrix c approximate interior eigenvalues unfortunately computation also challenges performance symmetric eigensolvers eg convergence behavior becomes irregular 27 furthermore since singular value corresponds eigenvalue pair symmetric eigensolvers tend take twice number iterations additional diculty stems increased length n basis vectors corresponding increase storage requirements approximations singular values drawn next describe lanczos bidiagonalization lbd holds central role framework lbd originally proposed golub kahan cf 8 10 sec 933 process transforming matrix c mn upper bidiagonal line bidiagonalization algorithms presented elsewhere literature consider version process transforms lower bidiagonal form fact discussion owes lot work larsen 21 k successful steps lbd produces two blocks lanczos vectors whose columns orthonormal bases krylov subspaces k k1 aa respectively 1 satisfy following relations matrix b k r k1k real elements lower bidiagonal k 6 table 1 provides algorithmic outline lbd following execution lbd singular values b k could used approximations singular values premultiply sides 5 use 4 obtain however lbd algorithm cf lines 68 table 1 also write matrix real symmetric tridiagonal therefore exact arithmetic relation 8 symmetric lanczos factorization hence lbd equivalent symmetric lanczos iteration aa also known equivalence lbd applied lanczos applied augmented matrix c 10 sec 932 particular consider starting vector z following standard terminology km r spanr ar m1 r 2k steps lanczos starting vector q 1 following relation holds q k oddeven permutation rows columns 9 obtain lanczos factorization contains lbd factorizations 4 5 next disuss diculties lbd algorithm important diculty lbd typical lanczos type algorithms loss orthogonality among basis vectors v k u k1 25 application reorthogonalization schemes remedy problem though extra computational cost compromise use partial reorthogonalization schemes dynamically update level orthogonality among bases vectors step recent work larsen produced matlab codes implement partial reorthogonalization context lbd see 213132 order obtain acceptable approximations smallest singular triplets even sophisticated schemes partial reorthogonalization convergence slow bases u k1 v k often need become long computational storage costs become overwhelming show next sections counter problems adopt implicit restarting mechanisms lbd maintain computational memory requirements constant step furthermore combine implicit restarting harmonic ritz values approximation smallest singular triplets algorithm bulgechasing input tridiagonal matrix output updated upper bidiagonal matrix l 1 set 2 3 determine sin c 4 apply b l givens rotation right b 5 sin c z 7 apply b l givens rotation left b 8 l 1 9 10 end 11 end table bulgechasing algorithm golubkahan svd step 10 sec 862 implicitly restarted lbd implicit restarting proposed sorensen 35 arnoldi lanczos iterations practical implementation arpack 22 widely acknowledged one successful frameworks solving large eigenproblems section describe apply framework case lbd implicit restarting context lbd first studied bjorck grimme van dooren 4 later larsen combined partial reorthogonalization section 2 established lbd equivalent lanczos applied aa according factorization 7 therefore steps lbd apply p implicitly shifted qr steps matrix l real symmetric tridiagonal alternatively apply golubkahan svd steps 10 sec 862 directly bidiagonal matrix b l order enhance stability 27 implicitly shifted qr step applied directly upper bidiagonal matrix means bulgechasing cf table 2 first givens rotation line creates bulge ie nonzero element subdiagonal trailing givens rotations chase bulge matrix order restore upper bidiagonal form since work lower bidiagonal matrix update written orthogonal matrices implement givens rotations therefore updating bases v l u l1 recover bidiagonalization l updated lbd factorization would obtained l steps lbd special starting vector using shift previous procedure repeated p1 shifts 2 3 p obtain bidiagonalization corresponds starting vector therefore apply polynomial filtering implicit restarts lbd equivalent implicitly restarted lanczos aa also showed relation 10 lbd equivalent lanczos applied augmented matrix c thus natural ask whether implicitly restarted lbd equivalent implicitly restarted lanczos c shown following proposition stated assuming exact arithmetic answer negative proposition 31 possible general apply implicit qr steps lanczos factorization 9 augmented matrix c obtain lanczos factorization computed lbd proof implicit restarts essentially perform polynomial filtering starting vector u 1 p implicit qr steps factorization 9 updated lanczos factorization written starting vector q nontrivial polynomial augmented matrix c degree p observe powers c following special structure define polynomials containing strictly odd even powers respectively polynomial c holds since starting vector holds q observe according 2 holds thus e aa u 1 used svd since v orthonormal denote diag 1 follows notice u u 1 cannot zero since u orthonormal full rank furthermore general matrix distinct nonzero singular values norm would zero e since degree e p however happen e identically zero therefore general updated vector q cannot special structure thus updated lanczos factorization augmented matrix c cannot equivalent lbd factorization next consider shift selection implicitly restarted lbd particular examine two strategies exact ritz values ii exact harmonic ritz values 41 ritz values using relation 5 premultiplying u l see l kp steps lbd following relationship holds l aa u l1 u l l av l1 e l1 applying relation 4 considering first l columns side follows u l aa u l l r denotes square lower subdiagonal matrix obtain omitting last row b l therefore squares singular values matrix b l ritz values hermitian matrix aa therefore provide approximations singular values exact ritz values strategy pick implicit shifts largest p squared singular values l worth noting since target compute singular values l eigenvalues l expect loss precision due squared conditioning furthermore approximating squared singular values aggravate existing clustering smallest singular values 42 lbd harmonic ritz values ritz values readily provide straightforward shift strategy often case however smallest singular values clustered situation significantly slow convergence implicitly restarted lanczos order secure satisfactory convergence rates try approximate smallest singular values computing largest ritz values aa 1 remainder section would assuming full rank line matrixfree approach aspired paper however prefer avoid explicit computations aa 1 becomes possible using concept harmonic ritz values 26 definition 41 value c harmonic ritz value matrix c mm respect linear subspace w k ritz value 1 respect w k returning lanczos factorization 7 since interested ritz values aa 1 could compute harmonic ritz values aa means oblique projection corresponding petrovgalerkin condition presentation remainder section owes lot discussion sleijpen van der vorst 33 regarding harmonic ritz values reader also refer 14 relevant discussion particular search space u l1 dimension l test space w corresponding petrovgalerkin condition becomes l1 harmonic ritz value aa furthermore u l1 w l1 bases span subspaces u l1 w l1 respectively harmonic ritz values aa eigenvalues matrix clear compute shifts implicit restart restart compute harmonic ritz values use shifts p largest ones worth noting actually using exact shift strategy harmonic rather ordinary ritz values show next harmonic ritz values computed eigenvalues symmetric rankone modification symmetric tridiagonal matrix particular expanding relation 11 help lbd relations 4 5 7 follows l l e l1 e notice next c l1 similarly previous section square lower bidiagonal matrix therefore b l1 cholesky factor c l1 furthermore term l1 written note also e l1 e l1 idempotent since b l1 cholesky factor c l1 eigenvalues c l1 l1 also eigenvalues therefore set relation shows harmonic ritz values real nonnegative computed eigenvalues symmetric rankone modification symmetric tridiagonal matrix needed large l therefore one could deploy fast algorithms exploit special structure worth noting harmonic ritz values 33 derived eigenvalues rank one update arnoldi matrix furthermore term l1 identical since u l1 orthonormal u l1 av lbd algorithm thus follows alternative way writing equation 13 terms follow naturally another lbd step furthermore singular value decomposition thus compute eigenvalues symmetric rankone modification diagonal matrix see 10 sec 86 one important issue design implicitly restarted arnoldi algorithms implementation ecient deflation techniques enhance convergence stability provide eective way compute multiple clustered eigenvalues let methods become eective alternative block methods also worth noting implicit restarting arnoldi also combined block methods deal computation selected eigenpairs singular triplets algorithm recently proposed baglama calvetti reichel 1 thus need consider implement deflation context implicitly restarted lbd scheme builds upon results presented 22334 23 employ locking decouples converged approximate singular values singular subspaces purging removes unwanted converged singular pairs section describe modification application orthogonal deflating transformation odt short scheme originally proposed sorensen 34 context implicitly restarted arnoldi eigenvalues show transformation applied directly bidiagonal matrix results implicitly restarted lbd deflation scheme enables efficient stable ecient locking approximate singular values converged relative accuracies may much larger machine epsilon odt based upon special unitary matrix say q built shown 34 satisfy qe suitably chosen unit norm vector construction q furthermore q form r upper triangular first column zero r may also written l lower triangular assuming q built following lemma shows apply odt case implicitly restarted lbd lemma 51 let l r approximate singular triplet c mn computed bidiagonal matrix b resulting k steps lbd let also unitary matrices produced odt vectors l r respectively updated matrix lower bidiagonal special form approximate singular value b also lower bidiagonal proof using notation following relations hold similarly following relations also hold qr r lr e prove upper hessenberg well lower trian gular therefore lower bidiagonal particular since q l therefore r rr since relations 19 matrix l l brr e 1 e 1 upper hessenberg l l rr upper triangular b lower bidiagonal thus b upper hessenberg furthermore r r since q l 15 therefore r r since r lr 20 since r l lr lower tri angular b would lower bidiagonal rankone update would modify lower triangular form therefore b also lower triangular worth noting observations concerning numerical stability odt discussed 34 carry present case particular note matrices q l qr built l r respectively therefore implicit properties exactly satisfied finite precision arithmetic therefore order bqr numerically upper hessenberg special care must taken g l l brr 2 would remain small practice write g l l brr 1 denotes first component l unfortunately small values l 1 factor could large rescaling strategy one described 34 must applied hand r r apply aforementioned rescaling strategy norm g r ris kept small therefore b would numerically lower triangular since e 1 z lr 2 small small z 6 refined singular vector approximations often case computing eigenvalues ritz vector may exhibit poor converge even though corresponding ritz value converged jia proposed 16 refined ritz vector strategy key approximate eigenvector means refined ritz vector designed minimize norm residual subspace involved first outline refinement process case lanczos follows naturally application lbd let us assume performed steps lanczos approximation eigenvalue l z corresponding refined ritz vector extracted krylov subspace k l v 1 moreover let corresponding lanczos factorization v l c mk basis krylov subspace l1l augmented tridiagonal matrix seek find approximation u minimizes norm residual therefore following relations hold min zc l av l z v l z zc l v l1 zc l v l1 zc l since norm residual minimized z right singular vector associated smallest singular value min singular value called refined residual jia reports angle refined ritz vector z exact eigenvector better corresponding angle standard ritz vector furthermore notice use rayleigh quotient attempt obtain improved eigenvalue since may accurate cf 36 sec 43 section 3 established implicitly restarted lanczos c cannot equivalent implicitly restarted lbd implicitly restarted lanczos remains equivalent implicitly restarted lbd however section 2 saw lbd decompositions equivalent lanczos decompositions either aa augmented matrix c starting vector special structure therefore compute refined residual vector using either aa c decomposition 7 suggests min current approximation smallest singular value refined residual refined singular vector retrieved computing smallest singular value right singular vector min 21 case augmented matrix c according lanczos decomposition 10 obtain refined residual refined singular vectors computing smallest singular value right singular vector matrix l 0 22 next decide refined residual compute one aa c since 21 involves tridiagonal matrix bb one might expect stability problems contrast 22 furthermore refined residual approximations left singular vector obtain approximations right singular vector would need use relation also work refined residual thus preferable use augmented matrix c also facilitates concurrent approximation left right singular vectors details see also discussion 36 sec 43 algorithm irlanb input matrix c mn k p eignum starting vector u 1 set output eignum smallest singular triplets 1 compute bases u l1 v l bidiagonal b l using lbd 2 repeat 3 shifts ritz 4 compute eigenvalues l 5 elseif shifts harmonic 6 compute eigenvalues 7 end 8 perform p implicit qr steps using bulgechasing b p largest eigenvalues shifts update lbd factorization av 9 compute approximation 10 compute refined residual 11 min converged 12 compute left right refined singular vectors 13 compute ql qr matrices using odt perform deflation 14 discard first column u l1 v l first row column b l 16 end 17 reorthogonalize u previous even converged basis vectors k length using lbd 19 convergence eignum singular values table irlanb method compute smallest singular triplets large sparse matrices 7 irlanb implicitly restarted harmonic lanczos bidiagonaliza tion based previous discussion next construct algorithm call irlanb depict table 3 computation smallest singular triplets large sparse matrices first proceed algorithmic description highlight important fine points implementation parameter maximum dimension bidiagonalization p number implicitly shifted qr steps applied b l parameter eignum determines number smallest singular values seek first step irlanb constructs lbd factorization length l purpose used function lanbpro larsens propack 20 see also 21 set matlab codes symmetric eigenvalue svd problems based lanczos lanczos bidiagonalization partial reorthogonalization described section 4 select shift ritz values prefer terms stability compute singular values b l rather eigenvalues b l b l instead select shift means harmonic ritz values could use eigenvalues 13 next step compute 2norm refined residual according either one strategies described section 6 convergence taken place proceed reorthogonalization steps line 17 repeat pro cess soon current approximation min satisfies convergence criterion compute corresponding left right refined singular vectors proceed deflation procedure compute orthogonal matrices using odt described section 5 purging accomplished discarding first column bases u k well first row column b k result obtain lbd factorization length k1 deflated factorization longer contains targeted singular values however subsequent restarts reorthogonalize updated vectors k previous vectors even purged ones since roundo may introduce components towards directions converged vectors note since computing small number singular triplets extra cost incurred low computational practice indicates limited reorthog onalization suces maintain orthogonality among basis vectors may degraded implicit restart 8 numerical experiments section present numerical experiments designed illustrate numerical computational performance irlanb codes written matlab 61 ran 866 mhz pentium iii equipped 1gb ram 512 kb cache memory running windows 2000 server also illustrate performance irlanb vs two recent methods matlab codes publicly available matrixfree permit solution large sparse problems computational environments methods irblsvdsirbleigs code due baglama calvetti reichel based implicitly restarted block lanczos 1 designed compute one eigenvalues andor singular values 2 jdqz code based jacobidavidson qz method due fokkema sleijpen van de vorst implemented matlab 7 3 note asked compute smallest singular values sparse matrices matlab 6 builtin function svds based compiled implementation arpack eigs applies shiftandinvert requires lu decomposition augmented matrix c therefore include svds experiments also worth noting 1 irblsvdsirbleigs compared methods selected based criteria similar ones described herein 81 ritz harmonic ritz shift strategies first set experiments designed illustrate convergence behavior ritz values visavis harmonic ritz values used shifts implicitly restarted lbd algorithm constructed sequence diagonal matrices r nn increasing clustering smallest singular values matlab notation test space dimension restart performed steps used random starting vector normalized unit length convergence tolerance tol1e8 figure 1 illustrates true relative error ritz shifts well harmonic ritz shifts evident clustering smallest singular values increases harmonic ritz values either converge significantly faster require fewer restarts backward error 2norm residual used ritz values produce results better forward relative error therefore case severe clustering smallest singular values use harmonic ritz values shown section 42 computed relatively small cost number restarts relative error ritz harmonic ritz number restarts relative error ritz harmonic ritz number restarts relative error ritz harmonic ritz number restarts relative error ritz harmonic ritz fig 1 experiments diagonal matrices 23 starting left top corner moving clockwise depict relative errors convergence tolerance set tol1e8 solid lines correspond standard ritz shifts dashed lines harmonic ritz shifts number restarts abs relative error 50 100 150 200 250 number restarts abs relative error fig 2 experiments diagonal matrices 24 increasing condition numbers 82 experiments illconditioned matrices next investigate behavior irlanb harmonic ritz values illconditioned matrices constructed sequence diagonal matrices 2 available httphypatiamathuriedujbaglama 3 available httpwwwmathruunlpeoplesleijpenjd softwarejdqzhtml number restarts residual number restarts residual fig 3 experiments irlanb grcar1000 convergence tolerance tol1e6 convergence tolerance tol1e10 r nn increasing condition numbers used starting vector parameters previous examples illustrates absolute value relative error achieved irlanb cases irlanb computed successfully smallest singular value particular case modest condition numbers left plot observed smooth convergence behavior however condition numbers matrices deteriorates behavior smooth error behavior vanishes especially towards end restarts still irlanb converges relative error order 10 5 worst case 83 computing singular values next illustrate ability irlanb quickly detect additional singular values lie near smallest one latter converged continue using irlanb harmonic ritz values l fig 4 experiments irlanb dw 2048 left convergence tolerance tol1e8 right convergence tolerance tol1e12 first experiment matrix grcar dimension included matlabs function gallery target compute 10 smallest singular values length lbd used implicit shifts per step figure 3 illustrates norms residual iteration dashed lines represent convergence criterion set equal normestatol normesta estimation norm approximate 2 b l 2 computed first restart conducted two experiments first case top figure 3 used convergence tolerance equal tol1e6 second case used tol1e10 plots right figure 3 detailed versions plots left immediately notice irlanb contine computing singular values subsequent restarts behavior even pronounced employ stricter convergence tolerance tol1e10 notice smallest singular value approximated restart number 98 subsequent 9 restarts remaining singular values approximated observe ratio among largest smallest singular values computed n9 obviously deflation helped deal eectively level clustering next experiment matrix dw 2048 matrix market 4 10 smallest singular values clustered previous case experimented convergence tolerances tol1e8 tol1e12 figure 4 illustrates results experiment grcar observe irlanb rapidly approximates remaining singular values convergence smallest one achieved decreased clustering smallest singular values however convergence fast previous case matrix irlanb irbleigsirblsvds jdqz jpwh 991 49 149 132 343 238 1365 well 1850 222 268 317 391 failed table runtimes seconds matrices jwph 991 well 1850 seconds order compute one two smallest singular triplets 84 comparisons related methods section provide numerical experiments illustrate behavior irlanb visavis methods selected namely irbleigsirlbsvds jdqz algorithms singular values obtained via augmented matrix c first two examples two matrices namely jwph 991 obtained matrix market used algorithms consideration compute one well two smallest singular triplets convergence tolerance set tol 1e6 minimum search space dimension k irlanb jmin jdqz blsz irbleigsirblsvds set 3 maximum search space dimensions used set kpjmaxnblsblsz15 cf help pages irbleigsirblsvds jdqz detailed explanation regarding input parameters table 4 illustrates corresponding runtimes indicates irlanb competes well modern available methods last experiment originates computation pseudospectra large matrices since pseudospectrum matrix defined locus points z complex plane satisfy inequality min zi becomes critical importance use fast algorithms estimate smallest singular value see 37 comprehensive survey experiment family matrices studied 39 originate specific bidiagonal ones add random sparse entries matlab notation matrices defined n size matrix specifically seek min dimensions 200000 parameters irlanb jdqz minimum dimension search space kjmin15 maximum dimension search space kpjmax30 convergence tolerance set tol1e10 corresponding parameters irbleigsirblsvds blsz3 nbls10 tol1e6 maximum number restarts set maxit1000 table 5 illustrates runtimes convergence results 100000 03719 163 03719 183 03719 429 200000 03737 332 03737 376 50000 12373e4 182 12373e4 243 18391e1 2270 100000 24861e4 474 24861e4 561 18754 11000 150000 59600e5 705 59600e5 850 200000 62756e5 943 62756e5 1210 table run times seconds approximations min family random matrices 25 star indicates method ran memory 1 gbyte observe shift z 35 three methods return similar results 4 digits however irlanb significantly faster furthermore observe jdqz ran memory shifts finally note min computed jdqz shift dierent result two methods agreement 9 digits 9 conclusions paper described design irlanb implicitly restarted lanczos bidiagonalization algorithm computation smallest singular values matrix investigated ritz well harmonic ritz values shifts implicit qr steps demonstrated superiority latter case clustered smallest singular values showed e ciently compute harmonic ritz values small additional cost compared ritz values furthermore demonstrated irlanb harmonic ritz values successfully compute smallest singular value matrices large condition numbers proved orthogonal deflation transformation applied directly lanczos bidiagonalization numerical experiments demonstrate deflation scheme eciently compute clustered singular values finally demonstrated application refined residuals vectors case lanczos bidiagonalization computation smallest singular values dicult computationally challenging problem believe framework prove helpful future investigations well practical computations acknowledgments first two authors wish thank bodossaki foundation financial support first version work developed context first authors diploma thesis 18 presented international workshop parallel matrix algorithms applications pmaa02 held neuchatel thank errikos kontoghiorghes hospitality stay neuchatel would also like thank valeria simoncini bringing attention 21 propack henk van der vorst helpful discussions hercma01 athens suggestion consider using harmonic ritz values gerard sleijpen michiel hochstenbach useful comments concerning stability issues andreas stathopoulos many insightful discussions regarding aspects work irlanb code available authors upon request r irbl implicitly restarted block lanczos method largescale hermitian eigenproblems templates solution algebraic eigenvalue problems practical guide large scale singular value decomposition computing field values pseudospectra using lanczos method continuation algorithm computing distance uncontrollability calculating singular values pseudoinverse matrix eigenvalue comptutation 20th century matrix computations parallel computation spectral portrait large matrices davidson type methods test matrix toolbox matlab version 30 jacobidavidson type svd method harmonic refined extraction methods singular value problem computational methods large eigenvalue problems refined iterative algorithms based arnoldis process large unsymmetric eigenproblems implicitly restarted refined bidiagonalization lanczos method computing partial singular value decomposition parallel iterative methods computation smallest singular values large sparse matrices applications inexact inverse iteration large sparse eigenvalue problems propack software package symmetric eigenvalue problem singular value problems lanczos lanczos bidiagonalization partial reorthogonalization lanczos bidiagonalization partial reorthogonalization arpack users guide solution largescale eigenvalue problems implicitly restarted arnoldi methods deflation techniques implicitly restarted arnoldi iteration parallel computation pseudospectrum large matrices computation eigenvalues eigenvectors large sparse matrices approximate solutions eigenvalue bounds krylov subspaces symmetric eigenvalue problem rational krylov algorithms nonsymmetric eigenvalue problems ii numerical methods large eigenvalue problems trace minimization method symmetric generalized eigenvalue problem lanczos algorithm partial reorthogonalization jacobidavidson iteration method linear eigenvalue problems deflation implicitly restarted arnoldi methods implicit application polynomial filters kstep arnoldi method matrix algorithms computation pseudospectra tr implicit application polynomial filters kstep arnoldi method algorithm computing distance uncontrollability deflation techniques implicitly restarted arnoldi iteration matrix computations 3rd ed symmetric eigenvalue problem jacobidavidson style qr qz algorithms reduction matrix pencils jacobidavidson iteration method linear eigenvalue problems implicitly restarted gmres arnoldi methods nonsymmetric systems equations lsqr algorithm sparse linear equations sparse least squares templates solution algebraic eigenvalue problems lowrank matrix approximation using lanczos bidiagonalization process applications eigenvalue computation 20th century trace minimization method symmetric generalized eigenvalue problem matrix algorithms jacobidavidson type svd method largescale computation pseudospectra using arpack eigs methods large scale total least squares problems parallel computation pseudospectra large sparse matrices lanczos algorithms large symmetric eigenvalue computations vol 1 implicitly restarted refined bidiagonalization lanczos method computing partial singular value decomposition ctr c bekas e kokiopoulou e gallopoulos design distributed matlabbased environment computing pseudospectra future generation computer systems v21 n6 p930941 june 2005