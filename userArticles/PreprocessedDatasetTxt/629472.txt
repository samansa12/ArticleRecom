scalable stability detection using logical hypercube abstractthis paper proposes use logical hypercube structure detecting message stability distributed systems particular stability detection protocol uses superimposed logical structure presented scalability compared known stability detection protocols main benefits logical hypercube approach scalability faulttolerance refraining overloading single node link system benefits become evident analytical comparison simulations another important feature logical hypercube approach performance protocol general sensitive topology underlying physical network b introduction reliable multicast recognized key feature many distributed systems allows reliable dissemination message large number recipients conse quently reliable multicast supported many middlewares group communication isis 5 horus 35 transis 10 ensemble 1 relacs 3 phoenix 23 totem 26 name protocols like rmtp 28 srm 12 near future standards like corba 27 reliable multicast typically involves storing copies message either several dedicated servers typically done group communication toolkits nodes system order limit size buffers systems middlewares supporting reliable multicast employ stability detection protocol systems middlewares must detect message received recipients words become stable point discarded stability detection protocols must balance tradeoff fast detect message stable become stable overhead imposed protocol one hand faster protocol detect stability smaller buffers need hand stability protocol generates many messages overhead imposed system prohibitively high hence performance scalability stability detection protocol affects overall scalability reliable multicast paper proposes structure stability detection protocols superimposing logical hypercube 17 21 system protocol messages generated stability detection protocol travel along logical hypercube connections regardless underlying physical network topology claim logical hypercube approach several appealing properties n refers number nodes system scalability node needs communicate logn nodes performance logical hypercube structure guarantees number hops stability information need travel logn faulttolerance hypercubes offer logn node distinct paths every two nodes therefore sustain logn failures regularity hypercubes regular structure protocol every node plays exactly role thus node loaded others also code regularity tends decrease potential software bugs protocol implementation paper explore performance scalability proposed protocol compare known stability detection protocols namely fully distributed protocol coordinator based protocol treebased protocol 13 15 comparison done analytically simulations results show logical hypercube based protocol compares favorably protocols investigated confirm assumptions use logical hypercubes mentioned simulations discovered another interesting property shared logical hypercube based protocols tree based protocols measurements carried randomly generated network topologies attempt made match underlying physical topology logical flow protocol yet tree based protocol hypercube based protocol appear insensitive network topology giving consistent results regardless topology believe also important aspect hypercube based protocols tree based protocols since practical distributed systems underlying network topology rarely known might change either system network changes evolve 11 related work many group communication toolkits example isis 5 horus 35 ensemble 16 employ fully distributed protocol along lines fulldist protocol present section 2 discuss later section 3 protocol scalable guo et al investigated scalability variety stability detection protocols 13 14 15 include example fully distributed protocol fulldist coordinator based protocol refer coord tree based protocol refer work coord discussed detail section 2 guos work also done primarily using simulations however 15 assumed physical topology network matches logical structure protocol 13 work make assumption difference important since many distributed applications control underlying network topology access routers thus investigating behavior protocol correspondence actual network topology great interest previous works unreliable reliable multicast suggested use logical ring form improving performance running shared bus communication medium works include totem project 26 work cristian mishra 9 1 rings useful avoiding collisions offer moderate scalability since node communicates two additional nodes however scalability rings limited since information must traverse entire ring order disseminate one node every node 13 hypercubes originally proposed efficient interconnect massively parallel processors mpp 17 21 great body research done solving parallel problems hypercubes described 17 21 particular much work done area routing onetoall alltoall communication gossiping hypercubes 4 7 8 11 19 31 hypercast protocol maintains logical hypercube structure among group mem bers heartbeats application messages sent along arcs logical hypercube 22 hypercast work carried independently concurrently conference version paper address stability issues also hy percast protocol nodes incomplete hypercube smaller degree others reduces faulttolerance example hypercube 2 n 1 nodes one nodes single neighbor according hypercast contrast construction guarantees even incomplete hypercubes degree node number node independent paths pair nodes roughly logn recently several bodies work generating approximation hy fact logical ring used communication shared access medium ieee 8024 standard 33 known also token bus however ieee 8024 guarantee reliable multicast use logical ring done improve throughput avoiding collisions percube topologies fully distributed manner providing efficient routing lookup services overlay networks 29 32 36 systems used example infrastructure large scale publishsubscribe systems stability detection protocols discussed section 1 stability detection protocols aim detect messages become stable received intended recipients copies discarded section describe three existing stability detection protocols later compare logical hypercube based protocol terms performance scalability fault tolerance cases assume fixed set n nodes known advance numbered 0 n gamma 1 also assume communication channels preserve fifo ordering underlying mechanism guaranteeing reliable pointtopoint message delivery 2 order present stability detection protocols introduce following notation denote arraymin elementwise array minimum n given arrays given n arrays length k r implies protocols proceed rounds executed sequentially round protocol nodes attempt establish stability messages received prior round although messages become stable round might detected round well round ends next round start delta time units passed delta integer adjusted system administrator optimal value delta depends message sending rate buffer size node goal stability detection protocol release stable messages buffers buffer overflow happens 13 become evident shortly interested latency round ready present protocols 2 note reliable pointtopoint message delivery guarantee reliable multicast since allows situation node fails messages delivered processes 21 coord protocol coord coordinator based protocol node maintains nelement array r whose jth entry r j sequence number last message received node node j one nodes serves coordinator coordinator multicasts start message node receives start message replies pointtopoint ack message coordinator ack message node contains array r receiving ack messages nodes coordinator constructs minimum array using function arraymin described following array contains sequence number last stable message sent node coordinator multicasts info message containing array pseudo code given figure 1 note pseudo code line 1 line 8 start protocol round coordinator noncoordinator nodes respectively 22 fulldist protocol fulldist fully distributed protocol node keeps stability matrix size n theta n k j sequence number last message knows received node k node j j sequence number last message received node node j minimum jth column across nodes represents sequence number last message sent node j received every node beginning round first node 3 multicasts info message contains first row matrix 0 node receives info message replies multicast info message info message contains row matrix every node replaces kth row matrix row received info message node k pseudo code presented figure 2 note pseudo code line 1 line 3 start protocol round node 0 nodes respectively 3 significance choice first node first node starts protocol chosen deterministic way example according node ids node maintains following arrays sequence number array stability array arraymin elementwise minimum input arrays initialization node 1 multicaststart 2 wait receiveackr nodes 3 4 multicastinfos j 5 label messages received every node k sequence number p j k stable 7 goto step 8 wait receivestart coordinator 9 send ackr coordinator 10 wait receiveinfos coordinator 12 label messages received every node k sequence number p k stable 13 goto step figure 1 coord protocol minr minimum value array r jth row matrix jth column matrix node maintains following sequence number matrix receive number info messages node received current round initialization node receive 0 1 waitdelta 2 multicastinforowm 0 0 3 upon receiving infor node 0 4 5 receive k receive k 7 done every node k 8 upon receiving infor node 10 receive k receive k received 12 label messages received every node j sequence number p mincolm k j stable 13 receive k 0 14 goto step 15 endif figure 2 fulldist protocol 23 coord protocol several treestructured protocols introduced 15 work take coord representative tree structured protocols since appeared perform best 15 coord logical tree superimposed network node maintains nelement array r whose jth entry r j sequence number last message received node node j root starts protocol multicasting start message leaves send ack messages parents containing array r node receives ack message one children calculates minimum array received array r stores result array receiving ack messages children tree internal node sends parent root stores array multicasts info message containing array node receives info message containing array sets array contains sequence number last stable message sent node see figure 3 pseudo code protocol note pseudo code line 1 line 2 start protocol round 3 logical hypercube based stability detection 31 hypercubes mcube undirected graph consisting 2 vertices labeled 0 edge two vertices binary representation labels differs one bit position precisely let hm denote mdimensional hypercube consists nodes node labeled mbit string corresponds dimension k two nodes p label label connected index j x j example 4dimensional hypercube h 4 given figure 4 mcube constructed recursively following way 1 1cube simply 2 nodes connected edge convention label nodes 0 1 protocol node notation children indexes node children tree number children node tree parent id node parent tree arraymin elementwise minimum input arrays node maintains following variables sequence number array stability array array holds minimum far receive number ack messages node received current round initialization receive 0 1 multicaststart 2 upon receiving start root 3 sendackr parent 4 done internal node root 5 upon receiving ackr j 7 receive receive 8 receive 14 label messages received every node k sequence number p k stable 15 receive 0 17 goto step 19 endif 20 done every nonroot node 21 upon receiving infos 23 label messages received every node k sequence number p k stable 24 receive 0 25 goto step figure 3 coord protocol figure 4 example 4dimensional hypercube h 4 2 mcube made two gamma 1cubes b labels preceded 0 labels b preceded 1 add edge node node b differs p leftmost bit hypercube powerful interconnection topology due many attractive features pointed 17 21 30 features include regularity small diameter logn small fanoutfanin degree logn multiple logn nodedisjoint paths every two nodes 32 cubefulldist protocol cubefulldist fully distributed protocol sense every node periodically multicasts information message stability logical neighbors hypercube cubefulldist employs gossip style mechanism similar 14 20 disseminate stability information round protocol node communicates logical neighbors learns messages received node beginning round order save messages divide round multiple iterations iteration r node sends stability information logical neighbors waits stability message one end iteration node checks whether learned messages received every node beginning round node sends current stability information neighbors proceed next round otherwise node loops next iteration precise pseudo code cubefulldist given figure 5 node maintains following variables ffl sequence number array r whose jth element r j sequence number last fifo message received node node j ffl stability array corresponding stability information end round ffl bitmap array g recording nodes learned stability information round ffl array containing minimum sequence numbers heard far protocol round ffl integer r holds iteration number redundant messages belonging previous iterations discarded protocol round starts step 1 step 1 initialized r node multicasts hypercube neighbors stability message containing r g step 2 node receives messages neighbors upon receiving message bitmap g sequence number array node sets bitmap array g bitwise arrays g g sets arraymin g contains 1s indicates node heard everyone round thus point view round case node multicasts neighbors last stability message current round starts new round otherwise round finished yet received stability messages neighbors iteration multicasts stability message neighbors starts another iteration step 2 note due fifo since starting new iteration node sends last stability information known neighbors node never receive messages r r precisely node receives messages neighbors time one neighbors j increases iteration number r j first multicast message 1 containing g j neighbors g j contains 1s node receives 1 increases r thus node increases r time j increases r j increases r nodes j iteration number messages node j node delivered 1 increased iteration number node receives message lower iteration number redundant message probably neighbor advanced current iteration time message sent hence message ignored 33 incomplete hypercubes hypercubes defined exactly 2 nodes given however practical systems may employ arbitrary number participants flexible version hypercube topol ogy called incomplete hypercube 18 eliminates restriction node numbers building logical connections incomplete hypercube strive keep properties make complete hypercubes attractive words goals designing incomplete hypercubes minimize system diameter performance b maximize number parallel shortest paths two nodes order fault tolerant c restrict number logical connections node limit logn protocol remains scalable denote incomplete hypercube n dimension total number nodes respectively achieve goals useful note incomplete hypercube comprises multiple complete ones connection node p h node q h k k addresses p q differ bit k example consider 14 4 given figure 6 example 3 complete cubes h 3 consisting nodes consisting nodes 10xx h 1 consisting nodes 110x aim compensate missing links incomplete hypercube n respect complete hypercube hm preserving goals described done adding one edge pairs nodes p q n whose hamming distance 2 connected hm node missing n nodes chosen follows missing node z g z set nodes z supposed connected formally denote hm n n set nodes hm appear n node z belongs hm ni n z defined g z fwjw 2 n hz 1g protocol node notation neighbors indexes node neighbors hypercube number neighbors node hypercube arraymin elementwise minimum input arrays maximum input arrays node maintains following variables array sequence number array stability array end round sequence number array round number current round receive number stability messages node received current iteration initialization receive 0 every node 1 multicaststabilityg r neighbors 2 upon receiving stabilitygm r node j 3 5 receive receive 1 7 g contains 1s start new round 8 multicaststabilityg r neighbors 11 j 6 g j 0 12 receive 0 13 label messages received node k sequence number p k stable 14 waitdelta 15 goto step 17 receive start another iteration neighbors 19 receive 0 20 endif 22 done figure 5 cubefulldist protocol figure incomplete hypercube 14 nodes fulldist cubefulldist number protocol iterations ologn o1 o1 ologn number messages per node per round o1 coord o1 ologn total number message 2 robustness failures yes yes code regularity yes yes figure 7 analytical comparison protocols g z empty one member connection added sg z obtained lexicographically sorting g z according node ids jsg z j odd first node sg z discarded sg z partitioned two groups g 1 z g 2 z g 1 z contains first half ids sg z g 2 z contains second half ids sg z connection added ith node g 1 z ith node g 2 z example 7 node 7 missing respect h 3 thus g connection added nodes 5 6 note due way label nodes node hmgammak connected hm k nodes hm n n also add one connection missing one thus node final degree therefore scalability fault tolerant properties preserved system diameter n adding links increase diameter system hence described incomplete hypercube matches goals 34 analytical comparison comparison four stability detection protocols represented figure 7 number protocol iterations serves indication latency detecting stability case coord information propagates tree according levels nodes since n nodes count logn far scalability concerned coord tree based protocol appears scalable followed closely cubefulldist problem tree protocols fault tolerant one node fails nodes logical branch become disconnected case tree needs rebuilt immediately current round protocol lost cubefulldist uses messages coord message redundancy makes cube fulldist fault tolerant coord since cubefulldist system logically partitioned logn neighbors node fail coord fulldist limited scalability coord coordinator receives messages nodes infeasible n large fulldist total number messages 2 contrast cubefulldist node receives ologn messages coord node receives messages tree degree looking number iterations theoretically cubefulldist slower coord fulldist however simulations show actually cubefulldist much faster reason coord coordinator bottleneck protocol fulldist total message number high node loaded loaded nodes create long message queues slow overall performance making fulldist coord much slower cubefulldist coord fulldist cubefulldist fault tolerant two protocols finally fulldist cubefulldist regular structure code executed nodes property tends yield simpler less error prone code hand coord advantage might easier embed tree topology typical physical network topologies embed hypercube topology 35 weakening network assumptions discuss possibility weakening network assumptions four stability detection protocols eliminate reliable delivery requirement note general stability nondecreasing property since messages sequentially increasing sequence numbers generally possible ensure correctness stability detection protocol periodically sending recent local information however reduce network load protocols advance rounds order keep efficiency may require adding protocol round number messages specifically code coord protocol figure 1 round number must attached messages line 1 repeated periodically coordinator receives ack nodes line 4 repeated periodically coordinator receives new type acknowledgment message ackinfo noncoordinator members lines 12 13 add sending ackinfo message co ordinator similar modifications also required code coord protocol figure 3 round number also attached messages code fulldist protocol figure 2 additionally node needs multicast info message periodically receives info messages round nodes also node already moved round r receives info message node round r r message stale node round r ignore message however node round r receives info message round r treat message round number r process message finally cubefulldist protocol figure 4 already includes round numbers thus work correctly simply multicasting messages periodically similar fashion protocols however efficiency reasons protocol also uses internal iteration advance node heard logical neighbors current iteration make sure indeed case advisable add iteration number stability messages protocol similarly receive increased message received first time node current iteration order eliminate requirement fifo delivery stability detection protocols possible remember last message received node check recent message carries information least recent previous one message handled according protocols otherwise ignored 4 experimental performance 41 simulation model use ns 25 simulator explore behavior stability detection protocols described sections 2 3 measured following indices goal checking effect number nodes indices four protocols node time beginning protocol round node recognizes current round protocol finished time detecting message stability function rtt frequency rounds stability detection protocol 1delta reliable multicast protocol deliver message receivers within seconds stability detection protocol triggered every delta seconds detect messages stability within rtt seconds maximum time detect messages stability seconds therefore buffer size unstable messages proportional time takes detect message stability frequency stability detection messages sent total number messages total number messages sent system message counted sent total number messages good indication processors load hop count total number hops messages pass message counted hop passes way source destination index shows overall protocol message overhead links system network load measure average network load average number messages links network given time maximum queue size maximum number messages waiting sent links system note average network load looks number messages given moment hop count interested cumulative number messages links full run protocol topology sensitivity measures difference best result worst result protocols indices described since logical flow protocol match physical underlying topology indicates sensitive protocol performance actual network topology lastly also measured effect node failures indices cube fulldist protocol note coord coord fault tolerant meaningful look effects failures also performance fulldist reported poor decide show results failures cubefulldist stability detection protocols tested several randomly generated network topologies use random network generator gtitm 6 build random network topologies edge probability varying 001 004 protocol run 6 times run different randomly generated topology used results presented average 6 runs links simulations chosen duplex 100mbps direction uniformly distributed delay 0 1 ms assume total number nodes varied 10 1900 groups smaller 50 nodes nodes sending messages larger groups however number senders fixed 50 sequence number size assumed 4 bytes thus size array stability information carried stability ack info messages 200 bytes also message header size set 32 bytes large enough transport protocols 2 34 tree degree coord set logn node logn children node 0 chosen coordinator coord root tree coord cubefulldist logical hypercube built according node ids binary representation since network generated randomly fitness logical structure network random well cubefulldist number nodes power two construction incomplete hypercubes described section 33 used first member rtt number nodes ms cubefulldist coord fulldist scoord 180010305070last member rtt ms number nodes figure 8 rtt function system size 42 simulation results 421 round trip time rtt fastest slowest nodes detecting stability reported figure 8 coord cubefulldist rtt remains almost flat number nodes increases protocols nodes reasonably loaded number messages sent received node small also seen construction logical incomplete hypercubes maintains scalability goals respect complete hy percubes since graphs major jitters near system sizes power two note data points set similar rtt values 100 128 200 256 300 500 512 1000 1024 rtt coord increases linearly n since coordinator load proportional n causes long message queue coordinator slows overall performance rtt fulldist increases dramatically number nodes increases fact timing fulldist bad could check beyond 400 nodes reason total load imposed fulldist network high node fulldist sends receives messages total 2 messages causes long message queues nodes heavy utilization links nodes system load caused fulldist seen figures 9 10 11 discuss graphs later interesting notice coord coord hardly difference first node last node rtt coordinatorroot informs everyone finishes protocol round fulldist hand shows significant difference first node last node rtt system load high 150 nodes rtt first last node 16ms 19ms respectively 400 nodes rtt becomes 46ms 82ms respectively system load low 150 nodes difference rtt values come distributed nature protocol system load high difference comes fact system overloaded 2 messages cubefulldist slight difference first node last node rtt difference caused distributed nature protocol takes time information propagate system 422 network load average network load maximum queue size measured reported figures 9 10 respectively given system size network load recorded every 1 ms averaged time round fulldist largest queue size fulldist node sends receives messages total 2 messages results high network load large message queues coord maximum queue size grows linearly system size coordinator receives messages average network load high though fact even somewhat better cubefulldist since total number messages sent system cubefulldist coord almost maximum queue length maximum queue size coord somewhat better cubefulldist since coord uses fewer messages cubefulldist average queue length maximum queue length load number nodes number messages cubefulldist coord fulldist scoord network load without full dist number nodes number messages cubefulldist coord scoord figure 9 average network load function system size right graph zooms results coord coord cubefulldist notice difference scale number nodes number messages cubefulldist coord fulldist scoord max queue length number nodes number messages cubefulldist scoord figure 10 maximum queue size function system size right graph zooms results coord cubefulldist notice difference scale number nodes hop count hop count cubefulldist coord fulldist scoord message count number nodes message count cubefulldist coord fulldist scoord onlognlogn figure 11 hop count number messages function system size notice difference scale similar nodes send receive number messages coord hand average queue length low node sends receives logn messages 423 hop count message count total hop count message count reported figure 11 protocols theoretical analysis message count see section 34 reflected simulation graphs fulldist enormous message count 2 reflected graphs coord coord linear message count coord hop count less coord protocol messages sent node parent tree whereas coord messages sent root node directly difficult embed logical tree arbitrary physical topology match logical topology physical topology much possible therefore actual number hops could even lower simulation result first member rtt difference best worst result number nodes difference cubefulldist coord fulldist scoord max queue difference best worst result number nodes difference cubefulldist coord fulldist scoord figure 12 difference worst best result function system size cubefulldist uses log 2 n messages reflected message count graph cubefulldist hop count relatively better message count protocol messages sent hypercube neighbors note coord hop count message count better cubefulldist cubefulldist faster provides faster rtt reason cubefulldist load distributed network coord messages must traverse root node 424 protocol sensitivity difference best worst simulation result first rtt max queue reported figure 12 performance coord much affected underlining network topology randomly generated network coordinator many connections coord achieves quite good performance hand coordinator assigned connections connections become bottlenecks performance poor protocols bottlenecks sensitive network topology first member rtt cubefulldist number nodes ms failures failures 3 failures 4 failures 5 failures number nodes queue length failures failures 3 failures 4 failures 5 failures figure 13 effects node failures cubefulldist performance 425 effect faults cubefulldist performance effects node faults cubefulldist performance seen figures 13 14 test protocol 05 node failures faulty nodes chosen randomly among node 0s neighbors mentioned cubefulldist fault tolerant performance hardly affected small number failures particular note choice faulty nodes worst case scenario since faulty nodes neighbors node rather arbitrarily chosen 5 discussion future work study indicates superimposing logical hypercube structure way obtaining scalability faulttolerance especially context reliable multicast promising direction 24 also study applicability logical hypercubes scalable failure detection causal ordering applicability logical hypercubes aspects reliable multicast group communication still open question work assumed general networks logical hypercube structure number nodes hop count failures failures 3 failures 4 failures 5 failures figure 14 effects node failures cubefulldist performance well structures superimposed random manner nevertheless trying map logical hypercube structure physical network topology smart way might improve performance protocol work already done matching hypercubes topologies mainly trees meshes 21 although looking problem general context internet interesting research direction finally none stability detection protocols described assume anything reliable multicast protocol might use conjunction optimizations example piggybacking stability messages protocol messages might possible tailoring stability detection protocol multicast protocol acknowledgements would like thank anonymous reviewers helpful comments r ensemble home page routing permutations 21 routing requests hypercube exploiting virtual synchrony distributed systems optimal broadcasting faulty hypercubes fast gossiping short unreliable messages pinwheel asynchronous atomic broadcast protocols transis approach high availability cluster communi cation optimal algorithms dissemination information generalized communication networks reliable multicast framework lightweight sessions application level framing scalable message stability detection protocols message stability detection reliable multicast hierarchical message stability tracing protocols ensemble system introduction parallel algorithms incomplete hypercubes fast gossiping hypercube providing availability using lazy replication introduction parallel algorithms architectures protocol maintaining multicast group members logical hypercube topology toolkit building faulttolerant distributed application large scale scalable multicast logical hypercube faulttolerant multicast group communication system reliable multicast transport protocol rmtp accessing nearby copies replicated objects distributed environment topological properties hypercube efficient alltoall communication patterns hypercube mesh topolo gies scalable peertopeer lookup service internet applications computer networks masking overhead protocol layering flexible group communication system infrastructure faulttolerant widearea location routing tr