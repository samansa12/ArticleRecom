estimation lower bounds scheduling algorithms highlevel synthesis produce efficient design highlevel synthesis system able analyze variety costperformance tradeoffs system use lowerbound performance estimated methods identify puune inferior designs without producint complete designs present lowerbound performance estimate method faster existing methods also produces better lower bounds cases lower bound produced algorithm tightscheduling algorithms branchandbound need fast effective lowerbound estimate methods often large number partially scheduled dataflow graphs reduce search space extend method efficiently estimate completion time partial schedules problem addressed existing methods literature lowerbound estimate shown effective reducing size search space used branchandbound scheduling algorithmour methods handle multicycle operations pipelined functional units chaining operations also present extension handle conditional branches salient feature extended method applicability speculative execution well cselect implementation conditional branches b introduction highlevel synthesis takes abstract behavioral specification digital system finds registertransfer level structure realizes given behavior usually many different structures used realize given behavior one main goals synthesis system find structure best meets constraints limitations number functional units registers power minimizing parameters like number time steps operation scheduling datapath construction core highlevel synthesis obtaining efficient designs terms area speed scheduling datapath operations best time steps task whose importance recognized many systems 12 14 15 16 since scheduling intractable problem highlevel synthesis systems use heuristics find good schedule absence good lowerbound estimates difficult evaluate performance heuristics synthesis system produce efficient designs capability analyze different costperformance tradeoffs scheduler explore design space variety resource constraints instead producing schedules every resource constraint scheduler use estimation identify prune inferior designs furthermore estimation lower bounds used evaluate heuristic solution estimation tool useful much faster actual scheduler lower bounds produces tight possible proposed efficient estimation technique lowerbound performance tested estimation method number benchmarks compared results known methods literature 17 20 method faster methods 17 20 method produces better lower bounds many cases cases lower bound tight many scheduling algorithms branch bound methods 3 multischedule methods 2 search design space constructively scheduling operations one step time search process schedules subset operations dfg produced evaluated check lead complete schedule target upperbound performance scheduling methods need method estimate lower bounds completion time partial schedules since number partial schedules generally high design space search process estimation faster estimation entire dfg paper proposed fast effective lowerbound estimation method partially scheduled dfgs extension method lowerbound estimation entire dfgs approach defined useful data structures need computed given dfg exploration using data structures method compute lower bound partial schedule ok time k number ready unfinished operations defined later paper partial schedule methods 5 17 20 21 originally proposed estimation entire dfg address estimation partial schedules slow used partial schedules example methods 17 20 used partial schedules take oc 2 respectively compute lower bound partial schedule n number operations scheduled c critical path length implemented method method 17 separately branch bound scheduling algorithm tested number benchmarks results show method least 20 times faster equally effective reducing size search space method used scheduling algorithm schedules one step time used method optimal dynamic programming scheduling algorithm 1 developed drastically reduced size search space could obtain optimal schedules short computational times methods handle multicycle operations pipelined functional units chaining operations extended methods handle conditional branches extended method applicable speculative execution well cselect execution operations conditional branches knowledge estimation method literature support speculative execution next section brief overview previous works lower bound estimation presented section 3 model terminology defined method estimation lower bounds entire dfg presented section 4 computational complexity method compared sharmas method 20 analyzed section lowerbound estimation method partial schedules presented section 5 extensions handle conditional branches chaining explained section 6 experimental results presented section 7 conclusions section 8 previous work several methods proposed literature lowerbound estimation cost well performance jain et al 7 proposed mathematical model predicting areadelay curve lowerbound method fast trivial consider precedence constraints technique proposed fernandez bussell 4 computes minimum number operations must scheduled subinterval time steps derives maximum increase total execution time intervals enough processors accommodate operations interval method considers homogeneous resources applied multiprocessor schedules method extended highlevel synthesis sharma et al 20 compute increase length interval due concentration type operations interval also address lower bounds area cost including interconnect cost method computational complexity onc 2 n number nodes dfg c critical path length method proposed ohm et al 10 estimates lower bounds functional units well registers technique functional unit estimation refinement basic technique 20 applicable lowerbound performance estimation complexity method nc 2 n e e number edges dfg method proposed 17 uses relaxation technique ilp formulation scheduling problem lowerbound estimation performance resource constraints computational complexity number time steps produced lower bounds good 20 many benchmarks method 21 similar 17 relaxes precedence constraints solves relaxed problem using slack driven list scheduling algorithm hu et al 5 proposed method estimate lower bounds iteration time functional unit cost functional pipelined dfgs complexity method onck 2 k initiation latency recursive technique proposed 8 lowerbound performance estimation complexity complexity method lowerbound performance estimation entire dfgs complexity 3 model definitions dfg data flow graph e directed acyclic graph representation behavioral description set nodes v represents set operations set edges e denotes set dependencies precedence constraints operations two operations finished operation start node x called predecessor successor x directed path x g using arcs e operation without predecessors called input operation operation without successors called output operation associated operation x v single type indicating functional unit type used execute operation resource constraints given set ordered tuples dt delay number time steps clock cycles operation type takes complete nt number available resources type resource type pipelined one instance resource type assigned one operation overlapping fashion latency overlap denoted ffi clearly let x denote delay operation x equal delay type resource executes x soon possible earliest timestep v scheduled start execution assuming unlimited resources msat v minimum steps operation minimum number time steps schedule g going take completion operation v assuming unlimited resources critical path length minimum number timesteps schedule g going take assuming unlimited resources computed maximum taken output operations v 4 lowerbound estimation performance intuitive idea behind lowerbound estimation follows resource type group operations type three nonoverlapping intervals compute lowerbound sum lengths intervals final lower bound maximum among resource types possible groupings operations type let p number operations type dfg oe operations type asap value less equal least p operations cannot scheduled first time steps similarly oe j type operations msat value less j least p operations cannot paper resources refer singlefunction functional units scheduled execute last j time steps thus least p operations cannot either scheduled first time steps scheduled execute last j steps schedule three intervals considered first steps interval 1 last steps interval 3 interval two interval 2 overlap two lengths intervals 1 3 j respectively length 2 depends minimum number type operations interval well number available resources type number operations 2 depends asap msat values operations determined data dependencies thus lowerbound estimation takes account precedence constraints resource constraints note takes least time steps operations 2 start execution least j steps last operation finished execution lengths 1 3 independent set operations scheduled intervals thus purposes lowerbound estimation three intervals nonoverlapping denote minimum number type operations interval 2 qi j minimum length 2 due type operations hi j explained qi j value hi j computed qi j follows operations scheduled dkre stages type resources pipelined stage takes dt time steps dt delay type resource pipelined latency ffi stage except last takes ffi steps last stage either case takes dt steps hence pipelined r e dt otherwise lower bound completion time schedule given dfg oe 1 oe 2 oe 3 oe 4 oe 5 oe 6 ordered pair next node shows asap msat values figure 1 example lowerbound estimation entire dfg given max tijc fhi c critical path length proof discussion implies lower bound given j type expression best lower bound among j condition makes sure intervals nonoverlapping 2 figure 1 shows example lowerbound computation ordered pair next node indicates asap msat values respectively assumed addition takes one time step multiplication takes two one adder one nonpipelined multiplier values oe oe multiplication addition shown figure example multiplication operations 1 2 asap value less equal 2 hence oe 2 2 similarly addition operations 6 7 8 9 msat value less 2 hence oe 2 4 example dfg maximum value obtained i0 j2 complexity analysis asap values computed topdown fashion starting input operations follows v input operation asap v 1 otherwise g msat values similarly computed bottomup fashion starting output operations follows v output operation g let n number operations dfg number edges dfg grow linearly n since number inputs operation generally bounded small number two hence asap msat values found time number resource types generally bounded small number oe oe found recursively follows oe number type operations asap value similarly oe number type operations msat value 1 values found computation asap msat values without affecting complexity hence computing oe oe takes oc time c critical path length finally computing lower bound using values takes oc 2 time oc 2 intervals thus complexity algorithm estimate lower bound entire dfg method 20 similar method estimates length interval time steps computes required computation cycles type sum minimum overlaps operations type interval difference required available computation cycles type divided number available functional units type get increase length interval method interval minimum overlap operation determined hence complexity onc 2 method computes number operations interval constant time using precomputed data structures oe oe thus complexity 5 estimating lower bound partially scheduled dfg scheduling algorithms branch bound methods need compute lower bounds completion times large number partially scheduled dfgs methods 20 17 proposed purpose estimating lower bound entire graph methods used estimating lower bounds partial schedules time spent estimation may high advantage estimation nullified take onc 2 compute lower bound partial schedule method previous section also takes time section present extension method lowerbound partial schedule computed efficiently method takes ok time k number ready unfinished operations defined later section partial schedule rest paper call partial schedule configuration configuration r result scheduling r time steps unscheduled operation r scheduled time step greater r call r depth r denoted depthr let fv denote time step operation v scheduled start execution operation x said ready r scheduled yet predecessors scheduled finished r ie predecessor x note delay set ready operations r denoted readyr multicycle operation x said unfinished r scheduled start execution time step less equal depthr finished depthr ie fx depthr 1 set unfinished operations r denoted unfinishedr number unscheduled operations type configuration r denoted unschr basic idea behind estimation partial schedules follows partial schedule subset operations already scheduled satisfy precedence constraints well resource constraints instead considering possible values j divide operations intervals consider following special case resource type unscheduled portion dfg find maxfijoe 0g intuitively number time steps current step type unscheduled operation start execution j number time steps complete schedule current configuration takes last type operation finished executing steps computing lower bound configuration r resource type follows 1 compute j 2 qi j unschr since oe 3 compute hi j qi j explained previous section lower bound number time steps schedule remaining operations type quantity depthr j lower bound completion time schedule r maximum lower bounds resource types unscheduled operations type gives lower bound completion time schedule configuration r lead nontrivial step computing lower bound computation j step 1 important merit algorithm computes j efficient way described figure 2 node u operation type ffu defined minimum number time steps type successor u start starting time u value ffu set infinity u successors type node u value 0 type operation readyr otherwise given mina b ffu number time steps u finished r value j given mina b fiu set operations unfinishedr type successor figure 2 computing values j operation type fiu defined minimum number time steps schedule given dfg going take completion type successors u value fiu computed min v fmsat vg v type successor u u successors type u type operation fiu otherwise set infinity note lower bound type computed unscheduled operations type therefore values j never infinity formulas computation j based following lemma unscheduled operation x configuration r x either member readyr exists readyr unfinishedr predecessor x x unscheduled operation x readyr predecessor p x scheduled scheduled finished executing among p let q farthest x ie length longest path q x maximum among p q scheduled finished executing q unfinishedr q readyr predecessor q 1 q scheduled unfinishedr note q 1 predecessor x also q 1 farther q x contradiction hence q readyr 2 f type completion operation readyr completion figure 3 example estimation lowerbound completion time partial schedules figure 3 shows example estimation lowerbound completion time partially scheduled dfg assumed scheduling first step finished one adder one multiplier delay one timestep lowerbound completion time 7 timesteps target performance 6 timesteps lowerbound estimation suggests selection operations 2 3 first timestep wrong method section especially useful class scheduling algorithms compute lower bound large number configurations design space exploration matrices ff fi operations dfg resource types computed design space exploration done computing transitive closure directed graph transitive closure computed using depthfirst search onen e number edges graph 18 already explained e grows linearly n dfg since number inputs operation generally bounded small number two thus ff fi computed 2 time note values operations readyr unfinishedr used computing values j hence lowerbound configuration r computed ok time k number operations another major advantage method introduces little memory overhead overhead store matrices ff fi large number partial schedules memory requirement dominated amount information stored configuration scheduling algorithm taking full advantage lowerbound estimation needs store little information configuration 6 extensions 61 conditional branches use approach dividing type operations three nonoverlapping intervals explained section 4 lengths first third intervals independent resource constraints length second interval function total resource requirement operations scheduled interval conditional branches resource requirement equal number operations presence conditional branches however one operation share one resource timestep effectively operation requires fraction resource operation share resources computes weights operations cdfg f partition operations conditional blocks operation x cdfg f b gamma block x number blocks type operation mutually exclusive block b figure 4 outline procedure compute weights operations operations timestep minimum resource requirement 1n 1 refer quantity weight operation given resource type minimum total resource requirement interval computed sum weights type operations interval given weights individual operations computation sum weights operations interval similar computation number operations impact complexity partial schedules use sum weights unscheduled operations type place unschr configuration r thus increase complexity extension conditional branches due computation weights operations figure 4 shows outline procedure compute weights individual operations partition operations blocks operations conditional behavior placed block since operations block control behavior concept mutual exclusiveness operations easily extended blocks x type operation block b given control step x share resource one type operation block mutually exclusive b hence n blocks mutually exclusive b type operation weight x 1n 1 method 19 handle conditional branches extension 20 approach interval operations one conditional path considered maximize minimum resource requirement interval since conditional path analysis performed interval method slow used scheduling algorithms partial schedules actual time spent estimation outweigh advantage resultant pruning comparison method computes weights operations complexity remaining steps remains unchanged method based distributejoin representation cdfgs cselect implementation cselect implementation operations conditional branches cannot executed corresponding condition resolved many scheduling algorithms recent literature allow execution branch operations corresponding conditional 24 23 26 27 known speculative execution shown produce faster schedules many benchmarks 27 estimation method support cselect implementation speculative execution cselect implementation control precedences treated way data dependencies considered computing asap msat values op erations speculative execution control dependencies ignored computing asap msat values 62 chaining chaining operations handled dividing time steps timeunits extending definitions msat asap values terms timeunits let length timestep timeunits let v denote delay operation v terms timeunits two operations u chained functional unit executing u cannot freed v finished 19 therefore spans across timesteps may result underutilization resources avoid follow assumption 19 operation v chained end operation u enough time v finished time step u finished execution condition imposed checking u mod 6 0 let av mv asap msat values operation terms timeunits values recursively computed similar computation asap msat u v 2 e earliest timeunit execution result u available v au however v cannot chained u v start execution beginning next time step hence av given chained u cannot chained u similarly mv given aev chained v cannot chained v values corresponding asap msat values derived lowerbound computed using asap msat values explained section 4 7 experimental results implemented methods c language sun sparc2 workstation tested using number benchmarks literature benchmarks used ar filter 6 fifthorder elliptic wave filter 13 twice unfolded wave filter complex biquad recursive digital filter 13 sixthorder elliptic bandpass filter 13 discrete cosine transform 11 fast discrete cosine transform 9 biquad filter example used three time steps multiplier one adder used resource type adder addition subtraction comparison examples used two time steps multiplication one adder 71 lower bound estimation partial schedules branch bound methods mentioned section 1 branch bound scheduling methods rely estimating lower bounds partial schedules keep design space exploding generally lower bounds need estimated large number partial schedules configurations time spent lowerbound estimation high big negative impact overall time taken scheduling algorithm implemented branch bound scheduling algorithm 3 tested benchmarks first find schedule using list scheduling algorithm use performance upper bound branch bound algorithm search design space exhaustively optimum schedule partial schedule estimate lower bound schedule completion time exceeds upperbound partial schedule cannot lead complete schedule target performance explored separately measured time spent lowerbound estimation using method section 5 rims method 17 results reported table 1 method least 20 times faster cases measure effectiveness lowerbound estimation reducing size search space also measured number configurations visited using method separately results also reported table 1 methods equally effective since estimation slow cpu time taken using method time taken without using lowerbound estimation cases however majority cases search space exploded without lowerbound estimation thus showing necessity estimation resources configurations method rim 17 method rim ar filter 2 3 035 82 1769 3497 unrolled 2 3 013 29 770 723 twice unrolled filter 2 3 40 812 33182 27767 filter fast discrete 1 1 014 31 688 892 table 1 cpu time number configurations branch bound algorithm branch bound scheduling algorithms method suitable existing methods used scheduling algorithms incorporated method dynamic programming scheduling dps algorithm 1 developed obtained excellent results 72 lowerbound estimation entire dfgs tested benchmarks different resource constraints pipelined multiplier latency 1 nonpipelined multiplier cases lower bound compared optimal solution obtained using dps algorithm 1 tables 2 3 present lower bounds cases obtained method section 4 column dps tables shows number steps optimal solution lower bound tight 156 198 cases 22 cases difference one step also implemented algorithms rim 17 sharma 20 compared results method gives better lower bound 17 nine cases five cases lower bounds better 20 17 lower bounds one method jain 7 also reported copied second last column jain lower bound resources optimum solution lower bounds lower bound difference rim 17 jain 7 sharma 20 ar filter 1 3 twice unrolled wave filter 3 2 50 50 0 50 fast complex multiplication takes 3 time steps lower bound case better rims z lower bound case better sharmas table 2 lower bounds nonpipelined multiplier tables benchmarks cases reported tables lower bounds identical rims 17 average cpu times 21 ms 25 ms 270 ms method rims method sharmas method respectively thus method faster fastest nontrivial method literature 17 produces better lower bounds cases method one order faster method 20 still produces better results cases lower bounds 7 far inferior lower bound resources optimum solution lower bounds lower bound difference rim 17 jain 7 sharma 20 fast 1 1 26 26 0 26 26 transform complex multiplication takes 3 time steps table 3 lower bounds pipelined multiplier 73 results cdfgs table 4 shows results examples conditional behavior maha 14 parker high level synthesis benchmark suite kim 25 waka 22 mult 23 resources column lists number adders subtracters comparators used case additions subtractions comparisons singlecycle presented number time steps schedules obtained dps algorithm lower bounds cases tight obtained schedules cselect implementation allowing speculative execution cselect implementation operations mutually exclusive branches always share resources however since control precedences strict precedences critical path length may increase table 4 maha parker two examples high degree branching cselect imple mentation advantage conditional resource sharing nullified increase critical path length length schedules could reduced even adding resources comparison speculative execution gives much superior results adding resources reduces schedules lengths benchmark resources time steps cselect spec exec maha 111 11 y7 maha 211 11 y6 maha 222 11 5 parker 111 11 y6 parker 221 11 5 parker 222 11 5 cases lower bound one step less lower bounds tight table 4 cselect speculative execution conditional branch benchmarks 8 conclusions future research presented simple efficient techniques estimating lowerbound completion time scheduling problem proposed techniques handle multicycle operations pipelined functional units conditional branches chaining operations method entire dfgs faster produces better lower bounds 17 20 also presented extension technique especially suitable finding lowerbound partially scheduled dfgs extended method useful keep search space exploding scheduling algorithms branch bound method exising methods literature give special consideration computing lower bounds partial schedules conducted extensive experiment using method fastest nontrivial method known literature 17 estimation partial schedules branch bound algorithm method found least 20 times fatser equally effective reducing size search space currently investigating estimation lower bounds presence loops multifunction functional units used also investigating estimation lower bounds additional constraints interconnect storage r optimum dynamic programming scheduling resource constraints multischedule approach highlevel synthesis experiments local microcode compaction horizontal machines bounds number processors time multiprocessor optimal schedules lower bounds iteration time number resources functional pipelined data flow graphs experience adam synthesis system predicting systemlevel area delay pipelined nonpipelined designs recursive technique computing lowerbound performance schedules new approach pipeline optimization comprehensive lower bound estimation behavioral descriptions personal communication slicer state synthesizer intelligent silicon compiler high level synthesis technique based linear pro gramming maha program datapath synthesis sehwa software package synthesis pipelines synthesis pipelines behavioral specifications lowerbound performance estimation highlevel synthesis scheduling problem algorithms c estimation design algorithms behavioral synthesis asics estimating architectural resources performance highlevel synthesis applications estimating implementation bounds real time dsp application specific circuits resource sharing control synthesis method conditional branches global scheduling independent control dependencies based condition vectors treebased scheduling algorithm controldominated circuits scheduling algorithm conditional resource sharing global scheduling highlevel synthesis applications new symbolic technique controldependent scheduling tr experience adam synthesis system algorithms c global scheduling independent control dependencies based condition vectors treebased scheduling algorithm controldominated circuits comprehensive lower bound estimation behavioral descriptions global scheduling highlevel synthesis applications maha multischedule approach highlevel synthesis estimation design algorithms behavioral synthesis asics new approach pipeline optimisation ctr shen zhaoxuan jong ching chuen lower bound estimation hardware resources scheduling highlevel synthesis journal computer science technology v17 n6 p718730 november 2002 helvio p peixoto margarida f jacome new technique estimating lower bounds latency high level synthesis proceedings 10th great lakes symposium vlsi p129132 march 0204 2000 chicago illinois united states margarida f jacome gustavo de veciana lower bound latency vliw asip datapaths proceedings 1999 ieeeacm international conference computeraided design p261269 november 0711 1999 san jose california united states margarida f jacome gustavo de veciana lower bound latency vliw asip datapaths readings hardwaresoftware codesign kluwer academic publishers norwell 2001 margarida f jacome gustavo de veciana viktor lapinskii exploring performance tradeoffs clustered vliw asips proceedings 2000 ieeeacm international conference computeraided design november 0509 2000 san jose california