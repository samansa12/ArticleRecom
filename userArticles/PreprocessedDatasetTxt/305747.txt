products help bits decision trees investigate two problems concerning complexity evaluating function f k distinct inputs k parallel decisiontree algorithmsin product problem fixed depth bound seek maximize fraction input ktuples k decision trees correct assume single input f best depthd decision tree correct fraction p inputs prove maximum fraction ktuples k depthd algorithms correct pk trivial lower bound show replace restriction depth expected depth result need holdin helpbits problem decisiontree computations begin k1 arbitrary binary questions helpbit queries asked ktuple inputs second stage possible k1tuple answers helpbit queries ktuple decision trees ith tree supposed correctly compute value function ith input input consistent help bits complexity maximum depth trees algorithm show k sufficiently large complexity equal degsf minimum degree multivariate polynomial whose sign equal f b introduction pick favorite computation model complexity measure eg boolean circuit size communication complexity decision tree depth interactive proof length tensor rank etc attempt understand model complexity measure requires understanding ways unreasonable computation efficient reasonable one course reasonable changes understanding model improves suppose given several unrelated instances problem solve reasonable approach solve instance separately intuitively computation useful solving one instance irrelevant others extent intuition valid given model following question common way formalizing directsum problem suppose complexity computing function f c true computing f twice two unrelated inputs requires complexity 2c computing f k unrelated inputs question first studied context boolean circuits ulig paul gf subsequent work concerned bilinear circuits j bsh boolean circuits fkn communication complexity krw paper consider two related problems similar flavor product problem let f function suppose complexity c computation fraction inputs correctly computes f p suppose two independent computations taking input ordered pair b inputs f first computation trying compute f second trying compute f b two computations complexity c fraction input pairs b correct exceed analogous question k independent computations k inputs first computation uses input second uses input b p 2 upper bound trivial intuition suggests advantage computation access others input variant problem seek compute f two inputs single computation studied recently irw helpbit problem suppose complexity computing boolean function f c suppose one wishes compute f two inputs b allowed free one helpbit ie arbitrary function two inputs possible choose helpbit function given helpbit f f b computed computation complexity less c much computing f k inputs helpbit problem introduced knowl edge context constant depth circuits cai also studied context boolean circuits abg point k inputs k help bits use obtain value f inputs computation necessary instance obtain value f still need complexity c compute f last input effective use help bits paper consider problems context boolean decision tree complexity perhaps simplest computational model cost computation decision tree simply number input variables read depth decision tree precise definition given section 2 easy exercise see directsum holds decision tree depth two problems difficult answer product problem qualified yes theorem 1 let f nvariable boolean function suppose depth decision tree computes f correctly fraction p inputs let decision trees access set nk variables corresponding ktuple 1 2 k inputs f depth fraction ktuples 1 2 k correctly outputs f p k theorem seems completely obvious however reader might test intuition following variation suppose theorem change complexity measure depth av erage depth ie average inputs depth leaf reached input modified statement theorem seems similarly obvi ous see false recent work irw done independently includes substantially different proof weaker variant theorem namely single depth tree tries compute k functions correct p k fraction inputs result shows even use k parallel decision trees cant better help bit problem answer com plicated nathan linial lin shown complexity computing f two inputs one help bit least degf degree unique multilinear real polynomial equal f since almost boolean functions nvariables degf says help bits dont help functions result seem extend k 3 fact sufficiently large k results imply false manage prove lower bound holds k always tight k number instances solved sufficiently large need following definitions f nvariate boolean function say nvariate real polynomial p signrepresents f inputs taking boolean set fgamma1 1g signdegree f deg f minimum degree polynomial sign represents f theorem 2 let f nvariate boolean function suppose optimal decision tree computes f depth k 1 solution help bit problem f k inputs help bits requires depth least deg f furthermore sufficiently large k decision tree algorithm bits whose depth deg f case f equal product n variables corresponds parity function f0 1gvalued variables deg f lower bound implies helpbits dont help case actually function negative functions deg f ordinary decision tree complexity boolean functions n means large enough k complexity k instances given bits less ordinary decision tree complexity func tions particular f majority function deg f lower bound vacuous upper bound says k sufficiently large possible ask questions given answers value function one k inputs computed probing one vari able remarkable savings typical recently shown rr almost functions satisfy next section review decision tree model section 3 give general formulation product problem decision trees prove generalization theorem 31 theorem 1 section 4 discuss help bits problem prove theorem 2 proofs appendices techniques develop apply decision tree model may applied models well fact suffice obtaining many known results boolean circuit model sketch applications last section preliminaries section present basic definitions notation notions discussed familiar cases notation nonstandard 21 boolean functions purposes paper convenient use boolean domain instead f0 1g x set boolean assignment x map ff x b set boolean assignments x denoted b x refer elements x variables consider probability distributions set assignments specified distribution random assignment chosen according denoted placing identifier eg ff boolean function variable set x range r xrfunction function b x r paper range r always equal b k integer k 22 decision trees trees paper rooted ordered binary trees tree every internal node v exactly two children two children distinguished 1child 1child v depth dt v node v usual number edges along path v root depth dt maximum depth node formally decision tree variable set x range r xrdecision tree triple rooted binary tree p map associates internal node v variable set x map associates leaf v element v r label p v called query associated v node v said probe variable generally say xrdecision tree keeping maps p implicit set x rdecision trees x denoted x r simply let xrdecision tree ff assignment b x computation ff unique path root leaf start root v 0 inductively define define v ffp v child v output computation label l ff thus viewed boolean function x range r trivially every xrfunction f computed xrdecision tree usual cost function computation performed ff length number internal nodes computation path denoted ct ff worst case complexity ct maximum ff ct ff cf decision tree depth f minimum ct decision trees compute f distribution assignments distributional complexity cd average ct ff respect distribution given x r function f complexity bound b respect complexity measure interested well f approximated tree complexity b closeness approximation defined respect probability distribution boolean assignments x thus xrdecision tree agreement probability q f f relative probability respect random assignment ff chosen according decision tree approximation problem f du f x rfunction distribution boolean assignments x u set decision trees determine q f u defined maximum agreement probability q f particular interest case u set x r decision trees depth finally decision forest f x ranges ordered sequence xr decision tree f computes boolean function b x r theta r k 3 product problem disjoint sets vari ables let respectively distributions assignments assignment fi x viewed ktuple assignment x let denote distribution assignments x given probd product distribution theta k suppose k decision tree approximation problems optimal agreement probability u f relative convenient sometimes view f function entire variable set x ignores variables except consider problem simultaneously approximating decision forest simultaneous agreement probability q f denotes prob ability ff chosen according 1 family x r trees q f denotes maximum q f choices trees since f depends x chooses assignments ff k dependently would seem q f product probabilities q clearly case tree queries variables x however shown examples allowed query variables outside x need case intuitively would seem variables outside x could help approximate f indeed trivially true trying approximate f seek approximate functions simultaneously longer obvious crossqueries irrelevant nevertheless one might expect reason able classes u decision trees optimal simultaneous agreement probability attained sequence trees querying variables x thus equal product individual optimal agreement probabilities main result section prove case u set trees fixed depth theorem 31 let 1 2 k nonnegative integers note theorem 1 special case giving proof present two examples show multiplicativity fails natural alternative choices classes u example 31 theorem 31 fails replace class class trees restricted query variables x along path query variables outside x free consider following trivial example let g distribution 1 assigns x 1 1 probability 12 2 assigns x 2 1 probability 12 functions f 1 f 2 given means allow 1 look variables x 1 allow 2 look variable ever achieve simultaneous agreement probability better 14 let 1 tree queries x 2 outputs x 2 2 tree queries x 1 outputs x 1 probability 1 f 1 agree 2 f 2 agree probability assigned value 12 somewhat subtle example given example 32 distribution b x let class trees whose expected depth respect ie 2 average number variables queried respect ff chosen theorem false replace see let x set four vari ables f parity function x let u uniform distribution assignments x 3 first show maximum agreement probability f attained decision tree expected depth 3 equal 34 agreement probability 34 attained tree queries particular variable x 0 returns 0 otherwise queries remaining three variables returns parity see best possible note decision tree al gorithm leaf l depth less 4 agree f exactly half inputs reach l thus p probability random input ff ends leaf depth agreement probability q f bounded suffices show p 4 12 1 expected depth tree least 4p 4 means let copies f u disjoint variable sets show possible choose decision trees expected depth 3 whose agreement probability exceeds described let x 1 denote variable x 1 probed first 1 let 2 following tree first probe x 1 0 output 0 one read four variables x 2 output parity expected depth tree 3 since half paths depth one half paths depth five let us consider probability event 1 1 conditional probability given x 14 x must agree f 1 2 must agree f 2 thus probability simultaneous agreement happens example variable x 1 acts shared random coin partially coordinates two computations likely simultaneously correct proof theorem 31 fix sequence decision trees depth denote event event trees indexed evaluate respective functions cor rectly seek prove probck bounded proof induction k fixed k induction ktuple 1 result vacuous assume k 2 consider first case may assume k th party must guess value f k ff k without looking variables k consists single leaf labeled 1 1 conditioning value vector ff k probability p ck holds written let fl assignment ff k maximizes probability last expression define tree u contracting using ff fl may rewrite last term probu 1 f tree u depth may bound first factor induction hypothesis equals desired result follows assume 0 define directed graph f1 2 kg edge first variable probed input f j since directed graph outdegree one directed cycle let j 1 length cycle let us rename set indices cycle set way first probe variable denoted x i1 first probe j variable denoted intuition behind rest proof possible replace tree trees depth first probe decreasing probability simultaneous agreement denote function obtained f fixing x distribution set obtained conditioning x event ff 1 write probability compute correctly conditioning b follows seek upper bound expression show claim b 2 b j conditional probability ck given ab assuming claim moment substitute expression 1 obtain following bound probability trees correct sum rewritten equal th term product corresponds probability correctly computing f first probe x depending outcome use optimal depth tree evaluate residual function thus upper bound term expression 3 upper bounded expression 2 required suffices prove claim define f ab function f b f otherwise similarly distribution ab equal b otherwise observe mutual independence given ab product distribution ab 1 k let ab tree obtained contracting assumption ab holds conditional probability ab equal probability respect product distribution ab depth ab j may apply induction say probability respect product distribution ab ab f ab f ab equal expression claim proves claim theorem remark proof theorem extended general model decision tree computation model case single function given function f arbitrary domain r want compute f unknown input given set q admissible queries query q 2 q partition sets q r response query q index 2 q nodes decision tree labeled queries branches node correspond answers query collection functions f disjoint domains formulation product problem generalizes model statement proof theorem go assuming 1 allowed query depends variables one function 2 distributions independent 4 help bits help bits problem k boolean functions disjoint variable sets given unknown assignment ff variables set evaluate f ff decision forest allowed ask free arbitrary set l binary questions assignment ff answer l questions vector 2 b l decision forest f k require f ff agrees assignment ff consistent thus algorithm specified l arbitrary boolean functions h help bits variable set x together 2 l decision forests complexity algorithm maximum depth 2 l k decision trees forests general decision tree computes f ff ff consistent allowed probe variables outside x conceivably useful together help bits probes could imply information variables x instance one help bit functions f ff theta ff j x x variable x j probing variable x deduce probes variables x say pure 2 l k decision trees pure algorithm pure paper restrict attention case variable set x boolean function f x x copies x functions f copies f help bits problem h kl f evaluate k copies f given l help bits complexity optimal algorithm solves also define problem pure f h kl f except require algorithm pure define c kl pure f complexity optimal pure algorithm goal obtain bounds c kl f c kl pure f main result section slight refinement theorem 2 theorem 41 boolean function f n variables positive integer k pure f k sufficiently large pure f first reformulate problems h kl f pure f given functions f decision forest f say f covers assignment ff x respect f 1 minimum number forests consisting trees depth needed cover inputs respect f let k pure f corresponding minimum restrict forests pure proposition 41 let f boolean function k l nonnegative integers 1 c kl f k f 2 l 2 c kl pure f k pure f 2 l words dlog 2 k f de minimum l h kl solved trees depth pure f de minimum l h kl pure solved trees depth proof prove first assertion proof second completely analogous c kl f 2 l forests given algorithm also cover k f 2 l suppose k f 2 l collection 2 l forests cover assignments x index forest f z z ranges b l order forests lexicographi cally define az set assignments covered f z covered f z sets partition set assignments x define help bit functions h l ff unique index z ff 2 az functions together solves h kl concentrate obtaining bounds k pure f need yet another definition randomized xrdecision tree algorithm probability distribution q xr decision trees algorithm said approximate f probability p assignment ff random decision tree chosen according q probability fff least p define pf maximum p distribution q set decision trees depth approximates f probability p easy see pf 12 ordinary decision tree complexity f pf 1 following result relates f pf lemma 41 boolean function f n variables k 0 havepf k f pure f nk k e proof middle inequality trivial last inequality use standard probabilistic argument show family k pfd e pure forests depth cover assign ments let q distribution rdecision trees depth approximates f probability pf corresponding distribution set x trees consider distribution theta q k forests suppose select forests according p given assignment ff j probability covers ff least pf k thus probability none forests cover ff 1 gamma pf probability exists assignment ff covered none forests 2 nk e expression 1 positive probability forest covers assignments must collection forests depth cover assignments turn lower bound f need following relationship pf agreement probability q f respect particular distribution assignments lemma 42 rboolean function f integer 0 exists distribution assignments q variant fundamental observation yao y1 follows minmax theorem two person zero sum games distribution lemma suppose family forests cover assignments ff x consider distribution p assignments ff product theta copy x theorem 31 forest f probability covers ff pf k expected number assignments covered tpf k since f 1 covers assignments expectation must least 1 1pf k immediate corollary lemma proposition 41 get following bounds complexity help bits problem corollary 41 boolean function f n variables integers k l 0 1 2 l 1pf k c kl f 2 2 l nkpfd k c kl pure f next need connect quantity pf signdegree deg f proposition 42 boolean function f pf 12 proof let deg f nvariate polynomial degree gff 0 f ff 1 shifting polynomial small constant may assume gff never 0 may assume without loss generality sum absolute values coefficients g 1 consider following randomized decision tree algorithm choose monomial g random probability given monomial chosen absolute value coefficient probe variables monomial output product values easily seen assignment ff probability correctly evaluating f ff minus probability incorrectly evaluating fff equal jgffj 0 use domain fgamma1 1g thus ff algorithm correctly evaluates f ff probability exceeding 12 suppose pf 12 must exist randomized decision tree algorithm q depth trees evaluates f ff correctly probability exceeding 12 well known easy see induction looking two subtrees root decision tree depth variables fx 1 xng polynomial degree gt assignments ff define polynomialgx 1 sum qt g gamma 12 sum trees depth qt probability selected distribution q 12 choice q latter term positive theorem 41 follows easily proof theorem 41 corollary 41 would follow 2 holds sufficiently large k since pf deg f also corollary 41 show c pure deg f suffices show k follows immediately fact proposition 42 pf deg f remark 1 interesting note k large enough possible construct obtain optimal algorithm decision trees particularly simple form randomized algorithm proof proposition 42 uses decision trees correspond computing monomials g using randomized algorithm proof upper bound lemma 41 decision trees used help bits algorithm form remark 2 noted introduction f majority function deg f decision trees used optimal algorithm h large k depth 1 case f majority function three variables manuel blum gave following constructive protocol solve h enumerate subsets k size least 2k3 number sets 2 ck c 1 fix encoding sets ck bits given k separate inputs majorityof3 function imagine inputs arranged k theta 3 array row least two three entries agree majority value column least 2k3 entries agree function value col umn help bits ask lowest index column requiring 2 bits set rows column gives function value requiring ck bits armed information value function row r equal entry row designated column r 2 negative entry otherwise remark 3 proof lower bound lemma 41 used theorem 31 order deduce forest f depth probability respect particular distribution p assignments f correct k functions pf k special case relevant case proving c theorem 41 alternative argument sketch argument benefit extends models besides decision trees seen next section noted pf 12 thus ff selected distribution lemma 42 decision tree depth agrees f probability exactly 12 particular shown imply fix values variables either partial assignment occurs probability 0 value f conditioned assignment unbiased define random variable c 0 want show probability c fact distribution uniform f0 1g k xor lemma vaz see also cghfrs distribution f0 1g k uniform subset j k random variable c j defined xor c j probability c j 0 event c event j equal f j combining decision trees ft ji 2 jg get single decision tree depth jj jd computes j claim decision tree must agree f j probability exactly 12 enough finish argument prove claim showing leaf tree j reached nonzero probability f j ff conditioned ff reaching leaf unbiased leaf tree variables x appear path recall value f unbiased conditioned values variables condition value f j values variables x f still unbiased therefore f j remark 4 one implication theorem 41 large enough k best algorithm h uses pure trees reasonable speculate case h kl f k l open case interesting note case hard show pure tree algorithm better cf ordinary decision tree complexity f see note help bit partitions set assignments two groups 1 2 hard see either set assignments x 1 induced 1 b x1 set assignments induced 2 must b x2 first case given 1 pure tree computation f 1 hard problem without help bits second case given 2 pure tree computation f x 2 hard problem without help bits 5 models ideas used far also relevant models computation get results models similar neither precise strong obtain decision trees convenient describe results following general framework fix computational model computing function f input ff 2 x class feas feasible algorithms results hold classes certain closure properties class feas closed kcounting k algorithms feas algorithm runs k algorithms input accepts rejects based number computations k accept also feas examples classes polynomial size circuits closed polycounting polylogbit communication complexity protocols closed polylogcounting class define multiinput algorithm feasible algorithm computing function f pair inputs ff said rectangularlyfeasible feas every fixed value ff 1 induced algorithm f feas every fixed value ff 2 induced algorithm f feas notice two examples mentioned essentially model one may think feas ae feas thus example case polysize circuits lower bounds given twoinput algorithms apply polysize circuits well 51 products product theorem setting may proven using yaos xorlemma y2 observe applies general setting let 1 2 distributions lemma 51 yao assume feas closed kcounting one deduce approximate product theorem theorem 51 assume feas closed k counting proof fix algorithm feas denote py probability correct inputs pnn probability incorrect py n probability correct first input pny probability correct second input since every fixed value ff 1 probability correct f 2 averaging ff 1 similarly finally yaos xorlemma implies omegagamma10 inequalities together fact p yy p n directly imply omegagamma1 proves lemma 52 help bits use approximate product theorem get helpbit results randomized algorithms given class feasible algorithms feas say function randomly feasibly computable rfc exists probability distribution algorithms feas input algorithm chosen distribution correct f probability least 23 constant 23 important usual amplification lemmas work general case lemma 52 feas closed kcounting constant 23 replaced 12 2 gammak without changing class rfc case feas class polynomial size circuits known randomization increase power thus rfc exactly equal functions computable deterministic poly size circuits case feas polylog bit communication protocols rfc functions computable randomized polylogbit protocols twosided error let us define feasible computation helpbit let feas given class algorithms 1helpbitfeasible algorithm feas 1 set two algorithms 0 1 feas boolean function h whose value input ff output hff function rfc 1 feas 1 algorithm computing two copies f every pair inputs correct probability least 23 prove randomized help bit theorem theorem 52 feas closed o1 counting rfc proof assume f 62 rfc amplifying similarly lemma 42 exists distribution q f feas 051 using approximate product theorem feas algorithm two copies f correct 051 2 o1 fraction inputs distribution theta follows feas 1 algorithm correct probability twice probability smaller 23 probability taken pair inputs chosen theta turn implies f 62 rfc 1 case boolean circuits proven abg 53 log k barrier approximate product theorem ran domized helpbit theorem naturally generalized log k functions family feas closed kcounting techniques break unknown example whether polynomial size circuit using n helpbits compute n1 copies function doesnt polynomial size circuits one show black box model alternatively relative particular oracle generalizations false using log consider model polynomialsize circuits access blackbox theorem 53 blackbox exists boolean function f cant computed polynomialsized circuit family helpbits allow polynomialsized circuit always compute answer n disjoint copies f n input size f proof well know random f cant computed polynomialsized circuit fix f successful circuit would take inputs output vector v blackbox way circuit without helpbits cant find circuit helpbits goes directly let n size x choose n input tuple output v following let random lnbit string place v location indexed place sorry location standard counting argument one show polynomial sized circuit family access black box answer correctly ntuples inputs however given l helpbits easy query oracle location revealing answer tuple interesting note yao xor lemma fails relative blackbox sense xor ln variables parity stops getting harder compute words xor lemma log n barrier acknowledgement authors many conversations several people regarding search would especially like acknowledge contributions richard beigel nati linial russell impagliazzo avi wigderson r connections bounded query classes nonuniform complexity extended direct sum conjecture lower bounds constant depth circuits presence help bits bit extraction problem tresilient functions amortized communication complexity complexity 2output boolean networks advances computational complexity theory fractional covers communication com plexity proving superlogarithmic depth lower bounds via direct sum communication complexity direct product theorem rounds communication complexity revisited realizing boolean functions disjoint set variables synthesis selfcorrecting schemes functional elements small number reliable components theory applications trapdoor functions probabilistic computations towards unified measure complexity tr ctr ronen shaltiel towards proving strong direct product theorems computational complexity v12 n12 p122 july 2004 paul beame toniann pitassi nathan segerlind avi wigderson strong direct product theorem corruption multiparty communication complexity disjointness computational complexity v15 n4 p391432 december 2006 anna gl peter bro miltersen cell probe complexity succinct data structures theoretical computer science v379 n3 p405417 june 2007