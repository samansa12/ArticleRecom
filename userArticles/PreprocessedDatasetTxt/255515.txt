algorithms scheduling realtime tasks input error endtoend deadlines abstractthis paper describes algorithms scheduling preemptive imprecise composite tasks realtime composite task consists chain component tasks component task made mandatory part optional part whenever component task uses imprecise input processing times mandatory optional parts may become larger composite tasks scheduled twolevel scheduler high level composite tasks scheduled preemptively one processor according existing algorithm scheduling simple imprecise tasks lowlevel scheduler distributes time budgeted composite task across component tasks minimize output error composite task b introduction hard realtime system contains tasks must produce logically correct results within certain timing constraints system processing times tasks transient overloads may unavoidable hard realtime system must remain robust maintain acceptable level performance transient overload imprecisecomputation technique 1 2 3 4 5 introduced way deal transient overloads technique motivated fact one often trade precision timeliness prevents missed deadlines provides graceful degradation transient overload ensuring approximate result acceptable quality available whenever exact result cannot obtained time imprecisecomputation model used previous studies 3 4 5 6 7 8 9 10 11 12 13 14 15 assumes quality tasks result depends solely time spent task produce result specifically input task free error task terminates prematurely result produced contains error nondecreasing function processing time unexecuted portion model adequately characterizes many realtime applications several others examples include video compression speech recognition radar tracking applications quality result produced task depends also quality input task results produced tasks used inputs tasks decision much task complete time order set dependent tasks produce good overall result made considering task independently others addition previous studies imprecise computation focus case timing constraints task given however timing constraints derived directly highlevel requirements typically individual tasks rather timing constraints sets tasks call timing constraints end toend timing constraints endtoend timing constraints set tasks must met contrast individual tasks set specific timing con straints imposed endtoend timing constraints thus freedom advance postpone executions individual tasks freedom gives us added dimension tradeoff result quality timing requirements paper extend imprecisecomputation model account input error well endtoend nature timing constraints according model tasks jointly support function system dependent amount time required complete successor task depends quality result produced predecessor task set dependent tasks forms composite task composite tasks independent ready time deadline composite task endtoend timing constraints component tasks describe paper twolevel approach scheduling composite tasks high level scheduler determines total amount time budgeted composite task order composite tasks meet deadlines low level scheduler distributes time budgeted composite task component tasks minimize output error highlevel scheduler use one several existing algorithms scheduling independent tasks precise inputs determine time budgets composite tasks describe several heuristic algorithms lowlevel scheduler use distribute time component tasks remainder paper organized follows section 2 provides background information needed section 3 describes extended imprecisecomputation wc feng jws liu department computer science university illinois urbanachampaign urbana il 61801 email feng janeliucsuiucedu manuscript received sept 9 1994 recommended acceptance ac shaw information obtaining reprints article please send email transsecomputerorg reference ieeecs log number s95622 ieee transactions software engineering vol 23 2 february 1997 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 2 14 model section 4 quantifies effect input error processing time requirements result quality dependent component tasks section 5 presents set heuristic scheduling algorithms attempt optimize overall result quality composite task section 6 presents performance algorithms lastly section 7 summarizes results presents future work model built imprecisecomputation model used previous studies 3 4 5 6 7 8 9 10 11 12 13 14 15 characterizes workload realtime system set preemptable tasks task logically decomposed mandatory part followed optional part following rational parameters ready time r time task available execution deadline time task must produce result processing time p amount processor time required execute task completion mandatory processing time amount processor time required execute mandatory part completion optional processing time amount processor time required execute optional part completion mandatory part must execute completion order produce acceptable usable result task meets deadline mandatory part completes deadline optional part execute mandatory part completes optional part may terminated completed necessary task tasks meet deadlines attention confined uniprocessor systems let f denote amount processor time assigned execute task according given schedule scheduling algorithm works correctly never schedules task ready time total time f assigns every task less mandatory processing time amount time remaining mandatory part completes execution optional part may less hereafter scheduling algorithm mean correct algorithm schedule mean valid schedule call schedule every task assigned units time deadline feasible schedule assigned processor time f equals p equivalently task said precisely scheduled otherwise f p last portion processing time discarded valid schedule p f equal equal less call amount discarded work f fraction discarded work 1 never range value f range irrelevant assumed value one sake convenience existing algorithms 3 4 5 7 8 9 10 11 12 13 14 15 scheduling tasks optional parts assume tasks monotone monotone task executes longer quality results improves hence algorithms seek schedules fraction discarded work function fraction task small possible specific performance metrics commonly used existing algorithms include weighted average fractions discarded work sum fractions discarded work maximum fraction discarded work number discarded optional tasks highlevel scheduler described later paper makes use algorithm g described 5 optimal offline algorithm finds preemptive schedules independent tasks maximum fraction discarded work among tasks small possible algorithm turn uses optimal algorithm developed earlier shih et al 11 scheduling offline preemptive tasks arbitrary ready times deadlines minimize sum amounts discarded work tasks algorithms allow tasks dependent possibility error propagation across dependent tasks considered shih liu 12 since modified algorithm schedule tasks online sum amounts discarded work tasks accepted system minimized concept trading result quality timeliness also independently studied artificial intelligence community dean boddy 16 17 proposed use anytime algorithms framework timedependent planning decisionmaking execution anytime algorithm may interrupted point return result whose quality solely function processing time completed portion therefore task based anytime algorithm optional task imprecisecomputation model mandatory processing time task zero zilberstein 18 19 20 extended work dean boddy introducing concept conditional performance profiles conditional performance profiles represent result quality function input quality well processing time spent produce result extended im precisecomputation model described next section resembles zilbersteins model way musliner 21 introduced concept anydimension al gorithmsa general class iterative algorithms concept generalizes anytime algorithm concept providing guarantees along dimensions time like anytime algorithm anydimension algorithm iterative algorithm termination condition halts iteration threshold along dimension reached aspect considered dey kurose towsley 22 introduce notion reward analogous error imprecise computation model quality anytime algorithms 1 previous studies imprecise computation e called error result task quality result assumed linear function amount discarded work feng liu algorithms scheduling realtime tasks input error endtoend deadlines 3 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 3 14 schedule tasks tasks receive increasing reward increasing service iris however model ignores dependency result quality input quality model extend imprecisecomputation model characterize applications inputs provided tasks may imprecise extended imprecisecomputation model workload consists set independent preemptable composite tasks particular input composite task independent output produced composite tasks composite task j consists n j component tasks k parameters processing time mandatory processing time optional processing time composite task respectively equal sums corresponding parameters component tasks j processing time mandatory processing time optional processing time component task focus attention type composite tasks whose component tasks linear precedenceconstraint graphs endtoend ready time r j composite task j ready time first component task 1 begin execution r j begin execution completes j immediate successor output input output last component task n j output composite task endtoend deadline j j deadline last component task n ready times deadlines intermediate component tasks specified capture endtoend nature timing constraints assign ready times deadlines component tasks composite task gives us maximum flexibility scheduling component tasks paper deals scheduling component tasks within given composite task ambiguity simplify notation dropping superscript j component tasks k composite task simply call tasks assume component tasks monotone component task i1 terminated completed output contains error e i1 input error e successor task one effect input error e mandatory part may extended sense takes additional h units processor time beyond produce acceptable result call h units mandatory part mandatory extension concatenation mandatory part mandatory extension extended mandatory part amount processor time needed execute completion given paper assume mandatory extension h e monotone nondecreasing function input error e h every component task monotone input error e task monotone nondecreasing function fraction discarded work f i1 predecessor task i1 conse quently mandatory extension monotone nondecreasing function f i1 slight abuse notation denote function h n mandatory extension zero predecessor task i1 assigned p units time ie f assume input error e 1 first component task every composite task zero hence h 1 effect processing time mandatory part illustrated newtons rootfinding method suppose processing time mandatory part time takes find root within 10 actual root processing time optional part time takes refine result mandatory part within 01 actual root obviously input newtons method poor ie predecessor component task provides input value far actual root mandatory part must execute longer order meet 10 threshold effect accounted mandatory extension optional part stays similar examples extending mandatory part occur image video processing well suppose processing time mandatory part time takes display client workstation video frame acceptable quality processing time optional part time takes enhance visual quality video frame transmission frame client packets lost corrupted client must image enhancement mandatory part displaying video frame extended correspondingly order bring quality video frame acceptable standards another possible effect input error task processing time optional part lengthened based argument processing time optional part extended k units offset effects input error k x monotone nondecreasing function x k additional time units optional part make optional extension juxtaposition optional part optional extension extended optional part amount processor time needed execute completion given radar tracking example application extending optional part necessary compensate input error mandatory part consists processing returned radar signal creating track records signal processor track record indicates position direction movement possible target optional part tries associate targets established tracks data processor returned radar signal weak 4 ieee transactions software engineering vol 23 2 february 1997 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 4 14 noisy amount time required process signal remains less ie processing time mandatory part stays however may false returnsrecords associated nonexistent targets result data processor must spend additional processing time associating tracks general mandatory part optional part may extended fraction f i1 optional part i1 discarded hence input error e nonz ero specifically mandatory part extended optional part k h means input error e fatal effect never produce acceptable result matter long executes similarly k finite effect input error never erased executing optional part longer longer although result produced acceptable hereafter refer h mandatory optional extension functions respectively consider composite tasks whose prece denceconstraint graphs linear composite task output error equal output error last component task turn depends output errors predecessor component tasks let f j denote total amount processor time assigned composite task j highlevel scheduler heuristic algorithms distributing total time f j component tasks attempt keep fraction discarded work f n last component task hence output error e n component task composite task small possible algorithms presented subsequent sections near optimal mandatory extension optional extension every component task linear functions fraction discarded work f i1 immediate predecessor i1 particular assume extension functions h mandatory errorscaling factor k optional errorscaling factor however assumption linearity h valid general return section 5 discuss approximate arbitrary functions h linear functions throughout section assume mandatory optional extensions component tasks 2 3 n given 1 2 mandatory optional extensions first component task 1 composite task zero since input composite task assumed errorfree first derive expression fraction discarded work last component task function amounts time assigned earlier component tasks special case optional errorscaling factors k zero consider special case mandatory error scaling factors h zero expressions fraction discarded work terms predecessors provide clues distribute amount time f j assigned composite task j component tasks mandatory optional extensions component tasks given 1 2 mandatory errorscaling factor h nonzero optional errorscaling factor k zero amount time f assigned component task must range extended mandatory part execute completion f constrained range fraction discarded work linearly decreasing function f illustrated dotted line fig 1 stated following lemma fig1 extended imprecisecomputation model lemma 41 fraction discarded work f component task optional errorscaling factor k zero given f assigned units time fraction discarded work predecessor f i1 proof lemma follows directly property similar triangles f example f enough time execute extendedmandatory part optional part left unexecuted result f 1 general fraction discarded work f n composite task consisting n component tasks given following theorem theorem 4 composite task n component tasks whose optional errorscaling factors zero fraction discarded work f n last component task n given f c amount time assigned component task constant feng liu algorithms scheduling realtime tasks input error endtoend deadlines 5 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 5 14 coefficients given h h h h proof lemma 41 composite task consisting one component task fraction discarded work given f composite task consisting chain two component tasks fraction discarded work f 2 equal f f f f suppose amount discarded work f n1 composite task consisting chain n1 component tasks f c c f amount discarded work f n composite task n component tasks c f f f similarly mandatory errorscaling factor h component task zero optional errorscaling nonzero value f must range processing time extendedoptional part lemma 42 amount discarded work f component task whose mandatory part errorscaling factor h zero given f assigned f units time fraction discarded work predecessor f i1 proof using fig 1 lemma follows directly property similar triangles f theorem 42 composite task two component tasks whose mandatory errorscaling factors h zero fraction discarded work f component task given i1 amounts time assigned optional parts i1 respectively f i2 fraction discarded work i2 proof lemma 42 describe highlevel algorithm scheduling composite tasks determining total amount time assigned task focus lowlevel algorithms distributing time assigned composite task among component tasks algorithms make use expressions derived previous section decide total amount time assigned composite task distributed among component tasks minimize output error e n composite task lowlevel algorithms compute amounts time given component tasks based errorscaling factors also present method extracting errorscaling factors 51 highlevel scheduling composite tasks since composite tasks independent quality result produced composite task independent amounts time assigned composite tasks therefore problem scheduling set preemptable composite tasks reduces problem scheduling set independent preemptable tasks fig 2 gives pseudocode description algorithm called scomposite scheduling composite tasks 6 ieee transactions software engineering vol 23 2 february 1997 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 6 14 figure use h j denote sum maximum extendedmandatory processing time algorithm makes use modified version earliest deadlinefirst algorithm medf described 11 algorithm g described 15 medf algorithm treats every composite task entirely optional schedules composite tasks earliestdeadlinefirst basis never schedules composite task dead line words every composite task terminated deadline completed shown 11 medf algorithm minimizes total processing time discarded portions tasks algorithm g distributes total available processor time evenly possible among tasks specifically given set ready times deadlines algorithm makes fraction discarded work composite task ie ratio processing time unexecuted portion composite task total optional processing time component tasks equal possible composite tasks input ready time r j deadline j every composite task j b total processing time maximum extendedmandatory processing time c parameters j every component task every composite task output feasible schedule feasible schedule subset list composite tasks cannot feasibly scheduled 1 composite task set processing time p j p b use medf algorithm find schedule resultant schedule precise schedule output error every composite task 0 done 2 set b use medf algorithm find schedule resultant schedule precise schedule q go step 4 3 use algorithm g schedule total amount time assigned according resultant schedule composite task 4 every j use one distribution algorithms distribute time f assigned j among component tasks b report infeasible composite tasks processing time distribution feasible composite tasks fig 2 algorithm scomposite algorithm scomposite four steps step 1 tries schedule every composite task j precisely step succeeds finding precise schedule output errors composite tasks zero component task j assigned units time step 1 fails find precise schedule precise schedule exists 11 step 2 tries precisely schedule every composite task whose optional processing time compared maximum extendedmandatory processing time step 2a reducing amounts time assigned tasks relatively large optional processing times step 2b medf algorithm finds precise schedule reduction composite tasks small optional processing times scheduled precisely zero output errors composite task whose optional processing times larger maximum extendedmandatory processing time assigned sufficient amount time ensure feasible distribution time among component tasks hand step 2b fails know whether feasibly schedule distribute assigned composite task component tasks step 3 carried finds f way processing times unexecuted portions composite tasks measured terms fractions processing times equal possible constraints imposed ready times deadlines composite tasks step 4 invoked distribute time component tasks example suppose two composite tasks following parameters fig 3 shows three schedules composite tasks produced steps 1 2 3 algorithm scomposite schedules produced step 1 step 2 precise step 3 carried fractions unexecuted optional portions tasks equal 114 times assigned tasks f 28 f 84 processing times unexecuted portions 1 2 1 3 respectively fig 3 example illustrate algorithm scomposite later expand example show algorithm used step 4 find way distribute 28 units time assigned 1 output error zero total time used component tasks less 28 results produced step 4 include amount unused time feasibly scheduled composite task additional amount time required infea feng liu algorithms scheduling realtime tasks input error endtoend deadlines 7 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 7 14 sibly scheduled composite task improve chance algorithm scomposite find feasible schedule fails carrying step 3 step 4 second iteration amount time used composite task feasibly scheduled step 4 first iteration considered mandatory similarly amount time required composite task feasibly scheduled step 4 used mandatory processing time task second iteration time complexity steps 1 2 oq ln q time complexity step 3 oq 3 algorithms distributing time component tasks time complexity hence time complexity algorithm 52 lowlevel scheduling distribute processor time f units time assigned composite task must distributed n component tasks way present five algorithms distribution since longer necessary us keep track different composite tasks drop superscript simplify notation algorithms make decisions amount time given component tasks based primarily mandatory errorscaling fac tors suited processing times mandatory extensions component tasks large compared processing times optional extensions contrast algorithms disto disto take account effect optional errorscaling factors output error composite task perform better distm distm distmiterative processing times optional extensions large comparison processing times mandatory extensions 521 algorithm distm fig 4 gives pseudocode description algorithm dist algorithm distributes processor time component tasks based solely mandatory errorscaling theorem 41 provides rationale algorithm according theorem optional errorscaling factors component tasks zero ie k 1 2 n fraction discarded work f n linear function times f assigned component tasks since constraints 6 7 f also linear problem finding assignment f ie set times assigned component tasks minimize f n hence output error e n composite task linearprogramming problem special case use linearprogramming package find f scheduling done offline however k 0 assignment f thus found optimal see later may even feasible algorithm distm variances offer better alternatives lower scheduling overhead time complexity input parameters component tasks b total time f assigned composite task output feasible assignment f time component tasks amount unused time u report failure find feasible schedule additional time required 1 f n schedule component tasks precisely setting done 2 report done 3 compute h according 4 sort nonincreasing order put list l l empty index largest l x1 marked x n else f mark x remove x l 4 compute amount unused time u 0 set report algorithm fails amount additional time required else report unused amount time u f fig 4 algorithm distm specifically algorithm distm four steps first two steps try find feasible assignment n scheduled yield zero output error two steps fail step 3 tries find good assignment small fraction discarded work f n see rationale behind step assume moment expression f n theorem 41 see fraction minimized choosing values f following way larger coefficient sum given 3 larger value f unfortunately constraints 6 7 choice f always possible constraints fact k zero step 3 hence algorithm distm optimal step 3 tries find assignment yields small fraction discarded work f n making locally optimal nearoptimal decisions follows begins making value f x largest coefficient x among 3 large possible 4 see x x1 means h x1 words processing time optional part x smaller processing time maximum mandatory extension x1 entire op 8 ieee transactions software engineering vol 23 2 february 1997 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 8 14 tional part x left unexecuted therefore f x made sufficiently large x execute completion similarly x x1 hence h x time required execute maximum mandatory extension x optional portion x1 therefore f x1 chosen extendedmandatory portion x1 completes process repeated values f chosen step 4 checks whether assignment f produced step 3 feasible total time f assigned composite task total time required f exceeds f another attempt find feasible assignment made produce schedule minimum allowable output error algorithm fails assignment also infeasible result step 4 amount time used feasible assignment f additional amount time needed feasible assignment reported highlevel scheduler make use information reallocate time among composite tasks eg giving time required one composite task ones requires time illustrative example consider composite task 1 fig 3 consists chain four component tasks suppress super script parameters component tasks total amount time assigned 1 28 1 cannot precisely scheduled executed hence step 1 algorithm distm fails find assignment yields zero output error step 2 assigns f units time 1 2 3 respec tively remaining time f 1s f insufficient 4 execute completion consequently step 3 carried 44 a4 2 1 4 3 first marked fraction discarded work f 1 1 1 fraction discarded work f 2 2 0 second iteration 1 largest entry 2 marked f 64 third iteration 4 largest thus f 4 chosen 4 fourth iteration time required 3 amount unused time 06 units fraction discarded work f 4 4 zero consequently output error zero 522 extensions algorithm distm algorithm distm strictly follows theorem 41 making scheduling decisions algorithm distm uses guide conceptual difference two algorithms step 3 unlike algorithm distm algorithm make scheduling decisions based solely distm algorithm goes one step checking see total execution time pair tasks shortened lengthened giving task processing time shortened task assigned time otherwise allocated enough time execute extendedmandatory part steps 1 2 4 algorithm corresponding steps algorithm distm step 3 described fig 5 note purpose marking algorithm different algorithm distm marked task task whose fraction discarded work zero 3 set f compute h according 4 sort nonincreasing order put list l l empty index largest l x1 marked x n else mark x else x1 unmarked else mark x remove x l fig 5 step 3 algorithm distm amounts time required complete component tasks may change execution algorithm algorithm distm applied iteratively produce schedule good better schedule produced single pass algorithm distm therefore algorithm distm repeatedly applies algorithm distm changes schedule 523 algorithm disto processing times mandatory extensions small compared processing times optional ex tensions expect distm variances unlikely perform well algorithm disto offers alterna tive algorithm consists three steps first two steps identical first two steps algorithm distm step 3 described fig 6 feng liu algorithms scheduling realtime tasks input error endtoend deadlines 9 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 9 14 step 3 carried step 2 fails words units time assigned earlier component tasks remaining time f insufficient last component task n complete decision must made whether assign time n earlier component task divide time component tasks manner step 2 report failure find feasible assignment additional time required done else report f done fig 6 step 3 algorithm disto algorithm disto based expression output error given 5 like algorithm distm decision made algorithm disto locally optimal understand reasoning behind choices made step 3 suppose units time divided evenly n n1 according 5 fraction discarded work f n given f ask whether f n reduced assigning units time n 0 expense n1 question equivalent whether inequality f f f true simple algebraic manipulation shows inequality holds case better give remaining time n otherwise give time earlier component task 524 algorithm disto decision made algorithm disto good processing times maximum mandatory extensions component tasks fairly small general may able reduce output error distributing available time earlier component tasks algorithm enhanced version algorithm disto serves purpose algorithm tries divide processing time across component tasks algorithm identical algorithm distm except heuristic guide step 3 calculated differently choice motivated expression 5 according equation mandatory errorscaling factors component tasks zero ie h 1 2 n component task whose optional errorscaling factor optional processing time smaller successor task given time successor task fraction discarded work predecessor sufficiently small otherwise successor task given time consequently choose 53 extracting errorscaling factors lowlevel algorithms distributing time component tasks require input parameters errorscaling factors component tasks algorithms cannot applied directly component tasks whose extension functions linear form given 1 2 describe transform given set component tasks arbitrary mandatory optional extensions another set linear mandatory optional extensions thus find errorscaling factors without loss generality suppose given mandatory optional extensions denoted h f respectively component task shown dotted curves fig 7a 7b respectively approximate given extension function two straightline segments segments lie entirely extension function straightline segments give upper bound values extension function values f i1 valid feasible schedule based straightline approximations extension functions surely valid feasible schedule given extension functions specifically one two straight lines vertical one f f 1 call discard threshold task task never produce precise result f fraction optional task i1 i1 left unexecuted want ensure condition never occurs component task reason increase mandatory processing time i1 decrease optional processing time i1 denotes given optional processing time i1 words transform predecessor task i1 one whose mandatory optional processing times given jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 given mandatory processing time i1 algorithms work transformed parameters i1 corresponding given parameters allowed range fraction discarded work f i1 based computed value adopting straightline segments finite slopes range following approximate extension functions x values defined fig 7 hence h assume characteristics component tasks first analyzed parameters every component task every composite task derived given mandatory optional processing times extension functions manner described fig 7 extension functions ran suite simulation experiments evaluate performance algorithms distm distm iterative disto disto convenience call five algorithms collectively dist algorithms experiment randomly generated composite task component tasks component task mandatory optional processing times ie mandatory optional errorscaling factors ie h randomly chosen respective probability distributions isolated effect parameters keeping parameters fixed example number component tasks composite task fixed 8 composite task parameters h component task chosen either uniform distributions bimodal distributions applied five algorithms composite task found fractions discarded work last component task produced given algorithm lower fraction discarded work better performance 61 uniform distribution table 1 shows performance dist algorithms found four representative experiments parameters chosen uniform distributions column corresponds composite task whose componenttask parameters selected either uniform distribution range 0 10 uniform distribution range 0 100 call distribution range 0 10 small uniform distribu tion parameter h component tasks chosen small distribution k larger distribution namely one range 0 100 label appropriate column small h exemplified second column experiment table 1 numerical entries table 1 either roman italic font first two steps five dist algorithms steps try find feasible scheduling assignment yields zero output error either step 1 2 succeed results listed roman font either steps fail succeeding steps distinguish individual dist algorithms results composite tasks benefit distinguishing steps italics none steps result feasible schedule composite task said unschedulable uns expected values h parameters small five algorithms perform almost identically small h parameters imply compensating input error component task much cheaper timewise scheduling predecessor tasks precisely sult best approach schedule types tasks general schedule extended mandatory parts last component task compensate accumulated error giving last component task much time possible approach step 2 dist algorithms thus explaining nearidentical performance instance algorithms perform identically h small small well case approach described takes much time scheduling component tasks precisely optional parameters small words time given last component task compensate error mandatory parts ie mandatory extensions accumulated error predecessors comparable amount time takes simply execute shorter optional parts entirely begin neither effect pronounced heuristics steps 3 4 dist algorithms come play possibly produce better schedules instance small h iterative achieve fraction discarded work 0211 perform better algorithms feng liu algorithms scheduling realtime tasks input error endtoend deadlines 11 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 11 general whenever h small large better approach schedule extended mandatory parts compensate accumulated error giving last component task much time avail able hand whenever small better approach schedule component tasks precisely performance five heuristics seen experiments small supports hypothesis heuristic steps dist algorithms effectively reconcile opposing approaches determine much scheduling approach use finding assignment set parameter values summary algorithms distm iterative perform better algorithms cases however cases exam ple experiment 4 h small distm performs better distm iterative locally optimal decisions made globally op timal finally results set experiments distinguish performance distm iterative 62 bimodal distribution table 2 shows results obtained four representative experiments parameters h chosen either uniform bimodal distributions spe cifically experiment parameters component task selected either uniform distribution range 0 100 bimodal distribution ranges 0 10 90 100 bimodal probability density function equal 120 ranges 0 10 90 100 equal zero elsewhere example h parameters chosen bimodal distribution chosen uniform distribution label appropriate column bimodal h results table 2 show different heuristics used different dist algorithms lead larger difference performance task parameters bimodally distributed reason steps 1 2 often succeed tasks bimodally distributed parameters instance column 2 table 1 shows large h small five dist algorithms achieve result corresponding case large chosen uniform distribution h chosen bimodal distri fraction discarded workuniformly distributed parameter jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 12 bution column 2 table 2 shows distm algorithms produce better results algorithms bimodal mixture small large h makes approaches taken step 1 step less effective thus allowing heuristics distm algorithms applied frequently leading better results steps 1 2 fail frequently tasks bimodally distributed parameters demonstrated larger number italicized entries table 2 table small table 2 shows bimodally distributed approach scheduling component tasks precisely still good one however longer good case task parameters uniformly distributed due mainly fact fewer parameters small bimodal distribution compared uniform distribution given composite task sample parameters longer uniformly distributed heuristics potentially opportunities tradeoff processing times mandatory optional extensions component tasks thus producing better results summary table 1 algorithms distm generally perform better algorithms parameters bimodally distributed furthermore distm performed well better distm future work paper extended imprecisecomputation technique account input error endtoend timing constraints developed five heuristic scheduling algo iterative disto minimize output error composite task realtime system algorithms time complexity although initial intuition indicated disto disto algorithms would perform better processing times mandatory extensions small compared optional exten sions turned false suite simulation experiments run evaluate algorithms distm algorithm variants always performed well better either algorithm disto algorithm makes sense optional ex fraction discarded workbimodal uniformly distributed parameters feng liu algorithms scheduling realtime tasks input error endtoend deadlines 13 jproductiontse2inprods95622s956221doc regularpaper97dot sl 19968 021897 456 pm 13 tension executed given schedule whereas mandatory extension must always executed optional extension long eg k andor large algorithms choose schedule mandatory extensions small ie h andor small easier compensate accumulated error produced earlier component tasks scheduling last component task much possible stated section 5 could used linearprogramming solver time distribution special case optional errorscaling factors zero however linearprogramming solutions applied composite tasks experimental suite nonzero optional errorscaling factors solution provided linearprogramming solver gives us infeasible time distribution every composite task generated experiments many natural extensions work including generation precedence constraint graphs accurate piecewise linear approximations extension functions example evaluating performance algorithms extension functions component tasks concave convex yet another extension would make global decision assigning time component tasks composite task specifically lowlevel algorithm unable schedule component tasks composite task within allotted time lowlevel algorithm could provide feedback highlevel algorithm additional processingtime needs highlevel algorithm finds composite tasks require entirety assigned processing times unschedulable composite task could borrow time order become schedulable acknowledgments work supported part office naval resarch contract n0001492j1146 air force office scientific research contract f496209310060 r faulttolerant scheduling problem minimizing mean weighted execution time loss identical uniform processors concord system imprecise computations imprecise results utilizing partial computations realtime systems position paper 1987 ieee workshop real time operating systems performance evaluation scheduling algorithms imprecise computer systems minimizing mean flow time error constraints scheduling periodic jobs allow imprecise results minimizing number late tasks error constraints algorithms scheduling imprecise computations algorithms scheduling imprecise computations minimize total online scheduling imprecise computations minimize scheduling imprecise hard realtime jobs cumulative algorithms scheduling imprecise computations timing constraints minimize maximum analysis timedependent plan ning deliberation scheduling problem solving timeconstrained environments constructing utilitydriven realtime systems using anytime algorithms operational rationality compilation anytime algorithms circa cooperative intelligent realtime control architecture tr ctr dongin kang richard gerber manas saksena parametric design synthesis distributed embedded systems ieee transactions computers v49 n11 p11551169 november 2000 k subramani analysis totally clairvoyant scheduling journal scheduling v8 n2 p113133 april 2005 hakan aydin rami melhem daniel mosse pedro mejaalvarez optimal rewardbased scheduling periodic realtime tasks ieee transactions computers v50 n2 p111130 february 2001 higinio moramora jernimo morapascual juan manuel garcachamizo antonio jimenomorenilla realtime arithmetic unit realtime systems v34 n1 p5379 september 2006 scott brandt gary j nutt flexible soft realtime processing middleware realtime systems v22 n12 p77118 janmarch 2002 vinay kanitkar alex delis realtime processing clientserver databases ieee transactions computers v51 n3 p269288 march 2002