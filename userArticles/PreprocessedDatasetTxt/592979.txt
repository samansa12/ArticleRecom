web proxy acceleration numerous studies show miss ratios forward proxies typically least 4050 paper proposes evaluates new approach improving throughput web proxy systems reducing overhead handling cache misses namely propose frontend web proxy high performance node filters requests processing misses forwarding hits new cacheable content proxy requests filtered based hints proxy cache content system called proxy accelerator achieves significantly better communications performance traditional proxy system instance accelerator built embedded system optimized communication http processing kernelmode http server scalability web proxy cluster size achieved using several accelerators use analytical models tracebased simulations real implementation study benefits implementation tradeoffs new approach results show single proxy accelerator node front 4node web proxy improve costperformance ratio 40 hintbased request filter implementation choices affect overall hit ratio available implementation hint management module integrated web proxy software presented experimental evaluation implementation demonstrates associated overheads small b introduction proxy caches large internet service providers receive high request volumes numerous studies show miss ratios often least 4050 even large proxy caches 7912 consequently reduction cache miss overheads result significant throughput improvements proxy caches experiencing high request volumes based insight experience web server acceleration 15 paper proposes evaluates new approach improving throughput web proxy systems namely propose frontend web proxy system high performance node filters requests processing misses forwarding hits new cacheable content proxy web proxys missrelated overheads reduced receiving cacheable objects pushed accelerator permanent connections consequently proxy use released resources service increased number hits figure 1 illustrates interactions proxy accelerator web proxy nodes clients web servers hints cache webserver client 30 webproxy gbytes 35 35 noncacheable content hits proxy accelerator figure 1 accelerated web proxy architecture accelerator extended http server running embedded operating system optimized communication like web server accelerator described 15 generalpurpose operating system kernelmode serviceinterrupt level like netfinity web server accelerator16 accelerator main memory cache mainly used store content forwarded web proxy accelerator filters requests based summary proxy cache content called hints hints maintained based information provided proxy nodes information derived accelerators decisions hint representation update mechanism important factors performance gains enabled proposed proxy acceleration method due related requirements system network resources intrinsic tradeoff resource usage information accuracy previous research considered use location hints context cooperative web proxies 8192210 system applies approach management clusterbased web proxy addition experiment new hint maintenance mechanisms specifically designed interaction front end cluster homogeneous nodes work extends set solutions proxy cache redirection 1131417 relevant comparison proposal 14 front end identifying processing requests noncacheable content extending functionality proxy accelerator processes requests content cached web proxy including cacheable content currently proxy cache building top previous research clusterbased network services 42 proxy acceleration method overcomes intrinsic limitations contentbased routing components integrating several accelerator nodes front web proxy cluster paper use analytical models conjunction simulations study potential performance improvement proxy acceleration scheme evaluate impact several hint representation maintenance methods throughput hit ratio resource usage addition present evaluate performance impact actual implementation hint management component web proxy application analytical study reveals throughput improvement signif icant instance accelerator achieve order magnitude better throughput web proxy node communications operations embedded system considered 15 single accelerator node boost throughput fournode web proxy 100 simulations validate appropriate hint representations update protocols proposed acceleration method offload 50 wp load impact observed hit ratio addition evaluation implementation shows overhead incurred hint management significant impact clientperceived response times throughput paper overview rest paper structured follows section 2 describes architecture accelerated web proxy section 3 analyzes expected throughput improvements analytical model section 4 evaluates impact hint management several web proxy performance metrics tracedriven simulation section 5 presents implementation hintmanagement module web proxy application evaluates performance impact section 6 discusses related work section 7 summarizes results 2 accelerated web proxy typical highperformance web proxy systems consist cluster nodes running web proxy application frontend node distributes requests application nodes front endbased solutions improving performance web proxy systems restricted mainly balancing load based criteria like number active connections cpu utilization inherently unpredictable content mixtures web proxy caches typical contentbased routing policies distinguish origin servers andor object types less beneficial however contentbased scheme distinguishing cacheable noncacheable content proved bring significant performance improvements web proxy systems combined offloading processing requests noncacheable content proxy nodes front end 14 paper propose offload proxy node overheads extending functionality frontend namely extended frontend called proxy accelerator pa contentbased router distinguish cache hits misses based information proxy cache content case cache hit pa forwards request web proxy wp node contains object either tcp splicing handoff 1721 case cache miss pa sends request origin web site bypassing wp receives object web site pa replies client appropriate pushes object wp node selected based load balancing criteria wp wp wp wp pa pa web proxy cluster requests hints router servers clients figure 2 interactions web proxy wp cluster several proxy accelerators pa enabling element new frontend functionality pas information content wp cache henceforth called hints possible solutions hint representation update mechanism discussed later section evaluated tracebased simulation section 4 pa includes main memory cache storing content waiting pushed wp addition pa cache store duplicates objects wp cache requests satisfied pa cache never reach wp reducing load wp figure 1 illustrates interactions pa fournode wp cluster pa wp nodes connected permanent tcp connections request handoff 17 hint updates content push notice wp nodes still interact web sites occurs pa filter accurate cache objects revalidated scalability system may include several pas figure 2 router balances load among pa hints wp nodes therefore pa appropriately forward incoming hits policy new content distribution may simple roundrobin pa built stock hardware runs embedded operating system optimized communication alternatively pa built extended kernelmode http server either way pa achieve order magnitude better throughput web proxy node communications operations wp node would typically run software extended hint maintenance distribution handoff tcpip connections url requests pushing objects pa caches hint representation previous research considered several hint representations consistency protocols hint representations vary schemes provide accurate information 2210 schemes trade accuracy reduced costs eg memory communication requirements lookup update study consider two representations one provides accurate information one provides approximate inaccurate information accurateinformation scheme called directory scheme uses list object identifiers including entry object known exist wp cache implementation list represented hash table 1022 hint space hint entry figure 3 hint representation based bloom filters approximateinformation scheme based bloom filters 5 filter represented bitmap henceforth called hint space see figure 3 several hash functions register object hint space hash functions applied object identifier corresponding bits generically called hint entries set hint space hint lookup positive entries associated object interest set hint entry cleared object left cache whose representation includes entry therefore cache owner ie wp node maintains collision counter entry updated whenever related object added removed cache collision counter reaches maximum value longer updated entire hint space recomputed number overflowed counters reaches threshold pa maintains bloom filter wp nodes hint consistency hint consistency protocol ensures information pa site reflects content wp cache protocol choices vary several dimensions entity identifies updates protocol initiator rate update messages exchanged information previously proposed solutions updates identified either wp henceforth called wponly updates 819 contentbased router pa 17 methods significant likelihood wrong request redirection decisions first method may result false misses inherent delay updates second method may result false hits information objects removed cache propagated router false misses also possible entries router directory discarded periodically due space limitations paper propose evaluate method called eager hint regis tration attempts address drawbacks previous methods namely pa wp identify record hints pa pushes object wp node eagerly registers object exists corresponding cache side effect method enables reduction update traffic sent wp node namely wp node send update notifications objects received pa small exception due asynchronous communication pa wp discussed section 5 respect protocol initiator previously proposed solutions address wponly updates updates pulled hint owner ie pa 19 pushed cache owner ie wp 82210 respect update rate previous proposals consider update messages sent fixed time intervals 19 fixed number cache updates 8 exchanged information may incremental addressing updates occurred since previous message 10819 copy entire hint space 8 proxy accelerator cache pa cache may include objects received web sites pushed associated wp nodes selecting pa cache replacement policy consider objects pa cache also exist wp cache consequently pa cache replacement policy focused minimizing networkrelated costs shown appropriate wp caches policies maximize hit ratio based hotness statistics object sizes expected enable better pa performance policies like greedydualsize 6 following sections evaluate throughput potential proposed proxy acceleration method impact several hint implementation choices 3 expected throughput improvements major benefit proposed hintbased acceleration web proxies throughput improvement analyze throughput properties scheme analytic model varying number wp pa nodes pa functionality cache size wps pas cpu speeds system modeled network mg1 queues servers represent pas wp cpus disks web site serviced events represent 1 stages processing client request eg pa miss wp hit disk access 2 hint cache management operations eg hint update object push event arrival rates derive rate client requests likelihood request switch one processing stage another likelihood various events cache hits disk operation derived recent studies cache performance web content models 2314618 overhead associated event includes basic compute overhead io overheads eg connect receive message handoff operating system overheads eg context switch basic overheads identical pa wp io operating system overheads different namely pa overheads correspond embedded system used web server acceleration 15 200 mhz power pc pa incurs 514sec miss overhead ie 1945 missessec 209sec hit overhead 4783 hitssec wp overheads derived 17 300 mhz pentium ii incurs 2518sec miss overhead ie 397 missessec 1392sec hit overhead 718 hitssec overheads assume 8 kbyte objects following parameters fixed study 1 40 noncacheable content ratio 25 miss ratio 2 tcp handoff used pa client connections upon positive hint lookup 3 directorybased hints 1 hour incremental updates 4 disk io required 75 wp hits 5 one disk io per object 6 four network ios per object transmission 7 25 wp hits pushed pa pa caches hot objects 8 30sec wp context switch overhead unless otherwise specified pa nodes 450 mhz cpus wp nodes 300 mhz cpus costs hintrelated operations derived implementation simulationbased study see section 4 hintbased acceleration improves throughput costperformance ratio figure 4 presents expected performance traditional wpcluster throughput wp nodes traditional figure 4 throughput number wp pa nodes service pa cache1030507090costperformance improvement wp nodes wp300mhz pa300mhz wp300mhz pa450mhz wp300mhz pa700mhz figure 5 costperformance improvement number speed wp pa nodes service pa cache clusters enhanced four pas pas service objects cache plot illustrates hintbased acceleration enables significant wp throughput improvements instance single pa node increase performance 2node wp three times 4 node wp two times two pas 4node wp achieve higher throughput 16node wp however consistent previous studies contentbased routing 4221 plot illustrates pa becomes bottleneck large wp clusters costperformance improvement enabled proposed scheme rele vant instance figure 5 illustrates assume cost pa throughput wp nodes traditional 1 pa noncacheable 2 pas noncacheable figure 6 throughput hintbased acceleration noncacheable redirection service pa cache200040001 throughput wp nodes traditional pa hit 0 pa hit 10 figure 7 throughput pa services objects cache almost wp node costperformance improvement achieved single pa 60 2node wp 40 4node wp performance benefits scheme increase difference wp pas cpu speeds illustrated figure 5 case 700 mhz pa cpus figure 5 also illustrates 2node accelerator benefits relatively large wp configurations instance costperformance improvement 2 pas lower 1 pa 2node wp hintbased acceleration benefit redirection noncacheable objects figure 6 illustrates appropriately sized wp clus ters proposed hintbased acceleration enable better performance previously proposed policy redirecting noncacheable objects 14 workload 25 miss ratio 2node wp cluster attain double throughput levels frontend identify process request cache misses along requests noncacheable content palevel caches benefit lowperformance wps figure 7 illustrates effect pa cache marginal particular ratio noncacheable content significant like selection experiment parameters summarize hintbased web proxy acceleration may lead significant performance costperformance improvements pa nodes achieve much higher throughput network io wp nodes new scheme improves upon previously proposed redirection noncacheable content appropriately sized wp clusters 4 impact hint management section evaluate hint representation consistency protocol affect performance accelerated web proxy focus performance metrics hit ratio throughput cost metrics memory computation communication requirements performance cost metrics depend various characteristics hint management mechanism see table 1 instance lookup overhead affects longterm pa throughput also false miss decisions pa filter cause undue network loads response delays table 2 summarizes differences representation methods update protocols introduced section 2 instance lookup overhead constant bloom filterbased scheme directory scheme depends con text namely well hash table balanced similarly eager registration results false miss wponly registration amount false misses increases update period study identify compare relevant trends representation methods update protocols study conducted tracedriven simulator segment home ip web traces collected uc berkeley 1996 11 traces include 557 million client requests cacheable objects period 1267 days number objects 168 million total size 17 gbytes factors factors considered study following 1 pa table impact hint management choices characteristic affects memory wp wp memory hit ratio memory pa pa cache hit ratio update period longterm throughput update period wppa shortterm throughput lookup time pa longterm throughput false hits wp load false misses network usage table selected method characteristics characteristic representation directory bloom filters memory wp none ohint space memory pa oobjs wp ohint space lookup overhead contextdependent constant false hits none oobjs wp protocol wponly eager reg false misses perioddependent none pa computation onoff large bursts smaller bursts wp memory 2 hint representation 3 hint update protocol 4 update period namely consider configurations 0251 gbyte pa memory memory bloom filterbased scheme vary size hint space 0510 mbytes number hash functions hash function returns remainder hint space size divided integer obtained combination four bytes object identifier due limitations associated trace encoding object identifiers composed 16byte md5 representation url 4byte encoding server name restriction makes impossible accurate evaluation resource requirements associated bloom filterbased scheme finally experiment update periods range 1 sec 2 hours fixed parameters experiment push updates comparison pull updates push updates allow better control hint accuracy 8 lower io overheads addition experiment incremental updates consider appropriate entire copy updates context hint representations system parameters considered study wp cache replacement policy lru pa cache replacement lru bounded replacement burst according policy incoming object cached would cause given number objects removed cache policy expected perform well based studies show small objects large contribution hit ratio 183 caches garbage collection invoked new object accommodated 41 cost metrics memory requirements main memory requirements hint mechanism derive hint metadata message buffers used hint consistency protocol hint metadata directory scheme metadata maintained wp pa requirements increase linearly population wp cache instance implementation 68byte entries metadata 70 mbytes 10 gbyte wp cache contrast bloom filterbased scheme metadata maintained pa wp independent cache size pa metadata large hint space multiplied number wp nodes wp metadata large hint space multiplied size collision counter eg 8 bits hint consistency protocol message buffer storage space required wp site hint consistency protocol increases rate wp cache updates period consistency protocol directory scheme update entry unpredictable length includes full name object bloom filterbased scheme update corresponds hint entry update represented 5byte data structure cache update result many hint entry updates hash functions filter computation requirements computation requirements associated acceleration scheme result mainly request lookup processing update messages addition minor computation overheads may incurred wp pa upon cache update lookup overhead directory scheme lookup overhead depends distribution objects hash table buckets bloom filterbased maximum entries per update message wp memory mbytes bloomfilter wponly bloomfilter eager wponly figure 8 variation maximum number entries per update message 1 hour period 256 mbyte pa 4 mbyte hint space 4 entries per object01030507 1000 2000 3000 4000 5000 6000 7000 8000 9000 1000011000 total entries per update payload mentries wp memory mbytes bloomfilter wponly bloomfilter eager wponly figure 9 variation total number update entries 1 hour update period 256 mbyte pa 4 mbyte hint space 4 entries per object scheme lookup overhead predictable depending mainly filter parameter specifically overhead includes transformation object name one integer values computation hash functions selection test corresponding bitmap entries 332 mhz powerpc transformation object name md5 representation takes 9sec per 55 byte string segment four simple hash functions used bloom filter implementation overhead hash function computation bitmap lookup 1sec overall lookup overhead lower 10 expected cache hit overhead 300mhz pa see section 3 hit memory mbytes directory bloomfilter figure 10 variation overall hit ratio wp configuration 512 mbyte pa bloom filter hint consistency protocol amount computation triggered receipt hint consistency message depends number update entries included message hint entry collisions bloom filterbased scheme results half load directory scheme 160byte object iden tifiers variation maximum average message sizes presented figure 8 figure 9 illustrates trend figures also illustrate benefit eager registration approach hint schemes average eager hint registration reduces half computation loads similar trends observed communication requirements consistency protocol note large maximums observed figure 8 due large wp cache replacement bursts 2300 objects 42 performance metrics hit ratio characteristic hint mechanism affects observed hit ratio likelihood false misses typically false misses due hint representation update delays experiments selected hint representations false misses result update delays expected likelihood false misses increases update period figure 11 illustrates trend indirectly ratio requests directed wp traditional update mechanism decreases increase update period eager hint registration reduces number observed false misses less impact bloomfilter scheme collisions 262728290 1000 2000 3000 4000 5000 6000 7000 8000 requests wp hint update period secs eager bloomfilter wponly bloomfilter eager directory wponly directory figure 11 variation wp requests update protocol period 256 mbyte pa 4 gbyte false hits hint space mbytes 6 gbyte wp 8 gbyte wp figure 12 variation false hit ratio hint space wp cache 512 mbyte pa amount hint metadata wp relevant impact overall hit ratio ie hits pa wp caches ratio metadata wp memory large small wp cache sizes see figure 10 pa metadata significant impact objects removed pa cache pushed wp rather discarded throughput extent throughput improvement depends well pa identifies wp cache misses characteristic reflected likelihood false hits affected representation method consistency protocol hint representation directory scheme false hits bloom false hits wp memory mbytes figure 13 variation false hit ratio hint entries perobject 512 mbyte pa filterbased scheme likelihood false hits increases hintspace collision illustrated figure 12 occurs hint space decreases number objects wp cache increases notice falsehit ratio constant hint space increases beyond threshold threshold depends wp cache size effect due characteristics selected hash functions likelihood false hits also depends number hint entries per object figure 13 illustrates variation observed experiments filters 35 hash functions typically ratio false hits decreases number hint entries per object hint space occupancy high inversions may occur due collisions hint consistency protocol impact update period false hit ratio significant configurations frequent wp cache updates eg systems small wp caches figure 14 illustrates trend hint schemes instance bloom filters difference falsehit ratios observed 1hour 1sec updates 007 4 gbyte cache 004 6 gbyte cache comparing two schemes relative impact update period almost identical request response time besides overhead hint lookup update accelerated wp architecture affect average request response time reduction hit ratio wp pa mainmemory caches besides amount metadata available main memory hit ratios depend cache replacement policies considering pa cache figure 15 illustrates 12340 1000 2000 3000 4000 5000 6000 7000 8000 false hits hint update period secs bloomfilter 4 gb wp bloomfilter 6 gb wp figure 14 variation false hits update period 256 mbyte pa 4 mbyte hint space40506070 hit replacement bound total hits 256 pa pa hits 256 pa total hits 512 pa pa hits 512 pa figure 15 variation hit rate replacement bound 1 unbounded replacements bloom filter 6 gbyte wp 4 mbyte hint space bounded replacement policy enables better pa hit ratios without reducing overall hit ratio instance limiting replacement burst 10 objects enables 5 larger pa hit ratios unlimited burst see bound 1 average replacement burst significantly smaller maximum eg 3 vs 2300 experiments summary trading accuracy bloom filterbased scheme exhibits lower computation communication overheads however metadata wp node may reduce memoryhit ratio general hint lookup overheads small respect typical request processing overheads overheads predictable bloom filterbased scheme eager hint registration reduces updaterelated overheads prevents hit ratio reductions caused update delays false hit ratio consequently throughput significantly affected hint representation update period bloom filterbased schemes ratio increases exponentially hint space contention 5 implementation hint management web proxy nodes implementation hintbased accelerated web proxy infrastructure built extending threadbased web proxy application kernelmode http server functionality hint management content push implementation hint mechanism based bloom filters eager registration periodic updates implementation makes possible flexible system configuration namely web proxy node interact multiple accelerators accelerator node interact multiple proxy nodes hint representation size hint space customizable initialization time collision counters take one byte bloom filter six hash four applied object name two origin server ip address object name 0 1 transformed integer value evaluating polynomial p fixed prime number overhead name transformation 095sec first 10 bytes 07sec additional 10 bytes measured 332 mhz powerpc note although less effective md5 avoiding collisions solution characterized lower computation overheads clearly benefit proxy accelerator performance hash functions equal modhintspace applied resulting 4byte integer three permutations bytes similarly modhintspace function applied 4byte integer representing ip address one permutation bytes overhead computing hash functions 55sec wp several nodes corresponding bloom filters represented pa interleaved bitmaps representation corresponding bits filters placed consecutive memory locations see figure 16 comparison original representation bloom filter represented separate memory segment interleaved representa hint entry hash1obj hint space figure 16 hint representation interleaved bloom filters 4 wp nodes tion characterized predictable lookup overheads independent cluster size interleaved representation lookup overhead 4bit entry constant 128sec 332 mhz powerpc original representa tion overhead varies 119sec single node lookup 439sec four node lookup hint update protocol hint management implementation uses eager hint registration protocol introduced section 2 namely accelerator registers hints pushes objects towards proxy node proxy node collects hint updates periodically sends accelerator accelerator receive updates resulting cache updates content pushed wp node exception made hint entry set push operation previous clear reached accelerator pushed object set entry representation appropriately handled situation may lead false misses identify type situation proxy updates labeled pushed content sent accelerator carry label recent update enacted proxy web proxy software extension extension web proxy software three components first component represents update interface invoked proxy threads handling client requests objects added permanently removed cache cache operations remove objects accommodating newer versions result hint updates calling thread indicates object name origin server corresponding cache operation resulting hint updates recorded update buffers update buffer gets full released transmission update buffers organized active set waiting set updates recorded buffers active set buffer gets full replaced one waiting set active set includes buffer active accelerator local proxy node updates registered active buffer associated node originated operation specifically updates resulting cache add operation registered buffer proxy node received content origin web server otherwise update registered buffer accelerator pushed object proxy cache updates cacheremove operations registered buffer proxy node scheme prevents replication update representations proxy interacts several accelerators permits use multicast available second component represents proxy accelerator interface component consists three threads one thread listens incoming connections accelerators one thread handles accelerator requests transmission entire hint space third thread handles periodic updates accelerators may request complete copy hint space initialization periodic update thread disseminates registered accelerators update buffers released transmission buffer released thread transmits currently active batch update buffer third component web proxy extension push handler component receives new content stores cache content sent http format post request requires proxy node duplicate header processing already done accelerator decouples implementations proxy cache accelerator order hide latency related io operations multiple push connections concurrently active accelerator proxy experimental evaluation remainder section present experimental evaluation overhead hint management experimental evaluation done web polygraph proxy performance benchmark 20 component benchmark polyclt polysrv web proxy proxy accelerators run separate nodes switched ethernetbased lan selected traffic model meant stress hintrelated component web proxy application namely request model characterized 75 miss ratio content size fixed 2 bytes results headers 370 bytes per request requests issued polyclt node besteffort mode meaning new request sent soon reply previous one received experiment consists 100000 requests experiments web proxy configuration varied original ie hint collection updates hint collection updates hint collection updates one two accelerators experiments role accelerators reduced receiving hint updates requests received directly web proxy therefore pass accelerator update period 5 min web polygraph statistics response times observed client show distributions hit miss response times almost identical 98percentile tested configurations 99percentile miss response times experienced configurations active hint management differ less 1 performance original configuration hit response times 99percentile difference less 10 performance original configuration throughput observed client unchanged experiment active accelerators 18 lower experiments active accelerators web proxy internal monitoring instrumentation collected statistics overhead hint collection proxy accelerator active overhead includes hint computation segment collection batch update buffers statistics show minimum 31sec median 4sec 95percentile 123sec results demonstrate hint collection update protocol negligible impact performance web proxy node 6 related work previous research considered use location hints context cooperative web proxies 8191022 papers hints help reduce network traffic efficient web proxy cache cooperation extending approaches use hints improve throughput individual web proxy addition propose evaluate new hint maintenance techniques reduce overheads exploiting interactions cache redirector associated cache web traffic interception cache redirection relates approach architectures web server accelerators 15 acedirector alteon 1 dy nacache infolibria 13 content smart switch 14 lard 17 ability integrate proxy acceleratorlevel cache renders approach similar architectures central element embedded systembased cache hierarchical caching architecture 13 front end web server 15 proxy accelerator extends approach bypassing web proxy proposed 14 besides noncacheable objects accelerator identify misses process locally trading throughput routing compo nent bottleneck resource approach boost even throughput bottleneck proxy nodes furthermore approach similar redirection methods used architectures focused contentbased redirection requests web proxy nodes 117 however approach enables dynamic rather fixed mappings objects wp nodes1 contrast method 17 redirection cause caching multiple object replicas independent client request patterns 7 conclusions based observation miss ratios proxy caches often relatively high 7129 developed method improve performance clusterbased web proxy shifting cache missrelated functionality executed proxy accelerator extended contentbased router implemented embedded system optimized communication consequently web proxy service larger number hits proxy acceleratorbased system achieve better throughput traditional web proxies 181917 systems web proxy bypassed noncacheable objects 14 addition moderate load response time improved proxy accelerator main memory cache 1513 study shows single proxy accelerator node order magnitude better throughput communication operations proxy node 1516 improve costperformance ratio 4node web proxy 35 study shows eager registration must bloom filterbased scheme appropriate directory scheme large wp clusters pa wp nodes comparable power implementation accelerated web proxy node demonstrates overhead added hint management significant comparison typical proxy node overheads r alteon web systems scalable contentaware request distribution clusterbased network servers proceedingsproc changes web client access patterns distributed packet rewriting application scalable server architectures spacetime tradeoffs hash coding allowable errors measured access characteristics world wideweb client proxy caches proceedingsproc scalable widearea web cache sharing protocol proceedingsproc performance web proxy caching heterogeneous bandwidth environments taste crispy squid uc berkeley home ip http traces httpwww system design issues internet middleware services deductions large client trace dynacache weaving caching internet 3rd international www caching workshop year1998year design performance web server accelerator ibm netfinity web server accelerator v2 performance study squid proxy http10 www journal 12 year1999year cache digests httpsquid high performance benchmarking web polygraph httpircache design alternatives scalable web server accel erators beyond hierarchies design considerations distributed caching internet scale performance cooperative web proxy caching tr ctr chihung chi hongguang wang generalized model characterizing content modification dynamics web objects web content caching distribution proceedings 8th international workshop kluwer academic publishers norwell 2004 yu state art locally distributed webserver systems acm computing surveys csur v34 n2 p263311 june 2002