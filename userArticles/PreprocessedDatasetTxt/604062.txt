lessons learned modeling schizophrenic depressed responsive virtual humans training paper describes lessons learned developing linguistic cognitive emotional gestural models underlying virtual human behavior training application designed train civilian police officers recognize gestures verbal cues indicating different forms mental illness verbally interact mentally ill schizophrenia paranoia depression modeled application linguistics application quite complex language grammars captured range syntactic structures semantic categories cognition great deal augmentation planbased transition network needed model virtual humans knowledge emotions gestures virtual human behavior based expertvalidated mapping tables specific mental illness paper presents five areas demanding continued research improve virtual human behavior use training applications b figure 1 avatalk architecture language processor language processor maps spoken input underlying semantics produces responsive output six components 17 parsing system uses minimum distance translator parser tries match spoken words closest grammatical sentence defined currently active language grammar 16 grammars grammar specifies acceptable spoken statements representation language quite free literally sentence encoded grammar figure 2 sentence help find spaceship return semantic statement asklocationship use semantic categories categorize syntactic components efficient parsing strategy greatly assists handling ambiguity main disadvantage domain specific behavior engine dynamically selects grammars active based current context language interpretation considerable ambiguity inherent language reliance linguistic context makes natural language processing difficult instance taken alone little meaning following command put knife makes sense knife ground environment multiple knives knife also ambiguous resolve ambiguities via dynamic context switching use utterance expectations sorted likelihood 41 ask please whereis ask whereis please damn 04 please please 02 please would please 03 whereis help find whereis find find find locate loc space ship ship loc rest room wc space mother space space figure 2 sample language grammar reliability scores compute likelihood correctly understood particular utterance factoring speech recognizer score goodness fit audio signal acoustic model spoken language parser score minimum distance parser returns score based number insertions deletions needed parse string words using language grammar expectation score based context goal weight certain critical goals may require exacting verification past recognition rate depending dynamic threshold system ask user repeat himselfherself paraphrase believes said ask confirmation accept interpretation continue emotional social tagging extended semantic grammars applying tags carry information related emotional social behavior engine state variables figure 2 symbol used indicate relative politeness different phrases also mapped confusion satisfaction humor time constraint tags applications values range 10 impolite 10 polite specified word phrase neutral value related attribute parsing values combined produce final score behavior engine behavior engine uses semantic interpretation generated language processor assist determining virtual human behavior current underlying architecture behavior engine augmented transition network atn typical atn often multiple conditional transitions leading network nodes least one transition condition defaults true multiple transition conditions satisfied particular node one selected random one important set variables maintain atn cognitive generally domainspecific variables variables used tracking conversational topics interface language processor expect generate relevant statements another set tracks physical physiological characteristics certain applications use physiological models provide continuous realtime cardiovascular respiratory pharmacological simulation 23 virtual human exhibit realtime medical signs symptoms turn affect behaviors another set emotion variables keep track base set emotions personality traits virtual human simulation combinations values base set used define emotional state descriptions instance base set use anger confusion disgust fear happiness humor politeness sadness surprise timecrunch volatility define emotions based well constants small medium large figure 3a emotional states iteratively based emotions emotional states using boolean expressions figure 3b emotional state descriptions used node condition statements node action state ments allow modification emotional state figure 3c instance node visited user commits error virtual human distracted action virtual environment value emotion values may change thus emotional state virtual human dynamic depends current state environmental constraints user performance choice base set somewhat arbitrary though used core commonly accepted set 113440 equations used define emotional states derived possible research 1039 otherwise expert advice common intuition application demands adhoc experimentation distrust sizeableangerfearmediumsurprise satisfaction verylargehappinessmediumanger b certain distrust extremelylow complacent satisfied notconfused hostile angry disgusted notfriendly c irk anger volatilitytrivial pressure timecrunch volatilitylarge figure 3 emotional state computations visualization engine visualization engine produces 3d virtual humans target images created extremes emotional expressions gestures phonemic facial movements body movements feed morphing algorithms create realtime movements morphing original image morph targets instance create happy morph target generate face completely happy level original image target figure 4a blend morph targets together combine 50 sarcastic face 75 distrustful face 90 handwave figure 4b normal 100 happy 50 happy 25 happy b50 sarcastic 75 distrustful 90 hand wave 3 combined figure 4 happy combined facial expressions behavior engine produces emotional gesture expressions based state simulation instance virtual human may distance salutation node instructed wave 8 commands sent directly visualization engine additional mechanism within visualization engine automatically generates appropriate facial expressions gestures based virtual humans emotional state analysis textual structure virtual humans utterances thus angry virtual human may produce angry expression even behavior engine explicitly specify action similarly positive negative responses invoke head nods shakes emblems 18 predefined terms invoke propositional gestures complement utterance 5 beat gestures inserted 5 eye movements reflect gazing modeled prototypical human behavior 8 finally behavior visualization engines insert small random head body movements add realism architecture allows us support synthesized recorded speech employ offtheshelf texttospeech synthesiz ers using extent possible virtual humans emotional state change synthesis parameters rate speech volume speech synthesizer great advantages flexibility design unfortunately available speech synthesizers lack fidelity real human speech initial impressions users tend negative distracting continued use users tend adapt stilted speech blatant mispronunciation fore applications user short interactions system use recorded voice instead synthesized voice rather try piece together fragments recorded sentences generally record entire utterances recordedspeech grammars used speech generation pointers associated sound files well gestural commands method much less flexible synthesized speech resulting simulation fidelity greatly increased application justtalk teaches students basic techniques managing encounters mentally ill work series oneonone scenarios simulated subject 12 also teaches look indications particular forms mental illness adapt responses appropriately observations virtual environment dialog virtual subject student must stabilize situation decide whether release detain subject justtalk virtual environment sidewalk front hardware store bench patrol car parked side street next hardware store subject white male adult justtalk implemented five scenarios schizophrenic hearing voices paranoid fears police conspiring federal agents normal individual agitated nearly run depressed individual become suicidal marital child custody problems normal individual depressed trying deal marital child custody problems session justtalk starts dispatch responding report young adult male reported behaving erratically entering street almost getting hit car virtual environment scene displayed scenario window first user expected introduce subject although novice may skip step start asking questions demanding responses introduction user interview subject interactions subject justtalk verbal teach apprehending even officer safety techniques either subject user may initiate dialog sometimes subject may withdrawn user open con versation times subject may agitated start talking user start user uses conversation stabilize situation assess subject anchored reality determine action needed eg leave transport subject mental health facility subdue subject user stabilize situation talking subject determine problem getting subject agree solution ie asking subject taking prescription drugs asking hasnt taken dose recently persuading subject reinitiate medication else visit mental health facility talking subject acknowledging subjects delusions real subject offering help agreeing delusions user destabilize situation using inflammatory language challenging delusional hallucinatory statements authoritative commanding language actually escalate intensity interaction particularly subjects paranoid distrustful afraid language conciliatory expressions understanding requests rather commands result reduced tension user assess subject delusional asking subject mental illness history listening delusional hallucinatory statements seeing subject respond rationally questions problem subjects physical status users also make note physical gestures head movements eye movements body language often subject hearing voices sounds taking antipsychotic medications visible side effects display distinct physical signals initial behavioral models justtalk application set create virtual human acts schizophrenic paranoid depressed sad stressed though used past virtual human intended pedagogical agent 2228 instead encounter take place virtual environment premise interacting public space law officer achieve virtual human required first understand normal calm aware attentive individuals would behave similar situation modify normal behaviors appropriate scenario basis agent research threequarters verbal utterances accompanied gestures 6 addition eye gazing body posture play crucial roles interactions behavior engine attempts mimic activities make virtual human appear realistic gestures majority representational iconic deictic emblematic metaphoric rest beats idle motions 6 iconic movements meant convey information spatial relationships concepts 5 deictic movements like pointing used mainly discussing shared task 5 emblematic gestures culturally specific nod meaning yes thumbsup good 18 metaphoric gestures commonly accompany new segments communicative acts thus like representational gestures rely semantic knowledge 56 fact representational gestures often begun utterance even begins soon speaker knows going say 6 beat gestures contrary rely syntax prosody occurring heavily emphasized words occasions turning floor another speaker though may also convey information novelty discourse 5 idle motions habitual actions winding checking ones watch lighting cigarette putting hands pockets manipulators stretching wetting lips scratching head randomly executed throughout interaction 18 eye gazing helps regulate flow conversation looking straight conversational partner utterance implies seeking feedback 5 staring meant intimidate 6 averted gaze indicate sadness depression embarrassment confusion 6 blink rates change based emotion normal blink per four seconds increases one per two seconds individual nervous decreases one per six seconds angry 31 together facial expression eye gazing provide meaning initiation termination conversation turn taking feedback 5 instance inviting contact involves sustained glance smile breaking away involves glancing around 8 similarly introduction often includes tilting head giving turn includes looking partner raising eyebrows wanting turn includes raising hands view looking partner planning response involves looking away lowering eyebrows 89 positive feedback often involves nodding negative feedback may involve gazing away increased blinking rate 9 degree eye opening position eyelids relative irises position shape eyebrows arched raised drawn together facial movements used indicate emotion 26 instance surprise shown wide open eyes lower eyelids drawn raised eyebrows mouth open wide 931 similarly fear shown wide open eyes andmouth upper eyelids raised lower lids tensed perhaps step back skin paling sweating 9 happiness shown wrinkles lower eyelids lids raised tensed smiling head lifted open body orientation 618 whereas contempt shown sneer wrinkled nose wrinkles eyes upper eyelids partially closed body turned side 9 precise position body one parts ie posture compared determined system references holds great meaning instance bodily attitude prostration head bent shoulders falling typical unease 18 postural positions well described include attentive relaxed insecure confused angry joyful mocking insulting rejecting welcoming 18 visualization based games quickly came realization rendering engine powerful flexible enough satisfy requirements normal virtual human much less mentally ill virtual human realistic gestures turns least important conversation simply emotional expressions 79 instance virtual asthma patient application 21 whenever virtual human delineated list items eg colds flu exercise perfumes hair spray pollens grass weeds house dust bother wanted tap hands count fingers modeling effort required allow delineate gesture prohibitive similarly bank teller training application demonstrated 15 wanted customer hand identification check settled magical appearance items requested visualization engine lacked capabilities designed primarily facial expression began developing avatalk envisioned basically talking head user interacted products capable portraying range emotion felt desirable invested rendering engine demand users though much complete environment could achieve level engagement needed talking head instance told justtalk subject matter experts schizophrenic person pace point move constantly depressed person sit rock becomes agitated revised behavioral models though discuss linguistic cognitive emotional gestural models separately fact interact knowledge new researchers found emotions interact social perceptual motivational motor systems 1025 spell interactions developed expert help series tables guide virtual human behavior table 1a shows sample table emotional state changes based user input table 1b shows sample table determination reply type based current emotional state table 1c shows sample table gestures also based current emotional state implemented tables atn conditionaction statements action definitions definitions emotional state changes atn determination next behaviors similar implementation described 38 linguistic models extended linguistic analyses considerably talk application user input built quite complex language grammars captured range syntactic structures semantic categories virtual human output devised extensible method labeling phrases increased productivity complexity capability reuse table 1 mapping tables emotional state transitions depressed individual based user input current state depression next state depression drivers personal request inform help statement concern depressed discouraged discouraged threat insult profanity personal request query inform help statement concern threat insult profanity depressed discouraged command impersonal query personal request inform help statement concern discouraged depressed discouraged command impersonal query threat command impersonal query threat reply mode map schizophrenic anger fear appeased ticked angry enraged terrified afraid scared deny deny deny deny question question challenge challenge respond respond challenge challenge respond respond challenge challenge c gesture map paranoid question replies anger fear appeased ticked angry enraged terrified afraid scared na run away run away run away lean forward look brace arms stand behind bench lean forward look forward brace arms stand behind bench torso upright tilt head arms sides pace get ready fight torso upright look hands stand bench ready comply torso rocks tilt head hands stand bench torso upright tilt head cross arms pace get ready fight torso upright tilt head hands sit ready comply torso upright tilt head cross arms stand bench ready comply torso upright tilt head hands hips pace na others 32 applications decomposed interaction introduction interview resolution found given domain introduction rather formalized instance clinical setting 2123 practitioner usually begin standard hello whereas formal field interview setting 14 interviewer taught begin scripted phrase hello name represent rti nonprofit research institute located north carolina neighborhood conducting survey sponsored received letter justtalk officer expected introduce himselfherself heshe would man street interview officer expected deescalate potentially explosive situation using calming polite responsive language given appropriate user input virtual human become calm composed responsive perhaps demonstrating stopping pacing sitting topics officer subject generally discuss include event leading dispatch subjects name family illness medications applications resolution normally simple goodbye thank consultation subjectmatterexperts settled five possible resolutions action taken officer says goodbye subject runs away subject verbally attacks officer subject descends catatonic state subject persuaded get patrol car taken mental health facility diagnosis observation treatment avatalk applications use spoken natural language interaction 30 textbased interaction 29 observed considerable number preliminary users collected actual phraseology grammar definition became iterative process redefinition subjected expert input assess accuracy relevance comprehensiveness still work us increase recognition user input take advantage requests repetition confirmation user input created grammar framework whereby justtalk language processor could mainly examining syntactic structures infer type input user uttered different types included commands requests information statements understanding appreciation informative declarations syntactic analysis calculated user politeness score input complexity value note scores somewhat domain specific instance experts informed us law officers taught always use sir maam conversing adults hence input lacking terms detracts politeness count field interviewing domain hand input including terms would increase politeness score similarly complex utterance depends phrases domain see 35 behavior engine used contextual knowledge evaluate semantics returned language processor semantic analysis derived relevance metric personalization score relevance metric tells appropriate user input based current topic determined previous input recent virtual human output personalization score provides estimate well user tailored hisher response virtual human measure domainspecific general weve found reply response described numerous adjectives listed table 2 descriptors listed left column able derive syntactic semantic analyses descriptors listed right column represent ongoing research requiring technology beyond readily available implemented table 2 user input descriptors accurate complete childlike emotional deceptive expected humorous femininemasculine hesitating linguistically complex instantaneous misunderstood loud nonnative personal polite positive nonverbal breath relevant sarcastic ungrammatical sick verbose tired untruthful virtual human output structured dialog virtual human replies one six ways response question denial challenge show confusion zone see figure 5 used fuzzy logic behavior engine decide reply format used information semantic content input language processor select specific appropriate verbal reply justtalk tagged following emotions grammars anger anxiety attention depression fear hostility base set derived discussions experts seemed capture range emotional states personalities needed portray work remaining though includes making virtual human replies less coherent abusive appropriate personality integrating recorded speech opposed texttospeech generation increase realism user engagement cognitive models keep track domain knowledge atn via state variable settings also structure since level planning inherent atn opposed using modeling language 13 virtual humans reason social roles conventions 36 atn structure stated asked point dialog grammar definitions gets stated asked figure 5 shows map language input different sections atn architecture designed allow application creators flexibility assigning general domainspecific knowledge instance virtual humans may understand satisfaction extremelylarge mean behave similarly virtual asthma patient 21 discusses relevant symptoms based specific setup variable indicating severity level justtalk subject portrays paranoia federal government distrust law enforcement relevant scenarios even though atn structure identical scenarios user initiative commands queries requests appreciates introduction greting commands queries requests attack panic go catatonic emotion computation confusion response denial challenge question get car respond informs threats understands commands figure 5 grammar atn mapping emotional models emotion models built using several emotion personality theories including five factor model 242 circumplex theory 34 cognitive theory emotions 33 latter model underscores work providing scheme labeling common emotions based virtual humans react inputs events objects 1 also include emotion reasoning architecture describe personalities change course interaction 10 though refrain rapid large fluctuations emotional states since users usually believe virtual humans consistent behavior 38 emotions determine behavior much way emergence conditions described elsewhere 3 user input update emotional state based three input characteristics format input eg command request query inform threat lexical analysis input politeness personalization level statement concern threat insultprofanity semantic content input ie interview topic also rely little research emotion expression schizophrenia depression 427 understand schizophrenic facial expressions least expressive responsive depressed positive stimuli schizophrenics show negative emotions normals schizophrenics less likely normals demonstrate felt happiness appropriate normal individuals show happiness contempt disgust anger schizophrenics likely show contempt still unlikely show disgust anger gestural models system train perceive behaviors indicative mental illness behaviors must realistic responsive virtual human behavior takes many forms including verbal output gesture body movement change internal emotional cognitive states worked experts devise algorithms data structures determine virtual human behave given inputs current emotional state interpretation user verbal input see table 1 instance using behavior engine resources schizophrenic knows begin pacing emotional state reaches certain threshold anger fear might user issues unexpected command topic conversation particularly upsetting gesture research also influenced model virtual human behavior instance childrens gestures larger adults 6 gestures rule cultures compared others 6 social roles status identity age familial relationship emotion eg sad look truthfulness utterance affect eye contact 38 unfamiliarity leads placing oneself bigger interactional distance familiarity avoiding aggressive gestures 18 finally schizophrenics attempt maintain greater distance less involvement healthy subjects interaction partner mental behavioral level 27 conclusion figure 6 shows screen shots justtalk tested next iteration application course ncja may 2002 october figure least five technical development goals feel need achieve improve virtual human architecture first need continue extensive testing recording inputs improve recognition student utterances key effort making virtual humans realistic natural language processing methods provide many opportunities tuning system provide better responses tuning iterative testing approach recognition accuracy measured continually improved second need look increasing visceral intrinsic engagement rather linguistic conversational engagement take two thrusts adding realism background replacing generated speech prerecorded speech existing technology upon justtalk based uses modeled ie photorealistic vr background increase user engagement photorealistic background created using rtis video reality technology integrated interaction environment integrating video reality require interfacing rendering code visualization engine building module convey camera geometry information associated video environment appropriate audio stream must decoded played synchronously image stream environmental sound must provided separately branching idle behaviors must provided video stream requiring careful filming editing need improve realism virtual subjects verbal replies justtalk used computersynthesized voice students instructors indicated using recorded voice highly desirable many nuances determining psychological state picked vocal inflections third need provide gesture cues newer immersive visualization environment virtual human allowed greater movement gesture created hundreds animations portray necessary pacing sitting fleeing looking around looking user looking nonexistent voices using gesture processing software variety projects ranging training emergency room staff recognize potential bioterrorism attacks training special operations soldiers first aid justtalk import leverage gesture databases software upgrades developed parallel efforts still work remaining includes providing range movement facial gestures lip synching fourth need improve emotional model working experts need reconsider base emotional states devised new methods updating emotional state current emotional state relies heavily past emotional state also syntactic semantic content users input personality environmental cues time course still ongoing work psychiatrists law officers experts develop sophisticated emotional models based clinical experience training police crisis intervention teams fifth students made assessment subject training noting dressed relatively nicely spoke welleducated appeared recently mental difficulties noted visual cues available students including facial movements although subject reacted negatively police several scenarios students said represent extreme fear dislike police students said commonly encounter preset viewpoint users could manipulate view rarely made difficult see details subjects particularly subject stood behind bench adjusting viewpoints appropriately help provide cues continuously refining models however already learned fielding schizophrenic depressed normal virtual humans expect lead much realistic engaging effective learning environments interaction skills acknowledgements material based work supported rti scda r9898001 national institute justice cooperative agreement 2000rdcxk002 national science foundation grant eia0121211 thank randy dupont university tennessee memphis deborah weisel north carolina state university martie stanford pam pope north carolina justice academy theirassistance efforts r emotional experience expression schizophrenia depression animated conversation rulebased generation facial display using affective reasoner support social simulations concept emotion viewed prototype perspective cognitive modeling knowledge nonresponse household interview surveys virtual reality trainingis talk presented american society training development international conference mechanisms mixedinitiative humancomputer collaborative discourse natural language processing virtual reality interactive training applications using responsive virtual human technology virtual humans training computer generated forces virtual standardized patientsimulated patientpractitioner dialogue patient interview training animated pedagogical agents facetoface interaction interactive learning environments virtual medical trainer patient assessment trauma care simulator sources power art science synthetic character design nonverbal communication human interaction 3rd lifelike pedagogical agents mixedinitiative problem solving constructivist learning environments developing 3dagent august dialogue system talking heads facial animation getaway simulation human interpersonal skill training cognitive structure emotions circumplex general model structure emotions personality measure semantic complexity natural language systems social role awareness animated agents preparing instructional technology gapa constructivist approach improvisational synthetic actors flexible personalities shall emotion called emotions dimensions discrimination among daily life effects variable initiative linguistic behavior humancomputer spoken natural language dialog five factor model personality theoretical perspectives tr animated conversation personalityrich believable agents use language cognitive modeling pretty face social role awareness animated agents lifelike pedagogical agents mixedinitiative problem solving constructivist learning environments fully embodied conversational avatars ctr curry guinn rob hubal evaluation virtual human technology informational kiosks proceedings 6th international conference multimodal interfaces october 1315 2004 state college pa usa lucio ieronutti luca chittaro employing virtual humans education training x3dvrml worlds computers education v49 n1 p93109 august 2007