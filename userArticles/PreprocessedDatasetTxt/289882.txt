quantitative evaluation register pressure software pipelined loops software pipelining loop scheduling technique extracts loop parallelism overlapping execution several consecutive iterations one drawbacks software pipelining high register requirements increase number functional units degree pipelining paper analyzes register requirements software pipelined loops also evaluates effects performance addition spill code spill code needed number registers required software pipelined loop larger number registers target machine spill code increases memory traffic reduce performance finally compilers apply transformations order reduce number memory accesses increase functional unit utilization paper also evaluates negative effect register requirements transformations might produce loops b introduction current highperformance floatingpoint microprocessors try maximize exploitable parallelism heavily pipelining functional units 12 making aggressive use parallelism 34 combination 5 trend current future highperformance microprocessors exploit effectively amount available parallelism aggressive scheduling techniques software pipelining required software pipelining 6 instruction scheduling technique exploits instruction level parallelism ilp loops overlapping execution successive iterations different approaches generate software pipelined schedule loop 7 modulo scheduling class software pipelining algorithms relies generating schedule iteration loop schedule repeated regular intervals dependence violated resource usage conflict arises modulo scheduling proposed beginning 80s 8 since many research papers appeared topic 910111213141516 incorporated production compilers 1718 drawback aggressive scheduling techniques software pipelining increase register requirements addition increasing either stages functional units number functional units current trends microprocessor design tends increase number registers required software pipelined loops 19 register requirements schedule extreme importance compilers since valid schedule must fit available number registers target chine way research effort produce optimalnearoptimal modulo schedules minimumreduced register requirements optimal methods mainly based linear programming approaches 2021 unfortunately optimal techniques prohibitive computational cost make impractical product compilers practical modulo scheduling approaches use heuristics produce nearoptimal schedules reduced register requirements 111622 approaches try reduce register requirements schedules applying postpass process 2324 proposals perform register allocation software pipelined loops 252627 number registers required larger available number registers spill code introduced reduce register usage different alternatives generate spill code software pipelined loops proposed evaluated 28 spill code also reduce performance paper show performance memory traffic aggressive terms ilp machines heavily degraded due lack registers avoid performance degradation big register files required addition number read write ports increases number functional units number registers number ports negative effect area required register file 29 access time register file 30 new register file organizations proposed big register files terms registers access ports without degrading either area access time 31323334 organizations used combined registersensitive software pipelinig techniques 35 resulting better performance shows techniques reducing effects register pressure complementary paper register requirements pipelined floatingpoint intensive loops evaluated several studies performed first register requirements loop invariants machineindependent characteristic loops studied section 3 section 4 carries study register requirements loop variants function latency number functional units section 5 studies cumulative register requirements loop variants invariants show loops high register requirements represent high percentage execution time perfect club section 6 considers effects limited size register file performance memory traffic purpose spill code added loops require registers available finally section 7 analyzes effects register requirements optimizations try improve performance reusing data increasing functional unit usage 2 related concepts experimental framework 21 overview modulo scheduling software pipelined loop schedule iteration divided stages execution consecutive iterations distinct stages overlapped number stages one iteration termed stage count sc number cycles per stage initiation interval ii execution loop divided three phases ramp phase fills software pipeline steady state phase software pipeline achieves maximum overlap iterations ramp phase drains software pipeline steady state phase execution pattern operations executed stage achieved iterating piece code termed kernel corresponds one stage steady state phase initiation interval ii two successive iterations bounded either loopcarried dependences graph recmii resource constraints architecture resmii lower bound ii termed minimum initiation interval mii max recmii resmii reader referred 1813 extensive dissertation calculate resmii recmii 22 register requirements values used loop correspond either loopinvariant variables loop variant variables loop invariants repeatedly used never defined loop execution loop invariants single value iterations loop invariant requires one register regardless scheduling machine configuration loop variants value generated iteration loop therefore different value corresponding iteration nature software pipelining lifetimes values defined iteration overlap lifetimes values defined subsequent iterations lifetimes loop variants measured different ways depending execution model machine assume variable alive beginning producer operation start last consumer operation overlapping lifetimes different iterations pattern length ii cycles indefinitely repeated obtained pattern indicates number values live given cycle shown 26 maximum number simultaneously live values maxlive accurate approximation number registers required schedule values lifetime greater ii pose additional difficulty since new values generated previous ones used one approach fix problem provide form register renaming successive definitions value use distinct registers renaming performed compile time using modulo variable expansion mve 36 ie unrolling kernel renaming compile time multiple definitions variable exist unrolled kernel rotating register file used solve problem without replicating code renaming different instantiations loop variant execution time 37 paper assume presence rotating register files 23 experimental framework experimental evaluation done using innermost loops perfect club benchmark suite 38 suitable software pipelining loops obtained ictineo compiler 39 ictineo sourceto source restructurer developed top polaris 40 internal representation combines high lowlevel information includes basic transformations allow us obtain optimized data dependence graphs total 1258 loops suitable software pipelining used set includes innermost loops subroutine calls conditional exits loops conditional structures bodies ifconverted 41 result loop looks like single basic block loops represent 78 total execution time perfect club measured hppa 7100 addition show effects aggressive optimizations individual loops also used livermore loops 42 loops scheduled wide range vliwlike target configura tions different number functional units latencies table 1 shows different configurations used along paper functional units fully pipelined except divider pipelined labeled different configurations pxly x number functional units kind latency number stages mostly used functional units adder multiplier considered constant latency loads stores divisions square roots independently configuration different metrics used along paper evaluate performance one side register requirements evaluated computing maximum number simultaneously live values maxlive shown 26 allocation strategies almost always achieve maxlive lower bound particular wands strategy using endfit adjacency ordering almost never requires maxlive registers second execution times approximated ii obtained modulo scheduling times trip count loop finally memory traffic approximated evaluating number memory accesses needed execute loop considering memory accesses defined graph spill code introduced due finite register file 3 register requirements loop invariants loop invariants values repeatedly used loop iteration never written defined entering loop used redefined least loop finished loopinvariant variables either stored registers memory since memory bandwidth without doubt performance limiting factor current processors even simple optimizing compilers try hold registers execution loop purpose loopinvariant variables loaded memory register entering loop uses even assuming memory bandwidth restrictions loading variables registers entering loop saves instruction bandwidth loadstore architectures ie almost current processors another source loop invariants invariant computations ie computations produce result iterations loops computations extracted loop performed every iteration computed entering loop also memory bandwidth instruction bandwidth partial result computations held registers optimization termed loopinvariant removal one optimizations performed ictineo compiler fact consider load store operations computations also extracted loopinvariant removal optimization figure 1a shows example figure 1b shows lowlevel representation loops removing loopinvariant computations figure 1c shows loops removing loopinvariant computations notice q loopinvariant variables loops loaded registers entering cj also loopinvariant variable innermost loop extracted outermost loop v1 v2 loop invariants assumed allocated registers computation v3 loopinvariant computation therefore extracted innermost loop extraction loop invariants lead smaller innermost loop one executed time less operations original one 1 addition 2 multiplications 5 memory accesses optimized one 1 addition 1 multiplication 2 memory accesses ictineo compiler performs among optimizations aggressive extraction loopinvariant computations used optimized dependence graph evaluate register requirements loops due loop invariants figure 2 shows cumulative distribution requirements loop invariants 1258 loops general loops loop invariants instance 25 loops loop invariants 95 loops 8 less invariants nevertheless loops high number loop invariants instance 9 loops invariants 1 requires 68 loop invariants 4 register requirements loop variants unlike loop invariants number registers required loop variants schedule dependent characteristic register requirements depend scheduling technique target machine configuration scheduling performed well topology loop section interested effects machine configuration register requirements main characteristics influence final schedule therefore register requirements number stages functional units number functional units degree pipelining degree parallelism purpose generated software pipelined schedule perfect club loops target configurations shown table 1 figure 3 shows cumulative distribution registers configuration notice product latency functional units number functional units goes number registers needed loops also increases note number functional units slightly bigger effect number registers required degree pipelining mainly due fact latency functional units kept constant configurations small number loops 6 require register loop variants loop bodies loops invariants store operations loops typically used initialize data structures another region 6 30 loops register requirements register requirements loops influenced number stages due fact loops arithmetic opera tions bodies load store operations loops register requirements hold values loads stores basically used copy data structures 5 combined register requirements although special architectures cydra5 43 separated register files loopinvariant variables global register file loopvariant variables rotating register file current superscalar microprocessors software pipelining also applied single register file store sets variables therefore great interest know combined register pressure loopvariant variables plus loopinvariant variables figure 4 shows cumulative distribution register requirements loops perfect club software pipelined configurations table 1 interesting notice 96 loops scheduled registers without adding spill code less aggressive configuration p1l2 contrary 85 loops scheduled registers aggressive configuration p2l6 64 registers available would able schedule 995 96 loops respectively also approximately 60 loops varies depending configuration require small number registers less figures one conclude register requirements extremely high 64 registers might seem enough configurations used even though observed small loops represent small percentage execution time time spent big loops general higher register requirements figure 5 shows dynamic register requirements loop weighted execution time graph figure 5 similar one figure 4 instead representing percentage loops require certain amount registers represents percentage time spent loops require certain amount registers data gathered figure shows small loops requiring less 8 registers portion execution time 15 32 registers available loops scheduled without adding spill code represent 67 52 execution time even machine 64 registers loops scheduled without adding spill code represent 78 69 execution time even big percentage execution time perfect club spent loops require 100 registers 6 effects limited register file previous sections infinite number registers assumed section study effects limited amount registers performance limited number registers register allocator fails find solution number registers available additional action must taken 28 proposed several alternatives schedule software pipelined loops register constraints purposes experiments use best option terms performance loops add spill code current microprocessors floatingpoint registers 32 integer reg isters think future generations microprocessors enlarge register file 64 registers least floating pointregister file since study targeted floating point intensive applications study effects register files registers 64 registers compared ideal case infinite number registers adding spill code generate valid schedule given number registers produces two negative effects one hurt performance indirectly since spill code adds new load store operations might interfere memory subsystem cause additional cache misses effect affects performance directly new operations added might necessary increase ii loop reducing throughput even hypothetical case perfect memory system figure 6 shows number memory accesses required execute loops six configurations use notice number memory accesses configurations spill code added also predictable fact number memory accesses increases number registers reduced also observed growth memory accesses dramatic aggressive configurations instance configuration p2l6 64 registers requires 52 accesses ideal machine infinite register file 176 memory accesses registers anyway difficult predict performance degradation additional accesses without simulating memory subsystem scope paper case easily predict direct effect performance spill code execution time loops larger iis figure 7 shows number cycles required execute loops six configurations infinite number registers 64 registers registers notice expected fewer registers mean lower performance cycles required execute loops general aggressive machine configuration bigger performance degradation instance p1l6 machine speedup 119 register file doubled 32 registers 64 registers instead p2l6 machine speedup 129 doubling register file data gathered experiment concluded simply adding functional units without caring number registers results performance figures lower expected due negative effects additonal spill code instance doubling number functional units ie going p1l6 p2l6 produces speedup 159 number registers limited machines 64 32 registers speedup 156 143 respectively however number register doubled together number functional units ie p1l6 32 registers p2l6 64 registers speedup 185 7 optimizations register requirements addition effect latency number functional units register requirements loops also increase certain optimizations applied loops order see advanced optimizations affect register requirements loops handoptimized livermore loops loops perfect club optimizations applicable considered common optimizations loopinvariant removal common subexpression elimination redundant load store removal dead code removal assume applied compiler following subsections present brief description optimizations studied effect applying optimizations performance register requirements 71 loop unrolling loop unrolling 44 optimization used compilers current micro processors allows better usage resources several iterations scheduled together increasing number instructions available scheduler also reduces loop overhead caused branching index update case achieve efficient iteration overlapping software pipelining unrolling required match number resources required loop resources processor also schedule loops fractional mii 45 example assume loop 5 additions processor 2 adders recurrences additional resources limit scheduling loop scheduled cycles loop executed 833 peak machine performance loop unrolled scheduling obtain new loop 10 additions new loop scheduled iteration new loop corresponds two iterations original loop average iteration completed 25 cycles unrolled loop executed 100 peak machine performance unroll increases register requirements bigger loops temporal variables store usually requires registers table 2 shows effects unrolling loops register requirements loops used unrolling results better usage available resources unfortunately also produces increase register requirements seen section 6 degrade performance number available registers less registers required 72 common subexpression elimination across iterations common subexpression elimination across iterations cseai extension inner loops common subexpression elimination optimization applied almost optimizing compilers consists reuse values generated previous iterations reused data stored register since value used across iterations one physical register required order overwrite live value new instantiation variable extension loops common subexpression elimination optimization sophisticated sense applied loops requires dependence analysis know values current iteration used iterations objective optimization reduce number operations loop body lead lower ii even applying optimization final ii lowered worthwhile applying number memory accesses reduced example consider loop figure 8a whose unoptimized body shown figure 8b added loop variants generated operations subindex associated iteration generated instance represents value generated first operation iteration conventional common subexpression elimination step recognize load value zi1 therefore operation v 4 removed subsequent uses v 4 substituted uses v 2 optimization produces output loop shown figure 8c notice optimization loop requires 7 operations instead 8 common subexpression elimination optimization detect value v 3 previous iteration v 3 equivalent value therefore operations required calculate v 6 removed uses substituted v 3 done operations producing loop body figure 8d notice resulting loop body 4 operations table 3 shows ii memory traffic loops without applying cseai notice cases improvements memory traffic ii also interesting notice even though optimization reduces number operations loops therefore number lifetimes per iteration register requirements increase cases mainly due fact loop variants must preserved across several iterations 73 backsubstitution backsubstitution 37 technique increases parallelism loops single recurrences therefore limited parallelism increases number operations executed per iteration instance consider livermore loop 11 shown figure 9a recurrence weight 1 limits mii adder 6 cycles latency loop scheduled ii 6 cycles using backsubstitution loop becomes one shown figure 9b recurrence limits schedule loop weight 2 obviously case two additions instead one transformed loop executed ii 3 cycles doubling performance avoid part increase operations optimizations applied common subexpression elimination across iterations example reduces number loads number additions way reducing increment operations perform unroll well backsubstitution apply unroll livermore loop 11 together backsubstitution obtain loop figure 9c notice loop require 3 additions compute two iterations original loop loop figure 9c executed ii 6 cycles performs two iterations performance loop figure 9b requires fewer operations backsubstitution applied number operations per iteration creased ii reduced general bigger loops require registers temporal values store addition reduced ii requires registers temporal values new values created iteration table 4 shows effect performance register requirements applying backsubstitution livermore loops 11 5 notice loop 5 cases ii 13 cases scheduler used fails find schedule 12 cycles even though exists 74 blocking blocking register level wellknown optimization context dense matrix linear algebra 46 blocking transformation applied multiple nested loops finds opportunities reuse subscripted variables replaces memory references involved references temporary scalar variables allocated registers blocking basically consists unrolling outer loops restructuring body innermost loop memory references reused iteration held registers uses blocking reduces number memory accesses loop memorybound reduction number memory references improves maximum performance also reduction memory references improve performance due less interference memory subsystem finally innermost loop bound recurrences several iterations outermost loops one iteration innermost loop improve resource usage unfortunately blocking increases size loop general increases register requirements also enlarges lifetimes loop variants must stored registers longer time reused later enlargement lifetimes also contributes increase register requirements transformed loop versus original one table 5 shows ii effective ii per iteration memory traffic registers required blocking applied basic matrix matrix kernel 8 conclusions paper evaluated register requirements software pipelined loops evaluated register requirements loop invariants loop variants loops perfect club shown empirically register requirements loop variants increases latency number functional units results corroborate theoretical study done 19 also shown loops high register requirements take important proportion execution time representative numerical applications also evaluated effect register file size number memory accesses performance shown memory traffic high growth register file small machine configuration ag gressive also performance even hypothesis perfect memory system degraded small register files finally done limited evaluation effects advanced opti mizations shown advanced optimizations increase performance reduce memory traffic expense increase register requirements suggests practice optimizations must performed carefully loop excessively optimized high register requirements offset benefits optimization applied even produce worse results future work integrate advanced optimizations ictineo compiler order perform extensive evaluation effect optimizations performance tradeoffs performance degradation due higher register requirements acknowledgements work supported ministry education spain contract tic 42995 cepba european center parallelism barcelona r mips r4000 processor next generation risc system6000 family superscalar instruction execution 21164 alpha microprocessor approach scientific array processing architectural design ap120bfps164 family software pipelining scheduling techniques easily schedulable horizontal architecture high performance scientific computing software pipelining effective scheduling technique vliw chines circular scheduling new technique perform software pipelining parallelisation loops exits pipelined architectures iterative modulo scheduling algorithm software pipelining loops realistic resourceconstrained software pipelining algo rithm modulo scheduling multiple initiation inter vals hypernode reduction modulo scheduling software pipelining parisc compilers compiling cydra 5 register requirements pipelined processors minimal register requirements resourceconstrained software pipelining optimum modulo schedules minimum register requirements swing modulo scheduling lifetime stage scheduling technique reduce register requirements modulo schedule resis new methodology register optimization software pipelining register allocation using cyclic interval graphs new approach old problem register allocation software pipelined loops meeting new model loop cyclic register allocation heuristics registerconstrained software pipelining principles cmos vlsi design systems per spective partitioned register files vliws preliminary analysis tradeoffs using sacks organize register files vliw machines digital 21264 sets new standard reducing impact register pressure software pipelining systolic array optimizing compiler overlapped loop support cydra perfect club benchmarks effective performance evaluation supercomputers uniform representation highlevel instructionlevel transformations polaris next generation parallelizing compilers conversion control dependence data dependence livermore fortran kernels computer test numerical performance range cydra 5 departmental super computer design philosophies unrolling loops fortran software pipelining comparison improvement improving register allocation subscripted variables tr principles cmos vlsi design systems perspective software pipelining effective scheduling technique vliw machines cydra 5 departmental supercomputer overlapped loop support cydra 5 improving register allocation subscripted variables parallelization loops exits pipelined architectures circular scheduling register allocation software pipelined loops register requirements pipelined processors partitioned register files vliws lifetimesensitive modulo scheduling compiling cydra 5 designing tfp microprocessor iterative modulo scheduling minimizing register requirements resourceconstrained rateoptimal software pipelining software pipelining optimum modulo schedules minimum register requirements modulo scheduling multiple initiation intervals stage scheduling hypernode reduction modulo scheduling heuristics registerconstrained software pipelining software pipelining systolic array optimizing compiler conversion control dependence data dependence mips r4000 processor superscalar instruction execution 21164 alpha microprocessor resis using sacks organize registers vliw machines scheduling techniques easily schedulable horizontal architecture high performance scientific computing nonconsistent dual register files reduce register pressure swing modulo scheduling ctr javier zalamea josep llosa eduard ayguad mateo valero software hardware techniques optimize register file utilization vliw architectures international journal parallel programming v32 n6 p447474 december 2004 david lpez josep llosa mateo valero eduard ayguad widening resources costeffective technique aggressive ilp architectures proceedings 31st annual acmieee international symposium microarchitecture p237246 november 1998 dallas texas united states javier zalamea josep llosa eduard ayguad mateo valero twolevel hierarchical register file organization vliw processors proceedings 33rd annual acmieee international symposium microarchitecture p137146 december 2000 monterey california united states david lpez josep llosa mateo valero eduard ayguad costconscious strategies increase performance numerical programs aggressive vliw architectures ieee transactions computers v50 n10 p10331051 october 2001 javier zalamea josep llosa eduard ayguad mateo valero improved spill code generation software pipelined loops acm sigplan notices v35 n5 p134144 may 2000