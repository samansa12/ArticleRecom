location densitybased hierarchical clustering using similarity analysis abstractthis paper presents new approach hierarchical clustering point patterns two algorithms hierarchical location densitybased clustering developed method groups points maximum intracluster similarity intercluster dissimilarity achieved point locations point separations performance clustering methods compared four methods approach applied twostep texture analysis points represent centroid average color regions image segmentation b introduction clustering explores inherent tendency point pattern form sets points clusters multidimensional space previous clustering methods assume tacitly points similar locations constant density create single cluster location densitybased clustering two ideal cases clusters shown figure 1 location density becomes characteristic property cluster properties clusters proposed based human perception 1 2 3 figure 2 left specific tasks texture discrimination perspective distortion 4 eg points constant directional change density figure 2 right properties clusters specified clustering performed usually priori unknown work presents new approach hierarchical clustering point patterns two hierarchical clustering algorithms developed based new approach first algorithm detects clusters similar locations points locationbased clustering method achieves identical results centroid clustering 5 6 7 slight improvement uniqueness solutions second algorithm detects clusters similar point separations densitybased clustering method create clusters points spatially interleaved dissimilar densities called transparent clusters figure 3 shows two transparent clusters detection orig data20x2 figure 1 ideal three left two right clusters location left density based clusterings origdata orig data figure 2 illustration possible properties points creating cluster left two clusters smoothly varying nonhomogeneous densities taken 1 right two clusters constant directional change density figure 3 two transparent clusters c transparent clusters unique feature method among existing clustering methods two methods developed using similarity analysis similarity analysis relates intracluster dissimilarity intercluster dissimilarity dissimilarity point locations point separations considered clustering denoted general dissimilarity elements e method described follows first every element e gives rise one cluster c e elements dissimilar e fixed number second sample mean elements c e cal culated third clusters would formed grouping pairs elements sample means computed two elements similar fourth degree dissimilarity used form several multiscale partitions given point pattern hierarchical organization clusters within multiscale partitions built agglomerating clusters increasing degree dissimilarity lastly clusters change large interval selected final partition experimental evaluation conducted synthetic point patterns standard point patterns 8ox handwritten character recognition iris flower recognition point patterns obtained image texture analysis performance clustering methods compared four methods partitional forgy cluster hierarchical single link complete link 5 detection clusters perceived humans gestalt clusters 1 shown location densitybased clusterings suitable texture analysis texture modeled set uniformly distributed identical primitives 8 see figure 4 primitive described set photometric geometrical topological features eg color shape spatial coordinates primitive described another set features thus point pattern obtained texture analysis consists two sets features eg centroid location average color primitives decomposed first locationbased clustering used form clusters corresponding identical primitives one subspace color primitives densitybased clustering creates clusters corresponding uniformly distributed primitives subspace centroid locations primitives resulting texture identified combining clustering results two subspaces decomposition approach also demonstrated point patterns obtained application domains general unknown determine choice subspaces thus exhaustive search best division terms classification error used experimental part handwritten character recognition taxonomy applications salient features work following first decomposition figure 4 example textures top original image bottom resulting five textures delineated black line obtained location densitybased clusterings clustering problem two lowerdimensional problems addressed second new clustering approach proposed detecting clusters constant property points location density third densitybased clustering method using proposed approach separates spatially interleaved clusters various densities thus unique among existing clustering methods methods related graphtheoretical algorithms paper organized follows section 2 provides short overview previous clustering methods theoretical development proposed clustering method presented section 3 analytical numerical experimental performance evaluations clustering method follow section 4 section 5 presents concluding remarks previous work clustering understood lowlevel unsupervised classification point patterns 5 9 classification method assigns every point one cluster without priori knowledge methods divided partitional hierarchical methods partitional methods create single partition points hierarchical methods give rise several partitions points nested partitional clustering methods subdivided roughly 1 errorsquare clusterings 5 6 2 clustering graph theory 10 2 5 3 3 density estimation clusterings 7 5 11 6 errorsquare clusterings minimize square error fixed number clusters methods require input number sought clusters well seeds initial cluster centroids comparative analysis work performed using implementations errorsquare clusterings called forgy cluster 5 forgy uses one kmeans pass k given number clusters final partition cluster uses kmeans pass followed forcing pass forcing pass mergers clusters obtained kmeans pass performed minimum square error achieved clustering graph theory uses geometric structures minimum spanning tree mst relative neighborhood graph gabriel graph delaunay triangulation methods using geometric structures construct graph first followed removal inconsistent edges graph inconsistent edges remove edges specified method due computational difficulties methods using mst used higher three dimensional point patterns density estimation clusterings used two approaches count number points within fixed volume mode analysis parsen window b calculate volume fixed number points knearest neighbors methods vary estimations parsen rosenblatt loftsgaarden quesenberry 11 two commonly used hierarchical clusterings singlelink completelink methods 12 5 methods based graph theory every point represents node graph two nodes connected link length link computed euclidean distance two points single completelink clusterings begin individual points separate clusters next links smaller length fixed threshold create threshold graph single link method redefines current clustering number maximally connected subgraphs threshold graph less number current clusters completelink method maximally complete subgraphs connected subgraph defined graph connects nodes corresponding points complete subgraph connected subgraph least one link pairs nodes points implementations singlelink completelink clusterings based huberts johnsons algorithms 5 used comparative analysis work use clustering methods found many applications related remote sensing 13 14 15 image texture detection 16 taxonomy 12 17 geography 18 19 objective work contribute 1 theoretical development nonexisting clustering methods 2 use clustering texture detection 3 location densitybased clusterings first mathematical framework established section 31 clustering method proposed section 32 algorithms hierarchical location densitybased clusterings outlined section 33 related methods proposed ones compared section 34 31 mathematical formulation ndimensional nd point pattern defined set points fp g p coordinates general goal unsupervised clustering partition set points nonoverlapping subsets points fc j g n w j index set integer numbers interval subsets points called clusters characterized work similarity dissimilarity point locations point separations notion element e introduced refer either point location point separation dl p1 p 2 euclidean distance two points also called length link dl p1 p 2 general every cluster elements characterized maximum intracluster dissimilarity intracluster similarity minimum intercluster dissimilarity dissimilarity value two elements defined euclidean distance figures 5 6 show cluster points cf j characterized cluster point separations links cl j characterized one would like obtain clusters minimum intracluster maximum intercluster dissimilarity maximum intracluster minimum intercluster similarity order decrease probability misclassification thus goal partition point pattern nonoverlapping clusters fc j g n minimum intracluster maximum intercluster dissimilarity elements clusters elements clusters points case point separations mapping clusters obtained clusters points performed mapping clusters point separations links clusters points takes two steps 1 construct minimum spanning tree average values individual clusters links 2 form clusters points sequentially clusters links order given minimum spanning tree smaller larger average values clusters cf cf f figure 5 characteristics clusters points clusters twodimensional points illustrated points one cluster within sphere center p midp radius ffik midp e e e e e e l k0 e 05e 05e e figure characteristics clusters links top three clusters links partitioning twodimensional points three clusters points bottom characteristics three clusters links horizontal axis represents values euclidean distances pairs points dl k links cluster links differ length 32 clustering method given set elements goal unknown parameters classification problem values ff final cluster well number final clusters n two steps taken partition input elements clusters first value intracluster dissimilarity fixed clusters characterized formed grouping pairs elements result first step set clusters denoted fce m1 since characterized second value estimated cluster ce j estimated value selected final partition fce j g n choice ce j driven maximization intercluster dissimilarity ff minimization intracluster dissimilarity final partition aimed identical ground truth partition fc j g n j1 assumed exist purpose evaluating classification accuracy number misclassified elements development proposed classification method described next addressing following issues 1 given fixed value intracluster dissimilarity estimate unknown cluster single element 2 group pairs elements based estimates calculated element 3 estimate value intracluster dissimilarity unknown cluster 1 estimate unknown cluster derived single element order create unknown cluster c j every pair elements c j grouped together grouping based certain estimate cluster c j computed element best estimate unknown cluster c j obtained single element e element e gives rise cluster c e identical unknown one c j would possible create cluster c e unknown cluster c j elements characterized value intercluster dissimilarity ff larger f cf d1p figure 7 cluster points e ee e e e figure 8 cluster links value intracluster dissimilarity see figures 7 8 assumption ff cluster c e obtained element e grouping together elements e k satisfying inequality k e thus two elements e 1 e 2 cluster c e pairwise dissimilarity always less 2 e 2 last fact 2 intracluster dissimilarity leads notation c e 2 grouping elements clusters using similarity analysis final clusters fce characterized obtained following way create clusters c 2 g k e b compare pairs clusters c 2 c assign elements final clusters elements based comparisons b steps b c performed using similarity analysis similarity analysis relates intracluster dissimilarity intercluster dissimilarity ff unknown cluster c ff relationship ff breaks two cases ff ff ff unknown cluster c ff j value intercluster dissimilarity larger value intracluster dissimilarity case clusters c 2 either identical totally different unknown cluster c ff thus two elements e 2 would belong final cluster ce e2 ff unknown cluster c ff j value intercluster dissimilarity smaller equal value intracluster dissimilarity case clusters c 2 identical unknown cluster c ff cluster c 2 superset c ff cluster c 2 also contains exterior elements c ff j due ff ff known group elements clusters analysis case proceeds analysis assumes case ff occurs due random noise assumption random noise leads statistical analysis similarity clusters c 2 two issues investigated next statistical parameter cluster c ff j would invariant presence noise ii maximum deviation two statistically invariant parameters computed clusters c ff first let us assume deterministic values elements corrupted zero mean random noise symmetric central distribution sample mean average elements would statistically invariant parameter mean noise zero although sample mean noise corrupted elements varies depending realization noise fixed number given set noise corrupted elements thus sample mean j noise corrupted elements c ff j statistically invariant parameter aforementioned assumptions noise second sample mean computed cluster c 2 denoted deviation j investigation c 2 subset c probability distribution e e figure 9 confidence interval 1d case e sample mean would deviate statement always true two arbitrary subsets e l sample means would apart superset c oe c deviation e either assumed e validity previous statement depends ratio elements true cluster c j clusters exterior c thus second issue sample mean expected deviated figure two elements would grouped together corresponding sample means e1 e2 apart inequality k used ff applied case ff would classification error final partition fce m1 case inequality used ff classification error evaluated statistical framework probability p rk complement probability corresponds confidence interval mean estimator confidence coefficient upper lower confidence limits sigma 3 estimation intracluster dissimilarity value intracluster dissimilarity priori unknown unknown cluster estimation value based assumption unknown cluster c j maximum intercluster dissimilarity ff change elements c j large interval values thus clusters ce j change elements large interval selected final partition fce j g n set fce j g n j1 estimate ground truth partition fc j g n procedure automatic selection uses analysis hierarchical classification results consists four steps produce multiple sets clusters varying value called multiscale classification ii organize multiscale sets clusters hierarchy clusters iii detect clusters change elements large interval iv select value based analysis step iii hierarchical organization output defined nested sequence sets clusters along scale axis nested sequence understood follows cluster obtained scale cannot split scale cannot merge scale clusters hierarchy multiscale classification results guaranteed modifying elements within final cluster ce created scale sample mean elements cluster implementation hierarchical organization supported following fact two elements e 1 e 2 identical values belong cluster ce scales 0 33 clustering algorithms proposed densitybased clustering elements links requires 1 map clusters links clusters points 2 process large number links two issues tackled final algorithms location densitybased clusterings provided specifics densitybased clustering order obtain clusters points mapping clusters links clusters points designed mapping consists three steps 1 compute average link length cluster links 2 construct minimum spanning tree average values individual clusters links 3 form clusters points sequentially clusters links order given minimum spanning tree smaller larger average values knowing mapping number processed links decreased merging links order link distances dl k shortest links longest links clusters cl created corresponding clusters points cs derived immediately links contain already merged points processed afterwards union clusters points includes given points cs links processed clustering algorithm locationbased clustering 2 create cluster cf 2ffi point 3 calculate sample means cf 2ffi group together two points p 1 p 2 cluster cf ffi 5 assign sample mean cluster cf ffi points cf ffi increase ffi repeat step 2 points clustered one cluster select clusters cf ffi final partition fcf j g n j1 change large interval ffi values clustering algorithm densitybased clustering calculate point separations dl k length links pairs points p 2 order dl k shortest longest dl 1 3 create clusters links cl 2 l k individual link l k dl k calculate sample means l k 5 group together pairs links l 1 l 2 sharing one point p cluster links assign unassigned points clusters cs belong links creating clusters remove links ordered set contain already assigned points perform calculations step 3 increased upper limit exist unassigned points assign link average cluster cl links cluster cl increase repeat step 2 points partitioned one cluster select cl clusters final partition fcs j g n j1 change large interval values 34 related clustering methods locationbased clustering related centroid clustering 5 densitybased clustering related zahns method 1 centroid clustering achieves results identical proposed locationbased clustering although algorithms different see 5 difference performance case equidistant points proposed method gives unique solution centroid clustering method due sequential merging updating point coordinates zahns method consists followings steps 1 construct minimum spanning tree mst given point pattern 2 inconsistent links mst 3 remove inconsistent links form connected components clusters link called inconsistent link distance significantly larger average nearby link distances sides link proposed densitybased clustering differs zahns clustering following ways 1 use average largest set link distances descriptors cl 2 l k rather nearby link distances defining inconsistent link leads accurate estimates inconsistent links 2 replace threshold removing inconsistent links significantly larger definition inconsistent links simple statistical rule 3 work links complete graph 1 rather links selected mst crucial detecting transparent clusters performance evaluation problem image texture analysis introduced section 41 problem statement explains motivation pattern decomposition followed using location densitybased clusterings theoretical experimental evaluations methods follow next evaluation focuses 1 clustering accuracy section 42 2 detection gestalt clusters section 43 3 performance real applications section 44 41 image texture analysis image texture modeled set uniformly distributed identical primitives shown figure 4 primitive figure 4 characterized color size primitives similar colors shapes uniformly distributed therefore centroid coordinates texture interior primitives similar interneighbor distances goal image texture analysis 1 obtain primitives 2 partition primitives sets primitives called texture 3 describe texture using interior primitives distribution work primitives found links pairs points create complete graph according notation graph theory based exclusively color homogeneity based segmentation 20 applied image segmentation partitions image homogeneous regions called primitives similar colors within region point pattern obtained primitives regions measuring average color centroid coordinates primitive given pattern decomposition features performed first one set features corresponds centroid measurements color measurements primitives two lower dimensional patterns created features locationbased clustering applied pattern consisting color feature densitybased clustering applied pattern consisting centroid coordinate features clustering results combined shown figure 4 bottom cluster similarity subspace provides texture description characterized similarity primitives uniformity distribution densitybased clustering applied pattern shown figure 10 top points pattern numbered zero maximum number points output figure 10 bottom shows three clusters labeled number point cluster minimum value number partial spatial occlusions blobs original image gave rise corrupted set features corresponding centroid coordinates primitives follows lower dimensional points absolutely uniformly distributed corresponding subspace value similarity selected manually method demonstrates exceptional property separating spatially interleaved clusters unique property clustering methods described dist 26 26 26 26 2626 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 26 figure 10 spatially interleaved clusters top original point pattern bottom densitybased clustering 42 accuracy computational requirements experimental analysis clustering accuracy evaluated measuring number misclassified points respect ground truth clustering accuracy tested 1 synthetic point patterns generated using location density models clusters 2 standard test point patterns 80x iris used several researches illustrate properties clusters 80x used 5 iris 12 5 1 computational requirements stated experimental results compared four clustering methods two hierarchical methods single link complete link two partitional forgy cluster 5 synthetic standard point patterns point pattern generated points numbered detected clusters shown pictorially sets points labeled number common number cluster corresponds number point minimum value number two models used generate synthetic point pattern first three locations twodimensional space gave rise synthetic pattern three clusters three locations perturbed gaussian noise zero mean variation oe various values standard deviation oe number points derived perturbations location varied well figure 11 shows two realizations synthetic patterns left column results obtained locationbased clustering shown figure 11 right column second 2d synthetic point pattern 64 points generated four clusters 30 10 12 12 points different densities point pattern shown figure 12 left points pattern corrupted uniform noise delta sigma 05 gaussian noise figure 12 middle right results obtained densitybased clustering method point patterns shown figure 13 input data2040 figure 11 clusters detected locationbased clustering left column three clusters points top 60 points bottom gaussian noise locationbased clustering corresponding left column point patterns 25 orig data75125175 data uniform noise10x2 data gaussian noise15 figure 12 synthetic pattern four clusters different densities internal link distances points four clusters equal 1 2 3 first left locations points corrupted noise uniform middle gaussian right distributions 1301122 dist 52 52 52 52 52 52 52 52 dist 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 43 dist 38 53 53 53 53 53 53 53 53 53 53 53 dist 55150 dist 000000 000000 000000 000000 0000003030303042 42 52 52 52 52 52 52 52 52 52 52 52 52 55152 dist 000000 000000 000000 000000 000000 figure 13 clusters detected densitybased clustering clustering results patterns shown figure 12 cluster labels points without noise top row uniform noise middle row gaussian noise bottom row number plot refers value selected two standard point patterns obtained 1 handwritten character recognition problem recognition 80x 8 features 2 flower recognition problem fisheranderson iris data denoted iris recognition iris setosa iris versicolor iris virginica 4 features features shown figure 14 data set 80x contains 45 points 3 categories size 15 points data set iris contains 150 points 3 categories size 50 results expressed terms misclassified points table 3 decomposition features followed location densitybased clusterings explored point pattern 80x iris unknown determine choice features decomposition goal create lower dimensional point patterns showing inherent tendency form sets points similar locations approximately constant density exhaustive search best division terms classification error used comparisons clustering methods two partitional clustering methods forgy cluster two hierarchical clus 8petal width length sepal width length figure 14 features standard point patterns features shown 80x top iris bottom standard data tering methods single complete link compared proposed methods compared four methods fully described 5 comparison based number misclassified points respect ground truth two hierarchical methods selected cluster points using links clustering graph theory similar proposed densitybased clustering two meth ods forgy cluster cluster points using coordinates similar proposed locationbased clustering misclassified points hierarchical methods counted best possible nonoverlapping point pattern partition closest ground truth dominant labels within correct clusters misclassified points partitional methods counted closest partition ground truth two input values variables 1 random seed location initial clustering 2 number expected clusters result summary clustering results terms misclassified points provided tables 1 2 3 synthetic standard data shown figures 11 12 14 order methods based performance shown right column table performance criterion sum misclassified points several point patterns known ground truth clusters shown second column right table best method class point patterns shown figure 11 proposed locationbased clustering see table 1 class point patterns shown figure 12 clustered accurately proposed densitybased clustering see table 2 combination location densitybased clusterings applied 80x iris data led best clustering results see table 3 eightdimensional point pattern 80x decomposed experimentally two lowerdimensional spaces one 4dimensional subspace features 1278 one 4dimensional subspace features 3456 order achieve result stated table 3 applying locationbased clustering n 4dimensional points followed densitybased clustering applied n 4dimensional points could separate 0 8x 8 x fourdimensional point pattern iris decomposed experimentally well clustering results better results locationbased clustering applied alone six methods used comparison applied class point patterns spatially interleaved clusters eg figures 3 10 proposed densitybased clustering outperforms methods method able separate spatially interleaved clusters time memory requirements time requirement running method linearly proportional number processed elements n point points n link links number used elements sample mean calculation element n cf 2ffi n cl 2 l k number processed links n link reduced sequential mapping clusters links clusters points therefore time requirement lowered time measurements taken various patterns example user time needed clustering point pattern points similar one figure 11 bottom takes average 006s table 1 number misclassified points resulting clustering data figure 11 method data pts order locat clus dens clus 1 11 8 11 31 6 single link 1 2 7 9 19 5 complete link 1 2 table 2 number misclassified points resulting clustering data figure 12 method data noise order locat clus dens clus 0 3 1 4 1 single link 9 14 13 36 6 complete link 0 11 4 15 2 table 3 number misclassified points resulting clustering 80x iris data method data 80x iris perform pts 150 pts p order locat dens clus 7 14 21 1 locat clus 24 14 38 4 dens clus single link 24 25 49 7 complete link 12 34 46 6 2 per one locationbased clustering 133s per one densitybased clustering sparc machine size memory required linearly proportional number processed elements n point points n link links 43 detection gestalt clusters gestalt clusters twodimensional clusters points perceived humans point groupings 1 10 goal section test properties proposed methods detecting describing gestalt clusters properties location densitybased methods demonstrated using data sample cluster problems 1 2 sample problems 1 1 composite cluster problem 2 particle track description 3 touching clusters 4 touching gaussian clusters 5 density gradient detection problems tackles one configurations clusters given point pattern configurations clusters refer properties individual clusters point pattern clusters detected properties exam ple location density clusters distribution points within cluster gaussian clusters spatial shape clusters lines particle tracks problems mutual spatial position clusters touching clusters surrounding clusters density gradient clusters point patterns containing clusters abovementioned properties figures 15 16 17 18 results corresponding gestalt clusters shown well results obtained using proposed methods two acceptable results figure 16 case touching clusters identical densities choice method similarity parameter shown result made manually proposed approach clustering elements points links gave rise location densitybased clusterings clusterings detect describe gestalt clusters equally well graphtheoretical methods using minimum spanning tree 1 cases point patterns similar figure require special treatment using graphtheoretical methods detecting removing denser cluster followed clustering rest points drawback present proposed methods 44 experimental results real data experimental results real data reported image texture analysis syn thesis analysis conducted 1 segmenting image regions 2 creating point pattern regions 3 clustering point pattern 4 presenting application dependent results following application goal represent image texture concise way suitable storage coding texture order achieve goal density texture primitives homogeneous regions assumed constant whole texture thus concise representation textures consist description primitives spatial distributions figure 19 left shows image regular texture tablecloth approximately constant density dark bright gray rectangles decomposition tablecloth sets dark bright gray rectangles performed 1 creating point pattern three features centroid locations average intensity value segmented regions 2 using densitybased clustering see result clustering figure 20 3 separating regions one image gave rise points grouped one cluster clustering decomposition shown figure top possible synthesis image shown figure 21 bottom synthesis starts painting background intensity largest region followed laying region representative cluster centroid locations cluster way textured image represented efficiently 1789437 dist00000000000 00 0262626 26 26 26 26 26262626 26 26 26 26 26 2626262626266060606060 figure 15 point pattern showing composite cluster problem problem particle track description top original data bottom result densitybased clustering dist dist 34 34 34 34 34 34 34 34 3434 34 34 34 34 34 3434 34 3434 3434 34 34 figure problem touching clusters top original data bottom results density left location right based clusterings origdata figure 17 problem touching gaussian clusters original data right result locationbased clustering dist 72 72 7272 72 72 72 72 72 72 72 72 72 72 72 72 72 figure problem density gradient detection original data right result densitybased clustering single pixel region based description 5 conclusion presented new clustering approach using similarity analysis two hierarchical clustering algorithms location densitybased clusterings developed based approach two methods process locations point separations denoted elements e methods start grouping elements clusters c e every element e elements c e dissimilar e fixed value dissimilarity two elements defined euclidean distance sample mean elements c e calculated clusters formed grouping elements similar resulting set clusters identified among clusters obtained varying clusters change large interval selected final partition order minimize intracluster dissimilarity maximize intercluster dissimilarity figure 19 image texture analysis image tablecloth left right original image segmented image contours segmented im age centroids segmented regions overlapped original image 7946564 dist0222222 figure 20 result densitybased clustering point pattern obtained figure 19 clustered numerical labels denote clusters corresponding dark blobs tablecloth label 2 white blobs tablecloth label 3 piece banana shown left corner label 78 background left top triangle shading banana label 0 figure 21 texture analysis synthesis image shown figure 19 decomposed reconstructed top row image decomposition analysis based obtained clusters shown figure 20 bottom row image reconstruction synthesis locationbased clustering achieves results identical centroid clustering densitybased clustering create clusters points spatially interleaved dissimilar densities separation spatially interleaved clusters unique feature densitybased clustering among existing methods accuracy computational requirements proposed methods evaluated thoroughly synthetic point patterns standard point patterns 8ox handwritten character recognition used quantitative experimental evaluation accu racy performance clustering methods compared four methods correct detections various gestalt clusters shown location densitybased clusterings used image texture analysis texture defined set uniformly distributed identical primitives primitives found segmenting image color homogeneous regions point pattern obtained textured images measuring centroid locations average colors primitives features point pattern divided two sets set features required different clustering model centroid locations primitives hypothesized uniform distribution therefore densitybased clustering applied form clusters lowerdimensional subspace corresponding features centroid locations properties primitives color modeled identical within texture therefore locationbased clustering applied form clusters second lowerdimensional subspace corresponding color feature resulting texture identified combining clustering results two subspaces nutshell clustering problem required 1 point pattern decomposition two lowerdimensional point patterns 2 location densitybased clusterings form clusters two point patterns 3 texture identification using clustering results decomposition approach motivated image texture analysis explored point patterns originated handwritten character recognition taxonomy problems contributions work summarized 1 addressing decomposition clustering problem two lowerdimensional problems 2 proposing new clustering approach detecting clusters constant property interior points location density 3 developing densitybased clustering method separates spatially interleaved clusters various densities acknowledgments authors greatfully acknowledge people provided data exper iments point patterns 1 2 21 mihran tuceryan texas instruments standard point patterns 80x iris chitra dorai permission anil jain authors thank providing four clustering methods chitra dorai professor anil jain pattern recognition image processing laboratory michigan state university research supported part advanced research projects agency grant n000149311167 national science foundation grant iri 9319038 r graphtheoretical methods detecting describing gestalt clusters extraction perceptual structure dot patterns dot pattern processing using voronoi neighborhoods shape texture integrating textureelement extraction surface estimation algorithms clustering data analysis john wiley sons inc uniformity homogeneity based hierarchical cluster ing pattern classification scene analysis john wiley sons inc freeman com pany binary division algorithm clustering remotely sensed multispectral images new clustering algorithm applicable multiscale polarimetric sar images texture segmentation using voronoi polygons advanced theory statistics comparison three exploratory methods cluster detection spatial point patterns models spatial processes segmentation multidimensional images extraction early perceptual structure dot pat terns integrating region boundary component gestalt tr ctr jos j amador sequential clustering statistical methodology pattern recognition letters v26 n14 p21522163 15 october 2005 qing song robust information clustering algorithm neural computation v17 n12 p26722698 december 2005 chaolin zhang xuegong zhang michael q zhang yanda li neighbor number valley seeking clustering pattern recognition letters v28 n2 p173180 january 2007 kuoliang chung jhinsian lin faster robust point symmetrybased kmeans algorithm pattern recognition v40 n2 p410422 february 2007 hichem frigui cheul hwang frank chunghoon rhee clustering aggregation relational data applications image database categorization pattern recognition v40 n11 p30533068 november 2007 ana l n fred jos n leito new cluster isolation criterion based dissimilarity increments ieee transactions pattern analysis machine intelligence v25 n8 p944958 august ana l n fred anil k jain combining multiple clusterings using evidence accumulation ieee transactions pattern analysis machine intelligence v27 n6 p835850 june 2005