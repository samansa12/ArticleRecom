enlarging margins perceptron decision trees capacity control perceptron decision trees typically performed controlling size prove quantities relevant reduce flexibility combat overfitting particular provide upper bound generalization error depends size tree margin decision nodes enlarging margin perceptron decision trees reduce upper bound generalization error based analysis introduce three new algorithms induce large margin perceptron decision trees assess effect large margin bias oc1 journal artificial intelligence research 1994 2 132 murthy kasif salzberg wellknown system inducing perceptron decision trees used baseline algorithm extensive experimental study real world data showed three new algorithms perform better least significantly worse oc1 almost every dataset one exception oc1 performed worse best marginbased method every dataset b introduction perceptron decision trees pdt introduced number authors different names 17 6 7 8 10 11 27 18 decision trees internal node associated hyperplane general position input space used many real world pattern classification tasks good results 7 18 9 given high flexibility feature share standard decision trees ones produced c45 20 tend overfit data complexity somehow kept control standard approach controlling complexity limit size early stopping pruning procedures paper introduce novel approach complexity control pdts based concept margin namely distance decision boundaries training points control quantity basis eectiveness systems vapniks support vector machines 12 adaboost 24 bayesian classifiers 13 prove quantity important treesize capacity control parameter theoretical motivations behind approach lie datadependent structural risk minimization 25 scale cover used vc theory provide bound generalization error depends margin hence hierarchy classes chosen response data course two complexity control criteria used together combining pruning phase bias towards large margins obtain better performance results motivate new class pdt learning algorithms aimed producing large margin trees propose three algorithms fat moc1 moc2 compare performance oc1 one best known pdt learning systems three largemargin systems outperform oc1 real world datasets used indicating overfitting pdts eciently combatted enlarging margin decision boundaries training data perceptron decision trees common decision trees node checks value single attribute could defined axis parallel tests associated node equivalent axisparallel hyperplanes input space many variations simple model proposed since introduction systems early 80s involve complex tests decision nodes usually testing one attribute decision trees whose nodes test linear combination attributes proposed dierent researchers dierent names linear combination trees multivariate dt 11 oblique dts 18 perceptron decision trees 27 etc first systems proposed breiman incorporated package cart10 tests associated node equivalent hyperplanes general position partition input space polyhedra illustrated figure 1 obviously include special case common decision trees output systems like c45 x x x x x x x x x x x x x x figure 1 perceptron decision tree way splits input space extreme flexibility systems makes particularly exposed risk overfitting ecient methods controlling expressive power typically pruning techniques always used combination standard topdown growth algorithms class functions computed pdts formally defined follows definition 21 generalized decision trees gdt given space x set boolean functions class gdtf generalized decision trees f functions implemented using binary tree internal node labeled element f leaf labeled either 1 0 evaluate particular tree input x x boolean functions associated nodes assigned argument x x argument x values assumed determine unique path root leaf internal node left respectively right edge child taken output function associated internal node 0 respectively 1 path known evaluation path value function x value associated leaf reached say input x reaches node tree node evaluation path x following nodes internal nodes binary tree leaves external ones examples given tree bdt gdt given tree cdt gdt kind decision tree defined continuous space output common algorithms like c45 cart refer cdts given tree pdt gdt assumed inputs augmented coordinate constant value hence implementing thresholded perceptron pdts generally induced means topdown growth procedure starts root node greedily chooses perceptron maximizes cost function usually measure impurity subsamples implicitly defined split maximization usually hard perform sometimes replaced randomized suboptimization subsamples mapped two children nodes procedure recursively applied nodes tree grown stopping criterion met tree used starting point bottomup search performing pruning tree implies eliminating nodes redundant unable pay terms cost function generally pruning overfitting tree produces better classifiers obtained early stopping since makes possible check promising directions fact worth exploring locally good solutions contrary deadend standard topdown algorithm extremely greedy procedure introduction pruning possible lookahead allows discovery hidden structure capacity control pdts hence completely achieved controlling size tree complexity overall classifier propose alternative method contrary focuses reducing complexity node classifiers independently tree size possible thanks theoretical analysis generalization performance function class defined pdts framework vc theory theoretical analysis generalization generalization performance learning machine studied means uniform convergence bounds technique introduced vapnik chervonenkis 30 central concept analysis eective capacity class hypotheses accessible machine richer class higher risk overfitting feature learning machine often referred flexibility capacity issue preventing overfitting allowing right amount flexibility therefore known capacity control notion eective cardinality function class captured growth function boolean classes covering numbers real valued functions size covering numbers depends accuracy covering well function class larger margin less accuracy required covering following concerned estimating capacity class pdts see margin aect flexibility hypothesis class treesize motivate alternative techniques controlling overfitting albeit conceptually similar pruning act complexity node classifiers rather complexity overall tree begin definition fatshattering dimension first introduced 15 used several problems learning since 1 4 2 3 definition 31 let f set real valued functions say set points x shattered f relative real numbers r x indexed x x binary vectors b indexed x function f b f satisfying fat shattering dimension fat f set f function positive real numbers integers maps value size largest shattered set finite infinity otherwise example relevant subsequent analysis consider class quote following result 5see also 12 theorem 32 5 let f lin restricted points ball n dimensions radius r origin following theorem bounds generalization classifier terms fat shattering dimension rather usual vapnikchervonenkis pseudo dimension let denote threshold function class functions f theorem 33 25 consider real valued function class f fat shattering function bounded function afat r n continuous right fix r learner correctly classifies independently generated examples z train error zero confidence 1 expected error h bounded k 8em importance theorem used explain classifier give better generalization would predicted classical analysis vc dimension essentially expanding margin performs automatic capacity control function classes small fat shattering dimensions theorem shows large margin achieved working lower vc class stress general bounds obtained better cases large margin observed priori guarantee margin occur therefore priori classical vc bound used view corresponding lower bounds generalization error terms vc dimension posteriori bounds depend favorable probability distribution making actual learning task easier hence result useful distribution favorable least adversarial sense result distribution dependent result despite distribution dependent traditional sense assumptions distribution made derivation benign behavior distribution automatically estimated learning process order perform similar analysis perceptron decision trees consider set margins obtained nodes bounding generalization function values turns bounding fat shattering dimension pdts viewed real function classifiers dicult therefore direct generalization analysis mimicking proof theorem 33 taking account margins decision nodes tree definition 34 let x pseudo metric space let subset x 0 set cover every exists b b da b covering number n minimal cardinality cover finite cover defined covering number f respect pseudometric measuring maximum discrepancy sample x respect distance f numbers bounded following lemma present historical reasons though fact require slightly general corollary lemma 35 alon et al 1 let f class functions x 0 1 p distribution x choose 0 1 let expectation e taken wrt sample x drawn according p corollary 36 25 let f class functions x b p distribution x choose expectation e samples x drawn according p position tackle main lemma bounds probability double sample first half zero error second error greater appropriate error interpreted dierently classified output tree order simplify notation following lemma assume decision tree k nodes denote fat f lin fat lemma 37 let perceptron decision tree k decision nodes margins 1 2 k decision nodes satisfying k correctly classified labeled examples x generated independently according unknown fixed distribution p support ball radius r second sample bound following probability less xy tree correctly classifies x fraction misclassified k k log8m using standard permutation argument 30 may fix sequence xy bound probability uniform distribution swapping permutations sequence satisfies condition stated consider generating minimal k 2covers xy value k suppose node tree margin hyperplane w satisfies therefore find xy whose output values within 2 w consider tree obtained replacing node perceptrons w corresponding f tree performs classification function first half sample margin node remains larger point second half sample incorrectly classified either still incorrectly classified adapted tree one decision nodes closer decision boundary k 2 point thus distinguishable left hand side points correctly classified margin greater k 2 node hence point must kept right hand side order condition satisfied hence fraction permutations allowed one choice functions covers 2 must take union bound choices functions covers using techniques 25 numbers choices bounded corollary 36 follows value lemma statement therefore ensures union bound less lemma 37 applies particular tree specified number nodes architecture fat shattering dimensions node practice observe quantities running learning algorithm generates tree hence obtain bound applied practice must bound probabilities uniformly possible architectures dimensions arise giving theorem give bound require two results first due vapnik 28 page 168 key bounding error probabilities terms probabilities discrepancies double sample lemma 38 let x set system sets x p probability measure x x second result gives bound number dierent tree architectures given number computational nodes theorem 39 21 number k k node decision tree skeletons combining two results lemma 37 obtain following theorem theorem 310 suppose able classify sample labeled examples using perceptron decision tree suppose tree obtained contained k decision nodes margins node bound generalization error probability greater less r radius sphere containing support distribution must bound probabilities dierent architectures trees dierent margins first use lemma 38 bound probability error terms probability discrepancy performance two halves double sample order apply lemma 37 must consider possible architectures occur architecture dierent patterns k decision nodes fixed value k theorem 39 gives number decision tree skeletons largest allowed value k fixed k bound number possibilities counts possible labeling k1 leaf nodes hence number applications lemma 37 fixed k since largest value k take let sum choosing applications lemma 37 ensures probability statements failing hold less 2 note replaced constant 8 order ensure continuity right required application theorem 33 upperbounded log4emk log4em hence applying lemma 38 case probability statement theorem fails hold less 4 experimental results theory presented previous section follows largemargin pdts likely generalize well bias toward largemargin trees implemented number dierent ways either postprocessing phase existing trees brand new impurity measure determine splittingstopping criteria topdown growth algorithms facilitate comparisons implemented three algorithms modifications one bestknown pdt learning systems oc1 18 murthy kasif salzberg freely available internet eect largemargin bias hence directly assessed running marginarbitrary version algorithm data first algorithm fat accepts input pdt constructed using oc1 outputs large margin version tree two moc1 moc2 dierent impurity measures take consideration margins three algorithms work multiclass data three systems compared oc1 10 benchmarking data sets results confirm predictions theoretical model clearly indicating generalization improved enlarging margin data sets used study 6 data sets used original oc1 paper18 4 data sets publicly available uci data repository 31 data sets studied 18 dim bright wisconsin breast cancer pima indians diabetes boston housing iris four additional data sets bupa sonar heart wisconsin breast cancer prognosis data sets dier greatly subjects sizes number attributes subjects data sets range medical astronomical sizes 150 4192 number attributes 4 60 1 details data sets see 18 31 data set single run 10fold crossvalidation carried relevant quantity experiment dierence test accuracy pdts arbitrary margins constructed oc1 pdts large margins data comparing learning algorithms drawn extensive attention recently 16 14 23 19 single run 10fold crossvalidation reasonable number data sets still preferred 1 number attributes points data set following bright142462 bupa6345 cer9 682 dim14 4192 heart13 297 housing 13506 iris4 150 pima8 768 prognosis32198 practical approach prone detect dierence two algorithms basically followed approach recommended 23 rest section first briefly review oc1 system present three large margin algorithms compare performances oc1 41 review oc1 oc1 18 randomized algorithm performs randomized hillclimbing search learning perceptrons builds tree topdown starting root node system chooses hyperplane minimizes predefined impurity measure eg information gain 20 gini index 10 twoing rule 10 18 etc system greedy stage chooses best split available randomized best split obtained means exhaustive search randomized hillclimbing process throughout study use twoing rule impurity measure oc1 fat moc1 moc2 uses modified twoing rule impurity measure impurity measures also applied fat moc1 without change moc2 would need minor changes twoing rule 1 total number instances current node number classes two class problems number instances left split ie w number instances right split ie w number instances category left split number instances category right split goodness measure rather impurity one oc1 attempts maximize split tree growth via minimizing 1twoingv alue details randomization pruning splitting criteria found 18 42 results fat description algorithm fat algorithm fat uses tree produced oc1 starting point maximizes margins involves finding node hyperplane performs split performed oc1 tree maximal margin done considering subsample reaching node perfectly divided two parts feeding data accordingly relabeled algorithm finds optimal separating separating hyperplane maximal margin linearly separable data optimal separating hyperplanes placed corresponding decision nodes new tree tested test data note pdt produced fat tree structure training accuracy original pdt constructed oc1 dier test accuracy use support vector machine svm algorithm 29 find optimal separating hyperplane conform definition pdt kernel used svm optimal separating hyperplane constructed input space algorithm fat 1 construct decision tree using oc1 call oc1pdt 2 starting root oc1pdt traverses nonleaf nodes node relabel points node x class right points node class left find perceptron optimal separating hyperplane separates class right class left perfectly maximal margin replace original perceptron new one 3 output fatpdt optimal separating hyperplane svm algorithm linearly separable case following problems solved node find optimal separating hyperplane linearly separable data 29 min subject w x corresponds class right corresponds class left number points reaching decision node computational reason usually solve dual problem 2 min subject fatpdt generalization error bounded theorem 310 observed fat completely relied restricted perceptron decision tree induced oc1 many cases margins splits found oc1 small fat little scope optimization general big margin top split root node fat generalize much better implies greedy algorithm oc1 good tree inducer fat sense margin need find better nongreedy tree inducer fat hand fat provides new approach applying support vector machine multiclass classification tasks comparison fat oc1 dataset 10fold crossvalidation used measure learning ability algorithm fat oc1 paired ttest used test dierence means fat oc1 10fold crossvalidation results fat vs oc1 oc1 10fold cv average accuracy fat 10fold average accuracy significant significant xy figure 2 comparison 10fold cv results fat versus oc1 point line indicates 10fold cv mean fat higher oc1 vice versa figure shows fat outperforms oc1 9 10 data sets outperformed 1 data set figure 2 see fat outperforms oc1 9 10 data sets outperforms oc1 6 data sets studied 18 10fold crossvalidation mean dierences fat oc1 9 data sets significant paired ttest applied one data set prognosis oc1 outperforms fat dierence significant also observed except one case prognosis fat performs good better oc1 every fold 10fold crossvalidation fat higher mean oc1 significant small level paired ttest even though dierence small strong indication perceptron decision trees large margins generalize better 10fold crossvalidation means p values summarized table 2 43 results moc1 description moc1 moc1 margin oc1 variation oc1 modifies objective function oc1 consider size margin underlying philosophy find separating plane tradeo training accuracy size margin node idea motivated support vector machine linearly nonseparable case minimizes classification error maximizes margin time svm soft margin minimizes sum misclassification errors constant c multiplying reciprocal soft margin svm tries find split high classification accuracy large soft margin analagously svm minimizes sum impurity measure constant times reciprocal hard margin moc1 algorithm minimizes following objective function objective impurity measure oc1 study default twoing rule used impurity measure current margin sum perpendicular distances hyperplane two nearest points dierent side current separating hyperplane scalar weight 0 1 points current node determines much large margin weighted selecting split tuning could improve performance determining weight margin also take number points current node consideration idea constant weight margin nodes good weight able adapt position current node size training examples current node since particularly interested finding tree highest possible accuracy rather demonstrating large margins improve generalization tune data set achieve highest possible accuracy set data sets words results moc1 presented best results possible comparison moc1 oc1 previous section use 10fold crossvalidation measure learning ability algorithm moc1 oc1 test dierence means moc1 oc1 paired ttest used figure 3 see moc1 higher 10fold crossvalidation mean oc1 8 10 data sets 5 significantly higher oc1 higher means two data sets cancer prognosis dierences tiny significant overall moc1 outperforms oc1 6 10 data sets good oc1 four six data sets studied 18 moc1 outperforms oc1 five performs well oc1 final one cancer see table 2 respective means p values oc1 10cv average accuracy moc1 average accuracy significant significant xy figure 3 comparison 10fold cv results moc1 versus oc1 point line indicates 10fold cv average moc1 higher oc1 vice versa figure shows moc1 outperforms oc1 6 10 data sets performs good oc1 four data sets 44 results moc2 description moc2 moc2 uses modified twoing rule directly incorporates idea large margin impurity measure unlike moc1 moc2 uses soft margin treats points falling within margin outside margin dierently impurity measure altered rest standard oc1 algorithm modified twoing rule mtr total number instances current node number classes two class problems number instances left split ie w number instances right split ie w number instances category left split number instances category right split number instances left split w mtr number instances right split w number instances category w number instances category w modified twoing rule goal node find split fewer points falling within margin accuracy outside margin good overall accuracy try achieve balance classification accuracy size margin want push apart two classes separating hyperplane far possible maintaining reasonable good classification accuracy hence improve generalization induced decision tree advantage moc2 free parameters tune comparison moc2 oc1 previous section 10fold crossvalidation used measure learning ability algorithms moc2 oc1 paired ttests used test dierence means moc2 oc1 figure 4 see moc2 higher mean 9 10 data sets slightly lower mean one data set housing 9 higher means 5 significantly higher one lower mean significant overall moc2 outperforms oc1 5 oc1 10cv average accuracy moc2 average accuracy 10fold cross validation results moc2 vs oc1 significant significant xy figure 4 comparison 10fold cv results moc2 versus oc1 point line indicates 10fold cv mean moc2 higher oc1 data set vice versa figure shows moc2 outperforms oc1 5 10 data sets performs well oc1 5 data sets 10 data sets performs well oc1 5 six data sets studied 18 moc2 outperformed oc1 three perform well oc1 three respective means p values summarized table 2 modified twoing rule opens new way measuring goodness split directly incorporates generalization factor measure experiments proven useful measure 45 tree sizes fat tree sizes exactly oc1 since fat pdt tree structure oc1 pdt fat replaces splits nodes oc1 pdt large margin perceptrons perform exactly splits ten data sets moc1 induced five smaller trees one size tree four larger trees compared leaves depth leaves depth leaves depth bright 540 280 620 320 570 290 bupa 500 280 210 110 740 360 cancer 250 130 400 250 290 150 heart 610 210 330 200 210 110 housing 1000 420 710 380 640 300 iris 320 210 320 210 300 200 prognosis 360 200 230 120 220 110 sonar 430 260 610 330 590 290 table 1 10fold cv average tree size oc1 fat moc1 moc2 x p value x p value x p value classifier bright 9846 9862 05 9894 10 9882 10 moc1 cancer 9589 9648 05 9560 9589 fat heart 7340 7643 12 7576 21 7778 10 moc2 housing 8103 8320 05 8202 8023 fat iris 9533 9600 17 9533 9600 fat pima 7109 7148 04 7318 08 7253 23 moc1 prognosis 7891 7415 7823 7959 moc2 table 2 10fold cv means oc1 fat moc1 moc2 oc1 moc2 induced five smaller trees five bigger trees compared oc1 find consistent pattern tree sizes table 1 list tree sizes oc1 fat moc1 moc2 46 summary experimental results theory states maximizing margins data points side separating hyperplane perceptron decision tree improve error bounds perceptron decision tree likely generalize better theory guarantee specific classifier low error rate 10fold crossvalidation results 10 data sets fat 9 higher means oc1 significantly higher moc1 7 higher means 6 significantly higher moc2 8 higher means 5 significantly higher equal lower means happened 3 data sets cancer moc1 slightly smaller mean oc1 moc2 mean oc1 housing moc2 slightly smaller mean oc1 prognosis fat significantly smaller mean moc1 also slightly smaller mean dierence significant classifiers highest mean fat produced four moc1 moc2 produced three oc1 produced none experiments believe pdts large margin likely smaller variance performance experiments cases fat moc1 moc2 produce classifiers smaller variances many significantly smaller though occasionally produce classifiers significantly larger variance however cannot draw confident conclusion variances therefore present study variances short experimental results show finding separating hyperplane large margin node perceptron decision tree improve error bound hence pdt likely higher average accuracy ie generalizes better furthermore believe improving error bounds margin maximization learning algorithm perform consistently likely smaller variance well conclusions experimental results presented paper clearly show enlarging margin improve generalization bias inserted growth algorithm providing trees specifically built minimize theoretical bound generalization error trees lose desirable features readability ease maintenance updating flexibility speed furthermore theoretical analysis algorithms shows dimension input space aect generalization performance hence possible conceive perceptron decision trees highdimensional feature space take advantage kernels marginmaximization support vector machines would provide side eect natural approach multiclass classification support vector machines theoretical results exist indicating tree size necessarily good measure capacity analysis also shows take advantage theoretical observation design learning algorithms control hypothesis complexity acting complexity nodeclassifiers hence whole tree three proposed approaches postprocessing method fat two margin based splitting criteria moc1 moc2 led significant improvement baseline oc1 method open question method best maximizing margins consideration every pdt algorithm r function learning interpolation generalization performance support vector machines pattern classifiers robust linear programming discrimination two linearly inseparable sets multicategory discrimination via linear program ming serial parallel multicategory discrimination support vector decision trees database marketing olshen r bayesian classifiers large margin hyperplanes hilbert space approximate statistical tests comparing supervised classification learning algorithms study crossvalidation bootstraping accuracy estimation model selection pattern recognition via linear pro gramming theory application medical diagnosis kasif assessing relevance determination methods using delve generalization neural networks machine learning learning decision trees using minimum description lenght principle growing pruning neural tree networks comparing classifiers pitfalls avoid recommended approach boosting margin new explanation e structural risk minimization datadependent hierarchies neural trees new tool classification estimation dependences based empirical data nature statistical learning theory uniform convergence relative frequencies events probabilities university california tr inferring decision trees using minimum description length principle c45 programs machine learning multivariate decision trees nature statistical learning theory networks fatshattering learnability realvalued functions scalesensitive dimensions uniform convergence learnability generalization performance support vector machines pattern classifiers approximate statistical tests comparing supervised classification learning algorithms comparing classifiers growing pruning neural tree networks boosting margin bayesian classifiers large margin hyperplanes hilbert space function learning interpolation ctr volkan vural jennifer g dy hierarchical method multiclass support vector machines proceedings twentyfirst international conference machine learning p105 july 0408 2004 banff alberta canada nello cristianini colin campbell chris burges editorial kernel methods current research future directions machine learning v46 n13 p59 2002 laurence hirsch robin hirsch masoud saeedi evolving lucene search queries text classification proceedings 9th annual conference genetic evolutionary computation july 0711 2007 london england martin anthony generalization error fixed combinations classifiers journal computer system sciences v73 n5 p725734 august 2007 martin anthony generalization error bounds threshold decision lists journal machine learning research 5 p189217 1212004