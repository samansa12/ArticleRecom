exploring hypermedia processor design space distributed hypermedia systems support collaboration important emerging tools creation discovery management delivery information systems becoming increasingly desired practical areas information technologies advance framework developed efficiently exploring hypermedia design space intelligently capitalizing tradeoffs performance area focus category processors programmable yet optimized hypermedia applicationthe key components framework presented paper retargetable instructionlevel parallelism compiler instruction level simulators set complete media applications written high level language media processor synthesis algorithm framework addresses need efficient use silicon exploiting instructionlevel parallelism found media applications compilers target multipleinstructionissue processorsusing developed framework conduct extensive exploration design space hypermedia application find enough instructionlevel parallelism typical media communication applications achieve highly concurrent execution throughput requirements high hand throughput requirements low little value multipleinstructionissue processors increased area improve performance enough justify use multipleinstructionissue processors throughput requirements lowthe framework introduced paper valuable making early architecture design decisions cache issue width tradeoff area constrained number branch units instruction issue width b introduction last decade multimedia services found increase use application systems education training office business information point sales 26 recent years wide spread use world wide web produced fertile ground multimedia services 4 5 hypermedia represents combination hypertext multimedia technologies 17 20 29 concept hypertext proposed 50 years ago v bush 6 nelson 37 generally credited first use term hypertext 18 two different models hypermedia 24 one model uses hypermedia deliver rigidly constrained embedded applications eg standalone cdrom based applications model distributed hypermedia widearea system information discovery management eg world wide web 5 hyperg 23 common model distributed hypermedia information systems three distinct roles supported passive participant informationservice provider active participation 24 last role emerging model collaboration hypermedia processor designers standpoint roles hypermedia systems must support present unique challenge since media tasks computationally demanding execute concurrently yet require reliable predictable operation example tasks video audio encodingdecoding text processing image processing authentication encryptiondecryption run parallel support hypermedia systems collaboration present approach distributed hypermedia system design space exploration applications support collaboration roles focus category processors programmable yet optimized run hypermedia application approach utilizes advances compiler technology architectural enhancements advances compiler technology instructionlevel parallelism ilp significantly increased ability microprocessor exploit opportunities parallel execution exist various programs written highlevel languages stateoftheart ilp compiler technologies process migrating research labs product groups 3 12 21 33 34 time number new microprocessor architectures introduced devices hardware structures well matched ilp compilers architectural enhancements found commercial products include predicated instruction execution vliw execution split register files 8 43 multigauge arithmetic variablewidth simd found family mpact architectures chromatic 22 designs microunity 19 multimedia extensions programmable processors also adopt architectural enhancement 28 39 key components framework presented paper retargetable ilp compiler instruction level simulators set complete media applications written high level language media processor synthesis algorithm discuss related works contributions section 2 section 3 presents preliminary materials including area model media application set experiment platform tools procedures measuring application characteristics using tools section 4 formulates search problem establishes complexity based problem formulation lay overall approach area efficient hypermedia processor synthesis solution space exploration strategy algorithm described section 5 tools algorithms extensively studied experimentation section 6 finally section 7 draws conclusions 2 related works contributions many articles summarize research efforts hypermedia systems 17 20 29 common internetbased hypermedia technologies world wide web 5 hyperg 23 represent distributed hypermedia systems widely available concept distributed hypermedia systems support collaboration emerging important idea distributed hypermedia systems becoming increasingly desired practical areas information technologies advance 24 since early 90s number efforts related design applicationspecific programmable processors applicationspecific instruction sets comprehensive survey works computeraided design application specific programmable processors found literature 16 38 35 particular great deal effort made combining retargetable compilation technologies design instruction sets 1 32 42 31 30 several research groups published results topic selecting designing instruction set processor architecture particular application domains 44 25 potkonjak wolf introduced hard realtime multitask asic design methodology combining techniques hard realtime scheduling behavioral synthesis 40 41 early work area processor architecture synthesis tended employ ad hoc methods small code kernels large part due lack good retargetable compiler technology conte mangionesmith 9 presented one first efforts consider large application codes written highlevel language spec similar goal ie evaluating performance efficiency including hardware cost evaluation approach substantially different conte menezes sathaye 10 refined approach consider power consumption efforts limited available compiler technology used single applications binary scheduled scalar machine execution superscalar implementations fisher faraboschi desoli 13 studied variability applicationsspecific vliw processors using highly advanced retargetable compiler however study considered small program kernels rather complete applications also focused finding best possible architecture specific application workload rather understanding difference best architectures across set applications unfortunately however know work addressing synthesis distributed hypermedia processors support collaboration quality requirements changes necessary take account timing synchronization requirements also throughput requirements designing hypermedia processor benefits advances compiler technology architectures also incorporated designing hypermedia systems lowlevel programming increasingly less practical focus category processors programmable yet optimized hypermedia application varying degrees throughput use stateoftheart ilp compiler simulation tools evaluate performance media applications variety multipleinstructionissue processors develop efficient optimal solution algorithm synthesis hypermedia processors although synthesis problem npcomplete find optimal solution algorithm practical typical hypermedia scenario design space exploration experiment reported paper include dynamic resource allocation instances media tasks arrive resources dynamically allocated arriving tasks main objective study viability design space exploration hypermedia processors using media applications written highlevel language 3 preliminaries section provide definitions terms present existing foundations describing target architecture area model media workload introduced last subsection explain experimental platform including tools procedures measuring application characteristics using tools 31 definitions assumptions use terms task individual application media application interchangeably refer task hypermedia application assume integrated circuit physically partitioned run different tasks parallel hence partition complete processor processor machine machine configuration used interchangeably throughout paper depending context used refer either single partition within processor hypermedia application entire set processors hypermedia application run time measurement platform individual applications divided fixed run time units called quanta experiment use one quantum length time taken encode decode 4 mpeg2 frames typical throughput 15 frames per second quantum size approximately 0267 seconds performance constraints used drive experiments based number processor cycles equivalent least one quantum cjpeg rawcaudio pegwitenc pegwitdec djpeg rawdaudio video stream image stream audio stream video stream image stream audio stream ecoding side decoding side figure 1 hypermedia scenario 32 target architecture target architecture use resembles multiprocessor system shared memory except processors given usage scenario laid single die media task assigned dedicated processor one media application assigned processor given performance constraints guaranteed met ie media tasks processor must finished within given time limit shared memory used data communication tasks processor maintaining cache multiple media applications assigned single processor flushing refilling cache accurately incorporated run time measurement platform defined previously divide tasks quanta one benefits using notion quantum simplifies synchronization several applications running multiple processors hypermedia applications realtime performance characteristics user receives benefit performance exceeds specified goals hence use quanta equivalent longest time frame tasks synchronized gives convenient task assignment unit allocate resources figure 1 shows one hypermedia scenario use evaluate framework scenario consists 8 media applications separated two distinctive sets media tasks encoder group decoder group figure illustrates synchronization boundaries media tasks example first quantum video audio still images encoded next quantum encoded data sets encrypted new video audio still images encoded pipeline fashion 33 area model use intel strongarm sa110 baseline architecture analysis 36 device singleissue processor classic five stage pipeline sa110 instruction issue unit integer execution unit integer multiplier memory management unit data instructions cache structures data instructions configuration issue ialu branch mem cache total 4 4 1 4 2 2 50 100 125 200 455 4328 table 1 processor configuration examples area estimates mm 2 configuration consists issue width number alus number branch units number memory units size instruction cachekb size data cachekb additional units phase locked loop pll fabricated 035m threemetal cmos process 035v thresholds 2v nominal supply voltage develop simple area model based sa110 area chip 4992mm 2 78mm theta 64mm approximately 25 die area devoted core 1248mm 2 issue unit branch unit occupies approximately 5 die area 250mm 2 integer alu loadstore unit consume roughly 5 die area 250mm 2 dmmu immu data instruction mmu occupies roughly 10 5mm 2 area rest core area used units write buffers bus interface controller assume area miscellaneous units relatively stable sense change increase issue width cache sizes assume vliw issue unit area model generally complexity model based area models used 13 2 particular use partitioned register files multicluster machines simplify model consequently areas components datapath register files generally superlinear complexity assumed linear complexity chip area model linear cycle speed remain constant across various machine configurations multicluster machines used model may extremely accurate may good enough demonstrate framework without going details building entire machine area arbitrarily configured vliw machine given branch branch nmemamem misc terms n issue issue nalu aalu n branch branch nmem amem misc issue width baseline issue unit area number alus area single alu number branch units branch unit area number memory units area single memory unit miscellaneous area respectively include floatingpoint units machine configurations applications used define issue 1 define ialu 1 define branch 1 define model superscalar enumerate resources resources declaration mem 00issue end figure 2 example highlevel machine description hmdes integer operations functional units multipliers cache area calculated using cache design tools 14 use cache parameters cache configurations except size number readwrite ports 64 bytes per line single bank external bus width 64 bits latency 4 cycles assume number readwrite ports number functional units set example area estimates superscalar machines different cache core configurations shown table 1 rest paper describe machine configuration 6tuple shown table 1 34 media applications set media applications used experiment composed complete applications publically available coded highlevel language use 8 applications culled available image processing communications cryptography dsp applications brief summaries applications data used shown table 3 detailed descriptions applications found 27 35 experiment platform use impact tool suit 7 measure run times media applications various machine configura tions impact c compiler retargetable compiler code optimization phases especially developed multipleinstructionissue processors target machine impact c described using highlevel machine description language hmdes highlevel machine description supplied user compiled impact machine description language compiler figure 2 shows example hmdes file impact provides cyclelevel simulation processor architecture implementation optimized code consumed lsim simulator simulation time lsim takes cache structure information provided user figure 3 shows flow simulation using impact tools source program written c impact compiler simulation results pcode hcode lcode highlevl machine description hmdes cycle time impact simulator icache dcache configuration limpactlsuperscalar 7 executables impact hmdes compiler mdes figure 3 performance measurement flow using impact tools configuration area mm 2 a1 a2 a3 m3 4 4 1 4 2 table 2 illustrative run time examples machine configuration consists issue width number alus number branch units number memory units size instruction cachekb size data cachekb application instr source description data file b data description jpeg encoder 139 independent jpeg image 101484 ppm bit map jpeg decoder 38 jpeg group encodingdecoding 5756 jpeg compressed mpeg encoder 11213 mpeg simul mpeg2 movie 506880 yuv 4 frames mpeg decoder 1755 ation group encodingdecoding 34906 mpeg2 httpwwwmpeg2de pegwit encryption 340 george barwood encryption 91503 plain ascii pegwit decryption 185 decryption 91537 pegwit encrypted adpcm encoder 68 jack jansen speech compression 295040 adpcm decoder 59 decompression 73760 adpcm encoded table 3 brief description applications data used experiment dynamic instruction count measured using spixtools sparc5 millions b bytes 4 problem formulation informally problem stated follows given set media applications performance constraints synthesize area optimal processor guarantees timing requirements applications assumptions given section 3 run times media task architecture consideration measured mesaured run times organized table shown table 2 one obvious albeit suboptimal solution obtained directly table selecting best processors individual task subsequently individual task assigned corresponding processor guarantees run time constraints example table 2 choose processors 1 2 media applications 1 3 respectively simpleminded solution good enough cannot find much parallelism across tasks run times applications selected processors similar cannot reduce run times applications increasing resources processor significant parallelism present tasks multipleinstructionissue processor little better singleinstructionissue processor words possible reduce run times individual task assign one task multipleinstructionissue processor satisfying timing requirements resources approach however result grossly inefficient solutions run times similar across tasks assuming 3 available example mentioned solution optimum solution unfortunately alluded solution problem longer trivial need run one task processor situation results find enough parallelism across tasks performance requirements justify use multipleinstructionissue processors thus requiring merging one tasks single processor example table 2 choose 1 since 2 3 run 3 turn without violating timing requirements sum areas two processors 5729 mm 2 smaller simpleminded solution 6553 discussed case problem size much bigger simpleminded case similar bin packing problem bpp 11 fact transform bpp problem polynomial time shown next section scenario subsets power set task set considered choose n processors n number tasks define problem using formal gareyjohnson format 15 selection problem instance given set n media applications run times e ij media applications machines c j c e question multisubset subset one instance processor included k processors c p c max j2m area machine c j j set tasks assigned machine j theorem selection problem npcomplete proof bin packing problem mapped special case selection problem given task set integer k 2 feje objects 2 excluding empty set power set k bins bpp mapped k processors note however simulation time measure run times task processor takes well two weeks depending experiment setup well worth try devise efficient algorithm obtain optimum solutions following section explain efficient optimal algorithm problem 5 system synthesis section informally explore processor selection space describe framework approach elaborate efficient algorithm optimum solutions 51 global design flow collect run times expressed number cycles media applications 175 different machine configurations 25 cache configurations 7 processor configurations first build executables media applications seven different architectures modify application way affect compiler ability find available ilp fact use applications box except eliminate graphical screen outputs compilation done advanced scheduling features designed multipleissuemachines turned processors considered machines single branch unit one one two four eightissue units machines two branch units one four eightissue units machines four branch units eightissue unit impact compiler generates aggressively optimized code increase achieved ilp core optimized code consumed lsim simulator simulate applications number different cache configurations executable benchmark simulate 25 combinations instruction cache data cache ranging 512 bytes 512 bytes 8 kb 8 kb simulations completed run efficient selection algorithm select machine configuration sets various performance constraints figure 4 shows global flow design process 52 synthesis algorithm following section develop branch bound based algorithm selection area minimal hypermedia processor configurations run times measured illustrated table 2 algorithm examines performance constraints machine models cache configurations find minimum area configuration elements pa meet constraint compute run times elements pa selection algorithm compile simulation measure run times figure 4 global design flow e set run times pa power set given media tasks possible combinations media task run times find best processor configurations entering branch bound loop algorithm finds area optimal processor element power set media applications step eliminates processors suboptimal terms running partial task sets size ranges 1 n n number media tasks subset tasks cannot find processor satisfy given timing constraint feasible solution run particular subset tasks processor algorithm given figure 5 6 run time algorithm dependent two factors size given task set timing constraint apparent size given task set affects run time combination tasks exponential respect number tasks lower timing constraint number feasible processors increases increase results limited pruning possible combinations tasks early stages algorithm experiment run sparc4 machines reported later run times algorithm ranges less one second strictest timing constraint approximately 50 seconds least strict timing constraint 6 experimental results evaluate framework presented paper conducting experiment set 8 media applications shown figure 1 range performance constraints examined 57 theta 10 6 447 theta 10 7 cycles maximum amount time allotted finish processing quantum worth computation experiment quantum size equal 0267 seconds implies speed constraint processors ranging 2137mhz 1676 mhz experiment tightest constraint 57 million cycles six processor components selected allow cycle times finish quantum need less processors less cache memory note processor configurations numbers eg 1 st constraint 57 million cycles 1 st processor constraint 162 millon cycles necessarily terms issue unit width number branch units forth figure 7 table 4 shows changes number selected processors overall area performance set media applications set processors set cache configurations construct run time table c set gamma fg set timing constraints timing constraint 2 branch bounds construct run time ablea mc 2 generate executable c 2 c time ij k cache return element find minimum area processor run tasks include processor return figure 5 synthesis hypermedia processors set branch bounds best node generate new nodess stack best node empty take node stack best cost node best else generate new nodess stack best node return best node generate new nodess stack best node 2 best insert stack figure 6 synthesis hypermedia processors continued peformance constraint number cycles millions area 6th processor 5th processor 4th processor 3rd processor 2nd processor 1st processor figure 7 minimum area configurations range cycle time constrains26101457 117 177 237 297 357 417 performance constraint number cycles millions issue width 6th processor 5th processor 4th processor 3rd processor 2nd processor 1st processor figure 8 issue widths minimum area configurations range cycle time constrains performance constraint number cycles milions number branch units 6th processor 5th prcoessor 4th processor 3rd processor 2nd processor 1st processor figure 9 branch widths minimum area configurations range cycle time constrains constraint loosens looser timing results reduction total number processors used also total area processor lower performance requirement applications fit onto single small processor rather separate multiissue processors phenomenon also seen figure 8 shows issue width processors performance constraint varies single issue processors dominant performance constraint range 147 theta 10 7 447 theta 10 7 number cycles reason single issue machines give performance per area wider issue machines available ilp applications compensate increase area wider issue units therefore wide issue machines appear viable choices 57 theta 10 6 117 theta 10 7 speed critical size branch units also shows similar characteristics figure 9 shows extreme case available would require 2 branch units single processor main reason result higher number branch units appear wide issue machines machines available ilp applications give equal amount speed figure show total size instruction cache icache data cache dcache performance constraint varies seems varying randomly however general trend cache requirement goes loosen constraint examining results reveals bumps total size goes local minimum local maximum occur exactly number processors reduced area processor saved reducing issue width transfered larger cache area applications run faster fit onto smaller number processors table 5 summarizes instruction data cache sizes cycles 1 st 2 nd 3 rd 4 th 5 th 6 th sum 57 682657 618987 809638 250326 210357 190315 276228 72 386433 314651 170273 682657 170273 1724287 87 140115 230284 145148 145148 27866 314651 1254006 102 175236 140115 140115 386433 260623 1102522 132 250326 180268 160226 170273 761093 192 160226 170273 180268 510767 222 145148 155194 15018 450522 252 210357 190315 400672 267 210357 160226 370583 282 190315 160226 350541 342 145148 15018 295328 372 140115 145148 285263 402 140115 140115 28023 417 140115 140115 28023 432 140115 140115 28023 table 4 required area mm 2 meet performance constraints instruction cache size kbytes 6th processor 5th processor 4th processor 3rd processor 2nd processor 1st processor figure 10 icache size minimum area configurations range cycle time constrains required meet variety cycle time constraints figure 12 13 show required cache amounts encoder group decoder group see figure 1 explanation terms respectively see dcache size roughly encoding decoding since working set temporal locality small case icache since encoding applications computationally intensive bigger inner loops example mpeg2enc requires 50 cycles encode number frames mpeg2dec decode processor configuration thus higher icache area usage seen encoding applications decoding performance constraint figure 14 shows area used encoding decoding combined sets encoding set require slightly area decoding set since combined set includes applications configuration combination choose total area used less sum area separated encoding decoding sets 7 conclusion distributed hypermedia system supports collaboration emerging tool creation discovery management delivery information distributed hypermedia systems becoming increasingly desired practical areas information technologies advance advances compiler technology architectural enhancements found commercial dsps motivated data cache size kbytes 6th processor 5th processor 4th processor 3rd processor 2nd processor 1st processor figure 11 dcache size minimum area configurations range cycle time performance constraint number cycles millions instruction cache size kbytes encoding apps decoding apps combined apps figure 12 required cache amount minimum area configurations encoding tasks cycles 1 st 2 nd 3 rd 4 th 5 th 6 th sum 162 282 372 417 432 table 5 cache variation data cache size kbytes encoding apps decoding apps combined apps figure 13 required cache amount minimum area configurations decoding tasks work thus approach presented paper makes use stateoftheart ilp compiler simulators notion multipleinstructionissue processors efficient algorithm combine processors optimized individual task set tasks minimize area resulting hypermedia processor although selection problem shown npcomplete found optimal solutions obtained reasonable run time practically sized problems using developed framework conduct extensive exploration area optimal system design space exploration hypermedia application found enough ilp typical media communication applications achieve highly concurrent execution throughput requirements high hand throughput requirements low need use multipleinstructionissue processors provide desirable benefits phenomenon due fact increased area produce enough performance gains justify use multipleinstructionissue processors throughput requirements low framework introduced paper valuable making early design decisions architectural configuration tradeoffs including cache issue width tradeoff area constraint number branch units issue width r instruction set design optimizations address computation performance cost analysis execution stage superscalar microprocessors treegion scheduling highly parallel processors world wide web information universe world wide web may think impact architectural framework multipleinstructionissue processors vliw architecture trace scheduling compiler determining costeffective multiple issue processor designs technique determine powerefficient introduction algorithms trace scheduling technique global microcode compaction computer architecture pipelined parallel processor design computers intractability guide theory npcompleteness embedded software realtime signal processing systems design technologies design issues dexterbased hypermedia system reflections notecards seven issues next generation hypermedia systems microunitys mediaprocessor architecture amsterdam hypermedia model adding time context dexter model highly concurrent scalar processing universal hypermedia systems distributed hypermedia heterogeneous builtin resiliency application specific programmable processors standardizing hypermedia information objects tool evaluating synthesizing multimedia communications systems media processing new design target viewing dexter open eyes retargetable generation code selectors hdl processor models instruction selection using binate covering code size optimization superblock effective technique vliw superscalar compilation effective compiler support predicated execution using hyperblock filestructure complex embedded software realtime signal processing systems application architecture trends mmx technology extension intel architecture cost optimization asic implementation periodic hard realtime systems using behavioral synthesis techniques heuristic techniques synthesis hard realtime dsp application specific systems memory bank register allocation software synthesis asips tis new evolution programming approach multiple behaviors design application specific programmable processors tr vliw architecture trace scheduling compiler reflections notecards seven issues next generation hypermedia systems introduction algorithms impact effective compiler support predicated execution using hyperblock superblock design issues dexterbased hypermedia system amsterdam hypermedia model viewing dexter open eyes worldwide web memory bank register allocation software synthesis asips instruction selection using binate covering code size optimization cost optimization asic implementation periodic hardreal time systems using behavioral synthesis techniques customfit processors mediabench computer aided design faulttolerant application specific programmable processors computer architecture computers intractability microunitys mediaprocessor architecture mmx technology extension intel architecture hardwaresoftware interactions mpact treegion scheduling highly parallel processors evolution programming approach multiple behaviors design application specific programmable processors retargetable generation code selectors hdl processor models technique determine powerefficient highperformance superscalar processors complex information processing instruction set design optimizations address computation dsp architectures