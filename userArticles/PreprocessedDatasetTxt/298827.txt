dynamically configurable message flow control faulttolerant routing abstractfaulttolerant routing protocols modern interconnection networks rely heavily network flow control mechanisms used optimistic flow control mechanisms wormhole switching ws realize good performance prone deadlock presence faults conservative flow control mechanisms pipelined circuit switching pcs ensure existence path destination prior message transmission achieving reliable transmission expense performance paper proposes general class flow control mechanisms dynamically configured tradeoff reliability performance routing protocols designed vicinity faults protocols use conservative flow control mechanism majority messages traverse faultfree portions network utilize ws like flow control maximize performance refer protocols twophase protocols ability provides new avenues optimizing message passing performance presence faults fully adaptive twophase protocol proposed compared via simulation based ws pcs architecture network router supporting configurable flow control also described b introduction modern multiprocessor interconnection networks feature use message pipelining coupled virtual channels improve network throughput insure deadlock freedom 692124 messages broken small units called flits flow control digits 9 wormhole switching ws data flits immediately follow routing header flits network 9 routing algorithms using ws characterized optimistic network resources eg buffers channels committed soon become available optimistic nature leads high network throughput low average message latencies however presence research supported part grant national science foundation grant ccr9214244 grant spanish cicyt grant tic940510c0201 preliminary version paper presented part 22nd annual international symposium computer architecture santa margherita ligure italy june 1995 faults behavior lead situations routing header become blocked longer make progress hence cause network become deadlocked typically additional routing restrictions andor network resources required ensure deadlock freedom presence faults 45811 example fault rings constructed around convex faulty regions using additional virtual channels attendant routing restrictions 4 additionally source hardware synchronization mechanisms proposed change routing decisions presence faults 20 partially adaptive routing around convex fault regions additional channels feasible 5 recently use timeouts deadlock recovery mechanisms proposed 22 alternatively pipelined circuit switching pcs flow control mechanism path setup data transmission stages decoupled 15 header flits first routed construct path presence faults header may perform controlled limited backtracking opposed ws routing algorithms based pcs conservative nature committing data network complete path established result extremely robust reliable communication protocol however path setup exact significant performance penalties form increased message latencies decreased network throughput especially short messages paper proposes use configurable flow control mechanisms fully adaptive routing pipelined networks paper contributes dynamically configurable flow control mechanisms lowest level twophase routing protocols routing layer routing protocols designed vicinity faulty components messages use pcs style flow con trol controlled misrouting backtracking used avoid faults deadlocked configurations time messages use ws flow control faultfree portions network attendant performance advantages protocols referred twophase protocols fully adaptive deadlockfree twophase protocol faulttolerant routing meshes tori proposed analyzed paper formal properties twophase routing established results experimental evaluation presented evaluation establishes performance impact specific design decisions addresses choice conservative vs configurable flow control faulttolerant routing discusses related deadlocklivelock freedom issues finally paper describes architecture operations single chip router implementing twophase routing protocols distinguishing features approach rely additional virtual channels already needed fully adaptive routing ii performance considerably better conservative faulttolerant routing algorithms equivalent reliability iii based flexible fault model ie supports link andor node faults require convex fault regions iv supports existing techniques recovery dynamic transient failures links switches vi provides routing protocols greater control hardware message flow con trol opening new avenues optimizing message passing performance presence faults following section introduces definitions network channel fault mod els new class flow control mechanisms introduced section 3 section 4 introduces fault tolerant routing section 41 provides analysis routing properties required deadlock freedom section 42 introduces fully adaptive twophase routing protocol meshes tori architectural support discussed section 5 results simulation experiments presented section 6 paper concludes plans implementation router future research directions preliminaries 21 network model although twophase routing used topology theoretical results generally topology specific class networks considered paper torus connected bidirec tional kary ncubes multidimensional meshes kary ncube hypercube n dimensions k processors dimension torus connected kary ncubes processor connected immediate neighbors modulo k every dimension multidimensional mesh similar kary ncube without wrap around connections message broken small units referred flow control digits flits flit smallest unit flow control performed represents smallest unit communication pipelined network processing element pe network connected routing node pe routing node operate concurrently assume one physical links routing node used pe connection network communication links fullduplex links channel width flit size assumed equivalent number virtual channels implemented direction physical channel virtual channel realized independently managed flit buffers share physical channel bandwidth flitbyflit basis mechanism described 6 used allocate physical channel bandwidth virtual channels demanddriven manner flits moved input channel buffers output channel buffers within node internal crossbar switch given header flit routed network intermediate node routing function specifies set candidate output virtual channels may used message selection function used pick channel set 12 profitable link link message header moves closer destination backtracking protocol one may acquire release virtual channels path setup releasing virtual channel used corresponds freeing buffers crossbar ports used message channel 22 virtual channel model following virtual channel model used paper unidirectional virtual channel v composed data channel corresponding channel complementary channel referred virtual channel trio 15 routing header traverse subsequent data flits traverse complementary channel reserved use special control flits corresponding channels complementary channels essentially form control network coordinating fault recovery adaptive routing header flits including limited controlled backtracking header flits complementary channel trio traverses physical channel direction opposite associated data channel channel model illustrated figure 1a two virtual channels v v r v j v r2 r1 one message progress data channel therefore compared existing channel models model requires exactly 2 extra flit buffers data channel one corresponding channel complementary channel respectively since control flit traffic small percentage overall flit traffic practice control channels across physical link multiplexed single virtual control channel 1 shown figure 1b example control channel c 1 figure 1b corresponds flit buffers v r v v j c v c 23 fault model online fault detection difficult problem paper assume existence fault c detection mechanisms focus information may used robust reliable com munication detection mechanisms identify two different types faults either entire processing element associate router fail communication channel may fail physical link fails virtual channels particular physical link marked faulty pe router fail physical links incident failed pe also marked faulty addition marking physical channels incident failed pe faulty physical channels incident pes adjacent failed pes andor communication channel may marked unsafe unsafe channel 23 designation useful routing across may lead encounter failed component protocols present section 42 use unsafe channels figure 2 shows failed pes failed physical links unsafe channels two dimensional mesh network failed pe longer send receive messages thus removed multiprocessor network failures either static dynamic static failures present network system powered dynamic failures occur random operation types failures considered permanent ie remain system repaired static failures dynamic failures occur idle links routers header flits encounter failed links routing protocols attempt find alternative paths figure 1 interrouter virtual channel model logical channel model 2 virtual channels routers r1 b implementation logical channel model c c c c c c r c r however dynamic failures occur busy links interrupt message transmission fur thermore failure transmission flit across channel cause flit lost since header flits contain routing information data flits whose progress blocked failure cannot progress remain network holding resources eventually cause deadlock rely existence recovery mechanism removing dead flits network exist least two techniques implementing distributed recovery 16 22 dynamic faults cases failure link generate control information propagated upstream andor downstream along message path resources along path recovered alternatively third approach recovering messages interrupted fault found 8 schemes nontrivial require hardware support developed elsewhere 8 22 16 assume existence technique evaluate performance impact section 6 scouting switching family flow control mechanisms scouting switching ss flow control mechanism configured provide specific tradeoffs fault tolerance performance ss first data flit constrained remain k links behind routing header flow control equivalent wormhole switching large values ensure path setup prior data transmission path exists figure 3 illustrates timespace diagram messages pipelined five links using ss mechanisms parameter k referred scouting distance probe lead every time channel successfully reserved routing header returns positive acknowledgment acknowledgments flow direction opposite figure 2 failed nodes unsafe channels faulty node faulty channel unsafe channel routing header gap header first data flit grow 2k 1 links header advancing routing header backtracks must send negative acknowledg ment associated virtual channel programmable counter virtual channel reserved header increments counter every time receives positive acknowledgment decrements counter every time receives negative acknowledgment value counter equal k data flits allowed advance performance reasons acknowledgments sent across channels case data flits immediately follow header flit example figure 4 header blocked faulty links node first data flit constrained remain k links behind header node b figure see header backtrack releasing link establish alternate path across link c statically fixing value k fix tradeoff network performance overhead positive negative acks fault tolerance ability header backtrack routed around faults dynamically modifying k gain improved runtime tradeoffs fault tolerance performance l message length flits l number links path k scouting dis tance derive expressions minimum message latency type routing mech figure 3 timespace diagram ws scouting pcs su data data data su su data scouting pipelined circuit switching route setup data transmission routing header pcs acknowledgment data flit scouting acknowledgment wormhole switching anism 4 faulttolerant routing basic idea proposed paper messages routed one two phases messages traversing faultfree segments network routed using protocols based ws messages traverse segment network faults conservative flow control mechanism associated faulttolerant routing protocol employed use ss flow control made dynamically simply modifying value k design effective twophase protocols dependent upon relationships scouting distance k ii number faults f iii number links header flit may forced backtrack routing around faults b iv number steps header may routed along nonminimal paths analysis following subsection establishes relationships kary ncubes multidimensional meshes section 42 describes fully adaptive twophase faulttolerant routing protocol 41 analysis messages assumed always follow shortest paths absence faults figure 4 backtracking faulty region data flit progress failed channel routing header progress scouting l header encounters faulty link allowed either misroute backtrack preference given misrouting theorem 1 absence previous misrouting maximum number consecutive links header flit backtrack torus connected kary ncube single sourcedestination path number faulty components proof previous misroutes header flit allowed misroute presence faults even number misroutes limited thus header backtrack healthy channel one previously used reach node figure 5 case kary ncube every node 2n channels incident distinct pe since header arrived nonfaulty pe forced backtrack 2n 1 channels faulty next node since header backtracked nonfaulty pe originally arrived nonfaulty pe forced backtrack remaining 2n 2 channels faulty additional backtracking step forced 2n 2 additional failed channels thus consider second case shown figure 5 turn end alley order cause routing header backtrack initially needs 2n 1 faulty channels second backtrack requires 2n 2 faulty channels third backtrack necessitated 2n 3 node figure 5 node faults causing backtracking case 1 case 2 faulty node faulty link faults 2n 2 channel faults subsequent backtracks require 2n 2 additional faults thus theorem 2 absence previous misrouting maximum number consecutive links header flit backtrack ndimensional mesh single sourcedestination path number faulty components proof previous misrouting operations message allowed misroute presence faults even maximum number misrouting operations limited several possible cases routing probe node 2n channels case torus connected kary ncube hence number faults required force first backtrack 2n 1 force additional backtracks 2n 2 additional faults required per additional backtrack probe node less 2n channels earlier cases channels except one used reach node used case faults either routing misrouting worst case figure 6a occurs node minimum number channels ndimensional mesh nodes located corners n channels one channels used probe reach node hence failure n 1 channels nodes causes routing probe backtrack probe edge mesh node channels one channel already used reach node first time another one previous backtracking operation therefore n 1 channels available routing channels must faulty force backtrack operation thus maximum number mandatory backtrack operations f div n 1 f number faults consider second case shown figure 6b turn end alley exists order cause initial backtrack needs n faults n 2 faults required cause backtrack corner processing element additional backtrack requires n 1 ii faults hence maximum number backtracking operations f 1 div n 1 ii n 1 faulty channels n 2 faulty nodes first additional backtracks theorems establish relationship number backtracking operations number faults meshes tori consider relationship number misrouting operations number faults number backtracking steps determined configuration faults specified following theorem useful determining scouting distance theorem 3 torus connected kary ncube less 2n faults maximum number consecutive backtracking steps b header make forward progress 3 iii figure 6 faults causing backtracking mesh faulty link faulty node b figure 7 fault configuration showing required search inputs one plane legend sourcedesination node failed node failed channel maximum number misroutes allowed 6 ii misrouting preferred backtracking iii necessary output channel selected routing function misrouting mes sage dimension input channel message proof consider figure 7 adjacent nodes destination one plane faulty routing header would take maximum six misroutes check possible input links destination lying within plane eliminate two dimensions search n possible dimensions permitted misroutes used routing header arrives previously visited node routing header must backtrack backtracking misroute removes path decrements misroute count routing header backtracks two hops point figure 7 point routing header take one misroute n 2 remaining dimensions j example j one two dimensions forming plane figure 7 routing header two hops away node adjacent destination lying along dimension j routing header check see node faulty one profitable hop node faulty routing header forced backtrack two hops back point alternatively two hops header check link adjacent destination faulty case maximum backtrack distance three hops back point point one misroute two profitable routes routing header check status every node one hop away destination andor every link adjacent destination since number faults allowed system limited 2n 1 existence one healthy node one healthy channel adjacent destination guaranteed hence maximum number backtracks routing header perform three theorem 4 ndimensional mesh less n faults maximum number consecutive backtracking steps b header make forward progress 3 maximum number misroutes allowed 6 ii misrouting preferred backtracking iii necessary output channel selected routing function misrouting message dimension input channel message proof consider case destination node cannot surrounded faults plane iii node failures considered number backtracks required per backtracking operation 2 figure 8 shows corner mesh 3 corner node mesh two three inputoutput channels corner node faulty routing probe entering corner node forced backtrack one step however since cannot additional faulty links nodes network due limit number faults routing probe reach destination without backtracking operations routing probe corner node node edge mesh since node edge mesh since maximum n 1 faults allowed backtracking required misrouting preferred backtracking consider case destination node surrounded faults plane means situation similar shown figure 7 occurs even nodes edge mesh number misroutes limited 6 results theorem 3 applied maximum number consecutive backtracking steps 3 2n n faults required disconnect network kary ncube ndimensional mesh respectively however practice network often remain connected considerably larger number failed nodes channels total number faults allowed greater 2n n possible messages may undeliverable allowed remain network messages impact performance may lead deadlock techniques described 62section 23 used detect remove messages figure 8 backtracking corner node mesh failed link failed node network 42 twophase routing protocol routing protocols operate two phases optimistic phase routing faultfree segments conservative phase routing faulty segments former uses existing fully adap tive minimal routing algorithm 12 section propose two candidates conservative phase candidates differ primarily impact performance function number faults proposed twophase tp protocol shown figure 9 operates follows absence faults tp uses deadlockfree routing function based duatos protocol dp 12 dp virtual channels physical link partitioned restricted unrestricted partitions fully adaptive minimal routing permitted unrestricted partition adaptive deterministic routing allowed restricted partition deterministic channels selection function uses priority scheme selecting candidate output channels router node first selection function examines safe adaptive channels one channels available either due faulty busy selection function examines structure twophase routing detour complete completed detour destination reached detour completed reset header dp mode end dp route using dp routing restrictions unsafe channels select safe profitable adaptive channel return select safe deterministic channel return safe deterministic channel faulty return blocks progress end select unsafe profitable adaptive channel acks sent sent depending switch ss mode set ack counter one two different conservative phases tp routing used select unsafe deterministic channel switch ss mode set ack counter set header detour mode end detour route restrictions detour mode select profitable channel return misroutes end end figure 9 structure twophase routing safe deterministic channel safe deterministic channel busy routing header must block wait channel become free safe adaptive channel becomes free deterministic channel freed header free take adaptive channel deterministic channel faulty selection function try select profitable adaptive channel regardless safe unsafe selection function select unsafe channel available safe channel unsafe channel selected alternative misrouting backtracking unsafe profitable channel selected output channel message enters vicinity faulty network region indicated setting status bit routing header subsequently counter values every output channel traversed header set k values k 0 permit routing header backtrack avoid faults need arises message flow control conservative supporting flexible protocols routing around faulty regions unsafe profitable channel available header changes detour mode detour mode positive acknowledgments generated positive acknowledg ments data flits advance construction detour routing header performs depthfirst backtracking search network using maximum misroutes adaptive channels used construct detour detour complete misroutes made construction detour corrected destination node reached detour complete ss acknowledgments flow data flits resume progress note channels none detour accepted data flits resume progress required ensure deadlockfreedom detour mode identified setting status bit header desirable remain ws faultfree routing optimistic phase alternatives possible conservative phase conservative phase tp figure 9 header enters ss mode unsafe channel selected alternatively conservative phase may chose continue optimistic ws flow control across unsafe channels case necessary mark channels unsafe ws forward progress stopped due faults detours constructed using increased misrouting necessary detour completed one acknowledgment sent resume flow data flits note case always positive negative acknowledgments transmitted larger values k used figure 9 increased ability backtrack route around fault regions reduces probability constructing detours thus see choice k tradeoff acknowledgment traffic increased misroutingbacktracking occurs detour construction expect choice appropriate value k dependent upon network load failure patterns tradeoffs evaluated section 6 note proofs deadlock freedom rely unsafe channels therefore designer freedom configuring appropriate mechanisms function failure patterns figure shows routing example using twophase routing protocol shown figure seven node failures initially set 0 routing header routes node b forced cross unsafe channel value k increased 3 header routes profitably node data flits advancing node b node routing header cannot make progress towards destination entering detour mode misrouted upwards two additional misroutes longer misrouted due limit routing header forced backtrack node since output channels select routing header forced backtrack node c misrouted twice downwards finds profitable links destination case detour completed destination reached also notice data flits advance header detour mode thus first data flit still node b comparison purposes consider use alternative conservative phase described figure 10 routing example failed channel failed node unsafe channels used k always 0 referring figure 10 routing header routed profitably node case thus first data flit also reaches node since cannot routed profitably node detour constructed header misrouted upwards three links cannot find path around fault region therefore forced backtrack back node routing header forced misroute node c node c misroutes downwards traverses path destination notice case path two hops longer since data flits pass node however header routed node b node acknowledgment flits generated two examples indicate specific choice flow controlrouting protocol conservative phase tradeoff dictated fault patterns network load theorems section 41 cover networks fixed number faults arbitrary number faults f small values destination node failures possible header may backtrack location first data flit fact may occur links simply busy rather faulty one solution retry point however possible also succeed point rely recovery mechanism referenced section 23 tear path designed retry source successive failures establish path source higher level protocol relied upon take appropriate action behavior particularly addresses messages destined failed nodes certain number attempts higher level protocol may mark node unreachable source livelock addressed fashion following theorem establishes deadlock freedom tp theorem 5 twophase routing deadlockfree proof let c set virtual channels c 1 set deterministic channels c 2 set adaptive channels following situations occur message routing routing header encounter faulty nodes channels tp routing uses dp routing restrictions shown deadlockfree faultfree network 12 routing header encounters unsafe channel selects safe channel unsafe channel deadlock occur since safe adaptive channel still contained set virtual channels c 2 routing set cannot induce deadlock routing header forced take unsafe adaptive channel deadlock occur since unsafe channels still channel set c 2 routing c 2 cannot induce deadlock routing header encounters faulty node channel cannot route profitably cannot take deterministic channel c 1 faulty routing header constructs detour deadlock occur building detour probe always backtrack node first data flit resides deadlock occur attempt construct detour several retries detour cannot constructed recovery mechanism tear path thus releasing channels occupied message detour uses adaptive channels channels c 2 deadlock arise routing message detour constructed taking account condition complete detour ordering channels deterministic channels c 1 still preserved finally detour uses adaptive channels c 2 thus building detour prevent messages using deterministic channels avoid deadlock 5 architectural support figure 11 illustrates block diagram router implements twophase routing modified version pcs router described 1 input output physical channel associated link control unit lcu input lcus feed firstinfirstout fifo data input buffer dibu virtual channel input control channels multiplexed single virtual channel therefore feed single fifo control input buffer cibu data fifos feed inputs crossbar control fifos arbitrate access routing control unit rcu rcu implements twophase routing protocol select output link maps appropriate input link crossbar selected output link modified control flit sent rcu output arbitration unit appropriate control output virtual chan nel lcus dibus support ss flow control described later section single chip version router pcs flow control implemented metal layer cmos process fabricated mosis 1 overall design contains 14000 transistors 0311 cm square chip 88 pins core logic router chip consumes 55 chip area crossbar occupies 14 area dedicated core circuitry additional 10 logic payload devoted rcu routing header figure 12 twophase protocol consists six fields first field header bit field identifies flit routing header second field backtrack field bit signifies whether routing header going towards source ie backtracking towards destination next field misroute field records number misrouting operations performed routing header since twophase protocol must allowed maximum 6 misroutes ensure delivery message network 2n 1 node faults field three bits size fourth field detour bit bit used control logic determine message detour mode bit clear ss bit set figure 11 overview router chip lcu cpu cpu data buffer inputoutput control buffer inputoutput data input bus data output bus control input bus control output bus legend cibucobu dibudobu lcu lcu lcu lcu lcu lcu lcu crossbar rcu rcu rcu input enable buffers figure 12 format header flits bit header backtrack misroute detour xnoffset x2offset x1offset ss router generates acknowledgment flit every time routing header advances acknowledgments propagated complementary control channel following detour field ss bit ss bit set ss flow control used across every channel traversed header thus setting counter k next field actually set offsets one offset n dimensions kary ncube size depends size interconnection network ie value k depending upon conservative phase implemented physical channel require unsafe channel status bit maintained rcu routing header enters rcu input virtual channel address used access unsafe channel store history store history store maintains record output channels searched backtracking header figure 13 shows organization rcu major distinguishing features router architecture due support backtracking search done header detailed discussion architectural requirements routing found 15 1 associated virtual channel counter recording acknowledgments register value k scouting distance two bit counter required virtual channel counters maintained counter management unit cmu rcu positive negative acknowledgment flit arrives virtual circuit cmu increments decrements counter corresponds data virtual channel counter value k data flits allowed flow otherwise blocked dibu show figure 14 figure 13 routing control unit channel mappings decision unit incdec banks history store decode unsafe store header modified output virt chan dibu enable input virt chan header unit counter management achieved providing dibu output enables rcu finally rcu propagate acknowledgment beyond first data flit message 6 performance evaluation performance faulttolerant protocols evaluated simulation studies message passing 16ary 2cube messages routing header 1 flit long simulator performs timestep simulation network operation flit level message destination traffic uniformly distributed simulation runs made repeatedly 95 confidence intervals sample means acceptable less 5 mean values simulation model validated 14 using deterministic communication patterns use congestion control mechanism similar 3 placing limit size buffer eight buffers per injection channel injection channels input buffers filled messages cannot injected network message buffer routed flit crosses link one cycle performance tp compared performance duatos protocol dp 12 dp wormhole based routing protocol partitions virtual channels two sets adaptive escape adaptive channels permit fully adaptive minimal routing escape channels used implement deadlockfree subnetwork measure fault tolerance tp compared misrouting backtracking misroutes mbm 15 mbm pcs based routing protocol allows fully adaptive routing misroutes per virtual circuit figure 14 data flit flow control cobu cibu rcu arb rcu dobu dobu dobu crossbar enable lines rcu dibu dibu dibu crossbar router router b metrics used measure performance tp average message latency network throughput average message latency average time messages spend network respective routing headers injected network time tail flit consumed destination node network throughput defined total number flits delivered divided number nodes network total simulation time clock cycles faults present network tp routing uses dp routing restrictions results performance identical dp fault performance tp evaluated configuration tp uses faulty regions ie use unsafe channels uses misrouting backtracking search construct detours header cannot advance 61 static faults figure 15 plot latencythroughput curves tp mbm 1 10 20 failed nodes randomly placed throughout network theorems developed paper depend number faults less degree processing elements ie connected kary ncube plots show performance tp larger values faults faults randomly distributed throughout network randomly placed 2n 1 faults perturb system significantly performance routing protocols drop number failed nodes increase since number undeliverable figure 15 latencythroughput tp mbm node faults throughput latency clock cycles latency vs throughput tp mbm faulty network mbm 1f mbm 10f mbm 20f messages increases number faults increase however latency tp routed messages given network load remains 30 40 lower mbm routed messages mbm degrades gracefully steady small drops network saturation traffic load saturation traffic network load average message latency increases dramatically little increase network throughput number faults increases figure 16a shows latency messages successfully routed via mbm remains relatively flat regardless number faults system number parenthesis indicates number messages offerednode5000 clock cycles however network offered load 02 flitsnodecycle 30 msgsnode5000 cycles latency increased considerably number faults increased low number faults system offered load flitsnodecycle saturation point network congestion control mechanism provided simulator additional offered load accepted however saturation point increases number faults cause aggregate bandwidth network increase beyond saturation therefore cause message latency increase network throughput drop offered load 032 flitsnodecycle network already beyond saturation increase number faults lesser effect low moderate loads lower number faults latency throughput characteristics tp significantly superior mbm majority benefit derived messages faultfree segments network transmitting trol tp however performed poorly number faults increased saturation traffic figure 16 latency throughput tp mbm function node faults node failures20006000latency clock cycles latency vs node faults tp mbm tp 1 mbm 1 mbm 30 node failures010030throughput throughput vs node faults tp mbm tp 1 mbm 1 mbm 30 one failed node 032 flitsnodecycle dropped slightly 20 failed nodes 17 original network throughput simulated system 16 ary 2cube 2n 1 faults 3 hence 20 failed nodes much greater limit set theorems proposed paper figure 16 also shows latency throughput tp function node failures varying offered loads higher loads increased number faults effect positive acknowledgments due detour construction becomes magnified performance begins drop due increased number searches routing header perform path successfully established corresponding increase distance source node destination tradeoff version tp increased number detours constructed vs performance messages faultfree sections network larger numbers faults former eventually dominates region purely conservative protocols appear remain superior summary lower fault rates network saturation loads tp performs better conservative counterpart also note tp protocol used experiments designed 3 faults 2 dimensional network relatively conservative version could configured figure 17 compares performance tp one fault network low network traffic versions realize similar performance however high network traffic larger number faults aggressive tp performs considerably better due fact k 0 substantial acknowledgment flit traffic introduced throughput flitscyclenode10002000latency clock cycles latency vs throughput conservative vs aggressive sr aggressive 1f aggressive 10f aggressive 20f conservative 1f conservative 10f conservative 20f figure 17 comparison aggressive conservative ss routing behavior network dominating effect increased number detours 62 dynamic faults dynamic faults occur messages may become interrupted 16 special type control flit called kill flit introduced permit distributed recovery message pipeline interrupted pes span failed channel pe release kill flits virtual circuits affected kill flits follow virtual circuits back source destination messages control flits release reserved buffers notify source message delivered notify destination ignore message currently received also interested guaranteeing message delivery presence dynamic faults complete path must held last flit delivered destination message acknowledgment sent destination traverses complementary control channel removes path flushes copy message source kill flits require one additional buffer control channel recovery approach described 16 interested impact performance tp figure 18 illustrates overhead recovery reliable message delivery mechanism additional message acknowledgment introduces additional control flit traffic sys tem message acknowledgments tend throttling effect injection new messages result tp routing using mechanism saturates lower network loads delivered messages higher latencies compare cases probabilistically inserting f faults dynamically ii f2 static faults average number dynamic faults would occur simulation results shown figure 18 see low loads performance impact support dynamic fault recovery significant however injection rates increase additional traffic generated recovery mechanism use message acknowledgments begins produce substantial impact performance point interest dynamic fault recovery useful range feasible operating loads tp protocols fact range extends almost saturation traffic 63 trace driven simulation true measure performance interconnection network well performs real communication patterns generated actual applications network considered failed program prevented completing due undeliverable messages communication traces derived several different application programs ep gaussian deviates mm matrix multiply mmp another matrix multiply program traces generated using spasm execution driven simulator 25 communication trace driven simulations performed allowing randomly placed physical link failures node failures would require remapping processes resulting remapping affecting performance recovery mechanisms used recovery undeliverable messages traces generated applications executing 16ary 2cube simulated network 16ary 2cube 8 16 virtual channels per physical link aggressive version tp used ie unsafe channels used figure 19 shows three plots probability completion rates three different program traces differing values misrouting trace said completed trace messages delivered hence probability completion defined ratio number traces able execute completion total number traces run even one message cannot deliv ered program execution cannot complete results show effect recovery mechanisms simulations implemented retries attempted message backtracks source node containing first data flit responsible probabilities completion 10 even small number faults performance effect recovery mechanism illustrated figure 18 expect 2 3 retries sufficient practice maintain completion probabilities 10 larger number faults instances increased number misroutes resulted poorer completion rates figure 18 comparison tp without tailacknowledgment flits throughput flitscyclenode10002000latency clock cycles latency vs throughput comparison dynamic faulttolerant mechanism wo tack 1f wo tack 10f wo tack 20f tack 1f tack 10f tack 20f believe primarily due lack recovery mechanisms retries increased misrouting causes network resources reserved message may turn increase probability messages forced backtrack due busy resources without tries completion rates suffer see importance implementating relatively simple heuristics small number retries finally larger number virtual channels offered better performance since provided increase network resources hence reduced probability backtracking due busy links 64 summary performance specifically performance evaluation provided following insights link failures080100 probability completion probability completion m3 v8 m4 v8 m5 v8 link failures0408probability completion probability completion m3 v8 m4 v8 m5 v8 link failures070090110 probability completion probability completion m3 v8 m4 v8 m5 v8 figure 19 probability completions various program traces numbers allowed misroutes cost positive acknowledgments dominates cost detour construction suggesting use low values k preferably configurable flow control enables substantial performance improvement pcs low modest number faults since majority traffic faultfree portions realizing close ws performance low modest number faults performance cost recovery mechanisms relatively low high fault rates still must use conservative protocols ensure reliable message delivery application program completion conclusions routing presence faults demands greater level flexibility required faultfree networks however designing routers based relatively rare occurrence faults requires message traffic penalized even messages route faultfree portions network overhead may arise due setting faultfree path prior data transmission pcs marking processors channels faulty construct convex fault regions 45 increasing number virtual channels routing messages around faulty components 4 low moderate number faults configurable flow control mechanisms lead deadlockfree faulttolerant routing protocols whose performance superior conservative routing protocols comparable reliability network large number faults tps partially optimistic behavior results severe performance degradation conservative routing protocols network resources reserved path setup source destination tp require complex renumbering scheme provide faulttolerance 1920 require construction convex regions 45 require additional virtual channels 4 dynamic faulttolerant version tp rely timeouts 11 padding messages 22 however result complex channel model affect link speeds router designed support tp requires slightly hardware router supporting pcs 1 making implementation feasible current efforts redesigning pcs router support tp protocols however apparent one important performance issues efficient mechanism implementing positivenegative acknowledg ments currently evaluating implementation adds control signals physical channel modifying physical flow control accordingly logical behavior remains unchanged implementing acknowledgment flits hardware hope extend superior low load performance tp significantly higher number faults r disha efficient fully adaptive deadlock recovery scheme comparison adaptive wormhole routing algorithms reliable router reliable highperformance communication substrate parallel computers high performance bidirectional signalling vlsi systems theory faulttolerant routing wormhole networks new theory deadlockfree adaptive routing wormhole networks scouting fully adaptive computer systems performance evaluation effects faults multiprocessor net works tracedriven study adaptive routing protocols hypercube interconnection networks turn model adaptive routing cray t3d new dimensions cray research compressionless routing framework faulttolerant routing faulttolerant communication scheme hypercube computers machine abstractions locality issues studying parallel systems tr ctr dong xiang faulttolerant routing hypercubes using partial path setup future generation computer systems v22 n7 p812819 august 2006 dong xiang ai chen jiaguang sun faulttolerant routing multicasting hypercubes using partial path setup parallel computing v31 n34 p389411 marchapril 2005