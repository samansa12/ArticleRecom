improved algorithms analysis secretary problems generalizations classical secretary problem n objects ordered set arrive random order one accept k final decision object made basis rank relative ones already seen variants problem depend goal either maximize probability accepting best k objects minimize expectation sum ranks powers ranks accepted objects problem generalizations core tasks large data set may impractical backtrack select previous choicesoptimal algorithms special case well known partial solutions first variant general k also known contrast explicit solution second variant general k known seems fact expected sum powers ranks selected items bounded n tends infinity known follow standard results derive results obtaining explicit algorithms z geq 1 resulting expected sum zth powers ranks selected objects kz best possible value kz okz methods intuitive apply generalizations also derive lower bound tradeoff probability selecting best object expected rank selected object b introduction classical secretary problem n items options presented one one random order ie n possible orders equally likely could observe could rank totally ties best rank 1 worst rank n however ith object appears observe rank relative previous relative rank equal one plus number predecessors preferred must accept reject object irrevocably basis rank relative objects already seen required select k objects problem two main variants first goal maximize probability obtaining best k objects second goal minimize expectation sum ranks selected objects generally given positive integer z minimize expectation sum zth powers ranks solutions classical problem apply also variety general situations examples include case objects drawn probability distribution interesting feature variant decisions algorithms may based relative rank item also absolute grade item receives ii number objects known advance iii objects arrive random times iv limited backtracking allowed objects rejected may recalled v acceptance algorithm limited memory also combinations situations addition providing intuition upper lower bounds important generalizations problem solutions classical problem also provide many cases good approximations even exact solutions see 4 13 14 survey also 8 methods also directly extended apply generalizations obvious application choosing best applicant job gives problem common name although problem results number applications computer science problem large data set may impractical backtrack select previous choices example context data mining selecting records best fit requirements retrieving images digital libraries applications limited backtracking may possible fact one generalizations mentioned another important application one needs choose appropriate sample population purpose study applications items may jobs scheduling opportunities investment objects fellowships etc 11 background intuition problem extensively studied probability statistics literature see 4 13 14 surveys also 10 case k 1 let us first review case one object selected since observer cannot go back choose previously presented object retrospect turns best clearly balance risk stopping soon accepting apparently desirable object even better one might still arrive risk waiting long find best item rejected earlier easy see optimal probability selecting best item tend zero n tends infinity consider following stopping rule reject first half objects select first relatively best one rule chooses best object whenever latter among second half objects second best object among first half hence every n rule succeeds probability greater 14 indeed established 7 5 2 see exists optimal rule following form reject first objects select first relatively best one none chosen end accept last object n tends infinity optimal value r tends ne probability selecting best approximately 1e lind ley showed using backward induction 7 later gilbert mosteller provided slightly accurate bound r 5 dynkin established result application theory markov stopping times 2 easy see optimal expected rank selected object tends finite limit n tends infinity observe algorithm maximizing probability selecting best object yields expected rank n2e selected item argument follows probability 1e best item among first ne items case algorithm selects last item conditional expectation rank last object case approximately n2 thus expected rank selected object algorithm tends infinity n indeed paper show surprisingly two goals fact conflict see section 12 proven backward induction exists optimal policy minimizing expected rank selected item following form accept object rank relative previously seen objects exceeds certain threshold depending number objects seen far note optimal algorithm maximizing probability selecting best remember best object seen far threshold algorithm remember previous objects see 11 solutions observer allowed remember one previously presented items fact suggests minimizing expected rank harder thus surprisingly finding approximate solution dynamic programming recurrence problem seems significantly harder case first variant prob lem ie goal maximize probability selecting best chow moriguti robbins samuels 1 showed optimal expected rank selected object approximately 38695 question whether higher powers rank selected object tend finite limits n tends infinity resolved 11 also shown order arrivals determined adversary algorithm yield expected rank better n2 12 case general k much interest case one object selected hard see every fixed k maximum probability selecting best k objects tend zero n tends infinity proof follows partition sequence n objects k disjoint intervals containing nk consecutive items apply algorithm maximizing probability selecting best object set independently resulting algorithm selects best item interval probability e gammak probability best k objects belong distinct intervals tends kk k n tends infinity first variant problem case considered 9 vanderbei 16 independently glasser holzager barron 6 considered problem general k showed optimal policy following threshold form accept object given relative rank number observations exceeds critical number depends number items selected addition object worse already rejected objects need considered notice means previously seen items remembered already selected best among already rejected property analogous happened case goal maximize probability selecting best item papers derive recursive relations using backward induction general solutions recurrences known authors give explicit solutions ie critical values probability case 16 also presents certain asymptotic results n tends infinity k fixed also k n tend infinity 2k gamma n remains finite analogy case bounding optimal expected sum ranks k selected items appears considerably harder minimizing probability selecting best k items also obvious see whether sum tends finite limit n tends infinity backward induction gives recurrences seem even harder solve derived case maximizing probability selecting best k equations presented henke 8 unable approximate general solutions thus question whether expected sum ranks selected items tends infinity n open explicit solution obtaining bounded expected sum thus sec ond possibly realistic variant secretary problem remained open 12 results paper present family explicit algorithms secretary problem positive integer z family includes algorithm accepting items values n k resulting expected sum zth powers ranks accepted items cz constant 2 kg clearly sum ranks zth powers best k objects k z1 z thus sum achieved algorithms bounded value independent n also differs best possible sum relatively small amount every fixed k expected sum bounded constant thus resolve open questions regarding expected sum ranks general zth powers ranks selected objects approach different dynamic programming approach taken papers mentioned addition successful obtaining explicit solution classical prob lem easily used obtain explicit solutions numerous generalizations require completely new derivation objective function remark approach partition items k groups select one item method suboptimal since constant probability constant fraction best k items appear groups ones best k therefore method rejects constant fraction best k constant prob ability expected value sum ranks obtained algorithm greater least constant factor optimal since expected sums achieved algorithms depend k z addition probability algorithms select object decrease rank follow probabilities algorithms actually select best objects depend k z hence fixed k z tend zero n tends infin ity particular means algorithms select best possible object probability bounded away zero contrast algorithm problem order arrival items worst possible ie generated oblivious adversary algorithm yields expected sum least kn z 2 gammaz1 zth powers ranks selected items lower bound holds also randomized algorithms finally section 11 observed optimal algorithm maximizing probability selecting best object results unbounded expected rank selected object second part work show fact coincidence two goals fact conflict algorithm simultaneously optimize expected rank probability selecting best derive lower bound tradeoff probability accepting best object expected rank accepted item due lack space proofs omitted sketched 2 algorithms section describe family algorithms secretary problem positive integer z family includes algorithm accepting objects resulting expected sum zth powers ranks accepted objects addition follow algorithm accepts best k objects positive probability depends k z let z positive integer given denote convenience exposition assume without loss generality n power 2 partition sequence 1 n corresponding objects order arrival consecutive intervals fng words first 1 n 4 containing half remaining elements mth interval contains last element note ji let us refer first intervals opening ones let rest closing ones note since p 64 last five intervals closing opening expected number top k objects latter necessarily integer ie one opening intervals expected number top k objects among first arrive delta k n let observe pm 0 refer p minimum number acceptances required observe hand intuitively interval algorithm attempts accept expected number top k objects arrive interval addition make number objects accepted prior beginning interval note since p intervals algorithm attempts make number objects accepted beforehand let us explain slightly formally execution algorithm beginning interval algorithm computes threshold acceptance goal time processing last object interval com pleted number accepted objects least minimumnumber acceptances required prior time particular recall denotes minimum number acceptances required given prefix execution prior beginning 1 number items accepted j let roughly speaking igamma1 difference minimumnumber acceptances required prior beginning number items actually accepted given prefix note given prefix execution prior beginning let ae refer computed beginning acceptance threshold execution loosely stated given prefix execution algorithm prior beginning number objects algorithm accept order meet minimum number required end algorithm aim accepting least objects ensure accepts many attempts accept little particular opening interval algorithm attempts accept expected number 6z 1 p log k see ensures algorithm accepts least objects interval probability least k gamma5z1 closing interval algorithm attempts accept expected number 32z ensures algorithm accepts least objects interval probability least 2 gamma5z1a 1 make distinction opening closing intervals order restrict expected rank accepted objects closing may much smaller p log k let ae log k opening closing order accept expected number b objects interval algorithm accept dth item one approximately ones among first since order arrival items random rank dth object relative first ones distributed uniformly set f1 dg therefore dth object accepted probability b since ji e expected number objects accepted indeed b point execution algo rithm number slots still filled equals number items processed yet remaining items accepted regardless rank analogously time dth item arrives slots already filled item accepted finally algorithm accept first dn8 ke items except executions number slots becomes equal number items dn8 ke items pro cessed roughly speaking modification allow bound expected rank dth item terms rank relative first items leads algorithm call select algorithm select algorithm processes items one time order arrival beginning interval algorithm computes described dth item 2 arrives algorithm proceeds follows slots already filled object rejected ii otherwise dn8 ke dth item accepted one top items among first b algorithm accepts dth item one top b32z items among first iii otherwise number slots still filled equals number items left ie 1 dth item accepted refer acceptances 3 ie number slots still filled equals number items remained seen manda tory acceptances elective example dth item arrives 1 latter opening item accepted electively one approximately k2 log k2 log top objects among first general dth object arrives opening object accepted electively one approximately top objects among first 3 analysis algorithm select loosely stated proof proceeds follows section 31 show observe implies high probability approximately p ie section 32 show dth object arrives opening conditional expectation zth power rank given accepted electively greater 2 iz 1 z1 z c 4 z2 iz zgamma05 log k constant c 4 z depend ing z closing conditional expectation greater c 6 z2 iz z c 6 z section 33 results sections 31 32 combined established dth object arrives opening conditional expected zth power rank given accepted electively k z constant cz closing conditional expected zth power rank c 0 zk z constant c 0 z approximately otherwise follow expected sum zth powers ranks elec tively accepted objects 1 addition use result section 31 show expected sum zth powers ranks mandatorily accepted objects ok z05 log k thus expected sum zth powers ranks accepted objects 1 addition fact expected sum zth powers ranks accepted objects bounded value depends k z also follow algorithm accepts top k objects probability depends k z 31 bounding section show high probability close p end distinguish smooth nonsmooth executions see 311 smooth prefixes denote e prefix execution e prior end note em e say computed e ji j j denote event e smooth section show opening interval executions whose prefix prior end 1th interval smooth probability exponentially j part 1 lemma 33 closing executions whose prefix prior end igamma1th interval smooth probability exponentially j part 2 lemma 33 part 1 part 2 lemma 33 follow respec tively lemmas 31 32 show executions whose prefix prior end ith interval smooth algorithm accepts objects high probability computed prefix execution intuitively restriction smooth executions necessary since objects selected lemma 31 every value sketch proof note 0 number objects accepted less loosely stated algorithm accepts dth object electively one top log objects among first since objects arrive random order rank dth object within set first distributed uniformly hence accepted electively probability less ba log cd moreover rank dth object within set first independent arrival order first gamma 1 hence independent whether previous object interval say th one one top objects among first 1 rest proof follows computing expected number accepted candidates chernoff inequality analogously lemma 32 n 16 every lemma 33 ii n 16 sketch proof outline proof part 1 recall minimum number acceptances required opening interval thus k2 gammai positive events dependent probabilities conditioned however shown dependency conditioning working favour lemma 31 thus implies underlying events fd q 0g probability less k gamma5z1 hence 312 nonsmooth executions lemma 33 implies smooth executions high probability close p complete proof close p show nonsmooth executions rare particular part 1 lemma 33 used show lemma 34 analogously lemma 35 n 16 k 1 case k n2 excluded lemma 35 thus handled separately later section 33 32 expected zth powers ranks let us denote r random variable rank dth object define arrival rank dth object rank within set first objects ie one plus number better objects seen far denote random variable arrival rank denote na event dth object accepted electively lemma 36 exist constants c 2 z c 3 z c z n k er z z combining result lemma 36 fact given object accepted electively opening interval distributed uniformly set f1 2 ba log k2 dncg get lemma 37 exist constants c 4 z c 5 z opening intervals ie every value dth object arrives n er z r analogously lemma 38 exists constant c 6 z closing intervals ie dth object arrives er z 33 expected sum ranks section show expected sum zth powers ranks k accepted objects isz theorem 31 follow adding expected sum zth powers ranks electively accepted objects lemmas 313 expected sum zth powers ranks mandatorily accepted objects lemma 315 331 elective acceptances denote sumz sum zth powers ranks objects accepted electively lemma 39 exists constant c 7 z opening intervals values z1 lemma 310 exists constant c 8 z closing intervals acceptance thresholds computed lemma 39 combined part 1 lemma 33 lemma 34 show lemma 311 exists constant c 9 z opening intervals analogously lemma 312 n 16 exists constant closing interval following lemma completes proof upper bound sum ranks electively accepted objects sums expected sum ranks electively accepted objects intervals lemma 313 332 mandatory acceptances section bounds expected sum mandatorily accepted objects first observe lemma 314 dth object mandatorily accepted execution e i1 denote sumdz sum zth powers ranks objects accepted mandatorily lemmas 34 35 section 312 imply probability prefix execution prior end smooth czn gamma25z1 log n cz constant case k 1 2 n handled without use lemma 35 since lemma excludes clearly bound applies also probability objects mandatorily accepted combine bound facts rank object never exceeds n number accepted objects k n show lemma 315 exist constants c 21 z c 22 z lemmas 313 315 imply theorem 31 expected sum ranks accepted objects corollary 31 algorithm select accepts best k objects positive probability depends k z 4 tradeoff small expected rank large probability accepting best theorem 41 let p 0 maximum possible probability selecting best object c 0 ffl 0 sufficiently large n algorithm selects one n objects probability pa selects best one greater expected rank selected object least cffl proof suppose contrary assertion algorithm selects best object probability least p yet expected value rank selected object less cffl starting construct another algorithm r r selects best object probability denote opt following algorithm let ne objects pass accept first object better anyone seen far object accepted time last object arrives accept last object n sufficiently large algorithm accepts best object highest possible prob ability hence probability p 0 7 3 better approximation r ne gamma1 although difference never 1 5 ignore difference sake simplicity define r modifying definition depend parameters c 1 0 assume sufficiently large absolute constant c 1 sufficiently large respect r accept object least one following conditions accepts object time nd time object better anybody else seen ii opt accepts object whereas accepted earlier somebody time acceptance known best one better one iii opt accepts object already accepted somebody time nd iv object comes time better anybody else seen r yet accepted anybody based rules 1 2 v object nth object r accepted yet object notation denote ba br bopt events r opt repectively accept best object denote b1 b2 b3 events best object appears intervals spectively denote ia1 ia2 ia3 events makes selection intervals 1 nd distinguish two cases case probfia1g 41 proof suppose made selection time nd according rule 3 case r accept object arrives time nd opt accepts object choosing sufficiently large objects accepted opt time nd thus made selection time nd r accept object opt accepts thus second inequality follows since probability opt accepts best object independent order arrival first nd objects hence independent whether makes selection time nd hand thus choosing sufficiently large claim follows 42 proof claim follows immediately fact picks best object nd 0 object must best seen far hence rule 1 r picks object 43 proof ia3 holds neither r accepted anybody till time 0 let x event chooses later r definition r x ia3 holds either accepts object already moment acceptance known best r accept object thus complete proof suffices show suppose ia3 x holds r accepts object time 0 definition accepted anybody yet object accepted r better anyone else seen earlier thus better object one accepted r arrives time means best object arrives time since objects arrive random order rank dth arriving object within set first distributed uniformly hence probability best object arrive time n gamma tn c 1 ffln notice probability independent ordering first objects hence independent fact r accepted tth object therefore probability object accepted r indeed best object least 1 gamma c 1 ffln probability accepts best one later smaller ffln thus fixed choice fixed order first objects property ia3 x probability br larger ba hence complete proof case probfbrg second inequality follows claims 41 42 43 fourth inequality follows theorem assumption ii probfia1g 3fflp 0 case assumption case ii probfia1g 3fflp 0 denote br1 br2 br3 events r picks best object selections interval respectively denote ba1 ba2 ba3 corresponding events since assumption case probfia1g picks best object nd 0 object must best seen far hence rule 1 r picks object thus choosing sufficiently large objects accepted opt time nd observe case second best comes time nd best comes time 0 r accepts best object probability second best object arrives time nd 1d conditional probability best object comes given second best comes time nd least c 1 ffl thus follows bounding probfba3g first use assumption expected rank object selected less cffl show proof 110dc 1 ffl objects rank smaller 110dc 1 ffl arrives time probability c 1 ffl therefore probability least 1 gamma 110d objects arrive time 0 rank larger 110dc 1 ffl hence probability ia3 greater 12d expected value rank would larger c 0 ffl absolute constant c theorem equal c 0 get contradiction assumption expected rank selected object cffl recall b3 denotes event best object arrives interval ia3g b3 independent order arrival first 0 objects hence independent whether accepted object time 0 thus claim 44 implies probfia3g delta probfb3 equations 1 4 imply last inequality follows assumption c 1 sufficiently large respect therefore acknowledgements indebted james aspnes eugene dynkin john preater yossi rinott mike saks steve samuels robert vanderbei helpful references r secretary problem optimum choice instant stopping markov process solved secretary prob lem statistical science volume4volume secretary problem ex tensions review recognizing maximum sequence choice secretary problem dynamic programming decision theory sequentialle auswahlprobleme bei unsicherheit generalization best choice problem multiple choice secretary prob lems finite memory secretary problem optimal counter strategies secretary problem secretary problems secretary problems source benchmark sounds amortized efficiency list updates paging rules optimal choice subset population tr ctr andrei broder michael mitzenmacher optimal plans aggregation proceedings twentyfirst annual symposium principles distributed computing july 2124 2002 monterey california robert kleinberg multiplechoice secretary algorithm applications online auctions proceedings sixteenth annual acmsiam symposium discrete algorithms january 2325 2005 vancouver british columbia mohammad taghi hajiaghayi robert kleinberg david c parkes adaptive limitedsupply online auctions proceedings 5th acm conference electronic commerce may 1720 2004 new york ny usa