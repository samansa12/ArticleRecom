heterogeneous cpu services using differentiated admission control present adaptive ratecontrolled scheduler heterogeneous applications running general purpose computers scheduler effectively support diverse application requirements employs uniform ratebased sharing application heterogeneity satisfied partitioning cpu capacity service classes different criterion admission control result able provide guaranteed performance flexible allocation rates excellent scalability intermediate service classes offering tradeoffs reserved rate utilization strength guarantees scheduler implemented solaris 251 runs existing applications without modifications present experimental results showing scalability efficiency guaranteed performance overload performance aspects scheduler demonstrate importance priority inheritance implemented scheduler stable system performance b introduction emerging continuous media cm applications well defined quality service qos constraints applications stringent resource requirements benefit noninterference possible run closed embedded system environment 11 instead many continue run general purpose machines applications diverse characteristics run concurrently qos requirements applications open general purpose computing environment requires research appropriate admission control scheduling policies must investigated avoid long term resource overload provide forms progress guarantees resources carefully scheduled cpu time one bottleneck resource consider processor requirements applications like software media codes designed implemented cpu scheduling framework conforms following service objectives 1 cpu scheduling satisfy diverse classes application requirements one extreme applications stringent progress constraints missed deadlines significantly degrade perceived quality audio processing teleconferencing system example extreme besteffort applications specific realtime properties nonzero progress rate desired flexibility form proportional sharing cpu time among applications provided network file transfers email processing belong type applications two extremes applications well defined qos requirements tolerate periods system overload graceful yau supported part national science foundation grant numbers eia9806741 ccr9875742 career b bhargava supported part national science foundation grant numbers ccr9901712 ccr0001788 part cerias earlier version paper appears proc ieee international conference multimedia computing systems florence italy june 1999 22 load shedding video playback example system busy users video applications may happy settle lower frame rate long video maintains good continuity 2 cpu scheduling provide suitable firewall protection among service classes well among threads within service class progress guarantees given service class thread independent service classes threads make scheduling requests applications stringent qos requirements must protected applications service classes class besteffort applications protected demanding service classes ensure acceptable level progress rate counterproductive however strong firewall protection besteffort applications system scalability want cpu scheduling limiting factor many besteffort applications admitted system implies actual progress rates existing besteffort applications become lower applications join system become higher applications leave system 3 certain service classes require cpu reservations prevent long term system overload since actual resource requirement application may known apriori may depend current context execution system provide feedback applications actual resource demands information reservations dynamically renegotiated applications system reflect actual resource needs 4 cpu scheduling unnecessarily restrict progress rates admitted applications particular reserved unused cpu cycles left idle made available ondemand applications 5 competitive existing round robin schedulers cpu scheduler providing diverse service classes little extra overhead 6 since different organizations may different characteristic workloads system administrator allowed configure service classes according needs organization scheduling framework evolves earlier work adaptive ratecontrolled arc scheduling retains arcs central features ratebased sharing firewall protection provision system feedback resource renegotiation improves arc providing improved scalability besteffort applications offering explicit tradeoffs reserved rate utilization strength guarantees adaptive applications paper present design innovations discuss experience evolution arc scheduling addition provide extensive performance results illustrate salient aspects current prototype results demonstrate soundness practical utility approach 11 contributions related work cpu scheduling multimedia applications active area research solutions designed embedded realtime systems applicable general purpose computers 1 12 use static priorities 9 generally susceptible runaway applications ratebased resource sharing widely used many ratebased systems however target flexible resource allocation consider guaranteed qos admission control 3 6 7 8 19 lack system feedback application performance makes difficult determine suitable ratesa highly flexible resource model proposed 18 offers probabilistic performance resource model specific protocol processing proposed 5 yields guaranteed performance without using threads approach immediately extend general computation hierarchical schedulers advanced support heterogeneity applications 4 6 employ leaf schedulers diverse types classical realtime schedulers like ratemonotonic earliestdeadlinefirst lack firewall property 11 15 adapt dynamic application behavior certain scheduling algorithms require close application participation sophisticated schedulability tests 14 systems appealed policing mechanisms external scheduling algorithm priority depression 10 13 17 propose solution uniformly applies well proven technique ratebased scheduling diverse application requirements considering scheduling algorithms provable firewall property offer protection among applications without resorting complicated machinery heterogeneity applications handled configuring service classes different criteria admission control result system achieves guaranteed performance flexible resource allocation excellent scalability intermediate services offering tradeoff reserved rate utilization strength guarantees new ratebased scheduling algorithm suitable use framework defined addition present system implementation general purpose operating system introduce use proxied scheduling account inexact rate control real system provide performance evaluations using real multimedia workload 12 paper organization section 2 discuss arcs ratebased sharing firewall protection basis research discuss issue progress fairness define new cpu scheduling algorithm good fairness properties extending arc accommodate heterogeneous services framework presented section 3 section 4 discusses importance priority inversion cpu scheduling use proxied class achieve predictable performance real system environment given section 5 present performance evaluations prototype implementations using real multimedia workload section 6 scheduling section summarizes main features arc scheduling details 23 arc defines family schedulers following three properties reserved rates negotiated ii qos guarantees conditional upon thread behavior iii firewall protection among threads provided firewall protection effected periodic rate control hence execute ratebased scheduling algorithm certain rescheduling points follows currently running thread exits becomes blocked algorithm executed block event system event occurs causes one threads become runnable algorithm executed thread becomes runnable unblock event periodic clock tick occurs system algorithm executed currently running thread clock tick event initial rc scheduling algorithm figure 2a chose proofofconcept experiment arc framework simple efficient using rc thread say request cpu reservation rate r period figure 2a event denotes one three rescheduling events triggered algorithm q thread rc executed rq pq denote qs reserved rate period respectively curtime real time rc begins execution finishq expected finishing time previous computation performed q valq rc value q system schedules threads nondecreasing order rc values assumption idealized execution environment 23 theorem 1 guarantees progress punctual thread say j system generates least k seconds work time interval 0 kp j theorem 1 thread j punctual r 1 j scheduled rc run least k time notice p j smaller rate guarantees provided finer time intervals concomitant increase context switch overhead conversely p j larger number context switches becomes smaller rate guarantees provided coarser time intervals hence p j rc allows tradeoff context switch overhead time granularity rate guarantees specifiable applications according needs performed experiments validate theorem 1 actual system running existing multimedia applications 23 show cm applications video audio meet deadlines using arc competing variety besteffort applications see example fig 1 simultaneously besteffort applications able achieve satisfactory progress despite demands cm applications firewall protection among applications achieved without significantly degrading cpu efficiency utilization b501502503500 100 200 300 400 500 600 700 800 interframe time ms frame103050700 500 1000 1500 2000 2500 interframe time ms frame figure 1 times pictures sent application running unix ts b arc presence competing computeintensive applications started frame 250 algorithm rcq event l1 event unblock l2 finishq maxfinishq curtime else l3 runtime time q run since rc last executed l4 finishq finishq l5 event 6 block l7 valq startq algorithm frcq event l1 event unblock l2 vtime l3 finishq maxfinishq vtime l4 else l5 runtime time q run since frc last executed l7 event block l8 fqg figure 2 specification algorithm rc b algorithm frc 21 progress fairness show 23 rc exhibits punishment phenomenon threads overrun resource reservations later punished ie scheduled extended time period thread little resource overrun joins system show 23 rate adaptation used longrunning cm applications avoid punishment phenomenon carefully matching reserved rate actual execution rate however explicitly designed arc framework highly modular flexible result able incorporate scheduling algorithms diverse fairness properties prototype system particular designed fair ratecontrolled algorithm improved fairness rc frc allows threads reserve guaranteed cpu rates rc frc calculates thread finish value giving time previous computation thread would finish progressing reserved rate system schedules runnable threads nondecreasing finish value order frc outlined figure 2b observe rc thread say r overruns reserved rate finishr may increase much beyond real time hence new thread say later joins system finishs set current real time l2 figure 2a may take unbounded time finishs catch finishr solve problem fig 2b line l3 uses virtual time value vtime calculated l2 closely match finish values existing runnable threads determine finish value newly runnable thread addition algorithm uses initially empty keep track current set runnable threads system discuss progress properties frc notational convenience adopt following exposition denotes finish value thread q denotes period system clock tick first prove lemma 1 bounds difference finish values two runnable threads scheduled frc bound implies progress fairness limiting long thread run another runnable thread given chance use cpu lemma 1 following invariant j runnable f f j qr proof invariant true first thread becomes runnable show invariant preserved rescheduling point proof f denote set runnable threads finish value thread respectively rescheduling point 0 f 0 denote set runnable threads finish value thread respectively rescheduling point 1 system clock tick occurs thread since chosen run f f j 0 j 2 l6 2 thread k becomes blocked affect finish value runnable thread hence trivially 3 thread becomes runnable consider two cases case case j finish value thread j last blocked notice f 00 moreover since last inequality follows fact invariant holds rescheduling point theorem 2 proves guaranteed throughput frc scheduling theorem 2 time interval 0 continuously runnable throughout interval scheduled frc run least 1 time set threads ever runnable 0 proof let w j denote total amount time j runs interval 0 denote finish value j j first becomes runnable 0 f 0 j finish value j time 0 lemma 1 fact f nondecreasing 2 3 l3 l6 j 6 fact continuously runnable since continuously runnable cpu busy throughout 0 hence 6 7 following corollary immediate states guaranteed progress cpu time overbooked ie r 1 notice 0 becomes large continuously runnable thread cpu rate converges reserved rate corollary 21 time interval 0 continuously runnable throughout interval j r j 1 scheduled frc run least time set threads ever runnable 0 3 arc scheduling heterogeneous services experience arc performs well guaranteeing progress diverse applications suffers practical problems one observation accommodate besteffort applications giving application low rate say 002 approach reasonable scalability since low rates add slowly admit good number besteffort applications rejected admission control however cpu scheduling using arc still imposes artificial limit number besteffort applications admitted time moreover besteffort realtime applications compete pool reserved rate may always desirable arc heterogeneous services arch extension arc overcome practical limitations major departure arc lies explicit recognition diverse classes applications discussed section 1 arch still retains use integrated scheduling algorithm rc frc described section 21 heterogeneity applications supported differential admission control arch system administrator partition total cpu capacity rates service classes ie service class k allocated rate r k r k 0 r 1 overbooking parameter thread j request service class k reservation specified two parameters nominal rate r j period request granted c k denotes subset threads already admitted service class k thread j admitted receives effective rate given c k subset threads admitted service class k includes thread j effective rates n total number threads arch used thread rates section 21 notice effective rate thread depends nominal rate also nominal rates threads admitted service class however shown hence corollary 21 provides hard guarantee effective rate r thread overbooking parameters used specifying different levels service b threads service class k get hard guarantee reserved rates service class called guaranteed rate gr suitable applications stringent timing constraints b class k used flexible rate allocation excellent scalability threads class receive guarantee besides nonzero progress service class called flexible rate fr suitable conventional best effort applications values b k lead service classes statistical guarantee different strengths service classes called overbooking obn n percentage overbook suitable adaptive multimedia applications gracefully shed work accommodate controlled periods system overload multiprocessor operating system like solaris threads contend inside kernel synchronization resources mutex locks semaphores condition variables readerswriter locks system priority inversion inside kernel becomes important problem solve problem arch leverages existing mechanisms solaris 251 provide priority inheritance thread arch inherit finish value another thread blocks inherited finish value rate controlled ie increased clock tick however original finish value inheriting thread cpu usage inherited priority accounted principle possible two threads say p q conspire hoard resources example p running acquire lock say l give later p preempted q gets scheduled q attempts acquire l p blocking q inherit qs finish value p runs inherited priority without ever giving l system priority inheritance implemented synchronization resources managed kernel code since kernel code trusted reasonably assume conspiracy cannot occur section 6 demonstrates practical utility priority inheritance system besides synchronization primitives priority inversion also occur different applications request service system server major problem using traditional rpc server thread run priority unrelated priority client tackle problem implemented trains abstraction solaris train allows thread control access services multiple processes carrying resource scheduling state intact ability achieved decoupling thread view purely scheduling entity associated process provides resource context albeit nonpermanently thread hence thread still home process ie process created free leave process enter new one welldefined stop exported latter stop exported secure entry point server code server offers service time service invocation server additionally provides stack executing new client request planning incorporate trains real applications report performance later paper avoid effects priority inversion due interrupt processing scheduler designed work best processing reduced minimum protocol processing system migrating sockets 21 example minimizes use interrupts handling packet arrivals network however small amount performance critical activities periodic system clock ticks cpu rate control still allowed take place interrupt priority higher priorities arch threads 5 proxied class frc used single level cpu scheduler theorem 2 says runnable thread effective rate r may get scheduled time interval length n 1q number threads admitted system since q nonnegligible real system expect value 1 ms 10 ms time interval become excessive n large presence besteffort applications particular concern since service class explicitly designed highly scalable solve system allows service class configured proxied class proxied class introduces twolevel scheduling arch system level class level system level proxied class represented proxy thread join arch system dispatch queue hence compete system cpu time class level proxied class maintains private dispatch queue runnable threads class increasing finish value order proxy thread considered running thread class running running runnable least one threads class runnable otherwise blocked effective rate equal configured algorithm l1 event unblock l2 vtime l3 finishq maxfinishq vtime l4 l5 call frccproxy unblock l6 c c else l7 runtime time q run since private frc last executed l8 finishq finishq l9 event block l10 c c fqg l11 l12 call frccproxy block else l13 call frccproxy tick else l14 call frccproxy tick figure 3 specification algorithm private frc proxied scheduling class rate scheduling state finish value like usual thread proxy thread selected execution currently highest priority however dispatched instead selects highest priority thread private runnable queue class dispatches specify algorithm private frc figure 3 proxied class scheduling algorithm used conjunction algorithm frc figure 2b nonproxied proxy thread ie scheduling system level private frc called rescheduling event occurs thread proxied class proxied thread algorithm q proxied thread c proxy class q belongs event specifies rescheduling event triggered algorithm proxy class c c denotes set threads c runnable cproxy denotes proxy thread represents c system level scheduling notice private frc invoked c may call frc cproxy suitable rescheduling event parameters example thread q c becomes blocked frc called block event q last runnable thread c tick event otherwise see benefits proxied scheduling consider video thread rate r v competing 1000 threads fr class cpu time fr class configured proxied class theorem 2 time interval length 999q video thread may scheduled fr class proxied however time interval reduced q 6 experimental results present performance results showing different aspects arch scheduling including guaranteed perfor mance overload performance suitability heterogeneous services scalability flexible proportional rate sharing stability efficiency arch scheduler used runs part solaris 251 sun ultrasparc1 workstation five applications representing multimedia workload used inour experiments measured performance first four applications various conditions fifth radio xmit ran computer different measurement platform used sending network audio packets read radio recv performance data taken radio xmit list applications follows greedy computeintensive application always enabled repeatedly round 25 ms computation prints timestamp periodic application wakes every performs 25 ms computation outputs timestamp mpeg2play cm application plays mpeg2 encoded video fps video contents played ipppp encoded 60 second segment tennis instruction radio recv cm application receives pcmencoded audio sample every 100 ms network radio xmit audio application captures pcmencoded audio microphone sends audio samples network samples generated 100 ms intervals reading radio recv experimentally determined cpu requirement mpeg2play ran one four copies mpeg2play minimal competing load solaris ts noted achievable frame rates one two applications frame rates full per second three applications frame rates became 2913 2985 2761 respectively four applications frame rates went 2079 2059 1963 1910 respectively conclude full cpu capacity support three mpeg2plays frames per second unless noted otherwise experimental cpu configured fr rate 025 gr rate 075 system clock tick interval used 10 ms fr configured proxied class whereas gr 61 flexible rates high utilization performance performed experiment demonstrate arch achieves flexible allocation rates graceful manner cpu configured gr rate 10 experiment five copies greedy six copies periodic application run rate gr class figure 4a plots timestamp value relative first timestamp application timestamp number application figure 4b closeup view first 100 seconds greedy applications graphs show execution rates gracefully adapted applications started finished different times hence changing offered cpu load examine system performance high utilization say periodic greedy application experiment time completes least one round computation every ms since round computation takes 25 ms rate requirement application time 25 ms total 11 applications running system aggregate cpu rate required applications time 0083 see performance periodic applications rate requirement actual cpu load 100 throughout experiment refer figure 5 clarity three applications shown profiles representative reference line shows periodic application mostly time experimental setup demonstrate differential rate sharing fr ran ten greedy applications service class six nominal rate 005 two nominal rate 01 remaining two nominal rate 02 figure 6 shows execution profiles applications figure shows applications active greedy rate 02 01 achieved 222 105 52 roundssecond respectively achieved ratios 1 close expected ratios 1 set experiments demonstrates arch able provide heterogeneous services firewall protection among service classes ran two different experiments first ran five greedy applications nominal rate 01 fr class together two mpeg2play rate 03 gr class second increased number greedy applications thirteen figure 7a shows execution profiles applications first experiment figure 7b shows corresponding profiles second experiment shown figure 7a greedy applications ran slope 4574 mpeg2plays still running slope increased 18687 mpeg2plays finished execution equal slopes show greedy application receiving share cpu figure 7b note increased number greedy achieved lower execution rate notice one greedy applications started earlier rest mpeg2plays however unaffected showing greedies fr sharing among resources figure 8a closeup view figure 7a 1025 seconds mpeg2plays affected starting greedy time ms round greedy 3 greedy 4 greedy 5 periodic time ms round greedy 3 greedy 4 greedy 5 figure 4 execution profile five greedy six periodic applications equal rate topmost line shows coincided periodic applications lines various greedys b execution profile greedy applications first 100 rounds graphs show graceful adaptation execution rates offered cpu load increases45504650475048504950150 152 154 156 158 160 162 164 time ms round periodic 6 figure 5 magnified view three periodic applications100030005000700090000 20 40 round number time seconds greedy1 greedy2 greedy3 greedy4 greedy6 figure applications running fr class showing differential rate sharing top line represents coincided profiles two applications rate 02 middle line two applications rate 01 lowest line six applications rate 005 greedy2 greedy3 greedy4 mpeg21 round number time seconds greedy1 greedy2 greedy3 greedy4 greedy6 mpeg21 mpeg22 figure 7 execution profiles two mpeg2plays gr running concurrently five greedy applications fr b thirteen greedy applications fr b shorter straight line two mpeg2plays coincided profiles b20040060080010 12 14 round number time seconds greedy1 greedy2 greedy3 greedy4 mpeg21 mpeg221030500 200 400 600 800 1000 1200 1400 1600 1800 2000 interframe time ms picture number mpeg21 figure 8 closeup view two mpeg2plays five greedy applications first 100 seconds thin straight line shows coincided mpeg2plays b plot interframe times mpeg2play running five greedy applications applications figure 7b shows representative plot interframe times mpeg2play expected frame rate per second achieved 63 graceful load shedding show certain cm applications gracefully adapt cpu overload hence run overbooking service class purpose configured ob70 service class overbook fraction 07 cpu partitioned fr rate 01 gr rate 03 ob70 rate 06 experiment ran three copies mpeg2play nominal rate 03 ob70 obtained execution profiles throughout experiment two greedy applications running gr fr classes respectively figure 9a shows execution profile applications mpeg2play achieved frame rate 24 frames per second experiment figure 9b gives plot interframe times representative mpeg2play application plot shows good picture continuity achieved despite reduced frame rate greedyfr greedygr mpeg2ob702 interframe time ms picture number mpeg21 figure 9 execution profile three mpeg2plays running ob70 class together two greedy applications gr fr classes respectively slanted line greedy gr flat one greedy fr middle one shows coincided mpeg2plays b plot interframe times first 60 seconds representative mpeg2play 64 priority inheritance demonstrate practical significance priority inheritance turned set experimental runs set experiments used two mpeg2play gr rate 03 one radio recv gr rate 01 two greedy applications fr rate 01 observe cases execution profile one shown figure 10a obtained shown instances occurred greedy application completely dominated cpu application able make progress greedy application completed execution case figure 10a occurred 60 90 seconds understand problem collected trace information inside kernel traces show 60 90 seconds clock tick occurred dominating greedy application hence application never preempted since priority never reduced rate control kernel source code could occur clock thread solaris handles periodic clock interrupts blocked synchronization primitive 1 happens subsequent clock processing deferred clock thread returns collecting trace information confirm case figure 10a clock thread indeed blocked 6090 seconds mutex lock attempting process high priority timer activities system data show one mpeg2play applications holding mutex lock question priority inheritance mpeg2play application holding timer lock required clock thread inherit latters priority interrupt thread solaris clock thread strictly higher priority arch thread hence blocking mpeg2play quickly scheduled preempting running greedy application necessary able quickly release timer lock result turn ensures clock thread complete tasks without delaying subsequent clock processing priority inheritance incorporated therefore kind gaps shown figure 10a longer observed figure 10b shows representative execution profile mix applications used preceding paragraph 65 implementation efficiency compare efficiency prototype scheduler solaris ts ran n copies greedy concurrently gr fr solaris ts respectively noted average completion time per application varied n 1 15 solaris ts used standard quantum sizes gr fr preemption quantum 10 ms used figure 11 shows three schedulers essentially performance gr fr slightly lower times 10 applications slightly higher times 15 applications see effects fine versus coarsegrained rate control varied preemption time quantum 10 30 50 70 ms gr fr figure 12 notice service classes number offers true multithreading inside kernel processes clock interrupts one kernel threads certain systems clock activities may handled interrupt handler cannot block unavailable resources radiorecv500plot200060001000014000 round number time seconds mpeg21 mpeg22 greedy1 greedy2 figure 10 unstable system performance without priority inheritance top two lines initially coinciding show two greedys b stable system performance priority inheritance top line shows coincided greedys b flat line radio recv middle line shows coincided mpeg2plays10210611 average completion time number applications solaris gr fr figure 11 average time complete one greedy application using gr fr solaris ts figure 12 average time seconds complete greedy application 1 5 10 15 competing applications preemption quantum size 10 30 50 70 ms gr class b proxied fr class applications large completion time drops somewhat preemption quantum increases 10 30 ms change significantly increase quantum size conclusions presented cpu scheduling framework suitable heterogeneous applications running general purpose com puters discussed present system evolved arc scheduling particular retains arcs central features ratebased sharing firewall protection provision system feedback rate renegotiation major design innovation arc definition heterogeneous services architecture based uniform ratebased sharing service classes different admission control criteria algorithm rc adapted virtualclock 24 uses expected completion times previous computations instead computations scheduled scheduling frcs solution fairness problems similar several approaches virtual clock reset 20 timeshift scheduling 2 leap forward virtual clock 16 ratebased algorithms suitable firewall protection also used framework system integration general purpose os environment discussed issues priority inheritance proxied scheduling diverse experimental results demonstrate soundness practical utility approach acknowledgment authors wish thank sanghamitra sinha conducting measurements development arch results reported paper r eventbased fair share scheduler cpu inheritance scheduling efficient user space protocol implementations qos guarantees using realtime upcalls hierarchical cpu scheduler multimedia operating systems fair share scheduler experiences processor reservation dynamic qos realtime mach scheduling algorithms multiprogramming hard real time environment qnx software systems ltd processor capacity reserves operating system support multimedia applications design analyzing multimedia operating system leap forward virtual clock new fair queueing scheme guaranteed delays throughput fairness lottery scheduling flexible proportionalshare resource management stride scheduling deterministic proportionalshare resource management delay guarantee virtual clock server migrating sockets end system support networking quality service guarantees arch uniform cpu scheduling heterogeneous services adaptive ratecontrolled scheduling multimedia applications new traffic control algorithm packet switching networks tr