performance considerations shared virtual memory machines abstractgeneralized speedup defined parallel speed sequential speed paper generalized speedup relation existing performance metrics traditional speedup efficiency scalability etc carefully studied terms introduced asymptotic speed show difference generalized speedup traditional speedup lies definition efficiency uniprocessor processing important issue shared virtual memory machines scientific application implemented ksr1 parallel computer experimental theoretical results show generalized speedup distinct traditional speedup provides reasonable measurement study different speedups interesting relation fixedtime memorybounded speedup revealed various causes superlinear speedup also presented b introduction recent years parallel processing enjoyed unprecedented attention researchers government agencies industries attention mainly due fact current circuit technology parallel processing seems remaining way achieve higher performance however various parallel computers algorithms developed performance evaluation still elusive fact advanced hardware software difficult evaluate parallel performance paper targeting recent development shared virtual memory machines study generalized speedup 1 performance metric relation existing performance metrics implementation issues distributedmemory parallel computers dominate todays parallel computing arena machines kendall square ksr1 intel paragon tmc cm5 ibm sp2 successfully delivered high performance computing power solving socalled grand challenge problems viewpoint processes two basic process synchronization communication models one sharedmemory model processes communicate shared variables messagepassing model processes communicate explicit message passing sharedmemory model provides sequentiallike program paradigm virtual address space separates user logical memory physical memory separation allows extremely large virtual memory provided sequential machine small physical memory available shared virtual address combines private virtual address spaces distributed nodes parallel computer globally shared virtual memory 2 shared virtual address space sharedmemory model supports shared virtual memory requires sophisticated hardware system support example distributedmemory machine supports shared virtual address space kendall square ksr1 1 shared virtual memory simplifies software development porting process enabling even extremely large programs run single processor partitioned distributed across multiple processors however memory access shared virtual memory nonuniform 2 access time local memory remote memory different running large program small number processors possible could inefficient inefficient sequential processing lead misleading high performance terms speedup efficiency generalized speedup defined parallel speed sequential speed newly proposed performance metric 1 paper theoretical proofs experimental results show generalized speedup provides reasonable measurement traditional speedup process studying generalized speedup relation generalized speedup many metrics efficiency scaled speedup scalability also studied relation 1 traditionally messagepassing model bounded local memory processing processors recent technology advancement messagepassing model extended ability support shared virtual memory fixedtime memorybounded scaled speedup analyzed various reasons superlin different speedups also discussed results show main difference traditional speedup generalized speedup evaluate efficiency sequential processing single processor paper organized follows section 2 study traditional speedup including scaled speedup concept introduce terminology analysis shows traditional speedup fixedsize scaled size may achieve superlinearity shared virtual memory machines furthermore traditional speedup metric slower remote memory access larger speedup generalized speedup studied section 3 term asymptotic speed introduced measurement generalized speedup analysis shows differences similarities generalized speedup traditional speedup relations different performance metrics also discussed experimental results production application kendall square ksr1 parallel computer given section 4 section 5 contains summary 2 traditional speedup one frequently used performance metrics parallel processing speedup defined sequential execution time parallel execution time parallel algorithms often exploit parallelism sacrificing mathematical efficiency measure true parallel processing gain sequential execution time based commonly used sequential algorithm distinguish interpretations speedup speedup measured commonly used sequential algorithm called absolute speedup 3 another widely used interpretation relative speedup 3 uses uniprocessor execution time parallel algorithm sequential time several reasons use relative speedup first performance algorithm varies number processors relative speedup measures variation second relative speedup avoids difficulty choosing practical sequential algorithm implementing sequential algorithm matching implementationprogramming skill sequential algorithm parallel algorithm also problem size fixed time ratio chosen sequential algorithm uniprocessor execution parallel algorithm fixed therefore relative speedup proportional absolute speedup relative speedup speedup commonly used performance study study focus relative speedup reserve terms traditional speedup speedup relative speedup concepts results study extended absolute speedup problem size point view speedup divided fixedsize speedup scaled speedup fixedsize speedup emphasizes much execution time reduced parallel processing amdahls law 4 based fixedsize speedup scaled speedup concentrated exploring computational power parallel computers solving otherwise intractable large problems depending scaling restrictions problem size scaled speedup classified fixedtime speedup 5 memorybounded speedup 6 number processors increases fixedtime speedup scales problem size meet fixed execution time scaled problem also solved uniprocessor get speedup number processors increases memorybounded speedup scales problem size utilize associated memory increase detailed study memorybounded speedup found 6 let p p number processors speedup p processors ffl unitary speedup ffl linear speedup debatable machinealgorithm pair achieve truly superlinear speedup seven possible causes superlinear speedup listed fig 1 first four causes fig 1 patterned 7 1 cache size increased parallel processing 2 overhead reduced parallel processing 3 latency hidden parallel processing 4 randomized algorithms 5 mathematical inefficiency serial algorithm 6 higher memory access latency sequential processing 7 profile shifting figure 1 causes superlinear speedup cause 1 unlikely applicable scaled speedup since problem size scales memory time constraint cache hit ratio unlikely increase cause 2 fig 1 considered theoretically 8 measured superlinear speedup ever attributed cause 3 exist relative speedup since sequential parallel execution use algorithm since parallel algorithms often mathematically inefficient cause 5 likely source superlinear speedup relative speedup good example superlinear speedup based 5 found 9 cause 7 explained end section 3 generalized speedup introduced virtual memory shared virtual memory architecture cause 6 lead extremely high speedup especially scaled speedup extremely large problem run single processor figure 5 shows measured superlinear speedup ksr1 machine measured superlinear speedup due inherent deficiency traditional speedup metric analyze deficiency traditional speedup need introduce following definition 2 cost parallelism ratio total number processor cycles consumed order perform one unit operation work processors active machine clock rate sequential execution time written terms work sequential execution amount work theta processor cycles per unit work machine clock rate ratio right hand side eq 1 processor cycles per unit work machine clock rate cost sequential processing work defined arithmetic operations instructions transitions whatever needed complete application scientific computing number floatingpoint operations commonly used measure work general work may different types units different operations may require different numbers instruction cycles finish example times consumed one division one multiplication may different depending underlying machine operation memory reference ratio may different different computations influence work type performance one topics studied 1 paper study influence inefficient memory access performance assume one work type increase number processor cycles due inefficient memory access shared virtual memory environment memory available depends system size let w amount work executed processors active work performed steps use processors let work cost parallelism p processor system denoted c p w elapsed time one unit operation work processors active w delta c p w gives accumulated elapsed time processors active c p w contains computation time remote memory access time uniprocessor execution time represented terms uniprocessor cost c p w cost sequential processing parallel system p processors different c p 1 w cost sequential portion parallel processing parallel execution time represented terms parallel cost traditional speedup defined depending architecture memory hierarchy general c p w may equal 10 c p w first ratio eq 3 cost ratio gives influence memory access delay second ratio simple analytic model based degree parallelism 6 assumes memory access time constant problem size system size vary cost ratio distinguishes different performance analysis methods without consideration memory influence general cost ratio depends memory miss ratio page replacement policy data reference pattern etc let remote access ratio quotient number remote memory accesses number local memory accesses simple case assume remote access parallel processing remote access ratio sequential processing p gamma 1p time per remote access time per local access 5 equation 5 approximately equals time per remote access time per local access since remote memory access much slower local memory access current technology speedup given eq 3 could considerably larger simple analytic model 4 fact slower remote access larger difference ksr1 time ratio remote local access 75 see section 4 therefore cost ratio 73 w assumed remote access ratio superlinear speedup 3 generalized speedup parallel computers designed solving large problems single processor parallel computer designed solve large problem uniprocessor computing power parallel system solving small problem inappropriate parallel system solving large problem single processor appropriate either create useful comparison need metric vary problem sizes uniprocessor multiple processors generalized speedup 1 one metric generalized sequential speed speed defined quotient work elapsed time parallel speed might based scaled parallel work sequential speed might based unscaled uniprocessor work definition generalized speedup measures speed improvement parallel processing sequential pro cessing contrast traditional speedup 2 measures time reduction parallel processing problem size work parallel sequential processing generalized speedup traditional speedup point view traditional speedup special case generalized speedup historical reasons sometimes call traditional speedup speedup call speedup given eq 6 generalized speedup like traditional speedup generalized speedup also divided fixed size fixedtime memorybounded speedup unlike traditional speedup generalized speedup scaled problem solved multiple processors fixedtime generalized speedup sizeup 1 fixedtime benchmark slalom 11 based sizeup memory access time fixed one might always assume uniprocessor cost c p stablized initial decrease due initialization loop overhead etc assuming memory large enough cache remote memory access considered cost increase slower memory accessed figure 2 depicts typical cost changing pattern eq 1 see uniprocessor speed reciprocal uniprocessor cost cost reaches lowest value speed reaches highest value uniprocessor speed corresponding stablized main memory cost called asymptotic speed uniprocessor asymptotic speed represents performance sequential processing efficient memory access asymptotic speed appropriate sequential speed eq 6 memorybounded speedup appropriate memory bound largest problem size maintain asymptotic speed choosing asymptotic speed sequential speed corresponding asymptotic cost local access independent problem size use denote corresponding asymptotic cost w 0 problem size achieves asymptotic speed remote access parallel processing assumed section 2 cs w 0 c p p w 0 3 corresponding speedup equals simple speedup fits cache cost problem size fits main memory fits remote memory execution time increases sequential insufficient memory figure 2 cost variation pattern consider influence memory access time general parallel work w w 0 c p w may equal general generalized equation 7 another form generalized speedup quotient sequential parallel time traditional speedup 2 difference eq 7 sequential time based asymptotic speed remote memory needed sequential processing cs w 0 smaller c p w therefore generalized speedup gives smaller speedup traditional speedup parallel efficiency defined number processors 8 generalized efficiency defined similarly generalized efficiency generalized speedup number processors definition generalized efficiency equations 10 11 show difference two efficiencies traditional speedup compares parallel processing measured sequential processing generalized speedup compares parallel processing sequential processing based asymptotic cost point view generalized speedup reform traditional speedup following lemmas direct results eq7 independent problem size traditional speedup generalized speedup lemma 2 parallel work w achieves asymptotic speed fixedsize traditional speedup fixedsize generalized speedup lemma 1 simple analytic model 4 used analyze performance difference traditional generalized speedup problem size w larger suggested initial problem size w 0 single processor speedup 1 may equal one 1 measures sequential inefficiency due difference memory access generalized speedup also closely related scalability study isospeed scalability proposed recently 12 isospeed scalability measures ability algorithm machine combination maintaining average unit speed average speed defined speed number processors system size increased problem size scaled accordingly maintain average speed average speed maintained say algorithmmachine combination scalable scalability w 0 amount work needed maintain average speed system size changed p p 0 w problem size solved p processors used definition since sequential cost fixed eq 11 fixing average speed equivalent fixing generalized efficiency therefore isospeed scalability seen isogeneralizedefficiency scalability memory influence consedered ie c p w independent problem size isogeneralizedefficiency isotraditionalefficiency case isospeed scalability isoefficiency scalability proposed kumar 13 2 lemma 3 sequential cost c p w independent problem size simple analysis model 4 used speedup isoefficiency isospeed scalability equivalent following theorem gives relation scalability fixedtime speedup theorem 1 scalability 12 equals one fixedtime generalized speedup unitary proof let cs w 0 defined eq 7 scalability 12 equals 1 let defined eq 12 define w 0 similarly w number processors p p 0 definition generalized speedup arithmetic manipulation similarly eq 13 two equations fixed speed equation 13 substituting eq 15 eq 14 equation 16 corresponding unitary speedup g 1 equal one work w unitary speedup defined definition 1 fixedtime generalized speedup unitary number processors p p 0 corresponding problem sizes w w 0 w 0 scaled problem size fixedtime constraint therefore average speed maintained also since equality scalability 12 equals one 2 following theorem gives relation memorybounded speedup fixedtime speedup theorem generalized speedup however based lemma 1 result true traditional speedup uniprocessor cost fixed simple analysis model used theorem 2 problem size increases proportionally number processors memorybounded scaleup memorybounded generalized speedup linear fixedtime generalized speedup linear proof let cs w 0 c p w w w defined theorem 1 let w 0 w scaled problem size fixedtime memorybounded scaleup respectively w 0 w defined accordingly memorybounded speedup linear constant 0 combine two equations equation assumption w proportional number processors available substituting eq 18 eq 17 get fixedtime equality w fixedtime generalized speedup linear fixedtime speedup linear following similar deductions used eq 17 applying fixedtime equality eq 19 eq 20 reduced equation assumption eq 18 eq 21 leads memorybounded generalized speedup linear 2 assumption theorem 2 problem size work increases proportionally number processors assumption true many applications however true dense matrix computation memory requirement square function order matrix computation cubic function order matrix kind computational intensive applications general memorybounded speedup lead large speedup following corollaries direct results theorem 1 theorem 2 corollary 1 problem size increases proportionally number processors memorybounded scaleup memorybounded generalized speedup unitary fixedtime generalized speedup unitary corollary 2 work increases proportionally number processors scalability 12 equals one memorybounded generalized speedup unitary since uniprocessor cost varies shared virtual memory machines theoretical results applicable traditional speedup shared virtual memory machines finally complete discussion superlinear speedup new cause superlin generalized speedup new source superlinear speedup called profile shifting 11 due problem size difference sequential parallel processing see figure 1 application may contain different work types problem size increases work types may increase faster others work types lower costs increase faster superlinear speedup may occur superlinear speedup due profile shifting studied 11 4 experimental results section discuss timing results solving scientific application ksr1 parallel computers first give brief description architecture application present timing results analyses 41 machine ksr1 computer discussed representative parallel computers shared virtual memory figure 3 shows architecture ksr1 parallel computer 14 processor ksr1 32 mbytes local memory cpu superscalar processor peak performance 40 mflops double precision processors organized different rings local ring ring0 connect 32 processors higher level ring rings ring1 contain 34 local rings maximum 1088 processors nonlocal data element needed local search engine se0 search processors local ring ring0 search engine se0 locate data element within local ring request passed search engine next level se1 locate data done automatically hierarchy search engines connected fattreelike structure 14 15 memory hierarchy ksr1 shown fig 4 processor 512 kbytes fast subcache similar normal cache parallel computers subcache divided two equal parts instruction subcache data subcache 32 mbytes local memory processor called local cache local ring ring0 32 processors 1 gbytes total local cache called group0 cache access group0 cache provided search engine0 finally higher level ring ring1 connecting 34 ring0s ring0 connecting processers ring0 ring0 figure 3 configuration ksr1 parallel computers mbytes local memory group0 cache 34 gb group1 cache 512 kb subcache processor search engine0 search engine1 figure 4 memory hierarchy ksr1 rings ring1 connects 34 local rings 34 gbytes total local cache called group1 cache access group1 cache provided search engine1 entire memory hierarchy called allcache memory kendall square research access processor allcache memory system accomplished going different search engines shown fig 4 latencies different memory locations 16 2 cycles subcache 20 cycles local cache 150 cycles group0 cache 570 cycles group1 cache 42 application regularized least squares problems rlsp 17 frequently encountered scientific engineering applications 18 major work solve equation orthogonal factorization schemes householder transformations givens rotations efficient householder algorithms discussed 19 shared memory supercomputers 20 distributed memory parallel computers note eq 22 also written ffi ffi b1 23 major task carry qr factorization matrix b neither complete full matrix sparse matrix upper part full lower part sparse diagonal form special structure b elements matrix affected particular step submatrix b transformed step columns step denoted b householder transformation described householder transformation initialize matrix b 1 ff 2 3 ii 4 b end calculation fi j updating b j done parallel different index j 43 timing results numerical experiments reported conducted ksr1 parallel computer installed cornell theory center 128 processors altogether machine period experiments performed however computer configured two standalone machines 64 processors therefore numerical results obtained using less 64 processors figure 5 shows traditional fixedsize speedup curves obtained solving regularized least squares problem different matrix sizes n matrix dimensions 2n theta n see clearly matrix size n increases speedup getting better better case speedup 76 56 processors although well known parallel computers speedup improves problem size increases shown fig 5 certainly good reasonable measurement real performance ksr1 problem traditional speedup defined ratio sequential time parallel time used solving fixedsize problem complex memory hierarchy ksr1 makes computational speed single processor highly dependent problem size problem big data matrix put local memory 32 mbytes single computing processor part data must put local memory processors system data accessed computing processor search engine0 result computational speed single processor slows significantly due high latency group0 cache sustained computational speed single processor 55 mflops 45 mflops 27 mflops problem sizes 1024 1600 2048 respectively hand multiple processors data needed local memory processor computational speed suffers less high group0 cache number processors theta theta theta theta theta theta theta figure 5 fixedsize traditional speedup ksr1 latency therefore excellent speedups shown fig 5 results significant uniprocessor performance degradation large problem solved single processor figure 6 shows measured single processor speed function problem size n householder transformation algorithm given implemented ksr fortran algorithm numerical complexity 265n speed calculated using cpu time used finish computation seen fig 6 three segments represent significantly different speeds different matrix sizes whole matrix fit subcache performance close 7 mflops speed decreases around 55 mflops matrix fit subcache still accommodated local cache note however matrix big access group0 cache search engine0 needed performance degrades significantly clear stable performance level observed two segments largely due high group0 cache latency contention search engine used processors machine therefore access time group0 cache less uniform compared subcache local cache take difference single processing speeds different problem sizes consideration use generalized speedup measure performance multiple processors ksr1 seen definition eq 6 generalized speedup defined ratio parallel speed asymptotic sequential speed parallel speed based scaled problem numerical tests parallel problem scaled memory dorder matrices subcache group0 cache theta theta theta theta figure 6 speed variation uniprocessor processing ksr1 bounded fashion number processors increases initial problem selected based asymptotic speed 55 mflops fig 6 scaled proportionally according number processors ie p processors problem scaled size fill theta p mbytes memory memory required unscaled problem figure 7 shows comparisons traditional scaled speedup generalized speedup traditional scaled speedup scaled problem solved one p processors value speedup calculated ratio time one processor p processors generalized speedup scaled problem solved multiple processors single processor value speedup calculated using eq 6 asymptotic speed used sequential speed clear fig 7 shows generalized speedup gives much reasonable performance measurement ksr1 traditional scaled speedup traditional scaled speedup speedup 20 10 processors excellent superlinear speedup result severely degraded single processors speed rather perfect scalability machine algorithm finally table 1 gives measured isospeed scalability see eq 12 solving regularized least squares problem ksr1 computer speed maintained different number processors 325 mflops 60 asymptotic speed 55 mflops size 2n theta n matrix increased number processors increases starts one processor increases processors one may notice 2 table 1 means machinealgorithm pair scales better 2 processors 4 processors number processors generalized speedup theta theta theta theta theta theta theta theta theta traditional speedup figure 7 comparison generalized traditional speedup ksr1 one processor two processors explained fact one processor matrix small enough data accommodated subcache data loaded subcache whole computation process need data local cache group0 cache therefore data access time one processor significantly shorter two processors involves subcache local cache group0 cache pass messages result significant increase work w necessary case two processors offset extra data access time involving different memory hierarchies major reason low 1 2 value number processors increases 2 4 data access pattern cases subcache local cache group0 cache involved work w need increased significantly offset extra communication cost going 2 processors 4 processors interesting notice scalability rlspksr1 combination relatively low data table 1 similar decreasing pattern measured computed scalability burgncube slalomncube burgmaspar slalommaspar combinations 12 scalabilities decreasing along columns irregular behavior 1 2 2 4 interested readers may wonder measured scalability related measured generalized speedup given fig 7 fig 7 demonstrates nearly linear generalized speedup corresponding scalability given table 1 far ideal ideal scalability would unity low scalability expected recall scaled speedup given fig 7 memorybounded speedup 6 number processors doubled usage memory also doubled table 1 measured scalability rlspksr1 combination result number elements matrix increased factor 2 corollary 2 shows work w increases linearly number processors unitary memorybounded speedup lead ideal scalability regularized least squares application however work w cubic function matrix size n memory usage doubled number floating point operations increased factor eight perfect generalized speedup achieved p p 0 2p average speed p p 0 eq 12 measured speedup little lower unitary shown fig 7 less 025 scalability expected table 1 confirms relation except 2 4 reason pointed earlier scalability last column noticeably lower columns 56 nodes involved computations communication pass ring1 slows communication significantly computation intensive applications often used achieve high flops rlsp application computation intensive application table 1 shows isospeed scalability give credits computation intensive applications computation intensive applications may achieve high speed multiple processors initial speed also high isospeed scalability measures ability maintain speed rather achieve particular speed implementation conducted ksr1 shared virtual memory machine theoretical analytical results given section 2 section 3 however general applied different parallel platforms instance intel paragon parallel computers virtual memory supported swap data memory disk expect inefficient sequential processing cause similar superlinear traditional speedup demonstrated ksr1 distributedmemory machines support virtual memory cm5 traditional speedup another draw back due memory constraint scaled problems often cannot solved single processor therefore scaled speedup unmeasurable defining asymptotic speed similarly given section 3 generalized speedup applied kind distributedmemory machines measure scalable computations generalized speedup defined parallel speed sequential speed given reasonable initial sequential speed used parallel platforms measure performance scalable computations 5 conclusion since scaled principle proposed 1988 gustafson researchers sandia national laboratory 21 principle widely used performance measurement parallel algorithms architectures one difficulty measuring scaled speedup vary large problems solved uniprocessor inefficient virtual memory supported impossible otherwise overcome shortcoming generalized speedup proposed 1 generalized speedup defined parallel speed sequential speed require solving large problems uniprocessor study 1 emphasized fixedtime generalized speedup sizeup meet need emerging shared virtual memory machines generalized speedup particularly implementation issues carefully studied current research shown traditional speedup special case generalized speedup hand generalized speedup reform traditional speedup main difference generalized speedup traditional speedup define uniprocessor efficiency uniprocessor speed fixed two speedups extending results scalability study found difference isospeed scalability 12 isoefficiency scalability 13 also due uniprocessor efficiency uniprocessor speed independent problem size two proposed scalabilities part performance study shown algorithmmachine combination achieves perfect scalability achieves perfect speedup interesting relation fixedtime memorybounded speedups revealed seven causes superlinear speedup also listed scientific application implemented kendall square ksr1 shared virtual memory machine experimental results show uniprocessor efficiency important issue virtual memory machines asymptotic speed provides reasonable way define uniprocessor efficiency results paper shared virtual memory extended general parallel com puters since uniprocessor efficiency directly related parallel execution time scalability benchmark evaluations range applicability uniprocessor efficiency study wider speedups uniprocessor efficiency might explored number contexts acknowledgement authors grateful cornell theory center providing access ksr1 parallel computer referees helpful comments revision paper r toward better parallel performance metric advanced computer architecture parallelism solution partial differential equations vector parallel com puters validity singleprocessor approach achieving large scale computing capabilities scalable problems memorybounded speedup modeling speedupn greater n parallel efficiency greater unity inflated speedups parallel simulations via malloc performance prediction scalable computing case study design scalable fixedtime computer benchmark scalability parallel algorithmmachine combinations isoefficiency measuring scalability parallel algorithms architectures ksr parallel programming fattrees universal networks hardwareefficient supercomputing ksr technical summary solution illposed problems gpst inversion algorithm history matching 3d 2phase simulators solving linear systems vector shared memory computers distributed orthogonal factorization givens householder algorithms development parallel methods 1024 processor hypercube tr ctr prasad jogalekar murray woodside evaluating scalability distributed systems ieee transactions parallel distributed systems v11 n6 p589603 june 2000 xianhe sun scalability versus execution time scalable systems journal parallel distributed computing v62 n2 p173192 february 2002 xianhe sun jianping zhu performance prediction case study using scalable sharedvirtualmemory machine ieee parallel distributed technology systems technology v4 n4 p3649 december 1996 xianhe sun wu zhang parallel twolevel hybrid method tridiagonal systems application fast poisson solvers ieee transactions parallel distributed systems v15 n2 p97106 february 2004 xianhe sun mario pantano thomas fahringer integrated range comparison dataparallel compilation systems ieee transactions parallel distributed systems v10 n5 p448458 may 1999