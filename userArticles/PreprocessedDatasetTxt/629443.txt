efficient dynamic scheduling algorithm multiprocessor realtime systems abstractmany timecritical applications require predictable performance tasks applications deadlines met paper propose efficient algorithm nonpreemptive scheduling dynamically arriving realtime tasks aperiodic tasks multiprocessor systems realtime task characterized deadline resource requirements worst case computation time p processors p degree parallelization task use parallelism tasks meet deadlines thus obtain better schedulability compared nonparallelizable task scheduling algorithms study effectiveness proposed scheduling algorithm conducted extensive simulation studies compared performance myopic 8 scheduling algorithm simulation studies show schedulability proposed algorithm always higher myopic algorithm wide variety task parameters b introduction multiprocessors emerged powerful computing means realtime applications avionic control nuclear plant control capability high performance reliability problem multiprocessor scheduling determine processor given task ex ecutes done either statically dynamically static algorithms assignment tasks processors time tasks start execution determined priori static algorithms work supported indian national science academy department science technology 9 12 often used schedule periodic tasks hard deadlines main advantage solution found one sure deadlines guaranteed however approach applicable aperiodic tasks whose characteristics known priori scheduling tasks multiprocessor realtime system requires dynamic scheduling algorithms dynamic scheduling 3 8 new tasks arrive scheduler dynamically determines feasibility scheduling new tasks without jeopardizing guarantees provided previously scheduled tasks thus predictable executions schedulability analysis must done tasks execution begun feasible schedule generated timing resource constraints tasks satisfied ie schedulability analysis successful tasks dispatched according feasible schedule r oeae oeae oeae current schedule dispatch queues processors min length dispatch queues fig1 parallel execution scheduler processors oe tasks task queue scheduler dynamic scheduling algorithms either distributed centralized distributed dynamic scheduling scheme tasks arrive independently processor task arrives processor local scheduler processor determines whether satisfy constraints incoming task task accepted satisfied otherwise local scheduler tries find another processor accept task centralized scheme tasks arrive central processor called scheduler distributed processors system execution paper assume centralized scheduling scheme communication scheduler processors dispatch queues processor dispatch queue organization shown fig1 ensures processors always find tasks dispatch queues finish execution current tasks scheduler running parallel processors scheduling newly arriving tasks periodically updating dispatch queues scheduler ensure dispatch queues always filled minimum capacity tasks left parallel operation minimum capacity depends average time required scheduler reschedule tasks upon arrival new task 10 shown 3 exist algorithm optimally scheduling dynamically arriving tasks without mutual exclusion constraints multiprocessor system negative results motivated need heuristic approaches solving scheduling problem recently many heuristic scheduling algorithms 8 13 proposed dynamically schedule set tasks computation times deadlines resource requirements 13 shown uniprocessor systems simple heuristic accounts resource requirements significantly outperforms heuristics scheduling based earliest deadline first edf ignore resource requirements multiprocessor systems resource constrained tasks heuristic search algorithm called myopic scheduling algorithm proposed 8 authors 8 shown integrated heuristic function deadline earliest start time task performs better simple heuristics edf least laxity first minimum processing time first meeting deadlines achieving high resource utilization two main goals task scheduling realtime systems preemptive 12 nonpreemptive algorithms 8 9 available literature satisfy requirements schedulability preemptive algorithm always higher nonpreemptive version however higher schedulability preemptive algorithm obtained cost higher scheduling overhead parallelizable task scheduling considered paper intermediate solution tries meet conflicting requirements high schedulability low overhead known scheduling algorithms 8 9 12 consider task executed single processor may result missing task deadlines due poor processor utilization moreover tasks would miss deadlines total computation time requirement deadline motivating factors go parallelizable task scheduling however simulation study assume computation times tasks less deadlines order compare results nonparallelizable task scheduling algorithm parallelizable task scheduling problem studied earlier nonrealtime systems 2 4 11 proved npcomplete many researchers assuming sublinear task speedups due interprocessor communication overhead proposed approximation algorithms 2 4 problem heuristic algorithm precedence constrained tasks linear speedup assumption reported 11 realtime systems tasks additional constraints namely ready times deadlines makes realtime scheduling problem harder nonrealtime scheduling 5 linear overhead assumption optimal pseudopolynomial time algorithm proposed schedule imprecise computational tasks realtime systems solution static scheduling cannot applied dynamic case considered paper 1 algorithms scheduling realtime tasks partitionable hypercube multiprocessor proposed degree parallelization task determined scheduler rather specified part requirements task ie scheduler cannot change degree parallelization task meeting deadline 7 parallelizable task scheduling algorithm dynamically scheduling independent realtime tasks multiprocessors proposed work assumes tasks periodic importantly algorithms reported 1 5 7 consider resource constraints among tasks practical requirement complex realtime system parallelizable realtime task scheduling wide applicability problems robot arm dynamics image processing example robot arm dynamics problem consists two computational modules computation dynamics solution linear system equations exhibit high degree parallelism realtime constraints 14 similarly typical realtime image processing application involves pixellevel operations convolution carried parallel different portions image operations task matching grouping splitting objects also done parallel objective work propose dynamic scheduling algorithm exploits parallelism tasks order meet deadlines thereby increasing performance system rest paper structured follows task model definitions stated section 2 section 3 present dynamic scheduling algorithm section 4 evaluate performance simulation studies finally section 5 concluding remarks made basics 21 task model assume realtime system consists processors 1 1 task aperiodic characterized arrival time ready time r worst case computation time worst case computation time upper bound computation time run j processors parallel 1 j 2 task might need resources data structures variables communication buffers execution every task two types accesses resource exclusive access case task use resource b shared access case share resource another task task also willing share resource resource conflict exists two tasks j require resource one accesses exclusive 3 task parallelized parallel subtasks also called split tasks start time order synchronize executions 4 tasks nonpreemptable ie task split task starts execution finishes completion 5 task worst case computation time j k called sublinear speedup assumption sublinearity due overheads associated communication synchronization among split tasks task 22 terminology definition 1 task feasible schedule timing constraint resource requirements met schedule schedule set tasks said feasible schedule tasks feasible schedule definition 2 partial schedule feasible schedule subset tasks partial schedule said strongly feasible schedules obtained extending current schedule one remaining tasks also feasible 8 definition 3 eat earliest time resource r k becomes available shared exclusive usage 8 definition 4 let p set processors r set resources requested task earliest start time task denoted estt earliest time execution started defined est eat u k avail timej denotes earliest time processor p j becomes available executing task third term denotes maximum among earliest available times resources requested task shared mode exclusive mode 3 dynamic task scheduling algorithm section present dynamic scheduling algorithm exploits parallelism tasks meet deadlines context paper dynamic scheduling algorithm complete knowledge currently active set tasks new tasks may arrive scheduling current set proposed parallelizable task scheduling algorithm variant myopic algorithm proposed 8 myopic algorithm heuristic search algorithm schedules dynamically arriving realtime tasks resource constraints vertex search tree represents partial schedule schedule vertex extended vertex strongly feasible strong feasibility checked first k tasks current task queue also known feasibility check window larger size feasibility check window higher scheduling cost look ahead nature proposed scheduling algorithm similar myopic algorithm except parallelizes task whenever deadline cannot met scheduling cost myopic algorithm degree parallelization ie number split tasks task chosen way tasks deadline met scheduling task processors resources minimum earliest available time selected scheduling cost parallelizable task scheduling algorithm made equal myopic algorithm performing feasibility check k tasks k k compared k myopic algorithm value k depends number tasks parallelized degrees parallelization ie feasibility check done till sum degrees parallelization tasks reaches k words parallelizable task scheduling algorithm number tasks checked feasibility less equal size feasibility check window k worst case none tasks need parallelized parallelizable task scheduling algorithm behaves like myopic algorithm case k parallelizable task scheduling algorithm scheduling set currently active tasks given parallelizable task schedulingk maxsplit k size feasibility check window maxsplit maximum degree parallelization task input parameters begin 1 order tasks task queue nondecreasing order deadlines start empty partial schedule 2 determine whether current vertex schedule strongly feasible performing feasibility check k less k tasks feasibility check window given ffl let k count number tasks feasibility check done k 1th task current task queue ffl let numsplit maximum degree parallelization permitted current task ffl let cost sum degree parallelization k tasks feasibility check done far b feasible true k gamma cost numsplit ii compute iii find smallest j est iv j exists cost v else numsplit maxsplit break vi else feasible false 3 feasible true compute heuristic function h first k tasks b extend schedule task best smallest h value 4 else backtrack previous search level b extend schedule task next best h value 5 move feasibility check window one task 6 repeat steps 25 termination condition met end termination conditions either complete feasible schedule found b maximum number backtracks h function evaluations reached c backtracking possible heuristic function h integrated heuristic captures deadline resource requirements task k w constant input parameter algorithm backtracks deadline task cannot met using degree parallelization upto maxsplit time complexity proposed algorithm scheduling n tasks okn myopic algorithm fig2b feasible schedule produced parallelizable task scheduling algorithm task set given fig2a 4 processors 1 resource 2 instances arrival time tasks fig2a 0 input values k w number backtracks maxsplit taken 4 1 1 2 respectively fig2c fig2d show search tree constructed myopic scheduling algorithm task set given fig2a myopic algorithm unable produce feasible schedule task set whereas proposed algorithm able produce feasible schedule task set search tree constructed proposed algorithm given fig2c fig2e fig2b tasks 11 13 parallelized scheduled processors p 2 p 4 p 1 p 3 respectively task ready time comp time deadline resource share 28 exclusive fig2a example realtime task set t2t 48 fig2b feasible schedule produced parallelizable task scheduling algorithm fig2c2e node search tree represented two boxes left box shows earliest available time processors executing new task right box two entries separated comma correspond earliest available time resource instances one entry per resource instance entry value within without parenthesis indicates available time particular resource instance exclusive shared mode example entry 0303434 indicates first instance resource available shared mode time 0 exclusive mode time 30 second instance resource available shared exclusive mode time 34 fig2c2e forward arcs correspond extending schedule whereas backward arcs correspond backtracking label b forward arc denotes task scheduled processor p b example 13 3 1 denotes task 13 parallelized scheduled processors 1 infeasible due 11 infeasible due 13 1 41374137 fig2c portion search tree common algorithms fig2d portion search tree specific myopic algorithm fig2e portion search tree specific parallelizable task scheduling algorithm illustrating working myopic algorithm consider first vertex fig2d point tasks feasibility check window est similarly three tasks also feasible therefore current schedule strongly feasible heuristic values four tasks 58 61 61 64 respectively best task 10 schedule extended scheduling p 3 new vertex thus obtained strongly feasible 11 feasible hence algorithm backtracks previous vertex extends schedule using next best task 11 parallelizable task scheduling consider vertex scheduling 10 fig2e feasibility check window size 3 since three tasks scheduled three 11 checked feasibility since feasibility checking 13 exceeds k therefore schedule extended scheduling 12 p 1 t11 t13 h value first schedule extended 11 parallelizing scheduling split tasks p 2 p 4 finally 13 scheduled note tasks feasible schedule 4 simulation studies study effectiveness task parallelization meeting tasks deadline conducted extensive simulation studies interested whether tasks task set finish deadlines therefore appropriate metric schedulability task sets 8 called success ratio defined ratio number task sets found schedulable scheduling algorithm number task sets considered scheduling parameters used simulation studies given fig3 schedulable task sets generated simulation using following approach 1 tasks task set generated till schedule length input parameter idle time processors described 8 computation time c 1 task chosen randomly min c max c 2 deadline task randomly chosen range sc 1 r sc sc shortest completion time task set generated previous step 3 resource requirements task generated based input parameters usep sharep 4 computation time c j task executed j processors j 2 equal 1 example c 1 computation times c 2 7 5 4 respectively point performance curves figs48 average 5 simulation runs 200 task sets task set contains approximately 175 200 tasks fixing schedule length 800 task set generation simulation runs number instances every resource taken 2 figs48 represent success ratio varying r w usep numbtrk k respectively maxsplit 1 task considered nonparallelizable algorithm behaves like myopic algorithm note scheduling costs different values maxsplit equal achieved making number tasks checked feasibility k variable discussed previous section ie maxsplit1 figs48 interesting note increase degree parallelization increases success ratio speedup function used parameter explanation min c minimum computation time tasks taken 30 max c maximum computation time tasks taken 60 r laxity parameter denotes tightness deadline usep probability task uses resource sharep probability task uses resource shared mode taken 05 k size feasibility check window w weightage given estt h calculation numbtrk number backtracks permitted search numproc number processors considered simulation numres number resource types considered simulation maxsplit maximum degree parallelization task fig3 simulation parameters 41 effect laxity parameter fig4 shows effect success ratio laxity parameter r helps investigating sensitivity task parallelization varying laxities fig4 clear lower values maxsplit sensitive change r higher values maxsplit example success ratio offered maxsplit1 varies 472994 compared variation success ratio offered maxsplit4 due fact tasks experience degree parallelization order meet deadlines laxities deadlines tight tasks higher laxities rarely need parallelization since deadlines met without parallelizing shows task parallelization effective tasks tighter laxities 42 effect w parameter sensitivity integrated heuristic various degrees task parallelization studied fig5 effect w different values maxsplit offers similar trend success ratio increases initially increasing w saturates larger values w increasing w beyond 60 would decrease success ratio shown fig5 w large integrated heuristic behaves like simple heuristic takes care availability processors resources ignoring tasks deadline similarly w0 success ratio would poor integrated heuristic reduces edf also simple heuristic success laxity parameter fig4 effect r paramter success parameter fig5 effect w parameter 43 effect resource usage effect resource usage success ratio shown fig6 fixing r k numbtrk sharep values 009 7 10 05 respectively fig6 observe success ratio decreases increasing usep due resource conflicts among tasks make value estt task decided availability required resources rather availability processors ready time task lower values resource usage usep difference success ratio offered maxsplit4 maxsplit1 less compared higher values usep shows task parallelization effective resource constraints among tasks high another study shown usep fixed sharep varied success ratio increases increasing sharep 44 effect number backtracks fig7 impact number backtracks success ratio plotted various values maxsplit plots interesting note success ratio improve significantly increasing values numbtrk values maxsplit clearly motivates need finding techniques increase success ratio increasing scheduling cost fixing number backtracks exploitation parallelism task proposed paper one technique demonstrated simulation results different values maxsplit success resource usage probability fig6 effect resource usage probability success number backtracks fig7 effect number backtracks 45 effect size feasibility check window fig8 shows effect varying feasibility check window k success ratio different values maxsplit note larger values k algorithm look ahead nature number h function evaluations feasibility window also means increase scheduling cost increasing size feasibility check window k increases success ratio values maxsplit effect lower values maxsplit ie larger values maxsplit less sensitive changes k indicates task sets feasibly scheduled allowing task parallelization nonparallelizable task scheduling scheduling cost conclusions meeting deadlines achieving high resource utilization two main goals task scheduling realtime systems preemptive nonpreemptive algorithms available literature satisfy requirements schedulability preemptive algorithm always higher nonpreemptive version however higher schedulability preemptive algorithm obtained cost higher scheduling overhead parallelizable task scheduling considered paper intermediate solution tries meet conflicting requirements high schedulability low overhead paper proposed new algorithm based parallelizable task model dynamic scheduling tasks realtime multiprocessor systems demonstrated simulation task parallelization useful concept achieving better schedulability allowing number backtracks without parallelization simulation studies show success ratio offered algorithm always higher myopic algorithm wide variety task parameters simulation studies following inferences drawn ffl task parallelization effective tasks tighter laxities resource constraints among tasks high sensitivity w different values task parallelization offers similar trend increasing size feasibility check window k increases success ratio values maxsplit ffl impact number backtracks success ratio less significant compared parameters clearly indicates need spending scheduling cost task parallelization rather backtracking success size feasibility check window fig8a effect k 8 processors success size feasibility check window fig8b effect k processors resource reclaiming schedule consisting parallelizable realtime tasks possible actual computation times tasks less worst case computation times resource reclaiming algorithms proposed 6 10 cannot applied algorithms ignorant fact tasks parallelized scheduled one processor therefore problem resource reclaiming parallelized tasks needs research r online hard realtime scheduling parallel tasks partitionable multiprocessors approximate algorithms partitionable independent task scheduling problem multiprocessor online scheduling hard realtime tasks approximate algorithm scheduling tasks varying partition sizes partitionable multiprocessor systems algorithms scheduling imprecise computations new approach scheduling parallelizable tasks realtime multiprocessor systems efficient scheduling algorithms realtime multiprocessor systems allocation scheduling precedencerelated periodic tasks resource reclaiming multiprocessor realtime systems heuristic scheduling parallel tasks analysis scheduling processes release times deadlines precedence exclusion relations scheduling tasks resource requirements hard realtime systems parallel processing realtime simulation case study tr ctr wei sun chen yu xavier defago yuanyuan zhang yasushi inoguchi realtime task scheduling using extended overloading technique multiprocessor systems proceedings 11th ieee international symposium distributed simulation realtime applications p95102 october 2226 2007 mohammed alghamdi tao xie xiao qin parm poweraware message scheduling algorithm realtime wireless networks proceedings 1st acm workshop wireless multimedia networking performance modeling october 1313 2005 montreal quebec canada g manimaran shashidhar merugu anand manikutty c siva ram murthy integrated scheduling tasks messages distributed realtime systems engineering distributed control systems nova science publishers inc commack ny 2001 g manimaran c siva ram murthy faulttolerant dynamic scheduling algorithm multiprocessor realtime systems analysis ieee transactions parallel distributed systems v9 n11 p11371152 november 1998 r alomari arun k somani g manimaran efficient overloading techniques primarybackup scheduling realtime systems journal parallel distributed computing v64 n5 p629648 may 2004 wan yeon lee sung je hong jong kim online scheduling scalable realtime tasks multiprocessor systems journal parallel distributed computing v63 n12 p13151324 december xiao qin hong jiang dynamic reliabilitydriven scheduling algorithm parallel realtime jobs executing heterogeneous clusters journal parallel distributed computing v65 n8 p885900 august 2005