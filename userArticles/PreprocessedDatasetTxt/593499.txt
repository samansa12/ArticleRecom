scalable techniques mining causal structures mining association rules market basket data proved fruitful area research measures conditional probability confidence correlation used infer rules form existence item implies existence item b however rules indicate statistical relationship b specify nature relationship whether presence causes presence b converse attribute phenomenon causes appear together applications knowing causal relationships extremely useful enhancing understanding effecting change distinguishing causality correlation truly difficult problem recent work statistics bayesian learning provide avenues attack fields goal generally learn complete causal models essentially impossible learn largescale data mining applications large number variablesin paper consider problem determining casual relationships instead mere associations mining market basket data identify problems direct application bayesian learning ideas mining large databases concerning scalability algorithms appropriateness statistical techniques introduce initial ideas dealing problems present experimental results applying algorithms several large realworld data sets results indicate approach proposed computationally feasible successful identifying interesting causal structures interesting outcome perhaps easier infer lack causality infer causality information useful preventing erroneous decision making b introduction paper consider problem determining casual relationships instead mere sociations mining market basket data discuss ongoing research bayesian learning techniques developed infer casual relationships observational data identify one line research community appears hold promise largescale data mining identify problems direct application bayesian learning ideas mining large databases concerning issue scalability algorithms appropriateness statistical techniques introduce ideas dealing problems present experimental results applying algorithms several large realworld data sets results indicate approach proposed feasible successful identifying interesting causal structures significant outcome appears easier infer lack causality information useful preventing erroneous decision making conclude notion causal data mining likely fruitful area research database community large discuss possibilities future work let us begin briefly reviewing past work involving market basket problem involves number baskets contains subset universe items alternative interpretation item boolean variable representing presence absence item view basket simply boolean vector values assigned variables market basket problem find interesting patterns data bulk past research concentrated patterns called association rules type item likely present baskets containing items major issue mining association rules finding appropriate definitions interest specific applications early approach due agrawal imielinski swami 2 find pair items occur together often high support also property one item often occurs baskets containing item high confidence 1 effect framework chooses conditional probability measure interest many variants interest measure considered literature flavor similar conditional probability measures critiqued brin motwani silverstein 9 proposed statistical correlation appropriate interest measure capturing intuition behind association rules previous work association rules market basket mining rules inferred existence item basket implies item b also likely present basket often denoted b indicate existence statistical relationship items b however specify nature relationship whether presence causes presence b converse phenomenon causes appear together knowledge causal relationships likely useful enhancing understanding effecting change fact even knowledge lack casual relationship aid decision making based data mining illustrate points 1 supportconfidence definition easily extends beyond pairs items incorporate sets arbitrary size following hypothetical example consider supermarket manager notes meatbuying customers following purchasing pattern buy hamburgers 33 time buy hot dogs 33 time buy hamburgers hot dogs 33 time moreover buy barbecue sauce buy hamburgers assumptions 66 baskets contain hot dogs 50 baskets hot dogs also contain barbecue sauce manager find association rule hot dogs barbecuesauce high support confidence course rule hamburger barbecuesauce even better confidence obvious association manager deal hot dogs may choose sell large discount hoping increase profit simultaneously raising price barbecue sauce however correct causal model purchase hamburgers causes purchase barbecue sauce tells us approach going work fact sales hamburgers barbecue sauce likely plummet scenario customers buy hot dogs fewer hamburgers leading reduction sales barbecue sauce manager could infer correct causal model even infer hotdogs causes barbecuesauce part possible causal model could avoid pricing fiasco basic tenet classical statistics 6 20 correlation imply causation thus appears impossible infer causal relationships mere observational data available data mining since infer correlations data fact would seem infer causal relationships essential collect experimental data variables controlled explicitly experimental method neither desirable possible applications data mining fortunately recent research statistics bayesian learning communities provide avenues attack two classes technique arisen bayesian causal discovery focuses learning complete causal models small data sets 8 12 14 15 16 17 21 22 23 25 26 27 offshoot bayesian learning method called constraintbased causal discovery use data limit sometimes severely possible causal models 11 26 24 techniques first class still practical large data sets limited version constraintbased approach linear database size thus practical even gigabytes data present flexible constraintbased algorithm linear number records baskets database though cubic number items record despite cubic time bound algorithm proves practical databases thousands items paper explore applicability constraintbased causal discovery discovering causal relationships market basket data particularly build ideas presented cooper 11 using local tests find subset causal relationships rest section discuss causality data mining context research causal learning begin section 2 particular constraintbased algorithm due cooper 11 upon build algorithms example borrowed talk given heckerman presented paper enhance algorithm first time causality inferred largescale marketbasket problems ffl section 2 introduces ccu inferences form causal structure used 11 ffl section 3 discusses weaknesses cooper algorithm notably susceptibility statistical error power statistics correlation used mitigate problems ffl section 4 describe detail algorithms developed discovering causal relation ships also discuss discovery noncausal relationships important technique filters many statistically unlikely inferences causality ffl first time able run causality tests real largescale data section 5 test algorithm variety realworld data sets including census data text data former data sets discover causal relationships nonrelationships census categories gender income text data set discover relationships words ffl finally section 6 discuss possible directions future research 11 previous research causality mentioned significant work discovering causal relationships using bayesian analysis bayesian network combination probability distribution structural model directed acyclic graph nodes represent variables attributes arcs represent probabilistic dependence effect bayesian network specification joint probability distribution believed generated observed data causal bayesian network bayesian network predecessors node interpreted directly causing variable associated node bayesian learning techniques user typically specifies prior probability distribution space possible bayesian networks algorithms search network maximizes posterior probability data provided general try balance complexity network fit data possible number causal networks severely exponential number variables practical algorithms must use heuristics limit space networks process helped quality prior distribution often prior distribution unknown tedious specify particularly number variables ie items large case uninformative prior used even informative priors available goal finding full causal model aggressive bayesian algorithms computationally expensive improved heuristics use sampling may make bayesian algorithms practical yet demonstrated data sets many variables view inferring complete causal models ie causal bayesian networks essentially impossible largescale data mining applications thousands variables class applications socalled constraintbased causal discovery method 24 26 appears useful basic insight articulated cooper 11 information statistical independence dependence relationships among set variables used constrain sometimes significantly possible causal relationships among subset variables simple example constraint attributes b independent clear causal relationship shown reasonable set assumptions data discussed later whole array valid constraints derived causal relationships variables constraintbased methods provide alternative bayesian methods pc fci algorithms 26 use observational data constrain possible causal relationships variables allow claims made x causes x caused x common cause pairs may able state causal relationship constraintbased algorithms like bayesian algorithms attempt form complete causal model therefore take exponential time due complexity causal tests may also less reliable simpler algorithms cooper 11 described algorithm called lcd special case pc fci algorithms runs polynomial time since algorithm based coopers discuss detail section 2 12 causality market basket analysis finding causality context data mining particularly difficult data sets tend large order megabytes data thousands variables large size poses challenge also allows specializations optimizations causal algorithms holding promise algorithms crafted particularly data mining applications may yield useful results despite large amount data processed promise holds particularly true market basket data even specialized application note issues involved finding causality market basket case ffl market basket data boolean may allow added efficiency algorithms work discrete continuous data shall see section 31 statistical tests essential constraintbased causal discovery pleasant properties boolean case ffl traditional market basket problem assumes missing data given item basket known whether item basket assumption obviates need complex algorithms estimate missing data values ffl market basket data usually voluminous algorithms need large amount data develop causal theory well suited application ffl thousands items likely hundreds thousands causal relation ships optimal algorithm might find relationships output interesting ones undoubtedly using another data mining algorithm subroutine acceptable find output small number causal relationships selection may occur either due pruning due algorithm finds causal relationships certain form algorithms output small number possibly arbitrarily decided causal relationships may useful outside data mining context data mining however used exploratory analysis hypothesis testing obviously technique finding causal relationships somehow picking interesting ones superior one chooses relationships arbitrarily even techniques latter category valuable data mining setting ffl market basket applications thousands items finding complete causal model expensive also difficult interpret believe isolated causal rela tionships involving pairs small sets items easier interpret ffl many market basket problems discovering two items causally related least directly causally related one may cause influence third factor may useful finding two items causally related complete causal models illuminate lack causality easily illuminate causality algorithms produce partial models useful market basket setting discover noncausal relationships well causal relationships aspects discovering causality market basket data drove development algorithms present section 4 many issues point constraintbased methods well suited market basket analysis others indicate tailoring constraintbased methods instance providing error analysis predicated boolean data discovering lack causality yield sizable advantages using generic constraintbased techniques 2 lcd algorithm lcd algorithm 11 polynomial time constraintbased algorithm uses tests variable dependence independence conditional independence restrict possible causal relationships variables crux technique markov condition 26 node causal bayesian network let b node descendant causal network markov condition holds b independent conditioned parents intuition condition follows b dependent b must either possibly indirect cause possibly indirectly caused second case b descendant first b ancestor effect immediate parents fixed assuming markov condition make causal claims based independence data instance suppose know possibly priori knowledge causes b dependent b must caused though possibly indirectly third variable c dependent b three variables lie along causal chain variable since causes head chain dont know whether b causes c vice versa however c become independent conditioned b conclude markov condition b causes c discussion follows denote b c claim b causes c note contrary normal use bayesian network literature use mean b direct cause c restricted attention three variables cannot fact say assurance b direct cause c may confounding variable hidden variable mediates b c confounding variable variable interacts causally items tested discovered included tests performed hidden variable represents effect interacts causally items tested captured variable data set even hidden confounding variables say assurance cause b b cause c also say assurance direct cause c since causality mediated b minimum drop assumption causes models besides consistent data particular may c case impossible without knowledge make causality judgments still say direct cause c though know indirect cause even caused c instead causing c summarize observations ccc rule named since holds b c pairwise correlated 3 rule 1 ccc causality suppose b c three variables pairwise depen dent c become independent conditioned b may infer one following causal relations exists b c suppose two variables b c independent correlated b c causal path causal path implying either ancestors descendants b c become dependent conditioned markov condition cannot descendants conclude b c causes observation gives rise ccu rule named since two variable pairs correlated one uncorrelated rule 2 ccu causality suppose b c three variables b corre lated c correlated b c uncorrelated b c become correlated conditioned may infer b c cause cannot say whether hidden confounding variables mediate causality 3 correlation indicates dependence specific value correlation coefficient use term correlation intend clear context algorithm lcd input set v variables w variable known causes data set tests dependence independence conditional independence ci respectively output list causal relationships supported data variables x 6 w dx variables 62 fx wg dx dy w cix output x causes table 1 lcd algorithm lcd algorithm uses ccc rule ccu rule determine causal relation ships looks triples items one item known priori cause way disambiguate possible causal models algorithm assumes tests dependence conditional independence shown table 1 lcd algorithm depends correctness statistical tests given input one test wrongly indicates dependence conditional independence results invalid false positives false negatives additional assumption already stated applicability markov condition list assumptions described cooper 11 validity market basket data database completeness value every variable known every database record commonly assumed market basket applications discrete variables every variable finite number possible values market basket problem boolean variables causal faithfulness two variables causally related independent reasonable assumption except extraordinary data sets instance positive negative correlations exactly cancel markov condition condition reasonable data actually represented bayesian network turn reasonable feedback variables bias probability distribution data set equal probability distribution underlying causal network reasonableness assumption depends specific problem collect supermarket data customers use special discount card likely selection bias collect data customers random customers selection bias unlikely problem valid statistical testing two variables independent test independence say dependent test dependence say assumption unreasonable since tests probability error many tests done case lcd algorithm error even bigger concern see section 31 criticism lcd algorithm finds causal relationships embedded ccc triples presumably small subset possible causal relationships furthermore pruning performed basis goodness function rather exigencies algorithm causal relationships discovered quickly trait lcd algorithm limiting general problematic context data mining mentioned section 12 data mining used exploratory analysis case necessary find even small number specified causal relationships ideal finding small number causal relationships acceptable data mining 3 determining dependence independence cooper 11 uses tests dependence independence primitives lcd algorithm also proposes bayesian statistics tests approach use instead much simpler refer 9 discussion using chisquared tests market basket applications necessary fact two boolean variables independent 2 value likely exceed threshold value 2 ff probability ff tables holding 2 ff various values ff 4 say 2 value greater 2 ff variables correlated probability extend definition market basket problem adding concept support proportion baskets set items occurs support threshold c 2 0 1 confidence threshold itemset said ccorrelated hereafter merely correlated following two conditions met 1 value supports exceeds 2 2 value set items exceeds 2 value significance level c typical values two threshold parameters would expect 5 pairs actually uncorrelated would claim incorrectly correlated support strictly necessary use increase effectiveness chisquared test eliminate rules involving infrequent items intimately tied notion correlation uncorrelation independence typically uncorrelation defined opposite correlation itemset adequate support uncorrelated 2 value support correlation effect chisquared test applied onetailed test 4 boolean case appropriate row table one 1 degree freedom definition clearly problematic sets 2 value cutoff judged uncorrelated even though judge almost 95 chance items actually correlated propose instead twotailed test says evidence dependence ff evidence independence ff 0 following definition based revised test support threshold c 2 0 1 confidence threshold itemset said cuncorrelated hereafter merely uncorrelated following two conditions met 1 value supports exceeds 2 2 value set items exceed 2 value significance level c would expect 5 pairs actually uncorrelated would fail say uncorrelated note would necessarily say correlated pair items may neither correlated uncorrelated pair cannot part either ccc causality ccu causality use chisquared test dependence independence also conditional dependence conditional independence variables b independent conditioned c pab j c chisquared test conditional independence looks statistic 2 ab j chisquared value pair b limited data standard correlation use twotailed chisquared test using different thresholds testing conditional dependence opposed conditional independence example suppose everybody drives votes nobody either driving voting dependent quite powerfully since driving excellent predictor voting vice versa independent conditioned age see note know somebodys age knowing whether drive yields extra insight predicting whether vote note correlation uncorrelation tests bound probability incorrectly labeling uncorrelated data estimate probability incorrectly labeling correlated pairs basic problem statistical analysis correlation rejecting null hypothesis independence requires one test namely correlation unlikely actually 0 rejecting null hypothesis dependence requires infinite number tests correlation 05 correlation 03 obviously observed correlation 01 likelier actual correlation 03 05 giving two different probabilities unclear number would capture concept pair correlated one solution problem define correlation correlation coefficient higher cutoff value boolean data equivalent testing chisquared value see section 31 appendix details 31 coefficient correlation lcd algorithm perform tests dependence independence tens thousands times data sets many items though individual tests may small probability error frequent use means hundreds errors final result problem exacerbated fact single erroneous dependence judgment could form basis rules problem usually handled statistical community lowering tolerance value individual test total error rate low general thousands tests error rate set intolerably low however boolean data even low tolerance value acceptable connection probability error strength correlation presented following theorem proof theorem along concept correlation coefficient heart found appendix theorem 1 let x boolean variables data set size n correlation coefficient ae fail judged correlated confidence level correlation test 2 relationship discarding rules likely erroneous time discarding rules weak correlation weak rules less likely interesting data mining context time reducing probability error improving quality results 4 algorithms causal discovery following discussion shall use following terminology pair items constitutes cedge correlated according correlation test constitute uedge uncorrelated according uncorrelation test note item pair may neither cedge uedge denote number items number baskets n degree node number c u edges involving item delta necessary shall also refer delta c delta u degree restricted c uedges respectively let delta maximum degree maxa defined similarly consider performance algorithms respect three factors memory use running time number passes required database since techniques look triples items memory enough store count information needed algorithms machines om 3 memory require one pass database cases algorithms assume order thousands items caching required database information way feasible however consider om memory available situations less memory available rely naive algorithm requires o1 memory 41 naive algorithm consider first brute force search algorithm determining valid causal relations market basket data effectively iterate triples items checking given triple satisfies conditions either ccc ccu causality requires conditional independence test requires count nabc thus brute force algorithm requires om 3 passes database alone takes time onm 3 however algorithm requires o1 memory words memory available bundle count requests reduce number database passes om 3 42 ccpath algorithm naive algorithm speeded easily odelta c memory available consider item turn determine items connected via cedges pair b c cneighbors check either causality rule applies abc approach requires examine instead om 3 importantly requires n passes database since pass item use space store counts abc b c connected cedge running time resulting algorithm accurately running time accurately still since takes onm time calculate neighbors correlated future ignore fine distinctions algorithm worstcase running time naive algorithm unless delta c large faster performing naive algorithm bundling n 2 count requests 43 cupath algorithm ccpath algorithm named looks joint checks existence third uncorrelated edge another approach appropriate finding ccu causality look c gamma u paths check third edge correlated algorithm superior delta u let delta delta u g general less delta c delta u cupath algorithm requires odelta cu memory om passes database tighter complicated time bound delta u 44 cupath algorithm heuristic cupath algorithm allows heuristic available ccpath algorithm follows fact every ccu triple two c gamma u paths one therefore every u edge choice looking c gamma u paths whether look one endpoint computational point view makes sense pick endpoint abuts fewer cedges result fewer c gamma u paths process one way think c gamma u paths part ccu triples former theoretical theoretical clari theoretical clari algorithm space time time db passes db passes naive o1 onm 3 ccpath cupath cupath heuristic table 2 summary running time space finding ccu causal relationships theory practice clari data set section 54 data set time seconds user time improve running time algorithm grouped items together use maximum memory available machine thus comparison memory use helpful naive algorithm run data set must always look latter try avoid heuristic proven extremely successful particularly number cedges large clari data set section 54 cupath heuristic cut running time half improvement smaller clariworld data set section 52 percent optimizations possible instance algorithms described check twice whether pair items share edge item pair would faster memory permitting determine correlated uncorrelated edges preprocessing step store hash table even better would store edges adjacency list well hash table serve readymade list c uedges abutting joint item experiments improvement data structures halved running time caching many triple counts fit main memory also improve running time constant factor 45 comparison performance table 2 holds summary algorithms consider efficiencies note number database passes algorithms item lacks correlated uncorrelated neighbor need perform database pass item clari data set section 54 316295 cedges 5417 uedges explains superior performance cupath algorithm terms time database passes data large expect io cost cost moving data main secondary memory dominate rather processing cost however really difference algorithms processor io costs justification fixed amount main memory number passes data need proportional number db passes times space required pass reason may process parallel passes many items needed space main memory simultaneously look table 2 see time required algorithm n times product space db passes thus time proportional io cost algorithms consider movedlast5yrs male support nevermarried employed carcab gamma00497 gamma00138 02672 householder 2040k nativeamer b c 02205 gamma00111 gamma00537 military pay govt 01350 gamma00795 gamma05892 table 3 25 causal ccc relationships found census data causal relationship given disambiguated using priori information ae coefficient correlation pair items positive two items found often together negative rarely found together b cause c ae ac ae bc black nogradhs cause carcab gamma00207 gamma01563 asian laborer cause 20k 00294 gamma00259 asian laborer cause 2040k gamma00188 00641 employed military cause under43 gamma00393 gamma02104 employed military cause nevermarried gamma00497 gamma00711 sales householder cause nogradhs gamma00470 gamma00334 table 4 36 causal ccu relationships found census data causal relationship uniquely determined ae coefficient correlation pair items given ab pair pair uncorrelated henceforth shall consider processor time comparisons 5 experimental results use two data sets analysis similar ones used brin motwani silverstein 9 one holds boolean census data section 51 data set collection text data upi reuters newswires section 52 actually study two newsgroup corpora one significantly larger experiments used chisquared cutoff edges use definition support given brin motwani silverstein 9 experiments performed pentium pro 166 mhz processor running solaris x86 251 96 meg main memory algorithms written c compiled using gcc 2722 o6 compilation option 51 census data census data set consists binary items 5 random sample data collected washington state 1990 census items listed appendix b simplify pinterpretation many items discarded responses 60 years old 5 census data categorical data divided number boolean variables thus marital status several items married divorced separated widowed nevermarried every individual true one variables false rest test ccu causality took 3 seconds user cpu time complete test ccc causality took 35 seconds user cpu time indicates census data many c edges u edges surprising since variables derived census question necessity correlated table 3 show results finding ccc causality since several variables male under43 cannot causes census data fits well coopers lcd framework often possible determine direction causation possibility confounding hidden variables however cannot determine direct causality ccc test however allows us rule direct causality yields interesting results intuitively apparent relationship two variables explained third variable example support position correlated moved past five years may lead one believe support personnel unusually unlikely move around however condition white apparent relationship goes away guess white causes one move frequently also causes one support notice case correlation support moving weak indicating rule powerful another ccc rule shows people never married less likely drive work less likely employed conditional used cannot sure causal relationship unmarried less likely jobs unemployed less likely get married table 4 shows ccu causal relationships discovered census data causal relationship uniquely determined confounding hidden variables keep us determining causality direct instance first row table 4 say graduated high school causes one drive work know mediated fact high school dropouts less likely jobs causal rule nogradhs employed may exist neither ccc ccu causality tests found see algorithms better exploratory analysis hypothesis testing note ccc ccu causality tests discovered causal relationship employed never married ccu result used disambiguate among possible causal relationships found ccc test danger ccu result inaccurate due statistical error using disambiguate ccc result propagates error improper uncorrelation judgment cause many erroneous causal inferences instance uncorrelated edge saleshouseholder base 10 ccu judgments causing 5 instance one choice marital status never married 15 years old question regarding means transportation work conflates unemployed 16 causal inferences edge marked uncorrelated incorrectly 20 causal inferences unjustified fact priori knowledge would lead us believe correlation sales head household causal inferences based uedge last entry table 4 clearly false dropping high school temporally prior getting job house thus cannot caused leading us question causal inferences involving saleshouseholder edge 52 text data analyzed 3056 news articles clariworld news hierarchy gathered 13 september 1996 comprising megabytes text text experiments considered article basket word 6 item transformations result data set looks remarkably different census data many items baskets basket sparse keep number items reasonable level considered words occurred least 10 articles also removed commonly occurring stop words much left 6723 distinct words since priori knowledge distinguish possible causal models returned ccc algorithm ran ccu algorithm text data algorithm returned 73074 causal relationships study sorted absolute value correlation coefficient would expect top pairs obvious causal relationships indeed see figure 5 case explore interesting causal relationships also show results 5 list correlations even first set causal relationships along obvious relationships united causing states surprises one relationships quoted causes saying probably part set phrase quoted saying though may illuminate content corpus lend insight writing style news agency another interesting property frequency causal relationships along converse instance prime causes minister minister causes prime probable reason words usually found phrase therefore deterministic relationship words one unlikely occur article without words strongly correlated part phrase iraqi iraq example see causal relationship one direction observation suggests somewhat surprising use causality phrase detection words always occur together part phrase detect phrases even without using word location information looking twoway causality presumably incorporating strategy along conventional methods phrase detection would improve quality phrase identification causal relationships 5 level intriguing top list causal relationship infiltration iraqi points issue may bear study 6 word defined series alphanumeric characters however allowed word single internal punctuation mark removed also lowercased words thus sentence itll cost oneno twopence pincenez words itll cost one two pence pincenez causal relationships 2 value ae causal relationships 2 value ae united states 16910389 07439 forces company 705456 gamma01519 states united 16910389 07439 company forces 705456 gamma01519 prime prime 12888601 06494 commitment peace 702756 01516 quoted saying 8666014 05325 british perry 702082 01516 news agency 7181454 04848 support states 701291 01515 agency news 7181454 04848 states support 701291 01515 table 5 causal relationships top 5 mark list causal relationships words clariworld news hierarchy list sorted absolute value correlation coefficient last column 2 value measures confidence causal relationship 2 values indicate probability error less 00001 ae value measures power causality relationships saturday state seem merely bizarre note also quickly correlation coefficients drop data set 23 causal relationships ae 02 final note causal relationships seem disproportionately concern iraq iraq much news september 1996 news hierarchy includes articles concerning parts world latin america africa oceania however diffuse set issues relating areas vocabulary iraq seemed large number cohesive articles necessary pass support confidence thresholds whether feature causal algorithm 7 bug depends individual application 53 comparing causality correlation question naturally arises advantage causal discovery merely ranking correlated item pairs figure 6 show top 10 correlations measured correlation coefficient results directly comparable top portion figure 5 two difference immediately noticeable one new item pairs like iraq warplanes seem like significant additions others like hussein northern plausible explanations us flight zone restricted northern southern bands iraq seem belong high list perspicuous causal relationships lower correlation coefficient noticeable difference since correlation symmetric case pair converse occurring insofar asymmetric causalities yield extra understanding data set identifying causal relationships yields advantage identifying correlations third difference noticeable figure many correlation rules 7 actually since support confidence concepts used identify c uedges concern causal discovery methodology based similar definition correlation reuter upi 24672895 gamma08985 states united 16910389 07439 minister prime 12888601 06494 quoted saying 8666014 05325 agency news 7181454 04848 hussein northern 6785580 04712 table correlations top list correlations sorted absolute value correlation coefficient last column list superset list top causal relationships figure 5 2 value measures confidence correlation 2 values indicate probability error less 00001 ae value measures power causality causal rules around 70 thousand causal relationships data set 200 thousand correlated pairs 54 performance large text data set clariworld hierarchy somewhat homogeneous seen advantage pruning megabytes small dataset therefore repeated text experiments entire clari hierarchy larger heterogeneous news hierarchy covers sports business technology along regional national international news data set gathered 5 september 1997 clariworld logically subtree clari hierarchy clariworld database subset clari database since articles collected different days clari data set consists 27803 articles 186 megabytes text thus ten times larger clariworld data set however number items kept larger data set 6303 items actually fewer items clariworld data set due pruning infrequent words cases words pruned occurred fewer 03 documents clari data set worked 84 document minimum smaller data set terms highest correlation come coherent subset documents collection unfortunately coherent subset clari collection large mass government postings soliciting bids automotive supplies words used posts abbreviations technical terms thus top causalities recd causes solnbr desc causes solnbr must go 25 lines find causality involving two english words even relationship office causes contact involves words procurement articles causal relationships found 5 list little interesting shown causal relationships 2 value ae cause company 5582142 01417 constitutes number 5578370 01416 modification today people update 5566686 01415 28 5561250 01414 table 7 causal relationships list causal relationships words clari news hierarchy starting 5 list list sorted absolute value correlation coefficient last column 2 value measures confidence causal 2 values indicate probability error less 00001 ae value measures power causality figure 7 note smaller text data set correlation coefficient rapidly becomes rather low 6 conclusion research data mining context constraintbased approaches promise find causal relationships efficiency needed large data sets involved size data mining data sets mitigate weaknesses constraintbased approaches namely sometimes need large amounts data order make causal judgments instead finding causal relationships find subset relationships data mining seeks explore data rather test hypothesis finding portion causal relationships acceptable furthermore large data sets number actual causal relationships likely large algorithms return small portion relationships likely yield interesting results another weakness constraintbased algorithms error inherent repeated use statistical tests mitigated boolean data using power statistic reduce probability error without discarding powerful causal relationships developed series algorithms based techniques used coopers lcd algorithm run time linear size database cubic number variables large data sets thousands variables algorithms proved feasible returned large number causal relationships equally interesting notdirectlycausal relationships feasibility came heuristics algorithmic choices improved time memory requirements naive cubictime algorithm finding causal relationships useful variety reasons one help visualizing relationships among variables another unlike correlation causation asymmetric concept contexts possible intervene variables instance manager choose stock certain food items causality help predict effect intervention whereas correlation analysis cannot context text analysis causation help identify phrases still variety unresolved unexplored issues area mining causal relationships briefly list choosing thresholds way determine optimal values correlation uncor relation cutoffs given data set better yet possible replace cutoff values estimates probability correlation efficiently disambiguation mentioned section 51 risk propagating error use known causal rules disambiguate ccc causality rule however seen may occur data principled way resolve bidirectional causality disambiguation devise efficient algorithms using incremental causal information perform disambiguation hidden variables bidirectional causality may indicate deterministic relationships text phrases error statistical tests presence hidden variables situations confident hidden variables cause techniques use discover hidden variables heuristics efficiency make algorithm even efficient largest speedups could obtained avoiding need check triples determine conditional independence test fail triples without explicitly testing reduce number items perhaps collapsing items similar distributions acknowledgments would like thank members stanford data mining research group particularly lise getoor useful comments suggestions would also like thank greg cooper david heckerman fruitful discussions r inferring structure semistructured data mining association rules sets items large databases database mining performance perspective fast discovery association rules fast algorithms mining association rules large databases categorical data analysis survey exact inference contingency tables probabilistic evaluation counterfactual queries beyond market baskets generalizing association rules correlations dynamic itemset counting implication rules market basket data simple constraintbased algorithm efficiently mining observational databases causal relationships bayesian method induction probabilistic networks data advances knowledge discovery data mining bayesian approach learning causal networks bayesian networks data mining learning bayesian networks combination knowledge statistical data bayesian approach causal discovery definition graphical representation causality mathematical statistics applications bayesian networks causal networks causal diagrams empirical research graphical models probabilistic causal reasoning theory inferred causation algorithm fast recovery sparse causal graphs causal inference presence latent variables selection bias mining generalized association rules sampling large databases finding association rules correlation causation tr ctr stefano ceri francesco di giunta pier luca lanzi mining constraint violations acm transactions database systems tods v32 n1 p6es march 2007 pedro domingos matt richardson mining network value customers proceedings seventh acm sigkdd international conference knowledge discovery data mining p5766 august 2629 2001 san francisco california zhiping zeng jianyong wang lizhu zhou george karypis outofcore coherent closed quasiclique mining large dense graph databases acm transactions database systems tods v32 n2 p13es june 2007 man leung wong shing yan lee kwong sak leung data mining bayesian networks using cooperative coevolution decision support systems v38 n3 p451472 december 2004 ling feng jeffrey xu yu hongjun lu jiawei han template model multidimensional intertransactional association rules vldb journal international journal large data bases v11 n2 p153175 october 2002 qing li ling feng allan wong intratransaction generalized intertransaction landscaping multidimensional contexts association rule mining information sciencesinformatics computer science international journal v172 n34 p361395 9 june 2005 ioannis tsamardinos laura e brown constantin f aliferis maxmin hillclimbing bayesian network structure learning algorithm machine learning v65 n1 p3178 october 2006