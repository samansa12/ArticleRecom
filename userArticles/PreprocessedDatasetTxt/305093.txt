asynchronous parallel prefix computation abstractthe prefix problem compute products x1 otimes x2 otimes cdots otimes xk 1 kn otimes associative binary operation start asynchronous circuit solve problem olog n latency log n circuit size otimesrm operations circuit contributions 1 modification circuit improves averagecase latency olog n olog log n time 2 modification allows circuit run fullthroughput ie constant response time construction used obtain asynchronous adder olog n worstcase latency olog log n averagecase latency b introduction renewal interest design asynchronous circuits motivated potential benefits designing circuits asynchronous fashion asynchronous circuits exhibit average case behavior therefore optimized datadependent fashion present asynchronous solutions parallel prefix problem exploit advantage asynchronous circuits synchronous counterparts reduce average case latency prefix computation letomega associative operation prefix problem compute given x results prefix problem used solve number problems efficiently ladner fisher show prefix problem used parallelize computation arbitrary mealy machine 6 leighton discusses number different problems solved using prefix computations 7 concrete application use method presented paper construct asynchronous adder averagecase latency olog log n steps variety synchronous solutions prefix problem discussed leighton latency olog n steps 7 winograd shown lower bound worstcase time complexity binary addition olog n n number bits input 10 therefore olog n lower bound latency synchronous adder gemmell harchol construct circuits binary addition add correctly probability latency log logn ffl steps construct asynchronous adder always adds correctly averagecase latency olog n steps 3 begin asynchronous solution similar synchronous counterpart improve performance solution introduction pipelining using two competing methods solving prefix problem picking answer arrives earliest produce output solutions presented log n hardware complexity worstcase olog n time complexity supported advanced research projects agency office army research part national semiconductor corporation graduate fellowship use chp communicating hardware processes variant csp 4 give highlevel description circuits use circuits mean asynchronous circuits paper brief description chp provided appendix 2 prefix problem formulate prefix problem terms asynchronous chp program assume inputs arrive input channels respectively outputs produced output channels respectively problem restated terms reading values x input channels computing values sending values appropriate output channels terms chp immediate solution leaps mind following program deltaomega program inefficient number reasons obvious 2 operations correspond 2 circuit elements serve specification problem purposes paper assume operationomega identity e merely aid clarityit detract construction way assume method constructing circuit compute 1omega dn2e could use circuits compute x deltaomega x n adding single process read output two stages performed singleomega operation since operation associative process would read two inputs channels b produce desired output channel c written value x deltaomega x n computed using tree processes shown fig 1 u r u u subtree prefix right subtree prefix left subtree prefix fig 1 tree processes input x k need prefix x deltaomega compute output k observe input particular node tree prefix inputs leaves left right subtree node prefix required first leftmost node right subtree computed prefix required first node left subtree known assume prefix obtained another input channel v process augmented send appropriate subtree prefixes back tree modified process notice ld rd channels provide exactly inputs needed v channel children particular process collection processes indeed solves prefix problem remains provide input root prefix computation tree read inputs produce final outputs v channel root tree requires null prefix identity e output root used process simplify root process e identity ofomega leaves prefix computation tree read inputs prefix tree produce appropriate output leaf process written complete solution problem shown fig 2 since node tree contains constant number ofomega computations since nodes tree node bounded fanin onomega computation circuits solution tree depth olog n therefore time complexity solution olog n ld rd ld rd r root u fig 2 solution prefix problem observe sequencing u xomega v p enforced environment process therefore split process two parts execute parallel however obvious split would cause variable x shared two processes introduce local channel c used copy value x new process two processes identical therefore write using similar technique rewrite leaf process compile process tree using standard techniques introduced martin 9 begin rewriting processes using handshaking expansions transformation eliminates communication channels replaces handshake protocols implement synchronization data communication 8 circuit quasidelayinsensitive must function correctly even inputs circuit arrive time therefore input must encoded using delayinsensitive unordered code code value input changes neutral value valid value without intermediate values valid neutral 9 different valid values used encode different inputs use functions vdelta ndelta denote validity neutrality code c concurrent assignment bits c result appropriate valid value without intermediate value valid neutral c concurrent assignment bits c result neutral value without intermediate value neutral valid exact nature operations depends encoding scheme operationomega prefix computation initiated environment setting inputs valid value environment waits outputs become valid inputs reset neutral value next input supplied outputs reset neutral value handshaking expansions processes comprise prefix computation handshaking expansions given compiled quasidelayinsensitive asynchronous circuit techniques outlined martin 9 resulting circuits similar shown 6 used synchronous implementations well programs presented use binary tree prefix computation method presented easily extended tree kary 3 pipelining solution presented drawback tree perform one prefix computation time permit tree operate simultaneously multiple inputs pipeline prefix computation observe since must wait output become valid resetting input protocol chosen earlier cannot pipelined circumvent problem introduce additional acknowledge signal input output environment permitted reset inputs receiving acknowledge circuit send next input acknowledge signal reset small modification handshaking expansion stage written signals end acknowledge signals various channels downgoing phase upgoing phase fig 3 pipelined prefix computation consider single node prefix computation tree pipeline stages two halves process however downgoing phase computation cannot begin value received channel v value computed circuit pipeline stages proportional depth node tree therefore even though olog n pipeline stages cannot olog n computations performed tree permit must introduce buffering channel connecting two halves leaf buffering proportional depth node tree logically simpler visualize computation unfolding tree two partsthe upgoing phase downgoing phaseas shown fig 3 vertical arrows internal channels c clear one must add stages buffering internal channel c shown vertical arrows fig 3 node steps away root circuit pipelined manner permits 2 log prefix operations performed fig 4 shows tree appropriate buffers introduced throughput number operations performed per second pipelined prefix computation buffers depend number inputs time takes perform theomega operation latency time output produced pipeline empty computation block proportional number stages therefore 2 log without buffers circuit log n components bounded fanin fanout circuits perform aomega computation downgoing phase upgoing phase fig 4 pipelined prefix computation buffers 4 improving average case latency pipelined prefix computation buffers useful prefix computation repeatedly performed however prefix computation used often adding buffers computation tree improve performance prefix computation however may still interested minimizing latency prefix computation tree begin considering simple solution prefix computation problem simplest way perform prefix computation bitserial fashion however since different input channels use n processes one input channel stages connected linearly shown fig 5 r fig 5 serial prefix computation stage x k receives k gamma1 channel l previous stage x k channel x k produces k channel k well channel r connects next stage chp intermediate stage solution given however know input channel x arrives much sooner input channel l given information possible produce outputs r receiving input l suppose know prefix computation operatoromega particular suppose values x input channel x equal produce output r reading value l rewrite serial process follows time taken solution produce output datadependent best case time receiving inputs producing output constantmuch better prefix computation tree worst case time taken onmuch worse prefix computation tree takes olog n time solution adopt combine prefix computation tree serial computation single computation two computations compete one another pick solution arrives first technique worstcase latency olog n bestcase latency o1 modify leaf processes include serial computation original leaf process used prefix computation tree add serial computation phase add channels l r process note value received along channel v value received along channel l combine two channels externally using merge process follows using process new leaf process finally modify merge picks first input produce output compilation serial depends structure ofomega compilation procedure picks first input given circuit efficient implementation know value received l v finally using similar transformation replace process prefix computation tree one also ripplecarry prefix computation resulting computation ripplecarry stage every level prefix computation tree prefix computation given cannot run full throughput o1 buffering stages serial part computation improve throughput prefix computation introduce 2d gamma 1 buffers stage prefix computation depth tree buffers implemented using folded fifo o1 latency 5 analysis average case latency prefix computation datadependent therefore need information input distribution determine averagecase latency consider process serial shown part prefix computation x 6 output r depends input c call propagate case since output process depends input c let probability particular input p let distribution independent across n inputs let ln latency prefix computation n inputs assume prefix computation uses kary tree purpose analysis write ms length longest sequence propagate inputs delay single stage serial propagate chain leaves tree h additional delay introduced adding one level tree ie h delay going upward downward one stage tree first part formula comes rippling computation latter tree computation expand l n observe next stage tree replaced mk inputs next stage tree constructed grouping inputs blocks size k result propagate sequences occur blocks size k longest sequence length mk applying expansion recursively obtain ms particular choosing log average latency bounded log k hlog mi compute expected value log observe reason expected value logarithm random variable log geometric mean variable since arithmetic mean always least geometric mean log increasing always nonnegative inequality follows bound hlni determine hmi know hmi log 2 n cf 1 simple extension proof shows ne proof given appendix therefore average latency prefix computation bounded log k log dlog 11gammap ne olog log n establishes averagecase latency prefix computation olog log n prefix computation operates fullthroughput value given function n since add 2d gamma 1 stages buffering depth tree serial computation part well implemented using cache buffer folded fifo value bounded function o1 therefore fullthroughput modification increase order averagecase latency 6 application binary addition prefix computation used construct binary kpgadder 6 perform binary addition bit position k carryin bitposition must known carryin computation formulated prefix computation follows suppose bit k two inputs zero matter carryin carryout stage zeroa kill k similarly two inputs one carryout always onea generate g otherwise stage propagates p carryin determine carryout two adjacent stages one use operation vertical column represents kpg code least significant bit table 1 prefix operator addition observe kpg code desirable property outlined preceding section namely values x therefore use techniques previous section reduce latency binary addition previous section observe average latency adder olog log n 32bit pipelined adder based section 3 pa132 32bit 64bit pipelined adders olog log n averagecase latency section 4 pa232 pa264 simulated various input values using gatelevel simulator well hspice consider gate circuit directly implemented cmos nand celement fanin fanout restrictions ensure gate delay 01ns 02ns hps 06m cmos technology used branching factor prefix computation tree except would violate gate delay restriction used case quasidelayinsensitive asynchronous circuits obtained result compilation handshaking expansions correspond closely precharged quasistatic domino logic kinniment compares latencies 32bit ripplecarry asynchronous adders asy32 synchronous ripplecarry adders spa32 32bit synchronous carry select adders csa32 5 able compare results reported 5 normalized gate delays one gate delay delay twoinput nand gate assumption made 5 extrapolated delay 64bit synchronous carry select adder csa64 using expression delay given paper two input distributions random numbers used uniform distribution b distribution corresponds realistic workloads 32bit adders 2 results simulation shown table 2 table includes best delays various adder implementations described 5 well throughput circuits pa132 pa232 pa264 one transfer every 163 gate delays adder type worst delay average delay average delay b gates gates gates csa32 113 asy32 401 172 192 pa232 142 104 112 table 2 delay asynchronous synchronous adders uniform b workload difference averagecase worstcase delay pa132 due variations number series transistors switch logic terms delay csa32 better simple prefix computation adder pa132 however pa232 performs better pa132 csa32 random inputs well realistic workloads pa264 performs significantly better csa64 random inputs however pa2 adders slightly higher worstcase delay compared pa1 adders increased fanout internal signals expect difference pa2n csan adders increase n increases however performance csan small n suggests better asynchronous adder could constructed using combination carry select prefix computation techniques pa132 pa232 larger area csa32 due pipelining overhead overhead introduced circuitry generates acknowledge signals 7 variant prefix problem prefix computation used determine location leading one binary string operation useful binary multiplication divisionpreshifting input reduces number stages required compute desired product quotient given nbit input prefix computation produces nbits output bit input know whether position leading one prefix computation number required shifted 0 n bit positions move leading one fixed bit position however input typical variable length shifter encoded binary form produced prefix computation observe sequence decisions made nodes along path taken leading one downgoing phase prefix computation binary encoding bitposition leading one assuming prefix computation tree balanced number inputs power 2 tree balanced using dummy processes therefore augment nodes tree produce bit produced appropriate input shifter part prefix computation done introducing bus level downgoing phase prefix computation tree addition note output buses produced one another significant bit first therefore using pipelined logarithmic shifter shifting completely overlapped downgoing phase prefix computation 8 conclusions paper presented number asynchronous solutions prefix problem first solution olog n latency 1 log n throughput using circuit size pipelined prefix solution olog n latency o1 throughput circuit size increased log n although still contained onomega computation blocks latency prefix computation block improved using two competing prefix computations picking result arrived first circuits 1 log n throughput circuit size circuits datadependent latency worstcase latency olog n bestcase latency o1 general assumptions averagecase latency prefix computation shown olog log n appendix a1 notation notation use based hoares csp 4 full description notation semantics found 8 follows short informal description notation use ffl assignment b statement means assign value b also write true false boolean expressions guards sis program parts execution command corresponds waiting one guards true executing one statements true guard notation g shorthand g skip denotes waiting predicate g become true guards mutually exclusive use vertical bar instead sn execution command corresponds choosing one true guards executing corresponding statement repeating guards evaluate false notation shorthand true means send value e channel x receive v means receive value channel store variable v ffl probe boolean expression x true iff communication channel x complete without suspending ffl sequential composition ffl parallel composition k a2 average case analysis given ninput prefix computation let c n length longest sequence propagate inputs would like determine expected value c n assuming n inputs independent identically distributed random variables probability input propagate type use simple generalization reasoning presented burks et al 1 clearly expected value c n given prc n k probability length longest sequence propagate inputs least k probability prc consists two parts probability first n gamma 1 inputs sequence propagate inputs least k b probability first sequence adding nth input produces sequence length k therefore write second term corresponds part b obtained observing n inputs last k inputs type propagate input position n gamma k type propagate also need take account fact first positions propagate sequence length least k repeatedly expanding first term obtain complete proof note prc n k 1 split range summation two parts pick k nq k 1 ie pick ne obtain ne r preliminary discussion logical design electronic computing instrument cmos vlsi implementation asynchronous alu tight bounds expected time add correctly add mostly correctly communicating sequential processes parallel prefix computation introduction parallel algorithms architectures arrays compiling communicating processes delayinsensitive vlsi circuits asynchronous datapaths design asynchronous adder time required perform addition tr ctr yenchun lin yaohsien hsu chunkeng liu constructing h4 fast depthsize optimal parallel prefix circuit journal supercomputing v24 n3 p279304 march yenchun lin jiannan chen z4 new depthsize optimal parallel prefix circuit small depth neural parallel scientific computations v11 n3 p221236 september yenchun lin junwei hsiao new approach constructing optimal parallel prefix circuits small depth journal parallel distributed computing v64 n1 p97107 january 2004 yenchun lin chinyu su faster optimal parallel prefix circuits new algorithmic construction journal parallel distributed computing v65 n12 p15851595 december 2005