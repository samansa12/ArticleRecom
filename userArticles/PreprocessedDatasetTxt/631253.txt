architecturebased performance analysis applied telecommunication system abstractsoftware architecture plays important role determining software quality characteristics maintainability reliability reusability performance performance effects architectural decisions evaluated early stage constructing analyzing quantitative performance models capture interactions main components system well performance attributes components paper proposes systematic approach building layered queueing network lqn performance models uml description highlevel architecture system exactly architectural patterns used system performance model structure retains clear relationship system architecture simplifies task converting performance analysis results conclusions recommendations related software architecture second part paper proposed approach applied telecommunication product lqn model built analyzed analysis shows performance bottleneck moving component component hardware software different loads configurations exposes weaknesses original software architecture prevent system using available processing power full capacity due excessive serialization b introduction performance characteristics response time throughput integral part quality attributes software system growing body research studies role software architecture determining different quality characteristics general 12 1 performance characteristics special 15 16 architectural decisions made early software development process therefore would helpful able assess effect software performance soon possible paper contributes toward bridging gap software architecture early performance analysis proposes systematic approach building performance models highlevel software architecture system describes main system components interactions architectural descriptions construction performance model based must capture certain issues relevant performance concurrency parallelism contention software resources example software servers critical sections synchronization serialization etc frequently used architectural solutions identified literature architectural patterns pipeline filters clientserver clientbrokerserver layers masterslave blackboard etc 3 12 pattern introduces higherlevel abstraction design artifact describing specific type collaboration set prototypical components playing welldefined roles helps understanding complex systems paper proposes systematic approach building performance model transforming architectural pattern employed system performance submodel advantage using patterns already identified catalogued build library transformation rules converting patterns performance models however components interactions highlevel architecture covered previously identified architectural patterns still describe remaining interactions uml mechanisms 2 proceed defining adhoc transformations performance models formalism used building performance models layered queueing network lqn model 11 17 18 extension wellknown queueing network model lqn developed especially modelling concurrent andor distributed software systems lqn components represent software processes others hardware devices one interesting performance characteristics systems software process may play dual role acting client processes devices server others see section 3 detailed description since software server may many clients important queueing delays may arise server may become software bottleneck thus limiting potential performance system occur even devices used process fully utilized analysis lqn model produces results response time throughput queueing delays utilization different software hardware components indicates components system bottlenecks understanding cause performance limitations developers able concentrate systems trouble spots order eliminate mitigate bottlenecks analysis lqn models various alternatives help choosing right changes system eventually meet performance requirements software performance engineering spe technique introduced 14 proposes use quantitative methods performance models order assess performance effects different design implementation alternatives earliest stages software development throughout whole lifecycle lqn modelling appropriate use due fact model structure derived systematically highlevel architecture system proposed paper since highlevel architecture decided early development process change frequently afterwards structure lqn model also quite stable however lqn model parameters execution times highlevel architectural components behalf different types system requests depend lowlevel design implementation decisions early development stages parameter values estimations based previous experience similar systems measurement reusable components known platform overheads system call execution times time budgets allocated different components development progresses components implemented measured model parameters become accurate results 14 shown early performance modelling definite advantages despite inaccurate results especially model parameters continuously refined throughout software lifecycle lqn applied number concrete industrial systems database applications 5 web servers 7 telecommunication systems etc proven useful providing insights performance limitations software hardware levels suggesting performance improvements different development stages system sizing capacity planning paper lqn applied real telecommunication system although structure lqn model derived highlevel architecture system chosen early development stage used model parameters obtained prototype measurements accurate estimated values available preimplementation phases reason became involved project system undergoing performance tuning used best data available analyze highlevel 5architecture system unchanged early design stages found weaknesses original architecture due excessive serialization used lqn model assess different architectural alternatives order improve performance removing mitigating software bottlenecks paper proceeds follows section 2 discusses architectural patterns uml notation 2 used represent section 3 gives brief description lqn model section 4 proposes transformations architectural patterns lqn submodels section 5 presents telecommunication system case study lqn model section 6 analyzes lqn model various loads configurations shows bottleneck moves around system proposes improvements system section7 gives conclusions work 3 architectural patterns according 1 software architecture represents collection computational components perform certain functions together collection connectors describe interactions components component type described specification defining functions set ports representing logical points interaction component environment connector type defined set roles explaining expected behaviour interacting parties glue specification showing interactions coordinated similar even though less formal view software architecture described form architectural patterns 3 13 identify frequently used architectural solutions pipeline filters clientserver clientbrokerserver masterslave blackboard etc architectural pattern describes two interrelated aspects structure components behaviour interact case highlevel architectural patterns components usually concurrent entities execute different threads control compete resources interact prescribed manner may require kind synchronization aspects contribute performance characteristics system therefore must captured performance model paper proposes use highlevel architectural patterns basis translating software architecture performance models subset patterns later used case study described paper form uml collaborations confused uml collaboration diagrams type interaction diagrams according authors uml collaboration notation describing mechanism pattern represents society filter1 upstreamfilter filter2 downstreamfilter upstreamfilter downstreamfilter filter1 filter2 wait item procitem wait next item procitem figure 1 structural behavioural views collaboration pipeline message filter1 buffer filter2 procitem return read sequential buffer filter1 1n filter2 1n buffer upstreamfilter downstreamfilter buffer upstreamfilter downstreamfilter buffer return read wait item wait next item figure 2 structural behavioural view collaboration pipeline buffer figure classes interfaces elements work together provide cooperative behaviour bigger sum parts 2 collaboration two aspects structural behavioural fig 1 2 illustrate aspects two alternatives pipeline filters pattern figures contains left uml classobject diagram describing pattern structure right uml sequence diagram illustrating pattern behaviour brief explanation uml notation used paper given see 2 details notation class object rectangle indicating classobject name name underlined objects rectangle may contain optionally section classobject operations another one attributes multiplicity classobject represented upper right corner rectangle thick lines represents active classobject thread control whereas rectangle thin lines represents passive one active object may implemented either process thread identified stereotype respectively constraint sequential attached operations passive object fig 2 indicates callers must coordinate outside passive object example means semaphore one calls passive objects operations given time uml symbol collaboration ellipse dashed line may embedded rectangle showing template classes collaboration symbol connected classesobjects dashed lines whose labels indicate roles played component line connecting two objects named link represents relationship two objects interact exchanging messages depending kind interacting objects passive active uml messages may represent either operation calls actual messages sent different flows control links objects may optionally annotated arrows showing name type messages exchanged example fig1 arrow half arrowhead active objects filter1 filter2 represents asynchronous message whereas fig2 arrows filled solid arrowheads labeled write read represent synchronous messages implemented calls operations indicated label relevant object flow carried message represented little arrow circle fig2 message arrow without circle synchronous message implies reply therefore carry objects directions example fig2 object flow carried message read goes reverse direction message sequence diagram right side fig1 2 shows messages exchanged set objects chronological order objects arranged along horizontal axis time grows along vertical axis top bottom object lifeline running parallel time axis lifeline one indicate period time object performing action tall thin rectangle called focus control state object rectangle rounded corners called state mark messages exchanged objects asynchronous synchronous represented horizontal directed lines object also send message means one operations invokes another operation object architectures using pipeline filters pattern divide overall processing task number sequential steps implemented filters data filters flows unidirectional pipes interested active filters 3 running concurrently filter implemented process thread loops following steps pulls data preceding pipe processes pushes results pipeline way push pull operations implemented may performance consequences fig1 filters communicate asynchronous messages filter pulls item accepting message sent previous filter processes item invoking operation procitem passes data next filter sending asynchronous message goes waiting state next item fig2 filters communicate shared buffer one pushes writing buffer pulls reading whereas filters active objects multiplicity one higher buffer passive object offers two operations read write must used one time indicated constraint sequential defining transformations architectural patterns lqn submodels use structural behavioural aspect respective collaborations structural part used directly sense software component counterparts structure lqn model mapping bijective however behavioural part used indirectly sense matched behaviour lqn model represented graphically 3 lqn model lqn developed extension wellknown queueing network qn model first independently 17 18 11 joint effort 4 lqn toolset presented 4 includes simulation analytical solvers merge best previous approaches main difference lqn respect qn server customer requests arriving queueing service may become client servers requires nested services serving clients lqn model represented acyclic graph whose nodes named also tasks software entities hardware devices whose arcs denote service requests see fig3 software entities drawn parallelograms hardware devices circles nodes outgoing incoming arcs play role pure clients intermediate nodes incoming outgoing arcs play role client server usually represent software components leaf nodes pure servers usually servers processors io devices communication network etc software hardware server node either singleserver multiserver composed one identical servers work parallel share request queue lqn task may offer one kind service modelled socalled entry drawn parallelogram slice entry execution time demands services given model parameters although explicitly illustrated lqn notation server implicit message queue incoming requests waiting turn served servers one entry still single input queue requests different entries wait together default scheduling policy queue fifo policies also supported fig 3 shows simple example lqn model threetiered clientserver system top two client classes known number stochastic identical clients client sends requests specific service offered task named application represents business layer system application entry requires services two different entries database task offers total three kinds services every software task running processor node drawn circle example clients class share processor whereas application database share another processor database uses also two disk devices shown fig3 worth mentioning application database proc2 proc1 proc3 figure 3 simple lqn model word layered name lqn imply strict layering tasks example task may call tasks layer skip layers three types lqn messages synchronous asynchronous forwarding whose effect illustrated fig4 synchronous message represents request service sent client server client remains blocked receives reply provider service see fig4a server busy request arrives request queued waits phase1 service client server synchronous message busy reply included services phase2 phase3 autonomous phases idle client server lqn synchronous message client server busy included services phase1 phase2 phase3 idle asynchronous message client server asynchronous message forwarding client synchronous message reply original client busy phase1 phase2 idle client c lqn forwarding message busy idle phase1 phase2 idle figure 4 different types lqn messages turn accepting message server starts serve executing sequence phases one end phase 1 server replies client unblocked continues work server continues following phases working parallel client completion last phase fig4a case three phases shown finishing last phase server begins serve new request queue becomes idle queue empty phase server may act client servers asking receiving socalled included services case asynchronous message client block sending message server reply back executes phases shown fig4b third type lqn message named forwarding message represented dotted request arc associated synchronous request served chain servers illustrated fig 4c client sends synchronous request begins process request forwards server2 end phase1 proceeds normally remaining phases parallel server2 goes another cycle client however remains blocked forwarded request served replies client end phase 1 forwarding chain contain number servers case client waits receives reply last server chain parameters lqn model follows customer client classes associated populations arrival rates software task entry average execution time per phase software task entry seen client device ie request arc task entry device average service time device average number visits per phase requesting entry software task entry seen client another task entry ie request arc task entry another task entry average number visits per phase requesting entry request arc average message delay software hardware server scheduling discipline typical results lqn model response times throughput utilization servers behalf different types requests queueing delays lqn results may used identify software andor hardware bottlenecks limit system performance different workloads configurations understanding cause performance limitations helps development team come appropriate remedies 4 transformation architecture performance models software system contains many components involved various architectural connection instances described patterncollaboration component may play different roles connections various types transformation architecture performance model done systematic way pattern pattern expected performance system depends performance attributes components interactions described patternscollaborations performance attributes central software architecture must supplied user additional information describe demands hardware resources software components allocation processes processors execution time demands software component behalf different types system requests demands resources io devices communication networks etc specify clearly kind performance attributes must provided patterncollaboration tranformations architecture performance modelling domain discussed next lqn model pipeline filters fig 5 6 show transformation lqn submodels two pipeline filters collaborations described fig1 2 respectively translation takes account one side structural behavioural information provided uml collaboration side allocation software components filter1 filter2 filter1 upstreamfilter filter2 downstreamfilter upstreamfilter downstreamfilter figure 5 transformation pipeline message lqn submodel filter1 filter2 semaphore buffer read proc filters running processor node filter1 filter2 semaphore proc1 proc2 read b filters running different processor nodes read sequential buffer filter1 1n filter2 1n buffer upstreamfilter downstreamfilter buffer upstreamfilter downstreamfilter buffer figure 6 transformation pipeline buffer lqn submodel processors lead different lqn submodels pattern see fig6 tansformation rules follows active filter fig5 6 becomes lqn software server single entry whose service time includes processing time filter filter tasks receive asynchronous message described fig 4b execute phases response typical distribution work phases receive message phase 1 process phase 2 send next filter phase 3 b allocation lqn tasks processors mimics real system way filters allocated different processor nodes make difference pipeline message reason processors represented fig5 affects model pipeline buffer explained c case pipeline message aspects related pipeline connector two filters completely modelled lqn asynchronous message cpu times send receive system calls added execution times phases respective operations take place want model network delay message represented delay attached request arc case pipeline buffer fig6 asynchronous lqn arc necessary sufficient model aspects concerning pipeline connector additional lqn elements required take account serialization delay introduced constraint buffer operations must mutually exclusive third task plays role semaphore enforce constraint due fact task serializes execution entries task many entries number critical sections executed filters accessing buffer two case write read since execution buffer operation takes place thread control filter initiating operation allocation filters processors matters filters running processor node may one processor fig6a read write operations executed processor node thus modelled entries semaphore task obviously coallocated filters however filters running different processor nodes fig6b mutualexclusive operations read write executed different processor nodes cannot modelled entries task lqn entries task executed processor node solution shown fig6b keep semaphore task enforcing mutual exclusion entries used delegate work two new tasks one responsible buffer operation new task allocated processor filter initiating respective operation lqn models pipeline filters collaborations fig 5 6 generated forwarding message fig4c instead asynchronous one fig4b source requests first filter multifilter architecture closed instead open closed source composed set client tasks sending synchronous requests first filter waiting reply last filter since lqn task may send forwarding message exactly end phase1 work done filter task must take place first phase clientserver pattern frequently used todays distributed systems fig7 illustrated case client communicates directly server synchronous requests described fig4a server may offer wide range services represented architectural view servers class methods one performance attributes performance modelling point view important identify theses services also find invoking frequently uml class diagram contains single association client server matter many server methods client may invoke therefore indicate addition line represents clientserver association messages sent client server used mostly collaboration diagrams indicate services client invoke one time another ways clientserver connections may realized described paper apply case study wellknown example use midware technology corba interconnects clients servers running heterogeneous platforms across local widearea networks corba connections introduce interesting performance implications modelling issues 9 lqn originally created model clientserver systems transformation clientserver pattern lqn quite straightforward lqn server may offer range services object methods architectural view cpu time number visits servers performance attributes must provided service modelled entry server task shown figure 7 contribute differently clientclientserver service1 service2 server client2 1n client1 1n client client server client server client server figure 7 transformation clientserver pattern lqn submodel response time utilization throughput server client may invoke one services different times performance attributes clients include average time demands average number calls entry server pipeline connection case cpu time required execute system call sendreceivereply added service times corresponding entries allocation tasks processors shown fig 7 transformation depend lqn task allocated exactly architectural component counterpart critical section collaboration lowerlevel abstraction previous architectural patterns frequently used describes case two active objects share passive object constraint sequential attached methods shared object indicates callers must coordinate outside shared object example means semaphore insure correct behaviour synchronization introduces performance delays must represented lqn model simplicity reasons fig8 illustrates case user invokes method shared object extended easily allow user call subset methods transformation critical section collaboration produces either model given fig 8a fig 8b depending allocation user processes processor nodes similar pipeline buffer case premise shared object operations mutually exclusive lqn task cannot change processor node entries task executed tasks processor node case users running processor node shared object operations modelled entries task plays role semaphore see fig8a running processor node users generalization allowing user call subset operations entries straightforward user connected request arcs every entry subset users running different processor nodes fig 8b shared object operations ie critical sections executed different threads controls corresponding different users running different processors therefore operation modelled entry new task responsible operation running users node user call shared operations new associated task entry every operation means operation called one user represented one entry however new tasks must prevented running simultaneously shared usern user1 accessor accessor shared critical section accessor shared user1 usern proc semaphore critical sections f1 f2 fn user1 usern semaphore proc1 procn users running processor node b users running different processor nodes figure 8 transformation critical section collaboration lqn submodel semaphore task one entry user used enforce mutual exclusion entry semaphore task delegates work entries modelling required operations performance attributes provided user must specify average execution times user outside inside critical section separately coallocation collaboration fig 9 shows socalled coallocation collaboration two active objects contained third active object constrained execute one time container object may implemented process example architectural connection casestudy system necessarily architectural pattern quite frequently used obvious solution model two contained objects entries task presents disadvantage cannot represent case two contained objects request queue lqn task unique message queue requests entries waiting together one reason may need separate queues avoid cyclic graphs could accepted lqn solver used paper solution presented fig9 represents contained active object separate dummy task delegates work entry container task serializes entries dummy tasks allocated dummy processor interfere scheduling real processor node dummyactive1 dummyactive2 container active1 active2 dummy proc proc activecontainer active1 active2 contained coallocation container contained contained container figure 9 lqn submodel coallocation collaboration 5 lqn model telecommunication system conducted performance modelling analysis existing telecommunication system responsible developing provisioning maintaining various intelligent network services well accepting processing realtime requests services according software performance engineering methodology 14 first identified critical scenarios stringent performance constraints correspond case realtime processing service requests next identified software components involved architectural patterns exercised execution chosen scenarios see fig10 client server client server buffer upstrmfilter downstrmfilter buffer upstrmfilter downstrmfilter coallocation container contained requesthandler 1n io ioin ioout stack stackin stackout doublebuffer inbuffer outbuffer coallocation container contained buffer upstrmfilter downstrmfilter buffer upstrmfilter downstrmfilter critical section accessor shared critical section accessor shared database figure 10 uml model telecommunication system real time scenario modelled starts moment request arrives system ends service completely processed reply sent back shown fig 10 request passed several filters pipeline stack process io process requesthandler way back main processing done requesthandler seen fig12 table 1 accesses realtime database fetch execution script desired service executes steps script accordingly script may vary size types operations involved hence workload varies largely one type service another one two orders magnitude based experience intuition designers decided beginning allow multiple replications requesthandler process order speed system two shared objects shmem1 shmem2 used multiple requesthandler replications system intended run either singleprocessor multiprocessor shared memory processor scheduling process run free processor ie processors dedicated specific tasks therefore processor node modelled multiserver dummy proc read ioin request handler ioout database proc ioexec stackin stackout buffer shmem1 l update figure 11 lqn base case model telecommunication system applying systematically transformation rules described previous section architectural patternscollaborations used system shown fig 10 lqn model shown fig11 obtained next step determine lqn model parameters average service time entry average number visits request arc validate model made use measurements using quantify 19 unix utility top measurements quantify obtained low arrival rates around couple requestssecond quantify profiling tool uses data compiler runtime information determine user kernel execution times test cases chosen user since wanted measure average execution times different software components behalf system request see table 1 appendix measured execution 2000 requests repeated loop computed average per request although computed confidence intervals measurements repeated experiments close agreement top utility provided us utilization figures high loads hundreds requestssecond close actual execution time demands per system request stackin stackout ioin ioout requesthandler database execution time msec noncritical section critical sectbuffer critical sectshmem1 critical sectshmem2 total figure 12 distribution total demand cpu time per request different software components operating point measurements done prototype lab two different hardware configurations one four processors repeated measurements close agreement used execution times measured quantify given table 1 appendix determine model parameters utilization results top validate model utilization values obtained solving model within 5 measured values unfortunately rigorous validation hindered lack response time measurements 6 performance analysis telecommunication system although lqn toolset 4 offers analytical simulation solvers model results used section obtained simulation reason one system features namely scheduling policy polling used requesthandler multiserver could handled analytical solver simulation results obtained confidence interval plusminus1 95 level maximum throughput vs replication factor requesthandler rh2006001000n1 processor n4 processors n6 processors configurations throughput figure 13 maximum achievable throughput different hardware software configurations single class service requests first question interest developers find best hardware software configuration achieve desired throughput given mix services configuration understand specifically number processors multiprocessor system number requesthandler software replications tried answer question exploring range configurations given service mix determining highest achievable throughput fig 13 configurations maximum throughput lower required values discarded cheapest configuration insure satisfactory throughput response time operating point saturation chosen solving lqn model efficient way explore different configurations wide range workloads measure real system cases although modelled system two classes services selected report results single class illustrate clearly bottleneck moves around hardware software different configurations model analyzed three hardware configurations one four six processors respectively chose one four processors since actual system run configurations six processors see software architecture scales running system single processor see fig 14 replication requesthandler increase maximum achievable throughput due fact processor system bottleneck known 8 replication software processes brings performance rewards unused processing capacity case software server said utilized effective work waiting served lower level servers including queueing included services fig 17 show different contributions utilization two tasks ioout rh system saturated ie works highest achievable throughput given fig 13 different numbers rh replications easy see five rh copies one task ie ioout high utilization even though little useful work whereas time another task ie rh copy lower utilization useful work interestingly enough case 4 processor configuration notice processing capacity system processors reach maximum utilization level shown fig15 instead two software tasks ioout ioin actually responsible little useful work behalf system reach critical levels utilization due serialization constraints software 4processor configuration base case02061 number requesthandler replications utilization ioout processor ioexec database requesthandler figure 15 task utilizations 4proc base case 6processor configuration base case02061 number requesthandler replications utilization ioout ioexec processor database requesthandler figure 16 task utilizations 6proc base case 1processor configuration base case02061 number requesthandlers utilization requesthandler processor ioexec database figure 14 task utilizations 1proc base case architecture two reasons serialization ioin ioout executed single thread control lqn means waiting task ioexec ii contend buffer thus increasing processing power system bottleneck moving hardware software trend visible case 6 processors configuration processor utilization reaches 866 shown fig16 bottleneck definitely shifted hardware software limitations performance due constraints software architecture tried eliminate serialization constraints two steps first making filter process ie removing stackexec ioexec tasks lqn model splitting pipeline buffer sitting io process requesthandler two buffers lqn model obtained 2step modifications shown fig 19 results half way modified system first step given fig 20 show major performance improvement processor still used capacity examining utilization components ioin ioout still bottleneck found 4proc base case contributions ioout utilization020613 4 5 6 7 number requesthandler replications utilization ioout waiting ioexec ioexec waiting semaphore processor useful work read buffer figure 17 contributions ioout utilization system saturated function rh replication level contributions requesthandler utilization020613 4 5 6 7 number requesthandler reprlications utilization useful work requesthandler useful work others behalf requesthandler requesthandler busy waiting nested services figure 18 contributions utilization rh copy system saturated function rh replication level wait time gain access buffer ioout waiting 90 time ioin 80 applying modification steps though software bottleneck due excessive serialization pipeline removed processor utilization went shown fig 21 4processor fig 22 6processor configuration expected maximum achievable throughput increased well throughput increase rather small case 4 processors 27 larger case 6 processors 103 unused processing power also realized case 6 processors new software bottleneck emerged namely database process 100 utilized new bottleneck caused lowlevel server propagated upwards saturating software processes using requesthandler replications final conclusion performance analysis different configurations different bottlenecks solving bottleneck one configuration shift problem somewhere else performance modelling offer ability explore range design alternatives configurations workload mixes detect causes performance limitations analyzing model proceeding change real system ioin request handler ioout database proc stackin stackout l bufferin shmem1 read write bufferout update figure 19 lqn model modified system 7 conclusions paper contributes toward bridging gap software architecture performance analysis proposes systematic approach building performance models highlevel software architecture system transforming architectural pattern employed system performance submodel ongoing work formalize kind transformations presented paper architecture performance domain using formal graph transformations based paper illustrates proposed approach building lqn models applying existing telecommunication system performance analysis exposes weaknesses original 4processors configuration halfway modified system020612 4 number requesthandler replications utilization ioout ioin processor database requesthandler stackout stackin figure 20 task utilizations 4proc halfway modified system 4processor configuration fully modified system020612 4 number rh replications utilization processor database requesthandler ioout ioin stackin stackout figure 21 task utilizations 4proc fully modified system 6processor configuration fully modified system02061 number requesthandler replications utilization requesthand ler processor database ioout stackout io stackin figure 22 task utilization 6proc fully modified architecture due excessive serialization show processing power added system surprisingly software components relatively little work behalf system request become bottleneck certain cases whereas components work removing serialization constraints new software bottleneck emerges leads conclusion software architecture scale well case study illustrates usefulness applying performance modelling analysis software architectures r formal basis architectural connection unified modeling language user guide system patterns toolset performance engineering software design clientserver systems performance analysis distributed server systems performance multilevel clientserver systems parallel service operations measuremnt tool modelling techniques evaluating web server performance software bottlenecking clientserver systems rendezvous networks deriving software performance models architectural patterns graph transformations multilayer clientserver queueing network model synchronous asynchronous messages method layers perspectives emerging discipline patterns software architecture performance engineering software systems architecturebased performance analysis performance evaluation throughput calculation basic stochastic rendezvous networks stochastic rendezvous network model performance synchronous clientserverlike distributed software tr ctr performance model bpi middleware proceedings 4th acm conference electronic commerce june 0912 2003 san diego ca usa software performance engineering web servicebased clinical decision support infrastructure acm sigsoft software engineering notes v29 n1 january 2004 gordon p gu dorina c petriu xslt transformation uml models lqn performance models proceedings 3rd international workshop software performance july 2426 2002 rome italy edward billard operating system scenarios use case maps acm sigsoft software engineering notes v29 n1 january 2004 christoph lindemann axel thmmler alexander klemm marco lohmann oliver p waldhorst performance analysis timeenhanced uml diagrams based stochastic processes proceedings 3rd international workshop software performance july 2426 2002 rome italy giovanni denaro andrea polini wolfgang emmerich early performance testing distributed software applications acm sigsoft software engineering notes v29 n1 january 2004 vincenzo grassi raffaela mirandola derivation markov models effectiveness analysis adaptable software architectures mobile computing ieee transactions mobile computing v2 n2 p114131 january vincenzo grassi raffaela mirandola primamobuml methodology performance analysis mobile software architectures proceedings 3rd international workshop software performance july 2426 2002 rome italy vittorio cortellessa katerina gosevapopstojanova kalaivani appukkutty ajith r guedem ahmed hassan rania elnaggar walid abdelmoez hany h ammar modelbased performance risk analysis ieee transactions software engineering v31 n1 p320 january 2005 johan moe david carr using execution trace data improve distribute systems softwarepractice experience v32 n9 p889906 july 2002 vibhu saujanya sharma kishor trivedi quantifying software performance reliability security architecturebased approach journal systems software v80 n4 p493509 april 2007 dorin bogdan petriu murray woodside software performance models system scenarios performance evaluation v61 n1 p6589 june 2005 vittorio cortellessa raffaela mirandola primauml performance validation incremental methodology early uml diagrams science computer programming v44 n1 p101129 july 2002