large fast instruction window tolerating cache misses instruction window size important design parameter many modern processors large instruction windows offer potential advantage exposing large amounts instruction level parallelism unfortunately naively scaling conventional window designs significantly degrade clock cycle time undermining benefits increased parallelismthis paper presents new instruction window design targeted achieving latency tolerance large windows clock cycle time small windows key observation instructions dependent long latency operation eg cache miss cannot execute source operation completes instructions moved conventional small issue queue much larger waiting instruction buffer wib long latency operation completes instructions reinserted issue queue paper focus specifically load cache misses dependent instructions simulations reveal 8way processor 2kentry wib 32entry issue queue achieve speedups 20 84 50 conventional 32entry issue queue subset spec cint2000 spec cfp2000 olden benchmarks respectively b introduction many todays microprocessors achieve high performance combining high clock rates ability dynamically process multiple instructions per cycle unfortu nately two important components performance often odds one another example small hardware structures usually required achieve short clock cycle times larger structures often necessary identify exploit instruction level parallelism ilp particularly important structure issue window examined cycle choose ready instructions execution larger window often expose larger number independent instructions execute outof order unfortunately size issue window limited due strict cycle time constraints conflict cycle time dynamically exploiting parallelism exacerbated long latency operations data cache misses even crosschip communication 1 22 challenge develop microarchitectures permit short cycle times large instruction windows paper introduces new microarchitecture reconciles competing goals short cycle times large instruction windows observe instructions dependent long latency operations cannot execute long latency operation completes allows us separate instructions execute near future execute distant future key design entire chain instructions dependent long latency operation removed issue window placed waiting instruction buffer wib reinserted long latency operation completes fur thermore since instructions dependence chain candidates reinsertion issue window need implement select logic rather full wakeup select required conventional issue window tracking true dependencies done wakeup logic handled issue window instructions reinserted paper focus tolerating data cache misses however believe technique could extended operations latency difficult determine compile time specifically goal explore design microarchitecture large enough effective window tolerate dram accesses leverage existing techniques provide large register file 13 34 assume large active list 1 possible since critical path 4 techniques exist keeping active list 1 active list refer hardware unit maintains state inflight instructions often called reorder buffer large using relatively small hardware structures 31 explore several aspects wib design including detecting instructions dependent long latency operations inserting instructions wib banked vs nonbanked organization policies selecting among eligible instructions reinsert issue window total capacity 8way processor compare committed instructions per cycle ipc wibbased design 32entry issue window 2048entry banked wib twolevel register files 128 l12048 l2 conventional 32entry issue window singlelevel register files 128 registers simulations show wib speedups conventional design 20 spec cint2000 84 spec cfp2000 50 olden speedups significant fraction achieved 2048entry conventional issue window 35 140 103 even ignoring clock cycle time effects remainder paper organized follows section provides background motivation work design presented section 3 evalute performance section 4 section 5 discusses related work section 6 summarizes work presents future directions background motivation 21 background superscalar processors maximize serial program performance issuing multiple instructions per cycle one important aspects systems identifying independent instructions execute parallel identify exploit instruction level parallelism ilp todays processors employ dynamic scheduling branch prediction speculative execution dynamic scheduling hardware technique identifying issuing multiple independent instructions single cycle 32 hardware looks ahead fetching instructions buffercalled windowfrom selects instructions issue functional units instructions issued operands available independent instructions execute outoforder results instructions executed outoforder committed architectural state program order words although instructions within window execute outoforder window entries managed fifo instructions enter depart program order simplified design assumes instructions window examined selected execution note possible separate fifo management active list reorder buffer independent instruction identification issue queue described gardless conflict increasing window issue queue size expose ilp keeping clock cycle time low using small structures 1 22 histor ically smaller windows dominated designs resulting higher clock rates unfortunately small window quickly fill long latency operation particular consider long latency cache miss serviced main memory latency large time load reaches head window data still arrived memory unfortunately significantly degrades performance since window contain executing instructions instructions loads dependence chain stalled instructions independent load finished waiting commit program order way make progress bring new instructions window accomplished using larger window 22 limit study remainder section evaluates effect window size program performance ignoring clock cycle time effects goal determine potential performance improvement could achieved large instruction windows begin description processor model followed short discussion performance various instruction window sizes 221 methodology study use modified version simplescalar version 30b 8 spec cpu2000 17 olden 11 benchmark suites spec cpu2000 benchmarks precompiled binaries obtained simplescalar developers 33 generated compiler flags suggested wwwspecorg olden binaries generated alpha compiler cc using optimization flag o2 spec benchmarks operate reference data sets subset olden benchmarks use inputs em3d 20000 nodes arity 10 mst 1024 nodes perimeter 4kx4k image treeadd levels omit several benchmarks either data cache miss ratios 1 ipcs unreasonably low health ammp less base configuration processor design loosely based alpha 21264 microarchitecture 12 14 19 use seven stage pipeline including speculative load execution loadstore wait prediction model clustered design 21264 instead assume single integer issue queue issue 8 instructions per cycle single floating point issue queue issue 4 instructions per cycle table 1 lists various parameters base machine note integer floating active list 128 128 int regs 128 fp regs loadstore queue 64 load 64 store issue queue floating point issue width 12 floating point decode width 8 commit width 8 instruction fetch queue 8 functional units 8 integer alus 1cycle multipliers 7cycle 4 fp adders 4cycle multipliers 4cycle dividers nonpipelined 12 nonpipelined 24cycle branch prediction bimodal twolevel adaptive combined speculative date 2cycle penalty direct jumps missed btb 9cycle others storewait table 2048 entries bits cleared every cycles l1 data cache inst cache unified cache 256 kb 4 way memory latency 250 cycles tlb 128entry 4way associative 4 kb page size 30cycle penalty table 1 base configuration point register files large active list remainder paper state single value active listregister file size value applies integer floating point register files simulator modified support speculative update branch history historybased fixup return addressstack repair pointeranddata fixup mechanism 26 27 also modified simulator warm instruction data caches initial fast forward phase spec benchmarks skip first four hundred million instructions execute next one hundred million instructions detailed performance sim ulator olden benchmarks execute 400m instructions completion approach used throughout paper note results qualitatively similar using different instruction execution window 24 222 varying window size performed simulations varying issue queue size base powers 2 4096 issue queue sizes 32 64 128 keep active list fixed 128 entries remaining configurations active list register files issue queue equal size load store queues always set one half active list size limit number outstanding requests unless otherwise stated figure 1 shows committed instructions per cycle ipc various window sizes normalized base 32entry configuration new ipc old spec integer floating point olden benchmarks absolute ipc values base machine provided section 4 goal examine relative effects larger instruction windows simulations show initial boost ipc window size increases 2k three sets benchmarks exception mst effect plateaus beyond 2k entries ipc increasing slightly matches intuition since 250 cycle memory latency 2000 instructions fetched 8way proces sor larger instruction windows beyond 2k provide minimal benefits many floating point benchmarks achieve speedups 2 art achieving speedup 5 2k window speedup larger window unroll loops many times allowing overlap many cache misses similar phenomenon occurs mst results motivate desire create large instruction windows challenge architects accomplish without significant impact clock cycle time next section presents proposed solution 3 large window design section presents technique providing large instruction window maintaining advantages small structures critical path begin overview convey intuition behind design followed detailed description particular de sign conclude section discussion various design issues alternative implementations 31 overview base microarchitecture instructions issue queue examined potential execution active list larger number entries issue queue 128 vs 32 allowing completed yet committed instructions release issue queue entries since active list critical path 4 assume increase size without affecting clock cycle time nonetheless face long latency operations issue queue could fill instructions waiting operands stall execution make observation instructions dependent long latency operations cannot execute long latency operation completes thus need exam020060100140180bzip2 gcc gzip parser perlbmk vortex vpr average spec 2000 integer100300500applu art facerec galgel mgrid swim wupwise average b spec 2000 floating point050150250350450em3d mst perimeter treeadd average c olden figure 1 large window performance ined wakeupselect logic critical path note observation exploited palacharla et al 22 technique examining head issue queues however goal design remove waiting instructions issue queue place waiting instruction buffer wib long latency operation completes instructions moved back issue queue execution design instructions remain issue queue short time either execute properly removed due dependence long latency operation paper focus specifically instructions dependence chain load cache misses however believe technique could extended types long latency operations figure 2 shows pipeline wibbased microarchitecture based 21264 twolevel register files described later fetch stage includes icache branch prediction instruction fetch queue slot stage directs instructions integer floating point pipeline based type instructions go register rename entering issue queue instructions selected issue queue either proceed register read execution memorywriteback stages move wib register read stage wib instructions wait specific cache miss depend complete occurs instructions reinserted issue queue repeat wakeupselect process possibly moving back wib dependent another cache miss remainder section provides details wib operation organization 32 detecting dependent instructions important component design ability identify instructions dependence chain load cache miss achieve leverage existing issue queue wakeupselect logic normal execution wakeupselect logic determines instruction ready execution ie operands available selects subset ready instructions according issue constraints eg structural hazards age instructions leverage logic add additional signal called wait bitthat indicates particular source operand ie input register value pretend ready signal similar ready bit used synchronize true dependencies differs used indicate particular source operand available extended period time instruction considered pretend ready one operands pretend ready operands truly ready pretend ready instructions participate normal issue request truly ready issued instead sent functional unit pretend ready instruction placed wib issue queue entry subsequently freed issue logic though actually executed note potential optimization scheme would consider instruction pretend ready soon one operands pretend ready would allow instructions moved wib earlier thus reducing pressure issue queue resources implementation wait bit physical register initially set load cache miss dependent instructions observe wait bit removed issue queue set wait bit destination registers causes dependent instructions removed issue queue set corresponding wait bits result queue issue point queue issue integer exec integer exec 32kb 4way cache data slot memory reg file reg file integer register rename instruction waiting instruction buffer fetch rename issue register read execute floating cache 32kb 4way floating rename register point reg file reg file figure 2 wibbased microarchitecture registers therefore instructions directly indirectly dependent load identified removed issue queue load miss signal already generated alpha 21264 since load instructions speculatively assumed hit cache allowing load dependent instructions execute consecutive cycles case cache miss alpha dependent instructions retained issue queue load completes case instructions move wib instruction might enter issue queue instructions producing operands exited issue queue producer instructions could either executed properly source operand available could wib instruction eventually moved wib therefore wait bits must available wherever conventional ready bits available case register rename note may possible steer instructions wib rename stage issue stage plan investigate future work current design implement instead instruction enters issue queue moved wib necessary 33 waiting instruction buffer wib contains instructions directly indirectly dependent load cache miss wib must designed satisfy several important criteria first must contain differentiate dependent instructions individual outstanding loads second must allow individual instructions dependent multiple outstanding loads finally must permit fast squashing branch mispredict exception occurs satisfy requirements designed wib operate conjunction active list every instruction active list allocated entry wib although may allocate entries wib never dependent load miss simplifies squashing mispre dicts whenever active list entries added removed corresponding operations performed wib means wib entries allocated program order link wib entries load misses use bitvector indicate wib locations dependent specific load instruction moved wib appropriate bit set bitvectors arranged two dimensional array column bitvector load cache miss bitvectors allocated load miss detected therefore outstanding load miss store pointer corresponding bitvector note number bitvectors bounded number outstanding load misses however possible fewer bitvectors outstanding misses link instructions specific load augment operand wait bits index bitvector table corresponding load cache miss instruction dependent case instruction dependent multiple outstanding loads use simple fixed ordering policy examine source operand wait bits store instruction wib first outstanding load encountered requires propagating bitvector index wait bits described possible store bitvector index physical register since space available however requires instructions moved wib consume register ports reduce register pressure assume bitvector index stored separate structure wait bits instructions wib reinserted issue queue corresponding load miss resolved reinsertion shares bandwidth case 8 instructions per cycle newly arrived instructions decoded dispatched issue queue dispatch logic modified give priority instructions reinserted wib ensure forward progress note instructions reinserted issue queue completion one load may dependent another outstanding load issue queue logic detects one instructions remaining operands unavail able due load miss way detected first load dependence instruction sets appropriate bit new loads bitvector removed issue queue fundamental difference wib simply scaling issue queue larger en tries larger queue issues instructions operands available contrast technique could move instruction issue queue wib many times worst case active instructions dependent single outstanding load requires bitvector cover entire active list number entries wib determined size active list analysis section 2 indicates 2048 entries good window size achieve significant speedups therefore initially assume 2kentry active list 1kentry load store queues assuming wib entry 8 bytes total wib capacity 16kb bitvectors also consume great deal storage limited number outstanding requests supported section 4 explores impact limiting number bitvectors load queue size 331 wib organization assume banked wib organization one instruction extracted bank every two cy cles two cycles include determining appropriate instruction reading appropriate wib entry fixed instruction width wib issue queue set number banks equal twice width therefore sustain reinsertion full bandwidth reading instructions wibs even banks one cycle odd banks next cycle enough instructions eligible set banks recall wib entries allocated program order conjunction active list entries perform allocation using roundrobin across banks interleaving individual instruction granularity therefore entries bank also allocated released program der partition loads bitvector according bank bits map case 2k entry wib dispatch width issue queue 8 would banks 128 entries bank also stores local head tail pointers reflect program order instructions within bank figure 3 shows internal organization wib read access bank set even odd operates independently select instruction reinsert issue queue examining appropriate 128 bits completed load bank create single bitvector logical bitvectors completed loads resulting bitvector examined select oldest active instruction program order many possible policies selecting instructions examine simple policies later paper leave investigation sophisticated policies eg data flow graph order critical path 15 future work regardless selection policy result one bit 128 set directly enable output corresponding wib entry without need encode decode wib index process repeated updated bitvector clears wib entry access completed may include new eligible instructions another load miss completed access policies similar select policies implemented issue queue logic highlights important difference wib conventional issue queue conventional issue queue requires wakeup logic broadcasts register specifier entry wib eliminates broadcast using completed loads bitvectors establish candidate instructions selection issue queue requires register specifier broadcast maintain true dependencies contrast wibbased architecture leverages much smaller issue queue task wib select instructions reinsertion order possible enough issue queue entries available consume instructions extracted wib case one banks stall access wait next access two cycles later attempt reinserting instruction avoid potential livelock access change starting bank allocating available issue queue slots furthermore bank remains highest priority instruction reinsert able bank assigned lowest priority inserts instruction instruction rein sert livelock could occur fixed priority scheme since instructions highest priority bank could dependent instructions lower priority bank could produce continuous stream instructions moving wib issue queue back wib since producing instructions yet complete producing instructions never complete since lower priority bank although scenario seems unlikely occur benchmarks thus use bit vectors wib bank issue queue priority even banks head tail bit vectors wib bank issue queue queue priority odd banks head tail figure 3 wib organization roundrobin priority 332 squashing wib entries squashing instructions requires clearing appropriate bits bitvector reseting banks local tail pointer twodimensional bitvector organization simplifies bitvector clear operation since applied bits every bitvector recall column corresponds outstanding load miss thus clear bits rows associated squashed instructions 34 register file considerations support many inflight instructions number rename registers must scale proportionally several alternative designs large register files including multicycle access multilevel 13 34 multiple banks 5 13 queuebased designs 6 paper use twolevel register file 13 34 operates principles similar cache hierarchy simulations multibanked register file show similar results details register file designs performance available elsewhere 20 alternative wib designs wib organization one several alterna tives one alternative considered large nonbanked multicycle wib although may possible pipeline wib access would produce fully pipelined access simulations see section 4 indicate pipelining may necessary another alternative considered poolofblocks structure implementing wib organziation load misses cache obtains free block buffer dependent instructions pointer block stored load load queue lq used deposit dependent instructions wib load completes instructions block reinserted issue queue block contains fixed number instruction slots slot holds information equivalent issue queue entries important difference approach compared technique use instructions stored dependence chain order blocks may need linked together handle loads long dependence chains complicates squashing since program order associated wib entries although could maintain information program order list management loads dependence chain becomes complex time consuming squash although bitvector approach requires space simplifies management poolofblocks approach potential deadlock enough wib entries continuing investigate techniques reduce list management overhead handle deadlock 36 summary wib architecture effectively enlarges instruction window removing instructions dependent load cache misses issue queue retaining wib misses serviced achieving leverage existing processor issue logic without affecting processor cycle time circuit complexity wib archi tecture instructions stay issue queue short period time therefore new instructions brought instruction window much rapidly conventional architectures fundamental difference wib design design simply scales issue queue scaling issue queue significantly complicates wakeup logic turn affects processor cycle time 1 22 however wib requires simple form wakeup logic instructions dependence chain load miss awakened miss resolved need broadcast instructions monitor result buses evaluation section evaluate wib architecture begin presenting overall performance wib design compared conventional architecture next explore impact various design choices wib per formance includes limiting number available bitvectors limited wib capacity policies selecting instructions reinsertion issue queue multicycle nonbanked wib simulations reveal wibbased architectures increase performance terms ipc set benchmarks average 20 84 50 spec int spec fp olden respectively also find limiting number outstanding loads 64 produces similar improvements spec int olden bench marks reduces average improvement spec fp 45 wib capacity low 256 entries maximum 64 outstanding loads still produces average speedups 9 26 14 respective benchmark sets 41 overall performance begin presenting overall performance improvement ipc relative processor 32entry issue queue single cycle access 128 registers hence 128entry active list 32iq128 figure 4 shows speedups ipc new ipc old various microarchitec tures although present results 8issue processor overall results qualitatively similar 4issue pro cessor wib bar corresponds 32entry issue queue banked wib organization 2kentry active list 2k registers using twolevel register file 128 registers first level 4 read ports 4 write ports pipelined second level 4cycle latency assuming 32entry issue queue 128 level one registers set clock cycle time wibbased design approximately clock cycle equivalent base architecture experiments number outstanding loads thus bitvectors limited explore parameter table 2 shows absolute ipc values base configuration banked wib design along branch direction prediction rates l1 data cache miss rates l2 unified cache local miss rates base configuration comparison also include two scaled versions conventional microarchitecture configurations use 2kentry active list single cycle access 2k regis ters one retains 32entry issue queue 32iq2k benchmark base branch dl1 ul2 local wib ipc dir miss miss ipc pred ratio ratio gzip 225 091 002 004 225 parser 083 095 004 022 095 perlbmk vortex applu 417 098 010 026 428 art 042 096 035 073 164 galgel 192 098 007 026 397 mgrid 258 097 006 042 257 wupwise 338 100 003 025 399 em3d 228 099 002 016 227 mst 096 100 007 049 251 perimeter 100 093 004 038 116 treeadd 105 095 003 033 128 table 2 benchmark performance statistics scales issue queue 2k entries 2kiq2k configurations help isolate issue queue active list provide approximate upper bound expected performance results shown figure 4 make following observations first wib design produces speedups 10 12 benchmarks average speedup 20 84 50 spec int spec fp olden respectively harmonic mean ipcs shown table 2 increases 10 124 spec int 142 302 spec fp 117 161 olden programs large speedups large issue queue wib design able capture significant fraction available speedup however programs 2k issue queue produces large speedups wib mgrid striking example wib produce speedup 2k issue queue yields speedup two phenomenon result wib recycling instructions issue queue consumes issue bandwidth 2k issue queue uses instructions ready execute evidence track number times instruction inserted wib banked implementation average number times instruction inserted bzip2 gcc gzip parser perlbmk vortex vpr average spec 2000 integer 522 39100140180220260 applu art facerec galgel mgrid swim wupwise average b spec 2000 floating point 438 261100140180220 em3d mst perimeter treeadd average c olden figure 4 wib performance wib four maximum 280 investigations insertion policies see reduces values average insertion count one maximum 9 producing speedup 17 also note several benchmarks increasing active list produces noticable speedups cases even outperforming wib indicates issue queue bottleneck benchmarks however overall wib significantly outperforms increased active list due size wib larger register file also evaluated alternative use space doubling data cache size base configuration 64kb simulation results reveal less 2 improvements performance benchmarks except vortex shows 9 improvement 32kb data cache indicating020060100140180integer fp olden figure 5 performance limited bitvectors wib may better use space explore tradeoff later section also performed two sensitivity studies reducing memory latency 250 cycles 100 cycles increasing unified l2 cache 1mb results match expectations shorter memory latency reduces wib speedups averages 5 30 17 spec int spec fp olden benchmarks respec tively larger l2 cache smaller impact speedups achieved wib average speedups 5 61 38 spec int spec fp olden benchmarks respectively larger cache impact integer benchmarks show dramatically reduced local l2 miss ratio average 22 6 caches exploit locality programs reference stream sometimes sufficiently large capture programs entire working set contrast wib expose parallelism tolerating latency programs large working sets lack locality remainder paper present average results benchmark suite detailed results benchmark available elsewhere 20 42 limited bitvectors number bitvectors important since bitvector must map entire wib area required become excessive explore effect limited bitvectors outstanding loads simulated 2kentry wib 16 32 64 bitvectors figure 5 shows average speedups base machine including 1024 bitvector configuration results show even 16 bitvectors wib achieve average speedups 16 spec int 26 spec fp 38 olden benchmarks spec fp programs particularly art affected limited bitvectors since benefit memory level parallelism bitvectors 16kb wib achieve speedups 19 45 50 three sets benchmarks respectively integer fp olden figure 6 wib capacity effects 43 limited wib capacity reducing wib area limiting number bitvectors certainly useful optimization however decreases required area achieved using smaller capacity wib section explores performance impact reducing capacity wib active list register file figure 6 shows average speedups wib sizes ranging 128 2048 bitvectors limited 64 results show 1024entry wib achieve average speedups 20 spec int 44 spec fp 44 olden configuration requires 32kb extra space 8kb wib entries 8kb bitvectors 8kb 1024entry register file roughly area equivalent doubling cache size 64kb stated 64kb l1 data cache produce noticable speedups benchmarks wib better use area 44 wib issue queue instruction selection wib design implements specific policy selecting eligible instructions reinsert issue queue current policy chooses instructions bank program order since banks operate independently alternate cycles extract instructions true program order evaluate impact instruction selection policy use idealized wib single cycle access time entire structure within design evaluate following instruction selection poli cies 1 current banked scheme 2 full program order among eligible instructions 3 round robin across completed loads loads instructions program order 4 instructions oldest completed load programs show little change performance across selection policies mgrid one show significant improvements mentioned mgrid shows speedups banked wib 17 17 and020060100140180integer fp olden banked 4cycle 6cycle figure 7 nonbanked wib performance 13 three new policies respectively speedups due better scheduling actual dependence graph however cases schedule worse three programs show slowdowns compared banked wib oldest load policy 4 bzip 11 parser 15 facerec 5 45 nonbanked multicycle wib access explore benefits banked organization versus multicycle nonbanked wib organization figure 7 shows average speedups banked nonbanked organizations base architecture except different wib access latencies 4cycle 6cycle bars assume nonbanked wib instruction extraction full program order results show longer wib access delay produces slight reductions performance compared banked scheme indicates may able implement sophisticated selection policies pipelining wib access necessary 5 related work limit study similar performed skadron et al 28 results show branch mispredictions limit benefits larger instruction windows better branch prediction better instruction cache behavior synergistic effects benefits larger instruction windows larger data caches trade overlapping effects simulation assumes large 8mb l2 cache models register update unit ruu 29 unified active list issue queue rename register file study instruction window sizes 256 examined extensive research architecture designs supporting large instruction windows multiscalar 30 trace processors 23 one large centralized instruction window distributed smaller windows among multiple parallel processing elements dynamic multithreading processors 2 deal complexity large window employing hierarchy instruction win dows clustering provides another approach collection small windows associated functional units used approximate wider deeper instruction window 22 recent research 7 18 investigates issue logic designs attemp support large instruction windows without impeding improvements clock rates michaud exploit observation instructions dependent long latency operations unnecessarily occupy issue queue space long time address problem prescheduling instructions based data dependencies dependencebased issue queue designs studied 9 10 22 zilles et al 35 balasubramonian et al 4 attack problem caused long latency operations utilizing future thread use portion issue queue slots physical registers conduct precomputa tion power consumption become important consideration processor design researchers also studied low power instruction window design 3 16 6 conclusion two important components overall execution time clock cycle time number instructions committed per cycle ipc high clock rates achieved using small instruction window limit ipc reducing ability identify independent instructions tension large instruction windows short clock cycle times important aspect modern processor design paper presents new technique achieving latency tolerance large windows maintaining high clock rates small window designs accomplish removing instructions conventional issue queue directly indirectly dependent long latency operation instructions placed waiting instruction buffer wib reinserted issue queue execution long latency operation com pletes moving instructions critical path previously occupied issue queue entries utilized processor look deep program ilp important difference wib scaledup conventional issue queues wib implements simplified form wakeupselect achieved allowing instructions dependence chain considered reinsertion issue window compared full wakeupselect conventional issue queues wib requires select logic instruction reinsertion simulations 8way processor 32entry issue queue reveal adding 2kentry wib produce speedups 20 84 50 subset spec cint2000 spec cfp2000 olden benchmarks spectively also explore several wib design parameters show allocating chip area wib produces signifcantly higher speedups using area increase level one data cache capacity 32kb 64kb future work includes investigating potential executing instructions wib separate execution core either conventional core perhaps grid processor 25 policy space selecting instructions area current research finally register file design management eg virtualphysical multibanked multicycle prefetching twolevel organization require investigation acknowledgements work supported part nsf career awards mip9702547 ccr0092832 nsf grants cda972637 eia9972879 duke university donations intel ibm compaq microsoft erics son thank anonymous reviewers comments suggestions work r clock rate versus ipc end road conventional microarchitectures dynamic multithreading processor power energy reduction via pipeline balancing dynamically allocating processor resources nearby distant ilp reducing complexity register file dynamic superscalar processors scalable register renaming via quack register file evaluating future microprocessorsthe simplescalar tool set reducing complexity issue logic early experiences olden compaq computer corporation issue logic 600mhz outoforder execution microprocessor focusing processor policies via criticalpath prediction spec cpu2000 measuring cpu performance new millennium circuits widewindow superscalar processors alpha 21264 microprocessor large trace processors memory behavior spec2000 benchmark suite characterizing removing branch mis predictions improving prediction procedure returns return addressstack repair mechanisms branch prediction instruction issue logic highperformance multiscalar processors power4 system microarchitecture efficient algorithm exploiting multiple arithmetic units understanding backward slices performance degrading instructions tr instruction issue logic highperformance interruptible multiple functional unit pipelined computers multiscalar processors complexityeffective superscalar processors trace processors dynamic multithreading processor improving prediction procedure returns returnaddressstack repair mechanisms branch prediction instructionwindow size cache size lowcomplexity issue logic understanding backward slices performance degrading instructions circuits widewindow superscalar processors clock rate versus ipc multiplebanked register file architectures twolevel hierarchical register file organization vliw processors reducing complexity issue logic dynamically allocating processor resources nearby distant ilp focusing processor policies via criticalpath prediction power energy reduction via pipeline balancing energyeffective issue logic design space evaluation grid processor architectures instruction scheduling logic reducing complexity register file dynamic superscalar processors alpha 21264 microprocessor early experiences olden dataflow prescheduling large instruction windows outoforder processors characterizing removing branch mispredictions ctr rama sangireddy register port complexity reduction wideissue processors selective instruction execution microprocessors microsystems v31 n1 p5162 february 2007 simha sethumadhavan rajagopalan desikan doug burger charles r moore stephen w keckler scalable hardware memory disambiguation highilp processors ieee micro v24 n6 p118127 november 2004 il park chong liang ooi n vijaykumar reducing design complexity loadstore queue proceedings 36th annual ieeeacm international symposium microarchitecture p411 december 0305 srikanth srinivasan ravi rajwar haitham akkary amit gandhi michael upton continual flow pipelines achieving resourceefficient latency tolerance ieee micro v24 n6 p6273 november 2004 yongxiang liu anahita shayesteh gokhan memik glenn reinman scaling issue window lookahead latency prediction proceedings 18th annual international conference supercomputing june 26july 01 2004 malo france edward brekelbaum jeff rupley chris wilkerson bryan black hierarchical scheduling windows proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey hiroshi sasaki masaaki kondo hiroshi nakamura energyefficient dynamic instruction scheduling logic instruction grouping proceedings 2006 international symposium low power electronics design october 0406 2006 tegernsee bavaria germany yongxiang liu anahita shayesteh gokhan memik glenn reinman tornado warning perils selective replay multithreaded processors proceedings 19th annual international conference supercomputing june 2022 2005 cambridge massachusetts dan ernst andrew hamel todd austin cyclone broadcastfree dynamic instruction scheduler selective replay acm sigarch computer architecture news v31 n2 may adrin cristal jos f martnez josep llosa mateo valero case resourceconscious outoforder processors towards kiloinstruction inflight processors acm sigarch computer architecture news v32 n3 p310 june 2004 ilhyun kim mikko h lipasti macroop scheduling relaxing scheduling loop constraints proceedings 36th annual ieeeacm international symposium microarchitecture p277 december 0305 haitham akkary ravi rajwar srikanth srinivasan checkpoint processing recovery towards scalable large instruction window processors proceedings 36th annual ieeeacm international symposium microarchitecture p423 december 0305 e f torres p ibanez v vinals j llaberia store buffer design firstlevel multibanked data caches acm sigarch computer architecture news v33 n2 p469480 may 2005 jos f martnez jose renau michael c huang milos prvulovic josep torrellas cherry checkpointed early resource recycling outoforder microprocessors proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey adrian cristal oliverio j santana francisco cazorla marco galluzzi tanausu ramirez miquel pericas mateo valero kiloinstruction processors overcoming memory wall ieee micro v25 n3 p4857 may 2005 tali moreshet r iris bahar poweraware issue queue design speculative instructions proceedings 40th conference design automation june 0206 2003 anaheim ca usa tali moreshet r iris bahar effects speculation performance issue queue design ieee transactions large scale integration vlsi systems v12 n10 p11231126 october 2004 mikko h lipasti brian r mestan erika gunadi physical register inlining acm sigarch computer architecture news v32 n2 p325 march 2004 amit gandhi haitham akkary ravi rajwar srikanth srinivasan konrad lai scalable load store processing latency tolerant processors acm sigarch computer architecture news v33 n2 p446457 may 2005 ilhyun kim mikko h lipasti halfprice architecture acm sigarch computer architecture news v31 n2 may hans vandierendonck philippe manet thibault delavallee igor loiselle jeandidier legat bypassing outoforder execution pipeline increase energyefficiency proceedings 4th international conference computing frontiers may 0709 2007 ischia italy srikanth srinivasan ravi rajwar haitham akkary amit gandhi mike upton continual flow pipelines acm sigops operating systems review v38 n5 december 2004 huiyang zhou thomas conte enhancing memory level parallelism via recoveryfree value prediction proceedings 17th annual international conference supercomputing june 2326 2003 san francisco ca usa yu bai r iris bahar lowpower inorderoutoforder issue queue acm transactions architecture code optimization taco v1 n2 p152179 june 2004 tanaus ramrez alex pajuelo oliverio j santana mateo valero kiloinstruction processors runahead prefetching proceedings 3rd conference computing frontiers may 0305 2006 ischia italy alex pajuelo antonio gonzlez mateo valero speculative execution hiding memory latency acm sigarch computer architecture news v33 n3 june 2005 luis ceze karin strauss james tuck josep torrellas jose renau cava using checkpointassisted value prediction hide l2 misses acm transactions architecture code optimization taco v3 n2 p182208 june 2006 haitham akkary ravi rajwar srikanth srinivasan analysis resource efficient checkpoint architecture acm transactions architecture code optimization taco v1 n4 p418444 december 2004 madhavi g valluri lizy k john kathryn mckinley lowpower lowcomplexity instruction issue using compiler assistance proceedings 19th annual international conference supercomputing june 2022 2005 cambridge massachusetts huiyang zhou thomas conte enhancing memorylevel parallelism via recoveryfree value prediction ieee transactions computers v54 n7 p897912 july 2005 ahmed alzawawi vimal k reddy eric rotenberg haitham h akkary transparent control independence tci acm sigarch computer architecture news v35 n2 may 2007 andrew hilton amir roth ginger control independence using tag rewriting acm sigarch computer architecture news v35 n2 may 2007 peter g sassone jeff rupley ii edward brekelbaum gabriel h loh bryan black matrix scheduler reloaded acm sigarch computer architecture news v35 n2 may 2007 francisco j mesamartnez michael c huang jose renau seed scalable efficient enforcement dependences proceedings 15th international conference parallel architectures compilation techniques september 1620 2006 seattle washington usa simha sethumadhavan rajagopalan desikan doug burger charles r moore stephen w keckler scalable hardware memory disambiguation high ilp processors proceedings 36th annual ieeeacm international symposium microarchitecture p399 december 0305 albert meixner daniel j sorin unified microprocessor core storage proceedings 4th international conference computing frontiers may 0709 2007 ischia italy monreal victor vinals jose gonzalez antonio gonzalez mateo valero late allocation early release physical registers ieee transactions computers v53 n10 p12441259 october 2004 adrin cristal oliverio j santana mateo valero jos f martnez toward kiloinstruction processors acm transactions architecture code optimization taco v1 n4 p389417 december 2004 joseph j sharkey dmitry v ponomarev kanad ghose oguz ergin instruction packing reducing power delay dynamic scheduling logic proceedings 2005 international symposium low power electronics design august 0810 2005 san diego ca usa joseph j sharkey dmitry v ponomarev kanad ghose oguz ergin instruction packing toward fast energyefficient instruction scheduling acm transactions architecture code optimization taco v3 n2 p156181 june 2006