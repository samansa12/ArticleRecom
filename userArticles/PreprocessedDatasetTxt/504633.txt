qos provisioning tracking fluid policies input queueing switches concept tracking fluid policies packetized policies extended input queueing switches considered speedup switch one one interesting applications tracking policy tdma satellite switches elaborated special case 2 2 switches shown tracking nonanticipative policy always exists found general nonanticipative policies exist switches two input output ports general case n n switches heuristic tracking policy provided heuristic algorithm based two notions port tracking critical links notions employed derivation heuristic tracking policies well simulation results show usefulness heuristic algorithm two basic concepts relies b introduction one main issues design integrated service networks provide service performance requirements broad range applications applications requirements translated network quantitative parameters common performance measures packet loss probability delay jitter delay jitter characteristics switch network determined scheduling algorithm used switch incoming traffic pattern hand network also capable analyze amount resources particular application requires based analysis connection request admitted rejected therefore important network designer understand effect scheduling policy connection performance usage network resources many cases easier perform analysis design scheduling policies modeling assumption traffic arrives treated fluid ie realistic case information organized packets taken account 3411126 fluid policy assume every time instant arbitrary fractions link capacity shared among different applications although practical situations idealistic assump tion enables us analyze effect scheduling policy network resources well major performance pa rameters therefore design scheduling policies conveniently one approach design packetized policies first find appropriate fluid policy derive packetized policy resembles tracks fluid policy certain sense existence packetized tracking policies well established fact single link case fact several tracking policies suggested performance efficiency analyzed 11 12 6 5 9 however existence policies input queueing switches still open problem main subject paper research scheduling n theta n switches mainly concentrated output queueing switches n theta n switch possible n inputs packets output time order accommodate scenario output queueing switch switch fabric work n times faster line rates might acceptable moderate size switches working moderate line rates capacity lines well switch sizes increase memories sufficient bandwidth available input queueing becoming attractive alternative one way circumvent problem combined input output queueing cioq switches limited speed matches output sequence purely output queueing switch fact shown 2 speed 2 sufficient resemble output pattern output queueing switch however scheduling algorithm proposed fairly complicated arbiter still requires receive information input ports switch speed n paper consider input queueing switch every input output port service 1 packet per time unit packets considered equal size fluid policy model every time slot every input output port connected several output input ports however total service rate port exceed capacity packetized policy every input output port connected one output input port every time slot ie speed switch fabric circum stances objective find packetized policy tracks given fluid policy appropriate manner special case 2 theta 2 switches existence tracking policies proved nonanticipative tracking policy provided general case heuristic algorithm good perfect tracking properties proposed fact simulations done less 1 percent packets lost track fluid policy utility switch around 92 another interesting application tracking policies scheduling tdma satellite switches tdmass multiperiodic messages problem objective schedule packet every period connection stream arrival next packet since usually possible queue packets satellite switches input queueing model appropriate case fluid policy accomplishes specified tdma objective trivial original problem solved specifying packetized policy tracts fluid policy organization paper follows next sec tion review concepts fluid tracking poli cies provide feasibility condition casesthe problem scheduling multiperiodic messages tdmass explained elaborated section iii show problem essentially special case posed input queueing scheduling problem section iv show 2 theta 2 switches tracking policy always exist provide nonanticipative algorithm find tracking policy section also address problem providing packetized policy satisfies prespecified packet deadlines section v useful ideas regarding design heuristic tracking policies given based concepts heuristic simulation algorithm proposed heuristic algorithm applied scheduling multiperiodic tdmass simulation results given ii fluid packetized tracking policies consider input queueing switches serve fixed size packets input output port capacity serving 1 packet per time unit since queues exist input ports latter assumption implies traffic 1 packet per unit time transferred input ports given output port assume time slotted length slot equal length packet slots numbered starting 1 2 slot k taking time interval beginning end time slot k packets arrive beginning time slot packets origin input port destination output port j served fcfs two broad classes policies considered fluid packetized policies time slot k fluid policy trans units information input port output port j w ij k nonnegative real number measured units packets since one unit work transferred given input port output ports since queueing permitted output ports w ij ks must satisfy following inequalities 1 packetized policy based assumption time slot input port transmit single packet one output ports therefore packetized policy j ij k number packets transmitted port port j slot k either 0 packet transmission slot single packet transmission slot k packetized policy feasible every time slot k 2 note conditions 2 imply k single 1 column row matrix matrix j ij k subpermutation matrix usually fluid policies cannot applied directly network since mixing traffic belonging different packets allowed however considered paper performance analysis scheduling policy design often convenient fluid policies approach design packetized policies first design analyze fluid policy implement packetized policy resembles certain sense departure process fluid policy packetized policy called tracking pol icy precisely purposes use following definition definition given fluid policy say packetized policy tracking every packet departs packetized policy latest end time slot packet departs fluid policy basic question tracking policies exist given fluid policy question answered positively single link case different sessions share single link 11 6 case perhaps well known fluid policies gps rate controlled service disciplines several tracking policies suggested single link case 11 6 9 1 concepts gps rate controlled schedulers extended multiinputmultioutput input queueing switches however existence tracking policies switches still open question searching tracking policy converted another scheduling problem scheduling packets dead lines suppose set packets given every packet two associated time stamps first time stamp eligible time time schedule packet instance arrival time packet switch second time stamp deadline packet objective schedule packet inside time frame eligibility time deadline time obviously packetized scheduling policy satisfies deadlines induced fluid policy tracking packetized policy definition section iv study special case 2theta2 switches prove special case 2 theta 2 switches every feasible fluid policy exists feasible packetized policy fact proof constructive provide algorithm derive tracking policy also show natural extension earliest deadline first scheduling used solve problem scheduling packets deadline general case n theta n input queuing switch currently investigation latter case provide paper heuristic algorithm shows good performance number simulation studies iii multiperiodic tdma satellite switches one potential applications tracking policies scheduling tdma satellite switches tdmass conventional method scheduling based inukai method 10 method based assumption messages period scheduling done frame length equal period messages repeated periodically thereafter let l equal maximum number packets serviced inputoutput port one period set messages schedulable every port total number packets serviced l inukai provided scheduling algorithm set schedulable messages inukai algorithm work appropriately messages different periods let message input port output port dm period pm apply inukai method frame length set lcm message periods say l message lpm unit length packets scheduled frame packets associated one period original message use inukai method allocate packets inside frame length l problem control place packets inside frame inukai method thus possible packets attributed single periodic message placed next assignment suffers high jitter moreover delay packet equal l large suppose objective schedule every packet time frame period thus every packet tolerate delay period question arises whether possible provide schedule constraints necessary condition schedulability utilization every input port output port j greater unity ie one considers fluid policies easy provide schedule provided 3 satisfied specifically consider fluid policy assigns fix service rate 1pm every message policy switch starts servicing every packet immediately arrival takes pm time units complete service means target deadlines accomplished therefore provide packetized policy tracks fluid policy packetized policy satisfy delay constraints well 3 becomes necessary sufficient condition schedulability packetized policies specified constraints 13 philp liu conjectured 3 necessary sufficient condition schedulability specified delay constraints giles hajek 8 proved conjecture special case model messages sorted based period moreover every two subsequent messages k integer unfortunately algorithm work well general case saw correctness conjecture trivial fluid policies proved packetized policies next section show existence tracking policies special case 2 theta 2 switches thus conjecture proved special case 2 theta 2 switches iv section consider 2 theta 2 input queueing switch provide algorithm designing packetized policy tracks given fluid policy total amount traffic transferred fluid policy input port output port j end slot k thus conditions 1 following address following problem problem find sequence subpermutation matrices k ij solution problem found packetized policy uses subpermutation matrix jk schedule packets slot k tracking given fluid policy see notice first according leftmost inequality 5 end slot k integer number packets completes transmission input port output port j fluid policy least number packets completes transmission input output port packetized policy fact packets ports j served fcfs policies imply packet completes transmission slot l fluid pol icy also complete transmission latest end slot l packetized policy note next realizable packetized policy serve packets arrival switch ensured rightmost inequality 5 see notice according inequality number packets complete transmission input output port j packetized policy cannot exceed number packets complete transmission j fluid policy 1 moreover w ij k integer necessarily fact packets served fcfs policies imply packet cannot complete transmission slot k packetized policy unless part packet already transmitted end slot k fluid policy since fluid policy feasible never begins transmission packet arrival holds packetized policy note solve problem fact packetized policy tracks finishing times packets fluid policy also times fluid policy starts transmission packets proceed need another definition definition ii integer valued matrix called u neighbor matrix w ij j 7 ij 8 address stricter version problem problem ii find sequence subpermutation matrices k ik uneighbor ij proceed provide solution problem ii proof induction beginning slot 0 traffic processed either policies fluid packe tized set assume found appropriate subpermutation matrices slot k show construct sub permutation matrix slot k 1 jk 1 based ik matrix ik jk1 subpermutation matrix see note first second inequality holds 1 next show single 1 column row see note hence single 1 say column 1 i1 k 2 gammax sincex last inequality contradicts fact i1 show ik 1 satisfies 6 9 also 0 remains prove 7 8 matrix ik 1 con sider say column 1 distinguish following cases case 1 j i1 hencex third relation holds 7 fourth relation correct sincebffc integer fifth relation follows case 2 j 0 i1 k bw 2 since also conclude difference i1 values 0 1 need distinguish following subcases subcase 21 i1 i1 k last relation correct since 1 1 subcase 22 i1 i1 k last relation follows since j i1 2 remains consider case w i1 noninteger may redefine j still subpermutation matrix see consider following two cases column 2 already j say subpermutation matrix know j 22 k therefore setting j 21 1 still subpermutation matrix jk 1 b j k1 set j k1 i1 one still subpermutation matrix jk 1 order show 6 still holds modified jk1 note since i1 1c w i1 k 1 noninteger clearly show 8 holds note since modified matrix j i1 k apply argument case 1 may continue fashion examine rest columns rows update necessary matrix j eventually matrix uneighbor k1 according procedure following algorithm creating tracking policy ie generating subpermutation matrix jk 1 algorithm 1 beginning slot create matrix elements 2 column row say column 1 holds i1 noninteger redefine j i1 modified matrix jk 1 still subpermutation matrix note policy obtained way nonanticipative ie depend future arrivals therefore implemented online far shown tracking policy exists procedure convert fluid policy packetized tracking policy given previous section mentioned obtain tracking policy convert problem deadline scheduling problem solve problem following simple extension edf algorithm 2 theta 2 switch given policy call edf2 always come admissible schedule schedule exists schedule admissible satisfies deadlines perflow tracking far considered perlink tracking policies proved existence 2 theta 2 switches basically showed every fluid policy exists packetized policy tracks aggregate traffic going every input port every output port j many circumstances quite enough aggregate traffic pair inputoutput nodes consists several distinct flows sessions generally provide perflow qos fluid policy work granularity flows guarantees service rate given every flow individually also reflected packetized tracking policy specifically corresponding packetized policy track service given every flow fluid policy let w l ij k l ij k total amount flow l traffic transferred port j time k fluid policy packetized policy p respectively packetized policy p perflow tracking policy f bw l ij kc l obviously implies stricter definition tracking poli cies recently able prove notion tracking policy 2 theta 2 switches well result given without proof following theorem theorem 1 consider arbitrary fluid policy f input queueing 2 theta 2 switches exists nonanticipative packetized policy p tracks individual services given every flow fluid policy f b qos provisioning 2 theta 2 switches alternative approach qos provisioning problem view directly requirements realtime traffic attempt satisfy natural framework approach deadline satisfaction every packet presents upon arrival maximum waiting time may tolerate deadline determined depart scheduler attempts satisfy many deadlines possible single link known earliest deadline first policy satisfies packet deadlines satisfiable show effect achievable 2 theta 2 switches notion generalized link j every slot let ij earliest deadline among backlogged packets two service configurations 1g let sorted deadline vectors associated two configurations first component always minimum deadline ie say deadline vector lexicographically smaller j 1 definition iii scheduling policy edf2 policy every time slot selects configuration minimum lexicographical deadline vector edf2 natural extension edf 2 theta 2 case suppose sequence packets deadlines given known deadlines satisfiable ie feasible scheduling meet deadlines scheduling policy edf2 also satisfies deadlines proof claim straightforward similar proof result edf policy single link case edf2 policy applied obtain tracking pol icy case every time slot k deadline packets set end time slot depart switch fluid policy departing times calculated based assumption future arrivals note crucial information scheduling relative order packets departure times departing times assume future arrivals change departure order packets departure orders obtained future arrival assumption correct regardless future arrivals therefore edf2 policy would nonanticipative tracking policy illustrate next section basic assumption regarding independence future arrivals departure order backlogged packets reasonable assumption general case n theta n switches v heuristic algorithms let f feasible fluid policy every time slot k specifies appropriate fluid scheduling matrix wk scheduling matrix wk n theta n matrix indicating rate transmission every input port every output port function arrivals k back logged traffic q k time k general arrival process nonanticipative therefore scheduling function known advance circumstances impossible track fluid policy perfectly n 2 illustrate example ffl example consider 4 theta 4 switch let 025 025 025 025 025 025 025 025 without loss generality assume tracking policy selects following two subpermutation matrices two first time slots assume fluid policy arrival packets higher priority takes following rate matrix next time slot clear fluid policy finishes four packets links 12 14 21 23 third time slot none scheduled first two time slots packetized policy thus end third time slot tracking policy least miss deadlines 2 packets worth mentioning one crucial assumptions single link sharing case departure order packets present node independent future arrivals valid justifiable assumption n theta n case properties nonanticipative tracking algorithms single link case due assumption one expect similar results regarding nonanticipative tracking policies hold n theta n switches recall already provided nonanticipative tracking policy 2 theta 2 case example shows result generalized n theta n case fact motivates us seek heuristic algorithms good perfect tracking properties intending provide complete efficient tracking policy want illustrate appropriate approach design tracking policies basically introduce two main concepts could employed design tracking poli cies illustrate simulation results simple tracking policy implemented based two concepts two concepts elaborate section port based tracking critical links based tracking one way implement packetized tracking policy based weighted matching bipartite graphs method weights links difference fluid policy tracking policy total job done link call weights tracking weights ij k add positive weights links associated every input output port assign weight corresponding vertex bipartite graph show vertex weights v v j added weight links regardless sign ones negative weight would lessen total weight vertex reduce chance positive weights lagging ones scheduled next select criterion function weights nodes matching perhaps ones left matching attempt optimize propose two possible candidates summation criterion one possible candidate maximize summation scheduled vertices weights way every step select set nodes overall maximum weights therefore overall lagging tracking policy minimized prioritization criterion possible choice would prioritization criterion nodes prioritized based weights nodes greater weight higher priority node excluded matching including necessitates removing node higher priority matching approach absolute lagging value node considered essential ones greater lagging weight scheduled hard show mentioned criteria equivalent due special structure bipartite graphs next lemma prove equivalence two criteria represents optimal matching graph based summation priority criterion 1 optimal based priority summation criterion proof suppose 1 represents optimal matching graph based summation criterion optimal based priority criterion let 2 optimal matching graph based priority criterion let 1 node 1 2 consider graph graph consists links one one two graphs 1 2 maximum degree vertex g two therefore consists union distinct paths loops first vertex path g degree one focus path two alternative cases possible number nodes path either even odd even last node path also member 1 intermediate nodes belong matching thus replace alternative set links path belonging 2 belonging 1 two vertices included 2 contradicts optimality assumption 2 number vertices path odd last vertex member 2 last node less weight first vertex 1 otherwise 2 optimal graph based priority criterion greater weight contradicts optimality thus weight equal 1 therefore every node 1 node 2 equal weight vice versa means graphs optimal according criteria argument also provides algorithm derive optimal matching graph algorithm based exploring augmenting path similar case maximum matching algorithm difference maximum matching case search results better matching whenever free node detected search results better matching node smaller weight first node augmenting path detected following algorithm finds maximum weighted vertex matching matching algorithm 1 sort nodes according weights 2 select highest weight node matching selected yet 3 search augmenting path started selected node step 2 search ends successfully either free vertex detected augmenting path found node smaller weight first node found search ends unsuccessfully possible paths searched none mentioned cases occurred 4 repeat steps 2 3 nodes selected although bipartite matching algorithms extensively used scheduling switches either based maximum link edge weighted matching maximum matching algorithms problem maximum link weighted matching algorithms complexity problem maximum matching algorithms poor performance vertex based matching considered intermediate solution enhance performance scheduling algorithm based vertex maximum matching selecting appropriate initial set eligible links provided ar biter modifying weights nodes urgent scheduled basically consider two stage scheduling first step set eligible links scheduling weights vertices derived next step arbiter select links matching based optimum vertex weighted matching algorithm described one way select eligible set links tracking problem based notion critical links critical links urgent scheduled scheduled tracking policy loose track fluid policy link detected noncritical links sharing input output port critical link excluded precise definition critical nodes given next section b critical ports links critical port port scheduled next time slot order miss deadline future example suppose beginning k gamma th time slot let say two packets one node j 1 node j 2 deadline k 1 note schedule packets deadline missed k gamma th time slot however definitely miss deadline subsequent time slot 1 say node critical node links associated critical links general sufficient condition port critical time k least packets deadlines less equal k p denote stating sufficient condition words might critical ports detected well advance using criterion case tracking policy deadline packets implicitly given equal end time slot packet departs switch fluid policy may know deadlines well advance since future rate every link fluid policy depends future arrivals nonanticipative nevertheless may approximate deadline every packet based backlogged traffic average arrival rate links instance based oe ae flow model atm traffic also approaches constant rate assigned session regardless arrival process multiperiodic messages tdmass rate controlled service disciplines case networks packet assigned session available time scheduling packets kind traffic instance best effort traffic use available slot 14 next issue set appropriate inspection horizon inspection horizon number time slots future inspect detect critical nodes based ex periments found inspection horizon around five ade quate fact tradeoff involved increasing inspection horizon helps us detecting critical links increases complexity algorithm well detecting critical port know schedule one critical links associated otherwise miss deadlines thus remove links associated critical port critical way chance scheduler arbitrate one critical links increased also increase weight critical ports constant weight become greater noncritical ports therefore nodes prioritized scheduler critical nodes detecting algorithm described critical node detecting algorithm 1 every node j steps 2 3 2 calculate number packets sent next time slots 3 number packets sent next l time steps equal l corresponding node critical moreover associated links least send one packet next l time slots critical links whole scheduling process switch divided two stages first stage weight ports calculated criticality ports investigated computation done parallel different ports switch interaction necessary next stage computed weights nodes eligible links every node provided arbiter processor one main concerns high speed switches volume information required exchanged different cards switch namely signaling scalability algorithm link weighted matching arbiters weights associated every link sent arbiter thus exchanging information order n 2 approach weights nodes eligible links one bit information per link sent arbiter order n finally provide simple scheduling algorithm based algorithms described heuristic scheduling algorithm 1 every time slot k following steps 2 calculate weights nodes using 1011 3 insert links positive weights eligible links set 4 check critical nodes associated critical links 5 increase weight every critical node weight exceed noncritical nodes weights moreover remove noncritical links critical nodes eligible links set 6 pass weights nodes critical links set matching algorithm result matching schedule time slot k algorithm used next section scheduling tdmass simulation results illustrated c simulation results section provide primary results regarding heuristic algorithm thorough investigation analysis heuristic algorithms still continuing ever primary results appear promising used heuristic algorithm scheduling tdmass multi periodic messages suppose messages periodic objective schedule every period message next one arrives thus period message slots schedule every packet mes sage fluid policy assigns constant rate 1p message accomplishes task messages generated randomly input output pairs equal probability period message selected uniformly range f3 8g messages selected every experiment utility every node 090 097 experiments average utility utility l0 l1 l2 late around 092 critical nodes inspected based constant rate inspection horizon set n done simulation different switch sizes every switch size generated 100 different message sets investigate performance algorithm model different messages input output scheduler works aggregate rate messages important complexity arbiter depend number messages large schedule different messages input output edf scheduler maintained every input port packet considered time zero latency scheduled within period interval arrival latency packet l equal k 0 scheduled k time units deadline result simulations given table far scheduler concerned working constant rate traffics therefore results simulation also applicable case fixed rate scheduler network switches number packets different latencies indicated table percentage late packets also shown last column every row correspond different switch size number packets missing deadlines less one percent maximum latency two time units cases believe many applications acceptable performance many applications excessive delay imposed arbiter tolerable fact applications allowed miss packets neglect packets miss deadline return aids us time scheduling packets important issue size switch many heuristic algorithms proposed degrades size switch increases 13 case observe degradation vi conclusion paper notion fluid policies tracking policies extended n theta n switches concepts useful high speed networks aid us providing guaranteed service different applications tdmass multiperiodic messages existence tracking policy proved special case 2 theta 2 switches general case n theta n switches heuristic algorithm provided heuristic algorithm mainly presented confirm validity two important notions measures tracking policies port tracking critical node concepts existence tracking policy n theta n still open question however based results provided special cases heuristic algorithm think tracking policy always exist however shown impossible perfect tracking policy fluid policy nonanticipative fact together complexity issue justify need better less complicated heuristic tracking policies good perfect performances r calculus network delay calculus network delay analysis simulation fair queueing algorithm optimal multiplexing single link delay buffer requirements efficient network qos provisioning based per node traffic shaping scheduling multirate periodic traffic packet switch shaping generalized processor sharing approach flow control integrated services networks single node case generalized processor sharing approach flow control integrated services networks multiple node case scheduling realtime messages packetswitched networks tr data networks analysis simulation fair queueing algorithm introduction algorithms generalized processor sharing approach flow control integrated services networks generalized processor sharing approach flow control integrated services networks efficient network qos provisioning based per node traffic shaping edd algorithm performance guarantee periodic hardrealtime scheduling distributed systems scheduling realtime messages packetswitched networks ctr yong lee jianyu lou junzhou luo xiaojun shen efficient packet scheduling algorithm deadline guarantees inputqueued switches ieeeacm transactions networking ton v15 n1 p212225 february 2007