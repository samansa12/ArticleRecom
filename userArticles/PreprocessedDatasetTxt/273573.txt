stability nullspace methods kkt systems paper considers numerical stability nullspace methods karushkuhntucker kkt systems particularly context quadratic programming methods consider based direct elimination variables attractive solving large sparse systems illconditioning certain submatrix system shown adversely affect method insofar commonly implemented particular cause growth residual error solution would normally occur gaussian elimination related methods used mechanism error growth studied due growth nullspace basis matrix z might expected indeterminacy matrix lu factors available shown alternative form method available avoids residual error growth conclusions supported error analysis matlab experiments extremely illconditioned test problems indicate alternative method robust regard residual error growth unlikely significantly inferior methods based orthogonal basis matrix paper concludes discussion needs done lu factors available b introduction karushkuhntucker kkt system linear system version paper presented dundee biennial conference numerical analysis june 1995 manchester ima conference linear algebra july 1995 r fletcher johnson involving symmetric matrix form systems characteristic optimization problem subject linear equality constraints objective quadratic func tion kkt system 11 represents first order necessary conditions locally minimum solution problem vector lagrange multipliers see 3 example problems like 13 arise many fields study newtons method nonlinear programming solution partial differential equations involving incompressible fluid flows incompressible solids analysis plates shells also problems inequality constraints often solved solving sequence equality constrained problems particularly active set method quadratic programming 12 13 g symmetric n theta n hessian matrix objective function n theta jacobian matrix linear constraints n assume full rank otherwise k would singular applications immediately full rank readily reduced full rank matrix suitable transformation various ways solving kkt systems regarded symmetrypreserving variants gaussian elimination pivoting see example forsgren murray 4 approach suitable oneoff solution large sparse kkt system incorporating suitable data structure permits fillin resulting factors interest kkt systems arises quadratic programming qp context using socalled nullspace method solve sequence equality constrained problems arise method described section 2 important feature qp successive matrices k differ one column either added removed nullspace method allows feature used advantageously update factors reduced hessian matrix arises solving kkt system however paper consider updaing issue concentrate solution single problem like 13 nullspace context fact nullspace method related one mentioned variants gaussian elimination point discussed towards end section 3 paper study numerical stability nullspace method matrix k illconditioned arises either matrix close rank deficient reduced hessian matrix illconditioned well known however gaussian elimination pivoting usually enables illconditioned systems solved small backward error computed solution exact solution stability nullspace methods 3 nearby problem wilkinson 6 points size backward error depends growth certain reduced matrices amount growth usually negligible illconditioned matrix although possible exponential growth occur give example kkt system unlikely practice consequence computed solution substituted system equations accurate residual obtained thus variants gaussian elimination pivoting usually provide stable method solving illconditioned systems however argument carry nullspace method indicate end section 2 serious concerns numerical stability nearly rank deficient describe matlab experiments section 6 support concerns particular residual kkt system seen proportional condition number present error analysis section 4 shows arises lu factors available show section 3 alternative way implementing nullspace method avoids numerical instability also supported matlab experiments reasons described section 5 present error analysis illustrates difference two approaches practice solving large sparse qp problems lu factors usually available usual use sort product form method conclude remarks done situation avoid numerical instability nullspace methods nullspace method see eg 3 important technique solving quadratic programming problems equality constraints section show method derived generalised form constraint elimination key issue procedure formation basis null space determine basis way able solve large sparse problems efficiently illconditioned argue serious concern numerical stability method null space may defined dimension full rank matrix whose columns basis n referred nullspace matrix matrix satisfies linearly independent columns general specification computing nullspace matrix choose n theta n gamma matrix v matrix 4 r fletcher johnson nonsingular inverse partitioned following way ngammam follows properties inverse construc tion columns z linearly independent follows columns form basis n value construction enables us parametrize solution set usually underdetermined system 13 b one particular solution solution x differs b vector zv say n thus 22 provides general way eliminating constraints expressing problem terms reduced variables v hence 22 substituted objective function 13 obtain reduced problem refer z gz reduced hessian matrix z gy bgammac reduced gradient vector point sufficient condition 23 unique minimizer z gz positive definite case exist choleski factors z 23 solved finding stationary point solving linear system substitution v 22 determines solution x 13 vector gx gamma c gradient objective function solution vector lagrange multipliers satisfying obtained virtue property vectors x also provide solution 11 readily verified practice large sparse matrix matrices z usually substantially dense impracticable store explicitly instead products z transposes obtained solving linear systems involving example vector could computed solving linear system virtue 21 likewise solving system stability nullspace methods 5 provides products u 1 computations require invertible representation matrix available solving systems involving usually major cost nullspace method keep cost low possible preferable choose matrix v sparse choices example based qr factors see 3 usually involve significantly fillin computational expense particular attractive choose columns v unit vectors using form pivoting keep well conditioned possible case assuming row permutation incorporated possible write 1 theta nonsingular submatrix 21 becomes provides explicit expression z particular see refer choice v direct elimination corresponds directly using first variables eliminate constraints see 3 shall adopt choice v throughout rest paper reduced hessian matrix z gz also needed use 23 calculated similar way method compute vectors z gze k unit matrix ngammam computation carried right left first computing vector z solving system z product gz k computed followed solution partition u 2 column k z gz required lower triangle z gz used calculate choleski factor l similar approach essentially used active set method qp choleski factor z gz built sequence iterations indefinite qp problems solved may required solve kkt systems z gz indefinite note systems also solved numerically stable way preserves symmetry see higham 5 regard method bunch kaufmann 1 6 r fletcher johnson advantage nullspace approach need available subroutine matrix product gv thus take full advantage sparsity structure g without example allow fillin gaussian elimination would require approach convenient z gz sufficiently small allow stored dense matrix fact close relationship nullspace method variant gaussian elimination shall see next section matrix z gz submatrix methods thus would equally easy difficult represent z gz sparse matrix format either method summarize content section enumerate steps implied 22 25 1 calculate z gz 210 211 2 calculate solve 26 3 calculate requiring product g 4 calculate u 2 solve 27 5 solve z determine v 24 6 calculate solve 26 7 calculate requiring product g 8 calculate solve also provides z g direct elimination based 29 used shall refer method 1 step 1 requires solves either products g set reduced hessian matrix remaining steps require 4 solves 2 products plus solve z gz circumstances counts reduced steps 2 3 required multiplier part solution interest steps 7 8 needed turn concerns numerical stability nullspace method hence 1 illconditioned case close rank deficient say null space higher dimension solve systems like 210 211 matrix z implicitly using badly determined therefore roundoff error effectively get significantly different z matrix time carry solve thus computed reduced hessian matrix z gz correspond one particular z matrix shall see rest paper lead solutions significant residual error stability nullspace methods 7 3 using lu factors section consider possibility readily compute lu factors given unit lower triangular u upper triangular assume row permutation made enables us bound elements l 1 l 2 1 shall see factors permit us circumvent difficulties caused illconditioning large extent unfortunately lu factors always available indication given section 7 might done situation also describe steps nullspace method changed finally explore connections gaussian elimination methods provide insight likelihood growth z key observation lu factors available possible express z alternative form uu gamma1 factors arising 29 31 cancelled minor disadvantage compared 29 l 2 needed likely less sparse 2 also requires additional storage however illconditioned manifested u usually l illconditioned 32 enables z defined way wellconditioned calculating reduced hessian matrix convenient define replace equations 210 211 steps resulting nullspace method follows using subscript 1 denote first rows vector matrix subscript 2 denote last 1 calculate z gz 34 35 2 calculate 1 8 r fletcher johnson 3 calculate requiring product g 4 calculate u 2 5 solve z v 6 calculate 7 calculate 8 calculate requiring product g 9 calculate 10 calculate inverse operations involving l 1 u done forward backward substitution method referred method 2 follows comparability method 1 also included calculation reduced gradient z although would normally required note solves n theta n matrix replaced solves smaller theta matrices also steps 1 4 6 10 use alternative definition 32 z avoid potentially illconditioned calculation 1 consider numerical stability method 1 method 2 detail next section rest section explore connections method variants gaussian elimination examine factored forms provided methods readily observed well known block factors k corresponding nullspace method general format factors using blanks denote zero matrix result readily verified using equation derived 21 expression makes clear inverse representations matrices z gz required solve 11 however factors directly useful method solution also involve matrices gy gz whose computation wish avoid nullspace method equation 36 also shows k gamma1 become large either z gz illconditioned would expect spectral condition number behave like using direct elimination 28 may partition k form g 11 g 21 g 22 stability nullspace methods 9 lu factors 31 readily verified another way factorizing k given by6 4 g 11 g 21 g 22 z u u t7 56 4 z defined 32 g 1 note matrix u occurs reverse diagonal middle factor operations u gamma1 required calculation factors thus illconditioning associated u manifest factors used solving kkt system 11 growth z backward error 37 small indicating potential small residual solution kkt system show section 5 come another related observation rank deficient factors 36 exist since calculation involves gamma1and hence u calculated without difficulty factorization 37 k closely related symmetry preserving variants gaussian elimination let us start eliminating 2 subdiagonal elements 1 row operations assume row pivoting used outcome row operations that6 4 g 21 g 22 g 22 note row operations exactly used gaussian elimination form 31 restore symmetry factors repeat procedure transposed form make column operations tand gives rise 37 also interleave row column operations without affecting final result pair first row column operation second row column operation get method ba pivots described forsgren murray 4 thus methods essentially share matrix factors difference nullspace method z gz calculated matrix solves described section 2 whereas methods obtained row column operations matrix k association gaussian elimination enables us bound growth r fletcher johnson factors k bound attained critical case typified matrix row operations pivots 17 28 39 positions leads column operations pivots 71 82 93 104 positions gives rise 2 corresponds middle factor 37 case corresponding matrix z given stability nullspace methods 11 general readily shown n growth 2 2m maximum modulus element k occur nullspace method based 32 example also illustrates maximumpossible growth 2 1 practice however growth unlikely usual get significant growth z 4 numerical stability method 1 next section consider effect illconditioning matrix k solutions obtained nullspace methods based direct elimination particular interested see whether establish results comparable gaussian elimination shall show forward error x severe would predicted condition number k also look residual errors solution show method 2 satisfactory respect whereas method 1 order prevent details analysis obscuring insight trying provide shall adopt following simple convention imagine solving sequence problems either spectral condition numbers increasing without bound use notation oh indicate quantity bounded norm ckhk sequence exists implied constant c independent may contain modest dependence n also shall assume system well scaled 1 enables us example deduce multiplication error bound gamma1 causes bound increased oa also choose assume kkt system models situation exact solution vectors x exist unreasonably large norm similar assumption needed order show gaussian elimination provides accurate residuals cannot expect dispense assumption sometimes may possible argue solving physical problem known well behaved solution another assumption make choice matrix v 28 hence partitioning made using form pivoting exact solution z given 33 using factors defined 31 follows l spectral condition number l assuming partial pivoting used jl ij j 1 negligible growth occurs l gamma1 follows negligible growth occurs z assert 12 r fletcher johnson another consequence assumption able neglect terms ol relative terms oa assessing propagation errors method 2 shall sketch properties wilkinson 6 floating point arithmetic relative precision nonsingular system n linear equations solved gaussian elimination computed solution b x exact solution perturbed system referred backward error e bounded expression form aeoen ae measures growth elimination oen modest quadratic n illconditioned systems assuming partial pivoting used growth rare ignored also bound usually overstates dependence n unlikely dominant factor hence backward error measure accuracy solution either forward error b x computing residual x using condition number since assuming 1 follows b likewise deduce bounds likely realistic tell us gaussian elimination illconditioning affects forward error x residual r long b x reasonable magnitude wilkinson also gives expressions backward error scalar product hence product ax computed product b exact product system relative perturbation element b n n dimension x express make assumption b o1 first stage nullspace calculation determination z gz denote method 1 computed 210 211 210 column z k matrix z computed applying 44 satisfies stability nullspace methods 13 spectral condition number product g introduces negligible error solution 211 together 45 shows ab multiplying l gamma1 extracting b partition gives using 47 42 hence established c argument given detail important see error oa 2 also observe hence c turn solution kkt system using method 1 shall assume systems involving solved way 45 applies using 46 assuming computed quantities b b o1 residual errors sequence calculations ab c z results together 48 may combined get forward errors solution vectors b x b multiplying equations 49 413 gammat magnifies errors factor since assuming o1 giving get rather better bound 411 415 first multiplying using give 14 r fletcher johnson second partition solution however first partition 415 gives combining 48 412 gives chain forward errors noting product z z magnify error previously computed quantity virtue 42 however product gamma1 b 421 magnifies error b factor product 420 magnifies error b g factor outcome 423 would expect forward errors affected condition numbers however although condition number k expected order 2 see factor magnifies error part solution x part less badly affected k illconditioned must necessarily expect forward errors adversely affected important question ask whether solution satisfies equations problem accurately three measures interest residuals kkt system 11 reduced gradient gx negative gradient vector solution note vector z computed byproduct step 8 method 1 compute r obtain b 46 follows 413 definition b computing q obtain b z 414 415 thus accuracy b q depends b z 419 follows stability nullspace methods 15 417 notice important use 422 would give unnecessary factor 48 412 411 410 used giving thus able predict assumptions reduced gradient b z residual b q adversely affected illconditioning illconditioning however residual b r unaffected illconditioning either simulations described section 6 indicate error bounds reliably predict actual effects illconditioning method 1 seen unsatisfactory accurate residual q cannot obtained illconditioned shall show next section method 2 share disadvantage main results section next summarised discussed section 7 5 numerical stability method 2 section assess behaviour method 2 presence illconditioning k although cannot expect improvement forward errors able show method 2 able give accurate residuals affected ill conditioning relationship method 2 gaussian elimination described towards end section 3 gives hope proving result however immediate method 2 make direct use factors 37 way gaussian elimination fundamental difficulty analysis method 2 deduce 47 result cannot improved lu factors available see know computed factors square matrix satisfy growth b u exact factors follows u say q strict lower triangular part l u gamma1 r upper triangular part l l unit lower triangular u b u gamma1 upper triangular deduce involves inverse operation b u expect b l l differ oa result confirmed computing lu factors hilbert matrix single double precision fortran applying result matrix follows 51 holds r fletcher johnson fortunately lost still able compute nullspace matrix accurately satisfies equation z z denote nullspace matrix obtained b l exact arithmetic follows b hence 52 also b long 1 analysis express errors arise method 2 terms b z rather z enables us avoid factor residuals first step method 2 compute gz 34 35 section denote c z value computed b z exact arithmetic use c c denote computed value c readily follows using results like 42 c c consider solution kkt system using method 2 equations 415 assume computed quantities b b o1 residual errors sequence calculations tb 1 c c readily seen equations forward errors propagate similar way method 1 turning residual errors computed value residual r 510 59 55 53 computing q obtain b method 1 follows 512 b q 1 53 deduce follows stability nullspace methods 17 thus accuracy residual b q depends b z method 1 b z use 513 511 510 59 get invoke 54 58 giving 57 56 thus established assumptions three measures accuracy kkt system method 2 affected illconditioning either results supported simulations next section figure 1 condition numbers k l 6 numerical experiments order check predictions sections 4 5 experiments carried artifically generated kkt systems experiments carried matlab machine precision suggest upper bounds given error analysis accurately reflect actual behaviour illconditioned system another phenomenon occurs illconditioning extreme also explained kkt systems constructed following way make illconditioned chosen first columns n theta n hilbert matrix provides sequence problems condition number increases exponentially factors calculated matlab routine lu uses gaussian elimination partial pivoting replaced pa first instance matrix g generated random numbers range gamma1 1 however make positive definite multiple unit matrix added g 22 partition g chosen smallest eigenvalue r fletcher johnson changed 10 1gammak positive integer k assumptions analysis require kkt system solution o1 achieve exact solutions x generated random numbers gamma1 1 right hand sides c b calculated 11 value 10 runs made different random number seed statistics averaged 10 runs first examine effect increasing condition number whilst keeping wellconditioned increase 2 10 whilst fixing 1 resulting condition numbers k l plotted figure 1 seen slope unbroken line k twice dashed line 1 consistent estimate k 2 deduced section 3 condition number l dotted line shows negligible increase showing growth l gamma1 thus enabling us assert o1 levelling k graph due roundoff error corrupting least eigenvalue k figure 2 error growth vs method 1 figure 3 error growth vs method 2 effect conditioning different types error illustrated figures 2 3 forward error shown two unbroken lines upper line error lower line error x upper line slope 2 loglog scale lower line slope 1 intercept yaxis 10 gamma16 precisely accordance 423 422 also seen methods exhibit forward error computed value residual error shown dashed line methods show behaviour predicted 424 514 increasing condition number effect difference methods 1 2 shown computed values residual dotted line reduced gradient line would expect 427 graphs superimposed clearly show influence error growth method 1 predicted 428 negligible error growth observed method 2 predicted 516 except stability nullspace methods 19 increase q greater 10 9 feature explained later section figure 4 error growth vs method 1 figure 5 error growth vs method 2 turn see influence illconditioning errors fix carry sequence calculations causes increase exponentially calculation average ten runs results illustrated figures 3 4 using key forward errors seen methods slope 1 loglog scale corresponding factor 422 423 upper line forward error lies 10 5 units forward error x extra factor 423 would predict residual r seen unaffected conditioning residual q reduced gradient z also unaffected graphs method 1 lie method 2 due factor 428 effects accordance error analysis predicts examine anomalous behaviour q figure 3 detail turn sequence illconditioned test problems obtained using last columns hilbert matrix define results method 2 illustrated figure 6 anomalous behaviour dotted line evident reason becomes apparent noticed sets forward error hence value b becomes greater unity possibility excluded error analysis assumption b o1 anomalous behaviour sets 2 gamma12 case 10 8 much figures 3 6 illustrate greater values term ob expression b indicating error form 2 fact part graph q parallel graph forward error supports conclusion calculations also carried using vandermonde matrix place hilbert matrix similar results obtained r fletcher johnson figure 6 error growth method 2 illconditioned matrix 7 summary discussion paper examined effect illconditioning solution kkt system nullspace methods based direct elimination methods important well suited take advantage sparsity large systems however often criticised lack numerical stability particularly compared methods based qr factors studied two methods method 1 invertible representation 28 used solve systems method 2 lu factors 31 available presented error analysis backed numerical simulations certain assumptions growth provide following conclusions ffl methods forward error bounds b ffl methods give accurate residuals well conditioned even illconditioned gives accurate residual method 1 ffl methods give accurate residual illconditioned conclusions indicate method 1 adversely affected illconditioning even though technique solving systems involving able provide accurate residuals reasons particularly interesting example one might expect illconditioned gamma1 would large might therefore expect 21 z would large fact seen long v chosen suitably growth z unlikely argument similar gaussian elimination course v badly chosen z large cause stability nullspace methods 21 significant error one might also expect forward error computing z necessarily order oa would follow nullspace method could provide accurate residuals way forward exploited analysis method 2 method 2 determines matrix b z b thus although nullspace inevitably badly determined illconditioned method 2 fixes one particular basis matrix z well behaved basis exact basis perturbation method 2 able solve perturbed problem accurately hand method 1 essentially obtains different approximation z every solve thus computed reduced hessian matrix z gz correspond accurately one particular b z matrix passing interesting remark computing factors defining also provides stable approach much avoids growth z seen rarely problem also provides fixed nullspace reference basis exact basis perturbation context quadratic programming common solution method large sparse systems use sort product form method gaussjordan bartelsgolubreid forresttomlin etc clear methods provide solutions systems involving solved method 1 although bgr may stable respect however main difficulty comes product form becomes unweildy reinverted illconditioned refactorization likely determine basis matrix z differs oa defined old product form thus old reduced hessian matrix z gz would correspond accurately defined new z matrix reinversion recourse would reevaluate z gz reinversion might expensive thus see product form method suitable paper shown fixed reference basis generated accurate residuals possible hoped show might done subsequent paper combining product form method another method lu factorization r parlett b erisman practical methods optimization newton methods largescale linear equality constrained minimization stability diagonal pivoting method partial pivot ing algebraic eigenproblem tr