accelerating filtering techniques numeric csps search algorithms solving numeric csps constraint satisfaction problems make extensive use filtering techniques paper show filtering techniques accelerated discovering exploiting regularities filtering process two kinds regularities discussed cyclic phenomena propagation queue numeric regularities domains variables also present paper attempt unify numeric csps solving methods two distinct communities csp artificial intelligence interval analysis b introduction several fields human activity like engineering science business people able express problems constraint problems csp constraint satisfaction problem schema abstract framework study algorithms solving constraint problems csp defined set variables associated domain possible values set constraints variables paper deals specifically csps constraints numeric nonlinear relations domains continuous domains numeric csps corresponding author email addresses ylebbahunivorandz lebbah olhommeilogfr lhomme paper extended version 31 see front matter 2002 elsevier science bv rights reserved general numeric csps cannot tackled computer algebra systems algorithm general nonlinear constraint systems numeric algorithms cannot guarantee completeness solutions may missed global optimum may never found sometimes numeric algorithm even converge numeric algorithms guarantee completenesseven floatingpoint computations usedare coming either interval analysis community ai community csp unfortunately safe constraintsolving algorithms often less efficient nonsafe numeric methods challenge improve efficiency safe constraintsolving algorithms typically searchtree exploration filtering technique applied node improvement efficiency possible finding best compromise filtering technique achieves strong pruning high computational cost another one achieves less pruning lower computational cost thus lot filtering techniques developed filtering techniques take roots numerical analysis main filtering technique used interval analysis 37 interval variation newton iterations see 2428 overview methods filtering techniques originate artificial intelligence basic filtering technique kind arcconsistency filtering 36 adapted numeric csps 17 2632 higherorder consistencies similar kconsistency 21 also defined numeric csps 2532 another technique artificial intelligence 1920 merge constraints concerning variables giving one total constraint thanks numerical analysis techniques perform arcconsistency total constraints finally 645 aim expressing interval analysis pruning partial consistencies bridging gap two families filtering techniques works address issue finding new partial consistency property computed associated filtering algorithm good efficiency respect domain reductions performed another direction search efficient safe algorithms try optimize computation already existing consistency techniques indeed aim paper study general methods accelerating consistency techniques main idea identify kinds regularity dynamic behavior filtering algorithm exploit regularities first kind regularities exploit existence cyclic phenomena propagation queue filtering algorithm second kind regularities numeric regularity filtering process converges asymptotically fixed point often extrapolated see paper ideas although quite general may lead drastic improvements efficiency solving numeric csps paper focus numeric continuous problems ideas general may interest also mixed discrete continuous problems even pure discrete problems paper organized two main parts first part section 2 presents overview numeric csps artificial intelligence works interval analysis works presented unifying framework second part consists next two sections presents contribution paper section 3 introduces concept reliable transformation presents two reliable transformations exploit two kinds regularities occurring filtering process cyclic phenomena propagation queue numeric regularities domains variables section 4 discusses related works 2 numeric csps section presents numeric csps slightly nonstandard form convenient purposes unify works interval analysis constraint satisfaction communities numeric csp triplet x dc x set n variables x 1 x n denotes vector domains ith component domain containing acceptable values x denotes set numeric constraints denotes variables appearing c j paper focuses csps domains intervals following notation used throughout paper interval b b empty interval vector domains component empty interval denoted lower bound upper bound midpoint interval respectively interval vector respectively denoted respectively lower bound upper bound midpoint inclusion relation union operator intersection operator defined interval vectors interpreted componentwise instance means 1 n means 1 n means kary constraint c kary relation real numbers subset r k 21 approximation projection functions algorithms used numeric csps typically work narrowing domains need compute projectiondenoted c j x also ji dof constraint variable x space delimited projection ji defined follows x x projection defined set elements find elements k 1 remaining variables 1 usually projection cannot computed exactly due several reasons 1 machine numbers floating point numbers real numbers roundoff errors occur 2 projection may representable floatingpoint numbers 3 computations needed close approximation projection one given constraint may expensive 4 projection may discontinuous whereas much easier handle closed intervals domains variables thus usually done projection constraint variable approximated let c j x also ji denote approximation order guarantee solutions numeric csp found solving algorithm uses needs includes exact projection also assume rest paper ji satisfies contractance property thus hides problems seen particular allows us go details relationships floating point real numbers see example 2 relationships consider real numbers remains build ji interval analysis 37 makes possible 211 interval arithmetic interval arithmetic 37 interval analysis built extension real arithmetic defines arithmetic functions intervals simple set extension semantics notation present interval arithmetic use following convention help reading x denote real variables vectors real variables xy denote interval variables vectors interval variables distinction scalar variable vector variables clear context notation arithmetic function intervals defined thanks monotonicity property arithmetic operators xy computed considering bounds intervals let xy xx arithmetic operators computed intervals follows 212 interval extension real function arbitrary function real numbers possible general compute exact enclosure range function 29 concept interval extension introduced moore interval extension function interval function computes outer approximations range function domain different interval extensions exist let f function real numbers defined variables x 1 x n following interval extensions frequently used natural interval extension real function f defined replacing real operator interval counterpart easy see contains range f thus interval extension example 1 natural extension x 2 natural extension x 2 2 natural extension x 2 taylor interval extension real function f interval vector x defined natural extension firstorder taylor development f 42 f nat f 2 intuition interval extension given footnote 2 example 2 taylor extension x x 2 let taylor extension taylor extension gives generally better enclosure natural extension small intervals 3 nevertheless general neither give exact range f example let 2 13 whereas range f x 0 34 3 2 taylor interval extension comes direct application mean value theorem let f real function defined continuous continuous derivative two points exists x 1 x 2 unknown done replace interval contains evaluate natural extension resulting expression thus know true every x 1 x 2 replace x 1 midpoint interval contains leads 2 generalization vectors result 3 taylor extension quadratic convergence whereas natural extension linear convergence see example 42 213 solution function constraint compute projection ji constraint c j variable x need introduce concept solution function expresses variable x terms variables constraint example constraint x z solution functions f assume solution function known expresses variable x terms variables constraint thus approximation projection constraint x given domain computed thanks interval extension solution function thus way compute nevertheless complex constraints may exist analytic solution example consider x log interest numeric methods presented paper precisely constraints cannot solved algebraically three main approaches proposed first one exploits fact analytic functions always exist variable express terms others appears one time constraint approach simply considers occurrence variable different new variable previous example would give log x way trivial compute solution function suffices know inverse basic operators example obtain f log x 2 f approximation projection constraint x computed intersecting natural interval extensions solution functions occurrences x c j last example could take log xexp x projection functions obtained way called nat paper second idea uses taylor extension transform constraint interval linear constraint nonlinear equation nat f x consider derivatives evaluated box contains x considered constant let c equation becomes nat f interval linear equation x contain multiple occurrences solution functions could extracted easily instead computing solution functions constraint without taking account constraints may prefer group together several linear equations squared system solving squared interval linear system allows much precise approximations projections computed see following section projection functions obtained way called tay example consider constraint x log using taylor form box obtain following interval linear equation log c log c cd unique solution function 1 dimensional linear equation straightforward x ba third approach 6 use analytical solution function instead transforms constraint c 1 k monovariable constraint c jl variable x obtained substituting intervals variables projection jj l computed thanks c jl smallest zero c jl interval consideration lower bound projection c j x j greatest zero c jl upper bound projection hence interval two zeros bounds gives approximation projection projection functions computed way called box 6 two extremal zeros c jl found monovariable version interval newton method 4 another problem inverse nonmonotonic function function intervals example range inverse function interval union possible extend interval arithmetic order handle unions intervals systems taken approach 2644 nevertheless approach may lead highly increasing number intervals two approaches commonly used consist computing smallest interval encompassing union split problem several subproblems intervals appear 22 filtering algorithm fixed point algorithms filtering algorithm generally seen fixed point algorithm following abstraction filtering algorithms used sequence k domains generated iterative application operator op r n see fig 1 operator op filtering algorithm generally satisfies following three properties op contractance op conservative cannot remove solutions op monotonicity conditions limit sequence k corresponds greatest fixed point operator op exists called closure denote op fixed point op may characterized property lcconsistency called local consistency alternatively op denoted lc algorithm achieving filtering lcconsistency denoted lcfiltering csp said lcsatisfiable lc filtering csp produce empty domain 4 general multivariable interval newton method briefly presented section 23 fig 1 filtering algorithms fixed point algorithms consistencies used numeric csps solvers categorized two main classes arcconsistencylike consistencies strong consistencies 23 arcconsistencylike consistencies numeric csp systems eg bnrprolog 40 interlog 1316 clpbnr 5 prologiv 15 unicalc 3 ilog solver 27 numerica 46 compute approximation arcconsistency 36 named 2bconsistency paper 5 2bconsistency states local property constraint bounds domains variables b 2bconsistency stands bound roughly speaking constraint c j 2bconsistent variable x bounds support domains variables c j wrt approximation given 2bconsistency defined notation 2bconsistent filtering algorithm achieves 2bconsistency derived fig 1 instantiating op operator 1 note operator op 2b applies vector ji operators operator 1 2bconsistency filtering operator op j1 fig 2 shows projection functions used 2bconsistency filtering algorithm reduce domains variables depending projection functions used obtain different 2bfiltering algorithms op nat operator op nat denote op 2b nat abstracts filtering algorithm presented 51732 two main differences abstraction implementations 1 classic implementations projection functions applied sequentially domain abstraction nonclassic 5 lot freedom choose ji definition 2bconsistency abstracts 2b consistency 32 boxconsistency 6 fig 2 2bfiltering constraint system x 2 implementations applied domain drawback increasing upper bound complexity advantage generating much regular sequences domains see section 32 2 implementations always applied ac3like optimization 36 consists applying iteration projection functions may reduce domain projection functions parameters variable whose domain changed applied sake simplicity ac3like optimization appear explicitly algorithm schema op box operator denotes op 2b uses box abstracts filtering algorithm presented 645 differences abstraction op tay operator denotes op 2b uses tay abstracts interval newton method 237 interval newton method controls precise way order projection functions computed used solving squared nonlinear equation systems 0 interval newton method replaces solving nonlinear squared system solving sequence interval linear squared systems linear system obtained evaluating interval jacobi matrix current domains considering firstorder taylor approximation nonlinear system resulting interval linear system typically solved interval gaussseidel method gaussseidel method associates constraint c variable x possible renaming variables loops applying projection functions ii summarize main differences abstraction implementation partial derivatives recomputed periodically step gaussseidel method apply projection functions realistic implementation interval newton method would correspond operator 2 follows 6 operator 2 interval newton operator op ii endfor note also general gaussseidel method converge towards solution interval linear system good convergence properties diagonallydominant matrices practice solving linear system preconditioning step achieved transforms jacobi matrix diagonally dominant matrix preconditioning consists multiplying interval linear equation matrix giving new linear system matrix typically inverse midpoint matrix nice property interval newton operator cases able prove existence solution op tay strict subset brouwers fixedpoint theorem applies states existence unicity solution cf 38 24 strong consistencies idea constraint satisfaction tackle difficult problems solving easyto solve subproblems constraints taken individually often worth global view generally leads better enclosure domains strong consistencies proposed solving csp 2122 adaptation numeric csps summarized section interval analysis methods op tay extensively use another kind global view preconditioning jacobi matrix nevertheless need strong consistencies although less crucial interval analysis methods may appear hard problems 43 strong consistencies first introduced discrete csps eg path consistency kconsistency 21 consistency 22 numeric csps 6 forloop corresponds one iteration gaussseidel method complete solving interval linear system practice useful 24 3bconsistency 32 kbconsistency 33 kbconsistency adaptation consistency numeric csp filtering kconsistency done removing domain values extended k variables kbconsistency ensures variable instantiated one two bounds csp k 1bsatisfiable refer operator 1 generally given definition 2 consistency ensures variable forced close one two bounds precisely distance less w csp k 1b wsatisfiable simplest presentation wconsistency refers 2bconsistency kb wconsistency say csp x dc wconsistent w k 1b wsatisfiable w k 1b wsatisfiable w respectively w denotes x c domain except replaced respectively replaced direct filtering operator op kb w underlying wconsistency uses kind proof contradiction algorithm tries increase lower bound proving closure k 1b wconsistency 1 w n empty tries decrease upper bound symmetric way 3bconsistency filtering algorithms used example interlog ilog solver numerica derived fig 1 instantiating operator op op 3b defined operator 3 operator 3 wconsistency filtering operator op filtering operator op kb w p k 3 defined follows op computed follows endfor fig 3 shows wfiltering uses 2bfiltering fig 3 3b wfiltering constraint system x 2 implementations using schema may optimized considerably need go details reader referred 32 initial algorithm 12 studies complexity unpublished implementation used years see example 30 efficient algorithm published 32 algorithm achieves boxconsistency closely related 3bconsistency indeed boxconsistency seen kind oneway 3bconsistency limited one constraint reader found 14 theoretical comparison boxconsistency 3bconsistency 3 acceleration filtering techniques question choosing best filtering algorithm given constraint system open problem preliminary answers may come observation fixed point algorithms suffer two main drawbacks tightly related existence slow convergences leading unacceptable response times certain constraint systems early quiescence 17 ie algorithm stops reaching good approximation set possible values focus paper first drawback acuteness varies according op operator op nat due local view constraints op nat often suffers early quiescence simplicity makes efficient operator compute many problems best solved filtering operator eg moreaux problem 46 first sight one could think slow convergence phenomena occur often op nat true early quiescence op nat far frequent slow convergence however op nat typically interleaved tree search called inside another higherorder filtering algorithm interleaved process slow convergence phenomena may occur considerably increase required computing time op box comments remain true op box although may take time computed may perform stronger pruning cases op tay interval newton operator one hand may efficient behavior may asymptotically quadratic convergence used near solution experience quadratic convergence essential compute precise roots nonlinear systems equations hand far solution jacobi matrix great chance singular typically leads early quiescence problem hence op tay really slow convergence problems needs expensive computation since preconditioning jacobi matrix needs compute inversion midpoint matrix problems like moreaux problem 46 huge dimension n 320 op tay expensive whereas op nat solution found quickly op wconsistency filtering algorithms may perform strong pruning making treesearch almost useless many problems example tried wfiltering transistor problem 4143 finds unique solution without search cpu time filtering search method used 41 also tried wfiltering benchmarks listed 45 solved without search p choice points made system unfortunately time slow convergence phenomena occur wfiltering different filtering algorithms thus complementary robust way solve problem probably use several together fixed point schema fig 1 operator op would result composition operators remainder section focus problem slow convergence occurs op nat op kb w observation many slow convergences algorithms led us notice kinds regularity often exist slow convergence phenomenon intuition regularities behavior algorithms could exploited optimize convergence seen section 2 filtering algorithms abstracted sequence interval vectors accelerating filtering algorithm thus consists transforming sequence another sequence hoping converges faster numerical analysis engineers use transformation methods unfortunately cannot sure reliability results change essence usual floatingpoint computation unreliability everywhere filtering techniques completeness results must guaranteed words solution csp lost thus question reliability becomes crucial leads us define reliable transformation definition 3 reliable transformation let n sequence complete set solutions sol ksol k let transformation let n n reliable transformation n wrt sol practical interest reliable transformation directly related ability accelerate greatest number sequences acceleration sequence traditionally defined terms improvement convergence order sequence convergence order characterizes asymptotic behavior sequences see section 32 formal definition convergence order addition convergence order practical criteria may importance like example time needed compute term sequence build reliable transformation accelerates original sequence exploit regularities sequence detect regularity filtering sequence general idea assume regularity continue appear following part sequence regularities looking allow computations saved first kind regularity may want exploit cyclicity section 31 summarizes previous work based idea another kind regularity caught extrapolation methods developed section 32 31 previous work dynamic cycle simplification subsection summarizes previous work 3435 built idea strong connection existence cyclic phenomena slow convergence precisely slow convergence phenomena move often cyclic phenomena transient period kind stabilization step main goal dynamically identify cyclic phenomena executing filtering algorithm simplify order improve performance subsection especially dedicated acceleration op nat op box algorithms direct use accelerated algorithms also leads significant gain speed wfiltering algorithms since typically require numerous computations approach could generalized identify cyclic phenomena wfiltering algorithms considering application op 2b may exist several projection functions perform reduction domain given variable op 2b performs intersection since domains intervals may 0 1 2 projection functions interest variable one gives greatest lower bound one gives lowest upper bound call projection functions relevant denote r set relevant projection functions thus 2b know advance r compute 2b efficiently applying relevant projection functions precisely case cyclic phenomenon say cyclic phenomenon period p n r ip r n big number consider r r i1 projection function r i1 due reduction domains performed projection functions r say f r j depends g r j denoted g f g f g computes projection variable belongs dependency graph graph whose vertices pairs f f r arcs dependency links see fig 4a assume cyclic phenomenon graph cyclic see fig 4b denotes steps mod according assumption two types simplification performed avoid application nonrelevant projection functions postpone projection functions vertex f successor dynamic dependency graph corresponds projection function postponed vertex removed dynamic dependency graph applying principle recursively remove noncyclic paths graph instance graph b fig 4 white arrows pruned vertex removed corresponding projection function pushed onto stack removing order must preserved suffices iterate simplified cycle fixed point reached fixed point reached evaluate stacked projection functions transformation corresponds two simplifications together clearly reliable transformation change convergence order general accelerating transformation 34 first experimental results reported gains fig 4 dynamic dependency graphs efficiency range 6 20 times faster 2bfiltering wfiltering complete experiments performed 23 sake simplicity first simplification applying relevant projection functions tried different combinations several improvements 2bfiltering tested problems fastest combination uses cycle simplification ratio cpu time varies 1 20 compared combination without cycle simplification 32 extrapolation previous section aims exploiting cyclicity way projection functions applied gain computation term n speed convergence n unchanged address accelerate convergence n n sequence intervals numerical analysis provides different mathematical tools accelerating convergence sequences real numbers extrapolation methods especially interesting purposes n sequence interval vectors exist extrapolation method accelerate interval sequences nevertheless interval seen two reals seen 2column matrix reals first column lower bounds second upper bounds thus apply existing extrapolation methods field extrapolation methods real number sequences first summarized deeper overview see 10 show use extrapolation methods accelerating filtering algorithms 321 extrapolation methods let n sequence real numbers sequence n converges limit lim n say numeric sequence n order r 1 exist two finite constants b 7 lim b quadratic sequence sequence order 2 say sequence linear lim convergence order enables us know exactly convergence speed sequence example 8 linear sequences obtain significant number every 2500 iterations whereas sequences order 101 number significant numbers doubles every 70 iterations examples show interest using sequences order r 1 accelerating convergence sequence n amounts applying transformation produces new sequence n n 7 details see 10 given 10 order present practical interest new sequence n must exhibit least particular classes convergent sequences n following properties 1 n converges limit n lim n 2 n converges faster n lim properties hold converging sequences particularly universal transformation accelerating converging sequences cannot exist 18 thus transformation accelerate limited class sequences leads us socalled kernel 8 transformation set convergent wellknown transformation iterated 2 process aitken 1 gives sequence n nth term kernel 2 process set converging sequences form aitkens transformation nice property 10 transforms sequences linear convergence sequences quadratic convergence apply transformation several times leading new transformation example apply 2 twice giving 2 n many acceleration transformations galgorithm algorithm algorithm overholtprocess multiple application transformations see 11 9 attempts build unifying framework transformation scalar transformations generalized vectoral matrix cases two kinds optimization filtering algorithms given first one makes direct use extrapolation methods leads transformation reliable second one reliable transformation 322 applying extrapolation directly let n sequence generated filtering algorithm naively apply extrapolation method directly main sequence n experimental results given rest paper scalar extrapolations consider element matrixeach bound domain independently others example scalar process uses bound domain last three different values extrapolate value 8 definition kernel given considers converging sequences accelerating directly convergence n dramatically boost convergence illustrated following problem 1000 0 1000 z 0 following table shows domain variable 278th 279th 280th 281st iterations 3bfiltering seconds sun sparc 5 precision obtained 278 314133342842583 314159265358979 applying aitkens process domains iterations 278 279 280 obtain domain precision extrapolated domain 10 14 precision obtained 5 hours 3bfiltering algorithm without extrapolation 314159265358977 314159265358979 lets take another example table 1 shows domain variables x first second third iterations 5b wfiltering precision obtained 10 6 table 5b wfiltering problem iteration domains x applying 2 process domain iterations 1 2 3 obtain domains precision extrapolated domain 10 19 precision obtained many hours wfiltering algorithm without extrapolation 893e19885e19 result surprising since following proposition theorem 1 convergence property aitkens process 7 apply 2 converges lim sequence converges quickly note solution provided aitkens process valid result x example shows extrapolation methods lose solutions extrapolated sequence may may converge limit initial sequence anomaly explained kernel transformation initial sequence belongs kernel sure extrapolated sequence converges limit furthermore intuition suggests initial sequence close kernel good hopes get limit however may case limits quite different cumbersome filtering algorithms must ensure solution lost propose reliable transformation makes use extrapolation 323 reliable transformation extrapolation reliable transformation presented section related domain sequences generated wfiltering algorithms sake simplicity deal 3b wfiltering generalisation straightforward transformation reliable thanks proofbycontradiction mechanism used 3b walgorithm tries provewith 2bfilteringthat solution exists subpart domain proof found subpart removed domain else subpart removed point may waste lot time trying find proof exist could predict good probability proof exist could save time trying find extrapolation methods job idea simply extrapolated sequence converges 2bsatisfiable csp quickly known probably good idea try prove 2bunsatisfiability done defining new consistency called consistency built upon existence predicate 2bpredict predicts 2bsatisfiability p2b stands 2b based prediction definition 4 p2bconsistency csp x dc p2bconsistent 2bconsistent 2bpredictd true op op fig 5 p 2bconsistency filtering schema may use extrapolation methods example 2 process thus prediction 2bpredictd may wrong proposition 1 know filtering algorithm p2bconsistency cannot lose solutions proposition 1 proof straightforward definition filtering algorithm achieves p2bconsistency fixed point algorithm op defined fig 5 main difference op 2b testing 2b satisfiability try function 2bpredict predict 2bsatisfiability extrapolation methods following idea algorithm schema fast3b wconsistency modified given operator 4 may obtain way algorithm schema fastkb wconsistency needs p kb operator applies extrapolator domains generated kb operator operator 4 let filtering operator op fast3b w defined follows op computed follows endfor following proposition means algorithm schema allows acceleration methods applied keeping completeness property filtering algorithms thus reliable transformation proposition 2 completeness fastkb walgorithm lose solutions proof built fact domain reduced proof k 1b wsatisfiability without extrapolationthat solution exists removed part table wfiltering results benchmarks problem nbr fastkb nbr kb time fastkb time kb brown caprasse 046 060 chemistry 061 069 neuro100 053 066 counterpart result improvements efficiency wfiltering compared wfiltering may less satisfactory improvement provided direct use extrapolation another counterpart greatest fixed point op fastkb w generally greater greatest fixed point op kb w practice overhead time always negligible improvement efficiency may vary 1 10 table 2 compares fast3bfiltering 3bfiltering problems taken 2346 gives ratios time time fastkb time kb number projection function calls nbr fastkb nbr kb two algorithms 4 related works two methods commonly used solving numeric csps seen reliable transformations preconditioning adding redundant constraints 41 preconditioning interval newton operator numeric csps allow general numeric problems expressed without limitation form constraints numerical analysis many specific cases numeric csps studied preconditioning squared linear systems equations among interesting results practical importance say linear system equation near 1 practice well conditioned system better solved ill conditioned one preconditioning methods transform system new system solution better conditioned first system solving better precision reliable computations solving original system classic preconditioning method consists multiplying two sides system approximate inverse thus b mb interval analysis interest preconditioning reliability already exists interval methods precision convergence already presented section 23 preconditioning key component interval newton method experimental results example see 2845 show effectiveness preconditioning solving squared nonlinear systems equations many theoretical results found 2283839 42 redundant constraints classic reliable transformation adding redundant constraints original constraint system approach often used discrete csps accelerate algorithms case interval analysis methods numeric csps since exploit fact system square artificial intelligence methods numeric csps benhamou granvilliers 4 propose add redundant polynomial constraints automatically generated depthbounded groebner bases algorithm 5 conclusion perspectives aim paper accelerate existing filtering algorithms led us concept reliable transformation filtering algorithms preserves completeness filtering algorithms two kinds reliable transformation proposed exploit regularities behavior filtering algorithms first one based cyclic phenomena propagation queue second one extrapolation method tries find numeric equation satisfied propagation queue solves first perspective detect kinds regularities exploit reliable transformation always intrinsic limitations example logarithmic sequences cannot accelerated extrapolation methods however case cyclic phenomena simplification may improve running time thus combining different reliable transformations try accumulate advantages transformation may high interest finally direction research could fruitful comes remark algorithms designed efficiency simplicity mind regularity never considered issue perhaps time consider issue try make regular existing algorithms order exploit new regularities acknowledgements would like thank christian bliek michel rueher patrick taillibert constructive comments early draft paper kathleen callaway lot english corrections work partly supported ecole des mines de nantes r bernoullis numerical solution algebraic equations introduction interval computations automatic generation numerical redundancies nonlinear constraint solving applying interval arithmetic real clpintervals revisited algorithmes dacclration de la convergence tude numriques derivation extrapolation algorithms based error estimates extrapolation methods general extrapolation procedure revisited improved bounds complexity kbconsistency constraint logic programming numeric intervals note partial consistencies continuous domains solving techniques interlog 10 guide dutilisation constraint propagation interval labels arc consistency continuous variables local consistency ternary numeric constraints sufficient condition backtrackbounded search consistances locales et transformations symboliques de contraintes dintervalles global optimization using interval analysis consistency techniques continuous constraints constraint reasoning based interval arithmetic tolerance propagation approach ilog solver 40 continuous problems computational complexity feasibility data processing interval computations acceleration methods numeric csps consistency techniques numeric csps dynamic optimization interval narrowing algorithms boosting interval narrowing algorithm consistency networks relations interval analysis interval methods systems equations simple derivation hansenbliekrohnningkearfott enclosure linear interval equations extending prolog constraint arithmetic real intervals constraints satisfaction approach circuit design problem computer methods range functions experiments using interval analysis solving circuit design problem hierarchical arc consistency applied numeric constraint processing logic programming solving polynomial systems using branch prune approach modeling language global optimization tr sufficient condition backtrackbounded search constraint propagation interval labels constraint reasoning based interval arithmetic arcconsistency continuous variables clpintervals revisited derivation extrapolation algorithms based error estimates solving polynomial systems using branch prune approach acceleration methods numeric cspc synthesizing constraint expressions constraint satisfaction approach circuit design problem note partial consistencies continuous domains ctr yahia lebbah claude michel michel rueher using constraint techniques safe fast implementation optimalitybased reduction proceedings 2007 acm symposium applied computing march 1115 2007 seoul korea yahia lebbah claude michel michel rueher rigorous global filtering algorithm quadratic constraints constraints v10 n1 p4765 january 2005