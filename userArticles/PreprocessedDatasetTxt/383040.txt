querybased sampling text databases proliferation searchable text databases corporate networks internet causes database selection problem many people algorithms ggloss cori automatically select text databases search given information need given set resource descriptions accurately represent contents database existing techniques acquiring resource descriptions significant limitations used widearea networks controlled many parties paper presents querybased sampling new technicque acquiring accurate resource descriptions querybased sampling require cooperation resource providers require resource providers use particular search engine representation technique extensive set experimental results demonstrates accurate resource descriptions crated computation communication costs reasonable resource descriptions fact enable accurate automatic dtabase selection b table 1 size size name bytes documents cacm 2mb 3204 test corpora size size unique total terms terms variety 6468 117473 homogeneous 122807 9723528 heterogeneous heterogenenous choices deferred later sections paper best represent large document database open problem however much prior research based simple resource descriptions consisting term lists term frequency term weight information information number documents 15 14 36 number words 7 39 40 contained resource zipfs law heaps law suggest relatively accurate estimates rst two pieces information term lists relative frequency term acquired sampling 20 43 clear whether size resource estimated querybased sampling also clear information actually required accurate database selection return point later paper hypothesis motivating work su ciently accurate resource descriptions learned sampling text database simple freetext queries hypothesis tested twoways 1 comparing resource descriptions learned sampling known databases learnedresource descriptions actual resource descriptions databases 2 comparing resource selection accuracy using learned resource descriptions resource selection using actual resource descriptions types experiments conducted discussed 4 experimental results description accuracy rst set experiments investigated accuracy learned resource descriptions function number documents examined experimental method based comparing learned resource descriptions known databases actual resource descriptions databases goals experiments determine whether querybased sampling learns accurate resource descriptions combination parameters produce fastest accurate learning secondary goal study sensitivity querybased sampling parameter settings following sections describe data type resource description used metrics parameter settings nally experimental results 41 data three fulltext databases used cacm small homogeneous set titles abstracts scienti c articles communications acm querybased sampling text databases 7 wsj88 1988 wall street journal mediumsized corpus american newspaper articles1 trec123 large heterogeneous database consisting trec cds 1 2 3 contains newspaper articles magazine articles scienti c abstracts governmentdocuments standard test corpora used bymany researchers characteristics summarized table 1 42 resource descriptions experiments conducted resource descriptions consisting index terms usually words document frequencies df number documents containing term stopwords discarded learned resource descriptions con structed however testing learned actual resource descriptions compared words appeared actual resource descriptions e ectively discarded learned resource description anyword considered stopword database databases used default stopword list inquery ir system 34 33 6 whichcontained 418 frequent closedclass words xes removed words stemming resource descriptions constructed however controlled testing su xes removed prior comparison actual resource description actual resource descriptions database indexes stemmed 43 metrics resource descriptions consisted twotypes information vocabulary frequency information eachvocabulary term correspondence learned actual vocabularies measured metric called ctf ratiothe correspondence learned actual frequency information measured spearman rank correlation coe cienteach metric described 431 measuring vocabulary correspondence ctf ratio terms learned resource description necessarily subset terms actual description one could measure howmany database terms found learning metric skewed many terms occurring twice collection 43 20 desired metric gave emphasis frequentand moderatelyfrequent terms whichwe believeconvey information contents database ctf ratio proportion term occurrences database covered terms learned resource description learned vocabulary v 0 actual vocabulary v ctf ratio 1the 1988 wall street journal data wsj88 included trec cd 1 wsj88 10 text trec cd 1 8 j callan connell table 2 ctf ratio example actual resource description learned resource descriptions vocabulary ctf vocabulary ctf ratio apple 4 bear 1 cat 3 dog 2 ctfi number times term occurs database collection term frequencyorctf ctf ratio 80 means learned resource description contains terms account 80 term occurrences database example suppose database consists 4 occurrences apple 1 occurrence bear 3 occurrence cat 2 occurrences dog table 2 learned resource description contains word apple 25 actual vocabulary terms ctf accounts 40 word occurrences database learned resource description contains apple cat ctf ratio 70 ctf ratio measures degree learned resource description contains words frequentin actual resource description note ctf ratios reported paper arti cially ated nding stopwords ctf ratio always computed stopwords removed 432 spearman rank correlation coe cient second component resource description document frequency information df indicates relative importance term describing database accuracy frequency information determined either comparison learned actual df values appropriate scaling comparison frequencybased term rankings produced learned actual df values two measurementmethods emphasize di erentcharacteristics frequency information direct comparison df values undesirable characteristic comparison biased favor estimates based larger amounts information estimates based 10n documents enable n digits accuracy scaled values characteristic concern even relatively noisy df estimates based small numbers documents might su cient enable accurate resource selection rankings produced learned actual df values compared spearman rank correlation coe cient accepted metric comparing two orderings spearman rank correlation coe cient de ned di rank di erence common term n number terms fk number ties kth group ties learned resource description gm number ties mth group ties actual resource description two orderings identical rank correlation coe cient 1 querybased sampling text databases 9 uncorrelated coe cient 0 reverse order coe cientis1 complexity variant spearman rank correlation coe cientmay readers simpler versions common eg 28 however simpler versions assume total ordering ranked elements two elements cannot share ranking term rankings many terms identical frequencies hence identical rankings variants spearman rank correlation coe cient ignore e ects tied rankings give misleading results case initial research querybased sampling 5 spearman rank correlation coe cientwas computed using terms intersection v v 0 use intersection appropriate spearman rank correlation coe cient used discover whether terms v 0 ordered appropriately learned frequency information database selection require rank correlation coe cient 10 su cient learned resource description represent relative importance index terms database degree accuracyfor example might su cienttoknow ranking term 5 although database selection algorithms likely insensitive small ranking errors open question howmuch error given algorithm tolerate selection accuracy deteriorates 44 parameters experiments querybased sampling require making choices howquery terms selected howmany documents examined per query experiments rst query run database determined selecting term randomly trec123 vocabulary initial query could selected using criteria example selecting frequent term could selected another resource several informal experiments found choice initial query term minimal e ect quality resource description learned speed learning long retrieved least one document subsequent query terms chosen byavariety methods described following sections however cases terms chosen subject requirements similar placed index terms many text retrieval systems term selected query term could number required 3 characters long hypotheses guide decision howmany documents sample per database query instead series experiments conducted determine e ect varying parameter experiments presented belowwere ended examining 500 documents stopping criteria chosen empirically running several initial experi ments biased interest learning resource descriptions small ideally constant sized samples several experiments database continued several thousand documents sampled ensure nothing unusual happened j callan connell ctf ratio 00 spearman rank correlation number documents examined number documents examined b fig 1 measures howwell learned resource description matches actual resource description fulltext database percentage database word occurrences covered terms learned resource description b spearman rank correlation coe cientbetween term rankings learned resource description database four documents examined per query point average 10 trials 45 results four sets experiments conducted study accuracy resource descriptions learned variety conditions rst set experiments initial investigation querybased sampling parameter settings discussed call baseline experiments second set experiments studied e ect varying number documents examined per query third set experiments studied e ect varying way query terms selected fourth set experiments studied e ect varying choice collection documents picked set experiments discussed separately 451 results baseline experiments baseline experiments initial investigation querybased sampling goal baseline experiments determine whether querybased sampling produced accurate resource descriptions accuracy varied function total number documents examined initial query term selected randomly trec123 resource de scription described subsequent query terms selected randomly resource description learned top four documents retrieved byeach query examined update resource description duplicate documents documents retrieved previously another querywere discarded hence queries produced fewer four documents ten trials conducted starting di erent randomly selected query term compensate e ects random query term selection experimental results reported averages results returned ten trials querybased sampling text databases 11 table 3 e ect varying number documents examined per query howlongittakes sampling method reachactf ratio 80 documents cacm wsj88 trec123 per total total total query docs spearman docs spearman docs spearman variation measurements obtained trial particular database large 10 15 50 documents decreased rapidlyat150 documents 4 5 250 documents 2 4 consistency among trials suggests choice initial query term particularly important long returns least one document e ects di erent strategies selecting subsequent query terms addressed section 453 figure 1a shows querybased sampling quickly nds terms account 80 nonstopword term occurrences collection2 250 documents new vocabulary discovered consists terms relatively rare corpus consistent zipfs law 43 figure 1b shows degree agreementbetween term orderings learned actual resource descriptions measured spearman rank correlation coe cient high degree correlation learned actual orderings observed collections seeing 250 documents correlation observed largest collection trec123 less correlations observed smaller collections cacm wsj88 extending number documents sampled beyond 500 substantially improve correlation measure large collection results metrics support hypothesis accurate resource descriptions learned examining small fraction collection result encouraging suggests querybased sampling viable method learning accurate resource descriptions 452 results varying sample size baseline experiments sampled four highly ranked documents retrieved queryhowever sampling process could retrieved documents fewer documents per querydoing could change number queries documents required achieveagiven level accuracy turn could ect costs running algorithm series experiments conducted investigate e ects varying number documents examined per queryvaluesof12468and10docu ments per query tested prior experiment ten trials conducted eachvalue trial starting di erent randomly selected query term 2recall stopwords excluded comparison stopwords included comparison rate convergencewould considerably faster j callan connell ctf ratio cacm data cacm data 4 docs qry 8 docs qry 00 spearman rank correlation number documents examined number documents examined b ctf ratio wsj88 data wsj88 data 4 docs qry 8 docs qry 00 spearman rank correlation number documents examined number documents examined c ctf ratio data trec123 data 4 docs qry 8 docs qry 00 spearman rank correlation number documents examined number documents examined fig 2 measures howwell learned resource description matches actual resource description fulltext database pointistheaverage 10 trials c e percentage database word occurrences covered terms learned resource description b correlation coe cientbetween term rankings learned resource description database querybased sampling text databases 13 subsequent query terms chosen randomly resource description learned experimental result reported belowisanaverage experimental results ten trials varying numberofdocuments per query little e ect speed learning measured average number documents required reacha given level accuracy indeed e ect small di cult display results di erentvalues single graph figure 2 shows results values 1 4 8 documents per query database results valuesof26and similar table 3 provides another perspective experimental results shows number documents required reachactf ratio 80 varying number documents examined per query 1 10 caused minor variations performance 2 3 databases careful study reveals examining documents per query results slightly faster learning fewer queries required small homogeneous cacm database examining fewer documents per query results somewhat faster learning larger heterogeneous trec123 database however e ects varying number documents per query average small noticeable e ect examining fewer documents per query results moreconsistent learning speed databases greater variation among ten trials documents examined per query 3 5 1 documentwas examined per query 1 3 experiment larger samples worked well small homogeneous col lection smaller samples worked well large heterogeneous collection nd result surprising samples biased queries draw documents within sample necessarily similar extent would expect many small samples would better approximate random sample fewer large samples collections signi cant heterogeneitythe results support intuition 453 results varying query selection strategies baseline experiments select query terms randomly resource description learned selection criteria could used terms could selected sources one hypothesis would best select terms appear occur frequently collection ie words nearly frequentenoughtobe stopwords would return random sample documents tested hypothesis selecting frequent query terms measured document frequency df collection term frequency ctf average term frequency avg tf ctf df one early concern learned resource descriptions would strongly biased set documents happened examined rst bias would reinforced selecting additional query terms learned resource description solution would select terms di erent complete resource description hypothesis named resource description ord hypothesis compared default learnedresource description lrd approach used experiments complete trec123 resource description served resource description 14 j callan connell ctf ratio df ord df ord ctf ord ctf ord 00 spearman rank correlation number documents examined number documents examined b ctf ratio df lrd df lrd ctf lrd ctf lrd 00 spearman rank correlation number documents examined number documents examined c fig 3 measures di erent query selection strategies ect accuracy learned resource description c percentage database word occurrencescovered byterms learned resource description b spearman rank correlation coe cientbetween term rankings learned resource description database 1988 wall street journal database four documents examined per queryeachpoint random lrd curves average 10 trials choice trec123 resource description mightbechallenged wsj88 subset trec123 possible trec123 mightbea biased unrealistically good resource description select terms sampling wsj88 wewere aware possible bias prepared conduct thorough experiments initial results appeared con rm resource description hypothesis series experiments conducted following experimental methodology used previous experiments except query terms selected query terms selected either randomly based one frequency criteria either learned resource description lrd resource description ord four documents examined per queryten trials conducted querybased sampling text databases 15 table 4 di erencesbetween selectingquery terms resource description ord learned resource description lrd signi cantatabove point curves figure 3 di erence selecting ord lrd resources becomes statistically signi cant test p 001 values learned resource descriptions random selection method averages 10 trials ctf ratio selection signi cant 100 documents 200 documents 300 documents method ord lrd ord lrd ord lrd avg tf 20 docs 08651 08026 08989 08552 09130 08779 random 20 docs 08452 07787 08859 08401 09067 08678 ctf 190 docs 07920 07774 08412 08310 08625 08558 df method selected query terms randomly learned resource description lrd compensate random variation order e ects experiments conducted three collections results su ciently similar results wsj88 collection presented experiments selecting terms resource description produced faster learning measured bythenumberofdocuments required reach agiven level accuracy figure 3 di erences statistically signi cant four term selection methods test p 001 however di erences relatively large avg tf random selection methods statistically signi cant 20 documents observed di erences small ctf df selection methods required 130 190 documents respectively achieve statistical signi cance table 4 might value using resource description avg tf random term selection methods appears little value ctf df selection methods one weakness selecting query terms resource description provide terms appear target resource vocabulary query terms characteristic particularly noticeable avg tf random term selection avg tf random selection resource description produced accurate results table 4 required many queries retrieveagiven number unique documents due vocabulary queries table 5 recall also resource description trec123 superset target database wsj88 number failed queries mighthave higher resource description less similar database experiments demonstrate selecting query terms learned resource description opposed complete resource description produce strongly skewed sample documents indeed random avg tf selection query terms learned resource description provided best balance accuracy e ciency experiments worstcase behav ior obtained resource description poor match target resource would also favor selecting terms learned resource description experiments also demonstrate selecting query terms randomly learned resource description e ective selecting based high frequency result surprise hypothesis high j callan connell table 5 number queries required retrieve 300 documents using di erent query selection criteria selection random random avg tf avg tf df df ctf ctf strategy ord lrd ord lrd ord lrd ord lrd number queries 378 84 6673 112 78 154 77 154 frequency terms would either occur manycontexts would relatively weak contexts producing random sample hypothesis supported experiments 454 results varying databases sampled results experiments described preceding sections support hypothesis database contents determined query based sampling however rule competing hypothesis relatively random sample documents nearly american english database would produce equally accurate description three test databases perhaps experiments merely reveal properties american discourse example certain words used commonly competing hypothesis true querybased sampling necessary partial description relatively similar resource would produce similar results lower computational cost importantlyitwould cast doubt whether partial resource descriptions distinguish databases su ciently enable accurate database selection partial resource descriptions american english databases similar database selection algorithm would presumably great di culty identifying databases best match speci c information need series experiments conducted test hypothesis relatively random samples documents di erent american english database would produce equally accurate descriptions three test databases experimental method consisted comparing resource descriptions created querybased sampling various databases actual complete resource description test databases example resource descriptions created querybased sampling cacm wsj88 trec123 databases compared actual description cacm database figures 4a 4b hypothesis would supported learned resource descriptions roughly comparable howwell matched actual complete resource description particular database experiments conducted cacm wsj88 trec123 databases comparisons performed 300500 examined documents experimental results summarized figure 4 experimental results indicate description learned one resource particularly large resource contain vocabulary occurs frequently resources example resource descriptions learned trec123 database contained vocabulary frequent presumably important wsj88 cacm databases figures 4a 4c results also suggest prior knowledge database characteristics might required decide descriptions use database cacm resource description example lacked much vocabulary important wsj88 trec123 querybased sampling text databases 17 ctf ratio0907050301 cacm database actual cacm database actual080604 cacm learned 03 cacm learned 00 spearman rank correlation number documents examined number documents examined b ctf ratio0907050301 wsj88 database actual wsj88 database actual080604 cacm learned 03 cacm learned 00 spearman rank correlation number documents examined number documents examined c ctf ratio0907050301 database actual trec123 database actual080604 cacm learned 03 cacm learned 00 spearman rank correlation number documents examined number documents examined fig 4 measures howwell learned resource descriptions three di erent databases match actual resource description given database c e percentage actual database term occurrences covered terms di erent learned resource descriptions b f spearman rank correlation coe cientbetween actual term rankings term rankings di erent learned resource description four documents examined per query j callan connell resources figures 4c 4e problem using description learned one resource describe another di erent resource apparent relative term frequency con sidered relative term frequency important indicates terms common database database selection algorithms prefer databases query terms common experiments relative frequency vocabulary items three test databases rarely correlated figures 4b 4d 4f example neither wsj88 trec123 databases gavean accurate indication relative term frequency cacm database figure 4b likewise neither cacm trec123 database gave accurate indication term frequency wsj88 database figure 4d one exception trend wsj88 database appear give relatively accurate indication relative term frequency trec123 database figure 4f 3 experiments refute hypothesis experimental results earlier sections based upon language patterns common across di erent collections american english text may considerable overlap vocabulary among di erent databases also considerable di erences relative frequencies terms database example term com puter occurs three databases relative frequency much higher cacm database wsj88 trec123 databases postexperiment analysis indicates improved experimental methodology would provide even stronger evidence refuting alternate hypothesis ctf ratio measure fact description learned trec123 contains many terms cacm database figure 4a hence ctf ratio results figures 4a 4c 4e overstate degree learned vocabulary one database ects actual vocabulary di erent database large dictionary american english would yield ctf ratio close 10 three databases people would argue accurately described anyofthem 5 experimental results selection accuracy experiments described previous section investigate howquickly reliably learned resource description database converges upon actual resource description however knowhow accurate resource description needs accurate resource selection indeed wedonoteven knowthat description accuracy correlated selection accuracy although wepresume second group experiments investigated accuracy resource selection function number documents examined experimental method based comparing e ectiveness database ranking algorithm using complete learned resource descriptions databases ranked inquery ir systems default database ranking algorithm 7 following sections describe data type resource description used metrics parameter settings nally experimental results 3this exception may caused fact 10 trec123 database consists wall street journal data querybased sampling text databases 19 table 6 summary statistics 100 databases testbed resource documents per database bytes per database description minimum average maximum minimum average maximum actual 752 10782 39723 28070646 33365514 41796822 learned 300 300 300 229915 2701449 15917750 51 data trec123 database described section 41 divided 100 smaller databases roughly equal size 33 megabytes varying number documents contained table 6 database contained documents single source ordered found trec cds hence documents database also usually similar timeframes cd 1 contributed 37 databases cd 2 contributed 27 databases cd 3 contributed 36 databases queries based trec topics 51150 17 used query sets inq001 inq026 created umass ciir part participation trec2 tipster 24 month evaluations 6 queries query sets long complex undergone automatic query expansion relevance assessments standard trec relevance assessments supplied us national institute standards technology 17 52 resource descriptions experiment used 100 resource descriptions one per database resource description consisted list terms document frequencies df previous experiments terms stopword list 418 common closedclass words discarded remaining terms stemmed kstem 21 53 metrics several methods proposed evaluating resource selection algorithms appropriate needs recalloriented metric called measures percentage relevant documents contained n topranked databases4 r de ned ni 1ri ni 1ri n number databases searched n total number databases ri number relevantdocuments contained bytheith database r isacumulative searching top 3 databases always returns least many relevant documents searching top 2 databases r desirable metric accuracy database ranking algorithm measured independently system components goal rank databases containing many relevant documents ahead databases containing relevant documents 4the metric called r called r 23 use recent widely known name r paper j callan connell r complete learned 700 docs learned 300 docs learned 100 docs 0 complete learned 700 docs learned 300 docs learned 100 docs percentage collections searched percentage collections searched b fig 5 measures collection ranking accuracy using resource descriptions varying accuracy topics 51100 trec query set inq026 b topics 101150 trec query set inq001 4 documents examined per query trec volumes 1 2 3 54 parameter settings experiments section 4 suggested relatively small sample size e ective di erentchoices produce small variations results chose sample size four 4 documents per query consistent baseline results previous experiments query terms chosen randomly learned resource description baseline experiments unclear experiments section 4 enough samples taken wechose build resource descriptions samples 100 documents queries 300 documents 75 queries 700 documents 175 queries database order cover space reasonable numbers samples results varied dramaticallywewere prepared conduct additional experiments collection ranking algorithm forces us set one additional parameter collection ranking algorithm normalizes term frequency statistics dfij using length words collection cwj 7 however knowhow estimate collection size querybased sampling experiments term frequency information df normalized using length words set sampled documents used construct resource description 55 experimental results experimental results summarized two graphs figure 5 one per query set baseline graph curveshowing results actual resource description complete resource descriptions best result collection ranking algorithm produce given complete description collection interest di erence achieved complete information achieved incomplete information graphs showonlya small loss e ectiveness resource descriptions based 700 documents querybased sampling text databases 21 losses grow less information used loss small compared information reduction accuracy low recall ie 1020 databases searched quite good even resource descriptions based 100 documents results consistent results presented section 4 earlier experiments showed term rankings learned actual resource descriptions highly correlated examining 100300 documents experimental results also demonstrate possible rank databases without knowing sizes size pool documents sampled database e ective surrogate actual database size tests testing reveal whether result general characteristic cori database selection algorithm quirk due 100 database testbed distribution database sizes testbed ranged 752 documents 39723 documents 28 megabytes 42 megabytes table 6 thorough study characteristic would require testbeds wider variety size distributions 6 experimental results retrieval accuracy experiments described previous section demonstrate resource descriptions learned querybased sampling enable accurate resource ranking accurate resource ranking generally viewed prerequisite accurate document retrieval guarantee nal document ranking depends upon results di erent databases merged uenced bythe quality resource descriptions database third group experiments investigated accuracy document retrieval presence learned resource descriptions experimental method based comparing accuracy nal document rankings produced distributed system uses complete learned resource descriptions make decisions search databases ranked selected searched results merged nal document ranking inquery ir systems default database ranking result merging algorithms 7 61 data data consisted 100 databases used test database selection accuracy section 51 provides details 62 resource descriptions database described learned resource description created sample 300 documents done experiments 4 documents per queryquery terms chosen randomly learned resource description sample size 300 documents chosen previous experiments provided reasonably accurate resource descriptions relatively low cost 75 queries per database 100 resource descriptions one per database consisted list terms document frequencies df previous experiments terms stopword list 418 common closedclass words discarded remaining terms stemmed kstem 21 22 j callan connell 63 metrics e ectiveness archival search systems often measured either precision speci ed documentranksorby precision speci ed recall points precision speci ed recall points eg 11point recall standard manyyears normalizes results based number relevant documents results easy queries many relevantdocuments hard queries relevantdoc uments comparable however many relevantdocuments case large databases precision speci ed recall points focuses attention results irrelevanttomany search patrons eg rank 50 100 precision speci ed document ranks often used emphasis results person would see rst screens interactive system precision rank n de ned rr rr number retrieved relevantdocuments ranks 1 n precision experiments measured ranks 5 10 15 20 uments common experiments trec data 17 values indicate accuracy would observed various points rst twoor three screens interactive system 64 parameter settings inquery system parameters set default values experi ment choices made experiments decisions howmany databases search howmany documents return database inquerysearched 10 databases ranked highly query byits database selection algorithm number10was chosen used recent research distributed search inquery system 39 database selection algorithm ranked databases using either learned resource descriptions complete resource descriptions determined bythe experimenter searched database returned highly ranked documents number chosen precision measured beyond rank 30 returned documents 10 merged using inquerys default algorithm merging multidatabase search results algorithm merging results multiple searches based estimating idfnormalized score d0 document score collection score c ds dmin dmax dmin 5 dmax dmin maximum minimum possible scores anydocu ment database could obtain particular queryandcmax cmin querybased sampling text databases 23 table 7 precision search system using complete learned resource descriptions database selection result merging trec volumes 1 2 3 divided 100 databases 10 databases searched eachquery topics 51100 query set inq026 topics 101150 query set inq001 complete learned complete learned document resource resource resource resource rank descriptions descriptions descriptions descriptions maximum minimum scores collection could obtain particular query scaling compensates fact system like inquery theory produce document scores range 0 1 practice tfidf algorithm makes mathematically impossible documenttohave score outside relatively narrow range dmin cmin usually 04 dmax cmax usually 06 exact values querydependent calculated setting tf componentofthetfidf formula 00 10 every query term 4 although theoretical justi cation heuristic normalization weak e ective practice 1 2 4 22 used inquery since 1995 65 experimental results ranked either index complete resource descriptions baseline condition index learned resource descriptions test condition searched returned documents result lists returned database merged produce nal result list documents scores used rank databases determined value c equation 6 precision measured ranks 5 10 15 20 documents experimental results summarized table 7 experimental results indicate distributed multidatabase retrieval e ective learned resource descriptions complete resource descriptions precision one query set inq026 topics 51100 averaged 48 higher using learned descriptions range 20to72 precision query set inq001 topics 101150 averaged 32 lower using learned descriptions range 11 61 improvement loss small person notice experimental results extend results section 5 indicated using learned resource descriptions rank collections introduced small amount error ranking process one might argue amountof error small cause noticeable change search results evidence support argument results demonstrate small errors introduced learned resource descriptions noticeably reduce accuracy nal search results accuracy document ranking depends also merging results j callan connell table 8 comparison 50 frequent terms measured document frequencyin text database learned resource description constructed database 1988 wall journal database 300 documents examined 4 documents per query text learned text learned rank database vocabulary rank database vocabulary million company 26 group york new million 27 concern operate 3 company new 28 exchange stock 4 make make 29 high hold executive 6 base base 31 operate close 7 business business price group 8 two market 33 unit international 9 trade co 34 increase increase hold general president 36 billion time close two 37 end exchange president billion 38 yesterday sale 14 stock say 39 product change interest result er service month share 42 recent manage us unit 43 america made 19 sta plan 44 manage work report expect 45 current america plan three 46 part buy 22 say trade national interest 48 bank expect product 49 executive end di erent collections accurately experimental results indicate learned resource descriptions support activityaswell result important inquerys result merging algorithm estimates normalized document score function collections score documents score respect collection results indicate collections ranked appropriately using learned descriptions scores used rank highly correlated scores produced complete resource descriptions evidence querybased sampling produces accurate resource descriptions 7 peek inside summarizing database contents interest primarily automatic method learning resource descriptions su ciently accurate detailed use automatic database selection algorithms however resource description also used indicate person general nature given text database simplest method display terms occur frequently querybased sampling text databases 25 table 9 covered combined health information database aids education disease prevention health promotion alzheimers disease epilepsy education prevention arthritis musculoskeletal skin diseases health promotion education cancer patient education kidney urologic diseases cancer prevention control maternal child health complementary alternative medicine medical genetics rare disorders deafness communication disorders oral health diabetes prenatal smoking cessation digestive diseases weight control stopwords method e ective database sense guaranteed words occur often example list top 50 words found sampling 1988 wall street journal table 8 contains words market interest trade million stock exchange indeed suggestiveoftheoverall subject database table 8 also compares top 50 words learned resource description top 50 words database demonstrates 300 documents learned resource description reasonably representativeofthevocabulary target text database representative relative importance ranks terms example 76 agreement top 50 terms seeing 300 documents controlled experiments essential understanding characteristics new technique less controlled real world experimentscanalsoberevealing simple database sampling system built test algorithm databases found web program tested initially microsoft customer support database time understood less e ective parameter settings accurate resource descriptions learned cost examining many documents 5 wechose paper reproduce earlier experiment easily accessible web database using sampling parameters consistent parameter settings described elsewhere paper combined health information database 29 published several healthrelated agencies us government national institutes health centers disease control prevention health resources services administration selected database contains healthrelated information topics summarized table 9 initial query term chosen randomly trec123 database subsequent query terms chosen randomly resource description learned four documents examined per query experimentwas ended 300 documents examined terms resource description sorted collection term frequency ctf top 100 terms displayed results shown table 10 one see easily database contains documents healthrelated topics terms hiv aids health prevention risk cdc trans mission medical disease virus drug immunode ciency showup 26 j callan connell table 10 top 100 words found sampling us national institutes health nih combined health information database terms ranked collection term frequency ctf sampled documents 300 documents examined 4 documents per query hiv 1931 254 lg 296 296 control 168 86 aids 1561 291 mj 296 296 department 166 90 health 1161 237 296 296 notes 163 163 prevention 666 195 veri cation 296 296 nt 163 163 education 534 293 yr 296 296 state 160 64 information 439 184 code 295 292 program 158 80 persons 393 174 english 294 280 video 148 number 384 296 ac 292 292 acquired 144 140 author 370 294 physical 282 267 de ciency 139 137 material 361 293 print 281 257 research 138 74 document 356 296 treatment 280 127 syndrome 138 138 human 355 212 cn 279 279 factors 137 95 source 346 296 corporate 279 279 drugs 132 68 report 328 89 description 278 266 united 132 80 accession 323 296 pd 266 266 centers 131 67 public 323 156 programs 264 112 world 131 55 update 317 296 organizations 261 126 box 130 121 community 313 107 positive 254 150 cdc 128 75 language 310 296 care 248 83 children 122 45 services 310 129 virus 246 192 patient 119 42 descriptors 308 296 disease 241 120 center 118 67 format 308 296 service 241 133 people 117 68 major 305 296 discusses 226 152 agencies 112 national 304 132 provides 226 154 government 112 63 transmission 304 114 professionals 217 167 nations 112 41 published 303 296 medical 212 117 describes 110 87 audience 302 293 immunode ciency 193 180 organization 109 51 availability 302 293 drug 190 74 sex 108 abstract 299 296 risk 185 99 std 107 50 date 299 296 issues 182 96 counseling 106 50 chid 297 296 brochure 180 54 refs 103 103 sub le 297 296 immune 179 144 surveillance 103 35 ab 296 296 examines 173 132 fm 296 296 women 171 61 high list several frequentwords appear indicate little database contents update published format abstract terms could removed using larger stopword list however general unclear whichwords multidatabase environment considered stopwords since words unimportant one database maybecontentwords others querybased sampling text databases 27 table 11 top 50 words found sampling trec123 terms ranked documentfre quency df sampled documents 500 documents examined 4 documents per query two 460 159 say 228 94 plan 163 79 new 553 158 made 246 94 million 199 79 time 437 135 result 249 93 end 556 78 three 269 128 information 706 93 allow 190 78 system 1609 122 develop 525 91 month 222 78 base 421 115 accord 322 91 set 278 77 high 585 115 service 468 90 manage 302 77 make 254 115 general 479 87 national 209 77 state 446 114 call 432 86 change 311 76 report 336 104 number 292 86 long 153 76 product 549 103 company 304 85 problem 170 75 part 371 101 show 223 83 line 271 75 group 513 101 president 339 82 close 207 75 work 256 98 require 432 80 increase 173 75 relate 269 96 people 181 79 second 882 75 operate 396 95 support 283 79 order 236 74 follow 262 94 data 608 79 particular resource description based simple approachto tokenizing case conversion stopword removal example terms converted lower case hence distinguish among terms di er case aids aids distinction important particular database illustrates issues real world system must address appropriate lexical processing necessarily major barrier accuracy real world settings probably requires addressed wall street journal combined health information databases homogeneous varying degrees whichmaymake easier summarize contents brief lists frequent terms summarization technique may less e ective larger heterogeneous databases trec123 top 50 words trec123 database table 11 provide evidence database contains documents us national business news would di cult draw rm conclusions database contents list words alone although simple word lists e ective summarizing database contents situations necessarily e ectivetechniques frequent phrases common relationships better indeed one consequence sampling approach creating learned resource descriptions makes powerful summarizations possible sampling process restricted word lists frequency tables restricted information database chooses provide instead set several hundred documents mine frequent phrases names dates relationships interesting information information likely enable construction powerful informative summaries possible simple resource descriptions used cooperative methods 28 j callan connell 8 uses set documents sampled single database ects contents database one use documents build resource description single database described however uses possible one potential use query expansion database recent research showed query expansion signi cantly improves accuracy database selection 39 stateoftheart query expansion based upon analyzing searched corpus cooccurrence patterns database used task database selection question unanswered documents sampled database combined query expansion corpus result would set documents ects contents word cooccurrence patterns across available databases would require little additional e ort database selection service create query expansion database manner cooccurrencebased query expansion viewed form data mining forms data mining could also applied set documents sampled databases example frequent concepts names relationships might extracted used visualization interface ability construct single database acts surrogate set databases signi cant could way rapidly porting manyfamiliar information retrieval tools environments containing many databases although many unanswered questions appears promising direction future research 9 conclusions hypothesis accurate description text database constructed documents obtained running queries database preliminary experiments 5 supported hypothesis conclusive experiments presented paper test hypothesis extensivelyfrommulti ple perspectives con rm hypothesis resource descriptions created querybased sampling su ciently similar resource descriptions created complete information makes little di erence used database selection querybased sampling avoids many limitations cooperative protocols suchasstarts querybased sampling applied older legacy databases databases incentive cooperate easily defeated byintentional misrepresentation also avoids problem needing reconcile di ering tokenizing stopword lists word stemming case conversion name recognition representational choices made database representation problem perhaps serious weakness cooperative protocols exist even parties intend cooperate experimental results also demonstrate cost querybased sampling measured bythenumber queries documents required reasonably low querybased sampling robust respect variations parameter settings finally perhaps importantly experiments described paper querybased sampling text databases 29 demonstrate fairly small partial description resource e ective distributed search complete description resource result suggests much information exchanged cooperative protocols un necessary communications costs could reduced signi cantly without ecting results demonstrated e ectiveness partial resource descriptions also raises questions terms necessary describing text collections querybased sampling identi es terms across wide frequency range necessarily favors frequent nonstopword terms database luhn suggested terms middle frequency range would best describing documents 24 open question whether terms middle frequency range would best describing collections several open questions remain among whether numberofdocu ments database estimated querybased sampling wehaveshown information may required database selection nonetheless desirable information also open question howmany documents must sampled resource obtain description desired accuracy although 300500 documents appears e ective across range database sizes work reported extended several directions provide complete environment searching browsing among many databases ex ample documents obtained querybased sampling could used provide query expansion database selection drive summarization visualization interface showing range information available multidatabase environ ment generally ability construct single database acts surrogate large set databases ers many possibilities interesting research acknowledgments thank aiqun du work early stages research reported also thank reviewers many helpful suggestions reviewer sigir conference suggesting experiments section 454 material based work supported part library congress department commerce cooperative agreementnumber eec9209623 andinpartby nsf grants iis9873009 eia9983253 eia9983215 opinions ndings conclusions recommendations expressed material authors necessarily ect sponsors r comparing performance database selection algorithms evaluating database selection techniques testbed experiment decisiontheoretic approach database selection networked ir starts stanford proposal internet metasearching generalizing gloss vectorspace databases broker hierarchies e ectiveness gloss text database discovery problem precision recall gloss estimators database discovery second text retrieval conference trec2 methods informationserver selection information retrieval computational theoretical aspects word sense disambiguation large text databases collection selection results merging topically organized u measures collection ranking evaluation automatic creation literature abstracts experimental comparison e ectiveness computers humans searchintermediaries determiningtext databases searchintheinternet estimating usefulness search engines facts gures national institutes health national information standards organization impact database selection distributedsearching numerical recipies c art scienti c computing inference networks document retrieval evaluation inference networkbased retrieval model dissemination collection wide information distributed information retrieval system learning collection fusion strategies multiple search engines databasemerging ectiveretrieval distributed collections search ranking algorithms locating resources world wide web server ranking distributedtext retrieval systems internet human behavior principle least e ort anintroduction human ecology tr evaluation inference networkbased retrieval model inference networks document retrieval numerical recipes c 2nd ed effectiveness gioss text database discovery problem trec tipster experiments inquery dissemination collection wide information distributed information retrieval system searching distributed collections inference networks learning collection fusion strategies hypursuit word sense disambiguation large text databases probabilistic model distributed information retrieval multiple search engines database merging effective retrieval distributed collections evaluating database selection techniques methods information server selection automatic discovery language models text databases comparing performance database selection algorithms clusterbased language models distributed retrieval decisiontheoretic approach database selection networked ir server selection world wide web impact database selection distributed searching collection selection results merging topically organized us patents trec data precision recall italicgiossitalic estimators database discovery information retrieval search ranking algorithms locating resources world wide web determining text databases search internet generalizing gloss vectorspace databases broker hierarchies server ranking distributed text retrieval systems internet estimating usefulness search engines ctr leif azzopardi mark baillie fabio crestani adaptive querybased sampling distributed ir proceedings 29th annual international acm sigir conference research development information retrieval august 0611 2006 seattle washington usa henrik nottelmann norbert fuhr evaluating different methods estimating retrieval quality resource selection proceedings 26th annual international acm sigir conference research development informaion retrieval july 28august 01 2003 toronto canada panagiotis g ipeirotis luis gravano one sample improving text database selection using shrinkage proceedings 2004 acm sigmod international conference management data june 1318 2004 paris france w bruce croft jamie callan collaborative research digital government language modeling approach metadata crossdatabase linkage search proceedings 2004 annual national conference digital government research p12 may 2426 2004 seattle wa l hedley younas james sanderson queryrelated data extraction hidden web documents proceedings 27th annual international acm sigir conference research development information retrieval july 2529 2004 sheffield united kingdom jared cope nick craswell david hawking automated discovery search interfaces web proceedings fourteenth australasian database conference p181189 february 01 2003 adelaide australia ronak desai qi yang zonghuan wu weiyi meng clement yu identifying redundant search engines large scale metasearch engine context proceedings eighth acm international workshop web information data management november 1010 2006 arlington virginia usa mark baillie leif azzopardi fabio crestani evaluation resource description quality measures proceedings 2006 acm symposium applied computing april 2327 2006 dijon france henrik nottelmann norbert fuhr retrieval status values probabilities relevance advanced ir applications information retrieval v6 n34 p363388 septemberdecember l hedley younas james sanderson twophase sampling technique information extraction hidden web databases proceedings 6th annual acm international workshop web information data management november 1213 2004 washington dc usa panagiotis g ipeirotis luis gravano distributed search hidden web hierarchical database sampling selection proceedings 28th international conference large data bases p394405 august 2023 2002 hong kong china mark baillie leif azzopardi fabio crestani towards better measures evaluation estimated resource description quality distributed ir proceedings 1st international conference scalable information systems p41es may 30june 01 2006 hong kong james caverlee ling liu joonsoo bae distributed query sampling qualityconscious approach proceedings 29th annual international acm sigir conference research development information retrieval august 0611 2006 seattle washington usa jamie callan fabio crestani henrik nottelmann pietro pala xiao mang shou resource selection data fusion multimedia distributed digital libraries proceedings 26th annual international acm sigir conference research development informaion retrieval july 28august 01 2003 toronto canada demet aksoy information source selection resource constrained environments acm sigmod record v34 n4 p1520 december 2005 leif azzopardi maarten de rijke automatic construction knownitem finding test beds proceedings 29th annual international acm sigir conference research development information retrieval august 0611 2006 seattle washington usa stefano berretti alberto del bimbo pietro pala merging results distributed content based image retrieval multimedia tools applications v24 n3 p215232 december 2004 jie lu jamie callan pruning long documents distributed information retrieval proceedings eleventh international conference information knowledge management november 0409 2002 mclean virginia usa james caverlee ling liu daniel rocco discovering ranking web services basil personalized approach biased focus proceedings 2nd international conference service oriented computing november 1519 2004 new york ny usa semisupervised learning method merge search engine results acm transactions information systems tois v21 n4 p457491 october jack g conrad xi guo cindy p schriber online duplicate document detection signature reliability dynamic retrieval environment proceedings twelfth international conference information knowledge management november 0308 2003 new orleans la usa luo si jamie callan using sampled data regression merge search engine results proceedings 25th annual international acm sigir conference research development information retrieval august 1115 2002 tampere finland panagiotis g ipeirotis tom barry luis gravano extending sdarts extracting metadata web databases interfacing open archives initiative proceedings 2nd acmieeecs joint conference digital libraries july 1418 2002 portland oregon usa henrik nottelmann norbert fuhr evaluating different methods estimating retrieval quality resource selection proceedings 26th annual international acm sigir conference research development informaion retrieval july 28august 01 2003 toronto canada jack g conrad xi guo peter jackson monem meziou database selection using actual physical acquired logical collection resources massive domainspecific operational environment proceedings 28th international conference large data bases p7182 august 2023 2002 hong kong china milad shokouhi justin zobel saied tahaghoghi falk scholer using query logs establish vocabularies distributed information retrieval information processing management international journal v43 n1 p169180 january 2007 henrik nottelmann gudrun fischer search browse services heterogeneous collections peertopeer network pepper information processing management international journal v43 n3 p624642 may 2007 bei yu guoliang li karen sollins anthony k h tung effective keywordbased selection relational databases proceedings 2007 acm sigmod international conference management data june 1114 2007 beijing china luo si rong jin jamie callan paul ogilvie language modeling framework resource selection results merging proceedings eleventh international conference information knowledge management november 0409 2002 mclean virginia usa elena renda umberto straccia automatic structured query transformation distributed digital libraries proceedings 2006 acm symposium applied computing april 2327 2006 dijon france yihling hedley muhammad younas anne james mark sanderson sampling information extraction summarisation hidden web databases data knowledge engineering v59 n2 p213230 november 2006 paul ogilvie jamie callan effectiveness query expansion distributed information retrieval proceedings tenth international conference information knowledge management october 0510 2001 atlanta georgia usa luis gravano panagiotis g ipeirotis mehran sahami qprober system automatic classification hiddenweb databases acm transactions information systems tois v21 n1 p141 january milad shokouhi justin zobel falk scholer tahaghoghi capturing collection size distributed noncooperative retrieval proceedings 29th annual international acm sigir conference research development information retrieval august 0611 2006 seattle washington usa yang minjie zhang twostage statistical language models text database selection information retrieval v9 n1 p531 january 2006 fabio simeoni murat yakici steve neely fabio crestani metadata harvesting contentbased distributed information retrieval journal american society information science technology v59 n1 p1224 january 2008 jack g conrad joanne r claussen early usersystem interaction database selection massive domainspecific online environments acm transactions information systems tois v21 n1 p94131 january jack g conrad joanne r claussen clientsystem collaboration legal corpus selection online production environment proceedings 9th international conference artificial intelligence law june 2428 2003 scotland united kingdom henri avancini leonardo candela umberto straccia recommenders personalized collaborative digital library environment journal intelligent information systems v28 n3 p253283 june 2007 panagiotis g ipeirotis eugene agichtein pranay jain luis gravano search crawl towards query optimizer textcentric tasks proceedings 2006 acm sigmod international conference management data june 2729 2006 chicago il usa milad shokouhi justin zobel yaniv bernstein distributed text retrieval overlapping collections proceedings eighteenth conference australasian database p141150 january 30february 02 2007 ballarat victoria australia john gerdes jr edgaranalyzer automating analysis corporate data contained secs edgar database decision support systems v35 n1 p729 01 april brian f cooper guiding queries information sources infobeacons proceedings 5th acmifipusenix international conference middleware october 1822 2004 toronto canada andrei broder marcus fontura vanja josifovski ravi kumar rajeev motwani shubha nabar rina panigrahy andrew tomkins ying xu estimating corpus size via queries proceedings 15th acm international conference information knowledge management november 0611 2006 arlington virginia usa alexandros ntoulas petros zerfos junghoo cho downloading textual hidden web content keyword queries proceedings 5th acmieeecs joint conference digital libraries june 0711 2005 denver co usa massimo melucci rank correlation information retrieval evaluation acm sigir forum v41 n1 p1833 june 2007