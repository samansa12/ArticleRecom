general method maximizing errordetecting ability distributed algorithms abstractthe bound component failures spatial distribution govern fault tolerance candidate errordetecting algorithm distributed memory multiprocessors specific algorithm topology processor interconnection network define bounds paper introduces maximal fault index derived system topology local communication patterns demonstrate maximal number simultaneous component failures tolerated particular interconnection network errordetecting algorithm index used design mapping processes processor groups errordetecting ability algorithm preserved certain multiple simultaneous processor failures b introduction fixed multiprocessor topology number permitted faults distribution topology restricted want able detect resulting errors paper introduces maximal fault index derived system topology local communication patterns algorithm obtain maximal number simultaneous byzantine component failures distribution errors still detected introduce mapping individual processes processor groups errordetecting abilities algorithms maximized faulttolerant processtoprocessor mapping used safety critical systems since ensures failure certain combinations multiple components go undetected increases dependability system call set processors obtained local interprocess communications algorithm communication environment figure 1a shows star pattern given design parameters maximum number faults permitted communication environment errors still detected local tolerance l topology entire system want compute global tolerance g maximizes number permitted faults system maintaining local fault tolerance condition figure 1b shows scenario two simultaneously faulty components system violate local fault tolerance contrast figure 1c shows syndrome faults violates local fault tolerance least one communication environment optimal fault distribution yields partitioning processes groups processes within particular group simultaneously faulty still errors detected processor groups mapped disjointly actual topology thus failure elements single processor group still allows detection errors 30 33 00 03 mapped group simultaneously faulty c processes may communication environment algorithm 00 03 30 33 conventional processto processor mapping figure 2 logical adjacency algorithm physical mapping example faulttolerant mapping given figure 2 communication environment used square described figure 2a conventional processto processor mapping shown 2b faulttolerant mapping seen 2c details mapping algorithm given section 4 section 2 provide definitions different collections processors based faulty nonfaulty status section 3 gives graph coloring algorithm determining distribution faulty processors within topology section 4 shows characterization optimal fault distribution npcomplete finding maximal fault index nphard arbitrary topologies communication patterns section 4 also gives algorithm determining process processor group partitioning based optimal fault distribution section 5 show maximal fault index several specific communication patterns regular topologies found polynomial time also give partitionings based optimal fault distribu tions section 6 provides example form assessment used errordetecting matrix relaxation algorithm 2 terminology mps topologies paper examine fixedtopology multiprocessor systems discussed 4 8 11 17 contrast 6 examine whether algorithm detect combinations k faults k specified bound assume algorithm designed certain local fault tolerance l communication environment 13 analysis 6 determine whether every combination l faults detected provides minimum number simultaneous faults condition hold contrast want determine maximum number faults g distribution topology errors still detected however claim combinations g faults tolerated underlying topology multiprocessor system mps described graph gv e set vertices v represents processors network set edges e determines direct communication links pairs processors network topology mps regular hypercube mesh arbitrary connected graph simplification focus processor failures since processor failure described failure links link failure described indicating processor failure 15 assume worstcase fault model byzantine malicious behavior faulty process lose modify messages check lost messages well inconsistency data sending multiple copies message nodedisjoint paths since allow relatively small number simultaneous faults assume always exists least one path communicating processes contain faulty components makes detection inconsistencies possible mps interconnection network interactions processors described communication patterns frequently algorithms restrict interprocessor communication adjacent processors improve efficiency however new routing technologies wormhole routing make delivery messages processors distance one away almost efficient direct communication 3 allow types interactions communication environment definition 21 communication environment ce processor p set processors p receive information execution program set includes p well communication environment specific processor subset set n processors network ie cep g 1 definition 22 fault group processor p fault tolerance l denoted fgp collection faulty processors cep guarantee error detection errors caused faults require communication environments usually intersect since p requests data processors processors request data p need relate independent failures different ces local fault tolerance l environment violated definition 23 collection processors must nonfaulty guarantee detection errors induced set faulty processors p called nonfault group p denoted nfgp set contains elements ces elements p members l reached algorithm detect errors following must invariantly hold faulty depending value l many different nonfault groups exist nfg set processors p determines processors p j outside nfgp failure p effect failures components tolerated errordetecting algorithm need ensure conflicts faulty processors respective nfgs means processor fails must nfg failed processor detection errors induced set faulty processors guaranteed coloring faulty mps topologies section discuss find evaluate nonfault groups interconnection network based individual communication environments augmentation problem graph represented mps interconnection network adds additional symbolic edges augmentation made actual topology elements located ce adjacent augmented problem graph thus ce forms completely connected subgraph augmented edges correspond fault dependencies processors ce since time must l faulty components ce l faulty vertices adjacent nonfaulty vertex augmented graph components adjacent faulty component algorithmically determine nfg individual processor p mark adjacent nodes augmented graph permit faulty must nonfaulty together processors ie processors ce p l 1 many different possibilities place l faulty components ce use coloring algorithm color graph indicating faultiness nonfaultiness components determining nfg individually faulty processor first describe coloring done one fault ce l 1 extend algorithm l 1 multicoloring vertex chromaticity l obtain nfgs finally algorithm used obtain possible distribution component failures whole mps figure 3 describes find nfg using algorithm colors faulty components one color components must nonfaulty i1 n n total processors color color processors ce p nonfaulty save nfgp reset colors end figure 3 algorithm determine nfgs individually faulty processors l 1 different one coloring scheme works arbitrary communication patterns long ces processors known theorem 31 time complexity coloring algorithm 3 proof step 2 algorithm evaluates n gamma 1 processors ces taking 2 steps process performed total n times loop hence time complexity 3 extend algorithm obtain nfgs larger number faults per ce perform multicoloring vertex chromaticity l coloring processor p j stored array least one colors indicates faultiness p j considered faulty colors show nonfaulty p j must nonfaulty case dont care state since still exist possibilities change fault status component multicolor algorithm given figure 4 theorem 32 time complexity multicoloring algorithm finding one nfg arbitrary p 2 proof loop first part algorithm examines n processors p coloring adjacent vertices augmented graph takes n steps giving first part algorithm considering time takes set augmented graph second part takes n delta l steps determining fault status thus overall complexity algorithm considering time generate augmented graph determine permissible fault distribution entire network use first part algorithm given figure 4 select arbitrary processor become faulty keep labeling nfgs selecting new faulty components undefined labels left processor p j fault distribution obtained determining faulty nonfaulty processors according second part algorithm 4 figure 5 shows example 2coloring ie l 2 dashed lines show augmentation ce edges actual links network importance stage ces processors follows ce1123 ce212 ce3123 ce4345 ce5357 ce63456 ce7357 selecting 1 faulty first pass cause 2 3 labeled nonfaulty since i1 jpj examine set faulty processors p ith element p color p j faulty colorji processors ce p j adjacent augmented graph adjacent p j augmented graphcolor p k nonfaulty colorki end determine fault status processor j1 n i1 l end end figure 4 algorithm determine nfg set p faulty processors arbitrary l adjacent 1 augmented graph dashed lines arbitrarily node 5 chosen faulty forcing 4 6 7 become nonfaulty note although 5 adjacent faulty node 1 original graph adjacent augmented graph since 1 5 dont communicate colorj1 labels processors j filled second pass arbitrary node considered faulty time node 3 selected vertices adjacent 3 augmented graph must colored nonfaulty colorj2 provides total three faulty processors 1 3 5 2 faulty components ce components 2 4 6 7 nonfaulty theorem 33 time complexity finding possible fault distribution using multicoloring algorithm ot l delta n 3 proof theorem 31 takes 2 steps find nfg one faulty processor determining fault distribution whole topology vertices colored variables colorji values assigned first round one node arbitrarily selected faulty nfg colored next unmarked processor colored faulty find nfg mark correspondingly process repeated variables assigned values thus takes 3 steps fill one set variables colorji 1 coloring process performed l times colored determination fault status processor done according second part multicoloring algorithm complexity thus complexity finding possible fault distribution ot l delta n 3 present nfgs processors help determining maximal fault index mps three different processor states fn fn figure 5 multicoloring augmented graph processor respect specific nfg faulty nonfaulty dont care use matrix representation definition 31 fault matrix mps gives sets faulty processors p processors must nonfaulty indicated logical value f matrix elements p faulty faulty processors marked processors outside nonfault group marked fault matrix corresponds collection nfgs specific l exists one nfg per processor l 1 several different nfgs may found since l processors faulty ce many combinations exist representation figure 6 shows setup fault matrix 5x5 torusconnected mesh adjacent processors communicate ie star pattern introduced section 1 mesh labeled row row left right starting node 1 top left corner ending node 25 bottom right providing maximal fault tolerance determining ces nfgs different processors finds largest collection component failures within topology algorithm still detect errors induced failures stated earlier examine algorithms local fault tolerance l define minimum maximum number faults tolerated simultaneously arbitrary topology using errordetecting algorithm trivially minimal fault index topology respect algorithm able tolerate l local faults l local fault tolerance figure fault matrices 5x5 torusconnected mesh star communication pattern definition 41 maximal fault index mfi topology respect algorithm able tolerate l local faults number failures g occur maximal definition 42 fault tolerance decision problem ftd determines total g faults tolerated specifically checks assignments different processors give answer following question given l g exist assignment fgs solution ftd depends network topology well communication patterns matrix representation use logical representation faulty nonfaulty processors row fault matrix represents logical expression faulty nonfaulty f dont care terms mentioned thus example first row figure 6 provides nfgp 1 5x5 torusconnected mesh l 1 corresponds statement must true know p 1 faulty l 1 guarantee errordetecting algorithm detect errors caused faulty processor solve ftd arbitrary topology fixed l g essentially want determine exists set l terms represented rows fault matrix true simultaneously example given 5x5 mesh l 1 possibly faulty processor could example p 8 since entry row indicates nfgp 1 dont care next step evaluate faultiness p 8 influences faulty processors may located determine assignments truth values processor states permits detection errors examine whether nfgs faulty processors match ie conjunction processor states indicated corresponding rows fault matrix must true rows sets faulty processors p therefore check rows appropriate fault matrix time needed determine possible specific assignment logical values 2 ie polynomial solve ftd check possible 2 n assignments evaluate one select ones permit number simultaneously faulty processors g nondeterministic algorithm guess correct assignment need determine whether ftd certain topology equal g fixed l lemma 41 ftd problem np proof using nondeterministic algorithm find assignment processors polynomial time see theorem 33 tell ftd provides result mfi equal value g thus ftd np lemma 42 variant 01 integer programming problem components required 01 called 01integer programming npcomplete even components x b components c required 01 5 reduced ftd problem polynomial time proof lemma 42 given 18 basically case provides entries fault matrix b indicates number faults tolerated ce value may vary ce frequently l entries c gives solution vector rows fault matrix satisfied simultaneously solution c 1entry processor selected optimal fault distribution theorem 41 ftd problem npcomplete proof proof follows directly lemmas 41 42 corollary 41 mfi problem nphard proof determine maximalpossible value faulty components need solve 01integer programming problem described ftd determines whether exists number faulty processors g g arbitrary integer g 1entries solution vector c thus solve ftd nt l times find maximal value since l minimal fault index n theoretical maximum thus mfi obtained ftd polynomial number steps therefore nphard definition 43 processor group k describes collection processes whose simultaneous failure still permits errors caused failure detected processor groups mapped disjointly onto actual processor topology corollary 42 partitioning individual processes onto processor groups based optimal fault distribution obtained polynomial time solution mfi proof instead equating process processor consider process individually try partition n processes onto smaller number processor groups use solution mfi provides optimal distribution processor faults providing solution vector c fault matrix indicating processes may simultaneously faulty nfg process indicates processes may located together processor algorithm figure 7 provides partitioning processes p processor groups k j process clearly polynomial example mapping given section 512 star pattern 5 finding maximal fault index fixed topologie although determining optimal distribution faults nphard arbitrary graphs necessarily true certain regular topologies regular communication pat terns example nearest neighbor algorithms processor neighbors form communication environment cases possible determine maximal nfg overlap inspection topologies evaluated section 2dimensional torusconnected meshes binary hypercubes provide underlying interconnection network errordetecting algorithms using regular communication patterns l 1 use compass coordinates describe adjacency processes 51 mfi meshes symmetry topology examine torusconnected meshes distribution faulty components meshes without wraparound connections similar less restrictive since wraparound connections dont considered k processor groups individual processes mapped 1entries solution vector c mfi mapped k 0 remaining processes mapped onto k ci1 end distribute remaining processes onto processor groups cannot map process group would nfg one elements already mapped group exists new one created l k l mapped km else l k l j end end figure 7 algorithm provide mapping results ftd 511 square pattern first communication pattern evaluated communication square communication environment p set processors pe p p se see figure 8 left part see augmented graph p also part cepnw cepn due adjacency pattern containing processors ces thus 3x3 processor group p located center see figure 8 center p faulty determined coloring algorithm section 3 nfgp maximal fault index places many faulty processors possible mesh apparent meshes smaller 3x3 mfi l arbitrary torusconnected mesh l 1 mfi determined gives maximal possible number faulty processors dependent number rows columns mesh figure 8 one see faulty processors must x x x x x x x x x figure 8 square communication pattern nfg optimal fault distribution torusconnected mesh wraparound shown least distance two away known faulty processor since p optimally exactly two away closest faulty neighbor place divm 2 every row divn 2 every column give result indicated particular distribution given figure 8 right course larger number processors available processes 4 processors divided placed onto additional processors partitioning individual processes onto smaller set processors square pattern already shown example section 1 figure 2 minimum number processors required 4 partitioning obtained placing nonoverlapping ces set processes described figure 2c 512 star pattern communication neighbors another common communication pattern case processor p communicates pe pw pn p augmented ce shown figure 9 top left discuss pattern section 6 evaluation relaxation algorithm goal permit many faulty components possible mesh guaranteeing time communication environment contains l faulty processors determine nfg individually faulty processor use augmented graph coloring algorithm finding mfi examine case l 1 one fault tolerated ce case nfg faulty p provided coloring algorithm augmented graph result star pattern figure 9 top right p faulty l 1 none processors must faulty ideal case obtain distribution faulty processors identical perfect 1adjacency placement resources nonresource node adjacent exactly one resource 16 case faulty component 16 show number resource nodes kary ncube perfect 1adjacency 40 44 x x x x x 00 04 04 11 23 02 14 21 03 10 22 figure 9 star communication pattern nfg optimal fault distribution torusconnected mesh wraparound shown faulttolerant mapping must integer expression one see perfect 1adjacency always exist bound number faulty processors permitted torusconnected mesh kary 2cube guarantee k theta k meshes case expression becomes allows 5 faulty components 5x5 torusconnected mesh possible distribution example shown figure 9 bottom left faulttolerant mapping particular communication pattern given figure 9 bottom right based optimal distribution faults obtained earlier processes placed noninterfering processes placed onto processor solution vector c obtained solving optimal fault distribution particular problem 1000000100000010100000010 ie vertices 00 12 24 31 43 problem graph simultaneously faulty 52 mfi binary hypercubes binary hypercubes also frequently interested communication patterns communicate adjacent processors ie dimensions hypercube determine maximal fault index topology use similar approach section 51 problem becomes harder since patterns formed nfgs multidimensional therefore difficult place inspection especially highdimensional hypercubes obtain starlike pattern described section 512 faulty processors mesh well hypercube least distance three away order find set processors hypercube property label vertices ndimensional hypercube binary gray code use hamming codes find number processors bn distance apart specifically according 7 provides upper bound maximal fault index example 3cube set two faulty nodes interfere others computations communications marked given figure 10 left faulttolerant mapping nodes onto smaller set processors given figure 10 right 6 specific example errordetecting algorith errordetecting algorithms work checking run time hardware communication 10 software errors 14 algorithms generated using executable optimal fault distribution b faulttolerant mapping based distribution figure 10 mfi faulttolerant mapping nearest neighbor communication 3cube assertions error detection 12 1 assertions example obtained program verification properly chosen set assertions guarantees operationally evaluated changeling 12 program meets specifications error flagged general add executable assertions statement verify previous statement executed correctly case error assertions force program halt execution indicate faulty condition specific problem interconnection network errordetecting algorithm able handle bounded number particular distribution failures bound exceeded distribution faults violated executable assertions may able correctly detect errors since multiple faults mask section discuss concepts described previous sections used assess fault tolerance errordetecting algorithm matrix relaxation 61 iterative relaxation iterative relaxation one fundamental computation methods relaxation used diverse problem ranging relaxation labeling 9 distributed scene analysis computational partial differential equation solvers 14 present general problem approximating solution large sparse system linear equations solution vector perfect square method gaussseidel relaxation iterative technique used obtain approximate solution final iteration system desired topology interconnection network computation twodimensional mesh data exchange pattern algorithm corresponds communication adjacent processors mesh described section 512 star pattern 62 errordetecting matrix relaxation using changeling 12 program verification proof outline based axiomatic semantics 2 used construct errordetecting matrix relaxation purposes paper choose concentrate one assertion matrix relaxation algorithm shows final iteration step k actually solved original problem found solution simply put postassertion appears ensures result obtained converged nodes within desired tolerance ffl problem solved correctly post assertion must hold otherwise error occurred must flagged distributed program runs two phases first phase iterative algorithm converges possible solution second phase verification solution used check whether post assertion satisfied processes ie whether solution meets desired specifications know fault must occurred computation verification process indicating result cannot trusted end final iteration k relaxation algorithm final result u k must satisfy following relation ij u k verify post assertion process send last computed value u k j members ce using message diffusion 3 2 checking different versions arrive paths 12 processor ce must receive identical versions sent message detect error inconsistencies messages sender discovered system equations solved relaxation algorithm unique lution two faulty processors ce cooperate fool processors spurious solution may introduced provide correct solution problem cannot detected example consider solving laplace equation u 2 solution obtained solving corresponds rows sparse matrix actually verify postcondition ce following relation local values components satisfied example satisfies condition locally tested ce easy see single statements effect executing program assertions made program variables program execution 3 message diffusion uses nodedisjoint paths sending least two messages destination compared consistency figure 11 star pattern 2 cooperating errors ce x x x x figure 12 communication pattern message diffusion possible fault distribution component faulty value violates bound always detected however two faulty components faulty errors add without violating bound example 25 could cooperate switching values components forced use value verification round ces participate could provide correct value ces faulty component cooperate another faulty component ones one faulty ce example shown figure 11 thus verification round algorithm allows l 1 ie every single error ce detected actual communication pattern used matrix relaxation extended form star pattern allow message diffusion providing nodedisjoint paths p components corners figure 12 since assertions reliably detect one fault ce l 1 upper bound number faults permitted mfi q theta q mesh calculated q 2 9 note many different distributions faulty components possible long condition one faulty component per ce violated possible faulttolerant mapping similar one described section 1 example 9 processor groups map individual processes according using xy coordinate system process ij maps group k lm mod assuming wraparound connections 7 conclusion paper maximal fault index introduced demonstrate maximal number simultaneous component failures tolerated errordetecting algo rithm based specific distributions faults within interconnection network depending individual sets component failures nonfault groups components indicate nonfaulty components located system able detect errors although solving maximal fault index problem arbitrary network topology communication pattern nphard bounds given paper specific frequently used communication patterns topologies based optimal distribution faults partitioning technique used assign processes processor groups system processes may become faulty simultaneously without errors able mask one another located processor group groups mapped disjointly actual processor topology thus failure single processor still allow detection errors assessment errordetecting algorithm based concept minimal maximal fault index used safety critical systems especially respect faulttolerant processtoprocessor mapping obtained ensure failure single component go undetected increases dependability system r using executable assertions testing fault tolerance atomic broadcast simple message diffusion byzantine agreement torus routing chip graceful degradable processor arrays computers intractability guide theory npcompleteness determining performance measures algorithmbased faulttolerant systems detecting error correcting codes graph model faulttolerant computing systems foundations relaxation labeling processes reliable parallel processing applicationoriented paradigm executable assertion development distributed parallel environment reliable distributed sorting applicationoriented fault tolerance paradigm resource placement kary ncubes diogenes approach testable faulttolerant arrays processors general method maximizing errordetecting ability distributed algorithms tr