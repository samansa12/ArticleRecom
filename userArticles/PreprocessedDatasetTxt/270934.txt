scalable parallel implementations list ranking finegrained machines abstractwe present analytical experimental results finegrained list ranking algorithms compare scalability two representative algorithms random lists address question locality properties image edge lists used improve performance highly datadependent operation starting wyllies algorithm anderson millers randomized algorithm bases use spatial locality edge links derive scalable algorithms designed exploit characteristics image edges tested actual synthetic edge data approach achieves significant speedup maspar mp1 mp2 compared standard list ranking algorithms modified algorithms exhibit good scalability robust across wide variety image types also show load balancing fine grained machines performs well large problem machine size ratios b introduction list ranking fundamental operation many algorithms graph theory computer vision problems moreover representative large class fine grained data dependent algorithms given linked list n cells list ranking determines distance cell head list sequential machine problem solved time simply traversing list however much difficult perform list ranking parallel machines due irregular data dependent communication patterns problem list ranking random lists studied extensively pram models several clever techniques developed implement algorithms existing parallel machines 2 3 10 11 paper study scalability techniques finegrained machines present efficient algorithms perform list ranking edge pixels images performance results based implementations maspar machines discussed algorithms proposed literature either simple workefficient 2 10 11 workefficient employ complex data structures large constant factors associated 1 3 11 12 order study performance scalability algorithms actual application scenario existing parallel machines chosen two representative algorithms wyllies algorithm anderson millers randomized algorithm 11 assume list ranking intermediate step parallel task therefore general case linked list likely spread entire machine random fashion study performance algorithms applications computer vision image processing locality linked lists present due neighborhood connectivity edge pixels purpose present modified approach takes advantage locality connectivity properties similar technique described 10 arbitrary linked lists reidmillers work assignment list cells processors determined algorithm whereas arbitrary case assume preassigned random cell distribution approach derived independently motivated contrast random list case characteristics edges images show case random lists cells randomly preassigned processors randomized algorithm runs faster wyllies algorithm maspar machines lists relatively long however wyllies algorithm performs better short lists agrees results reported machines 2 10 also implies order achieve scalability polyalgorithmic approach needed long lists use randomized algorithm sizes lists reduced certain length use wyllies algorithm approach also used design theoretically processortime optimal solutions show however list ranking edge pixels images finegrained simd machines standard wyllies algorithm randomized algorithm take good advantage image edge characteristics modified technique described section 4 runs two ten times faster depending image size standard wyllies randomized algorithms 16k processor maspar mp1 moreover whereas standard algorithms scale well image edge lists modified algorithms exhibit good scalability respect increases image size number processors study performance proposed algorithms images varying edge characteristics remainder section 1 briefly describe architecture maspar machines outline notion scalability used work section 2 presents overview parallel algorithms list ranking performance results standard wyllies randomized algorithms discussed section 3 scalability behavior analyzed efficient parallel algorithms performing list ranking image edge lists presented section 4 section 5 contains implementation results discusses scalability modified parallel list ranking algorithms image edge lists 11 finegrained simd machines parallel algorithms described paper implemented maspar mp1 mp2 finegrained simd machines finegrained machines general characterized large number processors fairly simple arithmetic logic unit alu processor maspar machines massively parallel simd machines maspar mpseries system consists high performance unix workstation front end data parallel unit dpu consisting 1k 16k processing elements pes 16 kbytes 1mbyte memory pes execute instructions broadcast array control unit acu lock step pes indirect addressing capability selectively disabled clock rate mp1 mp2 machines 125 mhz processors mp2 employ 32bit alu compared 4bit alu mp1 processors pe connected eight neighbors via xnet local communication besides xnet machines global router network provides direct pointtopoint global communication router implemented threestage circuit switched network provides pointtopoint communication two pes constant latency regardless distance third network called global ortree used move data individual processors acu network used perform global operations global maximum prefix sum global etc across data entire array experiments used maspar mp1 mp2 representative finegrained machines use router network provides pointtopoint communication two processors constant latency ensures performance results independent specific network topology also run experiments mp1 mp2 show effects processing power individual processors performance algorithms used extended version sequential ansi c maspar programming language mpl keep implementations free machinedependent software features 12 scalability parallel algorithms analyze scalability algorithms implementations using several architecture algorithm parameters study performance varying machine problem size varying characteristics input image varying processor speed several notions scalability exist 5 analyses define scalability follows consider algorithm runs n p time p processor architecture input problem size n algorithm considered scalable architecture n p increases linearly increase problem size decreases linearly increasing number processors machine size 7 8 experiments use definition intutively study scalability algorithms implememntations likely single algorithm scalable entire range machine problem sizes one important factors limiting range scalability sequential component parallel algorithm identify regions scalability different algorithms presented paper compare analytical results experimental data parallel algorithms list ranking implementations use wyllies parallel algorithm anderson millers randomized algorithm list ranking 11 section outline algorithms general case random lists compared parallel algorithms list ranking literature 11 3 12 chosen algorithms simplicity ease implementation small constant factors particular deterministic algorithms based ruling sets graph coloring 3 easily amenable implementation existing parallel machines 21 wyllies pointer jumping algorithm linked list n cells c head list first element list predecessor referred tail list list ranking problem deals finding rank cell respect head list wyllies algorithm uses pointer jumping dereferencing find rank cell pointer jumping successor cell c modified successors successor given one iteration pointer jumping reassigns successor c c i2 cell c maintains value ranki distance cell c current successor succi intuitively round linked list divided two linked lists half length see fig 1 logn iterations cells point nil ranki contains exact rank cell c p processors processor assigned np cells random although algorithm simple running time n log n pprocessor machine workefficient compared serial algorithm takes time next section describe workefficient randomized algorithm 22 anderson millers randomized algorithm anderson millers randomized algorithm modified version workefficient algorithm devised miller reif 9 assume processor holds np cells queue algorithm consists two phases first phase called pointer jumping phase processor splices cell top queue condition two consecutive cells list assigned two different processors spliced simultaneously order decide cells splice processor tosses coin assigns h cell top queue furthermore cells top queue assigned processor splices cell top queue cell marked h predecessor assigned see fig 1 b first phase ends cells processor spliced splicing cell c consists two atomic assignments followed updating ranki follows second phase referred reconstruction phase cells put back b c b c b c b figure 1 pointer jumping wyllies algorithms edge labels show rank edges predecessor cell current iteration b splicing condition anderson millers algorithm top cell spliced queue reverse order spliced reconstructing queue rank cell c respect head list updated expected running time algorithm onp assuming np log n additional details algorithm analysis found 11 rest paper refer algorithm randomized algorithm 3 implementation results using random lists algorithms presented previous section implemented maspar chines section study impact various machine problem parameters performance algorithms random lists generate random linked list size n traverse array n cells serial order cell assign pointer random location array ensured cell array pointed one cell input randomized algorithm also assign reverse pointers target location generate doubly linked list required algorithm resulting random linked list read parallel processor array every processor holds np cells array since np cells processor may point n array locations sublist processor generally contain successive cells linked list 31 scalability analysis fig 2 shows performance wyllies randomized algorithms maspar mp1 using various machine problem sizes experimental results presented fig 2 b consistent theoretical analysis asymptotic complexity wyllies algorithm random list size n p processors onp log n complexity randomized algorithm onp however randomized algorithm larger constant factors due increased overhead cointossing record keeping involved reconstruction stage algorithm wyllies algorithm suited smaller linked lists due small constant factors randomized algorithm outperforms wyllies algorithm problem size increases probabilistic splicing elements generates lower congestion communication network example shown fig 2 crossover point occurs random list size 94k elements 16k processor mp1 random list size n time mp1 16384 processors wyllie randomized number processors p time random list wyllie randomized b figure 2 performance wyllies randomized algorithms mp1 random list varying size b performance algorithms random list size 16k varying number processors mp1 interesting feature fig 2 b execution time randomized algorithm starts increasing number processors exceeds 4k random list size 16k fixed problem size number processors increases beyond certain point size queue np processor becomes small hence likely cell top queue processor pointed cell top queue another processor thus reducing chance cell spliced particular iteration increases total number iterations thus increases execution time algorithm varying problem size machine size able determine regions problem machine size algorithm fastest experiments also demonstrate scalability best achieved changing algorithm approach problem size increases fact agrees approaches used algorithm designers develop processortime optimal solutions list ranking problem 11 performed experiments maspar mp2 well mp1 mp2 use router communication network difference architectures faster processors mp2 thus study impact processor speed compare performance algorithms 4096 processors mp1 mp2 cases problem sizes greater 16k randomized algorithm outperforms wyllies algorithm however wyllies algorithm 35 faster randomized algorithm 40 faster mp2 computer vision list ranking intermediate step various edgebased matching represent compact data structure efficient processing subsequent steps 2 assume input form binary images pixel marked edge nonedge pixel furthermore result operation edge linking edge pixel points successor edge pixel 8connected neighborhood successor function defines direction edge n theta n image divided p subimages size n theta n processor assigned one subimage straightforward division distribution edge pixels processors might cause load imbalance section 55 describes effect load imbalance presents alternative datadistribution scheme improves load balance across processors 41 image edge lists fig 5 shows edge maps derived various real synthetic images particular fig 5 image picnic scene fig 5 b edge map obtained performing edge detection picnic image followed edge linking operation creates linked lists contiguous edge pixels image edge lists used experiments derived performing sequential edge linking 4 operations edge maps various images edge lists resulting images typically several properties may affect efficiency standard list ranking algorithms example average number lists fairly large lists short length edge lists exhibit spatial continuity implies list cells assigned single processor contiguous form sublists furthermore one processor may contain pieces several edge lists one hand properties adversely affect performance standard list ranking algorithms example run wyllies algorithm disregarding connectivity property several edge points belonging sublist processor may compete communication links access successor information processors similarly randomized algorithm processor may tossing coin edge point successor already stored processor overheads make standard wyllies randomized algorithms unattractive computing ranks edge pixels images hand image edge properties used modify standard algorithms achieve better performance edge lists images described next section 42 modified algorithms fig 3 compares performance wyllies randomized algorithms random lists versus performance edge maps equivalent sizes obtained picnic image achieved counting number edge pixels picnic image creating random list number elements fig 3 clear locality properties image edge lists cause performance degradation especially large image sizes wyllies picnic image wyllies random list image size execution time wyllies algorithm randomized picnic image randomized random list image size execution time randomized algorithm b figure 3 comparison performance algorithms random lists versus equivalent sizes picnic image 16k processor mp1 following outline modified approach takes advantage connectivity property inside processor reducing sublist single edge called bypass edge approach uses wyllies randomized algorithm bypass edges image addition eliminating redundant work within processors approach also reduces amount communication across processors approach consists three steps step 1 convert sublist contiguous edge pixels subimage bypass edge performing serial list ranking operation sublists within processor example see fig 4 associate edge length sublist representing lists span processors corresponding bypass edges connected bypass edge image contour processor figure 4 bypass edges step 2 run wyllies algorithm randomized algorithm lists bypass edges step 3 serially update rank edge pixel within subimage using final rank bypass edge represents pixel modified algorithms thus thought combination serial parallel list ranking algorithms analyze scalability list ranking algorithms image edge lists assume image n edge pixels uniformly distributed across p processors processor holds onp edge pixels simplifying assumption unlikely strictly true actual images however since number edge pixels per processor relatively low finegrained implementations extent number edge pixels per processor deviates onp limited modified approach first step takes onp computation time form bypass edges last step takes onp time update rank edge pixel thus total time taken serial component modified algorithms onp analyze parallel execution time second step assume image multiple edge lists varying lengths length longest edge l note l property underlying image edge map derived since edges assumed uniformly distributed across processors length longest list consisting bypass edges olp assume np pixels processor divided k sets set contains successive pixels edge list assigned processor ie processor contains k bypass edges first step algorithm simplifying assumption assumptions execution time second step log l wyllies algorithm ok expected time randomized algorithm assuming k logkp time taken parallel component modified algorithms therefore total execution time onpk log l modified wyllies algorithm onp modified randomized algorithm since constant factors modified randomized algorithm higher outperform modified wyllies algorithm l large ie image long edges algorithms presented section inherently finegrained due high commu nicationcomputation ratio irregular patterns interprocessor communication efficient algorithms coarsegrained machines implementation described 6 5 implementation results using image edge lists used edge maps number real synthetic images study performance list ranking algorithms fig 5 shows edgemaps used experiments fig 5 b c derived performing edge detection edge linking operations grayscale images edge characteristics images differ significantly example edges written text image local compared images typically edge density percent edge pixels compared total number pixels real images range 3 8 percent contrast edge maps also generated synthetic edge maps varying edge density length fig 5 e f show synthetically generated edge maps straight lines spiral respectively generated images edge densities ranging 5 50 percent edge characteristics real synthetic images help gaining insight performance algorithms images varying edge density edge length 51 comparison standard algorithms performance modified algorithms compared performance standard algorithms fig 6 fig 6 shows execution times varying sizes picnic image 16k processor mp1 modified algorithms significantly faster straightforward wyllies randomized algorithms algorithms efficiently exploit locality edges images verified results different machine sizes mp1 mp2 fig 6 b shows execution times algorithms dense synthetic spiral edge maps spiral edge map different picnic edge map much higher edge density much longer image edges despite vastly different image characteristics modified algorithms significantly faster standard algorithms also tested algorithms different edge maps shown fig 5 similar results thus conclude modifications result significant performance improvement standard wyllies randomized algorithms image edge lists point fig 6 relative performance modified algorithms varies depending image characteristics spiral image modified randomized algorithm faster modified wyllies images size greater 350 theta 350 pixels hand picnic image modified randomized algorithm always slower modified wyllies explain behavior detail section 53 52 scalability analysis scalability modified algorithms studied using different images varying image size number processors results obtained using different edge maps shown fig 5 similar hence restrict discussion performance modified algorithms b c figure 5 picnic image detected edge contours different images used experiments real picnic scene b edgemap picnic scene c edgemap written text edgemap street scene e synthetic edgemap straight lines f synthetic edgemap spiral randomized modified randomized modified wyllie image size execution time picnic image 6 randomized modified randomized modified wyllie image size execution time dense spiral image b figure performance algorithms various sizes picnic image b spiral image 16384 processors mp1 edge map derived picnic scene fig 7 examines scalability modified wyllie modified randomized algorithms respect increasing problem size plot displays overall execution time well serial parallel components modified algorithms small image sizes parallel component dominates overall execution time relatively large constant factors parallel component compared sequential component large image sizes subimage size per processor grows execution time sequential component grows much faster corresponding parallel component consistent analytical results since execution time sequential list ranking component grows linearly size subimage onp parallel component grows proportion number bypass edges subimage case modified wyllies algorithm crossover point execution times sequential parallel components occurs subimage size assigned processor 64 pixels case modified randomized algorithm crossover point occurs subimage size 128 pixels see fig 8 b fig 8 shows scalability behavior modified algorithms respect changes machine size notice sequential component dominates execution time high problemmachine size ratio parallel component dominates low problemmachine size ratio results shown mp1 mp2 performance curves sequential parallel total image size execution time modified wyllies parallel total image size execution time modified randomized b figure 7 performance sequential parallel components modified wyllie b modified randomized algorithms execution time picnic image 16k processor mp1 similar shape however mp2 crossover point parallel component begins dominate execution time occurs larger problemmachine size ratio due faster processors higher computationcommunication ratio mp1 sequential parallel total number processors execution time modified wyllies sequential parallel total number processors execution time modified randomized b figure 8 scalability respect number processors modified wyllies algo rithm b modified randomized algorithm execution time picnic image size 512 theta 512 mp1 fig 9 plots performance modified algorithms number processors increases linearly image size thus problemsizemachinesize ratio constant size subimage processor constant observe sequential time proportional size subimage processor remains approximately small increase parallel component due fact maspar ma0102 sequential parallel total image size execution time modified wyllies parallel total image size execution time modified randomized b figure 9 scalability constant problemsizemachinesize ratio 256 elements per processor mp1 modified wyllies algorithm b modified randomized algorithm chines increase number processors number links router network change proportionally however since overall increase execution time small conclude modified algorithms exhibit speedup proportional image size ratio imagesize number processors constant 53 effect image characteristics studied performance algorithms images varying characteristics terms edge density edge lengths discussed section 42 total execution time onpk log l modified wyllies algorithm onpk modified randomized algorithm fig 10 indicates increase execution time proportional increase image edge density onp true modified wyllies modified randomized algorithms fig 11 shows behavior modified algorithms edge maps varying edge lengths fig 11 modified randomized algorithm always slower modified wyllies algorithm also case picnic scene image see fig 6 due large constant factors modified randomized algorithm however fig 11 b modified randomized algorithm significantly faster modified wyllies algorithm beyond certain imagesize machinesize ratio image image image size execution time modified wyllies image image image size execution time modified randomized b figure 10 performance synthetic line image varying density 16k processor mp1 modified wyllies algorithm b modified randomized algorithm modified wyllies modified randomized image size execution time line image modified wyllies modified randomized image size execution time spiral image b figure 11 performance modified algorithms synthetic images density different edge lengths 16k processor mp1 line image b spiral image parallel execution time modified randomized algorithm ok compared ok log l modified wyllies algorithm since serial component equaldensity line image spiral image onp expect modified randomized algorithm run faster length longest edge l large case spiral image 54 mp1 vs mp2 effect processor speed performance algorithms studied executing algorithms 4k processor maspar mp1 mp2 machines shown fig 12 wyllies algorithm faster mp2 compared mp1 primarily due increased processor speed similar behavior exhibited randomized algorithm worth noting although mp2 lower execution times scalability behavior algorithms two machines similar crossover point sequential component dominates overall execution time occurs larger imagesizemachinesize ratio mp2 sequential parallel total image size execution time modified wyllies mp1 sequential parallel total image size execution time modified wyllies mp2 b figure 12 performance modified wyllies algorithm varying sizes picnic image 4k processors mp1 b 4k processors mp2 55 load balancing input derived real opposed synthetic image likely edge contours concentrated particular portion image case simple partitioning image p subimages assigning subimage processor may yield unbalanced load across processors order study effect load imbalance performance experimented various loadbalancing techniques general techniques based first computing load variance across processors redistributing load processors light loads failed yield high performance computation data redistribution loadbalancing step become significant part total execution time regardless load redistribution communication overhead remains following outline simple heuristic address load balancing problem present performance results heuristic based dividing input image subimages assigning one subimage processor partition input image kp identical sized subimages number subimages row shuffled order follows arrange subimages k sets set contains grid contiguous subimages number subimages set rowmajor order set processor j example rowshuffled ordering image 16 processor machine assuming shown figure 13 figure 13 heuristic partitioning scheme input image 16 processor machine figure 14 compares distribution edge pixels 1k theta 1k picnic image 16k processor mp1 using simple partitioning using partitioning based described heuristic loadbalanced partitioning scheme number processors zero edge pixels reduced half time variance load edge pixels per processor across entire machine reduced 214 89 figures 15 16 compare performance modified wyllies algorithm without loadbalancing varying image machine sizes observe loadbalancing pays large image sizes case simple partitioning scheme used earlier sections sequential execution time dominates parallel execution time large image sizes loadbalanced partitioning scheme sequential execution time reduced expense increase parallel component increase parallel component due fact edge pixels processor successors residing processors increases contention communication links pointer jumping phase thus increases parallel time sequential time decreases large ratios n p extent load imbalance possible small ratios always low since size subimage assigned processor small claim well supported figures 15 b 16 b number processors number processors b figure 14 histogram edgepixel distribution 1k theta 1k picnic image 16k processors mp1 original distribution b distribution loadbalancing conclusion loadbalancing scheme performs well large imagesize machinesize ratios terms scalability respect machine size well problem size behavior using load balancing scheme much different simple partitioning scheme unbalanced loadbalanced image size execution time execution time parallel unbalanced parallel loadbalanced image size execution time sequential parallel components b figure 15 comparison execution time unbalanced loadbalanced modified wyllies algorithm overall execution time b sequential parallel components execution time picnic image 16k processor mp1 1024 4096 16384002006 unbalanced loadbalanced number processors execution time execution time 1024 4096 16384001003005 sequential unbalanced parallel unbalanced parallel loadbalanced number processors execution time sequential parallel components b figure comparison scalability respect number processors unbalanced loadbalanced modified wyllies algorithm overall execution time b sequential parallel components execution time picnic image size 512 theta 512 mp1 6 conclusions paper studied scalability list ranking algorithms fine grained machines presented efficient algorithms list ranking image edge lists wyllies anderson millers algorithms list ranking chosen representative deterministic randomized algorithms respectively performance algorithms studied random lists image edge lists shown algorithms perform poorly image edge lists also single algorithm covers entire range scalability show poly algorithmic approach algorithmic approach changes data size reduced required scalability across machine problem sizes image edge lists presented modified algorithms exploit locality property edge lists performance modified algorithms actual images demonstrates gains achieved using applications characteristics algorithm design 16k processor maspar mp1 modified algorithms run two times faster small images ten times faster large images standard wyllies randomized algorithms modified algorithms robust across wide variety images finally results extensive experimentation shown standard algorithms scalable list ranking image edge lists tailored algorithms exhibited good scalability respect increases image size number processors also respect changes image characteristics also shown load balancing fine grained machines pay unless problem machine size ratio large summary study provides insight performance finegrained machines applications employ light computations intense data dependent communications contrast results list ranking edge lists coarsegrained machines results presented demonstrate implementations communication intensive problems finegrained machines sensitive characteristics input data machine parameters r simple parallel tree contraction algorithm efficient parallel processing image contours faster optimal parallel prefix sums list ranking sequential edge linking measuring scalability parallel algorithms architectures contour ranking coarse grained machines case study lowlevel vision computations introduction parallel algorithms scalable data parallel algorithms implementations object recog nition parallel tree contraction applications list ranking list scan cray c90 list ranking parallel tree contraction efficient algorithms list ranking solving graph problems hypercube tr ctr isabelle gurin lassous jens gustedt portable list ranking experimental study journal experimental algorithmics jea 7 p7 2002