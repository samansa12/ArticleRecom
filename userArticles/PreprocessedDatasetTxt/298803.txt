locality analysis parallel c programs abstractmany parallel architectures support memory model memory accesses local thus inexpensive memory accesses remote potentially quite expensive case memory references via pointers often difficult determine memory reference guaranteed local thus handled via inexpensive memory operation determining memory accesses local done programmer compiler combination overall goal minimize work required programmer compiler automate process much possible paper reports compiler techniques determining indirect memory references local locality analysis implemented parallel dialect c called earthc uses algorithm inspired type inference algorithms fast pointsto analysis algorithm statically estimates indirect reference via pointer safely assumed local access locality inference algorithm also used guide automatic specialization functions order take advantage locality specific particular calling contexts addition purely static techniques also suggest finegrain coarsegrain dynamic techniques case dynamic locality checks inserted program specialized code local case inserted finegrain case checks put around single memory references coarsegrain case checks put around larger program segments static locality analysis automatic specialization implemented earthc compiler produces lowlevel threaded code earth multithreaded architecture experimental results presented set benchmarks operate irregular dynamically allocated data structures overall techniques give moderate significant speedups combination static dynamic techniques giving best performance overall b introduction one key problems parallel processing provide programming model simple pro grammer one would like give programmer familiar programming language programmer focus highlevel aspects coarsegrain parallelism perhaps sort static dynamic data distribution compiler techniques required effectively map highlevel programs actual parallel architectures paper present compiler techniques simplify programmers job expressing locality pointer data structures reported previously developed highlevel parallel language called earthc 1 associated compiler translates earthc programs lowlevel threaded programs execute earth multithreaded architecture 2 3 main emphasis effective compilation programs use irreg ular dynamicallyallocated data structures initial approach provided highlevel parallel constructs type extensions express locality compiler used type declarations dependence analysis automatically produce lowlevel threads although initial approach provide good highlevel basis programming earth multithreaded architecture found programmer forced make many function specializations declare appropriate pointer parameters locally scoped pointer variables local pointers thus order experiment various locality approaches programmer needed edit many places hisher pro gram make several copies function copy specialized particular type locality order ease burden programmer developed new compiler techniques infer locality pointer variables automatically produce specialized versions functions allows programmer make minimal changes hisher highlevel program order try various approaches problem also leads shorter source programs programmer need make several similar copies function main idea behind approach use information context function calls memory allocation statements infer indirect memory references must refer local memory automatically create specializations functions appropriate parameters locallyscoped variables explicitly declared local pointers information used thread generator reduce number remote operations required lowlevel threads order test approach implemented techniques earthmccat c compiler experimented collection pointerbased bench marks present experimental measurements earthmanna machine compare performance benchmarks without locality analysis locality analysis handcoded versions best locality rest paper organized follows section presents overview earthc language earthmccat compiler earthmanna architecture section 3 provides examples motivate locality analysis section 4 describes analysis section 5 give experimental results set benchmarks programs finally section 6 discuss related work section 7 give conclusions suggestions work 2 earthc language earthc compiler designed accept highlevel parallel c language called earthc produce lowlevel threadedc program executed earthmanna multithreaded archi tecture section provide overview important points language target ar chitecture complete descriptions earth project found elsewhere 2 21 earthc language earthc language designed simple extensions c extensions used express parallelism via parallel statement sequences general type forall loop express concurrent access via shared variables express data locality via data declarations local pointers c program valid earthc program compiler automatically produce correct lowlevel threaded program however usually programmer make minimal modifications program expose coarsegrain parallelism add information data locality figure 1 gives two sample list processing functions written earthc cases functions take pointer list head pointer node x return number times x occurs list figure 1a uses forall loop indicate interactions loop body may performed parallel since loop must loopcarried dependences ordinary variables used shared variable count accumulate counts shared variables must always accessed via atomic functions case used builtin functions writeto addto valueof figure 1b presents alternative solution using recursion example use parallel sequence denoted using indicate call equal node recursive call count rec performed parallel earthc compiler captures coarsegrain parallelism level function invocations ordinary c function calls translated lowerlevel threaded c token calls token calls handled earth runtime load balancer call mapped processor runtime however earth c also possible programmer explicitly specify invocation executed using syntax pexpr case underlying threadedc invoke mechanism used explicitly map invocation processor specified expr example figure 1b call equal node mapped processor owning node x whereas recursive call count rec explicitly mapped processor assigned runtime load balancer cases using token invoke mecha nisms activation frame allocated processor assigned invocation invocation remain processor lifetime invoca tion thus earthc compiler assume parameters locallyscoped variables local memory accesses contrary since invocations mapped runtime either using runtime load bal ancer according expression evaluated runtime compiler must assume accesses global variables memory accesses via pointer directions remote memory using assumptions function count rec figure 1b see accesses head x c1 c2 local accesses access headnext remote memory ac cess note make locality easier see underline remote memory accesses put local pointer declarations bold type target architecture earth distributed memorymachine distinction local memory accesses remote memory accesses important local memory accesses expressed generated lowerlevel threadedc program ordinary c variables handled efficiently may assigned registers stored local data cache however remote memory references must resolved calls underlying earth runtime system thus remote memory accesses additional cost call appropriate earth primitive operation plus cost accessing communication network remote memory access turns actually processor request communication time minimal still significantly expensive making direct local memory access even though multithreaded architectures hide communication costs clearly advantageous maximize use local memory whenever possi ble order expose locality compiler earthc concept local pointers programmer knows pointer always points local memory keyword local may added pointer type declaration figure 1a calls equal node made owner first argu ment thus declaration equal node declared first parameter type node local p reading right left says p pointer local node thus body equal node earth compiler may assume pvalue local memory reference qvalue potentially remote memory reference figure 1b illustrates opposite case second parameter equal node local pointer case earth compiler must assume pvalue potentially remote whereas qvalue local earthc also includes another form function declaration also expresses locality functions may declared using keyword basic basic functions must reference local memory may call ordinary remote functions basic functions translated cheap function invocations target threadedc code memory references within bodies ordinary c variable references thus sometimes programmers use basic functions indicate locality variable references int countnode head node x shared int count node p equalnodepxownerofp int equalnodenode local p node q returnpvalue qvalue int countrecnode head node x node next int c1 c2 head null else int equalnodenode p node local q iterative solution b recursive solution figure 1 example functions written earthc within function body purpose paper help automate generation local pointer declarations automatically provide specialized versions functions different calling contexts thus programmer concentrates expressing computation mapped compiler infers locality information pointers inserts correct local pointer declarations reduces burden program mer leads shorter source programs makes changing source program less error prone examples figure 1 programmer would need declare one version equal node compiler would automatically generate appropriate specializations depending calling context 22 earthmccat c compiler paper builds upon existing earthmccat c compiler overall structure compiler given figure 2 compiler split three phases phase contains standard transformations anal yses important points source program simplified astbased simple intermediate representation 4 point programs made structured via gotoelimination statement simplified series simple basic statements statement including assignment statements conditionals loops function calls results sideeffect analysis gives set locations readwritten statement availability readwrite information allows locality analysis simple efficient methods presented paper found phase ii parallelization locality enhancement done phases use results analyses phase order transform simple program representation semantically equivalent program transformations presented paper introduce locality declarations produce new specialized versions functions phase iii takes transformed simple program phase ii generates threads produces tar simplify gotoelimination local function inlining heap analysis rw set analysis array dependence tester phase analyses transformations parallelization function specialization loop partitioning locality analysis pointsto analysis thread generation build hierarchical ddg code generation locality enhancement figure 2 overall structure compiler get threadedc code exposing locality phase ii allow thread generator deal fewer remote memory accesses lead fewer threads fewer calls earth primitives efficient parallel programs 23 earthmanna architecture earth model multiprocessor consists multiple earth nodes interconnection network 2 3 illustrated figure 3 earth node consists execution unit eu synchronization unit su linked together buffers su eu share local memory part distributed shared memory architecture aggregate local memories nodes represents global memory address space eu processes instructions active thread active thread initiated execution eu fetches thread id ready queue eu executes thread completion moving another thread interacts su network placing messages event queue su fetches messages plus messages coming remote processors via network su responds remote synchronization commands requests data also determines threads run adds thread ids ready queue eu su eu su network figure 3 earth architecture experiments performed multithreaded emulator built top manna parallel machine5 manna node consists two intel cpus clocked 50mhz 32mb dynamic ram bidirectional network interface capable transferring 50mbs direction two processors node mapped earth eu su earth runtime system supports efficient remote operations sequentially loading remote word takes 7s calling remote function performed 9s spawning new remote thread takes 4s issued pipeline operation take one third times motivating examples preceding section figure 1 presented example locality analysis could used make specialized versions equal node function section present typical examples locality information used earthc programs show locality analysis specialization lead better programs examples give intuitive ideas behind actual locality analysis presented section 4 example programs remote variable references underlined thus program fewer underlined references exhibits locality efficient 31 pointers local variables parameters outlined section 21 underlying earth runtime system maps functions activation frame processor executing invocation thus safe assume parameters locallyscoped variables references local memory assumption extended pointer variables shown pointer must point locallyscoped variables andor parameters figure 4a gives somewhat contrived example serves illustrate basic point function foo pointer p pointsto x x parame ter since parameters allocated local memory safe assume p points local memory pointer q points either parameter x locally scoped variable since x local assume q local well figure 4b gives localized version function foo note indirections p q remote underlined references original version foo local references localized version int fooint x int p int q expr else int fooint x int local p int local q expr else locality inference b locality inference figure 4 locality pointers 32 dynamic memory allocation rich source locality information comes fact dynamic memory allocation always allocates memory processor allocator called thus function f calls memory allocation function like malloc memory returned malloc local within body f consider example figure 5a without locality inference type declarations compiler must assume pointer may refer remote memory thus indicated underlined sections indirect references via must assumed possibly remote however one note points memory returned malloc thus safely declared local pointer illustrated figure 5b case memory accesses body alloc point assumed local 33 mapping computation owner data common kind locality information comes programmer mapping function invocations owner piece data using owner ex pression typical example given figure 6a function count equal recursively descends binary tree counting number nodes value v first recursive call left subtree explicitly mapped particular processor locality information however second recursive call explicitly sent owner right subtree means invocations assume references via pointer local illustrated figure 6b express properly specialized copy count equal must created called node allocpointdouble x double int colour node node allocpointdouble x double int colour node local locality inference b locality inference figure 5 locality dynamic memory allocation count equal spec example copy parameter declared local pointer thus memory accesses body local 34 mapping computation home another common method mapping computation specific processors use function calls form fhome indicates f invoked processor executing call locality standpoint gives us two kinds information first f returns pointer value local within f must also local within body function calling f second argument f local caller corresponding parameter must local body f figure 7a gives example figure 7b gives result applying locality analysis first note infer local pointer function newnode using ideas presented dynamic allocation given section 32 thus two calls newnode f must return local pointers p q must local pointers consider call lessthan f since arguments p q local point ers corresponding formals b body lessthan must also local pointers 4 locality analysis last section identified languageprogram features sources locality information section present complete algorithm associated analysis rules locality analysis overall algorithm presented figure 8 works iteratively two interrelated intra interprocedural steps beginning analysis functions program considered candidates specialization put set spclpool locality attribute formal parameters global variables initialized remote unless programmer given explicit local pointer declarations pointers explicitly declared local program locality attribute initialized local ini tialization analysis proceeds following two steps step step individually analyzes function pool functions specialized spclpool starts current locality attribute variables propagates information throughout procedure using flowinsensitive intraprocedural approach details step given subsection 41 step ii step performs interprocedural propagation locality procedure specialization ap plicable looks call site functions belonging spclpool called either home owner primitive based locality information callsite infers locality information formal parameters callee function illustrated sections 33 34 specialized version callee function locality already exists callsite modified invoke function instead otherwise newly specialized version callee function created given callsite locality attributes parameters newlycreated function appropriately initialized callsites within specialized function trigger specializations newlycreated function put spclpool end step spclpool nonempty go back first step clearly process terminate finite number func tionsparameters specialized specializations always add locality information actual implementation create new locality context represent specialized function actually create complete new function decision actually create specialized functions taken analysis depending upon benefit achievable particular specialization details specialization step given subsection 42 41 intraprocedural locality propagation perform intraprocedural propagation locality information using typeinference techniques 6 previously adapted perform almost linear pointsto analysis7 basic idea type inference algorithm partition program variables set equivalence classes achieve classification mergingbased approach used example simple assignment leads assignment type class variables x general terms merging current type classes x one wants collect pointsto information instead assignment would lead merging pointsto classes variables x pointsto class variable contains set locations may point runtime fast unionfind data struc int countequaltree int v int c1 c2 c3 else int countequaltree int v int c1 c2 c3 else int countequalspectree local int v int c1 c2 c3 else locality inference b locality inference specialization figure locality generated using owner tures used make merging fast technique used steensgaard 7 collect locality information enhance technique attaching additional locality attribute pointsto class locality attribute one three possible values indicating locality information yet determined ii local locations definitely allocated local memory iii remote locations may allocated remote memory two pointsto classes merged new locality attribute obtained merging locality attributes two classes using merge operator defined follows remote remote remote remote give small program fragment pointsto locality information obtained typeinference based algorithm int b c int x z else pointsto locality information different program points follows localg localg localg localg locality attribute local three pointers contain addresses local variables one also note information provided flow insensitive kill information otherwise x pointsto class b statement s2 thus final information s3 conservatively valid entire program fragment locality analysis uses typeinference based algorithm intraprocedural setting focus analysis accurately computing locality attributes computing complete pointsto information thus analysis account pointsto information holds due aliasing parameters globals however since make worst case assumption locality parameters globals loss information affect correctness technique found loss information affect quality locality information find thus appears inexpensive intraprocedural propagation good choice following subsections provide detailed rules intraprocedural locality analysis analysis performed simple intermediate representation earthmccat compiler simple representation provides eight basic statements affect pointstolocality information provide void f node p q lessthanpqhome node newnodeint val node int lessthannode node b void f node local p local q lessthanpqhome node newnodeint val node local int lessthannode local node local b locality inference b locality inference figure 7 locality generated using home locality analysis rules statement 411 address assignment points variable merge pointsto class x class variable belongs else 412 dynamic allocation statement containing mal loc call related memory allocation call create new variable called heaps also create class locality attribute class initialized local done earth programming model requires malloc call always allocated memory local processor creating new class merge pointsto class variable x giving following rule 413 pointer assignments statements belonging category include rules analyzing discussed statement operands z righthand side conservatively safe result depend operation performed type operands statement need follow additional level indirection lefthand side need know x pointsto perform appropriate mergings ie find pointstoclass pointsto class x class yet exist simply create class gets filled analysis proceeds argument applies statement x respect righthand side following table summarizes rules 414 function calls function call considerably affect locality information using pointer arguments global variables modify locality attribute set pointsto classes avoid always making worstcase assumptions function calls locality analysis uses results interprocedural readwrite modref analysis computed readwrite set analysis step compiler fer figure 2 section 22 based readwrite information two important cases case function call write pointer variable visible caller including globals guarantees call affect pointsto hence also locality information caller case statement statement affect pointsto relationshiplocality attribute variable x locality attribute pointsto class x updated depending upon locality attribute pointsto class return f return f symbolic name represents value returned function f optional expr used call function f basic function called home f returns pointer return f pointing local ie localitypointstoclassreturn f local implies location pointed return f resides fun locality need analyze functions initially initialize localityprog spclpool functions analyzed nongammaempty propagate localityspclpool fun propagate localityprog foreach func spclpool intraprocedural propagation propagate intraprocedural localityfunc deletfromsplcpoolfunc need analyzed foreach callsite prog interprocedural propagation newly specialized function created addtospclpoolcallsitefunc spclpoollambdanew func needs analyzed fun propagate intraprocedural localityfunc foreach assignmentstmt func locality analyze stmtassignmentstmt localityset foreach callstmt locality analyze callcallstmt localityset callsitetype home jj callsitetype owner find params local callee function specialzed version already exists locality set specialfuncexistscallsitefunc return new function created else new func callsite locality new return new specialized function created foreach func prog conservatively assume parameters globals pointgammato remote memory figure 8 overall algorithm locality analysis processor case new locality attribute pointsto class x obtained merging localitypointstoclassreturn f otherwise simply assigned remote per rule expr home isbasicfuncf else case ii alternative function call possibly writes pointer variables caller case make worstcase assumptions set locality attribute pointsto classes arguments remote recursively pointsto classes variables reachable via indirection arguments ie also set localityp ointst oclass arg remote need consider globals already initialize locality attribute remote start analysis 42 specializing functions completion step ii algorithm computed set possible specializations associated locality use static estimates number remote accesses saved decide specialized functions actually create given locality context function compute following data weight corresponding callsite reflects potential execution frequency ii count remote accesses eliminated creating specialized function specialized function created given locality context find weight count estimate greater threshold set 20 default compute weight callsites first initialize weight call sites one loop recursion cycle callsite embedded weight multiplied ten count remote accesses saved similarly estimated simple remote access saved counted one remote access saved inside loop counted ten call sites inside specialized function also specialized also add number remote accesses saved chainspecialization count 5 experimental results order evaluate approach experimented five benchmarks olden suite 8 described table 1 benchmarks use dynamic data structures trees lists except quicksort uses dynamicallyallocated arrays benchmark suite suitable evaluate locality analysis focused pointers benchmark description problem size power optimization problem based variable knary tree 10000 leaves perimeter computes perimeter quadtree encoded raster image maximum tree depth 11 quicksort parallel version quicksort 256k integers tsp find suboptimal tour traveling problem cites health simulates colombian healthcare system using 4way tree 6 levels 100 iterations table 1 benchmark programs benchmark provide results three ver sions simple earthc version localized earth c version advanced earthc version hence forth refer respectively simple localized advanced versions simple version implements benchmark best data distribution discovered date benchmarks exploits locality using owner home primitives uses neither local pointers basic functions purpose however use basic functions performing computations localized version benchmark obtained applying locality analysis subsequent function specialization simple version version tries find many local pointers possible advanced version handcoded benchmark user tries optimally exploit locality using local pointers basic functions possible tricks version based best efforts group produce good speedups none advanced versions implemented authors note three versions use general dynamic data distribution however generated lowlevel program exploits locality different degrees stat ically divide memory references must local might remote reference must local translated ordinary c variable reference may allocated registers target compiler may cached architecture reference might remote translated call earth runtime system calls runtime system may resolved memory requests local memory remote mem ory depending calling context runtime resolves local memory reference call pseudoremote memory access note pseudo remote references much expensive local references expensive real remote references must read write data communication network locality analysis specializations effectively introduce static declarations local pointer vari ables thus runtime execute fewer pseudo remote references local references explained previous sections done automatically introducing local pointer declarations introducing specialized versions functions capture locality specific calling contexts table 2 summarize static effect applying locality analysis specializations simple versions benchmarks benchmark first two columns list number local pointer declarations introduced number function specializations made producing localized version benchmark third column gives relative sizes lines code simple advanced versions note simple versions shorter sometimes substantially shorter advanced hand specialized programs benchmark locals spcls sizesimple power perimeter table 2 static measurements table 3 provide data actual execution time milliseconds three versions benchmark experiments performed earthmanna architecture described section 23 last two columns give percentage speedup obtained simple version localized advanced versions respectively example column labeled localized vs simple reports simple gamma localized simple 100 column labelled ad vanced vs simple reports simple gammat advanced simple 100 provide data benchmark runs 1 8 processors table 4 present actual number remote data accesses remote calls performed different versions benchmark last two columns table give percentage reduction number remote data accessesremote calls simple version localized advanced versions respectively benchmark simple localized advanced localized advanced earthc earthc earthc vs simple vs simple msec msec msec impr impr power 1 proc 6715806 6465942 6348245 372 547 8 procs 913292 884654 865186 314 527 perimeter 1 proc 709555 596637 525503 1591 2590 8 procs 122071 89486 87259 2670 2850 procs 74831 54623 52332 2700 3006 8 procs 539466 502013 458774 694 1500 8 procs 1719355 1510478 111616 1210 9350 table 3 execution time note number remote accesses performed independent number processors used given program differentiate real remote access pseudoremote access data tables 3 4 indicates localized version always performs better simple version ie locality analysis always able identify additional locality percentage improvement vary lot depending upon bench mark localized version comes close advanced version first three five bench marks last two cases localized version give improvement compete handcoded advanced version analyze results detail individually benchmark power benchmark implements power system optimization problem 9 uses fourlevel tree structure different branching widths level locality analysis achieves 34 improvement simple version execution time quite close advanced version 5 however able achieve 80 reduction number remote data accesses table 4 happens function calls benchmark typically format compute nodenodeowner ofnode function performs numerous scalar data accesses form nodeitem analysis captures locality pointer node eliminates remote data accesses respect significant reduction remote accesses reflect execution time benchmark spends time performing floating point operations far exceeds time spent data accesses advanced version achieves 93 reduction number remote calls simple localized version using basic functions factor enables achieve slightly better speedup localized version perimeter benchmark computes perimeter quadtree encoded raster image 9 unit square image recursively divided four quadrants one one point tree traversed bottomup compute perimeter quadrant localized version achieves 1527 speedup comes close advanced version 8 processor runs localized version 32 fewer remote accesses reduction significantly affects execution time power benchmark benchmark involve much computation spends time traversing quadtree hence performing data accesses irregular benchmark computation requires accesses tree nodes may physically close due characteristic advanced version cannot exploit additional locality using basic functions localized version thus competes well quicksort benchmark parallel version standard quicksort algorithm two recursive calls quicksort executed parallel call bigger subarray invoked home size subarrays recursive sorting phase unknown advance dynamicallyallocated arrays used simple version function qsort copies incoming array local array using blkmov end copies back local array incoming array using another blkmov locality analysis able identify locality incoming array home call generates specialized version recursive qsort function incoming array declared local pointer two blkmov instructions substituted calls basic function memcpy transformation enables localized version achieve significant 80 speedup simple version within 1 speedup obtained advanced version advanced version uses additional basic functions completely eliminate remote calls performs little better localized version benchmark simple localized advanced localized advanced earthc earthc earthc vs simple vs simple power 2294179 451179 204179 8033 9110 perimeter 2421800 1635111 1586323 3248 3449 quicksort 8498635 29128 216 9965 9999 tsp 4421050 2672068 829790 3956 8123 health 41409726 33148575 606 1994 9999 table 4 remote accesses saved tsp benchmark solves traveling salesman problem using divideandconquer approach based close point algorithm 9 algorithm first searches suboptimal tour subtreeregion merges subtours bigger ones tour found built circular linked list sitting top root nodes subtrees similar perimeter benchmark irregular nature spends significant amount time data accesses localized version achieves 68 speedup 39 reduction remote data accesses localized version however fails compete advanced version achieves upto 20 speedup resulting 81 reduction remote data ac cesses happens linked lists representing tours distributed segments links across processors knowledge entire sublist local advanced version exploits significant data locality using basic functions traverse local sublists locality analysis designed identify locality recursive fields kind locality implicit programmers organization data difficult find compiler analyses benchmark simulates colombian healthcare system using 4way tree 9 village four child villages village hospital treating patients villages subtree time step tree traversed patients assessed either treated passed parent tree node 4way tree evenly distributed among processors toplevel tree nodes children spread among different processors locality analysis able achieve 12 speedup resulting 19 reduction remote data accesses benchmark similar power call pattern however call format foovillage nodeowner ofvillage node recursive data structures village node linked list patients opposed scalar data items like power analysis able eliminate remote accesses respect village node like list village nodelist accesses like listpatient thus localized version gets decent speedup simple version compete advanced version knowledge top level tree nodes remote children advanced version eliminates almost remote data accesses calls regard benchmark similar tsp 51 summary summary find locality analysis give significant improvements cases however cases locality analysis cannot compete handcoded locality mapping declarations provided pro grammer programmer may implicit knowledge data locality important retain ability explicitly declare local pointers since many cases declarations auto mated locality analysis specialization sourcetosource transformation one could imagine programmer could use output compiler produce localized version program test program see acceptable speedup achieved locality program programmer could add locality declarations order improve program finally note experiments performed earth manna compared distributed memory systems like ibm sp2 network workstations earthmanna much smaller memory latency sometimes hidden multithreading techniques therefore expect better speedup locality analysis machines larger memory latencies support multithreading techniques 6 related work intraprocedural locality propagation approach similar steensgaards 7 linear pointsto analysis al gorithm related work area parallelizing programs dynamic data structures carlisle 9 distributed memory machines rinard diniz 10 shared memory machines particular carlisles 9 affinity analysis similar goals locality analysis albeit target different kinds locality steensgaard proposed typeinference based algorithm pointsto analysis almost linear time com plexity algorithm flowinsensitive context insensitive encountering callsite simply merges formal parameters respective actual argu ments thus algorithm cannot distinguish information arriving function different calling contexts locality analysis calling context information crucial invocation specification home owner call site major source locality information thus want merge locality information arriving different calling contexts contrary want create specialized versions function calling context provides us substantial locality end use typeinference propagate information intraprocedurally employ different technique interprocedural propagation explained section 4 however ensure intraprocedural propagation collects conservatively safe information need make conservative assumptions start procedure encountering callsites using readwrite set information thus although approach originally inspired pointsto analysis really specifically tailored capture information relevant locality analysis carlisles affinity analysis designed exploit locality respect linked fields analysis relies upon information regarding probability affin ity nodes accessible traversing linked field residing processor affinity high puts runtime checks eliminate remote accesses however affinity information infered compiler provided via programmer annotations locality analysis designed exploit locality achievable via linked fields discussed section wanted analysis automatic compiler analysis want burden user additional detailed information locality recursive fields explicitly declared using local pointer declarations earthc 7 conclusions work paper presented locality analysis parallel c programs based typeinference techniques analysis tries exploit additional finegrain locality coarsegrain locality information already provided user program characteristics like malloc sites evaluated effectiveness set benchmarks found eliminate significant number pseudoremote accesses provide speedups ranging modest 4 80 original parallel program several benchmarks speedup also comes close speedup obtained advanced handcoded version found locality analysis reduced burden programmer allowed us develop shorter general benchmarks based encouraging results paper plan evaluate analysis wider set bench marks also plan use flowsensitive locality propagation techniques exploit locality pointer even local within specific section program another goal automatically identify basic functions finally locality information linked fields sometimes provide significant speedups benchmarks health tsp plan extend analysis capture type locality using profile information efficientlyscheduled runtime checks acknowledgements gratefully acknowledge support people earth group specially prof guang r gao olivier maquelin research funded part nserc canada r compiling c earth multithreaded architecture study earthmanna multithreaded system polling watchdog combining polling interrupts efficient message handling designing mccat compiler based family structured intermediate representations la tency hiding messagepassing architectures efficient type inference higherorder bindingtime analysis pointsto analysis almost linear time supporting dynamic data structures distributedmemory machines olden parallelizing programs dynamic data structures distributedmemory machines commutativity analysis new analysis framework parallelizing compilers tr ctr francisco corbera rafael asenjo emilio l zapata framework capture dynamic data structures pointerbased codes ieee transactions parallel distributed systems v15 n2 p151166 february 2004 oscar plata rafael asenjo eladio gutirrez francisco corbera angeles navarro emilio l zapata parallelization irregular dynamic programs parallel computing v31 n6 p544562 june 2005