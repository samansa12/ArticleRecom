learning algorithms balancing loads time warp present paper algorithm integrates flow control dynamic load balancing order improve performance stability time warp algorithm intended use distributed memory environment cluster workstations connected high speed switch flow control algorithm makes use stochastic learning automata operates fashion leakybucket flow control algorithm used computer networks regulates flow messages processors continuously throughout course simulation dynamic load balancing algorithm invoked load imbalance detected algorithms make use spacetime product metric collect requisite information via snapshotbased gvt algorithmwe compare performance flow control algorithm dynamic load balancing algorithm integrated algorithm simulation without controls simulated large shuffle ring networks without hot spots pcs network sgi origin 2000 systemour results indicate flow control scheme alone succeeds greatly reducing number length rollbacks well number antimessages thereby increasing number nonrolled back messages processed per second results large reduction amount memory used outperforms dynamic load balancing algorithm measures integrated scheme produces even better results measures results reduced execution times well b introduction synchronization algorithm time warp 9 involves rolling simulation back previous state event arrives simulation object lp logical process timestamp smaller previously processed event order accomplish time warp periodically records checkpoints state simulation sends antimessages whose function cancel events resulted arrival straggler outoforder message well known optimistic simulations consume large amount memory subject explosive growth number rollbacks course simulation large demands memory stem checkpointing state sending antimessage output message storing input messages might later canceled problems subject much attention research literature one approach problems trying restrain optimism simulation 18 via global synchronization barrier approach 16 window virtual time defined within permissible simulate events lps provided violate causality constraints probabilistic algorithms lp determines blocking period amount time lp spends blocked state determined estimates time next event arrive comparing costs rolling back blocking 8 comparing frequency cost rollbacks 2 different approach via memory manage ment objective memory management reclamation space existing objects fossil collection reclaim sufficient space simulation may allowed continue techniques include cancelback 10 artificial rollback 11 adaptive memory management 6 attempt prevent simulation running memory increase processor utilization dynamic load balancing algorithms transfer lps heavily loaded processors lightly loaded ones 3 1 4 number metrics used evaluate load including virtual time progress number non rolled back events per second 1 queue length 7 contains comparison efficacy three metrics 14 authors use moving window fashion computer networks queuing model used determine initial window size adjusted course simulation depending performance shared memory environment integration approach adaptive memory management scheme also described algorithm described paper combines flow control algorithm dynamic load balancing algorithm flow control algorithm executed continuous basis regulating message traffic pairs communicating processors algorithm assigns pool tokens one way message flow order send message processor must first acquire token token pool depleted processor blocked number tokens pool dynamically updated throughout course simulation means stochastic learning algorithm metric use spacetime product processor defined next section dynamic load balancing algorithm employed spite use flow control load imbalance discovered condition load imbalance checked gvt cycle algorithm targeted towards use distributed memory architectures use clusters workstations connected highspeed switches contrast 14 combines memory management flow control shared memory environment section 2 paper contains description algorithms well background information stochastic learning automata section 3 describes experiments final section contains conclusions 2 algorithm make use spacetime product metric flow control dynamic load balancing algorithms define spacetime product processor real time follows st nevents number events nstates number states sizeofevent respective size event state lgv minimum lvt processor p objective algorithm control differences spacetime products processors involved simulation precisely require ffic maximum allowable difference two processors p set processors using spacetime product attempting balance memory used processors keep processors close one another virtual time order reduce possibility rollbacks 21 flow control flow control scheme similar leaky bucket scheme 17 used computer networks counter associated channel whenever packet sent counter increased counter increases fixed threshold arriving packets discarded algorithm processor first assigned number tokens permits order send message another processor processor makes use token ie time sends message processor decreases alloted token pool one separate pool tokens assigned processor corresponding processors number tokens pools varied dynamically throughout course simulation determine number tokens assigned processor means stochastic learning automata 13 sla consists stochastic automaton surrounding environment shown figure 1 environment response input input x action f pg stochastic automaton figure 1 stochastic learning automaton order make use sla flow control al gorithm must answer following questions 1 nature control model ie automata interact one another 2 reinforcement scheme used 3 often reinforcement scheme invoked provide answers questions turn control model control model consists collection automata automaton resides within processor cooperates remaining automata control flow messages figure 2 contains portrayal model defined number events arrive interval t1 t1 number departing events interval t1 defining regulation factor maximum number messages processor p may transmit processors number tokens assigned processor p next interval t1 l l environment figure 2 feedback response processor p environment reinforcement scheme adopted smodel linear rewardinaction scheme sl ri reinforcement scheme based 12 smodel takes continuous values interval 01 probability processor p sends message processor p k time denoted p ik n1 essence flow control scheme computation token generation probability p ij 6 j destination equation updating p id destination processor follows f jd tp jd tg 2 gt defined gain automaton automata involved simulation automaton n1 actions receives responses rest proces sors define regulation factor ratio define f id normalized environment response destination processor p processor f id spacetime product st ii processor p real time expressed st ii nevents nevents number events nstates number states processor p lgv minimum lvt processor p spacetime product processor piggybacked onto message sent another processor st id recent value processor p spacetime product st dd piggybacked messages sent p stmax maximum spacetime product simulation system monitored processor p time f id defined manner reflect spacetime difference processors p p value constrained lie 0 1 environ ments response sla must 0 1 effect equation 2 assigns new value p id proportion difference f id average f jd j 6 st ii st id f id equal one progressing faster p p consumes space p would like processor p acquire tokens case interpret mean p progressing faster p requires memory p would like assign fewer tokens sending processor p order reduce number outgoing messages thus value f id less 1 important recall assignment tokens processor p depend f id also depend upon mean f jd j 6 gain gt automaton computed following manner sl ri model gt processor adjusted depending upon spacetime products closeness average value st automaton residing processor spacetime product close average st gt processor assigned value close 1 automaton st farther away st value gt assigned lower value control automaton considered ineffective derived gt modifying chebyshevs theorem follows oe jst gamma expression 5 st within oe st gt equal 1 st farther away average value st gt processor p diminished proportional difference jst updating interval action probabilities periodically updated reflect responses environment elapsed time number received responses may used basis defining interval updating probabilities frequently may cause computational overloads learning automata spite reflecting recent responses environment hand infrequent updating may provide obsolete information inadequate choose optimal action action set model action probabilities updated assigned token number decreased 0 fixed number 500 events received processor 22 dynamic load balancing number dynamic load balancing algorithms appeared literature 3 15 1 4 differ one another several important ways among metric employ balance load way information pertaining value metric collected number lps chosen migrate manner chosen number metrics employed distributed load balancing algorithms examples metrics include number events input queue rate processed events processor virtual time progress effective utilization make use spacetime product previously defined metric algorithm migrates load heavily loaded processors lightly loaded processor rely gvt algorithm 5 provide information spacetime product processors involved simulation particular provides minimum spacetime product st min processor id pid min average spacetime product value st standard deviation oe processor actually makes use exponentially smoothed version spacetime product st n t1 ffst n t1 gamma ff st n order minimize fluctuation spacetime product clear mean value st standard deviation oe given gvt computation follow normal distribution number processors employed simulation small eg 6 hence use chebyshevs theorem proportion observations falling within z standard deviation units mean st least oe processor st within st sigma zoe 2oe probability st existing st sigma 2oe 075 1 therefore invoke dynamic load balancing condition choice lps migrate depends upon granularity lps amount traffic neighboring lps connectivity lps chose migrate group 10 lps transfer based upon experimental results research lps close topological relations lps residing destination processor pid min ones chosen migration 23 integrated scheme flow control dynamic load balancing flow control dynamic load balancing algorithms intention keeping spacetime product processors close one another throughout course simulation ie definition balancing workload attempting improve performance stability system integrate schemes complementary fashion integrated scheme algorithms executed independently one another flow control algorithm exerts control continuously outgoing messages processor determined action probabilities action probabilities regularly updated described hand dynamic load balancing algorithm executed gvt cycle depending whether sufficiently large load imbalance detected hence intention integrated scheme allow flow control balance load extent event sufficiently large load imbalance still detected course gvt computation load balancing algorithm invoked rectify imbalance 24 gvt computation gvt algorithm plays important part gathering dissemination information load balancing algorithms extension matterns algorithm 5 relies upon techniques used build global snapshot consistent cuts compute gvt approximate proportion within sigma 2oe normal distribution 955 5 show superior performance matterns algorithm well bellenots algorithms 3 simulation results 31 applications section compare performance flow control distributed load balancing algorithm integrated algorithm one another simulation without form control make use snapshot1 gvt algorithm described 5 simulations simulations executed sgi origin 2000 consists 8 64bit r10000 processors 256 mb memory per processor simulated shuffle ring networks pcs network 5 shuffle ring network shown figure 3 obtained modifying shuffle exchange network modified shuffle exchange network interconnecting nodes first last column substituting one input buffers local source one output buffers local sink topology gets name modification 03 figure 3 4x4 shuffle ring network pcs wireless communication network provides communications mobile users service area divided cells transmitter fixed number channels regular hexagon used represent cell user makes call channel assigned user channels allocated call blocked user moves one cell another call new channel allocated provide continuation call simulation lps correspond cells cell 500 channels calls static mobile velocity mobile call assumed constant direction chosen one six direction east southeast southwest west northwest northeast velocity direction call chosen uniform distribution call completion time determined exponential distribution mean 300 cell diameter fixed 1 km used hexagonal mesh topology wraps hexagonal mesh hmesh homogeneous graph outdegree six shown figure figure 4 wrapped hexagonal mesh n3 32 comparisons order compare algorithm made use following performance measures 1 simulation time 2 memory used 3 number length rollbacks 4 number antimessages simulated following size networks 125x125 srn 57862 lps 200x200 srn 146672 lps pcs h80 56884 lps pcs h80 network number cells peripheral edge mesh equal 80 uniform nonuniform load distributions used simulation order create nonuniform load distribution made use hot spots lps mean service times equal one third mean service times lps exponential service times used hot spots randomly distributed throughout network 33 experimental results rollbacks present results number rollbacks length rollback number antimessages produced course simulation table 1 contains number rollbacks scheme well percentage difference scheme simulation without form control results presented 125x125 srn without hot spots 200x200 srn hot spots pcs 2 links edge cells depicted figure table 1 rollback number srn networks pcs network network type table 2 antimessages srn networks pcs network network type see flow control results fewer rollbacks dynamic load balancing networks simulated except 125x125 srn without hot spots integrated scheme exhibits best per formance reduction number rollbacks ranging 1952 tables 2 3 number antimessages rollback lengths recorded tables reveal similar results flow control results fewer antimessages dynamic load balancing rollback length also shorter results dynamic load balancing except case 125x125 srn integrated scheme results best performance reducing rollback length 8 59 number antimessages reduced 1591 reason flow control scheme greater success dynamic load balancing scheme lies fact clusters lps moved processors necessary temporarily halt sending messages lps cluster results longer message delays increases probability rollback occurring increasing length rollback occurs addition lps formerly communicated one another processor must make use interprocessor links resulting larger message delays flow control algo rithm hand reacts incremental fashion dynamic load balancing algorithm cause interruption processing shifts lps exception observation 125x125 srn without hot spots reduce number rollbacks much dynamic load balancing reduction rollback length close obtained dynamic load balancing although relatively small reductions reason different behavior found nature simulations 125x125 srn simulation exhibits balanced behavior simulations two simulations hot spots pcs simulation nature experiences shifting load groups lps reason success integrated scheme judicious combination flow control dynamic load balancing flow control scheme reduces frequency dynamic load balancing algorithm needs called well number lps need transferred balance load since based learning algorithm sensitive changes load distribution processors goodput define goodput rate number processed non rolledback events simulation analogous throughput computer network intended measure progress simulation making simulated time hence measure stability simulation table 4 contains comparison goodputs three algorithms well uncontrolled simu lation table contains results simulations 125x125 200x200 srns hot spots pcs patterns established examined rollbacks antimessages assert flow control establishes superior dynamic load balancing integrated algorithm produces better results dynamic load balancing flow control srn simulations however produces results intermediate two table 3 rollback distances srn networks pcs network network type table 4 average goodput srn networks pcs network network type evtssec evtssec evtssec evtssec srn 200x200 25 242729 245782 13 288159 187 289154 191 methods pcs simulation processing load shifts course pcs simulation dynamic load balancing portion integrated algorithm suspends sending messages transfer lps processors end integrated scheme produces goodputs 1021 better uncontrolled version time warp improvements goodput generated flow control integrated algorithms result reduction number length rollbacks consequent decrease number antimessages memory table 5 contains results average amount memory used three schemes well simulation operating without control case far see flow control performs better dynamic load balancing integrated scheme gives best performance integrated scheme saves 1320 memory used uncontrolled scheme note simulation 200x200 srn uses less memory 125x125 srn simulation reason smaller gvt used termination condition 200x200 srn simulation execution times simulation times three schemes uncontrolled scheme contained table 6 percentage differences uncontrolled scheme included table cases integrated scheme provides best performance 1323 range improvements compared uncontrolled scheme examining table note flow control produce level improvements previously observed flow control also regulates sending messages necessarily increasing delays associated hence savings execution time results decrease number length rollbacks somewhat mit igated integrated algorithm dynamic load balancing algorithm reduces reliance upon flow control algorithm producing best results results indicate flow control scheme succeeded reducing number length rollbacks well number antimessages thereby increasing goodput simulation short flow control algorithm serves increase stability time warp combination flow control dynamic load balancing pronounced effect flow control dynamic load balancing alone suggests algorithm indeed act complementary fashion dynamic load balancing algorithm transferred load flow control algorithm could manage keep spacetime products sufficiently close one another reducing need invoke dynamic load balancing flow control algorithm decreased number times lps transferred processors lps trans ferred necessary suspend sending messages lps involved transfer resulting increase number length rollbacks well number antimessages sent order validate usefulness algo rithms necessary test context simulations real system hope opportunity near future table 5 used memory srn networks pcs network network type bytes bytes bytes bytes table simulation progress srn networks pcs network network type sec sec sec sec r dynamic load balancing clustered time warp logic simulation adaptive timewarp concurrency control algorithm load balancing strategies time warp multiuser workstations background execution time warp programs efficient gvt computation using snapshots adaptive memory management protocol time warp parallel simulation dynamic load balancing clustered time warp estimating rollback overhead optimism control time warp virtual time virtual time ii cancelback protocol storage management time warp reducing state saving overhead time warp parallel simulation learning automata models adaptive flow control packetswitching networks learning automata survey adaptive flow control time warp dynamic load balancing multicluster simulator network workstations speedes synchronous parallel environment emulation discrete event simulation new directions communications way information age performance evaluation bounded time warp algorithm behaviour stochastic automata variable structure tr virtual time virtual time ii storage management conservative optimistic systems adaptive memory management protocol time warp parallel simulation dynamic load balancing multicluster simulator network workstations background execution time warp programs dynamic load balancing clustered time warp logic simulation adaptive flow control time warp estimating rollback overhead optimism control time warp ctr tapas k som robert g sargent model structure load balancing optimistic parallel discrete event simulation proceedings fourteenth workshop parallel distributed simulation p147154 may 2831 2000 bologna italy johannes lthi steffen gromann resource sharing system dynamic federate mapping hlabased distributed simulation proceedings fifteenth workshop parallel distributed simulation p9198 may 1518 2001 lake arrowhead california united states herv avril carl tropper rolling back checkpointing time warp ieee transactions parallel distributed systems v12 n11 p11051121 november 2001 ewa deelman boleslaw k szymanski simulating spatially explicit problems high performance architectures journal parallel distributed computing v62 n3 p446467 march 2002 boon ping gan yoke hean low sanjay jain stephen j turner wentong cai wen jing hsu shell ying huang load balancing conservative simulation shared memory multiprocessor systems proceedings fourteenth workshop parallel distributed simulation p139146 may 2831 2000 bologna italy