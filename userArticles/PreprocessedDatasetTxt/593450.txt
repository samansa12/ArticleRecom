adaptive fraud detection one method detecting fraud check suspicious changes user behavior paper describes automatic design user profiling methods purpose fraud detection using series data mining techniques specifically use rulelearning program uncover indicators fraudulent behavior large database customer transactions indicators used create set monitors profile legitimate customer behavior indicate anomalies finally outputs monitors used features system learns combine evidence generate highconfidence alarms system applied problem detecting cellular cloning fraud based database call records experiments indicate automatic approach performs better handcrafted methods detecting fraud furthermore approach adapt changing conditions typical fraud detection environments b introduction united states cellular fraud costs telecommunications industry hundreds millions dollars per year walters wilkinson 1994 steward 1997 one kind cellular fraud called cloning particularly expensive epidemic major cities throughout united states cloning fraud causes great inconvenience customers great expense cellular service providers existing methods detecting cloning fraud ad hoc evaluation virtually nonexistent embarked program systematic analysis cellular call data purpose designing evaluating methods detecting fraudulent behavior cloning fraud one instance superimposition fraud fraudulent usage superimposed upon added legitimate usage account examples credit card fraud calling card fraud forms computer trusion superimposition fraud typically occurs nonlegitimate user gains illicit access account service legitimate user superimposition fraud detectable legitimate users fairly regular behavior generally distinguishable fraudulent behavior paper presents framework corresponding system automatically generating detectors superimposition fraud applied system domain cellular cloning fraud framework massive amounts cellular call data analyzed order determine general patterns fraud patterns used generate set monitors watches customers behavior respect one discovered pattern monitor profiles customers typical behavior use measures extent current behavior abnormal respect monitors particular pattern monitors output provided neural network weights values issues alarm combined evidence fraud strong enough article organized follows first describe problem cellular cloning fraud existing strategies detecting describe framework detail using examples implemented system present experimental results comparing system known methods detecting fraud finally discuss evaluation describe issues future automatic fraud detection 2 cellular communications cloning fraud whenever cellular phone periodically transmits two unique identification numbers mobile identification number min electronic serial number esn two numbers together specify customers account numbers broadcast unencrypted airwaves received decoded stored using special equipment relatively inexpensive 21 cloning fraud cloning occurs customers min esn programmed cellular telephone belonging customer second telephone used network sees customers min esn subsequently bills usage customer stolen min esn cloned phone user shall call bandit make virtually unlimited calls whose charges billed customer attraction free untraceable communication makes cloned phones popular major metropolitan areas fraudulent usage goes undetected customers next bill include corresponding charges typically customer calls cellular service provider carrier denies usage carrier customer determine calls made bandit legitimate calls fraudulent charges credited customers account measures taken prohibit fraudulent charges certain cases fraudulent call records referred law enforcement agency prosecution two primary motivations cloning fraud obviously cloning fraud allows lowcost communications bandit charged calls usually worth far retail dollars cost cloned phone less obviously cloning fraud allows untraceable communications bandits identity cannot tied cloned account second aspect important criminals demaria gidari 1996 cloning fraud detrimental many ways first fraudulent usage congests cell sites causing service denied legitimate customers second cellular calls noncellular destinations fraud incurs landline usage charges third cellular carriers must pay costs carriers usage outside home territory retail costs constitute considerable financial burden customers carrier fourth crediting process costly carrier inconvenient customer customer likely switch another carrier customer churn perceived less susceptible fraud reasons cellular carriers strong interest reducing cloning fraud 22 strategies dealing cloning fraud two classes methods dealing cloning fraud precall methods try identify block fraudulent calls made postcall methods try identify fraud already occurred account fraudulent usage blocked 221 precall methods precall detection methods involve validating phone user call placed common method requiring personal number pin entered every call pin serves password validated switch prior allowing call network pins use throughout many metropolitan areas united states unfor tunately like minesn pairs pins broadcast airwaves unencrypted technical reasons pins difficult receive decode sophisticated equipment pin cracking possible herzog 1995 although pins make cloning fraud difficult prevent methods prevention include rf fingerprinting authentication red den 1996 rf fingerprinting method identifying cellular phones transmission characteristics authentication reliable secure privatekey encryption method imposes inconvenience customer predicted authentication eliminate cloning fraud eventually however authentication requires changes hardware phones switches must capable processing authentication requests currently thirty million non authenticatable cell phones use united states alone replacement immediate steward 1997 meantime cloning fraud continue problem industry rely postcall fraud detection methods 222 postcall methods postcall methods periodically analyze call data account determine whether cloning fraud occurred one method collision detection involves analyzing call data temporally overlapping calls since minesn pair licensed one legitimate user simultaneous usage probably fraudulent closely related method velocity checking davis goyal 1993 involves analyzing locations times consecutive calls determine whether single user could placed traveling reasonable speeds example call made los angeles 20 minutes call made account new york two different people likely using account date time day duration origin destination fraud mins brooklyn ny stamfordct 10595 145327 fri 5 mins brooklyn ny greenwichct 10895 094201 mon 3 mins bronx ny white plains ny 10895 150124 mon 9 mins brooklyn ny brooklyn ny 10995 150609 tue 5 mins manhattan ny stamford ct 10995 162850 tue 53 sec brooklyn ny brooklyn ny 11095 014536 wed 35 sec boston chelsea bandit 11095 014629 wed 34 sec boston yonkers ny bandit 11095 015054 wed 39 sec boston chelsea bandit 11095 112328 wed 24 sec white plains ny congers ny 11195 220028 thu 37 sec boston east boston bandit east boston bandit figure 1 call records sample frauded account collisions velocity checks believed accurate share disadvantage usefulness depends upon moderate level legitimate activity lowusage subscribers example people use cellular phones emergencies rarely cause collisions velocity alarms bandits another postcall method dialed digit analysis mines call data build database telephone numbers called bandits periods fraudulent ac tivity detection database matched numbers called cus tomers alarms produced number hits threshold dialed digit hits 223 user profiling user profiling methods constitute special class postcall methods involve analyzing calling behavior order detect usage anomalies suggestive fraud profiling often works well lowusage subscribers unusual behavior prominent reason profiling good complement collision velocity checking covers cases others might miss figure shows chronological call data example fabricated frauded account fields shown sample call data contain many attributes shown column far right indicates whether call fraudulent whether call placed customer bandit fraud analyst looking account would quickly able recognize two classes calls 1 legitimate user calls metro new york city area usually working hours typically makes calls lasting minutes 2 bandits calls originate different area boston massachusetts 200 miles away made evenings last less minute ideally fraud detection system able learn rules automatically use catch fraud paper addresses automatic design user profiling methods user profiling methods attractive depend upon special hardware capability authentication require customer replace upgrade existing equipment moreover ability generate detectors domain independent system able generate fraud detectors domain superimposition fraud 23 need adaptive number commercially available expert systems fraud detection include user profiling fraud analysts system administrators tune techniques adjusting parameters entering specific patterns trigger alarms unfortunately determining potential patterns useful timeconsuming process trialanderror moreover patterns fraud dynamic bandits constantly change strategies response new detection techniques new cellular hardware capabilities time system manually tuned fraudulent behavior may changed significantly environment dynamic ways well level fraud changes dramatically monthtomonth modifications work practices carriers bandits also costs missing fraud dealing false alarms change intercarrier contracts fraud analyst workforce issues reasons important fraud detection system adapt easily new conditions able notice new patterns fraud also able modify alarm generation behavior example level fraud cost dealing false alarm changes adaptability achieved generating fraud detection systems automatically data using data mining techniques 3 automatic construction profiling fraud detectors one approach building fraud detection system classify individual trans actions calls case fraudulent legitimate classification well explored eg machine learning statistics would seem straightforward application existing techniques success using standard machine learning techniques construct classifier specific results discussed section 63 general two problems make simple classification approaches infeasible call would unusual one customer would typical another example call placed brooklyn unusual subscriber lives might strange boston subscriber 6 fawcett provost thus necessary discover indicators corresponding changes behavior indicative fraud rather absolute indicators fraud ii profile behavior individual customers characterize normal behavior available substantial information accounts context could possibly ameliorate problem context information would comprise behavior information phone used areas used areasnumbers normally calls times day context information available 1 solution derive historical data specific account discovery contextsensitive fraud indicators profiling individual accounts comprise two three major elements learning problem level individual call variation calling behavior large even particular user legitimate subscribers occasionally make calls look suspicious far able determine possible achieve simultaneously high degree accuracy high level coverage necessary classify individual calls effectively classifier fires significant number defrauded accounts produces unacceptably large numbers false alarms therefore decisions take corrective action cannot made confidence basis individual calls instead necessary aggregate customer behavior smoothing variation watch coarsergrained changes better predictive power third major element learning problem experiments describe later aggregate customer behavior accountdays sum learning problem comprises three questions corresponds component framework 1 call features important features combinations features useful distinguishing legitimate behavior fraudulent behavior 2 profiles created given important feature characterizeprofile behavior subscriber respect feature order notice important changes 3 alarms issued given results profiling behavior based multiple criteria combined effective determining fraud occurred issues corresponds component framework 4 detector constructor framework detector constructor framework illustrated figure 2 frame work system first learns rules serve indicators fraudulent behavior monitor construction monitor templates rules fraud detector call data mn training selection rule learning classifier profiling monitors figure 2 framework automatically constructing fraud detectors uses rules along set templates create profiling monitors monitors profile typical behavior account respect rule use describe far account typical havior finally system learns weight monitor outputs maximize effectiveness resulting fraud detector figure 3 shows detector used monitors provided single days calls given account monitor generates number indicating unusual accountday looks account numeric outputs monitors treated evidence combined detector detector enough evidence fraudulent activity account based indications monitors generates alarm discuss step framework detail illustrated particular choices made first implemented system applied problem cloning fraud detection first detector constructor system called dc1 call data used detecting cloning fraud chronological records calls made subscriber organized account data describe individual calls using attributes date fromstate duration cellsite accountday day time duration origin destination mins bronx ny miami fl tue 1005 3 mins scarsdale ny bayonne nj tue 1123 24 sec scarsdale ny congers ny tue 1453 5 mins tarrytown ny greenwich ct tue 1506 5 mins manhattan ny westport ct tue 1628 53 sec scarsdale ny congers ny tue 2340 17 mins bronx ny miami fl bronx night calls exceeds daily threshold airtime bronx night sunday airtime exceeds daily threshold1 0 value normalization weighting fraud alarm combining evidence q profiling monitors figure 3 dc1 fraud detector processing single accountday data 41 learning fraud rules first stage detector construction rule learning involves searching call data indicators fraud dc1 system indicators conjunctive rules discovered standard rulelearning program discussed obvious way mining fraud indicators create example set consisting frauded calls legitimate calls apply rule learning algorithm example set however approach loses context information normal behavior account fraud occurred illustrate importance context consider situation half subscribers live new york half los angeles cloned new york accounts used los angeles los angeles accounts used new york applying rule learning combined set call records would uncover fraud rules based call origin words knowing call originated new york says nothing likely fraud fact conclusion would wrong scenario new york account los angeles calls much likely cloned new york calls fact missed using combined example set combining examples account context information lost light need maintain context information rule learning performed two steps rules first generated locally based differences fraudulent normal behavior account combined rule selection step 411 rule generation dc1 uses rl program clearwater provost 1990 provost aronis 1996 generate indicators fraud form classification rules similar metadendralstyle rule learners buchanan mitchell 1978 segal etzioni 1994 webb 1995 rl performs general tospecific search space conjunctive rules type rulespace search described detail webb webb 1995 dc1 rl uses beam search rules certainty factors userdefined threshold certainty factor used runs simple frequencybased probability estimate corrected small samples quinlan 1987 order deal large numbers values attributes used describe calls 10000 values total rl also used breadthfirst marker propagation techniques algo rithms time complexity depend number attribute values aronis provost 1997 rls time complexity linear number attributes number examples call data organized account call record labeled fraudulent legitimate rl applied accounts calls produces set rules serve distinguish within account fraudulent calls legitimate calls example following rule would relatively good indicator certainty rule denotes call placed night bronx borough new york city likely fraudulent certainty means within account call matching rule 89 probability fraudulent account rl generates local set rules describing fraud account rule recorded along account generated covering heuristic typically used rl disabled maximally general rules probability estimates threshold would generated option chosen rule generation dc1 local decisions coverage made locally next step rule selection incorporates information coverage generality 412 rule selection accounts processed rule selection step performed purpose step derive set rules serve fraud indicators rule selection step necessary rule generation step typically generates tens thousands rules total specific single accounts system cannot know priori general rule example one account rl may generate rule given accts set accounts rules set fraud rules generated accts number rules required cover account taccts parameter number accounts rule must found output set selected rules 1 initialization 2 3 2 accts 4 r 2 rules 5 number accounts r occurs accounts generating r 7 end 8 set occur acctsgen 9 2 accts set rules generated 11 r 2 ra 12 occurr occurr 13 add acctsgenr 14 end end 15 cover accts rules 16 2 accts 17 list rules generated 18 sort ra occur 19 covera rules 20 r highestoccurrence rule ra 21 remove r ra 22 23 add r 24 a2 2 acctsgenr 25 26 end end 27 end end figure 4 rule selection covering algorithm used dc1 rule probably specific account generated priori way know rules generality generation step processes single account time rule found covers many accounts probably worth using found single account probably general indicator fraudulent behavior even account adaptive fraud detection 11 cloned defrauded exactly way note dc1s notion coverage slightly different standard notion multiple levels granularity particular dc1 selects set rules covers accounts opposed typical classifier learning set rules selected covers examples case calls rule selection algorithm given figure 4 algorithm identifies small set general rules cover accounts two parameters control algorithm rules threshold number rules required cover account selection process account already covered rules rules examined accts number accounts rule must found ie mined order selected account list rules generated account sorted frequency occurrence entire account set highest frequency unchosen rule selected account skipped already sufficiently covered resulting set rules used construction monitors 42 constructing profiling monitors rule learning produces set rules characterizing changes commonly occur account cloned rules universal given account know extent accounts normal behavior already satisfies rule example bronxatnight rule mentioned may useful someone living hartford connecticut may cause many false alarms subscriber living bronx fraud detection system distinguish two latter case system inhibit rule firing least require much higher level activation sensitivity different users accomplished converting rules profiling monitors monitor profiling step use step prior used account monitor profiles account profiling step monitor applied segment accounts typical nonfraud usage order measure accounts normal activity statistics profiling period saved account monitors use phase monitor processes single accountday time monitor references normalcy measures calculated profiling generates numeric value describing abnormal 2 current accountday profiling monitors created monitor constructor employs set templates templates instantiated rule conditions given set rules set templates constructor generates monitor ruletemplate pair two monitor templates shown figure 5 top template creates threshold monitors monitor yields binary feature corresponding whether users behavior threshold given day bottom figure 5 shows template standard deviation monitor profiling period monitors measure mean standard deviation oe typical usage use period produce continuous output representing many standard deviations mean accountday threshold monitors ffl given rule conditions fraud rule ffl profiling daily basis count number calls satisfy rule con ditions keep track maximum daily threshold ffl use given accountday let c set calls day satisfy rule conditions daily threshold standard deviation monitors ffl given rule conditions fraud rule ffl profiling daily basis sum airtime calls satisfying rule con ditions end training period record mean standard deviation oe samples ffl use given accountday let c set calls day satisfy rule conditions let call2c airtimecall airtime airtimegamma oe airtime figure 5 two templates creating monitors rules threshold monitor learns threshold maximum use outputs 1 whenever daily usage exceeds threshold standard deviation monitor outputs number standard deviations mean profiled usage example assume bronxatnight rule mentioned earlier used template shown figure 5b assume account subscriber called bronx average five minutes per night standard deviation two minutes end profiling step monitor would store values 52 account use account monitor processed day used used std deviation mean std deviation mean use profiling use profiling figure 6 using mean standard deviation profiling containing three minutes airtime bronx night monitor would emit zero monitor saw 15 minutes would emit 15 5 value denotes account five standard deviations average profiled usage level standard deviation monitors sensitive expected amount activity account expected daily variation activity figure 6 illustrates difference showing one monitor applied two accounts account left low variation profiling period standard deviation lower consequently erratic behavior use period produce large values monitor account right mean exhibits much larger variation profiling period standard deviation higher variations behavior use period produce large values monitor 43 combining evidence monitors third stage detector construction learns combine evidence monitors generated previous stage stage outputs monitors used features standard learning program training done account data monitors evaluate one entire accountday time training monitors outputs presented along desired output account days correct class fraud nonfraud evidence combination weights monitor outputs learns threshold sum alarms may issued high confidence many training methods evidence combining possible chose simple linear threshold unit ltu nilsson 1965 young 1984 experiments reported ltu simple fast enables good firstorder judgment features worth 14 fawcett provost feature selection process used reduce number monitors final detector rules perform well used monitors monitors overlap fraud detection coverage therefore employ sequential forward selection process kittler 1986 chooses small set useful monitors empirically simplifies final detector increases accuracy final output dc1 detector profiles users behavior based several indicators produces alarm sufficient evidence fraudulent activity figure 3 shows example simple detector evaluating accountday used account monitors profile account applied profiling segment thirty days experiments measure unfrauded usage study initial thirty accountdays guaranteed free fraud otherwise guaranteed typical initial profiling period monitor measures characteristic level activity 44 summary detector construction process sum dc1 begins examining call records defrauded accounts call records expressed terms set base level attributes thousands possible values data system generates rules characterizing fraudulent calls within accounts selects smaller set general rules indicators fraudulent behavior rules used basis build set profiling monitors examines behavior based one learned rule monitor learns typical behavior account scanning initial sequence accounts calls profiling period saving statistics subsequently monitor examines chunks calls experiments accountdays monitor subsequently examines chunk day accounts behavior outputs number indicating far away normal behavior order construct highconfidence detector dc1 must learn combine outputs monitors effectively trains classifier sample accountdays accountday training instance expressed vector monitor outputs day labelled either containing fraud training system classifier able combine monitors effectively final output system set monitors trained classifier combining outputs order applied new account monitors must see profiling period days account next sections describe cellular call data experiments performed system 5 data call data used study records cellular calls placed four months users new york city areaan area high levels fraud call described thirtyone attributes phone number caller duration call geographical origin destination call longdistance carrier used security considerations unable disclose features used system thirtyone attributes added several derived attributes incorporate knowledge judged potentially useful one attribute categorical timeofday variable representing time segment day call placed values morning afternoon twilight evening night another derived attribute topayphone binary flag indicating whether call terminated payphone note number additional features could added encode relevant domain knowledge call also give class label legitimate fraudulent done cross referencing database calls credited fraudulent time period 51 data cleaning like realworld data cellular call data contain errors noise various sources example calls marked fraudulent based process called block crediting process customer carrier representative together establish range dates fraud occurred calls within range credited customer usually asked individual call block crediting process uses heuristics discard obvious nonfraudulent calls credited block heuristics fallible also disagreement fraud span customer service representative usually concedes customers favor wider date span erroneously credited calls constitute noise data noise sources cleaned data several ways ffl accounts calls scanned automatically eliminate credited calls numbers called outside credited block words program looked credited calls made phone number also called legitimate subscriber case crediting may mistake call discarded completely ffl accountday classified fraudulent five minutes fraudulent usage occurred days including one four minutes fraudulent usage discarded policy eliminated small number gray area accountdays probably mislabelled due small amounts noise example database credits due fraud occasionally included credits reasons wrong numbers ffl within time period fraud yet detected assumed genuinely fraudulent calls would marked time lag attempted minimize noise delaying data retrieval two weeks ffl preliminary experiments rule learning uncovered unusual attribute values eg seemed strong indicators fraud discussions database providers led us conclude suspicious values artifacts crediting process circumstances crediting would erase replace certain fields values appeared primarily credited records data mining extracted highconfidence fraud rules found five six misleading values eliminated database records containing addition start times calls recorded local time respect switch origin calls normalized greenwich mean time chronological sorting 52 data selection call data separated carefully several partitions rule learning account profiling detector training testing monitors created accounts profiled system transforms raw call data series accountdays using outputs monitors features rule learning selection used 879 accounts comprising 500000 calls 3600 accounts selected profiling training testing condition used select 3600 accounts guaranteed least thirty fraudfree days usage fraudulent usage initial thirty days account used profiling remaining days usage used generate approximately 96000 accountdays using randomly selected accounts generated sets 10000 accountdays training 5000 accountdays testing training testing accounts distinct accountdays mixed training testing 3 set accountdays chosen comprise 20 fraud 80 nonfraud days 6 experiments evaluation rule learning generated 3630 rules applied two accounts rule selection process rules chosen order maximum account coverage yielded smaller set 99 rules sufficient cover accounts 99 rules used instantiate two monitor templates yielding 198 monitors final feature selection step reduced eleven monitors experiments performed 61 importance error cost domain different types errors different costs realistic evaluation take misclassification costs account classification accuracy standard metric within machine learning data mining sufficient false positive error false alarm corresponds wrongly deciding customer cloned based cost fraud analysts time estimate cost false positive error 5 false negative error corresponds table 1 accuracies costs various detectors detector accuracy cost us accuracy cost alarm 20 20000 20 alarm none 80 18111 sigma 961 80 collisions velocities high usage 88 sigma 7 6938 sigma 470 85 sigma 17 state art sota 90 sigma 4 6557 sigma 541 88 sigma 9 detector 92 sigma 5 5403 sigma 507 91 sigma 8 letting frauded accountday go undetected rather using uniform cost false negatives estimated false negative cost 40 per minute fraudulent airtime used accountday figure based proportion usage local nonlocal roaming markets corresponding costs ltu training methods try minimize errors error costs employed second step training training ltus threshold adjusted yield minimum error cost training set adjustment done moving decision threshold 1 1 increments 01 computing resulting error cost minimum cost training data found threshold clamped testing data evaluated 62 dc1 compared alternative detection strategies table 1 shows summary results dc1 compared detectors name detector shown leftmost column classification accuracy averages standard deviations shown second column third column shows mean standard deviations test set costs rightmost column accuracy cost corresponding classification accuracy detector threshold set yield lowestcost classifications detector run ten times randomly selected training testing ac counts comparison evaluated dc1 along detection strategies ffl alarm represents policy alarming every account every day opposite strategy alarm none represents policy allowing fraud go completely unchecked latter corresponds maximum likelihood accuracy classification note cost alarm none take account inhibitory effect fraud detection without fraud levels would likely continue rise ffl collisions velocities detector using collision velocity checks described section 222 dc1 used learn threshold number collision velocity alarms necessary generate fraud alarm surprising collisions velocity checks commonly thought reliable indicators cloning performed poorly experiments performance collisions velocity checks originally worse reported false alarms manual inspection false alarms revealed synchronization problems example apparent collisions caused call dropped quickly reestablished neighboring cell whose clock agree first cells conditions could caught easily patched detection algorithms check results paper improved detectors investigation confusion matrices revealed collision velocity check detectors errors due almost entirely false negatives words detectors fired accurate many fraud days never exhibited collision velocity check ffl fraud analysts believe cloning fraud usually accompanied large jumps account usage sophisticated mining fraud indicators probably unnecessary since fraud could caught looking sudden increases usage created high usage detector test hypothesis generates alarms based amount usage essentially standard deviation monitor see figure 5 whose rule conditions always satisfied threshold detector found empirically training data note evaluation cost high usage detector may overly optimistic due inadequacies cost model particular trained high usage detector learns optimally skim cream without regard fact errors makes involve annoying best customers cases cost false alarm may much higher fixed cost assigned ffl best individual dc1 monitor used isolated detector experiment done determine additional benefit combining monitors best individual monitor generated rule rule learning discovered 119 accounts sudden appearance evening calls accounts normally make coincident cloning fraud relatively high accuracy one monitor reveals valuable fraud indicator timeofday attribute five possible values morning noon twilight evening night although evening far frequent value implicated fraud rule learning generated fraud rules involving values suggests timeofday change subscribers normal behavior may indicative fraud though shifts may predictive enough use fraud monitor ffl dc1 detector incorporates monitors chosen feature selection used weight learning method described earlier determine weights evidence combining adaptive fraud detection 19 ffl art detector incorporates thirteen handcrafted profiling methods best individual detectors identified previous study method profiles account different way produces separate alarm weights combining sotas alarms determined weighttuning algorithm details detectors comprising given appendix results table 1 demonstrate dc1 performs quite well fact dc outperforms terms accuracy cost 4 experiments lowest cost classification occurred accuracy somewhat lower optimal words classification accuracy sacrificed decrease cost sophisticated methods could used produce cost sensitive classifiers would probably produce better results finally monitors sota dc1 combined hybrid detector resulting detector exhibits increase classification accuracy show slight improvement fraud detection cost work dealt differing costs false positive false negative errors however still glossed complexity given account false negative fraud days incur cost company prior first true positive alarm fraud detected terminated thus analysis overestimates costs slightly thorough analysis would eliminate days computation 63 fraudulent call classifiers section 41 asserted account context important rule learning step global example set taken accounts would lose information accounts normal behavior order test hypothesis two call classifiers created global example sets applying standard classification algorithms call data difficult several reasons first description language detailed many thousands attribute values appear data volume data necessary relatively large desktop platforms use fewer 100000 examples led erratic classification behavior furthermore order achieve high coverage calls massively disjunctive concept descriptions learned simple classifiers performed well trying many approaches chose two classifiers learned following manner set 100000 training examples sampled accounts set aside rule learning sample random stratified achieve 5050 class distribution rl applied data parameters set learned massively disjunctive rule sets two classifiers cc 1054 cc 1861 comprise 1054 1861 rules respectively 5 rule sets covered around 60 calls 92212 example test set accuracy 75 calls covered observed clear graceful tradeoff accuracy coverage coverage increased accuracy decreased table 2 comparison dc1 two global call classifiers detector accuracy cost us accuracy cost detector 92 sigma 5 5403 sigma 507 91 sigma 8 order achieve competitive comparison call classifiers given advantage profiling monitoring standard deviation airtime monitor created specifically instead instantiating monitor template single rule template instantiated entire classifier resulting monitor profiled accounts normal behavior respect clas sifiers output call classifier monitor learns particular customers legitimate behavior typically triggers positive output furthermore call classifier monitor inserted dc1 weighttraining framework order find optimal output threshold accuracy maximization cost minimization results shown table 2 two call classifiers perform similarly outperforms considerable margin indeed surprised call classifier monitors perform well 64 shifting distributions fraud discussed section 23 fraud detection system able adapt shifting fraud distributions example month relative amount fraud changes slightly rarely possible predict level fraud far future thus unless adaptive even welltuned detection system begin lose edge illustrate point simulated effects changing fraud distributions detector performance one dc1 detector trained fixed distribution accountdays 80 nonfraud 20 fraud tested several distributions ranging 75 99 nonfraud accountdays simulate welltuned nonadaptive detection system another dc1 detector allowed adapt distribution ltu threshold retrained minimum predicted cost training set new distribution results shown figure 7 xaxis percentage nonfraud accountdays yaxis cost per account day figure shows second detector allowed adjust new distribution consistently cost effective fixed detector difference increases testing distribution becomes skewed distribution upon fixed detector trained close noting experiments illustrated changes fraud detection performance respect fairly simple changes fraud distribution changing adaptive fraud detection 210206114 cost percentage nonfraud trained 8020 adapted distribution figure 7 effects changing fraud distributions fraud volume patterns fraud also change particularly reponse detection methods thus ability use data mining discover new patterns amplifies benefit adaptability 65 discussion difficult evaluate dc1 existing expert systems fraud detection fraud detection departments carefully protect information much fraud effective detection strategies likewise vendors fraud detection systems protect details systems operation may constitute trade secrets little performance data fielded systems available data exist insufficient careful evaluation reasons evaluated dc1 individual known fraud detection techniques well collection techniques representing state art understand results previous sections show dc detector performs better highusage alarm collisionvelocity alarm dc1 also outperforms detector consisting collection best fraud detection techniques known us trained dc1s evidence combining method 22 fawcett provost dc1s framework three main components complex approaches experiments designed evaluate overall performance system also analyze contribution individual components particular ffl high usage detector profiles respect undifferentiated account usage comparison dc1s performance demonstrates benefit using rule learning uncover specific indicators fraudulent calls ffl call classifier detectors represent rule learning without benefit account context comparison dc1s performance demonstrates value dc1s rule generation step preserve account context ffl comparison dc1 single best individual dc1 monitor demonstrates benefit combining evidence multiple monitors ffl experiments shifting fraud distributions indicate benefit making evidence combination sensitive fraud distributions cases composite dc1 system outperformed detector significant piece missing results suggest component contributes critically performance entire detector system uses linear threshold unit combine evidence monitors methods evidence combination possible performed experiments multilayer neural networks found adding units hidden layer improve performance networks produced higher training accu racies lower accuracies test sets behavior symptomatic data overfitting additional experimentation might yield betterperforming networks pursued possible neural network applied far along fraud detection process means combining evidence nonlinear combinations evidence contribute little fraud detection performance increasing expressiveness language used inductive learning may possible learn general patterns fraudulent behavior reducing need highly disjunctive class descriptions caveats mentioned earlier inability procure background knowledge context notwithstanding may possible provide additional context linking call account data geographic demographic databases furthermore may possible learn context one stage apply relational learning approaches later stage one possibility make use inductive learners learn concept descriptions firstorder logic foil quinlan 1990 ilp methods dzeroski 1996 given appropriate context information possible expressive methods could learn general relational rules following indicates fraud user calls abnormal location another possibility use learner forms propositional rules take advantage relational background knowledge process aronis provost buchanan 1996 explored use relational learning great extent linked data knowledge geographic locations telephone numbers aronis provost 1997 produce useful generalizations areas calls placed finally important point additional limitations evaluation learned classifiers realworld problems work described paper made use techniques deal skewed class distributions viz stratified sam pling deal nonuniform misclassification costs viz empirical threshold adjustment also ensured evaluation include cost effectiveness addition accuracy however complexity dynamics realworld domains determining precisely target cost class distributions often im possible noted levels fraud costs change monthly important able compare competing classification methods imprecision distributions investigation design techniques important area future research provost fawcett 1997 7 related work fraud detection related intrusion detection field computer security concerned detecting attacks computers computer networks frank 1994 sundaram 1996 kumar 1995 many forms intrusion instances superimposition fraud thus candidates systems built framework within intrusion detection community anomaly detection systems try characterize behavior individual users order detect intrusions users account via anomalies behavior existing anomaly detection systems typically examine audit trails user activities fill roll cellular call records dc 1 dc1 would considered statistical anomaly detection system sundaram open issue statistical approaches particular anomaly detection systems general selection measures monitor choice metrics known exactly subset possible measures accurately predicts intrusive activities dc1s framework directly addresses problem rule learning step examines large numbers fraud episodes order generate features measures distinguish fraudulent legitimate behavior best knowledge published anomaly detection system calling card fraud credit card fraud forms superimposition fraud system built yuhas 1993 1995 examines set records representing calling card validation queries identify queries corresponding fraudulent card usage yuhas transformed problem twoclass discrimination task trained several machine learning models data three models comparable performance test sets system must provided appropriate fea tures neither mines data fraud indicators measures typical customer usage stolfo et al 1997 address credit card fraud detection also transform problem twoclass discrimination task use customerspecific information detection specifically predict whether individual transactions fraudulent domain found dc1 significantly improves detection performance systems use transaction classification alone would interesting determine whether system like dc1 could improve performance superimposition fraud tasks ezawa norton 1995 1996 addressed problem uncollectible debt telecommunications services use goaldirected bayesian network clas sification distinguishes customers likely default work ezawa nortons work faces problems unequal error costs skewed class distributions however face problem determining typical behavior individual customers recognize superimposed fraudulent behavior mining data derive profiling features necessary fraud happens time methods deal time series relevant work however traditional time series analysis chatfield 1984 farnum stanton 1989 statistics strives either characterize entire time series forecast future events series neither ability directly useful fraud detection hidden markov models rabiner juang 1986 smyth 1994 concerned distinguishing recurring sequences states transitions however fraud detection usually deals two states frauded unfrauded states single transition yuhas 1995 mentions possibility recognizing home travel states order distinguish frauded states effectively differentiation could useful reducing false alarms aware work pursuing idea 8 conclusion detection cellular cloning fraud relatively young field fraud behavior changes frequently bandits adapt detection techniques fraud detection systems adaptive well however order build usage monitors must know aspects customers behavior profile historically determining aspects involved good deal manual work hypothesizing useful features building monitors testing determining combine involves much trialanderror well presented demonstrated framework automates process generating fraud detectors framework specific cloning fraud may applied superimposition fraud problems domain prime candidates toll fraud computer intrusion creditcard fraud example creditcard fraud data mining may identify locations arise new hotbeds fraud constructor would incorporate monitors notice customers begin charge usually specific locations even relatively simple components dc1 able exploit mined data produce detector whose performance exceeds stateoftheart system took several personmonths build dc1 detector took several cpuhours furthermore dc1 retrained time necessitated changing environment adaptability beneficial many ways save effort timeconsuming manual feature identification detector tuning save monetary losses would occur manual identification tuning process save less quantifiable damage done due higher fraud lower customer opinion even customer churn finally act prevent fraud system quickly adapts new patterns avoided bandits favor easier prey acknowledgments work sponsored nynex science technology views conclusions paper authors represent official policy thank nicholas arcuri fraud control department bell atlantic nynex mobile many useful discussions cellular fraud detection also thank usama fayyad andrea danyluk anonymous referees comments drafts developing dc1 made extensive use many freelyavailable software pack ages wish thank generous authors developers maintainers following software perl programming language many usercontributed modules donald tveters backprop program numerous gnu packages including emacs gcc gmt geographic information system gnuplot processing system appendix state art sota detector art detector incorporates thirteen profiling methods method profiles account different way produces separate alarm monitors designed hand employ weights used dc1s weight tuning methods specifically sota contains following monitors ffl two collision detectors scan call collisions greater ffl two velocity detectors using velocity thresholds 400 600 miles per hour respectively ffl three dialed digits monitors created dialed digit database follows scanned accounts reserved rule learning recorded many 26 fawcett provost distinct accounts called given number legitimately fraud period phone number discarded legitimate subscriber called otherwise count saved number times called cloned phone know ideal threshold number hits required created three monitors different threshold ffl two daily standard deviation usage monitors one counted number calls accountday one measured total airtime accountday ffl four bad cellsite indicators commonly believed certain cellsites locus higher average amounts fraud calls originating cellsites might suspicious test strategy tallied frauded accounts calling cellsites region computed percentage frauded accounts using cellsite twenty worst cellsites extracted list using cellsite list created four detectors counted hits bad cellsites different way notes 1 fact many cellular phones belong large corporate accounts often even basic user information home town work location unavailable 2 technically numeric value describes much normal account behavior levels normal considered 3 accountdays single account appear training testing sets performance evaluation deceptively optimistic fraudulent behavior within specific cloning episode similar fraudulent behavior episodes deployed monitors used search previously unseen cloning episodes 4 earlier work fawcett provost 1996 reported higher accuracy sota shown development sota revealed component methods developed prior study built account data overlapped data used test methods strict separation enforced performance declined slightly figures shown 5 learn cc 1861 1054 rl tried cover example set rules covered least 50 100 examples laplace estimate greater equal 095 using beam width 5000 r increasing efficiency data mining algorithms breadthfirst marker propagation exploiting background knowledge automated discovery analysis time series introduction third edition inductive logic programming knowledge discovery databases quantitative forecasting methods combining data mining machine learning effective user profiling feature selection extraction edupubcoastkumarphdintdet learning machines scaling inductive learning massive parallelism analysis visualization classifier performance comparison imprecise class cost distributions learning logical definitions relations generating production rules decision trees ieee assp magazine 3 1 learning decision lists using homogeneous rules hidden markov models fault detection dynamic systems jam java agents metalearning distributed databases opus efficient admissible algorithm unordered search recursive estimation timeseries analysis foster provost researcher machine learning data mining nynex science technology since tr ctr tom e fawcett foster provost fraud detection handbook data mining knowledge discovery oxford university press inc new york ny 2002 jiawei han russ b altman vipin kumar heikki mannila daryl pregibon emerging scientific applications data mining communications acm v45 n8 august 2002 zhaohui zheng xiaoyun wu rohini srihari feature selection text categorization imbalanced data acm sigkdd explorations newsletter v6 n1 june 2004 taeho jo nathalie japkowicz class imbalances versus small disjuncts acm sigkdd explorations newsletter v6 n1 june 2004 padhraic smyth task method selection selection tasks handbook data mining knowledge discovery oxford university press inc new york ny 2002 signaturebased methods data streams data mining knowledge discovery v5 n3 p167182 july 2001 tom fawcett peter flach response webb tings application roc analysis predict classification performance varying class distributions machine learning v58 n1 p3338 january 2005 saharon rosset uzi murad einat neumann yizhak idan gadi pinkas discovery fraud rules telecommunicationschallenges solutions proceedings fifth acm sigkdd international conference knowledge discovery data mining p409413 august 1518 1999 san diego california united states tom e fawcett industry adaptive fraud detection handbook data mining knowledge discovery oxford university press inc new york ny 2002 kenji yamanishi junichi takeuchi discovering outlier filtering rules unlabeled data combining supervised learner unsupervised learner proceedings seventh acm sigkdd international conference knowledge discovery data mining p389394 august 2629 2001 san francisco california wenke lee salvatore j stolfo kui w mok mining dataflow environment experience network intrusion detection proceedings fifth acm sigkdd international conference knowledge discovery data mining p114124 august 1518 1999 san diego california united states chris drummond robert c holte explicitly representing expected cost alternative roc representation proceedings sixth acm sigkdd international conference knowledge discovery data mining p198207 august 2023 2000 boston massachusetts united states nilesh dalvi pedro domingos mausam sumit sanghai deepak verma adversarial classification proceedings tenth acm sigkdd international conference knowledge discovery data mining august 2225 2004 seattle wa usa david jensen matthew rattigan hannah blau information awareness prospective technical assessment proceedings ninth acm sigkdd international conference knowledge discovery data mining august 2427 2003 washington dc data mining approach database intrusion detection proceedings 2004 acm symposium applied computing march 1417 2004 nicosia cyprus jennifer neville zgr imek david jensen john komoroske kelly palmer henry goldberg using relational knowledge discovery prevent securities fraud proceeding eleventh acm sigkdd international conference knowledge discovery data mining august 2124 2005 chicago illinois usa michael h cahill diane lambert jos c pinheiro x sun detecting fraud real world handbook massive data sets kluwer academic publishers norwell 2002 albert orriols ester bernadmansilla class imbalance problem learning classifier systems preliminary study proceedings 2005 workshops genetic evolutionary computation june 2526 2005 washington dc foster provost ron kohavi guest editors introduction applied research machinelearning machine learning v30 n23 p127132 feb march 1998 hang honghua dai applying positive negative selection supervised learning anomaly detection proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa tom fawcett roc graphs instancevarying costs pattern recognition letters v27 n8 p882891 june 2006 f bonchi f giannotti g mainetto pedreschi classificationbased methodology planning audit strategies fraud detection proceedings fifth acm sigkdd international conference knowledge discovery data mining p175184 august 1518 1999 san diego california united states tom fawcett foster provost activity monitoring noticing interesting changes behavior proceedings fifth acm sigkdd international conference knowledge discovery data mining p5362 august 1518 1999 san diego california united states mukund narasimhan paul viola michael shilman online decoding markov models latency constraints proceedings 23rd international conference machine learning p657664 june 2529 2006 pittsburgh pennsylvania wenke lee salvatore j stolfo kui w mok adaptive intrusion detection data mining approach artificial intelligence review v14 n6 p533567 december 1 2000 fabrizio angiulli stefano basta clara pizzuti detection prediction distancebased outliers proceedings 2005 acm symposium applied computing march 1317 2005 santa fe new mexico fisher daryl pregibon anne rogers hancock language extracting signatures data streams proceedings sixth acm sigkdd international conference knowledge discovery data mining p917 august 2023 2000 boston massachusetts united states tom fawcett introduction roc analysis pattern recognition letters v27 n8 p861874 june 2006 information mining platforms infrastructure kdd rapid deployment proceedings fifth acm sigkdd international conference knowledge discovery data mining p327331 august 1518 1999 san diego california united states markus breunig hanspeter kriegel raymond ng jrg sander lof identifying densitybased local outliers acm sigmod record v29 n2 p93104 june 2000 rakesh agrawal sridhar rajagopalan ramakrishnan srikant yirong xu mining newsgroups using networks arising social behavior proceedings 12th international conference world wide web may 2024 2003 budapest hungary p janeja vijayalakshmi atluri ahmed gomaa nabil adam christof bornhoevd tao lin dmams employing data mining techniques alert management proceedings 2005 national conference digital government research may 1518 2005 atlanta georgia perlich foster provost distributionbased aggregation relational learning identifier attributes machine learning v62 n12 p65105 february 2006 jennifer neville david jensen relational dependency networks journal machine learning research 8 p653692 512007 gang wu edward chang kba kernel boundary alignment considering imbalanced data distribution ieee transactions knowledge data engineering v17 n6 p786795 june 2005 tamas abraham event sequence mining develop profiles computer forensic investigation purposes proceedings 2006 australasian workshops grid computing eresearch p145153 january 1619 2006 hobart tasmania australia miroslav kubat robert c holte stan matwin machine learning detection oil spills satellite radar images machine learning v30 n23 p195215 feb march 1998 wengkeen wong andrew moore gregory cooper michael wagner whats strange recent events wsare algorithm early detection disease outbreaks journal machine learning research 6 p19611998 1212005 fisher daryl pregibon anne rogers frederick smith hancock language analyzing transactional data streams acm transactions programming languages systems toplas v26 n2 p301338 march 2004 klaus julisch marc dacier mining intrusion detection alarms actionable knowledge proceedings eighth acm sigkdd international conference knowledge discovery data mining july 2326 2002 edmonton alberta canada ting liu andrew w moore alexander gray new algorithms efficient highdimensional nonparametric classification journal machine learning research 7 p11351158 1212006 chris drummond robert c holte cost curves improved method visualizing classifier performance machine learning v65 n1 p95130 october 2006 clifton phua damminda alahakoon vincent lee minority report fraud detection classification skewed data acm sigkdd explorations newsletter v6 n1 june 2004 maarten van someren tanja urbani applications machine learning matching problems tasks methods knowledge engineering review v20 n4 p363402 december 2005 foster provost tom fawcett robust classification imprecise environments machine learning v42 n3 p203231 march 2001 sofus macskassy foster provost classification networked data toolkit univariate case study journal machine learning research 8 p935983 512007 gediminas adomavicius alexander tuzhilin expertdriven validation rulebased user models personalization applications data mining knowledge discovery v5 n12 p3358 januaryapril 2001 yongwon lee bruce g buchanan john aronis knowledgebased learning exploratory science learning rules predict rodent carcinogenicity machine learning v30 n23 p217240 feb march 1998 klaus julisch clustering intrusion detection alarms support root cause analysis acm transactions information system security tissec v6 n4 p443471 november foster provost venkateswarlu kolluri data mining tasks methods scalability handbook data mining knowledge discovery oxford university press inc new york ny 2002 predrag radivojac nitesh v chawla keith dunker zoran obradovic classification knowledge discovery protein databases journal biomedical informatics v37 n4 p224239 august 2004 maloof p langley binford r nevatia sage improved rooftop detection aerial images machine learning machine learning v53 n12 p157191 octobernovember jianping fan hangzai luo jing xiao lide wu semantic video classification feature subset selection context concept uncertainty proceedings 4th acmieeecs joint conference digital libraries june 0711 2004 tuscon az usa foster provost venkateswarlu kolluri survey methods scaling inductive algorithms data mining knowledge discovery v3 n2 p131169 june 1999 darse billings lourdes pea jonathan schaeffer duane szafron learning play strong poker machines learn play games nova science publishers inc commack ny 2001