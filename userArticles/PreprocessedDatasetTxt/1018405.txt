towards proving strong direct product theorems fundamental question complexity theory direct product question famous example yaos xorlemma one assumes function f hard average small circuits meaning every circuit fixed size attempts compute f wrong nonnegligible fraction inputs concludes every circuit size small advantage guessing randomly computing fxk independently chosen x1xk known proofs lemma property words circuit attempts compute fk smaller circuit attempts compute f single input paper addresses issue proving strong direct product assertions ones ks particular larger study question proving strong direct product question decision trees communication protocols b introduction 11 direct product question given boolean function f domain x integer k define function f intuitively f hard average say f computed correctly computational class 12 pfraction inputs expect f k computed correctly 12 fraction inputs intuition based information theoretic analog information theoretic setup f biased random coin probability heads k exclusiveor k independent coins indeed induces coin probability heads roughly equal 12 transferring intuition information theoretic setting computational settings much involved one expect first glance assertions referred direct product assertions let us present direct product question general computational setting consider computational resource circuit size decision tree depth number bits exchanged communication protocol let res r denote class functions computable using r units resource paper consider following classes size family functions computed circuits size comm c family functions two inputs computed communication protocol exchanges c bits depth family functions computed decision trees depth saying function f hard average res r means every algorithm res r computes f correctly bounded fraction inputs 1 use following notation suc res since f boolean always computed least half inputs interested advantage algorithm get guessing adv res direct product question presented follows 2 direct product problem true f r k adv res r p parameters words one supposes f hard average algorithms r units resource concludes f k hard average algorithms 1 paper restrict average case hardness relative uniform distribution indeed results generalize arbitrary probability distributions see discussion end paper dierent variant sometimes considered concatenation variant involves replacing function f k f k x1 xk asking weather suc res two variants closely related particular strong direct product assertion f k implies strong direct product assertion f k exact details omitted version r units resource naturally assertion stronger r large p small say assertion optimal r seems reasonable allow algorithm attempting compute f k use kr units resource input k times larger algorithm attempting compute f paper interested proving direct product assertions large r call assertions strong r kr p strongdirect product problem true f r k adv res res results r parameter fixing r kr made simplify presentation 3 12 previous work studied model direct product results circuit complexity called yaos xorlemma yao82 stated way terminology adv size number inputs f note result actually smaller words circuit tries compute f many instances smaller one tries compute f one instance unavoidable sense known proofs lemma lev85 imp95 gnw95 iw97 work proving contrapositive claim adv size f p use circuit computes f k subcircuit circuit computes f see gnw95 survey yaos xorlemma another unpleasant feature result p always larger 1s means one benefit taking k log unpublished result commonly attributed steven rudich shows blackbox 4 proofs xorlemma suer flaw thus proving result p 1s seems beyond current ability know handle boolean circuits using black boxes direct product question also studied computational models nisan et al nrs94 consider specific variant decision trees call decision forests kdecision forest depth consists k decision trees depth allowed query k inputs ith tree supposed compute fx final output decision forest concatenation outputs individual trees let us denote class functions computable depth kdecision forests f orest kd terminology result could stated way suc depth orest f k parnafes et al prw97 used technique razs parallel repetition theorem raz98 prove product theorem forests cbit communication protocols 5 result similar flavor 3 particular negative results work whenever p p apply intermediate values r positive result communication complexity gives tradeo r p 4 black box refers proofs like ones mentioned use circuit computes f k well black box circuit computes f well 5 forest cbit communication protocol collection k cbit communication protocols k inputs ith protocol supposed compute function ith input nrs94 exception p kc dependence c comes technique raz whereas dependence c unavoidable parallel repetition theorem shown fv96 open weather result prw97 best possible forests communication protocols 13 results first result general counterexample shows strong direct product assertions even ones r suciently larger r simply true apply counterexample whenever function adv res r f small yet f res r r much larger r means whenever computational model functions hard given r units resource easy given slightly units cannot expect strong direct product assertion hold counterexample applies boolean circuits communication protocols decision trees counterexample rules possibility strong direct product assertions seems exploit defects formulation problem rather show general intuition direct product assertions false intuitively algorithm counterexample able compute f k correctly high probability using resources imbalanced way allocating lot resources specific instances beneficial algorithm function counterexample high probability easy many instances contradict intuition strong direct product assertions true counterexample belief beneficial algorithm correlate computations dierent inputs elaborate point section 33 case assertion true order capture intuition prove strong direct product assertion would either strengthen assumption weaken conclusion 131 strengthening assumption demanding information function function presented counterexample property large subset inputs easy checking weather input belongs subset feasible algorithm natural ask weather strong direct product assertion holds functions property generally kind restrictions place function order make strong product assertion hold provide answer questions communication protocols analyzing discrepancy f k discrepancy f denoted discf measures imbalanced f large rectangles using ideas nw94 able show standard adv comm c f discf2 c immediately entails adv comm inequality following interpretation fact f hard average cbit communication protocols follows fact f low discrepancy strong product theorem holds f would like point discrepancy method common way prove f hard average communication protocols 132 weakening conclusion imposing restrictions algorithm algorithm presented counterexample property uses resource unfair way spending r units particular inputs natural ask weather strong direct product assertion holds fair algorithms generally kind restrictions place algorithm order make strong direct product assertion hold intuitively forest model nrs94 restriction however would like algorithm restricted algorithm res kr suggest impose fairness restriction algorithm evidence potential direction prove optimal direct product theorem fair decision trees decision tree depth kd variables x 1 x k fair every path root leaf bits variable queried let us denote class fair decision trees depth kd f airdepth kd hard prove following theorem adv depth kd hope two directions present extended prove strong direct product assertions stronger computational models 14 organization paper section 3 present counterexample section 4 prove strong direct product theorem communication protocols via discrepancy method section 5 prove strong direct product theorem fair decision trees preliminaries use denote exclusive two matrices b size n n use b denote tensor product two matrices precisely b n 2 think matrix n n matrix entries matrices size n n place copy matrix ij b ith row jth column tensor product k times denoted k use size denote class functions arbitrary number inputs computable boolean circuits size use comm c denote class functions two arguments computed cbit communication protocol exact definition communication protocol found textbook subject ie kn97 property protocols used paper protocol induces partition inputs 2 c rectangles use depth denote class functions computed decision tree depth whereas decision tree binary tree every internal node labeled specific bit input leafs labeled outputs input decision tree defines path root leaf obvious way output tree input leaf label 3 general counterexample section give general counterexample direct product results r boolean circuits decision trees communication protocols show given function hard given r units resource easy given slightly units construct function hard given r units resource yet computing k independent inputs easy present example using general notation section 31 draw conclusions specific models section 32 section 33 discuss implications counterexample 31 general setting present function hard average given r units resource yet f k computed correctly probability units resource r suciently larger r counterexample works assuming existence function hard given r units resource easy given slightly units formally assume existence function 0 1 r r suc res g res r another ingredient easy function inputs answers one prescribed fraction inputs formally given number q 1 assume existence function 0 1 small number r h res r pr yr 01 l counterexample function combination easy hard functions 0 1 l 0 1 following way algorithm computing f k utilize resource smartly spending lot resource expectedly inputs f involves hard function spend small amount inputs made formal following lemma lemma 1 following inequalities hold suc res r 2qkr proof lemma 1 first item note algorithm correct f probability greater 1 q4 must correct g probability greater 34 second third item note 1 k randomly chosen expect qk hy chernos inequality probability 2qk hy bounded check hy using kr units resource assuming constant function zero computed using 0 units resource compute function f x hy assuming 2qk use 2qkr units compute outputs hard inputs thus suc res corollary 1 kr remark 1 noted function f constructed isnt pathological may seem first glance impagliazzos hard core theorem imp95 shows least boolean circuit model every function f suc size large subset inputs slightly smaller circuit succeeds probability roughly 12 example hard core f function g unnatural state aairs example function easy outside hard core deciding weather input hard core easy computational task 32 conclusions specific models order use counterexample previous section show existence required building block functions g h various computational models use function h constructions namely choose l define h 0 1 l 0 1 take value one inputs zeroes zero otherwise immediate verify h size ol comm l depth l accepts qfraction inputs 321 boolean circuits hierarchy theorem circuits provides us function computable size size n following formulation weaker best known result theorem 1 pw86 2 n function 0 1 n 0 1 size size sn use hardness amplification techniques convert function hard average slightly smaller size 6 theorem 2 imp95 stv99 size exists function 0 1 suc size combining theorems 12 get existence function g wanted corollary 2 2 n constant exists function suc size using lemma 1 conclude adv size f c constants depend constant hidden the4528762 means strong direct product assertions true boolean circuits 7 6 hardness amplification techniques involve proving xorlemmas circuits thus counterexample actually based true direct product assertion hardness amplification results used explicit sense new function eciently computed given access initial one reflected moreover clause next lemma necessary purposes result stated strong variant hardness amplification sense new function roughly number inputs initial one 7 also draw conclusion general weakness example starting advantage constant 322 communication protocols communication complexity use inner product function gx functions n bit inputs g comm n known g hard average given n4 bits communication 8 theorem 3 cg88 adv comm using lemma 1 conclude adv comm kc c f suciently small constant q suciently large constant k thus strong direct product assertions communication protocols evan starting constant advantage remark 2 example c large particular avoided padding inputs two players increase n 323 decision trees decision trees choose g parity function immediate depth n adv depth use lemma 1 get counterexample behavior parameters counterexample communication protocols 33 bad counterexample seems counterexample bad sense contradict intuition direct product assertions true proving direct product assertion main task show algorithm benefit correlating computations dierent inputs counterexample presented correlations occur instead algorithm uses resource unbalanced way spending lot particular inputs particular algorithm able compute f single instances advantage greater p something ruled r r would like change formulation direct product problem rule cases next two sections suggest two strengthenings one involves adding assumptions function f hope assumptions prevent situation counterexample intuitively f hard robust way additional resources spent f one instance result loss another instance beneficial treat inputs unfairly involves restricting algorithm way insures cannot advantage greater p attempting compute f single coordinate 4 discrepancy product theorem previous section weve seen direct product assertion communication protocols true allow protocol trying compute f k communicate bits protocol attempting compute f section show f low discrepancy strong direct product theorem holds f convenient think outputs communication complexity problem 1 1 rather 0 1 thus problem viewed matrix entries 1 1 8 preparing section 4 remark proof statement works showing g low discrepancy matrix necessarily square matrix input dierent players may chosen sets dierent sizes still remainder section assume matrix square matrix results follow general case well assumption made simplify presentation choice 1 1 made tensor product k times denoted exactly matrix communication problem k set c n use c denote characteristic vector c c n n matrix entries 1 1 rectangle c n define c discrepancy defined following way maximum taken rectangles fixed rectangle c cd measures imbalanced matrix rectangle r r rectangle reached leaf communication protocol half quantity advantage protocol gets random guessing rectangle r definition multiplies quantity cd n 2 take account volume rectangle precisely advantage random guessing multiplied volume rectangle r give contribution r advantage protocol random guessing normalization made low discrepancy imply problem hard average made formal following lemma proof lemma 2 let p cbit communication protocol achieves adv comm c cbit communication protocol partitions 2 c disjoint rectangles rectangle r advantage protocol bounded bound advantage adv comm c requirement disca small stronger hard average still common way showing communication problems hard average showing low discrepancy intuitively low discrepancy provides smooth hardness condition rules counterexample previous section remark 3 note submatrix b discrepancy b upper bounded discrepancy times ratio volumes b thus lemma 2 low discrepancy means large submatrix average case hard another nice feature setup checking membership b easy communication protocols done exchanging bits thus captures intuition subsets inputs bound function easily computable compared remark 1 main theorem paper shows discrepancy taking tensor product k times goes exponentially k theorem 4 kthis following interpretation suppose often case fact adv comm p follows fact disca p2 c case adv comm words get strong direct product theorem stated generality next corollary corollary 3 every c adv comm note formulation one get rid constant 3 get result adv comm kc terms disca proof theorem require definition spectral norm matrix definition 3 vector x use x 2 denote l2norm x matrix 2 defined useful consider equivalent definitions norm fact 1 equivalent definitions 2 1 2 eigenvalue useful property 2 multiplicative tensor product fact 2 proof fact 2 consists two steps first show true symmetric matrices symmetric orthonormal basis eigenvectors maximal eigenvalue absolute value easy see eigenvalues k exactly products eigenvalues thus fact follows non symmetric matrices using second item fact 1 observation remainder section prove theorem 4 first step express discrepancy terms spectral norm use multiplicativity spectral norm get conclusion second item fact 1 enables us upper bound discrepancy using spectral norm proof lemma rectangle c define note c follows first item fact 1 c c nw94 nisan wigderson address called logrank conjecture show use ideas paper lower bound discrepancy using spectral norm lemma 4 disca start showing theorem 4 easily follows lemma 4 proof theorem first inequality follow lemma 3 second follows fact 2 third follows lemma 4 want prove lemma 4 similar way previous lemma first step way transform bilinear form arbitrary vectors one characteristic vectors transformation given nisan wigderson nw94 lemma 5 nw94 let u v vectors u v 1 exist rectangle completeness give proof lemma proof lemma 5 split u v positive coordinates negative coordinates u four vectors nonnegative since u one four terms larger absolute value u av4 setting c nonnegative coordinates upart term nonnegative coordinates vpart term tempted use lemma 5 directly prove lemma 4 start u v get rectangle roughly value since get bound disca divide n 2 thus argument gives non impressive estimate disca 2 case u v u v 1 could deduce 2 disca 2 better show 2 obtained u v lemma 6 vectors u v u v u av proof lemma vectors x let u vector obtained x setting coordinates zero v vector obtained setting coordinates j zero note j 1 2 since otherwise contribution elements j norm x greater one argue two terms right hand side small involve small rectangles bound first term second follow way second inequality follows cauchyschwartz inequality plugging previous calculation lemma 4 follows previous lemmas proof lemma given matrix set vectors existence given lemma 6 define new vectors v note using lemma 5 exists rectangle note result valid even 1 case follows directly without using anything conclude disca 5 fair decision trees section prove optimal direct product theorem fair decision trees start definition fairness decision trees definition 4 decision tree inputs x 1 x k 1 k fair every 1 k every path root leaf decision tree queries bits x decision tree dfair dfair let f airdepth 1 k denote class functions inputs x 1 x k computed 1 k decision trees let f airdepth kd denote f airdepth dd theorem 5 adv f airdepth kd f k proof theorem induction almost similar nrs94 simplify notation prove 2 proof general k follows way stronger induction hypothesis prove following stronger version lemma 7 every two functions f 1 f 2 numbers 1 2 proof lemma 7 prove lemma induction 1 decision tree base answer inputs standard check indeed bound adv f airdepth let decision tree achieves advantage without loss generality first query x 1 use notation x b bit queried remaining bits denote two subtrees 0 1 respectively b 0 1 define functions adv f used denote advantage f however 0 1 depth f airdepth d1 1d2 applying induction hypothesis continue get d2 consider trees p 0 p 1 achieve advantage g 0 g 1 construct tree p depth 1 starts querying b depending outcome activates p b first equality follows definition p second fact p depth 1 plugging previous calculation prove lemma 6 open problems natural direction try extend ideas paper stronger computational models particular extensions extend technique section 4 nonuniform probability distributions reason current argument extend use fact small rectangles small probability also nice able handle one sided discrepancy removing absolute value definition 2 may require totally dierent techniques unaware algebraic interpretation one sided discrepancy extension motivated lower bound disjointness function bfs86 ks87 raz92 uses one sided discrepancy nonuniform probability distribution next model may want prove strong product assertion imposing fairness restriction communication complexity seems result prw97 regarding forest model extend fair kcbit communication protocol models computations may obvious define fairness suggest following definition algorithm x 1 x k fair every every 1 i1 i1 k computation algorithm 1 i1 x i1 k fixed varying x simulated algorithm r units resource given x alternative approach replace syntactic fairness condition semantic one intuitively fairness restriction supposed guarantee algorithm cannot compute function individual coordinates advantage greater p hard impose fairness restrictions one may try prove direct product assertion algorithms obey semantic restriction acknowledgments would like thank advisor avi wigderson introducing area countless conversations guidance support r unbiased bits sources weak randomness probabilistic communication complexity reduction parallel repetitiona negative result preliminary version yaos xorlemma communication complexity probabilistic communication complexity set intersection preliminary version products help bits decision trees rank vs communication complexity direct product results gcd problem nearly optimal hierarchies network formula size distributed complexity disjointness parallel repetition theorem pseudorandom generators without xor lemma theory applications trapdoor functions extended abstract tr oneway functions pseudorandom generators unbiased bits sources weak randomness probabilistic communication complexity hardcore predicate oneway functions probabilistic communication complexity set intersection distributional complexity disjointness exponential circuits direct product results gcd problem old new communication models communication complexity parallel repetition theorem products help bits decision trees hardcore distributions somewhat hard problems reduction parallel repetitionmyampersandx2014a negative result