evaluation numa memory management modeling measurements dynamic page placement policies numa nonuniform memory access timesharedmemory architectures explored using two approaches complement eachother important ways authors measure performance parallel programsrunning experimental dunx operating system kernel bbn gp1000 whichsupports highly parameterized dynamic page placement policy also develop andapply analytic model memory system performance localremote numaarchitecture based approximate meanvalue analysis techniques model isvalidated experimental data obtained dunx running syntheticworkload results validation show general model predictions quitegood experiments investigating effectiveness dynamic pageplacement inparticular dynamic multiplecopy page placement cost replicationcoherency faulterrors cost errors deciding whether page move remotelyreferenced described b introduction numa nonuniform memory access time multiprocessor designs increasing importance support shared memory large scale systems placement movement code data crucial performance need deal data placement issues called numa problem presenting programmer explicit numa memory model results significant additional programming burden alternative considered operating system os manage placement policies mechanisms virtual memory subsystem system task oslevel memory management software decide reference memory remotely migrate move replicate copy page frame local memory processor generating memory request oslevel numa memory management area active research bolosky scott fitzgerald cox fowler 10 demonstrated specific solutions implemented ibm ace bbn butterfly plus multiprocessors respectively black et al proposed provably competitive algorithms page migration replication 4 5 6 scheurich dubois proposed page migration algorithms based page pivoting 26 bolosky et al conducted tracebased simulation study effects architectural features performance several migration replication policies 8 ramanathan ni conducted study critical factors numa memory management reported 25 also investigated oslevel numa memory management experimentation usmr programming library bbn gp1000 dunx kernel bbn gp1000 tc2000 14 15 17 18 19 20 21 unique contribution current work relation previous research complementary use 1 measurements based flexible parameterized policy implementation explore wide range policy behavior 2 experimentally validated analytic model focus class numa architectures known localremote architectures typified bbn gp1000 3 localremote architectures memory modules machine distributed one memory module local pro cessor rest remote processor local processor processormemory module pair called node processor may directly reference memory modules references local module much faster remote modules since request need sent interconnection network example gp1000 local read takes approximately 06s whereas remote reference takes approximately 75s ignoring various contention factors research implementationbased experimentation several advantages formal approaches importantly real applications used workload likelihood discovering subtle issues may important addressing problem increases complex interactions reference behavior real programs features policies implementable operating system kernel often difficult impossible capture abstract model thus developed dunx duke university nx operating system kernel experimental platform exploring potential role operating system solving numa problem hand performance measurement implemented systems also limitations architectural parameters cannot easily varied workload limited set available application programs interpretation results muddied implementation details order complement experimental work developed analytical model memory management behavior numa multiprocessor supporting dynamic multiplecopy page placement page placement migration replication 16 based approximate meanvalue analysis mva approach 2 9 22 27 29 28 goal model evaluate performance basic policies within context given workload model necessarily restrictions workload model policies considered claim workload model predict exact performance specific real application program however conjecture parameters workload model capture key features real programs provide insight general performance different classes programs given architecture operating system within context workload model straightforward define approximate ideal policy always makes proper choice remote reference migration replication depending interprocess reference granularity interprocess write granularity establishes performance goal compare policies analogous policy implemented measured experimental system without knowledge future references ideal policy modified introduce errors ie poor policy choices effects compared ideal performance different workload assumptions working experimental system analytic model puts us unique position investigate wide range issues numa memory management first approach allows us validate model using experimental data obtained dunx use measurements real applications running dunx model architectural parameters set values consistent gp1000 implementation architectures answer series questions dynamic page placment include effectiveness dynamic singlecopy page placement effectiveness dynamic multiplecopy page placement cost using replicationcoherencyfault pairs instead page migrations cost incorrect policy decisions next section describe dunx operating system kernel section 3 present modeling approach outline system model architecture operating system 31 workload model 32 validation done section 4 experiments results described section 5 finally summarize last section experimental framework developed dunx kernel bbn gp1000 numa shared memory multiprocessor framework implementing wide assortment dynamic page placement strategies initially viewed numa memory management policy design space terms distinct points individual policies captured various combinations large number factors suspected might affect performance nearly fifty policies tested using dunx including least approximations published policies experimental results reported 18 early experiences allowed us prune consolidate techniques appeared investigation policy issues could best formulated context single parameterized policy studied varying parameter settings measuring effect performance insight led development version two dunx supports tunable policy single policy seems capture fairly large region policy design space including successful policies identified earlier experiments study effects policy tuning respect differences applications architectural features appears 20 paper consider static singlecopy policy highly parameterized dynamic multiplecopy policy static policy places virtual page frame processor first references page frame processor explicitly specified application programmer virtual memory allocated processors wish share access page create mappings physical copy exception code pages always replicated node using placement page change unless selected removal replacement policy later paged dynamic policy consider uses initial placement static policy periodically reevaluates earlier decisions allows multiple physical copies single virtual page policy move page local frame upon demand supports migration replication choice two operations based reference history specifically recent history modifications made page directorybased invalidation scheme used ensure coherence replicated pages dunx supports sequentially consistent memory system recent work suggests weaker consistency models exploited obtain additional performance improvements 1 11 12 13 use weak consistency could incorporated dunx framework well policy applies freezedefrost strategy idea adopted 10 control page bouncing condition page continually migrated one node another freezedefrost strategy excessive page movement controlled param role freezewindow defines size recent invalidations window freezing decisions recentmod controls replication vs migration decision scandelay sets rate scanner daemons samplepasses adjusts number reference collection samples defrosttrigger remote count local count successes needed defrost triggermethod controls invalidate vs invalidate remote trigger decision table 1 policy parameter summary freezing page place forcing remote accesses freezing criterion based time since recent invalidation page determining defrost frozen page trigger reevaluation placement based time often decisions made reference history recent remotelocal usage time choosing trigger new placement decisions based reference data recent modification history six parameters control behavior policy one set parameters controls frequencies certain events take place defrost triggering decisionpoints reference data collection aging usage counts parameters set thresholds interpretation reference data eg defining recent history parameters intended orthogonal provide means systematically study policy design space appropriate parameter settings behavior policy adjusted mimic wide variety freezebased policies parameters roles summarized table 1 policy comprised two parts first defines behavior policy faced page fault second defines behavior page scanner daemons used trigger reevaluation earlier page placement decisions fault occurs page replicated already resident remote physical frame chosen course action depends primarily recent reference history page settings freezewindow recentmod policy parameters policy must decide installing remote mapping migrating replicating page first step involves determining whether page frozen checking see whether recent invalidation page due page migration coherency fault occurred within past freezewindow milliseconds page frozen either imposed sometime past remote frame used service fault freezewindow parameter essentially limits rate invalidations page occur freezewindow set zero policy behaves much like caching policies used proposed software distributed shared memory environments eg 23 24 freezewindow set infinity page may invalidated migrated replicated first coherency fault occurs frozen values freezewindow two extremes allow varying amounts dynamic page placement activity migration replication essence freezewindow parameter controls eagerness policy migrate replicate pages determined local copy page desired necessary decide migration replication recentmod parameter controls decision policy checks see page recently modified comparing modification history maintained page scanners aging hardware modification bits recentmod parameter aged modification counter exceeds recentmod threshold write reference triggered current fault page migrated local free frame otherwise local free frame used create replica page write access copies prohibited allowing fault handler ensure data coherency recentmod 0 migration always chosen favor replication ie replication allowed recentmod 1 replications chosen migrations fault triggered write reference assume goal policy replicate pages referenced readonly fashion characterize recentmod point policy concludes last modification page far enough past assume page referenced readonly fashion handling fault page already replicated requires data coherence maintained write memory reference triggered fault copy eventually used satisfy fault must invalidated local copy page exists one existing replicas migrated local frame read memory reference triggered fault policy either uses existing replica creates additional local one none already exists need check freezing since impossible page frozen replicated policy uses page scanner processor node trigger reevaluation earlier placement decisions page scanners run every scandelay seconds time scanner runs collects page reference modification information frames processor separate local remote reference counts maintained policy tell whether local processes remote processes local remote processes referencing page remaining parameters specify details scanner operation minor effects varied experiments presented paper 3 analytical framework 31 system model system model approximate meanvalue analysis mva similar reported elsewhere figure graphically depicts modeled system lo calremote memory architecture system comprised n processormemory nodes connected interconnection network queuing delays encountered upsilon upsilon upsilon interconnection network f figure 1 system queuing model ever processor attempts reference memory whenever message sent interconnection network table summarizes model hardware software input parameters since b number blocks page time read write entire page bt bm time transfer page across interconnection network bt bx basic system model assumes local memory reference takes uniform amount time modeled l input parameter account time differences read write references systems eg bbn gp1000 derive l input parameter using lr lw local read write reference times respectively memory management policy workload modeled software input parameters model assumes mean time memory references time units given reference local memory probability p l remote memory module probability number different types faults concentrate primarily faults resulting migration replication coherency operations probabilities q q r q c respectively discussion omits details types faults enter model subsection 32 describe input parameters relate application program reference patterns management policies mean total time virtual user program memory requests r issued processor sum execution time requests mean time complete memory request r r weighted mean time servicing encountered page faults r f equation 1 mean time complete virtual memory request r r equation 2 depends l equation 3 mean time required perform local memory reference including wait time r equa tion 4 time required make remote request page fault handler also makes local remote memory references mean time per virtual memory request spent servicing faults r f calculated based probabilities costs type fault calculation symbol meaning hardware input parameters l short message memory reference time lr local read reference time lw local write reference time x short message network transfer time bm block memory reference time bx block network transfer time b number blocks page mean disk transfer time software input parameters mean time memory reference requests l prob memory reference local r prob memory reference remote q r prob page fault results replication prob page fault results migration q c prob page fault coherency fault table 2 system model input parameters wait times w l w r w n discussed 17 consider processor zero figure 1 making reference local memory reference location memory module one first case wait required queue labeled b figure thus service time comprised single wait local memory w l time actually complete reference l second case request must sent network memory module one first request delayed queue wait network access w n time units must travel network x time units wait remote memory module queue w r time units wait queue time actually process request l return message must sent back original requesting processor zero involves waiting queue c w n time actually make final transfer x thus yielding equation 4 pr private data pages code pages ro readonly shared data rm readmostly shared data ss sharedsequential pages sp sharedparallel pages table 3 shared data page classes symbol meaning number pages class c r c mean read references page references page r c interprocess reference granularity mean number processors sharing page table 4 workload model input parameters c 2 fpr rormssspg 32 workload model subsection develop simple workload model obtaining approximations input parameters different applicationpolicy combinations assume virtual page address space process placed one small number classes shown table 3 similar classifications page classes use mva models developed independently studying cache coherency 2 29 pr pages contain program code variables process needs copy assume pages replicated local memory execution ro class contains shared data pages never modified execution program class rm pages contains shared data pages modified occasionally referenced readonly fashion far often two remaining classes ss sp contain shared data pages readwrite shared differ active sharing specifically readwrite shared page ss class page number references process makes page references another large enough justify migrating page sp class page otherwise five page classes define six workload model input parameters summarized table 4 p c c 2 fpr rormssspg number pages class c r c w c mean number read write memory references process makes page class c r c w c interprocess reference write granularity mean number references processor makes page class c reads writes writes page another processor policy description ideal chooses right operation static never migrate replicate cache migrate ss sp pages replicate ro rm pages mor always migrate rc ideal rc migrations error ideal percentage decisions wrong table 5 model policies sixth parameter c mean number processors sharing page class c r c parameter distinguishes ss sp pages r c small migration likely cost effective classify page class sp hand r c rather large migration likely worthwhile consider page class ss section 55 discuss results make distinction clear first reference nonlocal page policy must chose establishing mapping remote copy page thus deciding reference page remotely migrating replicating page local frame order ensure strict data coherency modification page allowed exists single valid copy page invalidationbased coherency protocol used enforce requirement table 5 lists management policies considered model ideal policy makes correct choice among options reference addition ideal policy consider several policies static never migrate replicate cache always migrate ss sp pages always replicate ro rm pages migrateonreference mor always chose migration remote references ideal migration errors rc ideal migration implemented replicationcoherency fault pairs ideal percent errors error certain percentage ideal policy decisions incorrect derive system model parameters policies based workload model parameters static page placement know q assume page placed frame randomly selected node actually uses page therefore local least one processors using page probability reference remote memory module p r local memory p derived cache policy always migrate replicate policy typically used software distributed shared memory systems eg 24 remote memory never referenced directly probability migrating page q simply total number ss sp migrations divided total number application references mean number migrations performed ss sp page mean total number references pages divided mean number references processor able make needing remigrate page back local frame probability cache policy replicating page q r number replications divided total number references references page replicated broken runs size w c c 2 frormg replication required start run page resident start computation coherency fault ensures replication required every w c references migrateonreference mor policy q calculation q includes ro rm page references well ss sp page references key approximate ideal policy knowledge reference count k mig necessary justify page migration reference count k rep necessary justify replication idea behind ideal policy better migrate page reference remotely whenever better replicate page reference remotely whenever w c k rep assume policy able distinguish page classes consequently ro rm page classes policy uses w c k rep values determine whether replicate page ss sp classes policy uses r c k mig values determine whether migrate page policy never choses migrate ro rm pages ever chose replicate ss sp pages migration effected replicationcoherency fault pair henceforth called rc migration rc policy uses ideal policy equations except q r q c set original q q set zero error policy performs like ideal policy certain fraction decisions incorrect equations error policy similar ideal policy percent error factor class e c 4 validation model implementation section investigate accuracy analytic predictions comparing experimental results obtained using dunx operating system kernel running bbn gp1000 multiprocessor difficult derive accurate estimates input parameters workload model arbitrary application program wish avoid task yet order validate model need examine wide assortment points possible workload space deal conflicting goals develop synthetic program called synth detailed analysis simplified synthetic program parameterized effect exhibit wide assortment different reference patterns five important input parameters synth number pages five instance p pr pro prm p ss p sp table synth program instances workload model page classes ie pr ro rm ss sp synth program allocates input number shared pages class enters series loops references pages loops constructed key workload model parameters eg interprocess reference granularities obeyed thus mean interprocess reference granularity ss page class r ss synth process make r ss references page process references page detailed handlevel analysis synth compilergenerated assembler code expressions numbers memory references instructions executed developed thus quickly determine total number memory references made type page given correct values five synth input parameters section consider nine points synth parameter space refer points instances synth numbered 1 9 instances defined table 6 first step analysis particular synth instance run onenode cluster gp1000 static page placement policy experiment conducted ten times statistical significance variation analytic results checked using reference count data obtained source analysis expressions mean measured completion time page fault data compute page fault probabilities instance synth possible onenode case know exactly fraction memory references made local exactly 1 total number references made source analysis expressions numbers page faults different types encountered mean costs experimental data figure 2 plot measured dunx predicted system model completion times seconds nine instances running onenode cluster static page placement experimental results two points plotted experiment points bound 99 confidence interval calculated using studentt distribution sample size comparison experimental predicted data 1 node case model figure 2 comparison 1node static results completion time seconds ten results match quite well however expected since used experimental data set input parameters model results didnt match would indicate problem methodology next step analysis use values obtained first step make predictions performance nnode cluster data compared experimental data obtained running synth dunx gp1000 example 8node results static page placement policy shown figure 3 two dunx points instance bound 99 confidence interval established ten sample points studentt distribution note ten sample points mean completion time eight processes comprise computation figure 3 shows analytic predictions quite close experimental results differing mean experimental time mean plotted lies halfway plotted bounds less 5 cases data clearly show memory network contention estimates reasonably accurate workload models p l p r estimates analytic predictions slightly optimistic however probably due combination following factors 1 clustering time references pages particular class likely synth processes references pages certain class roughly time course means memory network contention encountered making references may higher predicted since model assumes references distributed comparison experimental predicted data static policy model figure 3 comparison 8node static results completion time seconds uniformly time 2 clustering page faults though page faults occur must occur start application thus contention operating system data structures may higher resulting total page fault costs slightly greater predicted model 3 factors experimental data obtained real system supporting real user community certain operating systems functions process scheduler may play role slowing application may unexpected interference terms memory network os data structure contention users system 1 simply possible system model account factors may affect overall performance real application course despite quantitative errors much nearly 5 model predictions qualitatively accurate figure 4 compare analytic predictions nine synth instances running cache policy experimental results obtained running essentially policy results instances 5 7 8 9 instances p sp 0 appear figure cases model predicts excessively high completion times eg instance 5 prediction hours allow experimental runs users may affect memory network contention despite fact computation runs cluster processor nodes since operating systems disk buffer cache distributed across memories nodes system comparison experimental predicted data cache policy model 3 wbarriers theta theta theta theta theta theta theta figure 4 comparison 8node cache results completion time seconds instances complete obvious reasons allow run long enough conclude excessive amounts dynamic page placement activity migrations replications coherency certain result long application run times predictions synth instances 1 2 well within 5 mean measured completion times factors contributing quantitative differences likely proposed discussion 8node static policy results synth instances 4 6 analytic predictions differ mean experimental completion time significant amount 127 instance 4 214 instance 6 instance 4 case analytic prediction lies within 99 confidence interval analytic prediction instance 6 nearly 10 lower even lower bound 99 confidence interval lower bound 99 confidence interval instance 3 appears figure 4 upper bound interval 800 seconds indicating wide variance measured completion times synth instance following factors play role noted differences synth instances 3 4 1 fuzzy phase transitions deriving input parameters workload model make simplifying assumption phase transitions occur distinct points time assumption maximizes r ss wrm parameter estimates minimizing number migrations replications since overlapping phases occurs unfortunately actually run application dunx overlap may occur counter assumption since overestimate r ss wrm workload model predicts fewer migrations ss pages fewer coherency faults replications rm pages better estimates r ss wrm would likely improve success model clearcut way determine exactly much phase transitions may overlap barring introduction barrier synchronization phases 2 subtle dunx race turns subtle race condition dunx also partially blame processor may experience page fault results coherence operation page migration yet unable complete memory reference triggered fault processor able replicate disabling write access page migrate page causes first processor fault memory reference repeating process 2 item number 1 difficult imagine one would include effects race analytic model note effects introduce large amounts variance experimental measure ments since amount phase overlap number iterations dunx coherencywrite race highly unpredictable test hypotheses introduced several barrier synchronization points synth application noted problems would avoided results experiments also shown figure 4 two data points bound 99 confidence interval see performance modified synth much closer predicted model despite fact model account additional memory references contention associated barrier synchronization points additionally note confidence interval size modified synth instances also greatly reduced two instance 4 points lie top one another data give strong support explanation noted differences model predictions experimental measurements difficult test accuracy analytic model realistic policies since clear mapping modeled policies actual dunx policies figure 5 compare performance analytic ideal policy best performance able obtain parameterized dunx policy note policy tuning differs nine instances experimental results given lower upper bounds 99 confidence interval around mean measured completion time see predicted ideal performance reasonably close best performance able achieve dunx cases reasons differences include discussed relation static policy results well 2 note clear one would correct race condition dunx clear necessary problem occurs run cache policy since migration replication control mechanisms present policies prevent occurring appropriate action change policies faced behavior time instance number comparison experimental predicted data ideal policy model 3 figure 5 comparison 8node ideal policy results best possible results dunx completion time seconds first item list factors affecting performance cache policy factors also come play 1 lack ideal dunx policy cannot implement ideal policy since policy requires knowledge future reference patterns 2 page scanner overhead real dunx policies must suffer overhead effects associated running page scanner daemons overhead comes form lost cpu cycles used daemons well additional quick faults accounted workload model results even though predictions may extremely accurate though within 10 cases certainly terrible qualitatively accurate becomes especially obvious compare results figure 3 figure 5 evident model responds correctly differing reference patterns example predicts significant performance improvements made synth instances 2 6 whereas doesnt predict drastic improvements instances 7 8 also note relative performances instances 6 7 8 model successfully predicts instances improve instance 5 results figure 5 merit special attention since dunx results faster predicted ideal completion time relatively simple explanation however instance 5 comprised entirely sp pages ideal policy sp pages never replicated migrated r sp less k mig case thus predicted performance ideal policy instance 5 virtually identical predicted static policy r sp w sp values means however reality migration replication improve performance instance 5 evidenced experimental data figure 5 type error motivates development error policy though opposite sense error results pessimistic rather optimistic model predictions summarize results section found differences analytic predictions experimental results usually small cases difference substantial differences due several factors accounted analytic model especially important factors related program behavior clustering memory accesses page faults fuzziness phase transitions factors appear execution synthetic program designed specifically conform workload model factors likely play even important role real applications consequently though use model make predictions behavior policies defined context workload model predictions performance specific real applications running real policies questionable value 5 experiments results take approach using analytic model experiments dunx answer specific questions dynamic page placement behavior effects different workload features performance two methods complement technique strengths weaknesses limitations one approach tend covered capabilities measurements implemented system running real applications capture true program behavior complex interactions may hard anticipate impact actual system overhead specific workload suite tested hardwaresoftware implementation available thus experimental results considered accurate may easily generalizable architectures possibility better implementations different set programs hand model clearly include subtle effects real system performance allow exploration wider range hardwaresoftware parameters confidence model established example section 54 ask question effect poor policy decisions cost resulting migrations differs dunx implementation complexity actual behavior missing model also make experimental data difficult interpret whereas model explicitly formulates relationships among appar class p c r c w c r c w c c workload 1 characterization pr 50 500 000 50 000 550 000 550 000 1 ro workload 2 characterization pr 50 500 000 50 000 550 000 550 000 1 ss workload 3 characterization ss workload 4 characterization table 7 workload characterizations simple workloads ent contributing factors used test hypotheses explain results example section 53 question whether replication right mechanism serve basis dynamic placement addressed constructing workloads specially tailored favor replication emphasis readonly shared data migration emphasizing sequentially shared readwrite data see impact using intuitively less appropriate mechanism finally useful establish performance goal although implies policy decisions actually implemented thus use modeled ideal policy ask whether significant potential improved performance pursuing sophisticated dynamic placement strategies section 52 51 methodology applying analytic model use simple workloads vary one two key parameter values order study isolation particular aspect memory reference behavior workload settings experiments table 7 use variable x table signifies parameter varied hardware parameters set values gp1000 table 2 software parameters derived workload model experimental measurements dunx implementation architecture workload characteristics fixed actual hardware applications available basic costs page placement operations measured gp1000 dunx implementation 45 ms program description msort merge sort integer array gauss simulates gaussian elimination integer arithmetic hh3d simulates electrical conduction cardiac tissue hough computes hough transforms solves using block chaotic relaxation wave solves wave equation square grid periodic boundary fish simulates sharks fishes twodimensional sea mandel performs mandelbrot set calculation table 8 experimental workload collection migration 46 ms replication 21 ms servicing coherency fault experiments focus varying policy parameters achieve range responses workload used experimentation developed independently project effort prevent unconscious attempts making design decisions might affect results applications comprise workload collection listed table 8 versions written uma numa styles exception msort numa version numa version highlytuned implementation program written optimize memory reference locality assuming static policy using programming techniques manually placing shared data pages making explicit copies readonly data structures uma version numaspecific memory management one would expect numa version application typically complicated less portable much difficult write application workload collection began study tuning parameter settings achieve best possible performance application gp1000 within limits somewhat ad hoc tuning process arrived parameter settings application designated default settings application experiments default settings parameter varied used settings indicated figure captions plots dunx performance generally two heavy lines mark levels performance obtained uma numa versions application program using static page placement upper line uma result lower numa result diamond plot experimental data point obtained uma version program run dynamic policy corresponding parameter settings multiple trials done check validity data thin solid line plots mean values dunx plots time yaxis measured elapsed seconds 52 importance dynamic page placement perhaps important question answer whether dynamic page placement worth pursuing model predictions instances synth used validation study provide evidence dynamic page placement improve performance applications example results figures 3 4 5 show several synth instances cache andor ideal policies perform better static policy appropriate k mig k rep values minimal reference counts necessary justify page migration replication ideal policy never perform worse static policy though many cases perform better since ideal policy performs better cache policy many cases investigation sophisticated dynamic policies worthwhile validation results obtained running synth dunx also confirm dynamic page placement worth investigating answer question context actual programs practical policies dunx consider performance three applicationpolicy combinations uma version application run static page placement policy serves base case measure since case numa problem addressed either application programmer operating system assume numa versions well written sense represent successful attempts addressing numa problem consider difference performance uma version application run static page placement combination denoted umastatic numa version run static page placement numastatic cost numa problem performance numastatic combination serves performance goal sense achieve level performance method consider method successful case method dynamic multiplecopy page placement policy implemented dunx kernel individually tuned application workload thus third combination interest experiments umadynamic table 9 give raw completion time data three applicationpolicy combina tions table labels us ns ud correspond umastatic numastatic umadynamic combinations respectively cases umadynamic combination performs significantly better umastatic combination thus showing operating system indeed prove effective addressing numa problem many instances performance umadynamic combination approaches numastatic combination fact hough application umadynamic combination outperforms numastatic combination last result indicates numa version hough application must optimal since whatever operating system able improve performance program us ns ud msort 3367s 802s gauss 18331s 1747s 2381s hh3d 11022s 6285s 7229s hough 1804s 1540s 968s psolu 37960s 5307s 5776s wave 4650s 1244s 2510s fish 863s 855s 1054s mandel 11606s 11559s 11684s table 9 absolute performance applications programmer could also done likely efficiently data also show fish mandel applications dynamic multiplecopy page placement serves degrade performance since handtuned numastatic versions fish mandel fail perform significantly better umastatic counterparts surprising costs dynamic placement outweigh limited potential benefits results presented throughout remainder section support value dynamic page placement addition answering questions 53 importance page replication intuitively page replication desirable favored migration singlecopy static placement applications significant amount readonly sharing however singlecopy policies would simpler implement model workload 1 used investigate impact multiplecopy page placement comparing performance static mor cache policies see figure 6 since varying interprocess reference granularity r ro way change number migrations andor replications without changing total number references ro pages parameter varied experiment mor curve continues rise r ro decreases r ro 10 mor r mean time virtual memory requests 350 due page bouncing cache policy performs significantly better static policy indicating multiplecopy page placement policies improve performance applications figure also shows sufficiently high r ro values mor achieves performance good cache policy never better result makes clear importance multiplecopy page placement policies least one class applications ie applications significant amount ro pages experiments presented support similar conclusions respect rm pages given predetermined reference patterns generated real programs approach experimentally investigating choice replication migration vary policy r r ro importance page replication figure workload 1 model experiments r microseconds recentmod parameter dunx parameterized policy controls migration versus replication decision results varying recentmod gauss application gp1000 given figure 7 figure 7 indicates higher preference replication migration better measured performance since primary mode sharing gauss involves reading pivot rows matrix never modified become pivot rows value replication surprising figure 7 shows replication always chosen migration read faults performance uma version gauss nearly good numastatic version program intermediate recentmod values result performance better without replication recentmod 0 case fail take advantage potential page replications improve performance recentmod case results recentmod experiments psolu hough wave applications gp1000 resemble obtained gauss program based analytic results improved performance applications policy favoring page replication suggests share substantial amount data readonly fashion ie pages type ro rm 54 effects coherency faults performance workload 2 used investigate performance policy implements page migration workloads appropriate operation replicationcoherency fault pairs rc migrations experiment see figure 8 vary r ss w ss together time secs recentmod effect recentmod gauss performance dynamic policy points 33 3 3 3 33 uma numa static figure 7 effects recentmod gaussgp1000 measured performance workload consisting pr ss pages workload model predicts ideal policy page replications coherency faults occur sufficiently high r ss however ideal policy predicts positive q value values r ss w ss 1000 considered since values ideal policy static policy even worst case r ss w ss values 1000 10000 penalty using rc migrations excessive fortunate since real system memory management software way knowing fault time whether best migrate replicate particular page thus rc migrations likely fairly common real systems msort application example application benefit replication preferred migration gp1000 data shown figure 9 behavior explained fact readonly sharing msort benefit page replication result see slight performance degradation degradation due using replicationcoherency fault pairs migrate pages since replicationcoherency fault pair costly simply migrating page weakness negative impact coherency faults consistent analytic predictions figure 8 cost incorrectly choosing replication migration coherency fault 50 expensive dunx implementation gp1000 analytic model predicts avoiding coherency faults may important architectures processing coherency fault r r ss w ss migration vs replicationcoherency fault pairs migration replicationcoherency 222 2 22 figure 8 workload 2 model experiments r microseconds1002003001 time secs recentmod effect recentmod msort performance dynamic policy points 3 average dynamic policy uma static figure 9 effects recentmod msortgp1000 measured performance e ss effects ss page errors theta theta theta theta theta theta theta figure 10 workload 3 model experiments r microseconds expensive experimental results dunx implementation bbn tc2000 reported 20 also suggest case 55 effects policy errors performance success ideal policy promotes development sophisticated policies attempt approximate ideal policy selectively limiting page movement activity way however policies bound make mistakes either aggressive moving pages encountering page bouncing conservative passing desirable opportunities analytic model errors determining level dynamic placement activity represented error policy correctly handling pr ro pages prove difficult reasonable policy implementation assume errors made ie let 0 rm pages wrm k rep ss pages incorrect policy choice use remote reference clearly worst case performance degradation static policy interesting case incorrect policy choice replicate rm pages migrate sp pages since result performance worse basecase static policy use workload 3 consider ss page errors figure 10 plot r versus e ss five different r ss w ss values r ss w ss values performance error policy e ss 0001 approximately ideal policy performance expected r performance eventually degrades static policy theta theta theta theta theta theta theta figure 11 workload 4 model experiments r microseconds r 92s r case differs ideal performance nearly identical static policy performance error policy degrades e ss increases e identical cache policy worse static policy default error policy k mig parameter greater r ss value 1000 policy errors result undesirable page migrations rather missed opportunities effect ss pages low r ss values behave like sp pages fact natural division two page classes r mig next case workload 4 considers sp page errors shown figure 11 plot r versus e sp five r sp w sp values performance higher e sp values considerably worse encountered workload 3 poor performance due page bouncing behavior better see quickly page bouncing becomes concern data figure 11 plotted figure 12 smaller r values key shown figure due space limitations figure 11 see smaller r sp w sp values performance quickly degrades error policy e sp increases 0001 significant result however e sp value performance never better static policy r 92s questions naturally arise whether migration costs derived implementation simply high behavior may change page migration fault handling made significantly faster repeating workload 4 tests r five different parameter settings migration costs expressed percentages default values used previously exploits ability model explore different architectural parameters figure 13 theta theta theta theta theta theta theta figure 12 closeup workload 4 model experiments r microseconds shows trends curves e sp increases remain figures 12 11 although magnitude impact page bouncing changes different migration costs model predictions indicate better err side conservative approaches ie better miss migration opportunity suffer unwanted migra tions limiting page movement controlled freezingdefrost mechanism dunx freezewindow parameter essentially controls imposition freezing limit amount dynamic page placement activity freezewindow set zero limit frequency page migrations coherency faults applications gp1000 tc2000 page bouncing problem sets resulting incredibly poor performance order prevent situations higher freezewindow values must used however freezewindow set high prevention delay defrost desirable migrations replications becomes real possibility results freezewindow experiments psolu shown figure 14 typical plot shows performance lower freezewindow values suffers relative higher values let freezewindow go zero performance degrades point never able let computation complete important characteristic psolu freezewindow results freezewindow setting high enough increases little effect performance true hough gauss hh3d msort results well suggests potential problem delaying desirable operations concern applications architectures either effects delays negligible eg delays short r e sp effects sp page errors versus migration costs theta theta theta theta theta theta theta figure 13 workload 4 model experiments different migration costs r microseconds5506500 125 250 375 500 625 750 875 1000 time secs freezewindow ms effect freezewindow psolu performance dynamic policy points 33 3 average dynamic policy uma numa static figure 14 effects freezewindow psolugp1000 measured performance since defrost comes soon operations suspect combination two factors reason 6 summary dynamic multiplecopy page placement important operating system technique dealing numa memory management investigated issues related dynamic multiplecopy page placement mixture measurement operating system implementation running real workload applying mvabased model checked validity model comparing performance predictions experimental data obtained running synthetic program bbn gp1000 multiprocessor dunx operating system kernel cases predictions quite accurate substantial errors however occur cases due fuzzy phase transitions synthetic program certain race condition dunx kernel introducing barriers synthetic program caused differences become insignificant need introduce barriers cases highlights essential distinction say confidence conclusions draw model valid extent real programs conform workload model identified several important questions constructed experiments implementation model provide answers experiments dunx compared performance programs collected workload suite individualized policy tuning handtuned numa versions programs representing performance target policy parameters varied effect range dynamic placement activity response given program using model compared relative performance approximate ideal policy several policies implementable analytic modeling possible ideal policy always makes correct choice among remote reference migration replication alternatives considered static mor cache rc error sometimes make incorrect policy decisions varied workload parameters observe range behaviors results experiments support following conclusions 1 confirmed effectiveness dynamic placement policies experimentally measured performance uma versions workload programs running appropriate tunings often approaches performance handtuned numa versions modeling results show ideal cache policies improve performance workloads performance static policy 2 replication important feature model identifies workload characteristics multiplecopy policies perform significantly better singlecopy policies poor performance singlecopy policies workloads found result page bouncing phenomenon similar page thrashing sometimes encountered traditional virtual memory paging systems varying recentmod parameter dunx changes preference replication migration shows importance providing replication real workloads 3 replicationcoherency fault pairs used migrate pages effectively extra overhead associated type page migration called rc migration found fairly reasonable fortunate result since intuition says rc migrations likely fairly common real systems supporting multiplecopy page placement 4 given choice much dynamic placement activity potential lead page bouncing little missing opportunities local access appears better policy conservative captured model difference errors made ss pages errors sp pages error policy errors handling ss pages r ss k mig degrade performance ideal policy worse static policy errors handling sp pages hand result performance far worse static policy varying freezewindow parameter dunx adjusts aggressiveness policy move pages experimental results indicate important limit bouncing behavior take advantage every possible desirable migration replication consistent predictions analytic model r weak ordering new definition comparison hardware software cache coherence schemes scheduling resource management techniques multiprocessors competitive management distributed shared memory competitive algorithms replication migration problems simple effective techniques numa memory management numa policies relationship memory architecture experience mean value analysis models evaluating shared bus throughputoriented multiprocessors implementation coherent memory abstraction numa multiprocessor experiences platinum memory access dependencies sharedmemory multiprocessors performance evaluation memory consistency models sharedmemory multiprocessors memory consistency event ordering scalable sharedmemory multiprocessors page table management localremote architectures reference history memory coherence shared virtual memory systems hypercube shared virtual memory system critical factors numa memory management dynamic page migration multiprocessors distributed global memory analysis critical architectural program paramters hierarchical sharedmemory multiprocessor accurate efficient performance analysis technique multiprocessor snooping cacheconsistency protocols performance analysis hierarchical cacheconsistent multiprocessors tr memory coherence shared virtual memory systems accurate efficient performance analysis technique multiprocessor snooping cacheconsistency protocols page table management localremote architectures meanvalue performance analysis new multiprocessor architecture reference history page size migration daemons localremote architectures simple effective techniques numa memory management implementation coherent memory abstraction numa multiprocessor experiences platinum memory access dependencies sharedmemory multiprocessors performance analysis hierarchical cacheconsistent multiprocessors analysis critical architectural programming parameters hierarchical numa policies relation memory architecture performance evaluation memory consistency models sharedmemory multiprocessors experience mean value analysis model evaluating shared bus throughputoriented multiprocessors exploiting operating system support dynamic page placement numa shared memory multiprocessor comparison hardware software cache coherence schemes experimental comparison memory management policies numa multiprocessors robustness numa memory management page placement nonuniform memory access time numa shared memory multiprocessors analysis dynamic page placement numa multiprocessor weak orderingmyampersandmdasha new definition memory consistency event ordering scalable sharedmemory multiprocessors scheduling resource management techniques multiprocessors