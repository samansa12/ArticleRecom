learning parse natural language maximum entropy models paper presents machine learning system parsing natural language learns manually parsed example sentences parses unseen data stateoftheart accuracies machine learning technology based maximum entropy framework highly reusable specific parsing problem linguistic hints uses learn specified concisely therefore requires minimal amount human effort linguistic knowledge construction practice running time parser test sentence linear respect sentence length also demonstrate parser train domains without modification modeling framework linguistic hints uses learn furthermore paper shows research rescoring top 20 parses returned parser might yield accuracies dramatically higher stateoftheart b introduction task natural language parser take sentence input return syntactic representation corresponds likely semantic interpretation sentence example parsers given sentence buy cars tires would return parse tree format buy np cars pp np tires author working ibm tj watson research center po box 218 yorktown heights ny 10598 nonterminal labels denote type phrase eg pp stands prepositional phrase accurate parsing difficult subtle aspects word meaningfrom parsers viewdramatically affect interpretation sen tence example given sentence buy cars money parser might propose following two parses ffl unlikely buy np cars pp np money ffl likely buy np cars np money parses grammatical sense typical context free grammar english allow structures one corresponds likely interpretation sentence parser actually needs detailed semantic knowledge certain key words sentence order distinguish likely parse needs somehow know money refers buy cars parsers currently show superior accuracies freely occurring text classified statistical corpusbased since automatically learn approximate syntactic semantic knowledge parsing large corpus text called treebank manually annotated syntactic information order evaluate accuracy statistical parser first train subset treebank test another nonoverlapping subset compare labelled syntactic constituents proposes labelled syntactic constituents annotation treebank labelled constituent accuracies best parsers approach roughly 90 tested freely occurring sentences wall st journal domain sfbuysg npfmang man vpfbuysg buys npfcarsg fast cars ppfwithg npftiresg big tires figure 1 parse tree annotated head words 2 previous work recent corpusbased parsers differ simplicity representation degree supervision necessary agree resolve parse structure ambiguities looking certain cooccurrences constituent head words ambiguous parse head word constituent informally one word best represents meaning constituent eg figure 1 shows parse tree annotated head words parsers vary greatly head word information used disambiguate possible parses input sentence black et al 1993 introduces historybased parsing decision tree probability models trained treebank used score different derivations sentences produced handwritten grammar jelinek et al 1994 magerman 1995 also train historybased decision tree models treebank use parser require explicit handwritten grammar decision trees look words directly instead represent words bitstrings derived automatic clustering technique contrast hermjakob mooney 1997 use rich semantic representation training decision tree decision list techniques drive parser actions several recent parsers use statistics pairs head words conjunction chart parsing techniques achieve high accuracy collins 1996 1997 uses chartparsing techniques head word bigram statistics derived treebank charniak 1997 uses head word bigram statistics probabilistic context free grammar goodman 1997 uses head word bigram statistics probabilistic feature grammar collins 1996 goodman 1997 charniak 1997 collins 1997 use general machine learning algorithms instead develop specialized statistical estimation techniques respective parsing tasks parser paper attempts combine advantages approaches uses natural direct representation words conjunction general table 1 treebuilding procedures parser pass procedure actions description first pass tag pos tag tag set assign pos tag word second pass chunk start x join x assign chunk tag pos tag word third pass build start x join x x constituent label label set assign current tree start new constituent join previous one check yes decide current constituent complete machine learning technique maximum entropy modeling argue successful use simple representation general learning technique combination minimizes human effort maintains stateoftheart parsing accuracy 3 parsing maximum entropy models parser presented constructs labelled syntactic parse trees actions similar standard shiftreduce parser many parsing techniques exist natural language see allen 1995 introduction sequence actions ang construct completed parse tree called derivation explicit grammar dictates actions allowable instead actions lead wellformed parse tree allowable maximumentropy probability models used score action maximum entropy models trained examining derivations parse trees treebank individual scores actions derivation used compute score whole derivation hence whole parse tree parsing sentence parser uses search procedure efficiently explores space possible parse trees attempts find highest scoring parse tree section 31 describes actions treebuilding procedures section 32 describe maximum entropy probability models section 33 describes algorithm searches highest scoring parse tree 31 actions parser actions parser produced procedures take derivation predict action an1 create new derivation an1g actions procedures designed possible complete parse tree exactly one derivation procedures called tag chunk build check applied three lefttoright passes input sentence first pass applies tag second pass applies chunk third pass applies build check passes procedures apply actions procedures summarized table 1 typically parser explores many different derivations parsing sentence illustration purposes figures 28 trace one possible derivation sentence saw man telescope using consituent labels partofspeech tags university pennsylvania treebank marcus et al 1994 actions procedures scored maximum entropy probability models use information local context compute probabilities detailed discussion probability models occur section 32 using three passes instead one pass allows use local context example model chunk procedure output tag left right context models build check procedures output tag chunk left right contexts procedures implemented one lefttoright pass model chunk would output tag right context models build check would output tag chunk right context 311 first pass first pass takes input sentence shown figure 2 uses tag assign word partofspeech pos tag result applying tag word shown figure 3 tagging phase resembles standalone statistical taggers literature weischedel et al 1993 integrated parsers search procedure parser need commit single pos tag sequence 312 second pass second pass takes output first pass uses chunk determine flat phrase chunks sentence phrase flat constituent whose children constituents starting left chunk assigns wordpos tag pair chunk tag either start x join x x constituent label figure 4 shows result second pass chunk tags used chunk detection consecutive sequence words wn n grouped flat chunk wm assigned start x wn assigned join x result chunk detection shown figure 5 forest trees serves input third pass granularity chunks well possible constituent labels chunks determined treebank used train parser examples constituents marked flat chunks wall st journal domain penn treebank include noun phrases nonexecutive director adjective phrases 61 years old quantifier phrases 370 million chunking second pass differs chunkers literature ramshaw marcus 1995 church 1988 finds chunks constituent table 2 comparison build check operations shiftreduce parser procedure actions similar shiftreduce parser action check shift check yes reduce ff ff cfg rule proposed constituent build start x join x determines ff subsequent reduce operations saw man telescope figure 2 initial sentence vbd saw man telescope figure 3 result first pass start np vbd saw start np join np man start np join np telescope figure 4 result second pass vbd saw man telescope figure 5 result chunk detection labels noun phrase chunks multipass approach similar approach parser abney 1991 also first finds chunks one pass attaches together next pass start vp vbd saw join vp man telescope figure 6 application build join vp action start vp vbd saw join vp man telescope figure 7 recently proposed constituent shown start vp vbd saw join vp man telescope figure 8 application check action indicating proposed constituent figure 7 complete build process tree marked derivation partially completed tree f prp vbd dt nn dt nn start np start np join np start np join np start start vp join vp g 313 third pass third pass always alternates use build check completes remaining constituent structure build decides whether tree start new constituent join incomplete constituent immediately left accordingly annotates tree either start x x constituent label join x x matches label incomplete constituent left build always processes leftmost tree without start x join x annotation figure 6 shows application build action join vp build control passes check finds recently proposed constituent decides complete recently proposed constituent shown figure 7 rightmost sequence trees n annotated start x annotated join x check decides yes proposed constituent takes place forest actual constituent build work otherwise constituent finished build processes next tree forest n1 force check answer proposed constituent flat chunk since constituents must formed second pass otherwise flat chunks would unique derivations figure 8 shows result check looks proposed constituent figure 7 decides third pass terminates check presented constituent spans entire sentence complete derivation n word sentence consists n actions tag n actions chunk alternating actions build check reference purposes derivation partially completed tree figure 8 included caption constituent labels produced build ie types x start x join x actions determined treebank used train parser table 2 compares actions build check operations standard shiftreduce parser yes actions check correspond shift reduce actions respectively important difference shiftreduce parser creates constituent one step reduce ff procedures build check create several steps smaller increments use maximum entropy models together shiftreduce parsing novel knowledge shiftreduce parsing techniques popular natural language literature aho et al 1988 describe shiftreduce parsing techniques programming languages detail marcus 1980 uses shiftreduce parsing techniques natural language briscoe carroll 1993 describe probabilistic approaches lr parsing type shiftreduce parsing recent machine learning approaches shiftreduce parsing include magerman 1995 hermjakob mooney 1997 32 probability models use context predict parsing actions parser uses historybased approach black et al 1993 probability px ajb used score action procedure x 2 f tag chunk build check g depending partial derivation b also called context history available time decision conditional probability models px estimated maximum entropy framework advantage framework use arbitrarily diverse information context b computing probability action procedure x context b rich source information difficult know exactly information useful parsing however would like implement following inexact intuitions parsing ffl using constituent head words useful ffl using combinations head words useful ffl using lessspecific information useful ffl allowing limited lookahead useful intuitions implemented maximum entropy framework fea tures feature assigned weight corresponds useful modeling data later show mere handful guidelines sufficient completely describe feature sets used parsing models 321 maximum entropy framework maximumentropy framework clean way experimenters combine evidence thought useful modeling data exact nature evidence task dependent framework independent parsing task used many problems like language modeling speech recognition lau et al 1993 rosenfeld 1996 machine translation berger et al 1996 basic unit evidence framework feature function f set possible actions b set possible contexts feature given b pair captures information b might useful predicting given training set b observed probability pair b training set define e observed expectation feature ab intuitively normalized count feature f j training set later describe section 323 obtain training sets treebank desire conditional probability model p consistent observed expectation f j also one likely generalize well unseen data principle maximum entropy jaynes 1957 recommends choose model p highest entropy set models consistent observed expectations ie model maximally noncomittal beyond meeting observed evidence follow conditional maximumentropy framework described berger et al 1996 chooses p ab ab pbpajb log pajb features model pb observed probability context b training set p set consistent models models expectation f j hp entropy model p averaged contexts training set form solution p a2a parameters model ff j 0 zb normalization factor interesting relationship maximum likelihood estimates models form 2 maximum entropy models also case ab q set models form 2 lp proportional loglikelihood training set according model p therefore p viewed maximum entropy maximum likelihood frameworks maximizes entropy set consistent models p maximizes likelihood set models form 2 q duality appealing since maximum entropy model p assume anything beyond evidence maximum likelihood model p close fit observed data maximum entropy framework duality maximum likelihood estimation discussed detail elsewhere berger et al 1996 della pietra et al 1997 advantage framework independence assumptions inherent restrictions features beyond form 1 therefore experimenters add arbitrarily diverse complicated features parsing models advantage significant informative features parsing described section 322 often interdependent nature 322 features evidence maximum entropy framework must expressed features feature implemented function called contextual predicate contextual predicate checks presence absence useful information context b 2 b returns true false accordingly implementation maximumentropy framework every feature f format therefore expresses cooccurrence relationship action 0 linguistic fact context captured cp contextual predicates procedure x denoted cpx table 3 specifies guidelines templates creating cpx build check g templates linguistic hints specify information instead specify location useful information context b templates use indices relative tree currently modified example current tree 5th tree consgamma2 looks constituent label head word startjoin annotation 3rd tree forest actual contextual predicates cpx obtained automatically recording certain aspects context specified templates procedure x used derivations trees treebank example actual contextual predicate cp 2 cp build derived automatically template cons0 might ae true 0th tree b label np head word false otherwise order obtain predicate must exist derivation manually parsed example sentences build decides action presence partial derivation b 0th tree b constituent label np head word constituent head words found necessary algorithm black et al 1993 magerman 1995 contextual predicates look head words especially pairs head words may reliable predictors procedure actions due sparseness training set therefore lexically based contextual predicate also exist one corresponding less specific contextual predicates look context omit one words example templates cons0 1 cons0 1 omit references head word 1st tree 0th tree 0th 1st tree respectively less specific contextual predicates allow model provide reliable probability estimates words history rare less specific predicates enumerated table 3 existence indicated default predicates table 3 return true context least specific frequent predicates provide reasonable estimates model encounters context every contextual predicate unreliable contextual predicates attempt capture intuitions parsing information discussed earlier example predicates derived templates like cons0 look constituent head words predicates derived templates like consgamma1 0 look combinations head words predicates derived templates like look less specific information predicates derived templates like cons0 use limited lookahead furthermore information expressed predicates always local parsing action taking place contextual predicates tag discussed elsewhere ratnaparkhi 1996 look previous 2 words tags current word following 2 words contextual predicates chunk look previous 2 words tags chunk labels well current following 2 words tags build uses head word information previous 2 current trees well following 2 chunks check looks surrounding 2 words head words children proposed constituent intuitions behind contextual predicates linguistically deep result information necessary parsing specified concisely templates 323 training events contextual predicates procedure x used encode derivations treebank set training events g b 2 tx represents action procedure x derivation encoded cp contextual predicates cp 2 cpx cp context action occurred procedure x example figure 9 shows encoding partial derivation build procedure predicts join vp context b 2 b practice encoded sequence contextual predicates encoding implementation choice mathematics maximum entropy framework rely upon one particular encoding space possible contexts b training events tx procedure x 2 f tag chunk build check g used feature selection parameter estimation described 324 feature selection feature selection refers process choosing useful subset features sx set possible features px use maximum entropy model corresponding procedure x cpx contextual predicates used encode training events tx ax possible table 3 contextual information used probability models possible less specific contexts used less specific context includes word must include head word current tree ie 0th tree procedure templates description templates used tag see ratnaparkhi 1996 chunk chunkandpostagn word pos tag chunk tag nth leaf chunk tag omitted n 0 chunkandpostag0 chunkandpostaggamma1 chunkandpostag1 default returns true context build consn head word constituent pos label startjoin annotation nth tree startjoin annotation omitted n 0 punctuation constituent could join 1 contains current tree 2 contains current tree 3 spans entire sentence current tree bracketsmatch iscomma end ofsentence default returns true context check checkconsn head word constituent pos label nth tree label proposed constituent begin last first last child resp proposed constituent checkconsbegin checkconsmn checkconsm checkconsn checkconsilast last production constituent label parent x constituent pos labels children proposed constituent tag word nth leaf left con stituent n 0 right constituent default returns true context start vp vbd saw join vp man telescope action join vp encoded follows vertical bar separates information subtree comma separates information different subtrees tilde denotes constituent label opposed partofspeech tag contextual cons0npman cons1inwith cons2nptelescope cons10startvpvbdnpman cons10startvpvbdsawnpman cons01npinwith cons01npmaninwith cons012npmaninnptelescope cons012npmaninwithnptelescope cons101startvpvbdnpmaninwith cons101startvpvbdsawnpmaninwith cons210startsnpstartvpvbdnpman cons210startsnpistartvpvbdnpman cons210startsnpstartvpvbdsawnpman cons210startsnpistartvpvbdsawnpman figure 9 encoding derivation contextual predicates actions procedure x set possible features px use xs model thus contextual predicate cp occurs action 0 potentially feature however many features occur infrequently therefore reliable sources evidence since behavior training events may represent behavior unseen data example unlikely contextual predicates table 9 would form reliable features use simple feature selection strategy assume feature occurs less 5 times noisy discard feature selection count cutoff yield minimal feature set many selected features redundant however practice yields feature set mostly noisefree almost computational expense therefore selected features use procedure xs model approach burden deciding contribution selected feature towards modeling data falls parameter estimation algorithm 325 parameter estimation training set tx used estimate parameters corresponding probability model px form 2 tag chunk build check g feature f j corresponds parameter ff j viewed weight reflects importance usefulness feature parameters fff model found automatically generalized iterative scaling algorithm darroch ratcliff 1972 summarized 1 add correction feature f k1 model defined c constant 1 b pair 2 estimate parameters using following iterative algorithm ab l ff n algorithm guarantees likelihood training set nondecreasing ie lp n1 lp n sequence fp n eventually converge p maximum likelihood estimate models form 2 practice parameter updates stopped fixed number iterations eg 100 lp heuristically set threshold gis algorithm applied separately training sets create models px x 2 f tag chunk build check g 326 scoring parse trees use models p tag p chunk p build p check define function score search procedure uses rank derivations incomplete complete parse trees notational convenience define q follows tag ajb action tag chunk ajb action chunk build ajb action build check ajb action check ang derivation parse necessarily complete action treebuilding procedure design treebuilding procedures guarantee ang derivation parse score merely product conditional probabilities individual actions derivation context decided 33 search search heuristic attempts find best parse defined advance theta q gamma applies relevant tree building procedure returns list new derivations whose action probabilities pass threshold q insert theta h gamma void inserts heap h extract h gamma removes returns derivation h highest score completed gamma ftruefalseg returns true complete derivation completed parses contains derivations length break completedd q insertd q c else insertd q h figure 10 top k bfs search heuristic treess complete parses input sentence heuristic employs breadthfirst search bfs explore entire frontier rather explores top k scoring incomplete parses frontier terminates found complete parses hypotheses exhausted furthermore g possible actions given procedure derivation context b sorted decreasing order according qa jb consider exploring actions hold probability mass defined follows q threshold less 1 search also uses tag dictionary described ratnaparkhi 1996 constructed training data reduces seconds sentence length figure 11 observed running time top k bfs section 23 penn treebank wsj using one 167mhz ultrasparc processor 256mb ram sun ultra enterprise 4000 number actions explored tagging model thus three parameters search heuristic namely km q experiments reported paper use describes top k bfs semantics supporting functions emphasized k 1 parser commit single pos chunk assignment input sentence building constituent structure three passes described section 31 integrated search ie parsing test sentence input second pass consists k top scoring distinct pos tag assignments input sentence likewise input third pass consists k top scoring distinct chunk pos tag assignments input sentence top k bfs described exploits observed property individual steps correct derivations tend high probabilities thus avoids searching large fraction search space since practice constant amount work advance step derivation since derivation lengths roughly proportional sentence length would expect run linear observed time respect sentence length figure 11 confirms assumptions linear observed running time table 4 sizes training events actions features procedure number training events number actions number features tag 935655 43 119910 chunk 935655 41 230473 check 1097584 2 182474 build 1097584 52 532814 4 experiments experiments conducted treebank widely used statistical natural language processing community namely wall st journal treebank release 2 university pennsylvania marcus et al 1994 maximum entropy parser trained sections 2 21 roughly 40000 sentences wall st journal corpus tested section 23 2416 sentences comparison work table 4 describes number training events extracted wall st journal corpus number actions resulting probability models number selected features resulting probability models took roughly hours train probability models using one 167 mhz sun ultrasparc processor 1 gb disk space words partofspeech tags constituent labels constituent boundaries penn treebank used training testing annotation function tags indiciate semantic properties constituents null elements indicate traces coreference removed training testing previous literature statistical parsing used following measures based proposed black et al 1991 comparing proposed parse p corresponding correct treebank parse correct constituents p constituents correct constituents p constituents p constituent p correct exists constituent label spans words 2 table 5 shows results using measures well results using slightly forgiving measures used magerman 1995 table 5 shows maximum entropy parser compares favorably stateofthe art systems magerman 1995 collins 1996 goodman 1997 charniak 1997 collins 1997 shows results collins 1997 better precision recall parser hermjakob mooney 1997 also performs well 90 labelled precision recall wall st journal domain uses test set comprised sentences frequent words recovers different table 5 results 2416 sentences section 23 0 100 words length wsj treebank evaluations marked pi ignore quotation marks evaluations marked collapse distinction constituent labels advp prt ignore punctuation parser precision recall maximum entropy pi 868 856 maximum entropy 875 863 table 6 speed accuracyon 5 random sample test set function search parameters km secondssentence precision recall form annotation therefore comparable parsers table 5 figure 12 shows effects training data size versus performance table 6 shows effect varying search parameters k parsers speed accuracy parsing accuracy degrades k reduced even accuracy 82 precision recall sample original training figure 12 performance section 23 function training data size x axis represents random samples different sizes sections 2 21 wall st journal corpus 41 portability across domains important concern since corpusbased methods suffer accuracy tested domain unrelated one trained eg see sekine 1997 since treebank construction timeconsuming expensive process unlikely near future treebanks exist every domain could conceivably want parse becomes important quantify potential loss accuracy training treebanked domain like wall st journal testing new domain experiments section address following two practical questions ffl much accuracy lost parser trained wall st journal domain tested another domain compared parser trained tested wall st journal ffl much small amount additional training material 2000 sentences new domain help parsers accuracy new domain new domains namely magazine journal articles general fiction adventure fiction brown corpus francis kucera 1982 collection english text brown university represents wide variety table 7 description training test sets name description category wsjtrain sections 2 21 wsj corpus financial news gtrain first 2000 sentences section g brown corpus magazine articles gtest remaining 1209 sentences section g brown corpus magazine articles ktrain first 2000 sentences section k brown corpus general fiction ktest remaining 2006 sentences section k brown corpus general fiction ntrain first 2000 sentences section n brown corpus adventure fiction ntest remaining 2121 sentences section n brown corpus adventure fiction table 8 portability experiments brown corpus see table 7 training test sets description test corpus accuracy precisionrecall avg accuracy g k n precisionrecall 1 train wsjtrain test xtest 802795 791788 806799 800794 2 train wsjtrain test xtest 810805 809803 820810 813806 3 train xtrain test xtest 782763 777767 787776 782769 different domains domains annotated convention similar text wall st journal treebank part penn treebank project table 8 describes results several different training schemes table 7 describes training test corpora feature sets parser changed way training brown corpus domains according table 8 training schemes parsing new domain ranked order best worst 1 strategy 2 train mixture lot wall st journal wsj little 2 strategy 1 train lot wsj 3 strategy 3 train little experiments particular new domain g k n controlled use test set additional training sets gtrain ktrain ntrain consist 2000 sentences respective domain compared accuracy achieved training testing wall st journal 868 precision856 recall shown table 5 conclude ffl average lose 68 precision 62 recall training wall st journal testing brown corpus strategy 1 ffl average lose 55 precision 5 recall training wall st journal domain interest testing domain strategy 2 discussion thus far omitted one possibility namely lower brown corpus performance strategies 1 2 due inherent difficulty parsing brown corpus text mismatch training test data quick glance figure 12 table 8 dispels possibility since training roughly 2000 sentences wall st journal yields 79 precision 78 recall slightly higher 1 results brown corpus identical circumstances strategy 3 roughly 78 precision 77 recall follows brown corpus slightly difficult parse wall st journal corpus training domaintest domain mismatch must account accuracy loss using strategies 1 2 42 reranking top n often advantageous produce top n parses instead top 1 since additional information used secondary model reorders top n hopefully improves quality top ranked parse suppose exists perfect reranking scheme sentence magically picks best parse top n parses produced maximum entropy parser best parse highest average precision recall compared treebank parse performance perfect scheme upper bound performance actual reranking scheme might used reorder top n parses figure 13 shows perfect scheme would achieve roughly 93 precision recall dramatic increase top 1 accuracy 87 precision 86 recall figure 14 shows exact match counts percentage times proposed parse p identical excluding pos tags treebank parse rises substantially 53 30 perfect scheme applied surprising accuracy improves looking top n parses suprisinggiven thousands partial derivations explored discardedthat accuracy improves drastically looking top 20 completed parses reason research reranking schemes appears promising practical step towards goal improving parsing accuracy accuracy number parses sentence recall figure 13 precision recall perfect reranking scheme top n parses section 23 wsj treebank function n evaluation ignores quotation marks 5 comparison previous work compared parsers accuracy maximum entropy parser stateoftheart performs slightly better equal systems compared table 5 performs slightly worse collins 1997 however differences accuracy fairly small unclear differences matter performance applications require parsed input main advantage maximum entropy parser accuracy achieves accuracy using simple facts data derived linguistically obvious intuitions parsing result evidence needs specified concisely method reused tasks resulting minimum amount effort part experimenter furthermore maximum entropy parser combines best aspects work example parsers black et al 1993 jelinek et al 1994 magerman 1995 use general learning techniquedecision treesto learn parsing actions need represent words bitstrings derived statistical word clustering technique maximum entropy parser also uses general learning technique uses natural linguistic representations words constituents therefore require typically expensive word clustering procedure accuracy number parses sentence exact match 33333 3 3 3 3 3 3 3 3 3 3 3 3 3 figure 14 exact match perfect reranking scheme top n parses section 23 wsj treebank function n evaluation ignores quotation marks parsers like collins 1996 goodman 1997 charniak 1997 collins 1997 use natural linguistic representations words constituents use general machine learning techniques instead use custombuilt statistical models combine evidence clever ways achieve high parsing ac curacies always possible tune methods maximize accuracy methods specific parsing problem require nontrivial research effort develop contrast maximum entropy parser uses existing modeling framework essentially independent parsing task saves experimenter designing new parsingspecific statistical model general supervision typically leads higher accuracy example collins 1997 uses semantic tags penn treebank slightly less accurate parsers table 5 discard information also hermjakob mooney 1997 uses handconstructed knowledge base subcategorization table report 90 labelled precision recall using different test set evaluation method additional information used approaches well word clusters used magerman 1995 could theory implemented features maximum entropy parser research needed see additions parsers representation improve parsers accuracy portability parsers discussed limited availability treebanks currently treebanks exist constructing new treebank requires tremendous amount effort likely current corpusbased parsers parse text less accurately domain text similar domain treebank used train parser 6 conclusion maximum entropy parser achieves stateoftheart parsing accuracy minimizes human effort necessary construction use general learning technique simple representation derived intuitions parsing results exceed parser presented require much human effort form additional resources annotation practice parses test sentence linear time respect sentence length trained domains without modification learning technique representation lastly paper clearly demonstrates schemes reranking top 20 parses deserve research effort since could yield vastly better accuracy results high accuracy maximum entropy parser also interesting implications future applications general machine learning techniques parsing shows procedures actions parser builds trees designed independently learning technique learning technique utilize exactly sorts information eg words tags constituent labels might normally used traditional nonstatistical natural language parser implies feasible use maximum entropy models general learning techniques drive actions kinds parsers trained linguistically sophisticated treebanks perhaps better combination learning technique parser treebank exceed current stateoftheart parsing accuracies 7 acknowledgments author would like thank mike collins mitch marcus university pennsylvania many helpful comments work author would also like thank three anonymous reviewers paper constructive comments work supported arpa grant n6600194c6043 notes 1 parameters km q optimized speed accuracy development set separate training test sets 2 precision recall measures count partofspeech tags constituents r parsing chunks natural language understanding maximum entropy approach natural language processing procedure quantitatively comparing syntactic coverage english grammars towards historybased grammars using richer models probabilistic parsing generalized probabilistic lr parsing natural language corpora unificationbased grammars statistical parsing contextfree grammar word statistics stochastic parts program noun phrase chunker unrestricted text three generative new statistical parser based bigram lexical dependencies generalized iterative scaling loglinear models inducing features random fields ieee transactions pattern analysis machine intelligence frequency analysis english usage lexicon grammar probabilistic feature grammars learning parse translation decision examples rich context information theory statistical mechanics decision tree parsing using hidden derivational model adaptive language modeling using maximum entropy principle statistical decisiontree models parsing theory syntactic recognition natural language building large annotated corpus english penn treebank text chunking using transformationbased learning yarowsky maximum entropy part speech tagger domain dependence parsing coping ambiguity unknown words probabilistic models tr ctr tong zhang david johnson robust risk minimization based named entity recognition system proceedings seventh conference natural language learning hltnaacl 2003 p204207 may 31 2003 edmonton canada nanda kambhatla combining lexical syntactic semantic features maximum entropy models extracting relations proceedings acl 2004 interactive poster demonstration sessions p22es july 2126 2004 barcelona spain ittycheriah l lita n kambhatla n nicolov roukos stys identifying tracking entity mentions maximum entropy framework proceedings conference north american chapter association computational linguistics human language technology companion volume proceedings hltnaacl 2003short papers p4042 may 27june 01 2003 edmonton canada michele banko eric brill mitigating paucityofdata problem exploring effect training corpus size classifier performance natural language processing proceedings first international conference human language technology research p15 march 1821 2001 san diego hongyan jing radu florian xiaoqiang luo tong zhang abraham ittycheriah howtogetachinesenameentity segmentation combination issues proceedings conference empirical methods natural language processing p200207 july 11 analysis grammatical functions adnoun noun phrases korean using support vector machines natural language engineering v9 n3 p269280 september yasemin altun mark johnson thomas hofmann investigating loss functions optimization methods discriminative learning label sequences proceedings conference empirical methods natural language processing p145152 july 11 david mcclosky eugene charniak mark johnson reranking selftraining parser adaptation proceedings 21st international conference computational linguistics 44th annual meeting acl p337344 july 1718 2006 sydney australia james henderson ivan titov datadefined kernels parse reranking derived probabilistic models proceedings 43rd annual meeting association computational linguistics p181188 june 2530 2005 ann arbor michigan nanda kambhatla minority vote atleastn voting improves recall extracting relations proceedings colingacl main conference poster sessions p460466 july 1718 2006 sydney australia eugene charniak mark johnson edit detection parsing transcribed speech second meeting north american chapter association computational linguistics language technologies 2001 p19 june 0107 2001 pittsburgh pennsylvania eugene charniak immediatehead parsing language models proceedings 39th annual meeting association computational linguistics p124131 july 0611 2001 toulouse france dan klein christopher manning parsing fast exact viterbi parse selection proceedings conference north american chapter association computational linguistics human language technology p4047 may 27june 01 2003 edmonton canada james henderson discriminative training neural network statistical parser proceedings 42nd annual meeting association computational linguistics p95es july 2126 2004 barcelona spain zhou guodong discriminative hidden markov modeling long state dependence using knn ensemble proceedings 20th international conference computational linguistics p22es august 2327 2004 geneva switzerland michael collins brian roark incremental parsing perceptron algorithm proceedings 42nd annual meeting association computational linguistics p111es july 2126 2004 barcelona spain james henderson inducing history representations broad coverage statistical parsing proceedings conference north american chapter association computational linguistics human language technology p2431 may 27june 01 2003 edmonton canada eugene charniak maximumentropyinspired parser proceedings first conference north american chapter association computational linguistics p132139 april 29may james r curran stephen clark investigating gis smoothing maximum entropy taggers proceedings tenth conference european chapter association computational linguistics april 1217 2003 budapest hungary joseph turian dan melamed advances discriminative parsing proceedings 21st international conference computational linguistics 44th annual meeting acl p873880 july 1718 2006 sydney australia gerard escudero llus mrquez german rigau comparison supervised learning algorithms word sense disambiguation proceedings 2nd workshop learning language logic 4th conference computational natural language learning september 1314 2000 lisbon portugal wang kenji sagae teruko mitamura fast accurate deterministic parser chinese proceedings 21st international conference computational linguistics 44th annual meeting acl p425432 july 1718 2006 sydney australia james henderson neural network probability estimation broad coverage parsing proceedings tenth conference european chapter association computational linguistics april 1217 2003 budapest hungary brian roark michiel bacchiani supervised unsupervised pcfg adaptation novel domains proceedings conference north american chapter association computational linguistics human language technology p126133 may 27june 01 2003 edmonton canada xiaoqiang luo imed zitouni multilingual coreference resolution syntactic features proceedings conference human language technology empirical methods natural language processing p660667 october 0608 2005 vancouver british columbia canada rahul gupta sunita sarawagi creating probabilistic databases information extraction models proceedings 32nd international conference large data bases september 1215 2006 seoul korea ryan mcdonald koby crammer fernando pereira online largemargin training dependency parsers proceedings 43rd annual meeting association computational linguistics p9198 june 2530 2005 ann arbor michigan xavier carreras b llus mrquez c jorge castro filteringranking perceptron learning partial parsing machine learning v60 n13 p4171 september 2005 rens bod minimal set fragments achieves maximal parse accuracy proceedings 39th annual meeting association computational linguistics p6673 july 0611 2001 toulouse france ismael garcavarea francisco casacuberta maximum entropy modeling suitable framework learn contextdependent lexicon models statistical machine translation machine learning v60 n13 p135158 september 2005 rebecca hwa philip resnik amy weinberg clara cabezas okan kolak bootstrapping parsers via syntactic projection across parallel texts natural language engineering v11 n3 p311325 september 2005 exploiting dictionaries named entity extraction combining semimarkov extraction processes data integration methods proceedings tenth acm sigkdd international conference knowledge discovery data mining august 2225 2004 seattle wa usa rens bod parsing shortest derivation proceedings 18th conference computational linguistics p6975 july 31august rens bod fragments count natural language engineering v9 n4 p307323 december