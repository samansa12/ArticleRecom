softwaredirected register deallocation simultaneous multithreaded processors abstractthis paper proposes evaluates software techniques increase register file utilization simultaneous multithreading smt processors smt processors require large register files hold multiple thread contexts issue instructions order every cycle supporting better interthread sharing management physical registers smt processor reduce number registers required improve performance given register file size techniques specifically target register deallocation outoforder processors register renaming effective knowing new physical register must allocated limited knowledge physical registers deallocated propose architectural extensions permit compiler operating system immediately upon last use registers allocated idle thread contexts results based detailed instructionlevel simulations smt processor show techniques increase performance significantly registerintensive multithreaded programs b introduction simultaneous multithreading smt highperformance architectural technique substantially improves processor performance executing multiple instructions multiple threads every cycle dynamically sharing processor resources among threads smt increases functional unit utilization thereby boosting instruction throughput multiprogrammed workloads application speedup multithreaded programs 5 previous research looked performance potential smt 24 well several portions design including instruction fetch mechanisms cache organization 2313 paper focuses another specific design area impacts smts costeffectiveness organization utilization register file smt raises difficult tradeoff register file design large register file required service architectural renaming register needs multiple thread contexts smaller register files provide faster access times therefore smt processor needs use register resources efficiently order optimize die area performance paper propose evaluate software techniques increase register utilization permitting smaller faster register file still satisfying processors need support multiple threads techniques involve coordination operating system compiler lowlevel register renaming hardware provide effective register use singlethreaded multithreaded programs result improved performance given number hardware contexts ability handle contexts given number registers example experiments indicate 8context smt processor 264 physical registers managed techniques present attain performance comparable processor 352 physical registers techniques focus supporting effective sharing registers smt processor using register renaming permit multiple threads share single global register file way one thread high register pressure benefit threads low register demands unfortunately existing register renaming techniques cannot fully exploit potential shared register file particular existing hardware effective allocating physical registers limited ability identify register deallocation points therefore hardware must free registers conservatively possibly wasting registers could better utilized propose software support expedite deallocation two types dead registers 1 registers allocated idle hardware contexts 2 registers active contexts whose last use already retired first case thread terminates execution multithreaded architecture hardware context becomes idle threads waiting run registers allocated terminated thread dead freed practice hardware register deallocation occurs registers new active thread mapped causes potentiallyshared smt register file behave like partitioned collection perthread registers experiments show notifying hardware os scheduling decisions performance register file size 264 boosted 3 times 2 4 threads running comparable processor 352 registers address second type dead registers active threads investigate five mechanisms allow compiler communicate lastuse information processor renaming hardware deallocate registers aggressively without information hardware must conservatively deallocate registers redefined simulation results indicate mechanisms reduce register deallocation inefficiencies particular small register files best schemes attains speedups 25 applications 16 average register deallocation schemes could benefit outoforder processor smt remainder paper organized follows section 2 briefly summarizes smt architecture register renaming inefficiencies experimental methodology described section 3 section 4 describes os compiler support use improve register usage discuss related work section 5 offer concluding remarks section 6 simultaneous multithreading smt processor model similar used previous studies eightwide outof order processor hardware contexts eight threads every cycle four instructions fetched two threads fetch unit favors high throughput threads selecting two threads fewest instructions waiting executed fetching instructions decoded registers renamed inserted either integer floating point instruction queues operands become available instructions thread issued functional units execution finally instructions retired perthread order components smt processor integral part dynamicallyscheduled wideissue superscalar instruction scheduling important case point instructions issued operands calculated loaded memory without regard thread register renaming hardware eliminates interthread register name conflicts mapping threadspecific architectural registers onto processors physical registers major additions conventional superscalar instruction fetch unit mentioned several perthread mechanisms program counters return stacks retirement trap logic identifiers tlb branch target buffer register file contains register state processorresident threads consequently requires two additional pipeline stages accessing one reading writing see 23 details 21 register renaming register deallocation problem register renaming eliminates false output anti dependences introduced compilers register allocator assigns arbitrary number pseudoregisters limited number architectural registers instruction set architecture dependences broken dynamically aliasing defined architectural register different physical register enabling formerly dependent instructions executed parallel smt assumes register mapping scheme similar used dec 21264 8 mips r10000 27 register renaming hardware responsible three primary functions 1 physical register allocation 2 register operand renaming 3 register deallocation physical register allocation occurs demand instruction defines architectural register mapping created architectural register available physical register entered mapping table registers available instruction fetching stalls rename register operand renaming hardware locates architecturaltophysical mapping mapping table aliases physical number register deallocation works conjunction instruction retirement active list keeps track uncommitted instructions perthread program order instructions retire physical registers deallocated become available reallocation renaming hardware handles physical register allocation renaming rather effectively fails manage deallocation efficiently register dead could deallocated last use commits hardware however cannot identify last uses registers knowledge register lifetimes consequently hardware safely deallocate physical register commits another instruction redefines associated architectural register shown figure 1 22 physical register organization register deallocation problem finegrained multithreaded architectures like tera 1 hardware context includes register file one thread thread accesses registers context shown figure 2a 1 contrast smt processor single register file shared among contexts figure 2b call organization fsr fullyshared registers register file structured single pool physical registers holds state resident threads smts register renaming hardware essentially extension register mapping scheme multiple contexts threads name architectural registers context renaming hardware maps threadprivate architectural registers pool thread independent physical registers register renaming thus provides transparent mechanism sharing register pool although smt processor best utilized hardware contexts busy contexts may occasionally idle maximize performance physical registers allocated idle contexts instead physical registers shared active threads however existing register deallocation schemes thread terminates architectural registers remain allocated processor redefined new thread executing context consequently fsr organization behaves like partitioned file shown figure 2c call partitioned organization pasr private architectural shared renaming registers isas architectural registers consequently thirtytwo physical registers must dedicated context pasr scheme example eightcontext smt 352 registers 96 352832 physical registers available sharing among active threads 1 note discussing different logical organizations register file file physically structured separate issue 3 addl r20r21r12 figure 1 example illustrates inability renaming hardware efficiently deallocate physical register r20 destination registers italicized instruction 1 defines r20 creating mapping physical register say p1 instruction 3 last use r20 however p1 cannot freed r20 redefined instruction n meantime several instructions potentially large number cycles pass last use p1 r20 deallocation threadthreadthreadthreada figure 2 logical register file configurations terastyle partitioned register file b smt register file threads share common pool physical registers c smt register file given current register deallocation schemes hardware context dedicated physical registers isadefined architectural registers renaming registers shared across contexts b c threadthreadthreadthreadrenaming registers architectural registers 3 methodology experiments defined several register file management techniques devised compensate conservative register deallocation evaluated using instructionlevel simulation applications spec 95 20 splash2 26 benchmark suites table 1 suif compiler 9 automatically parallelized spec benchmarks multithreaded c code programs already explicitly parallelized programmer programs compiled multiflow tracescheduling compiler 14 dec alpha object files multiflow generates highquality code using aggressive static scheduling wide issue loop unrolling ilpexposing optimizations object files linked versions anl 2 suif runtime libraries create executables smt simulator processes unmodified alpha executables uses emulationbased instructionlevel simulation model detail processor pipelines hardware support oforder execution entire memory hierarchy including tlbs 128 entries instruction data tlbs cache behavior bank bus contention memory hierarchy processor consists two levels cache sizes latencies bandwidth characteristics shown table 2 register file management affected memory application data set instructions simulated spec 95 fp applu 33x33x33 array 2 iterations 2719 iterations 4735 mgrid 64x64x64 grid 1 iteration 3193 b su2cor 16x16x16x16 vector length 4096 2 iterations 5356 b iterations 4191 tomcatv 513x513 array 5 iterations 1891 turb3d data points 320 lu 512x512 matrix 4312 waternsquared 512 molecules 3 timesteps 8699 waterspatial 512 molecules 3 timesteps 7835 table 1 benchmarks used study spec95 applications data sets size spec reference set reduced number iterations length simulation time l1 icache l1 dcache l2 cache size bytes 128 k associativity twoway twoway direct mapped line size bytes 64 64 64 banks cache fill time cycles latency next level table 2 configuration latency parameters smt cache hierarchies used study latencies 1 experimented two different memory hierarchies larger memory configuration represents probable smt memory hierarchy machines production approximately 3 years future smaller configuration serves two purposes 1 models todays memory hierarchies well tomorrows lowcost processors multimedia coprocessors 2 provides appropriate ratio data set cache size modeling programs larger data sets data sets less data locality benchmarks 19 also examined variety register file sizes ranging 264 352 gauge sensitivity register file management techniques register size 352 registers processor resources instruction queues become performance bottlenecks low end least 256 registers required hold architectural registers eight contexts 2 provide additional 8 renaming registers total 264 smaller register files attractive several reasons first shorter access time advantage could used either decrease cycle time register file access critical path eliminate extra stages allow register reading writing second take less area register files current processors occupy negligible portion roughly 1 chip area large multiported smt register file could raise around 10 area allocation might acceptable third smaller register files consume less power branch prediction used mcfarlingstyle hybrid predictor 256entry 4way setassociative branch target buffer hybrid predictor 8k entries selects global history predictor 13 history bits local predictor 2kentry local history table indexes 4kentry 2bit local prediction table 16 length simulations limited detailed simulation results parallel computation portion applications norm simulating parallel applications initialization phases applications used fast simulation mode warmed caches turned detailed simulation mode main computation phases reached 4 techniques improving register file management despite flexible organization smt register file underutilized renaming hardware fails deallocate dead registers promptly section describe communication mechanisms allow operating system compiler assist renaming hardware register deallocation identifying dead registers belong idle active contexts 41 operating system support deadregister deallocation explained section 22 executing thread terminates threads physical registers remain allocated consequently active threads cannot access registers causing fullyshared register file fsr behave like one registers partitioned context pasr thread terminates operating system decides schedule newlyavailable hardware context three options different implication 1 smaller caches increase miss rates latencies hidden register pressure increases opposite true larger caches 2 absence mechanisms avoid detect recover deadlock register deallocation 1 idle contexts new threads run context idle terminated threads physical registers could deallocated become available active threads 2 switching new thread physical registers new threads architectural registers normally allocated begins execution efficient scheme would free terminated threadss physical registers allocating physical registers new thread demand unallocated physical registers would available contexts 3 switching swappedout thread context switch code loads register state new thread load instructions retire physical registers used terminated thread deallocated three scenarios present opportunity deallocate terminated threads physical registers early propose privileged context deallocation instruction cdi triggers physical register deallocation thread operating system scheduler would execute instruction context terminated thread response renaming hardware would free terminating threads physical registers instruction retires three tasks must performed handle context deallocation instruction creating new map table invalidating contexts register mappings returning registers free list cdi enters pipeline current map table saved new map table valid entries created saved map table identifies physical registers deallocated new table hold subsequent register mappings cdi retires saved map traversed mapped physical registers returned free list finally entries saved map invalidated cdi executed wrongpath consequently gets squashed new saved map tables thrown away much hardware required three tasks already exists outoforder processors register mapping branch enters pipeline copy map table created branch resolved one map tables invalidated depending whether speculation correct instructions must squashed renaming hardware traverses active list structure identifies physical registers determine physical registers returned free list although cdi adds small amount logic existing renaming hardware allows smt register file behave true fsr register file instead pasr deallocating registers promptly experimental results evaluate performance fullyshared register organization fsr varied number active threads register set sizes compared pasr identical configurations modeled os scheduler frees physical registers terminated threads making physical registers available parallel application began execution results comparison shown figure 3 pasr figure 3a renaming registers shared among threads execution time therefore greater smaller register files larger numbers threads threads competed fewer registers fsr shown figure 3b less sensitive parameters fact smaller register files performance larger ones threads executing registers tied idle contexts except smallest configuration fsr performance stable varying numbers threads parallelism provided additional threads overcame increased competition registers 264register file performance sweet spot speedups figure 4 show fsr equals surpasses pasr register file sizes numbers threads fsr provides greatest benefits registers share several idle contexts pasr fewer small register files example 320 registers 4 idle contexts 4 threads fsr outperformed pasr 8 averaged applications 288 264 registers fsrs advantage grew 34 205 6 idle contexts 320 registers 15 taking factors account 288264 registers 6 idle contexts fsr outperformed pasr 51232 contexts active fsr pasr comparable case architectural state threads resident schemes fsr larger performance edge smaller cache hierarchies hiding longer memory latencies requires inflight instructions therefore outstanding registers suggests efficient register management particularly important memoryintensive workloads applications relatively poor data locality summary results illustrate partitioning multithreaded register file pasr restricts ability expose parallelism operating system support deallocating registers idle contexts enables register file fully shared across threads fsr improves performance makes less dependent size register file number active threads 42 compiler support deadregister allocation previously described hardware register deallocation inefficient hardware number threads1030 normalized execution time pasr figure 3 execution time fsr pasr larger memory hierarchy register file organization normalized 352 register 1 thread execution results smaller smt memory hierarchy identical trends288352 number threads1030 normalized execution time b fsr number registers pasr b pasr threads 4 threads 8 threads figure 4 fsr speedups pasr larger smaller b memory hierarchies different register file sizes number registers number registers b knowledge registers redefinition last use although compiler identify last use register currently means communicating information hardware section describe evaluate several mechanisms allow compiler convey register lastuse information hardware show improve register utilization smt processors fsr register file organization proposed mechanisms either new instructions fields existing instructions direct renaming hardware first however examine three factors motivate need improved register deallocation 1 often physical registers unavailable 2 many registers dead cycle 3 many cycles pass registers last use redefinition call deadregister distance register unavailability percentage total execution cycles processor runs physical registers causing fetch stalls measure severity problem caused current hardware registerdeallocation mechanisms average number dead registers cycle indicates many physical registers could reused thus potential compilerbased solution deadregister number registers integer fp applu hydro2d swim tomcatv fft lu radix watern applu hydro2d swim tomcatv fft lu radix watern large cache hierarchy 31 31 small cache hierarchy 288 26 21 53 264 22 25 442 02 649 227 934 07 881 872 27 940 85 67 00 747 table 3 frequency percentage total execution cycles registers available executing 8 threads bold entries frequencies 10 represent severe stalling due insufficient registers number registers integer fp applu hydro2d swim tomcatv fft lu radix watern applu hydro2d swim tomcatv fft lu radix watern large cache hierarchy 288 small cache hierarchy 288 74 58 table 4 average number dead registers per cycle executing 8 threads bold entries registers available 10 execution cycles distance measures average number cycles completion instruction last uses register registers deallocation rough estimate likely performance gain solution data table 3 indicate projected smt design 352 registers fsr file sufficient applications smaller register files introduce bottlenecks often severe many applications register pressure particularly high integer registers fft radix floatingpoint registers applu hydro2d tomcatv watern applications also ran registers frequently smaller cache hierarchies closer examination reveals cases stalling due insufficient registers problem bold entries table 3 huge number registers dead shown table 4 table 5 shows dead registers freed could reallocated many instructionscycles earlier suggests registers managed efficiently performance could recouped even 264register fsr might sufficient five compilerbased solutions using dataflow analysis compiler identify last use register value section evaluate five alternatives communicating lastuse information renaming hardware number registers applu hydro2d swim tomcatv fft lu radix watern average int instrs 576 591 323 672 307 569 27 327 472 int cycles 2146 1554 278 2257 899 856 80 2154 1255 fp instrs 184 309 117 226 204 71 327 185 fp cycles 971 1574 284 1200 657 224 1337 818 table 5 dead register distance 264 registers smaller cache hierarchy data indicate registers frequently deallocated many cycles last use retired figures register sizes similar bold entries registers available 10 execution cycles ldl ldl addl r20r21r24 addl r210x1r21 stl ldl base ldl r20addr1r22 ldl addl r20r21r24 addl r210x1r21 stl r12addr3r21 ldl r20addr4r25 lda r250x1000r31 free int regs identified mask c free mask ldl r20addr1r22 ldl addl r20r21r24 addl r210x1r21 stl r24addr3r21 ldl b free register figure 5 code fragments illustrate register freeing mechanisms original code fragment b shows free register instructions necessary free registers r12 r25 c free mask instructions necessary free registers 1 free register bit communicates lastuse information hardware via dedicated instruction bits dual benefits immediately identifying last uses requiring instruction overhead although unlikely implemented instruction sets two unused bits serve upper bound performance improvements attained compilers static lastuse information simulate free register bit modified multiflow generate table indexed pc contains flags indicating whether either instructions register operands last uses simulated instruction simulator performed lookup table determine whether register deallocation occur instruction retired 2 free register realistic implementation free register bit rather specifying last uses instruction uses separate instruction specify one two registers freed compiler generates free register instruction unused opcode alpha isa immediately instruction containing last register use register also redefined instruction like free register bit frees registers soon possible additional cost dynamic instruction overhead 3 free mask instruction free 32 registers used deallocate dead registers large sequence code basic block set basic blocks experiments inserted free mask instruction end multiflow trace rather identifying dead registers operand specifiers compiler generates bit mask particular implementation free mask instruction uses lower 32bits register mask indicate registers deallocated mask generated loaded register using pair lda ldah instructions 16bit immediate field example figure 5 compares free register free mask code fragment frees integer registers 20 25 free mask sacrifices promptness free registers deallocation reduction instruction overhead 4 free opcode motivated observation 10 opcodes responsible 70 dynamic instructions last use bits set indicating benefit free register bit could obtained providing special versions opcodes addition executing normal operation new instructions also specify either first second operands last uses paper use 15 opcodes listed table 6 obtained profiling free register bit instruction frequencies applu hydro2d tomcatv 1 retrofitting 15 instructions existing isa feasible example added dec alpha isa without negatively impacting instruction decoding 5 free opcodemask augments free opcode generating free mask instruction end trace hybrid scheme addresses register last uses instructions covered particular choice instructions free opcode current renaming hardware provides mechanisms register deallocation ie returning physical registers free register list perform many deallocations cycle example alpha 21264 deallocates 13 registers cycle handle multiple 1 experimented 10 22 free opcode instructions additional opcodes top 15 tended occur frequently one two applications using brought limited additional benefits exceptions swim radix instruction retirement squashing five proposed register deallocation techniques use similar mechanism free mask slightly complex specify registers case deallocation could take multiple cycles necessary experiments however 72 registers average freed mask five register deallocation schemes compared figure 6 charts speedup versus explicit register deallocation free register bit bars show register deallocation potentially improve performance significantly small register files 77 average ranging high 195 free register bit results highlight attractive outcome register deallocation improving register utilization smt processor small register files achieve large register file performance shown figure 7 significance becomes apparent context conventional register file design single threaded outoforder processors often double registers support greater degrees parallelism eg r10000 64 physical registers 21264 80 multiple register contexts smt processor need double architectural registers effectively shared results show 8context smt fsr register file ie support deallocating registers idle contexts needs 96 additional registers alleviate physical register pressure lowering renaming register cost 27 isadefined registers compilerdirected register deallocation active contexts drops overhead even 8 registers 3 architectural register state free register free mask results highlight tradeoff two alternative schemes free register effective reducing number dead registers deallocates promptly last uses registers severe bottleneck applu hydro2d tomcatv radix small register files free register outperforms free register mask free register mask hand incurs less instruction overhead therefore preferable larger register files applications low register usage free opcode variant free opcodemask 1 schemes choice strike balance free register free mask promptly deallocating registers avoiding instruction overhead registers premium free opcodemask achieved exceeded performance free register larger register file applications low register usage free mask performance attained surpassed programs register set sizes cache hierarchies free opcodemask met came close optimal performance free register bit example within integer fp opcode operand opcode operand table opcodes used free opcode note mult stt fcmov two new versions must added versions specify whether first second operands last uses 4 average 264 registers 10 352 small cache hierarchy tuning opcode selection use hybrid schemes perhaps judiciously combining free opcode free mask free register expect gap free register bit narrowed even achieve upper bound 1 profiled small sample programs determine best selection opcodes free opcode used free opcodemask provide flexibility opcode choice speedups two schemes close performance edge varies across applications 264 regis ters looking different larger set programs determine hot opcodes might tip performance balance cases example adding 6 singleprecision floating point free opcodes singleprecision swim free opcode exceeded free register free mask therefore discuss results free opcode free opcodemask together free register bit free register free register mask free register opcode free register opcodemask applu hydro2d swim tomcatv fft lu radix waternsquared mean applu hydro2d swim tomcatv fft lu radix waternsquared mean1030 applu hydro2d swim tomcatv fft lu radix waternsquared mean applu hydro2d swim tomcatv fft lu radix waternsquared mean1030 small cache small cache figure comparison register deallocation alternatives bar speedup deallocation 8 threads compilerdirected register deallocation performance summary providing hardware explicit information register lifetimes compilerdirected register deallocation significantly improve performance small smt register files become viable alternative even registerintensive applications although particularly wellsuited smt register deallocation benefit outoforder processor explicit register renaming 5 related work several researchers investigated register file issues similar discussed paper large register files concern multithreaded architectures processors register windows waldspurger weihl 25 proposed compiler runtime support managing multiple register sets register file compiler tries identify optimal number registers thread generates code using number runtime system tries dynamically pack register sets active threads register file nuth dallys 17 named state register file caches register values dynamically mapping active registers small fast set registers backing full register name space memory reduce required chip area processors register windows sun designed 3d register files 22 one register window active time density register file increased overlaying multiple register cells share wires several papers investigated register lifetimes register issues farkas et al 6regsregsregsregs500swimregsregsregsregs1000hydro2dregsregsregsregs5001500 execution cycles millions applu figure 7 comparison execution time fsr without free register bit range register file sizes bothregsregsregsregs500tomcatv larger smaller cache sizes height solid black bar represents execution time free register bitregsregsregsregs10003000 hydro2d smallregsregsregsregs500swim smallregsregsregsregs5001500 small free register bit base used total height bar corresponds execution time deallocation performed relativelyregsregsregsregs5001500 execution cycles millions small flat height black bars indicates free register bit smaller register files achieve performance larger register files compared register file requirements precise imprecise interrupts effects number registers needed support parallelism outoforder processor also characterized lifetime register values identifying number live register values present various stages renaming process franklin sohi 7 lozano gao 15 found register values short lifetimes often need committed register file proposed compiler support identify last uses architectural mechanisms allow hardware ignore writes reduce register file traffic number write ports neither applied concepts register deallocation pleszkun sohi 18 proposed mechanism exposing reorder buffer compiler could generate better schedules provide speculative execution sprangle patt 21 proposed staticallydefined tag isa exposes register renaming compiler relies basic blocks atomic units work part register file used storing basic block effects rest handles values live across basic block boundaries janssen corporaal 10 capitanio et al 3 llosa et al 12 multiflow 4 kiyohara et al 11 also investigated techniques handling large register files including partitioning limited connectivity replication use new opcodes address extended register file 6 conclusions simultaneous multithreading potential significantly increase processor utilization wideissue outoforder processors permitting multiple threads issue instructions processors functional units within single cycle consequence smt requires large register file support multiple thread contexts raises difficult design tradeoff large register files consume die area impact performance paper introduced new softwaredirected techniques increase utilization registers smt fundamental techniques global sharing registers among threads architectural register renaming register needs introducing new instructions additional fields isa allow operating system compiler signal physical register deallocation processor thereby greatly decreasing register waste result effective register use permitting either reduction register file size increase performance given file size introduced explicit softwaredirected deallocation two situations first context becomes idle operating system indicate idle contexts physical registers deallocated permits registers freed order serve renaming needs executing threads results show notification significantly boost performance remaining threads eg register file 264 registers demonstrates performance equivalent 352register file 4 threads running second allowing compiler signal last use register processor need wait redefinition register order reuse proposed several mechanisms signalling last register use showed small register files average speedups 16 obtained using efficient mechanisms results shown context smt processor mechanisms would appropriate processor using register renaming outoforder instruction issue r tera computer sys tem portable programs parallel processors partitioned register files vliws preliminary analysis tradeoffs vliw architecture trace scheduling compiler simultaneous multithreading platform nextgeneration processors register file design considerations dynamically scheduled proces sors register traffic analysis streamlining interoperation communication finegrained parallel processors digital 21264 sets new standard maximizing multiprocessor performance suif compiler partitioned register files ttas register connection new approach adding registers instruction set architectures converting threadlevel parallelism instructionlevel parallelism via simultaneous multithreading exploiting shortlived variables superscalar processors combining branch predictors namedstate register file implementation performance performance potential multiple functional unit processors scaling parallel programs multiprocessors methodology examples standard performance evaluation council facilitating superscalar processing via combined staticdynamic register renaming scheme three dimensional register file superscalar processors exploiting choice instruction fetch issue implementable simultaneous multithreading processor simultaneous multithreading maximizing onchip parallelism register relocation flexible contexts multithreading splash2 programs characterization methodological considerations mips r10000 superscalar microprocessor tr ctr hua yang gang cui hongwei liu xiaozong yang compacting register file via 2level renaming bitpartitioning microprocessors microsystems v31 n3 p178187 may 2007 matthew postiff david greene steven raasch trevor mudge integrating superscalar processor components implement register caching proceedings 15th international conference supercomputing p348357 june 2001 sorrento italy dean tullsen john seng storageless value prediction using prior register values acm sigarch computer architecture news v27 n2 p270279 may 1999 jos f martnez jose renau michael c huang milos prvulovic josep torrellas cherry checkpointed early resource recycling outoforder microprocessors proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey david w oehmke nathan l binkert trevor mudge steven k reinhardt fake 1000 registers proceedings 38th annual ieeeacm international symposium microarchitecture p718 november 1216 2005 barcelona spain mikko h lipasti brian r mestan erika gunadi physical register inlining acm sigarch computer architecture news v32 n2 p325 march 2004 chulho shin seongwon lee jeanluc gaudiot adaptive dynamic thread scheduling simultaneous multithreaded architectures detector thread journal parallel distributed computing v66 n10 p13041321 october 2006 eric tune rakesh kumar dean tullsen brad calder balanced multithreading increasing throughput via low cost multithreading hierarchy proceedings 37th annual ieeeacm international symposium microarchitecture p183194 december 0408 2004 portland oregon james burns jeanluc gaudiot smt layout overhead scalability ieee transactions parallel distributed systems v13 n2 p142155 february 2002 monreal victor vinals jose gonzalez antonio gonzalez mateo valero late allocation early release physical registers ieee transactions computers v53 n10 p12441259 october 2004 joshua redstone susan j eggers henry levy analysis operating system behavior simultaneous multithreaded architecture acm sigplan notices v35 n11 p245256 nov 2000 joshua redstone susan j eggers henry levy analysis operating system behavior simultaneous multithreaded architecture acm sigarch computer architecture news v28 n5 p245256 dec 2000