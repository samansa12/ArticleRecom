complete orthogonal decomposition weighted least squares paper proposes complete orthogonal decomposition cod algorithm solving weighted leastsquares problems applications weight matrix highly ill conditioned cause standard methods like qr factorization return inaccurate answers floatingpoint arithmetic stewart todd independently established norm bound weighted leastsquares problem independent weight matrix vavasis proposed definition stable solution weighted least squares based norm bound solution computed stable algorithm must satisfy accuracy bound affected ill conditioning weight matrix forward error analysis shows cod algorithm stable sense simpler efficient algorithm proposed vavasis forward error bound contrasted backward error analysis previous works weighted least squares b introduction consider solving problem min symmetric positive definite theta matrix theta n matrix nvector b mvector equivalent way write problem x b special case equilibrium system 9 applications include optimization involving barrier function finite elements structural analysis electrical networks following assumptions made throughout paper work supported nsf presidential young investigator grant matching funds received att xerox corp center applied mathematics cornell university ithaca new york 14853 z department computer science cornell university ithaca new york 14853 a1 rank n ie full column rank a2 diagonal a2 imply 1 fullrank weighted leastsquares problem unique solution allow us use norm bound obtained stewart bound given following theorem theorem 1 8 let denote set positive definite theta real diagonal matrices let mthetan real matrix rank n exist finite constants similar result obtained independently todd 10 theorem norm matrix norm induced vector norm paper similarly condition number matrix condition number 2norm ie make one assumption a3 illconditioned illconditioning arises certain classes finite element problems 11 electrical networks always occurs barrier method optimization 14 also indicates coefficient matrix leastsquares problem illconditioned reason methods typically used solve leastsquares problems give highly inaccurate solutions argued vavasis 12 since source illconditioning use definition stability given vavasis algorithm 1 stable presence finiteprecision arithmetic error bound form satisfied true solution computed solution fa function depending ffl 0 machine roundoff standard terminology modified analogously example wellconditioned matrix one upper bound condition number depend order show algorithm stable strive obtain bounds norms condition numbers errors depend present algorithm algorithm orthogonal decomposition step 1 qr factor column pivoting get q n theta n orthogonal matrix r n theta upper triangular matrix p theta permutation matrix step 2 apply reduced qr factorization without pivoting r get z 1 theta n matrix orthonormal columns u 1 n theta n upper triangular matrix step 3 solve following system via back substitution step 4 get multiply result step 3 q solution leastsquares problems via qr factorization column pivoting introduced golub 3 note qr factorization leastsquares problem occurs step 2 qr factorization step 1 make algorithm stable first compare algorithm vavasiss nsh method 12 nsh method algorithm literature known stably sense definition 1 solve 1 nsh algorithm employs nonstandard techniques particularly choosing nullspace basis contrast complete orthogonal decomposition algorithm uses standard techniques well understood namely qr decomposition back substitution also algorithm requires less work nsh algorithm nsh method requires solving theta system equation thus requires om 3 flops work qr factorizations dominates work required complete orthogonal algorithm algorithm requires omn 2 flops since could much smaller complete orthogonal decomposition algorithm requires less work rest paper devoted analysis stability orthogonal decomposition algorithm giving rigorous stability analysis algo rithm offer intuitive explanation algorithm finds accurate solution first step qr factorization matrix wellconditioned scaling columns result computed upper triangular matrix close exact upper triangular matrix would useful know something condition number matrix well minimize confusion assume without loss generality gamma12 prepivoted means columns gamma12 ordered way norms first n columns loosely speaking decreasing order addition norms first n columns larger last columns one might suspect implies entries gamma12 ordered way words inequality similar gamma12 might hold ordering becomes significant second step algorithm recall notice q upper triangular let notice also r illconditioned illconditioning arises try offset effects gamma12 following naive way let consider following dm r 1m dm clear r wellconditioned weights indeed order described difficult show upper bounds entries also shown upper bounds entries using information difficult show 12 r hence r wellconditioned scaling columns second step leastsquares problem coefficient matrix wellconditioned scaling columns namely min traditional analysis r wellconditioned scaling columns indicates standard algorithms give accurate solution analysis therefore one might expect parallel result remainder paper present rigorous stability analysis proposed algorithm next section contains discussion numerical tolerance section 3 examines condition number accuracy upper triangular matrix r computed first step algorithm section 4 u 1 upper triangular matrix computed step 2 analysis steps 3 4 algorithm presented section 5 note numerical tolerance upcoming analysis assume throughout occurrence exact linear dependence among columns always determined correctly step 1 algorithm qr factorization pivoting requires use numerical tolerance illustrate point consider applying algorithm b observe third column dependent first two qr factorization gamma12 done exact arithmetic dependence would manifested 0 3 3 position factored gamma12 first two qr factorization steps column 4 would chosen third pivot finiteprecision arithmetic however would expect 3 3 entry order machineepsilon rather 0 column 4 weighted gamma20 unwanted residual 3 position could cause column 3 chosen next column pivot instead column 4 thus without modifi cation ordinary qrfactorization column pivoting procedure missed linear dependence address problem follows kth qr factorization step check whether residual portion positions n uneliminated column become small according tolerance level respect original norm column change entries zeros notice test requires little additional work usual qr factorization algorithm column pivoting already monitors norms residual portions columns 3 way exact dependences among rows algorithm miss numerical test fails detect exact dependence stability analysis longer holds shown test proposed fail case neardependence among columns however case parameter given theorem 1 large stability bound depends practically applicable 3 first qr factorization intuitive discussion x1 asserted ordering weights produced step 1 algorithm important stabilizing algorithm necessary determine weights basis rows compare basis rows nonbasis rows begin comparing norms rows n theta n matrix whose columns arbitrary set n rows 1 form basis rowspace 1jn 1jn proof let b basis defined without loss generality suppose ka write partition b gamma1 means v n 1 cauchyschwarz inequality kvk 1ka n k also first inequality v row b gamma1 second 12 thus ie min 1jn multiply sides inequality inequality obtain 1jn 1jn required 2 notice proved lower bound column basis rowspace suppose k 0 steps factorization completed partition resulting matrix rows follows lemma 1 extended applies residual portions rows ie set n columns first k columns b fa 1 b basis suppose 1 first columns chosen column pivoting qr factorization write ff k k j k 8 proof let defined r upper triangular comparing matrix partitioned one see columns k1 prove lemma 2 need lower bound typical column b notice r therefore turn upper bound k lower bound column using previous two lemmas determine relationships weights basis rows nonbasis rows remainder paper assume intuitive discussion x1 columns gamma12 reordered pivoting necessary implies first n rows form basis rowspace also order imposed rows let denote reordered entries theorem 2 suppose first k 0 steps qr factorization completed gamma12 k1 weight assigned k1 2 b gamma12 j weight assigned j 62 b k1 provided j linearly independent first k basis vectors proof let defined lemma 2 k 0 notice matrix partioned rows since b forms basis rowspace assuming j linearly independent first k basis rows implies c means c 6 0 least one k us take notice least one let l k l c l n g basis f 8 hold basis rowspace k j k k recall columns gamma12 reordered pivoting necessary means order imposed columns gamma12 specifically since step k k j k k k1 k thus k1 k k1 k k j k k min k1in k k 9we also need know relationships weights basis rows suppose follows 7 8 implicit order indicated absence column pivoting recall intuitive argument given x1 relied weights following gamma12 found however ordered exactly way instead ordering holds scaling constant ie gamma12 gamma12 bound sufficient arguments second step algorithm performs qr factorization r order analyze step necessary know something condition r relationships weights rows used following theorem show r wellconditioned scaling rows columns recall rectangular matrix condition number 2norm ie theorem 3 let rd 12gammaa 0 1 k n proof first must find upper bound k ck since c submatrix c k therefore sufficient show upper bound kck write c follows rd q gamma12 entries c written explicitly dm r 1m dm consider basis consisting first n rows r ii ith row r kr facts 9 10 imply followinga fld recall theorem 2 thus 13 holds j linearly independent first vectors must consider case covered theorem 2 suppose b defined nonbasis row j 1 k n j linearly independent first basis vectors linearly dependent first k basis vectors c k 6 0 suppose k steps qr factorization completed ff 1i ff ki3 lemma 2 point transformations act j gives ff 1i ff ii3 telling us r entries contribute norm 13 thus 13 holds even case j linearly independent first vectors c th row c 1in 1in next step find upper bound recall easy show 1 submatrix c gammat obtain upper bound kc gammat 1 k use following fact proved current proof fact c kc gammat bound condition number thus proved claim 2 recall must still prove fact used proof state form following lemma give proof defined previous theorem kc gammat proof recall notice b rowspace basis consisting first n rows l 11 l 21 l 22 l n1 l l c th row c gammat kc gammat 1in 1in claimed 2 know r wellconditioned scaling rows wellconditioned scaling rows columns result useful later analysis standard results tell us differences columns computed r exact matrix r small since second step algorithm qr factorization r need know true rows given following theorem theorem 4 let r j j th rows r r respectively proof recall according wilkinson 13 r th column r r th column r gives us bound elementwise error namely find bound normwise error rows r namely consider kr suppose k 0 steps qr factorization completed partition x manner similar lemma 2 pivoting necessary columns x ordered k x thus taking square root sides gives required result 2 established qr factorization first step algorithm gives upper triangular matrix r wellconditioned scaling rows columns also yields computed matrix r whose rows close r results hand move analysis second step algorithm 4 second qr factorization recall step use skinny qr factorization z 1 theta n matrix orthonormal columns u 1 n theta n upper triangular matrix results x3 tell us r wellconditioned scaling columns qr factorization step gives upper triangular matrix u 1 close exact upper triangular matrix u 1 addition results x3 used prove similar results u let coefficient matrix system equations back substitution step following theorem concerning condition u 1 quite useful theorem 5 let u 1 defined u 1 proof first notice follows fact u gammat rr r e k k th column k theta k identity matrix r r z r r z 12 z k kth column z kth column r x last column r r multiplying sides gammaa gammaa z 12gammaa x show upper bound righthand side follows z 12gammaa xk r r r r r r r r rd gammaa r rd gammaa r fifth line inequality r 11 11 entry notice gamma 1 1 theorem 3 applies kd gammaa rd gammaa r kd gammaa 1in kd gammaa order find upper bound k u 1 12gammaa k u 1 kd 12gammaa u 1in kd 12gammaa u 1in kd 12 u ith column u 1 r ith column r r ith column r third line inequality derived second using 10 fact u 1 upper triangular u last line obtained applying theorem 3 thus gamma 1 1 u 1 u 1 know u 1 12gammaa wellconditioned gamma 1 1 move analysis remainder algorithm 5 finding solution analyzing remainder algorithm first show small error introduced back substitution step step 3 algorithm upper triangular system solved note slightly different system given step 3 algorithm presented x1 assuming columns gamma12 prepivoted instead working system given consider following system n working steps back substitution find solving system equivalent solving original one even floating point arithmetic words rescaling rows change numerical bounds recall last section u 1 12gammaa wellconditioned gamma 1 1 therefore standard back substitution results apply showing error step small following theorem states error bound theorem 6 let exact solution computed solution proof let computed solution system exact solution nearby system equations matrix e accounts errors back substitution jej ffl delta substituting righthand side yields e thus e e claimed 2 theorem errors computation u 1 also contribute error included could accounted somewhat larger perturbation matrix e already argued end x3 errors computing u 1 small fact errors made forming row u 1 small respect norm row therefore perturbation matrix e small respect explicitly including analysis previous theorem would make proof complicated bound would qualitatively final step obtain multiplying q let computed result assume accounts errors step previous step error bound obtained follows notice error bound form thus algorithm satisfies definition stability 6 summary open questions leastsquares problem min theta diagonal positive definite illconditioned matrix theta n fullrank matrix b nvectors unique solution illconditioning standard methods solving leastsquares problems find accurate solution attempt find standard algorithm solve problem accurately employed complete orthogonal decomposition involves four steps given x1 proceeded show algorithm stable defined x1 first step stabilizing qr factorization gives upper triangular matrix wellconditioned scaling rows columns using able show result second step upper triangular matrix also wellconditioned scaling rows columns able show bound error back substitution step easy show small error introduced last step thus algorithm gives accurate solution leastsquares problem know algorithm stable couple questions 1 algorithm implemented using dense methods many applications matrix sparse implement algorithm way takes advantage sparsity 2 results thus far theoretical algorithm yet extensively tested applications question whether algorithm effective applications currently beginning tests algorithm interior point methods 6 problem stably solving illconditioned equilibrium system barrier methods optimization received fair amount attention 2 case barrier methods linear programming interior point methods equibrium system reduces weighted least squares problem addressed paper authors recently looked illconditioning barrier methods including coleman liu 1 wright 15 wright 16 nash sofer 7 gould 5 differences works may summarized fol lows works typically look general problem minkh gamma12 aygamma bk h symmetric positive definite necessarily diagonal problem currently cannot address techniques hand authors make assumption large small entries diagonal h correlation columns corresponds nondegeneracy assumption underlying optimization problem contrast method involve restrictions large versus small entries appear thus method difficulty degeneracy neardegeneracy underlying optimization problem r interior newton method quadratic pro gramming practical optimization numerical methods solving linear least squares problems matrix computations accurate determination search directions simple differentiable penalty functions complete orthogonal decomposition interior point methods barrier method largescale constrained opti mization scaled projections pseudoinverses framework equilibrium equations dantzigwolfelike variant karmarkars interiorpoint linear programming algorithm stable finite elements problems wild coefficients stable numerical algorithms equilibrium systems algebraic eigenvalue problem interior methods constrained optimization determining subspace information hessian barrier function stability linear algebra computations interiorpoint methods linear programming tr