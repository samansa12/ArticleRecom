column approximate minimum degree ordering algorithm sparse gaussian elimination partial pivoting computes factorization sparse matrix row ordering p selected factorization using standard partial pivoting row interchanges goal select column preordering q based solely nonzero pattern limits worstcase number nonzeros factorization fillin also depends p q selected reduce upper bound fillin subsequent choice p choice q dramatic impact number nonzeros l u one scheme determining good column ordering compute symmetric ordering reduces fillin cholesky factorization ata conventional minimum degree ordering algorithm would require sparsity structure ata computed expensive terms space time since ata may much denser alternative compute q directly sparsity structure strategy used matlabs colmmd preordering algorithm new ordering algorithm colamd presented based strategy uses better ordering heuristic colamd faster computes better orderings fewer nonzeros factors matrix b introduction sparse gaussian elimination partial pivoting computes factorization sparse nonsymmetric matrix p q permutation matrices l lower triangular matrix u upper triangular matrix gilbert peierls 30 shown sparse partial pivoting implemented time proportional number point operations required method used matlab solving system linear equations sparse 27 improved implementation sparse matrix package superlu 11 solution process starts nding sparsitypreserving permutation q next permutation p selected numerical factorization using standard partial pivoting row interchanges permutation p selected without regard sparsity goal compute sparsitypreserving permutation q solely pattern lu factorization remains sparse possible regardless subsequent choice p resulting code incorporated superlu matlab version 6 section 2 provides theoretical background algorithm section 3 describe symbolic lu factorization column interchanges precursor colamd ordering algorithm presented section 4 section 4 also describes various metrics selecting columns evaluated design code experimental results square nonsymmetric matrices rectangular matrices symmetric matrices presented section 5 section 6 presents conclusions describes obtain colamd symamd codes notation follows set subtraction denoted n oper ator use jj denote either absolute value scalar number nonzero entries matrix size set usage clear context structure matrix denoted structa set contains locations nonzero entries 0g throughout paper algo rithms assume exact numerical cancellations occur entries matrix may happen become zero factorization cause accidental cancellation still refer nonzero entries let given nonsymmetric matrix assume nonsingular follows du 14 rows columns permuted diagonal entries permuted nonzero therefore assume throughout paper given matrix permuted accordingly zerofree diagonal suppose l u triangular factors obtained gaussian elimination partial pivoting applied row permutation p consider symmetric positive denite matrix cholesky factorization l c lower triangular george ng 25 showed zerofree diagonal pattern lc l includes patterns l u regardless row permutation used partial pivoting summarize result following theorem theorem 21 george ng 25 let nonsingular nonsymmetric matrix zerofree diagonal let l c denote cholesky factor let l u lu factors obtained partial pivoting structu structl entries within column l rearranged yield triangular matrix l struct gilbert ng 28 also showed bound u tight strong hall matrix theorem 22 gilbert ng 28 let nonsingular nonsymmetric matrix zerofree diagonal assume strong hall let lc denote cholesky factor let l u lu factors obtained partial pivoting choice exists assignment numerical values nonzero entries u ij 6 0 well known sparsity l c depends drastically way rows columns permuted 23 thus theorems 21 1 matrix strong hall every set k columns 1 k n 1 contain least rows strong hall matrix irreducible see coleman et al 6 details 22 suggest way reduce amount l u 25 26 given matrix rst form pattern compute symmetric ordering q reduce amount lc finally apply permutation q columns main disadvantage approach cost forming even sparse product may dense consequently time storage required form product may high primary goal paper describe ordering algorithms compute q pattern without explicitly forming 3 symbolic lu factorization column ordering technique based symbolic analysis conventional outerproduct formulation gaussian elimination nbyn matrix row interchanges maintain numerical stability let denote bottom right n kbyn submatrix k 1 gaussian elimination performed assume rows columns k labeled k 1 n kth step gaussian elimination one nds entry largest magnitude column k k 1 swaps rows place entry diagonal column k l scaled version column k k 1 row k u row k k 1 outer product column k l row k u subtracted k 1 give k result factorization permutation matrix determined row interchanges sparse update using outer product may turn zero entries nonzero new nonzero entries referred llin amount llin occurs depends order columns eliminated 23 goal therefore nd column ordering q matrix prior numerical factorization lu factorization columnpermuted matrix aq sparser lu factorization original matrix regardless p chosen another application column orderings sparse qr factorization 33 order control llin occurs sparse need know nonzero patterns matrices k k 0 n 1 determine column ordering q attempts keep factorization aq sparse factorization progresses must compute symbolic patterns l u k account possible row interchanges may occur numerical factorization actual structures l u k factorization pa specic row permutation p subsets patterns let l k u k denote nonzero patterns column k l row k u respectively k let r k denote set column indices nonzero entries row k r k similarly j k let c k denote set row indices nonzero entries column j k note denitions imply 1 k j describe compute l k u k k order increasing k begin using assumption zerofree diagonal easy see pattern kth column l simply column k k 1 may take regardless nonzero numerical values interchanged consider possible nonzero pattern kth row u partial pivoting row selected pivot row k 1 ik nonzero means potential candidate pivot rows correspond set l k pattern kth pivot row bounded union candidate pivot rows 26 may take arbitrary row r 2 l k selected pivot row r k 1 2 l k u k accommodate row interchanges due numerical partial pivoting outer product step multiples pivot row added row pivot column pattern row matrix k outer product step must contained set u k n fkg since know row pivot row bound pattern row k r k note rows l k n fkg pattern save time space storing step modies one rows modify rows nonzero pattern let fkg step p l k n fkg l p r p nfkg thus step k replace rows single superrow r k r represents pattern rows set l k nfkg integer r arbitrary placeholder symbolic factorization algorithm choose arbitrary row index set c k 1 dene r set rows size jrj represented superrow r symbolic factorization starts every row belongs exactly one set ie frg compute symbolic update need place single representative r set c k remove discarded rows l k n frg sherman 43 introduced concept supercolumns context sparse cholesky factorization simplications step k sets r c represent bound pattern k lu factorization also quotient graph representation 17 21 matrix obtained kth step cholesky factorization column preordering method require patterns l u discarded result algorithm shown figure 1 requires ojaj space superscripts r c dropped clarity initial storage required ojaj step k r r computed r r r ia n fkg 2 sets r c k n frg discarded outer product formed column c j j 2 r r reduces size stays 2 implies 9i 2 c k j 2 r symbolic lu factorization algorithm n determine pattern pivot row column let r arbitrary index c k outer product update end end end figure 1 symbolic lu factorization algorithm implies j thus step strictly reduces total storage required pattern k total time taken dominated symbolic update computing pivot rows r r entire algorithm takes total oju j time since fkg pattern odiagonal part row k u since r r discarded included set union subsequent pivot row modifying single column c j symbolic update takes oja j j time since jc j j ja j j column j modied row u k contains column index j thus column j modied ju j j times entire algorithm u j upper bound pattern column j matrix u row permutation p due partial pivoting thus total time taken nonzero pattern u accommodate row permutation p due partial pivoting time required compute sparse matrix product au typically much less time required numerical factorization equal time required compute sparse matrix product l times u 31 faster methods exist compute upper bound symbolic factorization partial pivoting george ngs method 26 computing patterns l u takes ojlj column ordering xed method produce nonzero patterns k however cannot used basis colamd algorithm described next section 4 colamd ordering algorithm present column ordering method based symbolic lu factorization algorithm presented last section time complexity storage requirements step k select pivot column c minimize metric candidate pivot columns attempt reduce llin columns c k exchanged presence dense nearly dense rows columns greatly aect ordering quality run time single dense row renders bounds useless bound nonzero pattern 1 completely dense matrix hope dense row selected rst pivot row numerical factorization withhold row ordering algorithm dense columns aect ordering quality increase ordering time single dense column increases ordering time 2 dense columns withheld symbolic factorization ordering algorithm placed last column ordering q determining dense row column ignored problem dependent used default threshold used matlab 50 probably high matrices taking advantage supercolumns greatly reduce ordering time symbolic update step look columns j set r r two columns pattern tested via hash function 2 merged single supercolumn saves time storage subsequent steps selecting supercolumn c allows us masseliminate 24 columns c represented supercolumn c skip ahead step symbolic factorization pattern column supercolumn becomes pivot column pattern c update eliminated immediately since columns c represented supercolumn keep nonzero pattern eliminated need maintain degree column selection metric representative column c superrows size set c j diers sum numbers rows represented superrows set c j similarly jr j number supercolumns row number columns represented supercolumns r let kr k denote sum numbers rows represented supercolumns j r similarly dene kc j k similarly jc superrows necessity choice pivot column c heuristic since obtaining ordering minimum llin npcomplete problem 45 several strategies possible selects column c minimizes metric described methods need compute initial metric column prior symbolic factorization ordering recompute metric column j pivot row pattern r r step k 1 exact external row degree select c minimize size resulting pivot row r ia n fcg exclude pivot column thus computing external row degree 37 exact degree expensive compute time dominate symbolic factorization time experience symmetric orderings exact degrees provide better orderings good approximate degrees ordering methods amdbar mc47bd 1 thus test method 2 matlab approximate external row degree colmmd column ordering algorithm matlab based symbolic lu factorization algorithm presented section 3 27 colmmd selects pivot column c minimizes loose upper bound external row degree note c 2 r kr n jcj using bound symbolic update increase asymptotic time complexity ordering algorithm symbolic lu factorization algorithm computing matlab metric initial columns fast taking ojaj time 3 amd approximate external row degree amd algorithm ordering symmetric matrices prior cholesky factorization based bound external row degree tighter matlab bound 1 rst used nonsymmetric pattern multifrontal method umfpack compute ordering numerical factorization 8 9 context column ordering algorithm bound llin sparse partial pivoting method bound kr r k r recent pivot row modied c c symbolic update thus 2 c c compute amd metric initial columns select arbitrary 2 c c compute bound column c computing initial amd metric takes amount time takes compute sparse matrix product aa although costly increase asymptotic time algorithm time compute bound symbolic update phase asymptotically computing matlab bound 4 size householder update symbolic lu factorization also computes pattern r qr factorization 6 32 step k size householder update kc k kbykr r k term kc k k known exactly kr r k term computed approximated using methods method tested selected c minimize product kc c k amd approximation kr r k 3 tested discarded method since gave much worse orderings methods 5 approximate markowitz criterion markowitz heuristic selects pivot entry ij minimizes product degrees row column j amount work required subsequent outer product step 38 criterion assumes rst k 1 pivot rows columns selected case know exact pivot row ordering yet know true row column degrees tests selected c minimize kc c k times max i2cc kr k tighter upper bound actual pivot row degree column c selected kth pivot column row selected kth pivot row although r bound pattern r r kth pivot row arbitrary row partial bound size actual pivot row row ordering selected since kc c k kr k known exactly approximations need used tested discarded method since gave much worse orderings methods 6 approximate deciency deciency pivot number new nonzero entries would created pivot selected selecting pivot least deciency leads minimum deciency ordering algorithm exact deciency costly compute approximate minimum deciency ordering algorithms successfully used symmetric matrices context cholesky factorization 40 42 nonsymmetric context deciency column c bounded new nonzeros limited kc c kbykr r k householder date superrow however contained submatrix thus reduces possible llin number nonzeros repre sents kc c k kr k terms known exactly used amd approximation kr r k 3 tested one variant approximate deciency 35 36 initialization phase computes approximate deciency columns approximate deciency recomputed time column mod ied aggressive row absorption used discussed since worsens approximation experimental results mixed compared nal colamd variant approximate deciency better 60 matrices large test suite worse colamd sometimes much worse vice versa byproduct amd row degree computation compute sizes set dierences kr n r r k superrow r bound pivot row step k rows remaining matrix nd set dierence zero r subset row r r presence row aect exact row degree although aect matlab amd approximations row deleted absorbed r refer deletion r r r aggressive row absorption similar element absorption introduced du reid 17 amd row degrees computed initial metric initial aggressive row absorption occur phase well aggressive row absorption reduces run time since costs almost nothing detect condition amd metric used results fewer rows consider subsequent steps tested sixteen variants colamd based possible combinations following design decisions 1 initial metric matlab amd approximation 2 metric computed symbolic outer product update matlab amd approximation 3 without initial aggressive row absorption 4 without aggressive row absorption symbolic factorization note combinations somewhat costly since aggressive row absorption easy using amd row degrees dicult using matlab approximation since amd metric shown superior matlab approximation context minimum degree orderings sparse cholesky factorization 1 expected four variants based solely amd metric superior much intend test sixteen methods surprise found better orderings obtained initial matlab metric amd metric symbolic update discovered accident bug initial computation amd metric resulted matlab approximation computed instead bug gave us better orderings kept using initial matlab metric gave average orderings 8 fewer oatingpoint operations subsequent numerical factorization using initial amd metric initial matlab metric also faster compute version ordering algorithm recommend simply call colamd uses initial matlab metric amd metric symbolic update initial aggressive row absorption aggressive row absorption symbolic update since amd metric incompatible incomplete degree update 18 19 multiple elimination 37 uses neither strategy multiple elimination set pivotal columns selected symbolic update column set aect columns set selection set reduces number symbolic updates must performed matlabs colmmd ordering algorithm uses matlab metric throughout multiple elimination relaxed threshold superrows supercolumns mass elimination aggressive row absorption aggressive row absorption free colamd instead explicit test made every three stages multiple elimination supercolumns searched every three stages default rows 50 dense ignored since matlab metric lead lower quality orderings exact metric options provided selecting exact external row degree metric modifying multiple elimination threshold changing frequency supercolumn detection aggressive row absorption changing dense row threshold selecting spparms tight matlab improves ordering computed colmmd high cost ordering time 5 experimental results tested colamd ordering algorithm three sets matrices square nonsymmetric matrices rectangular matrices symmetric positive de nite matrices test set entire university florida sparse matrix collection 7 includes harwellboeing test set 15 16 linear programming problems netlib httpwwwnetliborg 13 well many matrices exclude complex matrices nonsymmetric matrices pattern provided unassembled nite element trices matrices include explicit zero entries description pattern since ignore numerical cancellation included entries nding ordering determining resulting factorization method compared ordering time quality number nonzeros factors number oatingpoint operations compute factor ization although tested matrices collection present summary larger problems best ordering resulted factorization requiring 10 7 operations com pute complete results presented larimores thesis 36 available technical report httpwwwciseufledu performed experiments sun ultra enterprise 40005000 2 gb main memory eight 248 mhz ultrasparcii processors one processor used code written ansiiso c compiled using solaris c compiler via mathworks mex shell script interfacing matlab software written c strict ansiiso compliance 51 square nonsymmetric matrices square nonsymmetric matrices used colamd nd column preordering q sparse partial pivoting results compared colmmd default option settings amdbar 1 applied pattern ignoring numerical cancellation withholding dense rows columns ignored colamd colmmd amdbar routine mc47bd harwell subroutine library except perform aggressive row absorption amdbar mc47bd use amdstyle approximate degree sparse partial pivoting matrices test set amdbar provides slightly better orderings mc47bd nding column ordering factorized matrix aq superlu package 11 package chosen since colamd written replace column ordering current version superlu superlu based blas 12 2 excluded matrices permuted upper block triangular form 14 substantial improvement factorization time two rea sons 1 bounds tight matrix strong hall 2 superlu take advantage reducibility block upper triangular form matrices factorized ordering factorizing irreducible diagonal submatrix permuting matrix block triangular form resulting test set 106 matrices requiring operations factorize representative sample shown table 1 sorted according colamd versus colmmd ordering quality 3 table 2 reports ordering time colamd used blas routines provided superlu factorization time secondary measure diculty using sunoptimized blas matlabcallable driver 3 obtain sample sorted 106 matrices according relative point operation count colamd ordering colmmd ordering selected every 8th matrix also included twotone matrix largest dimension test set table 1 unsymmetric matrices matrix n nnz description goodwin 7320 324784 niteelement uid dynamics navierstokes elliptic mesh r goodwin raefsky2 3242 294276 incompressible ow pressuredriven pipe raefsky twotone 120750 1224224 frequencydomain analysis nonlinear analog circuit 20 computational uid dynamics cfd charleston harbor steve bova lhr17c 17576 381975 light hydrocarbon recovery problem 47 exchanger ow redistribution averous rdist3a 2398 61896 chemical process separation 46 garon2 13535 390607 2d niteelement navierstokes garon twophase uid ow graham cavity25 4562 138187 driven cavity niteelement chapman ex20 2203 69981 2d attenuation surface disturbance nonlinear cfd saad wang1 2903 19093 electron continuity 3d diode 39 ex14 3251 66775 2d isothermal seepage ow saad ex40 7740 458012 3d die swell problem square die computational uid dynamics saad colmmd amdbar time compute pattern included amdbar time comparison last column reports superlu factorization time using colamd ordering table 3 gives resulting number nonzeros l u oatingpoint operations required factorize permuted matrix ordering methods median results reported paper representative samples full test sets results samples full test sets similar colamd superior methods matrices colamd typically 39 times faster colmmd 21 times faster amdbar two matrices colmmd took time order matrix superlu took factorize orderings found colmmd result median increase table 2 ordering factorization time seconds matrix colamd colmmd amdbar superlu goodwin 031 042 151 4465 raefsky2 111 158 211 6236 twotone 588 7082 1415 30685 lhr17c 162 1522 308 580 ex40 234 1358 261 2721 median time relative 39 21 371 table 3 ordering quality factorized superlu nonzeros l u matrix colamd colmmd amdbar colamd colmmd amdbar goodwin 5634 3103 2734 1909 665 498 twotone ex20 483 589 464 48 86 50 ex14 711 1012 885 91 214 157 ex40 4315 8537 6072 1075 5369 2606 median result relative 110 099 136 105 10 nonzeros lu factors 36 oatingpoint operations compared colamd ordering quality colamd amdbar similar although large variations directions small number matrices matrices larger test set table 1 amdbar requires space store superlu requires factorize permuted matrix 52 rectangular matrices mbyn rectangular matrices n found column ordering q cholesky factorization aq aq one method solving least squares problem n found row ordering p cholesky factorization pad 2 pa arises interior point methods solving linear programming problems 34 44 diagonal matrix latter case colamd colmmd found column ordering used row ordering p compared two methods amdbar corresponding matrix n test set limited included 37 matrices requiring three netlib linear programming problems n representative selection 4 shown table 4 compared three methods based ordering time number nonzeros factor l oatingpoint operation count required cholesky factorization metrics obtained symbfact matlab fast symbolic factorization 22 23 29 perform numerical cholesky factorization time construct aa included ordering time amdbar results shown tables 5 6 matrices colamd twice fast colmmd slightly faster amdbar three produced comparable orderings method matrices well poorly colamd colmmd typically require less storage amdbar sometimes several orders magnitude need compute pattern aa prior ordering amdbar size cholesky factors always dominates size aa however primary advantage colamd 4 every 5th matrix 37 large matrices increasing order colamd versus colmmd ordering quality chosen table 4 rectangular matrices linear programming problems gran 2629 2525 20111 60511 british petroleum operations lower bound quadratic assignment problem 41 tting linear inequalities data min sum piecewiselinear penalties r fourer pds 20 33874 108175 232647 320196 military airlift operations 5 d2q06c 2171 5831 33081 56153 j tomlin table 5 ordering time seconds matrix colamd colmmd amdbar gran 004 007 006 pds 20 386 1053 392 median time relative 200 114 colamd table ordering quality nonzeros l 10 3 flop count 10 6 matrix colamd colmmd amdbar colamd colmmd amdbar gran 191 158 143 48 33 27 pds 20 6827 8159 6929 8598 12640 8812 median result relative 100 099 102 098 colamd colmmd amdbar context ability analyze cholesky factorization nding ordering size resulting factor l space proportional number nonzeros matrix rather proportional size matrix factorized 53 symmetric matrices symmetric matrices matlabs symmmd routine constructs matrix pattern nds column ordering using colmmd one row entry ij diagonal nonzero entries column j method gives reasonable ordering cholesky factorization implemented analogous symamd routine based colamd test set included 50 matrices requiring 10 7 operations factorize largest computational uid dynamics problem ed rothberg requiring 136 billion operations factorize cfd2 sample test matrices 5 shown table 7 results symamd symmmd amdbar mc47bd shown tables 8 9 time construct included ordering time symamd symmmd 9 matrices symamd six times faster symmmd 5 every 7th matrix order increasing ratio symamd symmmd ordering quality chosen table 7 symmetric matrices matrix n nnz description pwt 36519 326107 pressurized wind tunnel r grimes msc00726 726 34518 symmetric test matrix mscnastran bcsstk38 8032 355460 stiness matrix airplane engine component r grimes engineering problem nasa langley cfd2 123440 3087898 computational uid dynamics e rothberg 3dtube pressure tube e rothberg gearbox 153746 9080404 zf aircraft ap actuator e rothberg finan512 74752 596992 portfolio optimization 4 table 8 ordering time seconds matrix symamd symmmd amdbar mc47bd pwt 078 353 045 044 msc00726 cfd2 736 4868 390 371 3dtube 609 7775 095 092 gearbox 1658 45449 294 289 finan512 160 261 092 095 median time relative 613 039 039 symamd table 9 ordering quality nonzeros l 10 3 op count 10 6 matrix symamd symmmd amdbar mc47bd symamd symmmd amdbar mc47bd pwt 1497 1425 1592 1556 156 140 173 162 msc00726 103 108 111 111 20 22 23 23 cfd2 74832 94444 75008 75008 137470 211328 136476 136476 3dtube 26128 33213 26355 26355 29969 45578 30053 30053 median result relative 126 103 103 152 108 104 colamd average nearly always produced signicantly better orderings con trast symamd always slower amdbar mc47bd although found orderings similar quality finan512 notable exception none methods nds good ordering tree dissection method 4 ordering algorithm designed symmetric matrices amdbar mc47bd thus superior one based column ordering may least one important exception however applications better matrix available consider nbyn nite element matrix constructed summation e nite elements normally e n nite element matrix dense symmetric submatrix suppose element k nonzero entries ij j set e k construct ebyn matrix row k pattern e k since pattern compute column ordering use cholesky factorization colamd would faster using constructed without knowledge nite element structure space perform ordering symbolic analysis less well since fewer nonzeros although many matrices test set arise nite element problems small ones available unassembled form collection nite elements thus able evaluate strategy large realistic test matrices 6 summary two new ordering routines colamd symamd presented square nonsymmetric matrices colamd much faster provides better orderings matlabs colmmd routine also faster symmetricbased ordering methods amdbar uses less storage rectangular matrices arising least squares problems interior point methods linear programming colamd faster colmmd amdbar nds orderings comparable quality presented symmetric ordering method symamd based colamd although produces orderings good truly symmetric ordering algorithm amdbar slower amdbar colamd symamd routines written ansiiso c matlab callable interfaces version 20 code freely available following sources 1 university florida httpwwwciseufleduresearchsparse 2 netlib httpwwwnetliborglinalgcolamd 3 mathworks inc usercontributed contributions matlab httpwwwmathworkscom colamd symamd builtin functions matlab version 60 4 collected algorithms acm algorithm 8xx described 10 r compressed graphs minimum degree algorithm test collection nonhermitian eigenvalue problems solving multistage stochastic programs using tree dissection univ florida sparse matrix collection algorithm 8xx colamd supernodal approach sparse partial pivoting distribution mathematical software via electronic mail yale sparse matrix package algorithms data structures sparse symmetric gaussian elimination fast implementation minimum degree algorithm using quotient graphs optimal algorithm symbolic factorization symmetric matrices computer solution large sparse positive de application minimum degree algorithm implementation gaussian elimination partial pivoting sparse systems symbolic factorization sparse gaussian elimination partial pivoting sparse matrices matlab design implementation predicting structure nonsymmetric sparse matrix factorizations sparse partial pivoting time proportional arithmetic operations two fast algorithms sparse matrices multiplication permuted transposition finding good column orderings sparse qr factorization new polynomial time algorithm linear program ming approximate de approximate minimum degree column ordering algo rithm elimination form inverse application linear programming exponentially performance greedy ordering heuristics sparse cholesky factorization resende ramakrishnan drezner node selection strategies bottomup sparse matrix orderings e computing minimum sparse matrix methods chemical process separation calculations supercomputers multifrontal vs frontal techniques chemical process simulation supercomput ers tr new polynomialtime algorithm linear programming predicting fill sparse orthogonal factorization distribution mathematical software via electronic mail symbolic factorization sparse gaussian elimination partial pivoting sparse matrix test problems set level 3 basic linear algebra subprograms empirical evaluation korbx algorithms military airlift applications generalized envelope method sparse factorization rows sparse matrices matlab sparse matrix methods chemical process separation calculations supercomputers sparsity analysis italicqritalic factorization efficient algorithm compute row column counts sparse cholesky factorization modification minimumdegree algorithm multiple elimination compressed graphs minimum degree algorithm approximate minimum degree ordering algorithm unsymmetricpattern multifrontal method sparse lu factorization combined unifrontalmultifrontal method unsymmetric sparse matrices node selection strategies bottomup sparse matrix ordering supernodal approach sparse partial pivoting performance greedy ordering heuristics sparse cholesky factorization two fast algorithms sparse matrices multiplication permuted transposition algorithms obtaining maximum transversal multifrontal solution indefinite sparse symmetric linear computer solution large sparse positive definite algorithm 836 algorithm 837 ctr timothy davis john r gilbert stefan larimore esmond g ng algorithm 836 colamd column approximate minimum degree ordering algorithm acm transactions mathematical software toms v30 n3 p377380 september 2004 patrick r amestoy enseeihtirit timothy davis iain duff algorithm 837 amd approximate minimum degree ordering algorithm acm transactions mathematical software toms v30 n3 p381388 september 2004 marco morandini paolo mantegazza using dense storage solve small sparse linear systems acm transactions mathematical software toms v33 n1 p5es march 2007 kai shen parallel sparse lu factorization different message passing platforms journal parallel distributed computing v66 n11 p13871403 november 2006 xiaoye li overview superlu algorithms implementation user interface acm transactions mathematical software toms v31 n3 p302325 september 2005 frank dellaert michael kaess square root sam simultaneous localization mapping via square root information smoothing international journal robotics research v25 n12 p11811203 december 2006 nicholas gould jennifer scott yifan hu numerical evaluation sparse direct solvers solution large sparse symmetric linear systems equations acm transactions mathematical software toms v33 n2 p10es june 2007 doron chen daniel cohenor olga sorkine sivan toledo algebraic analysis highpass quantization acm transactions graphics tog v24 n4 p12591282 october 2005 timothy davis column preordering strategy unsymmetricpattern multifrontal method acm transactions mathematical software toms v30 n2 p165195 june 2004