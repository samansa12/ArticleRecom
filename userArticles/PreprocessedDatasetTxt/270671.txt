krylov subspace approximations matrix exponential operator krylov subspace methods approximating action matrix exponentials analyzed paper derive error bounds via functional calculus arnoldi lanczos methods reduces study krylov subspace approximations functions matrices linear systems equations side result obtain error bounds galerkintype krylov methods linear equations namely biconjugate gradient method full orthogonalization method krylov approximations matrix exponentials show superlinear error decay relatively small iteration numbers onwards depending geometry numerical range spectrum pseudospectrum convergence exptau av faster corresponding krylov methods solution linear equations itau axv usually arise numerical solution stiff ordinary differential equations odes therefore propose new class time integration methods large systems nonlinear differential equations use krylov approximations exponential function jacobian instead solving linear nonlinear systems equations every time step b introduction article study krylov subspace methods approximation expav matrix large dimension v given vector scaling factor may associated step size time integration method krylov approximations apparently first used chemical physics 20 22 17 recently studied gallopoulos saad 10 24 see also account related previous work present krylov schemes exponential propagation discuss implementation report excellent numerical results give theoretical error bounds also mention bounds however pessimistic explain numerically observed error reductions moreover error bounds make evident krylov methods perform far better standard explicit time stepping methods stiff problems open question concerns relationship convergence properties krylov subspace methods exponential operators linear systems equations arising implicit time integration methods present paper intend clear error behavior wrote paper unaware important previous work druskin knizhnerman 3 4 14 15 use different approach analysis comment relationship results note end paper error analysis based functional calculus arnoldi lanczos methods reduces study approximations expav corresponding iterative methods linear systems equations somewhat oversimplified may said error mth iterate expav behaves like minimum mathematisches institut universitt tubingen auf der morgenstelle 10 d72076 tubingen germany email marlisnaunituebingende lubichnaunituebingende taken ff 0 e ff multiplied error mth iterate solution krylov subspace method minimum usually attained far especially large iteration numbers unless good preconditioner gamma available iteration expav converges therefore faster v know however way precondition iteration expav gallopoulos saad showed error mth iterate approximation expav bound proportional kak gives superlinear convergence ae kak many cases however superlinear error decay begins much smaller iteration numbers example show symmetric negative definite matrices occurs already kak whereas skewhermitian matrices uniformly distributed eigenvalues substantial error reduction begins general near kak obtain rapid error decay kak also class sectorial nonnormal matrices convergence within required tolerance ensures methods become superior standard explicit time stepping methods large systems kak error bounds improve upon 10 24 typically factor 2 gammam e gammack c 0 analysis explains error depends geometry critical sets complex plane namely numerical range arnoldibased approximations location spectra pseudospectra krylovgalerkin matrix hm lanczos arnoldibased approximations framework also easily seen clustering eigenvalues similar beneficial effects krylov subspace approximation expav iterative solution linear systems equations mentioned expav often computed faster krylov subspace methods fact implications time integration large systems ordinary differential equations arising eg manyparticle simulations spatial discretizations timedependent partial differential equations justifies renewed interest ode methods use exponential related functions jacobian instead solving linear nonlinear systems equations every time step methods type literature include exponential rungekutta methods lawson 18 friedli 8 adaptive rungekutta methods strehmel weiner 27 nonapproximated form exponentially fitted methods 5 exponential multistep methods 9 last section paper propose promising new class exponen tial integration methods krylov approximations substantial savings expected large moderately stiff systems ordinary differential equations routinely solved explicit timestepping methods despite stability restrictions step size implicit methods require prohibitively expensive jacobians linear algebra paper organized follows section 2 describe general framework derive basic error bound arnoldi method section 3 leads specific error bounds approximation expav various classes matrices lanczos methods studied section 4 contains also error bounds bicg fom section 5 introduce class timestepping methods large systems odes replace solution linear systems equations multiplication whose krylov subspace approximations converge fast expav throughout paper k delta k euclidean norm induced matrix norm 2 arnoldibased approximation functions matrices sequel let complex square matrix large dimension n v 2 c n given vector unit length 1 arnoldi process generates orthonormal basis krylov space matrix hm dimension upper left part successor hm1 e ith unit vector r induction clearly implies noted 3 theorem 2 24 lemma 31 standard use arnoldi process solution linear equations 23 one approximates eigenvalue hopefully hm latter condition always satisfied outside numerical range since 21 implies avm therefore turn approximation functions let f analytic neighborhood fa z gamma contour surrounds fa view 23 led replace z approximate approximation proposed previously 22 33 3 10 different derivations practice left task computing lowerdimensional expression fhm e 1 n usually much easier compute fav eg diagonalization hm derivation 27 also indicates obtain error bounds study error arnoldi approximation 23 linear systems integrate error bounds multiplied jfj varying along suitable contour gamma actually done present paper error bounds based lemma 1 prepare setting let e convex closed bounded set complex plane let oe conformal mapping carries exterior e onto exterior unit circle fjwj 1g note ae logarithmic capacity e finally let gamma boundary curve piecewise smooth bounded region g contains e assume f analytic g continuous closure g lemma 1 assumptions numerical range contained e every polynomial q mgamma1 degree z length boundary curve e e ds minimal distance fa subset complex plane e straight line segment disk 28 holds remark useful choose integration contour dependent order balance decay oe gammam away e growth f outside e functions f exponential function studied detail ultimately yield superlinear convergence hand liberty choosing polynomial q mgamma1 materialize study exponential function proof begin studying error 23 consider fixed moment argumentation part proof inspired 25 using v rewrite error 21 orthogonality hence arbitrary note polynomial degree conversely every av form bound delta recall kvm use estimates ki follow 26 thm41 24 thus obtain every polynomial p degree b remains bound p since z special case e line segment form hermitian b complex coefficients ff fi e disk jz gamma j ae p z chosen multiple z inequality berger see 1 p 3 tells us cases thus stated lemma 1 c proceed proof use nearoptimality properties faber polynomials employed previously analyses iterative methods eiermann 6 nevanlinna 21 let oe z denote faber polynomial degree associated region e defined polynomial part oez ie 1 choose polynomial p z normalization cf 21 p76 theorem kovari pommerenke 16 thm2 provides us bound implies max z2e joe combining inequalities 210211 214 gives us proof completed inserting bound difference formulas 25 26 taking account 22 remark part c proof combined cauchys integral formula shows exists polynomial pi mgamma1 z degree gamma 1 z ffi minimal distance gamma e holds pi r 212 polynomial approximation bounds type closely tied bernsteins theorem 19 thmiii319 3 approximation matrix exponential operator section give error bounds arnoldi approximation e v various classes matrices may restrict attention cases numerical range contained left halfplane ke k view 24 also bounded unity assumption entails loss generality since shift changes e v approximation factor e ff bounds theorems 2 6 even slightly favorable valid also krylov subspace approximations av theorem 2 let hermitian negative semidefinite matrix eigenvalues interval gamma4ae 0 error arnoldi approximation e v ie bounded following ways remark instructive compare error bounds conjugate gradient method applied linear system given bound becomes small ae p ae linear decay proof use lemma 1 conformal mapping start applying linear transformation interval gamma1 1 contour gamma choose parabola rightmost point fl mapped parabola pi given parametrization parabola osculates ellipse e foci sigma1 major us error bound z z phi 1 absolute value phi constant along every ellipse foci sigma1 since parabola pi located outside ellipse e along pi hence obtain 33 z 1e gammaae 2 fig 31 errors error bounds symmetric example moreover r e ff 2ffl ff 096 ffl 12 ff 098 ffl 14 minimizing e 2ae fflgammam 2ffl respect ffl yields inserting ffl 34 results bound together 2 sharper version 31 condition ffl 12 equivalent 2ae obtain bound 32 note 1 insert 34 close minimum ae ae yields 2ae sharper version 32 finally remark view proof theorem 3 bounds 31 32 also obtained gamma chosen composition part parabola contained right halfplane two rays imaginary axis give illustration error bounds consider diagonal matrix equidistantly spaced eigenvalues interval gamma40 0 random unit vector v dimension 1001 fig 31 shows errors approximation expav cg approximation nearly straight line moreover dashed line shows error bounds 35 36 dotted line corresponds 2k 1 error bound 24 corollary 46 symmetric negative semidefinite matrices well known krylov subspace methods solution linear systems equations benefit clustering eigenvalues true also krylov subspace approximation e v actually surprising view cauchy integral representations 25 26 example result state following theorem might generalized various directions different types clusterings different types matrices pursue theorem 3 let hermitian negative semidefinite matrix eigenvalues contained f 1 gamma4ae 1st error m1 arnoldi approximation e v bounded righthand sides 31 32 proof result proved using polynomial instead 212 absolute value first factor bounded unity z 2 gamma4ae 0 0 hence obtain error bounds theorem 2 replaced gamma 1 skewhermitian matrices uniformly distributed eigenvalues cannot show superlinear error decay ae reason basically conformal mapping oe maps vertical line contour joej symmetric negative definite case joej ffl behavior affects equally convergence krylov subspace methods solution linear systems v skewhermitian general substantial error reduction ae convergence linear rate like theorem 4 let skewhermitian matrix eigenvalues interval imaginary axis length 4ae error arnoldi approximation e v bounded proof use lemma 1 conformal mapping applying linear transformation choose integration contour ellipse foci sigma1 minor semiaxis semiaxis length contour bounded 2a addition 1 absolute value constant along ellipse lemma 1 get error fig 32 errors error bounds skewhermitian example inserting gives stated error bound sharper bound ae 1 2 obtained integrating parabola osculates ellipse rightmost point reads numerical illustration choose diagonal matrix 1001 equidistant eigenvalues gamma20i 20i random vector v unit length fig 32 shows errors approximation expav bicg approximation nearly straight line dashed line shows error bound 37 dotted line corresponds bound given 10 corollary 22 theorem 5 let matrix numerical range contained disk jz error arnoldi approximation e v bounded proof use lemma 1 circle radius rae centered gammaae lemma 1 gives bound setting gives stated result following worstcase example shows nearly error reduction ae example let bidiagonal matrix dimension n gamma1 diagonal 1 subdiagonal numerical range contained disk arnoldi process gives mdimensional version error vector thus contains entries e gamma k k k largest close 2 gamma12 stirlings similar theorem 2 onset superlinear convergence begins already ae fa contained wedgeshaped set particular consider conformal mapping maps exterior unit disk onto exterior bounded sectorial set left halfplane corner 0 opening angle symmetric respect real axis theorem 6 ae 0 let numerical range contained ae delta error arnoldi approximation e v bounded ae 1gamma constants c c 0 depend proof course proof c denotes generic constant takes different values different occurrences transformation ae use choose ffi r1 note ae rightmost point integration contour ae hence ae ae ff righthand side minimized near inserting ffl gives 38 ff ff r 2 ffi 0 lemma 1 gives e rae becomes 39 upon choosing 4 lanczosbased approximation functions matrices arnoldi method unfortunately requires long recurrences construction krylov basis lanczos method overcomes difficulty computing auxiliary basis spans krylov subspace respect w 1 lanczos vectors v j w j constructed satisfy biorthogonality condition block biorthogonality case lookahead version 7 28 ie dm vm block diagonal lookahead process ensures dm well conditioned index terminates block assumed sequel lanczos vectors constructed short mostly threeterm recurrences results matrix representation 21 block tridiagonal avm however unlike arnoldi case neither vm wm orthogonal matrices usual scale lanczos vectors unit norm case norms vm wm bounded p since hm oblique projection numerical range hm general contained fa variants lemma 1 apply situation given following two lemmas exponential function lemmas 7 8 lead essentially error bounds given arnoldi method theorems 5 6 except different constants theorems 2 3 4 arnoldi lanczos approximations coincide first lemma works fflpseudospectrum 32 defined otherwise setting one described lemma 1 lemma 7 error lanczos approximation fav bounded 28 proof proof modifies proof lemma 1 lanczos process therefore noting v thus obtain every polynomial p degree 1 assumption norms bounded fl gamma1 2 gamma using kp ak e2ffl delta max z2e jp zj leads 4 turn yields estimate stated lemma diagonalizable matrix let x matrix contains eigenvectors columns following lemma involves spectrum uses setting lemma 1 lemma 8 let diagonalizable assume ae e h gamma lanczos approximation fav satisfies 28 ffi minimal distance gamma proof result follows 41 along lines parts c proof lemma 1 remarks known generic situations extreme eigenvalues well approximated hm sufficiently large 34 contour gamma bounded away one thus expect usually ki uniformly bounded along gamma b lemmas 7 8 apply also arnoldi method kvm c convexity assumption e removed price larger factor e continuum containing one point one use instead inequality 213 estimate lemma pp 107f volume iii 19 proofs lemmas 1 7 8 provide error bounds iterative methods solution linear systems equations whose iterates defined galerkin condition 23 gives new error bounds biconjugate gradient method krylov basis constructed via lanczos process full orthogonalization method based arnoldi process proofs extended give similar error bounds also quasi minimization methods qmr gmres see 13 5 class integration methods large systems odes numerical integration large stiff systems ordinary differential equations fy krylov subspace methods used successfully solution linear systems equations arising fully linearly implicit integration schemes 11 2 25 linear systems form jacobian f evaluated near current integration point h step size fl method parameter attraction krylov subspace methods lies fact require computation matrixvector products aw convenient approximated directional derivatives aw jacobian need never formed explicitly theoretical results well computational experiments indicate krylov subspace approximations e flha v flhav converge faster corresponding iterations v least unless good preconditioner hand suggests use following class integration schemes linear systems arising linearly implicit method rosenbrockwanner type replaced multiplication flha starting 0 yt 0 scheme computes approximation 1 coefficients determine method internal stages computed one one multiplication flha function evaluation stage simplest method type wellknown exponentially fitted euler method order 2 exact linear differential equations b appears well suited basis richardson extrapolation another example method theorem 9 twostage methods coefficients eter order 3 arbitrary step sizes provide exact solution every linear system differential equations constant matrix constant inhomogeneity b proof taylor expansion h exact numerical solutions shows order conditions order 3 correspond elementary differentials given sums extend 1 set ff cf order conditions rosenbrock methods 12 p116 differ present order conditions righthand side polynomials fl righthand side last order condition vanishes hence condition automatically satisfied every twostage method ff remaining three equations yield stated method coefficients direct calculation shows method applied claimed property remarks 34 method satisfies order condition fi 2 ff 3 corresponds fourthorder elementary differential f 000 f f f order conditions corresponding f satisfied independently ff order condition corresponding f 00 f f 0 f fourthorder condition remains violated b nonautonomous problems useful rewrite equation autonomous form adding trivial equation taking jacobian e particular method exact every linear equation form tc since rewritten c linear system constant inhomogeneity efficient implementation higherorder methods currently investigation note added revised version finishing paper learned druskin knizhnerman 3 4 previously obtained estimate similar 35 symmetric case using different proof give asymptotic estimate 3 prove using chebyshev series expansion exponential function extension technique nonhermitian case knizhner man 14 derived error bounds terms faber series arnoldi method 27 showed km faber series coefficients f exponent ff depends numerical range one referee emphasizes faber series approach could put similar use lemma 1 fact leonid knizhnerman showed us personal communication would become possible derive result type theorem 6 using 59 approach via lemma 1 makes obvious see geometry numerical range comes play example similar theorem 5 given 15 x3 thank anne greenbaum two referees pointing references leonid knizhnerman providing commented version russian paper 14 error bounds via chebyshev faber series related problem approximating matrix functions methods generalize semiiterative methods linear systems given talezer 29 30 31 acknowledgement grateful peter leinen harry yserentant providing initial motivation work r numerical ranges operators normed spaces elements normed algebras two polynomial methods calculating functions symmetric matrices krylov subspace approximations eigenpairs matrix functions exact computer arithmetic uniform numerical methods problems initial boundary layers semiiterative methods generated faber polynomials implementation lookahead lanczos algorithm nonhermitian matrices verallgemeinerte rungekutta verfahren zur losung steifer differentialgleichungen method exponential propagation large systems stiff nonlinear differential equations efficient solution parabolic equations krylov approximation methods iterative solution linear equations ode codes solving ordinary differential equations ii analysis krylov methods nutshell computation functions unsymmetric matrices means arnoldis method bounds arnoldis method case normal matrix propagation methods quantum molecular dynamics generalized rungekutta processes stable systems large lipschitz con stants theory functions complex variable new approach manystate quantum dynamics recursive residuegeneration method convergence iterations linear equations unitary quantum time evolution iterative lanczos reduction krylov subspace methods solving large unsymmetric linear systems analysis krylov subspace approximations matrix exponential operator analysis lookahead lanczos algorithm spectral methods time hyperbolic problems spectral methods time parabolic problems polynomial approximation functions matrices applications pseudospectra matrices iterative solution method solving fax convergence analysis nonsymmetric lanczos algorithms tr ctr p novati explicit onestep method stiff problems computing v71 n2 p133151 october vladimir druskin krylov subspaces electromagnetic oil exploration ieee computational science engineering v5 n1 p1012 january 1998 ya yan lu computing matrix function exponential integrators journal computational applied mathematics v161 n1 p203216 1 december c gonzlez ostermann thalhammer secondorder magnustype integrator nonautonomous parabolic problems journal computational applied mathematics v189 n1 p142156 1 may 2006 christian lubich variational splitting integrator quantum molecular dynamics applied numerical mathematics v48 n34 p355368 march 2004 marlis hochbruck alexander ostermann exponential rungekutta methods parabolic problems applied numerical mathematics v53 n2 p323339 may 2005 krogstad generalized integrating factor methods stiff pdes journal computational physics v203 n1 p7288 10 february 2005 f carbonell j c jimenez r biscay numerical method computation lyapunov exponents nonlinear ordinary differential equations applied mathematics computation v131 n1 p2137 10 september 2002 serhiy kosinov stephane marchandmaillet igor kozintsev carole dulong thierry pun dual diffusion model spreading activation contentbased image retrieval proceedings 8th acm international workshop multimedia information retrieval october 2627 2006 santa barbara california usa philip w livermore implementation exponential time differencing scheme magnetohydrodynamic equations spherical shell journal computational physics v220 n2 p824838 january 2007 caliari vianello l bergamaschi interpolating discrete advectiondiffusion propagators leja sequences journal computational applied mathematics v172 n1 p7999 1 november 2004 paolo novati polynomial method based fejr points computation functions unsymmetric matrices applied numerical mathematics v44 n12 p201224 january koikari error analysis modified scaling squaring method computers mathematics applications v53 n8 p12931305 april 2007 roger b sidje expokit software package computing matrix exponentials acm transactions mathematical software toms v24 n1 p130156 march 1998 james v lambers practical implementation krylov subspace spectral methods journal scientific computing v32 n3 p449476 september 2007 hvard berland brd skaflestad wright expinta matlab package exponential integrators acm transactions mathematical software toms v33 n1 p4es march 2007 botchev harutyunyan j j w van der vegt gautschi time stepping scheme edge finite element discretizations maxwell equations journal computational physics v216 august 2006 elena celledoni arieh iserles syvert p nrsett bojan orel complexity theory liegroup solvers journal complexity v18 n1 p242286 march 2002 tokman efficient integration large stiff systems odes exponential propagation iterative epi methods journal computational physics v213