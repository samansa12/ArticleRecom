minimum achievable utilization faulttolerant processing periodic tasks abstractthe rate monotonic scheduling rms policy widely accepted scheduling strategy realtime systems due strong theoretical foundations features attractive practical uses periodic task set n tasks deadlines end task periods guarantees feasible schedule single processor long utilization factor task set n21n 1 converges 069 large n analyze schedulability set periodic tasks scheduled rms policy susceptible single fault recovery action reexecution uncompleted tasks priority rms policy maintained even recovery conditions guarantee task miss single deadline even presence fault utilization factor processor exceed 05 thus 05 minimum achievable utilization permits recovery faults expiration deadlines tasks bound better trivial bound 0692 0345 would obtained computation times doubled provide reexecutions rms analysis result provides scheduling guarantees tolerating variety intermittent transient hardware software faults handled simply reexecution addition demonstrate permanent faults tolerated efficiently maintaining common spares among set processors independently executing periodic tasks b introduction realm realtime computation frequently encounter systems tasks required execute periodically applications requirement common often found example process control space applications avionics others even external events trigger tasks periodic many realtime systems sample occurrence events periodically execute associated tasks time slots reserved sampling rate depends expected frequency external event reason aperiodic sporadic tasks executed periodic manner periodic execution well understood predictable variety scheduling policies periodic realtime systems studied scheduling policy defined optimal schedule feasible set tasks policy also system called fixedpriority system tasks fixed priorities priorities change run time rate monotonic scheduling rms proven optimal scheduling policy scheduling set fixed priority tasks uniprocessor earliestdeadlinefirst edf optimal scheduling policy variable priority system note priority task different criticality former measure assigned tasks scheduling policy facilitate scheduling whereas latter measure importance task defined application rms widely used practice easily implemented preemptive policy priority tasks assigned increasing order periods task particular priority preempts lower priority task liu layland proved long utilization factor task set consisting n tasks less n2 1n gamma 1 task set guaranteed feasible schedule uniprocessor 1 bound approaches 069 n goes infinity however may exist task sets utilization factors bound still may feasibly scheduled stochastic analysis breakdown utilization factor randomly generated task sets presented 2 problem scheduling periodic tasks multiprocessors considered 3 4 5 easy demonstrate neither rms edf algorithms optimal scheduling set periodic tasks multiprocessor system among fixed variable priority algorithms respectively 3 fact scheduling policy proven optimal multiprocessor system another issue realtime computing currently gaining increased attention researchers fault tolerance computers introduced great extent critical applications reliance placed reducing human intervention minimum situations demand hard realtime processing merges catastrophic consequences failures difficult imagine fault tolerance must provided responsive systems 6 must perform computations successfully meet deadlines even presence faults indispensable many applications paper contributes evolving framework design implementation responsive systems goal paper investigate issues fault tolerance system realtime periodic tasks employing rate monotonic scheduling previous work usually addressed software faults task primary alternate code 7 offline scheduling strategy considered periodic tasks period particular task integral multiple next lower task period alternates scheduled rms policy first effort made include maximum number primary executions schedule similar problem scheduling alternate versions programs called ghosts considered 8 dynamic programming used perform scheduling attempt made minimize cost function load balancing scheme presented periodic task sets scheduled rms 9 neighbors faulty processor ring take tasks eventually distributed processors however consideration missing deadlines due overload caused task migration response fault paper address schedulability criterion set periodic tasks faulttolerant processing specifically prove minimum achievable utilization 05 set periodic tasks executing environment susceptible occurrence single fault recovery action recompute partially executed tasks result guarantees tasks meet deadlines even presence fault utilization factor task set processor less 05 classes faults tolerated include intermittent transient hardware software faults addition permanent crash incorrect computation faults also handled providing spares perform recovery subsequent execution task set paper organized follows section 2 provide background explain problem declare assumptions following section present proof assertion minimum achievable utilization 05 section 4 address practical implementation issues conclusions given final section background problem statement assumptions mentioned introduction rms strong theoretical foundation widely used practice due simplicity rate monotonic scheduling policy assigns priorities tasks increasing order periods consider set n tasks task described tuple execution time task period r release time ie time first invocation task occurs thus ng assume tasks labeled manner task expected complete computation prior end period thus j th instance j 1 2 task ready execution time r deadline completion assume dealing hard realtime system aim meet deadlines conditions opposed soft realtime systems deadlines may missed aim reduce delay paper explicitly mentioned r assumed zero execution tasks preemptive ie execution task higher priority task k ready execution computation task interrupted remains suspended task k completes execution task continues state suspended provided task higher priority waiting execution usually assumed time swap tasks negligible accounted computation time note definition preemption recursive ie task k interrupted task interrupted another task still higher priority rms fixed priority policy since priorities tasks remain static change course execution tasks priorities assigned increasing order task periods task smallest period assigned highest priority task largest period lowest call arrival time task instant ready execution ie deadline next arrival task departure time task defined time instant task completes execution thus arrival time j th instance task r departure time cannot defined easily depends parameters higher priority tasks utilization factor u task set defined single processor system task set said fully utilize processor scheduling algorithm task set feasibly scheduled using algorithm increasing cause schedule infeasible least upper bound utilization factor minimum utilization factors possible task sets fully utilize processor 1 also called minimum achievable utilization 3 task set utilization factor less minimum achievable utilization guaranteed feasible schedule 1 task set n tasks minimum achievable utilization n2 1n gamma 1 n 1 minimum achievable utilization converges ln2 approximately 069 21 fault classification discussion fault tolerance necessary consider issue fault assumptions significant impact design system crash fault model processor either operating correctly fault occurs respond event internal external incorrect computation fault assumption considers processor may fail produce correct result response correct inputs issues related fault diagnosis consensus faulttolerant processing reader refer 10 addition faults also classified permanent intermittent transient 11 permanent hard fault erroneous state continuous stable intermittent fault occurs occasionally due unstable nature hardware transient fault results temporary environmental conditions permanent fault tolerated providing spares take tasks primary processor fault occurs intermittent transient faults tolerated repeating computations 22 analysis problem general scheduling problem concerned allocating shared resources multiple processes need resources simultaneously allocation performed attempting achieve certain prespecified goals traditional computers goal usually minimize total time increase response time requests however realtime systems goal simply allocate resources manner deadlines associated tasks met paper dealing scheduling tasks execution resources processors hard realtime systems scheduler tasks guaranteed completed deadlines realtime systems used critical applications necessary system survives spite faults may arise system unlike nonrealtime systems occurrence faults subsequent recovery may permitted cause delays imperative results computations realtime systems meet deadline even presence faults thus notion guaranteeing feasible schedule extended cover random events fault occurrences challenging endeavor addressed nevertheless paper consider fault tolerance strategies set periodic tasks executed rms policy guarantee task miss even single deadline due occurrence fault random moment subject fault assumptions explicitly stated therein maintaining priority rms policy one considers introducing fault tolerance computation host issues need considered addition already existing means providing fault tolerance introducing redundancy system selection appropriate level time andor space redundancy driven requirements application redundancy provided creating replicas level computation usually task level realtime systems time redundancy provided reexecuting task multiple number times original execution reexecutions performed single processor different processors choice dependent fault model assumption realtime systems time redundancy desirable choice provided sufficient laxity deadlines enough spare capacity tasks miss deadlines allow maximum utilization available resources however deadlines stringent little laxity available space redundancy choice thus ideal design one effectively resolves tradeoff two choices minimum cost overhead incurred tasks guaranteed meet deadlines fault assumptions spacetime tradeoff fundamental design responsive computer systems result presented optimizes tradeoff provide scheduling guarantees single fault environment periodic tasks 23 single fault reexecution task recovery analyze following scenario ffl set tasks executing single processor tasks scheduled rms policy ffl tasks independent ffl fault may occur instant ffl interval successive faults greater largest period task set ffl fault detected next occurrence departure task processor example lower priority tasks executing occurrence fault time later another higher priority task supposed preempt first task fault detected higher priority task expected depart normal execution ffl recovery action reexecute partially executed tasks instant fault detection includes currently executing task preempted tasks ffl tasks required meet deadlines even reexecuted due occurrence fault ffl priorities rms policy maintained even recovery maintaining priorities tasks important since rms fixed priority scheduling policy priorities assigned system design time approach simplifies design process designer worry assigning separate priorities recovery analyze effect change priorities schedulability task set one note stage place restrictions kind faults tolerated architecture system long conditions satisfied design results paper valid example one consider hardware permanent crash fault recovery subsequent computation would performed regular execution faults b primary processor fault occurs prior time 17 c spare processor figure 1 feasible schedule presence fault spare processor hand software fault occurs recovery possible primary processor incorrect computation fault handled fault detected perhaps consistency checks task expected depart addition recovery program task need one normally executed long computation time less equal computation time primary code two examples shown figures 1 2 consider task set consisting two tasks periods 5 7 examples assume crash faults processors figure 1 processor state function time shown regular execution figure 1a observe schedule feasible fault occurs figures 1b 1c show state processor spare respectively fault occurs prior time instant 17 fault occurs task 2 could complete restarted spare meets deadline time 21 figure 2a shows execution profile two tasks whose periods 5 7 respectively however example 2 though schedule feasible fault occurs true fault causes recovery action taken arrival task 1 time 15 preempts task 2 fault occurs prior completion time 17 spare restarts execution tasks starting task 1 higher priority task task 1 completes time 19 manages meet deadline time 20 reexecution task 2 starts time 19 preempted time 20 arrival next instance task 1 task 2 misses deadline time 21 seems obvious examples certain amount time redundancy provided recovery rms scheduling criteria u 069 sufficient trivial regular execution faults b primary processor fault occurs prior time 17 c spare processor figure 2 infeasible schedule presence fault solution reserve enough space tasks event fault enough spare capacity terms time task reexecuted still meet deadline since worst possible time fault occur prior completion task amount extra time devoted task recovery additional c thus rate monotonic analysis schedulability entire task set computation time tasks assumed 2c means general case effective minimum achievable utilization processor 0345 ie half 069 however situation pessimistic appears prove following section minimum achievable utilization 05 guarantees enough time redundancy complete recovery deadlines thus long utilization factor task set processor less equal 05 task set guaranteed feasible schedule presence single fault 24 motivation one popular traditional approaches design faulttolerant system use n modularredundancy nmr 11 technique every processor provided extra spares spares may hot warm cold realtime systems hot spares preferred choice time wasted perform recovery spare said hot synchronously performs computations primary processor takes primary processor fails fault models incorrect computation byzantine faults may distinction primary spares perform computation vote result mask faulty results assume crash failstop model nmr requires processor duplicated tolerate single fault number processors faulttolerant system 2m number processors original system system called duplex system tolerate one fault primary spare faults long one fault affects particular primary spare achieved space overhead equal size original system ie doubling space resources space overhead duplex system high many applications usually desirable single spare group processors processor fails spare substituted place whereas providing single spare simple feat nonrealtime systems ensuring recovery performed within deadlines easy contributions paper makes easy guarantee recovery limiting utilization factor processor 05 u total utilization factor large set tasks number processors needed system single spare du 05e 1 assumes crash faults even distribution utilization factor likely significantly less 2 du 069e duplex system interestingly trivial solution ensure recovery doubling computation time requirements require du 035e nearly required duplex system addition tolerating hardware crash faults major application result towards tolerating software faults deal greater detail section 4 3 determination minimum achievable utilization prove minimum achievable utilization 05 present definitions terms used proof recovery defined reexecution partially executed tasks priority rms maintained thus recovery lower priority task higher priority task arrives higher priority task preempt recovery lower priority task addition fault affects multiple tasks higher priority tasks perform recovery action first schedule said feasible set tasks task set guaranteed schedule rate monotonic algorithm ie tasks meet deadlines even recovery performed due single fault occur arbitrary instant time set tasks said fully utilize processor task set feasible schedule increasing computation time task set causes schedule become infeasible minimum achievable utilization minimum utilization factor every possible sets tasks fully utilize processor define critical instant task instant arrival task largest response time presence fault schedule set tasks fully utilizes processor least one critical instant task response time period task shall call time interval arrival deadline task critical period fault occurs prior completion task creates maximum delay task lower priority tasks interrupted hence need examine effects fault instants tasks completed consider number cases lead proof theorem minimum achievable utilization 05 31 case 1 task set one task consider task set comprising single task c case release time matter observation 1 minimum achievable utilization task set one task 05 proof obvious since c 1 cannot exceed 1 2 c 1 equals value x occurs instant kt 1 44 48 54 55 b recovery task 2 recovery task 2 recovery task 1 figure 3 schedule two tasks periods 6 11 sufficient time reexecute task still meet deadline processor fully utilized c important note even task set one task computation time tasks cannot exceed half value period ie c n number tasks set 32 case 2 task set two tasks begin analysis minimum achievable utilization case let us consider issue release times traditional rms analysis worst delay task 2 observed arrives simultaneously task 1 first arrival task 2 feasibly scheduled subsequent arrivals also meet deadlines one consider feasibility conditions simultaneous arrivals tasks necessarily true one considers possibility faults example consider task set f1 6 45 11g release times zero considering first arrival would appear task set feasible schedule processor fully utilized shown figure 3a tasks 1 2 released simultaneously since task 1 higher priority starts execution departs begins fault occurs prior completion task 2 time instant 55 restarted perform recovery task 1 arrives time 6 preempts recovery recovery completes time 11 next arrival task 2 occurs however fault occurs time instant 49 schedule infeasible shown figure 3b task 2 arrives time 44 preempted task 1 arrives time 48 fault occurs prior completion task 1 time 49 tasks reexecuted task 1 recovers time time instant 50 recovery task 2 begins however next arrival task 1 occurs time 54 preempts recovery task 2 causes miss deadline time 55 4 units time available task 2 recovery time interval 5054 whereas computation time 45 thus correct value c 2 fully utilizes processor c hence analysis consider possible values release times consider set two tasks arbitrary release times first consider case 2 15t 1 next consider various subcases 321 case 2a theorem 1 minimum achievable utilization 05 set two tasks satisfying condition proof first prove long utilization factor less equal 05 feasible schedule guaranteed task set give particular instance processor fully utilized utilization factor 05 observation 1 clear c 1 1 2 within interval r 2 dt 2 1 e arrivals task 1 worst possible scenario task 2 completed preempted arrival task 1 fault occurs prior completion task 1 case tasks 1 2 need executed task 1 meet deadline since c 1 1 2 task 2 meet deadline following condition ie 2 traditional rms analysis feasibility condition dt 2 1 faulttolerant system task executed worst case scenario occurrence single fault assume utilization factor task set less equal 05 ie therefore thus feasibility condition given equation 2 guaranteed equation 5 satisfied thus task set satisfying condition theorem 1 guaranteed feasible schedule utilization factor less equal 05 b c figure 4 modeling subsequent arrivals tasks consider cases c two cases processor fully utilized since increasing c 2 first case c 1 second case causes schedule become infeasible cases utilization factor 05 also proved long utilization factor less equal 05 tasks feasibly scheduled hence 2 15t 1 minimum achievable utilization 05 2 322 case 2b take following approach proof proof first show instance task modeled arrival first instance values release times r 0and r 0 prove first instances feasibly scheduled possible values release times long utilization factor less equal 05 ie prove minimum achievable utilization among task sets fully utilize processor first instance 05 also without loss generality assume one r 1 r 2 zero consider figure 4 interested feasibility meeting deadline time instant th instance task 2 arrives time instant r 2 kt 2 consider various cases r 1 ffl r 2 shown figure 4a th instance task 2 modeled first instance task 2 task set 0g possible fault execution j th instance task 1 affect schedulability th instance task 2 ffl r 2 shown figures 4b c th instance task 2 modeled first instance task 2 task set appendix consider possible cases release times periods tasks cases present value task computation times fully utilize processor first instance task 2 cases prove processor fully utilized first instance task 2 utilization factor greater 05 theorem 2 minimum achievable utilization set two tasks satisfying condition 15t 1 05 proof shown subsequent instance two tasks first instance modeled first instance release times proved lemmas 314 appendix possible values release times processor fully utilized first instance utilization factor greater equal 05 hence minimum achievable utilization set two tasks satisfying condition 33 case 3 task set n 2 tasks consider set n tasks whose utilization prove induction minimum achievable utilization set n tasks 05 let us assume minimum achievable utilization set tasks 05 prove also true set n tasks consider set first n gamma 1 tasks whose utilization sets n ngamma1 feasible schedule u thus need consider cases u 05 since u feasible schedule assumption thus need consider feasibility scheduling task n 331 case 3a theorem 3 minimum achievable utilization 05 set n tasks satisfying condition assuming minimum achievable utilization set tasks case set two tasks following condition representing worst possible scenario satisfied corresponding task set feasible schedule note reverse true ie task set may satisfy following condition still feasible schedule ie assume u n 05 therefore thus condition equation 7 guaranteed whenever 0 thus sum also nonnegative equation 7 satisfied task set guaranteed feasible schedule thus sets n tasks minimum achievable utilization 05 n 15t 332 case 3b consider two subcases following lemmas assume set tasks n fully utilizes processor note set ngamma1 fully utilize processor since u 05 add task n set ngamma1 increment computation time till processor fully utilized value computation time c n hence task n least one critical period occurrence fault subsequent recovery cause task deadline two possible cases worst case instant occurrence fault prior completion task n case recovery solely reexecution task n worst case instant occurrence fault prior completion task former case fraction time processor spends executing task critical period task n x dt n e latter case fraction time processor spends normal execution recovery task critical period task n lemma 1 minimum achievable utilization 05 set n tasks satisfying conditions e assuming minimum achievable utilization set tasks 05 construct set 0 tasks follows utilization factor u 0 set 0 n ie u 0 consider fault prior completion task c interval critical interval set n time completion task thus last task misses deadline set 0 infeasible schedule since assumed minimum achievable utilization set tasks 05 utilization factor 0 must exceed 05 however u u n 05 thus minimum achievable utilization every set n tasks satisfy conditions lemma 05 2 proved every set n tasks fully utilizes processor satisfies conditions lemma 1 converted another set tasks infeasible schedule example consider set three tasks 0g task set fully utilizes processor task set construct set 0 5g set 0 2 infeasible schedule fault occurs time prior completion task 2 time instant 2625 enough spare time recover lemma 2 minimum achievable utilization 05 set n tasks satisfying conditions assuming minimum achievable utilization set tasks 05 assume set tasks n fully utilizes processor since set ngamma1 fully utilize processor increment computation time task ngamma1 ngamma1 utilization factor 05 let increase delta let new set 0 utilization factor u 0 delta easy observe c n 2delta since task lowest priority task set reduction computation time delta c 0 frees least 2delta amount time task n interrupted tasks amount 2delta reduction delta also frees extra delta recovery thus 05we prove following theorem general case theorem 4 set n tasks minimum achievable utilization 05 proof theorem 3 lemmas 1 2 proved minimum achievable utilization set n tasks 05 provided minimum achievable utilization set tasks 05 addition theorem true one task shown observation 1 also proven true set two tasks theorems 1 2 hence induction true n 2 implementation issues 41 tolerating hardware crash faults consider distributed system common spare spare idle monitors state processors completion instance task processor sends message spare indicating task successfully completed spare maintains list tasks system processor executing information either provided lookup table completion times tasks completion times easily computed onthefly let ccomm maximum communication latency network task supposed completed time c spare expects confirmation time case message received processor declared faulty spare takes faulty processors task set initiates recovery rate monotonic analysis task set processor communication time overhead reconfiguration assumed included computation time task task computation requirement c c 0 used analysis technique assumes communication delays finite bounded unreasonable assumption practical applications also requires executable code tasks accessible spare discussed section 2 space overhead guaranteeing deadlines presence single fault duplex systems 2 du069e processors however number processors needed system single spare recovery du05e 1 u total utilization factor task set assume task set partitioned utilization factor evenly distributed table 1 shows number processors required scheme different values utilization factors observe providing common spare significantly reduces size system effect pronounced large values utilization factors table 1 number processors systems computation times doubled rms analysis duplex systems system common spare recovery different values utilization factor u doubling computation duplex system common spare time rms analysis recovery l u 0345 l u 069 l u 05 5 6 19 7 22 22 15 9 28 28 19 100 291 290 200 42 tolerating incorrect computation faults caused hardware fault triple modular redundancy tmr systems required tolerate incorrect computation faults duplex system detect presence incorrect computation fault results two processors agree third processor required majority result assumed correct similar technique described used tolerate single incorrect computation fault rather tmr system duplex system spare used case duplex pair detects error spare used perform recovery number processors required tmr system 3 du069e whereas number processors required duplex spare recovery 2 du05e 1 u total utilization factor entire task set number processors required schemes shown table 2 notice duplex spare requires less space overhead compared tmr system however benefit large observed crash faults 43 tolerating software faults intermittent transient hardware faults believe greatest application results paper would towards tolerating software faults intermittent transient hardware faults space hostile industrial applications outside environment conditions alpha particles electrostatic interference etc cause transient errors addition software faults stack overflows operating systems etc best handled reexecution limiting utilization factor 05 processor guarantee recovery performed within deadlines even though consider reexecution partially executed tasks necessary fault affects single task task reexecuted meet deadline confident reexecution cause tasks miss deadlines addition recovery code need table 2 number processors tmr system duplex system common spare recovery different values utilization factor u tmr duplex system system common spare l u 069 l u 05 5 9 42 37 100 435 401 primary code especially true software faults alternate program desirable long time execute recovery program less equal execution time primary program certain deadlines met 44 tolerating multiple faults multiple faults tolerated analysis long interval successive faults larger largest period task set assumption unlimited transient faults tolerated k permanent crash faults tolerated providing k spares limiting utilization factor processor 05 certain task sets k nmr system yield lesser space overhead greater fault coverage would easier implement case 05 069 u utilization factor entire task set assume task set partitioned utilization factor evenly distributed example total utilization uses two processors whereas approach would require three processor general cases providing k common spares would result lesser overheads conclusions provided theoretical foundation faulttolerant processing periodic realtime tasks scheduled rate monotonic scheduling policy scenario recovery fault involves restarting partially executed tasks maintaining priority levels rms pol icy show minimum achievable utilization processor 05 result guarantees tasks meet deadlines even presence fault utilization factor processor restricted 05 bound much better maximum utilization factor 0345 0692 would obtained computation times tasks naively doubled rms analysis provide recovery time result provides framework tolerating transient intermittent hardware software faults reexecution preferred recovery technique addition result applicable tolerating permanent crash incorrect computation faults spares must employed replace faulty processors system show space redundancy achieved maintaining common pool spares cases less nmr system contributions paper form important component evolution responsive systems concept providing guarantees meeting deadlines system spite occurrence faults integral design faulttolerant realtime systems critical applications providing simple criterion ensure feasibility meeting deadlines presence single fault considerably reduces complexity encountered designers lead safer dependable use realtime systems critical applications r scheduling algorithms multiprogramming hard realtime environment rate monotonic scheduling algorithm exact characterization average case behavior realtime scheduling problem scheduling periodically occurring tasks multiple proces sors note preemptive scheduling periodic realtime tasks responsive systems challenge nineties faulttolerant scheduling problem scheduling tasks quick recovery failure diffusion model based task remapping distributed realtime systems consensus problem faulttolerant com puting theory practice reliable system design tr ctr rodrigo santos jorge santos javier orozco least upper bound fault tolerance realtime systems journal systems software v78 n1 p4755 october 2005 sylvain lauzac rami melhem daniel moss improved ratemonotonic admission control applications ieee transactions computers v52 n3 p337350 march sasikumar punnekkat alan burns robert davis analysis checkpointing realtime systems realtime systems v20 n1 p83102 jan 2001 frank liberato rami melhem daniel moss tolerance multiple transient faults aperiodic tasks hard realtime systems ieee transactions computers v49 n9 p906914 september 2000 tarek f abdelzaher vivek sharma chenyang lu utilization bound aperiodic tasks priority driven scheduling ieee transactions computers v53 n3 p334350 march 2004