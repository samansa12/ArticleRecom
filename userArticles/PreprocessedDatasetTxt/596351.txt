copositive programming standard quadratic optimization problems standard quadratic problem consists finding global maximizers quadratic form standard simplex paper usual semidefinite programming relaxation strengthened replacing cone positive semidefinite matrices cone completely positive matrices positive semidefinite matrices allow factorization fft f nonnegative matrix dual cone cone copositive matrices ie matrices yield nonnegative quadratic form positive orthant conic formulation allows us employ primaldual affinescaling directions furthermore approaches combined evolutionary dynamics algorithm generates primalfeasible paths along objective monotonically improved local solution reached particular primaldual affine scaling directions used escape local maxima encountered evolutionary dynamics phase b introduction standard quadratic problem standard qp consists nding global maximizers quadratic form standard simplex ie consider global optimization problems form subject x 2 1 paper presented go99 conference firenze sept 28oct 2 1999 imb md thank locatelli f schoen hospitality perfect organization large part work done tt working tu delft c 1999 kluwer academic publishers printed netherlands im bomze dur e de klerk c roos quist arbitrary symmetric n n matrix denotes transposition standard simplex ndimensional euclidean space ir n denotes nonnegative orthant ir n course region fy 2 ir n always represented ir n1 introducing slack variable avoid trivial cases assume throughout paper objective constant means fa eg linearly independent n n matrix consisting entirely unit entries x review standard qps applications also oers justication terminology see 9 note maximizers 1 remain replaced arbitrary constant without loss generality assume henceforth entries nonnegative furthermore question nding maximizers general quadratic function x qx homogenized similar way considering ranktwo update ce 1 objective values course quadratic optimization problems like 1 nphard 23 nevertheless several exact procedures try exploit favourable data structures systematic way avoid worstcase behaviour whenever possible one example type algorithms specied paper proposed procedure exploits extensively special structure standard qp eg feasible set standard simplex opposed general formulation quadratic problem article organized follows section 2 contains concise exposition primal dual problems copositive programming involves copositive rather positivesemidenite matrices using explicit characterization dual cone convex nonpolyhedral cone copositive matrices also shortly treat relaxation copositive programming allquadratic problems simplex considered 41 section 3 specialized applied standard qps enjoy property copositive programming relaxation becomes exact reformulation 1 dual fact univariate copositivefeasibility problem seen straightforward generalization eigenvalue bound problem section 4 contains short review replicator dynamics become increasingly popular local optimization procedure standard qps technique combined primaldual search directions general conic programming 28 45 used escape inecient local solutions returned replicator dynamics iteration copositive programming standard quadratic optimization problems 3 2 copositive programming problems general setup consider following primaldual pair linear programming problems pointed convex cone k ir see eg 37 17 28 45 subject matrix full row rank b 2 ir c 2 ir subject k kg dual cone k semidefinite programming coincides cone p symmetric positivesemidenite n n matrices selfdual usual inner product trace sx ddimensional euclidean space n constructed identifying upper triangular half symmetric n n matrix vectorized version however need restrict cases selfdual cones k handle dual cone k even geometry k k becomes complicated fact turns useful study general cases eg putting k equal cone copositive matrices recall symmetric n n matrix said copositive precisely ie quadratic form generated takes nonnegative values positive orthant matrix said strictly ir n copositive inequality 4 strict whenever v 6 clearly cone k nonempty interior predual cone k see proposition 1 described follows see eg 19 43 convex hull symmetric rankone matrices ie dyadic products generated nonnegative vectors elements k called completely positive matrices note dropping nonnegativity requirement arrive semidenite case even without constraints checking whether matrix belongs k conphard 36 algorithms problem found eg 33 18 46 5 47 48 14 6 mention less obvious primal feasibility problem also without constraints fact authors aware nite exact procedure determine whether given symmetric nn matrix completely positive see also 32 29 20 4 3 25 15 49 however following result may helpful 4 im bomze dur e de klerk c roos quist proposition 1 let k 5 n1 denote x negative nonnegative n proof view caratheodorys theorem rst identity cf theorem 1 32 obvious taking 1g noting middle set 7 necessarily subset k due fact hmff columns f inclusion k k also immediate nalize proof observe x x implies k co k unfortunately cone k convex therefore strictly smaller k following example shows example 1 nonsingular 3 3 matrix 6 403 belongs k cf 3 however square root approximately 0908 0092 0408 0092 0908 0408 0408 0408 16337 5 whence although rankone matrices aa bb cc seen belong k singular variant obtained aa bb ie replacing lower right corner entry x 2 general application primaldual approach given 2 3 consider socalled allquadratic problem appears subproblem 41 subject x 2 note also inhomogeneous quadratic constraints written form see introducing slacks also write problems quadratic inequality constraints form 8 additional linear constraints form written hd change copositive programming standard quadratic optimization problems 5 sign feasible set otherwise one subdivide set accordingly normalization condition written hence k 5 may view following copositive programming problem relaxation subject indeed linearity fact convexity objective ensures one solution x problem 9 attained extreme point feasible set x happens lie also extreme ray k automatically condition dropped without loss generality case relaxation 9 becomes exact reformulation 8 unfortunately always case following example shows example 2 consider problem 9 maximize ha subject course x 2 k well 1 obviously solution problem given ranktwo matrix x x proceed general case primaldual pair 23 establish dual problem 9 1 structural variables 0 also slacks contained subject given solve primal dual feasibility problems limited eort possible use search directions feasible primaldual interior point algorithm indeed following results nesterov nemirovskii 37 valid general class convex cones include cone k given 5 exist socalled selfconcordant barrier functions cones k k interior point methods converge polynomially bounded number steps formulated using selfconcordant barriers unfortunately selfconcordant barriers k k known elaborate discussion topic see 43 however tuncel 45 recently noticed even case one still formulate class interior point methods known primaldual ane scaling algorithms ease reference reproduce generic roster primaldual interiorpoint method 21 27 34 course general harder solve 8 6 im bomze dur e de klerk c roos quist optimality resolve feasibility questions ie check membership k could special instances procedure still helpful generic interiorpoint primaldual algorithm 1 choose initial point x 2 stopping criterion satised repeat following step choose improving feasible direction dx dy ds step length 0 still xdx 2 int k well feasibility wrt equality constraints maintained socalled primaldual ane scaling zeroorder search direction provided kojima tuncel 28 45 slightly simplied class directions solution linear system n h arbitrary positivedenite symmetric linear operator n usual remaining strict feasibility requirements guaranteed suitable choice step lengths note solution 11 always exists also qh positivedenite provided hx si 0 guaranteed interior point pairs theorem 33 45 since assume fe linearly independent correspondence full row rank assumption 2 thus situation classical sdp case search direction commonly used cf eg 16 kojima tuncel prove 28 cf theorem 34 45 choose search directions 12 duality gap decreases linearly factor essentially step length primal dual objectives improved unless optimality reached decisive arguments positive deniteness h property looking formula 12 evident much would gained terms containing hs vanished course impossible h positivedenite copositive programming standard quadratic optimization problems 7 therefore propose positivesemidenite variant abovementioned result h single zero eigenvalue belonging direction note longer assume x 2 int kint k hx si 0 recall latter relation characterizes nonoptimality pairs x theorem 2 suppose h positivesemidenite symmetric linear operator consider pair x 2 k k hx si 0 dene symmetric linear operator rh n rh positivedenite satises furthermore solution dx dy ds system n ir m1 n unique satises hx proof rst argument quite similar theorem 33 45 nonnegative vanish hx absurd latter relation implies assumption whereas hx assumption hx si 0 hence operator positivedenite finally turning system 14 show related homogeneous system dx dy ds trivial solution indeed substituting ds equation yields dy substituting dx rst 1 equations 14 gives changing signs homogeneous system dy coecient matrix6 6 6 4 8 im bomze dur e de klerk c roos quist due linear independence fe easily seen positive denite rh thus dy yielding hence 14 always unique solution establish reduction duality gap let us rst deal secondorder term hdx dsi vanishes feasibility conditions imposed dx dy ds 14 indeed rstorder terms hx dsi establishes hx using similar arguments 28 one also show primal dual objectives improved directions given 14 establish result directly next section special case focus upon paper remarks semidenite programming sdp many possible choices operator rh one choice known allow convergent algorithms namely nesterovtodd primaldual anescaling direction note rh positive denite linear operator also note choice rh possible copositive programming since x positivedenite copositive matrices sdp primaldual algorithm using search direction globally convergent polynomial suitable choice step length 26 another choice primaldual scaling direction socalled primal hkm ane scaling direction mentioned search direction globally convergent choice step length particular converge nonoptimal point 35 moreover cannot used copositive programming copositive matrix singular despite hx si 0 linearly independent e finally primaldual ane scaling direction sdp also dened copositive programming socalled dual hkm direction given copositive programming standard quadratic optimization problems 9 solution primal hkm direction primaldual sdp algorithm using search direction globally convergent 35 preceding observations prove two things using primaldual ane scaling directions interior point methods conic programming necessarily lead globally convergent algorithm one cannot guarantee xed feasible step length primaldual ane scaling directions even sdp case words jamming occur reasons discuss hybrid algorithm section 4 uses primaldual anescaling steps escape strategy 3 standard quadratic optimization copositive programming first note standard qp 1 special case allquadratic problem 8 quadratic constraints hence case arrive copositive programming problem 9 single constraint subject dual one structural variable subject ye amounts search smallest ye copositive sense dual problem 16 related question eigenvalue bounds replace e identity matrix copositive semidenite observe case 15 relaxation indeed exact reformulation standard qp 1 due following lemma 3 extremal points feasible set 15 exactly rankone matrices 1 point denote scalar variable im bomze dur e de klerk c roos quist proof course belong 1g suppose vector x 2 xx 0 1 choose orthogonal basis fx 1 ir n since z u also positive semidenite get x z u rank one belong k thus obtain obtain x z u must positive multiples xx requirement shows show converse suppose x extremal point k well hence due 17 convex combination matrices u whence extremality assumption form stated principle roster algorithm section 2 applies update equations reduce dual part means simply continue line search generalized eigenvalue bound 16 course similar reduction applies kojimatuncel search directions 11 qh replaces rh let us calculate update steps explicitly order avoid unnecessary numerical complications remember still freedom choosing positive semidenite operator h long gives unique direction zero eigenvalue h note assumption linear independence fa eg matrix never vanish regardless whether belongs k instance may assume orthoprojection e onto orthogonal complement n also eigenvector h suitably chosen eigenvalue 0 copositive programming standard quadratic optimization problems 11 equivalent imposing theorem 4 put denote dx dy ds solution 18 19 implies proof inserting obtain result dy observing similarly derive hxsi x proof complete formulation may convenient write x directly show objectives indeed improved chosen directions theorem 5 assume x 2 kk hx si 0 improving feasible direction dx dy ds chosen theorem 4 0 primal dual objective function improve strictly ie proof first dy strictly negative since n 2 hesi 2 cauchyschwarz inequality note also fe sg linearly independent see strict monotonicity primal objective function compare reduction duality gap improvement dual objective theorem 2 know reduction duality gap hx si therefore show also primal objective contributes reduction show dy hx si since denominator fraction positive number bigger 1 12 im bomze dur e de klerk c roos quist sake completeness also provide explicit update formulae original kojimatuncel search direction ie solutions system h positivedenite otherwise arbitrary qh 12 course concrete implementation remains specify values ha theorem 6 assume x 2 k k hx si 0 put denote dx dy ds solution 22 furthermore primal dual objectives strictly improved 0 proof arguments similar theorems 4 5 therefore omitted 4 hybrid method replicator dynamics primaldual escape steps nd local solutions standard qp 1 propose use replicator dynamics readers convenience provide short overview refer detail 7 11 12 consider following dynamical system operating dot signies derivative wrt time discrete time version ng 25 note x0 2 ir n implies since nonnegative assumption stationary points 24 25 coincide local solutions 1 among course quite many stationary points eg vertices however shown 7 x strict local solution x copositive programming standard quadratic optimization problems 13 asymptotically stable ie every solution 24 25 starts close enough x converge x 1 24 25 arise population genetics name selection equations used model time evolution haploid genotypes symmetric tness matrix x representing relative frequency allele population fundamental theorem selection states average tness ie objective function xt axt strictly increasing time along trajectories 13 22 moreover every trajectory xt converges stationary point 31 22 furthermore one prove 7 12 following facts principal minor vanishes probability one trajectory converges strict local solution x 1 ng 6 x contained basin attraction x subset shall denote face corresponding relative interior dynamical systems 24 25 frequently called replicator dynamics well suited implementation practical applications see 40 11 8 ected also theory result 24 eciently approaching xed points sense shahshahani gradient system 44 discrete time version 25 also corresponds particular instance algorithm widely popular computer vision relaxation labeling processes closely related articial neural network learning systems found applications variety practical tasks eg solve certain labeling problems arising 3d interpretation ambiguous line drawings 42 24 39 furthermore dynamics 25 belongs class dynamical systems investigated 1 2 proven useful speech recognition domain 30 although strictly increasing objective values guaranteed follow trajectories 24 25 could get stuck inecient local solution x 1 preceding results necessarily x one possibility escape x genf approach 12 alternative merge replicator dynamics method usual interiorpoint steps borrowed semidenite programming described sequel given escape procedure ready describe principal algorithm solving 1 globally note procedure stops nitely many repetitions since yields strict local solutions every 14 im bomze dur e de klerk c roos quist one strictly increasing objective values replicator dynamics algorithm 1 start n e nearby iterate 25 convergence limit lim t1 xt strict local solution probability one provided principal minors vanish 2 call escape procedure improve objective still possible denote improving point e x 3 repeat 1 starting x ready present combination procedure interiorpoint method yielding improving direction hope possible escape inecient local solutions hybrid algorithm 1 initialisation choose n e nearby put 2 replicator dynamics fast primal updates starting x0 iterate 25 convergence limit strict local solution probability 3 dual update check copositivity ye via shortcuts cf fig 1 6 special case see 10 armative x global solution 1 since duality gap zero cf also theorem 7 7 stop however point e found e x ye aex 0 e x improves objective repeat step 2 starting point else decision keep old value 0 proceed step 4 4 step back boundary choose 0 small point matrix satises b x previous iterate x ax b x abx previously obtained improvement x abx 1 quadratic inequality note construction x positive denite nonnegative square root r copositive programming standard quadratic optimization problems 15 5 since x positivedenite nonnegative square root one choose 21 0 suciently small e properties possible mapping x 7 x holder continuous around x hence primal feasibility e x maintained cf lemma 1 get explicit positive square root factorization e nonnegative thus e 0 x 1g 6 primal update x ax ha xi ha e possible choose e x x always possible ha e repeat step 2 starting following small example illustrates ideas behind hybrid algorithm par ticular example meant illustrate escape strategy steps 4 6 works example 3 let suppose arrived via replicator dynamics starting already suboptimal local solution x improvement x global solution matrix copositive following step 3 hybrid algorithm return old arrive dually feasible ie copositive matrix incidentially coincides optimal see note although neither x interior hx suppose moment ignored step 4 tried proceed directly forming matrix signshall emphasize preliminarity trial escape step along 20 21 key quantities 20 21 9 hence im bomze dur e de klerk c roos quist furthermore therefore dy 9 positivedenite negative odiagonal entries infeasible positive shows step back boundary ie step 4 hybrid algorithm really necessary note ignoring primal feasibility respect one could investigate instead whether vector e belongs ie negative coordinate automatically e improves objective regard latter aim desirable take large possible recall x locally optimal objective quadratic improvement largest largest possible distance one case means considering candidate improving point vector 39 38 indeed manage escape get improvement chosen large enough let us return hybrid algorithm proposed choose eg step 4 09 01 xx 081 009 009 001 well 0748 0072 0072 0108 duality gap slightly increased expected note update part 26 remain dual variable change observe required step 4 choice motivated trial choose large enough enable escape eg arrive positivedenite matrix copositive programming standard quadratic optimization problems 17 hence primal feasibility requirement e met entries latter matrix nonnegative means 0864 1792 0482 typical choice step 5 would 2 cf45 simplicity choose 3 e 06306 00222 00222 03250 int k 07939 00163 00163 05699 h e step 6 hybrid algorithm therefore obtain normalizing last column x objective value e x aex 28912 2 last steps hybrid algorithm follows use improving point e x starting vector replicator dynamics iteration nally leads global solution nal check optimality calculate x 5 conclusions problem maximizing quadratic form simplex exact reformulation copositive programming problem ie conic programming problem cone copositive matrices advantage reformulation successful ideas theory interior point methods thus applied nonconvex quadratic optimization particular primaldual ane scaling directions used escape strategies inecient local solutions obtained local optimization procedures like replicator dynamics r inequality applications statistical estimation probabilistic functions markov processes model ecology complete positivity remarks recursive structure copositivity introduction population genetics theory recursive algorithm detect strict copositivity symmetric matrix completely positive matrices associated matrices exploiting sparsity primaldual interiorpoint methods semide nite programming copositive matrices interiorpoint method semide nite programming theory evolution dynamical systems introduction global optimization foundations relaxation labeling processes nonnegative factorization matrices polynomial primaldual ane scaling algorithms semide nite programming square triangular factorizations completely positive matrices introduction application theory probabilistic functions markov process automatic speech recognition factorizations completely positive matrices copositive matrices de npcomplete problems quadratic linear program ming interior point methods convex programming theory applications new semide dynamics relaxation labeling processes nonconvex allquadratic global optimization problems solution methods scene labeling relaxation operations copositive relaxation general quadratic programming game dynamics notes completely positive matrices tr ctr kurt anstreicher samuel burer dc versus copositive bounds standard qp journal global optimization v33 n2 p299312 october 2005 immanuel bomze etienne de klerk solving standard quadratic optimization problems via linear semidefinite copositive programming journal global optimization v24 n2 p163185 october 2002 immanuel bomze branchandbound approaches standard quadratic optimization problems journal global optimization v22 n14 p1737 january 2002