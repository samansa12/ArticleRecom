efficiency parallel backtracking analytical models experimental results concerning average case behavior ofparallel backtracking presented two types backtrack search algorithms areconsidered simple backtracking use heuristics order prunesearch heuristic backtracking analytical models used comparethe average number nodes visited sequential parallel search case forsimple backtracking shown average speedup obtained linear thedistribution solutions uniform superlinear distribution solutions isnonuniform heuristic backtracking average speedup obtained least linearand speedup obtained subset instances superlinear experimental results formany synthetic practical problems run various parallel machines validate thetheoretical analysis presented b introduction consider problem finding solution statespace tree containing one solutions10 28 26 6 backtracking also called depthfirst search widely used technique solving problems storage efficiency 13 28 throughout paper use two names interchangeably use acronym dfs denote backtracking depthfirst search statespace trees many variants dfs algorithms tuned certain types problems paper deal two important simple backtracking use heuristic information ii heuristic backtracking uses ordering andor pruning heuristics reduce search complexity number parallel formulations dfs developed various researchers12 7 22 2 25 23 one formulation23 n processors concurrently perform backtracking disjoint parts statespace tree parts statespace searched different processors roughly equal sizes actual parts search space searched different processors sequence nodes subspaces visited determined dynamically different different executions result execution sequences parallel version may find solution visiting fewer nodes sequential version thus giving superlinear speedup speedup defined ratio times taken sequential parallel dfs execution sequences may find solution visiting nodes thus giving sublinear speedup type behavior common variety parallel search algorithms referred speedup anomaly 18 19 superlinear speedup isolated executions parallel dfs reported many researchers 12 25 22 7 33 20 may appear average speedup would either linear sublinear otherwise even parallel dfs executed sequential processor via timeslicing would perform better sequential dfs paper considers average case speedup anomalies parallel dfs algorithms based techniques developed 23 17 though simple backtracking heuristic backtracking algorithms analyze use dfs strategy behavior different analyzed separately develop abstract models search spaces traversed two types dfs algorithms analyze compare average number nodes visited sequential search parallel search case simple backtracking show average speedup obtained linear distribution solutions uniform ii superlinear distribution solutions nonuniform heuristic backtracking average speedup obtained least linear ie either linear superlinear speedup obtained subset instances difficult instances superlinear theoretical analysis validated experimental analysis example problems problem generating testpatterns digital circuits3 n gammaqueens 15puzzle26 hackers problem31 result parallel backtrack search gives least linear speedup average important since dfs currently best known practically useful algorithm solve number important problems occurrence consistent superlinear speedup certain problems implies sequential dfs algorithm suboptimal problems parallel dfs timesliced one processor dominates sequential dfs highly significant known search technique dominates sequential dfs problems restricted attention paper statespace search trees dfs algorithms effective searching trees overall speedup obtained parallel dfs depends upon two factors search overhead defined ratio nodes expanded parallel sequential search communication overhead amount time wasted different processors communication synchro nization etc orthogonal sense causes completely different search overhead caused sequential parallel dfs search nodes different order communication overhead dependent upon target architecture load balancing technique communication overhead parallel dfs analyzed previously published papers17 16 4 14 experimentally validated variety problems architectures 1 paper analyze search overhead however experiments run real multiprocessors overheads incurred hence overall speedup observed experiments may less linear ie less n n processors even model predicts parallel search expands fewer nodes sequential search parallel dfs effect communication overhead less significant larger instances ie instances take longer time execute hence larger instances problem obey analyses accurately smaller instances reader keep mind interpreting experimental results presented paper section 2 briefly describe two different kinds dfs algorithms analyzed paper section 3 review parallel dfs simple backtrack search algorithms analyzed section 4 ordered backtrack search algorithms analyzed 5 section 6 contains related research section 7 contains concluding remarks experiments parallel dfs modified find optimal solutions number nodes searched sequential dfs parallel dfs become equal making search overhead 1 2 types dfs algorithms consider problems formulated terms finding solution path implicit directed statespace tree initial node goal node tree generated fly aid successorgenerator function given node tree function generates successors backtracking ie dfs used solve problems follows search begins expanding initial node ie generating successors later step one recently generated nodes expanded problems heuristic information used order successors expanded node determines order successors visited dfs method heuristic information also used prune unpromising parts search tree pruned nodes discarded searching recently generated node successors determined node lead solutions backtracking done recently generated node remaining yet unexpanded nodes selected expansion major advantage dfs storage requirement linear depth search space searched following two search methods use backtrack search strategy 1 simple backtracking depthfirst search method used find one solution uses heuristics ordering successors expanded node heuristics may used prune nodes search space search avoided nodes 2 ordered backtracking depthfirst search method used find one solution may use heuristics ordering successors expanded node may also use heuristics prune nodes search space search avoided nodes method also referred ordered dfs13 3 parallel dfs many different parallel formulations dfs7 15 19 34 2 8 23 suitable execution asynchronous mimd multiprocessors formulation discussed used quite commonly 22 23 2 4 14 formulation processor searches disjoint part search space whenever processor completely searches assigned part requests busy processor work busy processor splits remaining search space two pieces gives one piece requesting processor solution found processor notifies processors search space finite solutions eventually processors would run work search sequential parallel terminate without finding solution backtrack search algorithms search terminates whole search space exhausted ie either searched pruned parallel dfs algorithms analyze theoretically differ slightly description follows simplicity analyses models assumes initial static partitioning search space sufficient good load balancing parallel dfs used experimental results work partitioned dynamically reader see close agreement experiments analyses 4 analysis speedup simple backtracking information 41 assumptions definitions statespace tree leaf nodes solutions occurring among leaf nodes amount computation needed visit leaf node execution time search proportional number leaf nodes visited unreasonable assumption search trees branching factor greater one number nodes visited dfs roughly proportional number leaves visited also section dont model effect pruning heuristic explicitly assume number leaf nodes statespace tree already pruned using pruning function sequential parallel dfs stop finding one solution parallel dfs statespace tree equally partitioned among n processors thus processor gets subtree nodes least one solution entire tree otherwise parallel search sequential search would visit entire tree without finding solution resulting linear speedup information order search statespace tree hence density solutions across search frontier independent order search solution density ae leaf node probability leaf node solution assume bernoulli distribution solutions ie event leaf node solution independent leaf node solution also assume ae 1 wn denotes average total number nodes visited n processors one processors finds solution w 1 average number leaf nodes visited sequential dfs solution found clearly w 1 wn less equal since execution time search sequential well parallel case proportional number nodes expanded wn theta n efficiency e speedup divided n e denotes effective utilization computing resources wn 42 efficiency analysis consider search frontier leaf nodes statically divided n regions leaves let density solutions among leaves th region ae parallel case processor searches region independently one processors finds solution sequential case regions arranged random sequence searched order theorem 41 ae 0 density region number leaves k region large mean number leaves visited single processor searching region 1 ae proof since bernoulli distribution mean number large enough k second term becomes less 1 hence mean number trials aesequential dfs selects one n regions probability 1n searches find solution hence average number leaf nodes expanded sequential dfs 2 ae n 2 given expression assumes solution always found selected region thus one region searched probability solution another region would need searched taking account would make expression w 1 precise increase average value w 1 somewhat reader verify overall results analysis change step parallel dfs one node n regions explored simultane ously hence probability success step parallel algorithm approximately ae 1 neglecting second order terms since ae assumed small hence inspecting equations see w hm hm harmonic mean ae 0 arithmetic mean since know arithmetic mean harmonic mean hm satisfy relation hm w 1 wn particular ffl ae equal solutions uniformly distributed average speedup parallel dfs linear ffl different hm therefore w 1 wn solution densities different regions nonuniform average speedup parallel dfs superlinear assumption event node solution independent event nodes solution unlikely true practical problems still analysis suggests parallel dfs obtain higher efficiency sequential dfs provided solutions distributed uniformly search space information densities different regions available characteristic happens true variety problem spaces searched simple backtracking 43 experimental results present experimental results performance parallel dfs three problems hackers problem 31 ii 15puzzle problem26 iii n gammaqueens problem6 experiments discussed section sequential parallel dfs visit newly generated successors node random order different conventional dfs successors visited statically defined left right order ordered dfs successors visited heuristic order visit successors random order rather lefttoright heuristic order trying validate model assumes heuristic information available order nodes hence random order good 3 get average run time 3 aside reader note ordering information always improve effectiveness dfs example experience ida algorithm 15puzzle problem 11 indicates experiment repeated many times note besides random ordering successors another source variability execution time parallel dfs parts statespace tree searched different processors determined dynamically highly dependent run time events beyond programmers control hence parallel dfs experiment repeated even frequently sequential dfs hackers problem involves searching complete binary tree leaf nodes solution nodes path solution node represents correct password among various binary sequences fixed length may one solution due wild card notation implemented program sequent balance 21000 multiprocessor experimented different cases 16 processors experiments done two different kinds trees one case one solutions distributed uniformly whole search space corresponds case branching points due wild cards tree 1 solutions wild cards exactly one solution case predicted analysis sequential search parallel search approximately amount work hence speed parallel dfs linear case corresponds curve labeled 1 figure 1 efficiency starts decreasing beyond 8 processors communication overhead higher larger number processors second case four solutions distributed uniformly small subspace total space subspace randomly located whole space corresponds case branching point due characters denoted wild cards low tree case expected efficiency parallel dfs greater 1 regions searched different processors tend different solution densities results shown figure 1 fractions indicated next curve denotes size subspace solutions located example 1means curve case solutions located randomly 1of space figure 1 reader would notice peak efficiency r processors case solutions distributed 1 r fraction search space see curves labeled 18 116 happens possible one r processors receive region containing solutions thus giving substantially higher density region compared processors course since search space experiments distributed dynamically best case happens times probability occurrence becomes smaller number processors increases heights peaks successive curves decreasing values 1r also decreasing use manhattan distance heuristic ordering best known admissible heuristic 15puzzle make dfs better hand problems n gammaqueens ordering information improves performance dfs substantially9 32 experiments 15puzzle performed bbn butterfly parallel processor 9 processors experiments involved instances 15puzzle uniform distribution nonuniform distribution solutions depth bounded dfs used limit search space instance sequential dfs parallel dfs executed depthbound equal depth shallowest solution nodes average timings sequential parallel search obtained running experiment 100 times every 15puzzle instance figure 2 shows average speedups obtained instances uniform distribution solutions show near linear speedup maximum deviation speedup indicated banded region width banded region expected reduce lot repetitions say 1000 every instance tried instances nonuniform distribution solutions give superlinear speedups figure 3 show efficiency versus number processors n gammaqueens problem problem naturally known exhibit non uniformity solution density8 data point shown obtained averaging 100 trials see parallel dfs exhibits better efficiency sequential dfs number processors increased fixed problem size efficiency goes overhead parallel execution masks gains due parallel execution expect larger instances problems parallel dfs exhibit superlinear speedup even larger number processors experiments confirm predictions model superlinear speedup occurs parallel dfs density solutions regions searched different processors different linear speedup occurs solutions uniformly distributed whole search space means solution density regions searched different processors parallel number processors n efficiency figure 1 efficiency curves hackers problem efficiency greater 1 indicates superlinear speedup number processors n uniform dist non uniform dist single soln figure 2 speedup curves 15puzzle problem 13queens 16queens 22queens linear speedup number processors n figure 3 efficiency curves nqueens problem 5 speedup parallel ordered depthfirst search 51 assumptions definitions given balanced binary tree depth tree contains 2 nodes 2 leaf nodes 2 solution nodes find one solutions traversing tree using sequential parallel dfs bounding heuristic available makes unnecessary search nonleaf node either following two cases 1 identifies solution reached node even identifies node solution 2 identifies solution exists subtree rooted node thus makes unnecessary search node bounding heuristic succeeds pruning nonleaf node need search node node nonleaf node bounding heuristic succeed search proceeds usual node characterize bounding heuristic success rate 1 gamma ie probability procedure succeeds pruning node purposes discussion shall assume 05 ensures effective branching factor greater 1 05 search complexity becomes insignificant consider balanced binary tree depth k pruned using bounding heuristic let f k number leaf nodes tree clearly f k would 2 k given tree solutions dfs visit f leaf nodes tree one solutions dfs find solution visiting fewer leaf nodes f actual number leaf nodes visited depend upon location left solution tree turn depend upon order successors nodes visited extreme case correct successor node visited first dfs solution found visiting exactly one leaf node left node search tree solution practice ordering heuristic available aids us visiting promising node first postponing visit inferior one necessary later characterize ordering heuristic parameter fl heuristic makes correct choice ordering probability fl ie flfraction time subtree containing solution visited remaining 1 gamma flfraction time subtree containing solution visited obviously makes sense consider 05 means heuristic provides worse information random coin toss 10 ordering perfect solution found visiting 1 leaf node shall refer trees obtrees orderedbounded trees ordering bounding information available reduce search summarize obtrees model search problems bounding andor ordering heuristics available guide search error probability constant reader cautioned problems may necessarily true 52 efficiency analysis analyze average number leaf nodes visited sequential parallel dfs algorithms obtrees let sd average number leaf nodes pruned nodes terminal nodes visited sequential search p sum average number leaf nodes visited processor parallel dfs theorem 51 f proof see proof theorem a1 appendix atheorem 52 sd see proof theorem a2 appendix athus use ordering bounding heuristics sequential dfs cuts effective size original search tree large factor bounding heuristic reduces effective branching factor 2 approximately 2 ordering heuristic reduces overall search effort factor 1 gamma fl even though obtrees complete binary trees backtrack algorithm uses pruning heuristic reduces branching factor less 2 lets consider number nodes visited parallel dfs clearly bounding heuristic used parallel dfs effectively used sequential dfs however might appear parallel dfs cannot make good use ordering heuristic one processors work promising part space whereas processors work less promising parts following theorem says intuition wrong theorem 53 obtrees parallel dfs expands nodes average sequential dfs proof first consider two processor parallel dfs later generalize result twoprocessor parallel dfs tree statically partitioned root processors search two trees depth independently least one succeeds individually performs sequential dfs help bounding pruning heuristics note though second processor violates advice ordering heuristic root node follows advice everywhere else consider case root node pruned bounding heuristic two possible cases case 1 solution exists left subtree case happens flfraction time case sequential dfs visits sd gamma 1 leaf nodes average whereas parallel dfs visits 2sd gamma 1 leaf nodes left subtree also solution parallel dfs visits exactly 2sd gamma 1 leaf nodes average otherwise subtrees solution average work done parallel dfs smaller case 2 solution exist left subtree ie exists right subtree case happens 1gammaflfraction time case sequential dfs visits f dgamma1sdgamma1 leaf nodes average whereas parallel dfs visits exactly 2sd gamma 1 leaf nodes thus flfraction time parallel dfs visits sd gamma 1 extra nodes 1 gamma fl fraction time visits f nodes sequential dfs hence average ignoring case solution found root 4 0 theorem a2 result extended case 2 processors performing parallel search following theorem theorem 54 p number nodes expanded parallel search 2 processors 0 p p agamma1 proof theorem compares search efficiency 2 agamma1 processors used 2 processors used first case entire search tree split 2 agamma1 equal parts near root part searched one processor 4 root pruned ignore difference p sd tree one node second case split two equal parts two processors share work one processor used let us compare number nodes expanded one processor first case corresponding pair processors second case know subtree dealing obtree fore theorem 53 shows pair processors much work single processor first case summing 2 agamma1 parts whole tree theorem follows induction theorem shows p sd holds case 2 k processors performing parallel search521 superlinear speedup hard solve instances theorem 53 following important consequence partition randomly selected set problem instances two subsets one subset average speedup sublinear average speedup one superlinear one partition according correctness ordering near root let us call instances ordering heuristic makes correct decision near root easytosolve instances others hardtosolve instances sequential dfs easytosolve instances take smaller time solve hardtosolve instances 2processor case easytosolve instances flfraction total instances ordering heuristic makes correct decisions root parallel version obtains average speedup 1 ie speedup remaining instances average speedup roughly 2gammafl arbitrarily high depending upon close fl 1 2 processors easiest solve instances fl fraction total instances sequential search makes correct decision first branches starting root maximum superlinearity available hardest solve instances fraction total instances 53 experimental results problem chose experiment test generation problem arises computer aideddesign cad vlsi problem automatic test pattern generation atpg obtain set logical assignments inputs integrated circuit distinguish faulty faultfree circuit presence set faults input pattern said test given fault presence fault produces output different faulty faultfree circuits studied sequential parallel implementations algorithm called podem pathoriented decision making 3 used combinational circuits sequential circuits based levelsensitive scan design approach one successful algorithms problem widely used number faults possible circuit proportional number signal lines known sequential algorithm able generate tests 90 faults reasonable time spends enormous amount time much 90 execution time trying generate tests remaining faults result execution algorithm terminated fails generate test predefined number node expansions backtracks faults cannot solved reasonable time serial algorithm called hardtodetect htd faults27 practice important generate tests many faults possible higher fault coverage results reliable chips atpg problem fits model analyzed well following reasons search tree generated binary ii nonredundant fault problem typically one small number solutions iii good imperfect ordering heuristic available iv bounding heuristic available prunes search node either pruned node solution longer lead solutions experiments atpg problem support analysis hardtosolve stances parallel algorithm shows superlinear speedup implemented sequential parallel versions podem 128 processor symult 2010 multiprocessor performed experiment using iscas85 benchmark files test data details implementation experimental results found 1 experiments conducted follows htd faults first filtered picking faults seven files whose test patterns could found within 25 backtracks using sequential algorithm serial parallel podem algorithms used find test patterns htd faults since htd faults may solvable sequential andor parallel podem algorithm reasonable time upper limit imposed total number backtracks sequential parallel algorithm could make sequential parallel algorithm exceeded limit sum backtracks made processors counted parallel case algorithm aborted fault classified undetectable backtrack limit time taken purely sequential podem parallel podem used compute speedup results shown figure 4 circuit iscas85 benchmark experiments 25600 used upperlimit backtracks test variation superlinearity hardness faults selected two sets faults first set consisted faults serial algorithm able solve executing total number backtracks node expansions range 16006400 similarly number processors speedup figure 4 speedup curves atpg problem second set faults solved serial algorithm backtrack range 640025600 faults second set thus harder solve serial algorithm two seven files namely c499 c1355 yield faults either two sets executed parallel algorithm 16 128 processors averaged speedups obtained given number processors separately two sets faults runtime fault average obtained 10 runs results shown figure 5 results clear superlinearity increases increasing hardness instances degree superlinearity decreases increasing number processors efficiency parallel dfs decreases problem size fixed number processors increased16 note experimental results validate discussion section 521 validate theorem 53 would necessary find number nodes expanded parallel dfs even easy detect faults faults experimental run time roughly proportional number nodes searched parallel dfs small trees communication overhead becomes significant superlinearity hardtodetect faults experimentally observed atpg heuristics patil banerjee 27 6 related research occurrence speedup anomalies simple backtracking studied 22 8 monien et al22 studied parallel formulation dfs solving satisfiability problem formulation processor tries prove satisfiability different subformula input formula due nature satisfiability problem subformulas leads search space different average density solutions differing solution densities responsible average superlinear speedup context model monien et al showed possible obtain average superlinear speedup sat problem analysis simple backtracking section 4 done similar model results general stronger also analyzed average case behavior parallel simple backtracking 24 theoretical results present much stronger 24 24 showed regions searched processors solutions uniformly distributed regions searched rest processors solutions average speedup parallel backtracking would superlinear analysis section 4 shows nonuniformity solution densities among regions searched different processors leads superlinear speedup average two types heuristic dfs algorithms discuss outside scope 22 24 160064003282251751257525number processors figure 5 speedup curves hardtosolve instances atpg problem search space searched random fashion ie newly generated successors node ordered randomly number nodes expanded solution found random variable lets call t1 one simple parallel formulation dfs presented 21 8 let search space searched many processors independent random order one processors finds solution total number nodes expanded processor formulation random variable lets call tn clearly g v random variable average value tn less 1 times t1 also expect superlinear speedup21 8 certain distributions t1 happens case example probability finding solution level statespace tree property21 note parallel formulation dfs dominates one 21 8 terms efficiency parallel formulation duplication work hence parallel formulation exhibit superlinear speedup search space formulation 21 8 exhibits superlinear speedup converse true certain problems probabilistic algorithms29 5 perform substantially better simple backtracking example happens problems statespace tree balanced binary tree like hackers problem discussed section 43 overall density solutions among leaf nodes relatively high solutions distributed nonuniformly probabilistic search performs better simple backtracking problems make density solutions leaf nodes look virtually uniform reader infer analysis section 4 kinds search spaces parallel dfs also obtains similar homogenization solution density even though processor still performs enumeration part search space domain applicability two techniques probabilistic algorithms vs sequential parallel dfs however different depth leaf nodes tree varies probabilistic search algorithm visits shallow nodes much frequently deep nodes statespace tree many problems n gammaqueens problem shallow nodes correspond failure nodes solution nodes located deep tree problems probabilistic algorithms perform well simple backtracking visit failure nodes frequently note simple backtracking visit failure node exactly density solutions among leaf nodes low expected running time probabilistic algorithm also high extreme case solution probabilistic search never terminate whereas simple backtracking parallel dfs cases also enumerative search algorithm simple backtracking 5 probabilistic algorithm state space search obtained generating random walks root node leaf nodes solution found superior probabilistic algorithm parallel variant retains advantages homogenization ordered dfs randomized parallel dfs algorithms given 21 8 perform poorly able benefit ordering heuristics probabilistic algorithms weakness decision problems analysis section 5 shows utilization ordering heuristic cuts search large factor sequential dfs parallel dfs case optimization problems ie interested finding leastcost solution randomized parallel dfs algorithms 21 8 well probabilistic algorithms useful one cannot guarantee optimality solution unless exhaustive search performed saletore kale 30 present parallel formulation dfs quite different ones 22 23 2 formulation explicitly ensures number nodes searched sequential parallel formulations nearly equal results paper apply parallel dfs 5 general model explaining occurrence superlinear speedups variety search problems presented shown parallel algorithm performs less work corresponding sequential algorithm superlinear speedup possible paper identified analyzed problems indeed case conclusions presented analytical models theoretical results characterizing average case behavior parallel backtrack search dfs algorithms showed average parallel dfs show deceleration anomalies two types problems also presented experimental results validating claims multiprocessors identified certain problem characteristics lead superlinear speedups parallel dfs problems characteristics parallel dfs algorithm better sequential dfs algorithm even timesliced one processor isolated occurrences speedup anomalies parallel dfs reported earlier various researchers experimental analytical results showing possibility superlinear speedup average exception results 22 24 available parallel dfs number questions need addressed research problems sequential dfs dominated parallel dfs search technique best possible sequential search algorithm one derived running parallel dfs one processor time slicing mode yes optimum number processors emulate mode case ordered backtrack search showed parallel search efficient hardtosolve instances sequential search efficient easytosolve instances practice one therefore use combination sequential parallel search optimal combination paper analyzed efficiency parallel dfs certain models would interesting perform similar analysis models also parallel formulations backtrack search given 7 30 acknowledgements would like thank sunil arvindam hang ng helping us experiments would also like thank dr james c browne dr vineet singh many helpful discussions appendices details analysis ordered dfs algorithms theorem a1 f proof clear f 1 consider case k 0 root node pruned thus f 1 remaining probability root node pruned 2 successors case f hence bounding heuristic succeeds root dfs visits one leaf otherwise visits left subtree root fl fraction time visits left subtree unsuccessfully visits right subtree fraction time hence 1 moderate suffices hence using theorem a1 simplify previous assumption 1 d1 term ignored term becomes negligible larger 05 say 055 thus theorem a3 error ignored smallin twoprocessor parallel depthfirst search tree statically partitioned root processors search two trees depth d1 independently least one succeeds individually performs sequential dfs consulting three wise oracles note though second processor violates advice ordering heuristic root node follows advice everywhere else hence time root pruned prune liberal convention two nodes expanded parallel search otherwise two obtrees depth d1 searched two nodes expanded step one processors succeed inequality arises average minimum two trials minimum two averages formula sd using theorem a1 error ignored less 1 theorem a1 inequality becomes equality restrict one solution entire search tree theorem a4 average parallel search visits number nodes sequential search large randomly selected set problem instances single solutions proof see arguments r automatic test pattern generation multiprocessors implicit enumeration algorithm generate tests combinatorial logic circuits experimental evaluation load balancing techniques hypercube modeling speedup n greater n fundamentals computer algorithms parallel searching scheme multiprocessor systems application combinatorial problems randomized parallel algorithms prolog programs backtracking applications perfect heuristic n nonattacking queens problem search artificial intelligence personal communication use parallelism implement heuristic search scalable load balancing techniques parallel computers parallel branchandbound formulations andor tree search scalable parallel formulations depthfirst search parallel depthfirst search anomalies parallel branch bound algorithms wah computational efficiency parallel approximate branchandbound algorithms shared virtual memory system parallel computing superlinear speedup randomized algorithms superlinear speedup parallel back tracking parallel depthfirst search superlinear speedup statespace search parallel implementation iterativedeepeninga principles artificial intelligence parallel branchandbound algorithm test generation probabilistic algorithms consistent linear speedup first solution parallel statespace search average complexity depthfirst search backtracking cutoff efficient search techniques empirical study nqueens problem performance pragmatics orparallel logic programming system tr heuristics intelligent search strategies computer problem solving average complexity depthfirst search backtracking cutoff dibmyampersandmdasha distributed implementation backtracking principles artificial intelligence performance orparallel logic programming system parallel depth first search part implementation parallel depth first search part ii analysis search artificial intelligence almost perfect heuristic italicnitalic nonattacking queens problem scalable parallel formulations depthfirst search anomalies parallel branchandbound algorithms fundamentals computer alori automatic test pattern generation multiprocessors superlinear speedup parallel statespace search ctr jung krishnamoorthy george nagy andrew shapira ntuple features ocr revisited ieee transactions pattern analysis machine intelligence v18 n7 p734745 july 1996 finkelstein shaul markovitch ehud rivlin optimal schedules parallelizing anytime algorithms case independent processes eighteenth national conference artificial intelligence p719724 july 28august 01 2002 edmonton alberta canada fumiaki okushi parallel cooperative propositional theorem proving annals mathematics artificial intelligence v26 n14 p5985 1999 james cheetham frank dehne andrew rauchaplin ulrike stege peter j taillon solving large fpt problems coarsegrained parallel machines journal computer system sciences v67 n4 p691706 december ariel felner sarit kraus richard e korf kbfs kbestfirst search annals mathematics artificial intelligence v39 n12 p1939 september daniel j challou maria gini vipin kumar george karypis predicting performance randomized parallel application robot motion planning journal intelligent robotic systems v38 n1 p3153 september g karypis v kumar unstructured tree search simd parallel computers summary results proceedings 1992 acmieee conference supercomputing p453462 november 1620 1992 minneapolis minnesota united states weiming lin wei xie bo yang performance analysis parallel solutions generic search problems proceedings 1997 acm symposium applied computing p422430 april 1997 san jose california united states andrea di blas arun jagota richard hughey optimizing neural networks simd parallel computers parallel computing v31 n1 p97115 january 2005 g karypis v kumar unstructured tree search simd parallel computers ieee transactions parallel distributed systems v5 n10 p10571072 october 1994 ananth grama vipin kumar state art parallel search techniques discrete optimization problems ieee transactions knowledge data engineering v11 n1 p2835 january 1999 peter krauss andreas ganz kurt j antreich distributed test pattern generation stuckat faults sequential circuits journal electronic testing theory applications v11 n3 p227245 dec 1997 lucas bordeaux youssef hamadi lintao zhang propositional satisfiability constraint programming comparative survey acm computing surveys csur v38 n4 p12es 2006