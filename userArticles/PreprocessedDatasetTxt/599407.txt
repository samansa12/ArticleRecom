stable local computation conditional gaussian distributions article describes propagation scheme bayesian networks conditional gaussian distributions numerical weaknesses scheme derived lauritzen journal american statistical association 87 10981108 1992the propagation architecture lauritzen spiegelhalter journal royal statistical society series b 50 157 224 1988in addition means variances provided previous algorithm new propagation scheme yields full local marginal distributions new scheme also handles linear deterministic relationships continuous variables network specificationthe computations involved new propagation scheme simpler previous scheme method implemented recent version hugin software b introduction bayesian networks developed important tool building systems decision support environments characterized uncertainty pearl 1988 jensen 1996 cowell et al 1999 exact computational algorithms developed concerned networks involving discrete variables research report r992014 department mathematical sciences aalborg university lauritzen 1992 developed computational scheme exact local computation means variances networks conditional gaussian dis tributions unfortunately scheme turned fatal numerical difficulties basically due computationally unstable transformation two different representations distributions motivation present work remedy numerical insta bility fundamental idea behind developments times keep interesting quantities represented units direct meaning probabilities means regression coefficients variances must necessarily reasonable order magnitude computational scheme developed rather remote computational architecture used deal discrete variables hugin software similar schemes represented example abstract form shenoy shafer 1990 lauritzen jensen 1997 difference partly related fundamental operations combination marginalization partially defined also handling evidence quite different scheme closest original scheme developed lauritzen spiegelhalter 1988 abstract considerations shafer 1991 seem necessary embed scheme unifying framework additional benefits present scheme includes deterministic linear relationships continuous variables represented without difficulty show calculate full local marginals continuous variables without much computational effort represent major improvements original scheme lauritzen 1992 distributions regressions bayesian networks considered distributions conditionally gaussian family distributions introduced lauritzen wermuth 1984 1989 shall briefly review standard notation otherwise refer reader lauritzen 1996 details set variables v partitioned variables discrete delta continuous gamma type joint distribution continuous variables given discrete assumed multivariate gaussian ie denotes continuous variables discrete jgammaj denotes cardinality gamma sigmai positive semidefinite say follows cg distribution symbol n jgammaj sigma denotes multivariate gaussian distribution mean covariance matrix sigma case sigma positive definite distribution density 2 jgammaj det sigma exp sigma singular multivariate gaussian distribution density implicitly determined property vector v linear combination v univariate gaussian distribution interpreted distribution degenerate see example rao 1973 chapter 8 description gaussian distribution level generality note slight difference terminology used lauritzen 1996 allow pi equal 0 entries also avoid using socalled canonical characteristics cg distribution numerical instability scheme lauritzen 1992 associated switching moment characteristics additional benefit allow singular covariance matrices sigma occasionally interest describe cg distribution depends additional variables dependence set discrete variables j vector continuous variables z determined refer dependence simple cg regression note neither covariance matrix discrete part depends continuous variables z conditional expectation continuous variables depends linearly continuous variables fixed values discrete variables j general cg regression p also permitted depend z specific way lauritzen 1996 relevant 3 mixed bayesian networks consider probabilistic networks directed acyclic graph dag known bayesian networks pearl 1986 mixed bayesian network conditional gaussian distributions specified set nodes variables discrete continuous variables dag associated network must satisfy restriction discrete nodes continuous parents conditional distributions discrete variables given discrete parent variables specified usual whereas conditional distribution continuous variables given cg regressions note onedimensional fli nonnegative real number distribution specifies linear deterministic dependence z assumptions imply joint distribution variables bayesian network cg distribution computational task addressed computing joint distribution interesting subsets variables particular single variable possibly given specific evidence ie given known values arbitrary subsets variables network distribution general mixture conditional gaussian distributions propagation scheme described involves usual steps construction junction tree strong root initialization junction tree incorporation evidence local computation marginals cliques 4 potentials operations 41 cg potentials basic computational object cg potential cg potential represented partitioning continuous variables domain oe head tail h denote variables head tail z assume r sdimensional arbitrary configuration discrete variables domain denoted thus every potential domain discrete nodes head nodes tail nodes could absent expression table nonnegative numbers ie usual potential discrete case table r theta 1 vectors fbig table r theta matrices table r theta r positive semidefinite symmetric matrices potential represented p b ch specifies cg regression abstract notion potentials head tail due shafer 1991 many ways would natural also partition discrete variables head tail variables reflecting potentials always represent conditional distribution head variables given tail partitioning discrete variables exploited propagation scheme chosen propagation scheme type madsen jensen 1998 could exploit partitioning initial conditional distribution continuous variable v parent nodes pav mixed bayesian network corresponds cg potential domain equal pav delta similarly specification conditional distribution discrete variable given parents corresponds cg potential p gamma gamma gammagamma j gamma p determined conditional probability tables discrete part domain equal family hyphens indicate corresponding parts potential void 42 extension reduction cg potential extended adding discrete variables domain continuous variables tail adding discrete variables domain parts oe extended p adding continuous variables tail b matrices extended adding zero columns new tail variables similarly b columns identically zero values corresponding variables removed tail potential say tail reduced columns b identically zero tail potential said minimal 43 marginals propagation scheme lauritzen 1992 marginals cg potential defined certain conditions marginals groups discrete continuous variables calculated marginals continuous variables calculated first marginals continuous variables calculated head variables p b ch corresponding partitioning head variables marginal oe say marginals strong correspond calculating ordinary marginals relevant conditional gaussian distributions head variables removed marginalization tail reduced become empty discrete potential emerges leads indirectly marginalization tail variables marginals discrete variables defined tail potential empty ie continuous conditioning variables therefore b matrix marginal cg potential gamma discrete domain partitioned u w w ae oe marginalization said weak correspond calculating full marginal distribution general full marginal distribution discrete mixture cg distributions distribution represented weakly marginalized potential cg distribution closest kullbackleibler distance true marginal see lauritzen 1996 lemma 64 44 direct combination combination operation cg potentials defined arbitrary pair potentials scheme quite different propagation schemes direct combination two cg potentials defined head disjoint domain oe ie satisfies always assume potentials first reduced tails minimal 1 fulfilled reduced potentials subsequently extended extensions done extending next let corresponding h define direct combination apparently noncommutative product combination operation corresponds ordinary composition conditional distributions note oe omega omega oe exist equal direct combination also satisfies omega omega omega sense combinations one side well defined side resulting potentials shafer 1991 called type algebraic structure partial commutative semigroup notation reflects operation direct combination sense similar forming disjoint union sets unfortunately direct combination cg potentials sufficient propagation scheme work arbitrary mixed bayesian network define general combination need introduce notion complement 45 complements head cg potential partitioned p strong marginal oe define complement oe jh1t cg potential q e f gh denotes arbitrary generalized inverse matrix penrose 1955 ie arbitrary matrix gamma satisfying see also rao 1973 pp 2427 rao mitra 1971 easily checked using formulae combination together 2 fact generalized inverse 11 c 11 also holds see eg rao 1973 formula 8a212 note expressions either p decomposition potential strong marginal complement corresponds exactly decomposition probability distribution marginal conditional 46 recursive combination next define general combination cg potentials required initialization process described section consider two potentials minimal tails h combination remain undefined heads potentials disjoint let omega omega oe least one righthandside expressions defined oe omega oe defined ambiguity definition neither direct combinations defined must let empty combination defined else decompose one factors say oe assuming 12 6 omega oe 00 attempt combine oe equation understood recursively sense procedure described repeated product oe 0omega whereas direct combination expression well defined construction recursion terminates unsuccessfully two potentials minimal tails satisfy 3 also combination oe remains undefined initialization setting computational structure involves several steps forming strong junction tree strong root assigning potentials cliques transforming potentials specific form sending messages first towards root away root junction tree strong root constructed usual way see example cowell et al 1999 chapter 7 thus assume begin computational scheme point specified mixed bayesian network associated junction tree cliques c root neighbouring cliques c c closer root ie residual n c contains discrete variable separator consists discrete variables also holds variables v fav contained clique junction tree 51 assignment potentials cliques every cg potential corresponding specification conditional distribution node given parents assigned arbitrary clique junction tree contains family potentials assigned given clique subsequently combined order always done using direct combination dag acyclic continuous node head exactly one potential 52 collecting messages root next step initialization process involves sending messages leaves junction tree towards root way similar process known collectevidence standard hugin architecture jensen et al 1990 although messages sent slightly different thus clique allowed send message leaf junction tree received messages neighbours away root process stops root received messages neighbours use term collect operation collectmessage sent clique c neighbour towards root separator potentials oe c c oe modified become oe c oe oe domega oe ie oe c complement oe c marginalization separator oe obtained combining original potential marginal oe c remains argued combination 6 indeed well defined see first realize heads two potentials combined must necessarily disjoint variable occurs head potentials involved 6 holds tail variables parents dag induced conditional specifications combined possibly marginalized form potential thus potential reduced minimal tail must directed path every variable present tail potential variable head potential holds tail variable u conditionally independent head given remaining tail variables thus must trail dconnects u variable head tail variables parents trail must initially directed away u leave tail immediately tail variables conditioning set headtohead nodes active trail must form directed path u head assume 4 satisfied h 1 h 2 nonempty implies deduce must directed path every variable u implying v must directed path variable w thus every u directed path nonempty finite would contradict acyclicity dag illustrate recursive combination necessary initialization process consider two simple examples example 1 consider dag figure 1 potentials assigned cliques nodes c e must assigned fb c eg remaining nodes fa b c dg combining potentials two cliques leads potentials head tail fc eg j fbg fb c eg fb dg j fcg fa b c dg first marginalized separator fb cg result head tail fcg j fbg cannot directly combined potential root clique fa b c dg e figure 1 mixed bayesian network associated junction tree variable discrete variable strong root fa b c dg root clique potential decomposed potentials head tail fdg j fb cg fbg j fcg latter reduced fbg j gamma dependence c spurious potentials combined directly 2 example potential receiving clique decomposed combined potentials receiving clique combining incoming message combination could performed directly next example illustrates may incoming message needs decomposed way avoid computation decomposition example 2 consider dag figure 2 potentials assigned cliques nodes e f must assigned fc e fg c fa c eg b fa b dg two choices node choose assign clique fa b dg also chosen root collecting towards root first message fc eg marginal potential fc e fg must calculated combining assigned potentials one head tail fd e fg j fcg marginalizing fd eg j fcg cannot directly combined potential neighbouring clique head tail fcg j feg incoming potential decomposed potentials head tail fdg j fc eg feg j fcg latter reduced feg j gamma dependence c spurious potentials combined directly 2 root received messages neighbours root potential contains correct root marginal tail empty evidence incorporated normalization discrete part root potential may necessary see section 7 e f figure 2 mixed bayesian network associated junction tree variable discrete variable strong root could chosen either fa b dg fa c eg also potential oe representing joint distribution variables equal combination clique potentials oe c fact marginals computed collect phase strong holds subset c 0 c contains root r forms connected subtree junction tree complements stored cliques collect separators playing specific role process computation similar process forming set chain lauritzen spiegelhalter 1988 thus inward computation type called lauritzenspiegelhalter architecture shafer 1996 see also lauritzen jensen 1997 53 distributing messages root first step calculation marginals involves sending messages away root similar distributeevidence standard hugin architecture root begins sending messages neighbours clique allowed send message soon received one neighbour closer root use term distribute process slightly different messages standard hugin architecture distributemessage sent clique c neighbour away root separator c received message neighbour towards root make inductive assumption separator 0 towards root contains weak clique marginal joint potential sending message new potential oe created follows first weak clique marginal c calculated formula correct seen exactly lauritzen 1992 next potential marginalized separator combination well defined collect operation complements stored cliques head oe c disjoint 0 weak marginal well defined tail oe c contained head oe 0 implying combination 9 empty tail distribute separators contain weak marginals separator nodes note chosen store weak clique marginals calculated distribute preferred keep original complement potentials minor variation lauritzenspiegelhalter architecture initialization process completed cliques junction tree contain complement potentials separators contain weak marginals joint potential joint potential recovered 7 6 computation marginals junction tree initialized described previous section various types marginals easily calculated 61 marginals variables single clique stored separately weak clique marginals always recalculated 9 needed marginalized subsets cliques particular single nodes circumstances weak marginals happen strong give correct full marginal distribution variables involved clearly true desired marginal involves discrete variables cases interest true already mentioned root clique contains correct full marginal distribution variables thus example true marginal set continuous variables root clique easily calculated gaussian discrete mixture weights pi ie root potential p gamma marginalization easily performed holds clique c satisfies slightly less restrictive condition tail potential empty example case separator clique c towards root contains discrete variables see argue follows 8 true marginal union cliques path root c given combination relevant potentials cliques path c continuous variables c conditionally independent remaining discrete variables path given separator variables tail potential c assumed empty also holds given discrete separator variables proposition 63 lauritzen 1996 yields weak marginal c also equal full marginal proceed root clique 62 rearranging junction tree obtain marginal set variables subset clique junction tree obtain strong marginals group variables single variable clique potential empty tail junction tree must rearranged fortunately simple operation used achieve necessary rearrangement denote push acts group variables contained clique w neighbour u towards root corresponding separator operation push appplied variables 1 potential oe w decomposed omega 2 clique u extended u 3 potentials changed omega omega push operation variables come closer strong root extended junction tree still represents joint potential initialization price paid clique u increased u example 3 illustrate push operation using mixed bayesian network figure 2 assuming chosen fa b dg root initialization clique fa c eg contains potential representing conditional distribution variables fc eg given fa dg head tail fc eg j fdg use push fcg potential decomposed marginal head tail fcg j fdg complement head tail feg j fc dg root clique extended variable c marginal combined root potential whereas complement kept clique fa c eg 2 63 marginals variables different cliques weak marginal desired set variables subset clique original junction tree first form smallest connected subtree original junction tree contains variables let c clique subtree closest strong root original junction tree repeated use push operation eventually achieve variables question become members c desired weak marginal computed directly using 9 64 strong marginals strong marginal group variables desired push operation yields appropriate rearrangement junction tree computation weak marginals first form smallest connected subtree original junction tree contains variables let c clique subtree closest strong root r original junction tree use push operation make variables question become members c c performing push operations potential empty tail compute desired strong marginal potential c 10 otherwise need push variables question closer r eventually variables contained clique potential empty tail potential clique compute desired potential 10 necessary may need push variables way r calculation strong marginal single continuous variable important special case discussion follows marginal calculated limited additional effort since potential junction tree extended single continuous variable part calculation 7 incorporating evidence point assume initialization process completed cliques junction tree contain complements separators contain weak marginals discrete evidence incorporated usual matter necessary insert discrete evidence one clique describe incorporate continuous evidence first realize every continuous node necessarily appears head exactly one clique clique appears closest strong root clique potentials appears must tail node also u w neighbouring cliques u closest root continuous variables separator constitute superset tail potential complement stored w convenient incorporate evidence continuous nodes single node time evidence must entered cliques appears assume clique 2 appears head potential empty tail case use push operation described subsection 62 achieve proceed follows 1 cliques 2 tail node tail clique potential decreased 2 p c unchanged b changed removing column b 2 corresponding 2 modified become 2 clique 2 head node partition head nodes marginalization potential inserted evidence denoted oe obtained h removing 2 tail thus b empty distinguish two cases j c 22 j let ae p 0 let b else let 2c22 p 0 let intuitively operation reflects deterministic explanation evidence c 22 infinitely likely nondeterministic one available calculation case 2a simply based upon fact whereas standard density calculation appropriate case 2b correctness operation formally proved small calculation elementary probability simplicity give argument case 1 void let qi j denote kernel obtained normalizing p let dependence explicit ie need show interval real line q satisfies relation z marginal distribution ie j denoting normal distribution nfaj cjg degenerate aj c 22 z ae thus get z ae p ae c 22 0 similarly get z z z piece continuous evidence inserted representation still complement representation insertion next f figure 3 bayesian network strong junction tree waste incinerator example variables w type waste f filter state b burn ing regimen metals waste e filter efficiency c co 2 emission emission dust emission metals l light penetrability variables w f b discrete piece evidence take place evidence inserted collect towards root initialization collection involve proper computations discrete part potentials normalizer root clique equal joint density evidence example 4 final example waste example described lauritzen 1992 cowell et al 1999 section 77 refer either details numerical specifications example concerned control emission heavy metals waste incinerator emission waste incinerator differs compositional differences incoming waste another important factor waste burning regimen monitored measuring concentration co 2 emission filter efficiency depends technical state electrofilter amount composition waste emission heavy metals depends concentration metals incoming waste emission dust particulates general emission dust monitored measuring penetrability light essence description represented bayesian network figure 3 also shows junction tree strong root chosen either fb cg fb f weg one way assign potentials corresponding continuous variables cliques junction tree c assigned fb cg fb wedg e fb f weg l g exactly one potential involving continuous variables assigned clique continuous components potentials become corresponding continuous components clique potentials initialized strong junction tree collect operation particular junction tree change continuous components clique potentials initialization process incorporation evidence c e done without invoking push operation since variables appear either head root clique discrete separator towards root incorporating evidence requires pushed fb f weg unless evidence e already incorporated similarly incorporation evidence l require pushing l fb f weg unless separator along path fl dg fb f weg made empty fully discrete incorporation evidence andor e incorporation evidence clique fw dm g potential head fm g empty tail incorporating evidence point therefore done without invoking push operation hand evidence incorporated potential clique fw dm g head tail fm g j fdg incorporating evidence point require pushing closer fb f weg incorporation evidence pushing fw dm g unless evidence incorporated similar considerations apply finding full mixture distributions individual continuous variables figures 4 5 display full mixture distributions continuous variables incorporation information waste industrial type l measured 11 c gamma09 2 figure 4 screendumps hugin software displaying full marginals continuous variables waste incinerator example evidence incorporated figure 5 screendumps hugin software displaying full marginals remaining continuous variables waste incinerator example inserting evidence waste industrial type l measured 11 c gamma09 acknowledgements first author benefited conversations glenn shafer concerning development abstract theory local computation research partly supported danish research councils pift programme anders l madsen provided helpful comments draft version paper lars nielsen prepared hugin screendumps shown figures 4 5 r probabilistic networks expert systems introduction bayesian networks bayesian updating causal probabilistic networks local computation propagation probabilities graphical models local computation valuations commutative semigroup local computations probabilities graphical structures application expert systems discussion mixed interaction models graphical models associations variables annals statistics lazy propagation junction trees probabilistic reasoning intelligent systems generalized inverse matrices linear statistical inference applications john wiley sons axiomatic study computation hypertrees probabilistic expert systems axioms probability belief function propagation netherlands tr ctr anders l madsen empirical evaluation possible variations lazy propagation proceedings 20th conference uncertainty artificial intelligence p366373 july 0711 2004 banff canada thiesson david maxwell chickering david heckerman christopher meek arma timeseries modeling graphical models proceedings 20th conference uncertainty artificial intelligence p552560 july 0711 2004 banff canada robert g cowell local propagation conditional gaussian bayesian networks journal machine learning research 6 p15171550 1212005 david barber expectation correction smoothed inference switching linear dynamical systems journal machine learning research 7 p25152540 1212006 martin neil manesh tailor david marquez inference hybrid bayesian networks using dynamic discretization statistics computing v17 n3 p219233 september 2007