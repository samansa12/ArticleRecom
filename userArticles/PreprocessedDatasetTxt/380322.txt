efficient local search dag scheduling abstractscheduling dags multiprocessors one key issues highperformance computing realistic scheduling algorithms heuristic heuristic algorithms often room improvement quality scheduling algorithm effectively improved local search paper present fast local search algorithm based topological ordering compaction algorithm effectively reduce schedule length produced dag scheduling algorithm thus improve quality existing dag scheduling algorithms algorithm quickly determine optimal search direction thus low complexity extremely fast b introduction scheduling computations onto processors one crucial components parallel processing environment performed compiletime runtime scheduling performed compiletime called static scheduling scheduling performed runtime called dynamic scheduling exibility inherent dynamic scheduling allows adaptation unforeseen appli cations requirements runtime however load balancing suers runtime overhead due load information transfer among processors load balancing decisionmaking process communication delay due task relocation furthermore runtime scheduling algorithms utilize neither characteristics information application problems global load information load balancing decision major advantage static scheduling overhead scheduling process incurred compile time resulting ecient execution time environment compared dynamic scheduling static scheduling utilize knowledge problem characteristics reach wellbalanced load consider static scheduling algorithms schedule edgeweighted directed acyclic graph dag also called task graph macrodata ow graph set homogeneous processors minimize completion time since static scheduling problem npcomplete general forms 6 optimal solutions known restricted cases 3 5 7 considerable research eort area resulting many heuristic algorithms 19 24 4 25 20 2 14 paper instead suggesting new scheduling algorithm present algorithm improve scheduling quality existing scheduling algorithms using fast local search technique algorithm called task topological assignment scheduling kernel systematically minimizes given schedule topological order move dynamic cost node used quickly determine search direction eectively reduce length given schedule paper organized follows next section review dag scheduling algorithms section 3 local search technique described random local search algorithm discussed section 4 section 5 propose new local search algorithm task performance data comparisons presented section 6 finally section 7 concludes paper scheduling directed acyclic graph dag consists set nodes fn 1 connected set edges denoted e ij node represents task weight node n wn execution time task edge represents message transferred one node another node weight edge e ij ij equal transmission time message communicationtocomputation ratio ccr parallel program dened average communication cost divided average computation cost given system dag node parent called entry node whereas node child called exit node node cannot start execution gathers messages parent nodes static scheduling number nodes number edges node weight edge weight assumed known program execution weight two nodes assigned processing element pe assumed zero objective static scheduling assign nodes dag pes schedule length makespan minimized without violating precedence constraints many approaches employed static scheduling classical approach 13 also called list scheduling basic idea make priority list nodes assign nodes one one pes scheduling process node highest priority chosen scheduling pe allows earliest start time selected accommodate node reported scheduling algorithms based concept employing variations priority assignment methods hlf highest level first lp longest path lpt longest processing time cp critical path 1 24 15 following review contemporary static scheduling algorithms including mcp dsc dls cpn methods modied critical path mcp algorithm based aslateaspossible alap time node 24 alap time dened critical length critical path leveln length longest path node n exit node including node n 5 mcp algorithm designed schedule dag bounded number pes sorts node list increasing alap order rst node list scheduled pe allows earliest start time considering idle time slots node deleted list operation repeats list empty dominant sequence clustering dsc algorithm designed based attribute task graph called dominant sequence ds 25 ds dened partially scheduled task graph path maximum sum communication costs computation costs graph nodes ds considered relatively important others ready nodes highest priority scheduled rst priorities child nodes scheduled node updated operation repeats nodes scheduled dynamic cost used quickly determine critical path length idea incorporated task algorithm reduce complexity dynamic level scheduling dls algorithm determines node priorities assigning attribute called dynamic level dl node every scheduling step 20 dl dierence static level message ready time dls computes dl ready node available processors suppose dln j largest among pairs ready nodes available processors schedule n processor j repeat process nodes scheduled recently new algorithm proposed using critical path node cpn 16 algorithm based cpndominate priority next cpn ready node put cpndominate list nonready cpn parent node n smallest alap time put list parents n already list otherwise ancestor nodes n recursively included list cpn node list rst node list scheduled pe allows earliest start time scheduled node removed list operation repeats list empty cpndominate algorithm utilizes two important properties dag critical path topological order potentially generates good schedule although algorithms produce relatively good schedules usually optimal sometimes generated schedule far optimal paper propose fast local search algorithm task improve quality schedules generated initial scheduling algorithm local search one early techniques combinatorial optimization applied solve nphard optimization problems 12 principle local search rene given initial solution point solution space searching neighborhood solution point recently number ecient heuristics local search ie con ict minimization 8 21 random selectionassignment 22 23 pre partial selectionassignment 22 23 developed several signicant local search solutions scheduling problems sat1 algorithm rst local search algorithm developed satisability problem later 80s 8 9 10 11 scheduling problem wellknown maxsatisability problem local search solution sat problem applied solve several largescale industrial scheduling problems two basic strategies used local search rst one random search local search direction randomly selected initial solution point improved moves rened solution point otherwise another search direction randomly selected random strategy simple eective problems nqueens problem 21 however may ecient problems microword length minimization 18 dag scheduling problem second strategy utilizes certain criteria nd search direction likely lead better solution point microword length minimization 18 compatibility class considered moving nodes class may reduce cost function strategy eectively reduces search space guiding search toward promising direction local search algorithm presented paper uses strategy carefully selected criteria local search dag scheduling becomes ecient scheduling quality improved signicantly 4 random local search algorithm number local search algorithms scheduling presented 16 17 random local search algorithm dag scheduling named fast given 16 see figure 1 algorithm node randomly picked moved randomly selected pe schedule length reduced move accepted otherwise node moved back original pe move successful takes oe time compute schedule length e number edges graph reduce complexity constant maxstep dened limit number steps maxstep nodes inspected time taken algorithm proportional emaxstep maxstep set 64 16 moreover randomly selected nodes pes may able signicantly reduce length given schedule even maxstep equal number nodes leading complexity oen random search algorithm still cannot provide satisfactory performance f pick node n randomly pick pe p randomly move n pe p schedule length improve move n back original pe searchstep maxstep figure 1 random local search algorithm fast fast algorithm modied 17 shown figure 2 major improvement uses nested loop probabilistic jump total number search steps maxstepmaxcount margin used reduce number steps maxstep set 8 maxcount 64 margin 2 17 parallel version fast algorithm named fastest speedup 1193 1445 16 pes obtained fastest 17 5 local search topological ordering scheduling propose fast local search algorithm utilizing topological ordering eective dag schedul ing algorithm called task topological assignment scheduling kernel algorithm nodes dag inspected topological order order required visit every edge determine whether schedule length reduced time spent move drastically reduced inspecting every node large graph becomes feasible also order compact given schedule systematically given graph order describe task algorithm succinctly several terms repeat f pick node n randomly pick pe p randomly move n pe p schedule length improve move n back original pe increment counter otherwise set counter 0 searchstep maxstep counter margin schedule length schedule endif randomly pick node critical path move another processor searchcount maxcount figure 2 modied fast algorithm dened follows largest sum communication computation costs top level node ie entry node n excluding weight wn 26 largest sum communication computation costs bottom level node ie n exit node 26 critical path cp longest path dag length critical path dag node set graph task algorithm applied previously scheduled dag case scheduled dag constructed contains scheduling execution order information 25 enforce execution order pe pseudo edges zero weights inserted incorporate initial schedule graph denitions tlevel blevel critical path still applied scheduled dag dene terms scheduled pe pen predecessor node scheduled immediately node n pe pen node n rst node scheduled pe pn null successor node scheduled immediately node n pe pen node n last node scheduled pe sn null procedure task dag schedule begin initialization construct scheduled dag node 0 n 1 longest path dag search nodes dag scheduled begin pick node max ln pe k obtain l k n moving n pe k pick pe min l k improvement let node n stay pe pen improvements else begin move node n pe pen pe modify pseudo edges dag propagate tlevel n children mark n scheduled figure 3 task topological assignment scheduling kernel local search algorithm based topological ordering fast scheduling sketch task algorithm shown figure 3 detailed description task algorithm figure 4 one characteristics task algorithm independence algorithm used generate initial schedule node labeled n current pe number pen long initial schedule correct every node n available application local compaction algorithm guarantees new schedule graph better equal initial one input algorithm given dag schedule generated heuristic dag scheduling algorithm first scheduled dag constructed pseudo edge may added zero communication time data transferred along edge step 2 computes value blevel node scheduled dag initializes tlevel entry nodes edges marked unvisited variable next k points next node inspected pe k initially none nodes inspected next k points rst node pe k step 3 ready node n maximum value ln selected inspection ties broken tleveln tleveln ties broken randomly node ready parents inspected way nodes inspected topological order although topological orders blevel tlevel cpndominate used tlevel blevel shown good indicator order inspection 24 25 inspect node n step 4 value ln recalculated pe conduct recalculation pe k node n pretended inserted right front next k tleveln varied parent nodes scheduled either pe k pe pen similarly bleveln varied child nodes initially scheduled either pe k pe pen tlevels parent nodes available blevels child nodes unchanged value ln every pe easily computed values indicate degree improvement local search new ln recalculated every pe node n moved pe allows minimum value ln node n moved pe corresponding pseudo edges modied step 5 tlevel n propagated children node becomes ready tlevel computed process continues every node inspected task algorithm satises following properties theorem 1 critical path length lcp increase step task algorithm proof ln node n determined longest path includes n assume increases result moving node n n n j must path entry node exit node ln j increases path must longest step 1 constructing scheduled dag node n last node pe exists e ij create pseudo edge e ij n n j ij step 2 initialization node n compute bleveln considering pseudo edges entry node mark n ready initialize tleveln mark every e ij unvisited pe k let next k point rst node pe step 3 selection pick ready node n highest value ln ties broken tleveln tleveln ties broken randomly step 4 inspection pe k recompute l k n assuming n moved pe k inserted next k find pe l n step 5 compaction stay pe let next else move node n pe delete edge e li pseudo edge delete edge e im pseudo edge edge e lm previously exists create pseudo edge e lm lm visited let sn l pseudo edge create pseudo edge e xi edge e xi previously exists create pseudo edge e iy edge e iy previously exists let sn x step 6 propagation tlevel child node node n say n mark edge e ij visited incoming edges n j marked visited mark n j ready compute tleveln j repeat steps 36 nodes inspected figure 4 detailed description task algorithm path includes n j determines value ln j path determines value otherwise longer path determines ln ln ln j increase ln lcp thus ln j lcp since l value every node larger lcp lcp increase 2 n node critical path reduction ln value implies reduction critical path length entire graph may immediately reduce critical path length case parallel critical paths n node critical path reducing ln value reduce critical path length immediately however increases possibility length reduction later step task algorithm tlevel blevel values reused complexity determining l reduced following theorems explain topological order makes complexity reduction possible theorem 2 nodes dag inspected topological order ready node appended previous node list pe blevel node invariant inspected tlevel node invariant inspected proof node n inspected topological order implies descendants inspected therefore blevel n changed since blevel descendants n changed n inspected topological order implies ancestors n x inspected node always appended previous scheduled nodes pe tlevel inspected node remains unchanged 2 following topological order node inspection localize eect edge zeroing l value nodes inspected move tlevel currently inspected node computed instead computing tlevels blevels nodes therefore time spent computing l values signicantly reduced theorem 3 time complexity task algorithm oe e number edges n number nodes p number pes proof insertion pseudo edges rst step costs second step spends oe time compute blevel values third step costs nding highest l value main computational cost algorithm step 4 computing l value node costs inspecting every edge connected n dn degree node n n steps cost p complete inspection node target pe must selected p pes resulting cost onp therefore total cost oe task algorithm shares concepts dsc algorithm 25 topological order used avoid repeated calculation dynamic critical path complexity reduced task selection criteria tlevelblevel used md 24 dsc algorithms measures importance node scheduling proven ecient criteria node selection task algorithm dierent dsc algorithm many aspects dsc algorithm schedules dag onto unbounded number clusters whereas task local search algorithm improves existing schedule bounded number processors although dsc task algorithms aim reduce schedule length dsc realizes merging clusters whereas task realizes moving nodes among processors dsc merging clusters based gain reduction edges node parents task goes one step considering possible gain reduction edges node children potentially results better ecient decision following use example illustrate operation task algorithm example 1 assume dag shown figure 5 scheduled three pes dag scheduling algorithm schedule shown figure 6a three pseudo dashed edges added construct scheduled dag one node n 6 node n 8 one node n 3 node one node n 4 node n 5 shown figure 6a schedule length 14 blevel node computed shown table 1 tables 2 3 trace tlevel values step table 2 p indicates node largest l value inspected current step table 3 indicates original pe p pe node moved first one ready node n 1 cp node l value pe 0 l 0 n 1 14 l values pes computed l 1 n 1 shown table 3 thus node n 1 moved pe 0 pe 2 shown figure 6b lcp dag reduced 12 iterations 2 3 4 moving nodes n 2 reduce l value iteration 5 node n 6 moved pe 0 pe 1 l value reduced 12 11 shown figure 6c following iterations nodes move figure 5 dag example 1 time time b c2next next next next next next nextnext next figure example tasks operations table 1 initial blevel value nodes example 1 blevel 14 9 9 table 2 l values ready nodes selecting node inspected iteration table 3 l values node n pe select pe iteration node pe 96 15 94 13 65 11 6 performance study section present performance results task algorithm compare task algorithm random local search algorithm fast performed experiments using synthetic dags well real workload generated gaussian elimination program use random graph generator 17 synthetic dags randomly generated graphs consisting thousands nodes large dags used test scalability robustness local search algorithms dags synthetically generated following manner given n number nodes dag rst randomly generated height dag uniform distribution mean roughly equal n level generated random number nodes also selected uniform distribution mean roughly equal n randomly connected nodes higher level lower level edge weights also randomly generated sizes random dags varied 1000 4000 increment 1000 three values communicationcomputationratio ccr selected 01 1 10 weights nodes edges generated randomly average value ccr corresponded 01 1 10 performance data average two hundreds graphs evaluated performance algorithms two aspects schedule length generated algorithm running time algorithm tables 4 5 show comparison modied fast algorithm 17 adn task algorithm 4 pes 16 pes respectively cpn cpndominate algorithm fast modied fast algorithm task task algorithm comparison conducted dierent sizes dierent ccrs cpndominate algorithm 16 generates initial schedules schedule length value column cpn length initial schedule value column fast initial scheduling plus random local search algorithm value column task initial scheduling plus task algorithm column sd following schedule value standard deviation columns following fast task percentage improvement initial schedule running times cpndominate algorithm modied fast algorithm task algorithm also shown tables seen task much eective faster fast search order l value superior random search order table 5 ccr10 16 pes improvement ratio drops case degree parallelism exploit maximized much fast algorithm two orders magnitude slower task partly 256 fastest algorithm running 16 pes faster still one order magnitude slower task table 4 comparison synthetic dags cpn initial scheduling algorithm 4 pes ccr schedule length running time sec nodes cpn sd fast sd task sd cpn fast task 1000 2000 table 5 comparison synthetic dags cpn initial scheduling algorithm 16 pes ccr schedule length running time sec nodes cpn sd fast sd task sd cpn fast task table comparison synthetic dags dsc initial scheduling algorithm 4 pes ccr schedule length running time sec nodes dsc sd fast sd task sd dsc fast task 1000 28 45 2756 28 124 060 161 016 2000 table 7 comparison synthetic dags dsc initial scheduling algorithm 16 pes ccr schedule length running time sec nodes dsc sd fast sd task sd dsc fast task tables 6 7 show comparison dsc 25 initial scheduling algorithm cluster merging algorithm shown 26 maps clusters processors cpndominate algorithm generates better schedule dags smaller ccr dsc ecient ccr large smaller ccr dsc good therefore task produces large improvement ratio hand dsc particularly suited large ccr task unable improve much result general less improvement obtained task algorithm better schedule good schedule leaves less room improvement task algorithm normally provides uniformly consistent performance schedule produced task depend much initial schedule also tested local search algorithms dags generated real application gaussian elimination partial pivoting gaussian elimination program operates trices matrix partitioned columns nest grain size column partitioning scheme single column however negrain partition generates many nodes graph example negrain partition 1k1k matrix generates dag 525822 nodes reduce number nodes mediumgrain partition used table 8 lists number nodes dierent matrix sizes grain sizes number columns ccr 01 08 graphs generated hypertool annotated sequential gaussian elimination program 24 comparisons fast algorithm task algorithm dierent dags dierent number pes shown tables 9 10 table 9 uses cpn initial scheduling algorithm table 10 uses dsc initial scheduling algorithm general cluster algorithm dsc performs well communication dag heavy therefore generates better schedules gaussian elimination task performs better fast cases much faster fast 7 conclusion future works local search eective method solving nphard optimization problems applied improve quality existing scheduling algorithms task lowcomplexity highperformance local search algorithm static dag scheduling quickly reduce schedule length produced dag scheduling algorithms utilizing topological order much faster much higher quality random local search algorithm demonstrated task able reduce drastically schedule length produced wellknown algorithms dsc cpn future work comparison best scheduling algorithms mcp 24 conducted preliminary comparison showed small improvement observed since mcp produces good results already table 8 number nodes dierent matrix sizes grain sizes gaussian elimination matrix size 1k1k 2k2k grain size 64 nodes 138 530 2082 8258 530 2082 8258 32898 table 9 comparison gaussian elimination cpn initial scheduling algorithm matrix grain schedule length running time sec size size pes cpn fast task cpn fast task table 10 comparison gaussian elimination dsc initial scheduling algorithm matrix grain schedule length running time sec size size pes dsc fast task dsc fast task acknowledgments research partially supported nsf grants ccr9505300 ccr9625784 nserc research grant ogp0046423 nserc strategic grant mef0045793 nserc strategic grant str0167029 would like thank anonymous reviewers constructive comments r comparison list scheduling parallel processing systems applications performance analysis compiletime optimization approach list scheduling algorithms distributed memory multiprocessors scheduling parallel program tasks onto arbitrary target machines task scheduling parallel distributed systems computers intractability guide theory npcompleteness rinnoy kan parallel algorithms architectures fast search phd thesis solve largescale satis ability problems average time complexities several local search algorithms satis local search satis parallel sequencing assembly line problems comparison multiprocessor scheduling heuristics grain size determination parallel processing fastest practical lowcomplexity algorithm compiletime assignment parallel programs multiprocessors microword length minimization microprogrammed controller synthesis partitioning scheduling parallel programs multiprocessors compiletime scheduling heuristic interconnectionconstrained heterogeneous processor architectures programming aid messagepassing systems dsc scheduling parallel tasks unbounded number processors pyrros static task scheduling code generation messagepassing multiprocessors tr ctr savina bansal padam kumar kuldip singh improved duplication strategy scheduling precedence constrained graphs multiprocessor systems ieee transactions parallel distributed systems v14 n6 p533544 june