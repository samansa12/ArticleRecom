research demonstration hardware referencecounting heap hardware selfmanaging heap memory rcm languages like lisp smalltalk java designed built tested benchmarked every pointer write processor referencecounting transactions performed real time within memory garbage cells reused without processor cycles processor allocates new nodes simply reading distinguished location address space memory hardware also incorporates support offline multiprocessing marksweep garbage collectionperformance statistics presented partial implementation scheme five different memory models two garbage collection strategies main memory access rcm fully operational rcm installed external bus performance rcm memory competitive main memory b introduction 11 technological maturity scale 1992 stuart feldman presented series hurdles measure progress computing 15 paralleling accepted milestones thermonuclearfusion power specified five milestones new computer technologies comparisons alternative tools 1 ideaconcept idea conceived perhaps published sounds good original backoftheenvelope calculations trivial usually paper examples support 2 research demonstration idea embodied first serious example running demonstration proof ofconcept originator still likes though useful actual problems 3 scientific breakeven technique developed sufficiently used real problems shown better common technique tool experience wide probably controversial 4 engineering breakeven technique tool something useful fullscale problems concert tools 5 financial breakeven concept known technique choice significant domain profitable use general software practice concert techniques 14 context paper reports research demonstration hardware support referencecounting garbage collection part computer memory related work 21 supports scientific breakeven well concept published twelve years ago 36 path ideaconcept scientific breakeven usually story indeed parts paper read like narrative however writing stories like thiseven unsuccessful onesis essential advancing complex symbiosis hardware software without denied ability whipsaw interface reaching beyond improvements one whose support foreseen financial marketplace innovative steps must taken without timetable financial breakeven 12 referencecounting memory report design construction testing specialized memory provides systemlevel heap management real time providing atomic transactions allow multiported access multiprocessing collection 20 without repeated synchronization memory system installed next cube experiments compare conventional collection machine stopcopy marksweep used support purely applicative file system 21 served test rapidprototyping new insights compiletime management 39 storage management broad problem recovering unused space heap without explicit instructions programmer includes reference counting garbage collection hybrids two like reported although second term often used include storage management 7 25 choose original taxonomy 26 p 412 find descriptive reference counting better analog curbside recycling trash collection central role played heap management become problem worthy hardware support indeed others implemented hardware uniprocessing proposed multiprocessing 3 18 2 28 31 33 although reference counting used successfully managing secondary storage garbage collection still thought far suitable primary storage hardware support effective shown however hardware quite effective leveling reputed disadvantages reference counting every pointer written causes increment new referent every pointer erased causes decrement well thus common pointer overwrite causes although principal strategy online reference counting implemented purely memory 36 rcm also includes support marksweep garbage collection 34 fast parallel offline multiprocessing implementation transactions increments decrements well marking would dispatched asynchronously performed locally memory balanced multiprocessor computes fast therefore multiprocessing heapmutator 18 generates garbage tremendous rate balanced collector requires parallelism keep apace conventional garbage collection however assembles global knowledge nothing points thus multiprocessor realization requires much synchronization constraint uniprocessors garbage collection thought perfected 1 11 asynchronous atomic transactions reference counting 8 make heap manager choice multiprocessor multitasking system commonly used recover available sectors shared disk traversing collector rarely used egunixs fsck contrast garbage collection become heapmanagement algorithm choice uniprocessors amortized performance measured processormemory transactions undercuts processordriven reference counting paper shows moving counting processor memory inverts conventional wisdom 13 onward remainder paper six parts second section reviews philosophy design reference counting hardware third description hardware support offline garbage collection fourth brief chronology project limitations next brief description scheme software test problems sixth section presents results testing final section reviews future including features implemented yet exercised reference counting hardware 21 reference counting three reasons reference counting 8 studied primary strategy memory management spite prevailing practice using either offline online garbage collection 7 2 3 29 22 30 first properties reference counting make usual strategy managing disk sectors also become particularly important multiprocessing three transactions vi implement reference counting finite nonglobal performed locally asynchronously memory without interference transactions atomic action various processes free continue without synchronizing storage management second referencecounting allows heaps address space much smaller collected one nodes recycled real time existing space used denselyeven 100 capacitywithout sacrificing global performance locality increases finally reference counting indeed handle many useful data structures specifically including certain cyclic ones conventional wisdom breaks cycles stems overstatements textbooks research references arbitrary circular structures well known break reference counting often overused even classic examples better implemented without cycles 26 x224 moreover wisdom ignores strategies circularities sustain reference counting useful situations 9 5 17 39 baker 3 4 instance implies consumes address space processor time neither used 22 heap node prototype provides nodes either atomic binary skeletal c declaration illustrates models cons nodes scheme lisp also suffices aggregates arbitrary size via naturally corresponding binary trees 26 x232 better complete trees 26 x2345 latter used implement matrix decomposition section 52 generalizations needed smalltalk cstyle languages whose efficient implementations likely require fourpointer node cf section 6 word char4 32bit word address 4k unsigned int bool const bool false0 true1 enum type atomic binarynode struct node union struct struct node left right twolinks double atom bool mark liveleft liveright type unsigned int refct const distinguishes addresses double words words inline double selectlftword ptr return longptr leftright inline bool isright word ptr return intptr leftright 23 operations node rcm every write pointer referencecounting memory rcm becomes readmodifywrite new pointer overwritten memory location removal former reference location memory cycle dynamic ram provides operation little cost beyond conventional write although readily available stock ram chips lost commodity simms lines datain dataout wired wider simms could write pointer address data dispatched processor remote memory following algorithm executed uninterruptibly remote procedure local destination word address void storercmnode pointer word destination rcmnode leftdest selectlftdestination leftdesttype binarynode isrightdestination leftdestliveright dispatch decrementcountleftdestdataright destination else dispatch decrementcountleftdestdataleft destination code bends c language bit reflecting ad hoc hardware instance dispatchs signaled asynchronous circuitry four steps occur parallel subject two constraints increment dispatched backdoor bus decrement 1 former content destination read overwritten new pointer fetches destination tags stores occur memory readmodifywrite cycle sequentiality three steps c code satisfies constraints uniprocessor intend nearly simultaneous hardware referencecounting transactions interleaved similar ones dispatched memories destination long incrementsdecrements arrive target interleaving orders dispatched unique noncaching path sourcedestination pair bus banyan net 19 meets constraint consistency rcm memory assured memory overwrites occur atomic operations locally rcm writing multiprocessors need wait completion dispatching new pointerwrite rcm address pointer must already alive counted referent dispatch write causes eventual increment newly shared referent decrementing count would require overwriting one extant enlivening references last decrement zero cannot occur new increment arrives without violating order restriction destination address increments const far smallereg 255 void incrementcountrcmnode ptr ptrrefct sticky ptrrefct decrements occur atomic transactions sticky count provides counter smaller worstcase requirement 6 void decrementrcmnode ptr else freeptr instruction freeptr indicates return ptr availablespace structure board rcm mem ory increment decrement operations serialized target address either handled simultaneously read write readwrite uses circuits distinct incrementdecrement 1 necessary dispatch increment decrement handle correctly reflexive assignment ptrptr ptr unique reference tag data count link read dataaddress processor switch incr decr address tofrom rcm backdoor processor figure 1 layout referencecounting memory three operations requires finite time node typically returns available space still containing live yetcounted pointers 35 24 physical implementation figure 1 illustrates hardware configuration rcm implemented every address rcm data memory referencecount memory data memory handles conventional reads writes processors delivered via address data busses strobed ordinary ram counting memory handles increments decrements arrive resulting earlier writes ad hoc commands ad hoc queries commands implemented reads writes distinguished locations within rcms address space much like control busresident device two memories bus ports data port various processors also narrower ports realtime dispatch receipt incrementsdecrements modules rcm since single data transaction write might generate two dispatches dispatches must handled twice speed data transaction fortunately bandwidth incrementdecrement address action bit less half data transfer address data processing doubled dispatches rcmpointer writes moreover also absorbed interleaved transactions involve referencecounts eg rcm reads rcm writes overwrites dead data ram idlememory cycles data rcm tagged either live dead 39 memory atomic information immediate references like count link tags 64bit atomic value floatingpoint number count link tags figure 2 memory one rcm node null dead pointers tagged live dead atomic datum written rcm increment dispatched dead datum overwritten decrement issued figure 2 illustrates node appears programmer l tagging live datum tagging dead one atomic nodes distinguished binary nodes allocation types established tagged 25 available space bank rcm memory maintains available space whenever processor needs new node reads distinguished memory location obtain address new node reading one location allocates node atom another binary node coded distinguished locations used control data registers rcm device example writing address either two distinguished addresses dispatches increment respectively decrement count addressed node special garbagecollection mode interpretation reads writes rcm completely redefined supports deutschschorrwaite markphase 26 34 provides multiprocessor marking place single processor cycle requires interprocessor synchronization cycles node traversed support hardware hybrid garbage collection also new stateoftheart storage managers used smalltalk systems 23 10 well many secondarystorage managers also hybrids garbage collection reference counting device first provide hardware support 3 inplace garbage collection prototype provides several new features included ideaconcept paper 36 including hardware support deutschschorrwaite collection 34 two features render algorithm competitive recopying collection even uniprocessor importantly also provide asynchronous multiprocessing collection experiments however demonstrate speed uniprocessor collection turned faster recopying first sweep phase performed online memory marking complete sweeper runs even mutator already resumed secondly importantly rcm performs pointer rotations associated marking atomic operations memory fits livedead tagging described complements reference counting form truly hybrid heap manager garbage collection becomes necessarywhen available space list exhausted spite reference countingall mutators must synchronize enter collection together time banks rcm switched gc mode arbitrarily many collectors traverse active nodes without synchronization marking marking collectors synchronize leave gc mode whereupon mutators may resume fact leaving gc mode initiates hardware sweeper bank rcm reconstructs available space locally time overlapped mutators rcm admit parallel collection also recomputes reference counts perfect accuracy like recopying collection runs time necessary traversing counting active pointers mark increment recomputed reference count correcting counts inflated cycles compact counts unsticking shrunken sticky counts 9 thus garbage collection improves performance reference counting reference counting symbiotically postpones need collection aside initiating hardware sweeper gc mode terminated mode redefines meaning read write rcm cannot even cached writethrough memory mode actually two read functions called first read later read plus special write operation rotates node two reads distinguished fourbyte word address even odd access eightbyte node first read atomic operation responds differently node read first time entering gc mode second later issues first read address returns nil increments reference count first time read applied node node marked reference count reset one content first live field returned fields alive nil returned parallel collector nil means infrastructure beneath node traverse however first read returns nonnil pointer infrastructure must traversed recursively avoid separate stack bookkeeping special write used replace pointer stackpointer rotation node implicit memory one two later visits another live pointer readwritten later read ultimately stack read last live pointer written back restoring node original configuration 34 effect special reads write allow traversal node two live pointers six memory cycles one live pointer four memory cycles pointers dead eg atomic one cycle later shared reference node costs additional cycle synchronization beyond implicit path memory collecting node less six cycles compares favorably recopying performance although rcm must yet spend another cycle initially reallocate measurements show hardware collector indeed beat nongenerational stopandcopy 4 constraints prototype undercurrent project effort develop memory hardware without hacking kernel without rebuilding programming environment former constraint met latter low level figure 3 referencecounting memory installed nextbus project vulnerable upheavals manufacturers revisions mach operating system difficulties chosen language implementation end developed rudimentary scheme environment establish rcm performance sound statistics complete stack protocol precluded continuations project three original motivations exercise rapid hardware prototyping another project refinement digital design tools 24 support applicative programming research substantially successful three goals three erect additional constraints around design later rcm became essential applicative file system 21 toward development ultimate scheme software directed rapid prototyping effort dictated use available hardware software much possible thus prototype rcm implemented device resident bus running bus speed rather speed main memory order avoid hacking host hardware chose nextbus familiarity motorola 680x0 architecture two machines macintosh next use availability nexts nextbus interface chip nbic timely delivery prototype boards swung us next testbed moreover lab manufacturer receptive new ventures new product standard 8bit simms prototype memory initially contained one million nodes ninetysix bits twelve simms figure 1 user sees address space eight megabytes figure 2 remainder remains hidden except engineers access rcm ram via special addressing mode used heap onabus ram onabus tests figure 3 shows two wirewrapped boards implement rcm either end bus simms visible nine one three constraints turned worse anticipated figure 4 illustrates physical location rcm within next computer original sketch rcmprototype timing provided 240 nanosecond cycle time approximated understood buscontention time readmodifywrite nextbus allowance rcm figure 4 rcm nextbus subtlety nbicthat three nextbus cycles needed seize second bus within devicethe sketch suddenly rose 960 ns overwhelming minimum needed readmodifywrite simms rowaddress followed doublestrobe columnaddress 300 ns readfollowedbywrite actually implemented fact timings much faster another subtlety described later results surprises arose exercise hard implementation simulation would never exposed software lots references recursion stack rcm one requires ad hoc increments decrements sustain counts pushespops stack provide alternative fast stack expanded portion rcm originally ramlike register file issues increments decrements otherwise physically isolated pool heap nodes enlarged serial file called pacram pointers always counted ram tested version two megabytes pacram six rcm heap 34 meganode rooting pointers stack get deleted run time recursion stack residing pacram overwritten deletion however occurs subsequent stackpush rather immediately stack pop intuition suggests ironic stack pop passive respect storage management memory contents hardware built eight months schedule pacram design modification made four months later minor wiring changes made later one wiring error one counter expanded errortraps set original design remained unchanged except pacram expansion 5 description experimental software 51 hooks operating system multiprocessor use rcm requires caching interfere order writes dispatched processor memory writethrough caching suffices writes cache occur order writes processor otherwise caching must disabled requirement fodder debate risc vs cachecoherency multiprocessors protocol suffices prevent node prematurely released write one processor pending increment asynchronously delayed within cache another therefore rcm accessed private device without caching system traps interrupt protocols transparent user access busresident memory surprising exercise kernel hacking necessary mach operating system allows users program dynamically loaded kernel servers provide bit schemes processcontrol block indicates scheduler state transparenttranslation register preserved across context swap provision newer version slot driver next allowed user software privilege transparent access devices nextbus course would problem nonvirtual systems like 68020 macintosh would possible unix systems 52 scheme compiler five memories initial goal testing rcm hardware race hardware nextbus delay unfair compare ramheap speed rcmheap speed factoring bus delay therefore series problems designed refined provide extrapolation performance rcm built vlsi technology installed close processor like dynamic ram experiments cannot indicate multiprocessor performance reveal contention might result intensive increments decrements bus cycles long enough absorb rcminternal cycles figure 5 illustrates five versions partial scheme implementation used quite good compiler minimal language omitting bignums floats continuations example identical except recursion stack resides heap binary nodes resides managed memory available either cached ram uncached rcm memory nextbus latter slower cases cached host next cube running mach 30 68030 processor 16 megabytes ram exclusive rcm ffl stock ram small scheme compiler stack heap code resident nexts stock ram vectors embedded within heap composed two semispaces three megabytes uses fast stopandcopy garbage collector nexts stock read cycle 520 ns sixteen bytes first four become available within 160200 ns ffl heap onabus order establish slowdown geography rcms remote location bus compiler altered use rcm memory randomaccess heap rcm used engineering mode storing binary cons cells two threemegabyte semispaces specialized rcm transactions suppressed vectors remain ram remain static tests purpose version establish impact slower memory nextbus size restrictions rcm threemegabyte semispaces used ffl ram onabus identical heap onabus except stack also moved rcm accessed ram coincident pacram move objects two steps separate impact heap transactions stack transactions nailed rcm intermediate step toward referencecounting scheme next enabled marksweep collector rcm without yet enabling reference counting since marksweep runs place one semis pace needed rcm hardware provides six megabyte heap twiddled minor cost recursion stack static code cache vectors various sizes recopying collector twosemispace heap recopying collector heap counted marksweep collector heap uncounted marksweep collectormain memory ram referencecounting memory rcm stock ram rcm main memory ram nailed rcmpacram rcm main memory ram full rcmram main memory ram ram onabusmain memory ram ramheap onabus figure 5 five versions scheme using different memory number ram bytes rcm bytes collector mutator total system gcs recovered recovered seconds seconds seconds stock ram heap onabus ram onabus nailed rcm full table 1 experimental results balancedtree insertion collection timings three megabytes new nodes allocated rcm reference counts initialized toohighbyone new reads wrong register count must also artificially incremented every garbage collection similarly expense extra memory cycle node use excessive count effect nailing every node even though referencecount machinery operating count ever reaches zero version exercises garbagecollection machinery exhibits impact support markphase online hardware sweeper performed memoryresident hardware ffl full rcm finally scheme implementation maintains accurate reference counts difference nailed rcm one bit object code new reads proper register renailing cycle omitted garbage collection exercised tests 6 tests results tested two programs use trees dags heavily create release lots intermediate results solve well known problems consume tens minutes run time 61 performance balancedtree insertion problem first problem builds familiar binarysearch trees appendix presents code scheme function inserts keyinformation pair initially empty avl balanced tree 27 x623 purely functional returning resulting tree insertion without requiring side effects arguments first test apply tailrecursion insert 75000 different random numbers initially empty tree keys information immediate data keys small ints interior node balanced tree list four consboxes since box occupies eight bytes figure 3 space required final tree 24 megabytes average depth 155 however recopying spine tree typical insertion point reallocates 500 bytesmore balancing act necessary results appear table 1 even though first four systems collect garbage exactly 30 times first recovers less another 1992 bytes static vectors share heap others use space allocate recover even nodes third nailed rcm system collects garbage slightly earlier two onabus systems three nodes preallocated hardware therefore recovery counts slightly different full rcm counts bytes recovered real time last transaction systems figures slightly lower derive complete collections including abandoned space yet collected termination mutator collector times increase heap stack moved nextbus although much feared indeed moving heap bus comparatively little impact perhaps slow reads balance nbicbuffered writes collector likewise exhibits balance even recursion stack moved little stacking mutators stack moved bus however observe marked slowdown likely heavier reading stack frames aggregate 41 mutator slowdown heap stack moved rcms address space nailed rcm performs extremely well recovering space twothirds less time ram onabus needed even including extra cycle reset nail balanced tree ideal structure collector many nodes two dead pointers full rcm runs even faster avoiding garbage collection mutator time therefore total time time 710 seconds extrapolates rcm local memory 501 seconds stock ram would halve performance including collections observed 62 exactarithmetic quadtreematrix inversion second test program exactarithmetic matrix inversion chosen problem familiar nontrivial purely applicative algorithm 37 16though unfamiliar compiled wellmust perform place ever compete popular alternatives results appear table 2 figure 6 problem compute integer matrix det 6 da quadtree representation matrices 38 offers uniform representation sparse full matrices directed acyclic graphs dags briefly matrix either homogeneously zero nil nonzero 1 theta 1 scalar integer quadruple four equallyordered submatrices nil used pad matrix order seems power two fill sparse matrices internally properties additive identity multiplicative annihilator unifies algorithms sparse dense matrices algorithm used exercise rcm exactarithmetic lu decomposition inversion algorithm 37 followed backmultiply aa 0 matrix di full undulantblock pivoting used 2 p theta 2 p subtree submatrix might eliminated single elimination step pivoting attempts eliminate large block small determinant one matrix selected harwellboeing data set 12 sparse matrices chose can62 small integer nonsingular decomposition consumes many nodes without generating bignums would skew measurements heap use 62 theta 62 patterned symmetric matrix 140 nonzero elementsall ones determinant 117 inversion matrix generates massive intermediate structures completely rcm resident rcm tests garbage generated particular problem never uses much heap one time average 63 kilobytes measured garbage collection collection load atypically small therefore loaded heap static linear lists length 0 100000 200000 300000 8byte nodes constrain garbage collector typical loads addition traffic inversion tests generated single run reproduced repeatedly consistently load number ram bytes rcm bytes collector mutator total system bytes gcs recovered recovered seconds seconds seconds stock stock ram 8m 12 26399800 0 1155 435 550 stock ram 16m 20 27934824 0 3555 440 796 stock ram 24m heap onabus 8m 12 448 26510892 1126 472 585 heap onabus 16m 20 464 28125700 3490 478 827 heap onabus 24m 46 520 27925732 11750 483 1658 ram onabus 8m 12 448 26510892 1132 621 734 ram onabus 16m 20 464 28125700 3508 628 979 ram onabus 24m 46 520 27925732 11789 634 1813 nailed rcm 0 9 444 27715104 72 661 669 nailed rcm 8m 12 448 27332736 580 677 735 nailed rcm 16m 19 460 28138384 1648 695 860 nailed rcm 24m 41 508 27950328 5287 738 1267 full full rcm full rcm 16m 0 0 28207208 0 655 655 full rcm 24m 0 0 28207208 0 663 663 table 2 experimental results integer matrixinversion total time varying five seconds within accuracy sought times sufficiently precise claims mutator total times except stock ram 3 seconds subtracted rcm initialization time considered negligible constant included data full rcm tests repeated nearly sixty times without space leaking garbage collection ffl number effectiveness garbage collection consistent one anomaly number gcs stock ram heap onabus ram onabus almost nailed rcm stock ram one collection others 24m loading explained fact vectors nodes heap separated elsewhere ffl number bytes recovered consistent expectations stock ram effectively smaller heap vectors included recovers slightly less space except squeezed extra collection heap moved rcm count rambytes recovered becomes negligibledue abandoned vectorswhose growth small come inversion algorithm heap onabus ram onabus perform identically nailed rcm performs similarly recovering slightly space ffl garbage collection times essentially first three systems stock ram heap onabus ram onabus grow loading expected available heap becomes cramped time stopandcopy collection soars hardware support marksweep collection enabled time drops precipitously ffl mutator time grow much 8 stock ram heap onabus grows 33 heap onabus ram onabus cost reflects distance processor rcm memory also loss caching stack 33 would recovered even rcm resident ram cpu board nevertheless total times nailed rcm recover much difference efficient collector ffl full rcm performs nicely indeed garbage collection eliminated single run measured also least 59 successive runsuntil repetitive test killed therefore vectors recovered probably none generated startup full rcm seen recycle appropriate number bytes run time slightly garbage collection statistics gc tests account garbage recoverable termination program ffl full rcm gc time mutator timings total times total time far less systems except simplest case compared stock ram full rcm slows mutator cannot cache stack must write entries nextbus speeds eliminating garbage collection ffl full rcm exhibits flat performance profile one expects program designed realtime parallel performance test jig cannot yet verify latter performance numbers indicate available multiprocessor systems architecture requires synchronization garbage collection one ever necessary except interleaves among processors like conventional ram stock ram0 stock ram1 stock ram2 stock ram3 heap onabus0 heap onabus1 heap onabus2 heap onabus3 nailed rcm0 nailed rcm1 nailed rcm2 nailed rcm3 full rcm0 full rcm1 full rcm2 full rcm3 mutator time sec x 10 gc time sec x 101234number garbage collections figure experimental results ffl full rcm well nailed rcm actually twice capacity tested 075 meganode heap 0375 available tests anything effort tying 0375 meganode increased collector timings somewhat nailed rcm full rcm never required garbage collection 7 conclusions future directions 71 parallel heaps parallel processing become costeffective must apply large computations overhead processscheduling amortized new problems cost software revision justified however exactly class large parallel programs current garbagecollection technology fades 11 storage management essential modern programming languages like smalltalk ml lisp haskell java must either abandon languages depend automatic storage management cast parallel programs likes c find strategies managing dynamic storage parallel processors third distasteful alternative abandon multiprocessing entirely innovative projects exploit languages 72 technological maturity experiments constitute first research demonstration hardware support reference counting also offer first research demonstration support marksweep collection although yet uniprocessor results together contribute research demonstration hardware support multiprocessing storage management furthermore recognize applicative file system 21 demonstration scientific breakeven reference counting hardware rcm allowed management disk main memory homogeneous storagemanagement strategy online reference counting primary algorithm backed expensive offline garbagecollector melding reference counting ram existing reference counting disk would impossible real time without rcm hardware indeed critical success project might accept scientific breakeven however inhouse experience may narrow broader sense results contribute scientific breakeven software hardware support storage management extramural research demonstrations already exist 30 31 33 73 future work advocates implementors functional programming heap memory take care separate assumptions cs ideal many presume lowlevel continuationpassing style makes easy return functions results outer environments presumption place unusual demand heapmanagement especially programs need might better exploit hardware stack c always compilers applicative languages manage eliminate heapresident continuations algorithms could also expressed c 13 compilation would necessary fair comparison c suggested experience design present implementation boardlevel prototype installed io device bus underlying design supports vlsi implementation 36 like ordinary dynamic ram prototype installed uniprocessor design targeted several banks rcm within multiprocessor moreover software available prototype compiler much opportunity improvement three enhancements necessary engineering breakeven demonstrated features designed rcm tested yet one online multiprocessor reference counting related one offline multiprocessor garbagecollection another unimplemented facility store dead pointer thread single cycle originally intended recover circular structures since demonstrated useful reducing counts contexts well 39 must included revision foresee many rcms built standard simm interface installed stock multiprocessor biggest difference one described available space constantly swept hardware obviating need large countlink field therefore hidden memory figure 1 cut half moreover would also provide fourpointer nodes motivated need within system software efficient randomlyreferenced records like schemes lexical frames research shows simple hardware memory accelerates referencecounting garbage collection manner consistent largescale parallelism cost hardware redesign fact small processors unaffected processormemory path unchanged simple circuitry needed perimeter memory bank memory still remains available dynamic ram conventional access worst difficulty arises sharing cached data problem already familiar parallelism acknowledgements thank machs designers providing preservation transparenttranslation ta bles next generously providing us nbics prototype boards bob wehrmiester early help hardware peter beckman preparing matrix data esen tuna loaning us compiler 13 thanks also anonymous referees helpful comments r garbage collection faster stack allocation managing reentrant structures using reference counts note shared structure lisp garbage collection linked data structures method overlapping erasure lists efficient efficient implementation smalltalk80 system sparse matrix test problems three implementation models scheme technological maturity scale technological maturity history unix matrix inversion using quadtrees implemented gofer reference counting manage circular environments mutual recursion exercise proving programs correct nyu ultracomputer designing mimd shared memory parallel computer language concurrent symbolic computation implementation applicative file system garbage collection task deletion distributed applicative processing systems smalltalk76 programming system design implementation derivation verified microprocessor garbage collection art computer programming art computer programming iii garbage collecting world garbage collection large lisp system progress hardwareassisted realtime garbage collection revised 3 report algorithmic language scheme performance hardwareassisted realtime garbage collector efficient machineindependent procedure garbage collection various list structures symmetric list processor design multiprocessing heap onboard reference counting undulant block elimination integerpreserving matrix inversion costs quadtree representation nondense matrices static dynamic partitioning pointers links threads tr ctr matthias meyer novel processor architecture exact tagfree pointers ieee micro v24 n3 p4655 march 2004 hansj boehm space cost lazy reference counting acm sigplan notices v39 n1 p210219 january 2004 srisaan chiatien dan lo jien morris chang active memory processor hardware garbage collector realtime java embedded devices ieee transactions mobile computing v2 n2 p89101 january david j roth david wise onebit counts unique sticky acm sigplan notices v34 n3 p4956 march 1999