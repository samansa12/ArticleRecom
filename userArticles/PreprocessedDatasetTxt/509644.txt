loop reordering prefetching runtime order loop iterations executed large impact number cache misses applications takes new loop order preserves semantics old order better cache data reuse improves performance application several compiler techniques exist transform loops order iterations reduces cache misses paper introduces runtime method determine order based dependencedriven execution dependencedriven execution execution traverses iteration space following dependence arcs iterations b introduction despite rapid increases cpu performance primary obstacles achieving higher performance current processor organizations remain control data hazards estimate 5 shows performance singlechip microprocessors improving rate 80 annually dram speeds improving rate 510 amount time 5 8 growing inability memory systems keep processors increases importance cache data reuse reduce traffic main memory prefetching mechanisms hide memory access latencies technological trends pose challenge interesting scientific engineering applications whose data requirements much larger processors cache scientific engineering applications spend execution time loops effort locality optimizations focused restructuring loops changing iteration order restructuring loops significantly improve performance application reordering iterations loop conventionally done compile time applying transformations loop interchange skewing reversal unfortunately compiletime transformations apply certain types loops transformations must provably correct without knowing values variables forcing compiler make conservative assumptions paper present hybrid compiletimeruntime method reorder loop iterations using dependencedriven execution model loosely based concept systolic arrays 911 coarse grain dataflow 3 dependencedriven execution system enables block iterations dependence constraints iterations satisfied immediate execution newly enabled iterations produces depthfirst traversal iteration space improves data reuse maintain symbolic datadependence information based array subscript expression found body loop evaluated runtime metacomputation symbolic dependences allows us avoid early commitment specific order giving system greater flexibility turn increases class loops optimized reordering iterations furthermore maintaining dependence information runtime runtime system prefetch sinks dependences hide latency memory accesses conventional wisdom suggests determining iteration order dynamically would add much computational overhead however overheads addition computational ones overheads caused control data hazards previous generations computers balanced memory system cost may indeed unjustified contemporary processors cpu cycles relative cheap comparison memory cycles two orders magnitude expensive imbalance suggests computational overhead logic avoid cache misses may significant logic reduce traffic memory hide latency memory operations elsewhere 16 discussed parallelism scalability dependencedriven execution multiprocessor paper evaluate efficacy runtime loop ordering improve temporal locality contemporary uniprocessor background related work many important numerical applications science engineering consist composite functions form f functions necessarily distinct large data set much greater processors cache size n denotes number times function sequence applied implemented imperative languages composite function would appear nested loop f expressed simple loop iterating data space semantics loops languages orders iterations lexicographically respect induction variables forcing computation traverse data space strict functionatatime order execution order leads poor reuse cache data fit entirely cache cache contains last c bytes upon completion function f forcing f i1 reload every byte cache may possible desirable execute iterations different order improve locality determine desirable legal orders specify express orders efficient execution much work locality optimization relies compiletime transformations reorder iterations loops unfortunately transformations apply loops perfectly nested loops assignment statements occur innermost loop loops transformed perfectly nested loops put differently compiletime transformations applicable case f equation 1 section briefly review compile time loop transformations following section describe loop reordering extended composite functions f discuss compile transformation useful define notion iteration space iteration space ndimensional space integers models nested loops depth n loop iteration point iteration space described vector 1 2 n p index variable delimited iteration range corresponding loop depth p linear loop transformation transformation original iteration space another iteration space desired properties better locality parallelism sequence loop transformations modeled product nonsingular matrices matrix making transformation skewing loop interchange reversal etc thus finding possible desirable iteration order formulated search nonsingular matrix objective function satisfying set constraints transformations also called unimodular transformations preserve volume iteration space integers loop transformation legal transformation preserves dependence relations dependence two points j iteration space difference vector j vector ji called dependence distance vector set distance vectors makes data dependences determine allowable reordering transformation based dependences optimizing compilers may make following transformations improve locality loop interchange loop interchange 191 swaps inner loop outer loop optimizing compilers apply transformation improve memory locality interchange reduces array access stride blocking tiling blocking 201217 takes advantage applications spatial locality traversing rectangle iteration space time memory accesses application limited addresses within rectangle rectangle data fits wholly cache processor access cache line multiple times leaves cache skewing blocking may legal iteration spaces distance vectors contain negative distances cases skewing 19 applied enable blocking transformation skewing traverses iteration space diagonally waves figure 1 skewing tiling transformations hyperbolic 1d pde transformed iteration space compiler generates code form new loops example consider hyperbolic 1d pde figure 1 shows dependences iteration space prior skewing blocking transformation block size two generated code complex original new code better locality parallelism survey compiler transformations high performance computing found 418 dependencedriven execution given transformed iteration space compilers must generate code describes traversal entire iteration space early commitment specific order limits flexibility specifically compile time transformations following limitations unimodular transformation apply composite functions multiple distinct functions apply large class imperfectly nested loops dependences loop iterations involve unknown user variables subscript expressions example consider following loop i0 n1 j1 j n2 j compiler cannot apply unimodular transformations without knowing values k l least knowing whether values negative positive compilers must give static specification iteration order code generated transformed iteration space become complex example skewing blocking transformation figure 1 complex code many levels nesting conditionals causes control hazards reduces instruction level parallelism contemporary processors furthermore difficult compilers apply optimizations complex code example none compilers various architectures experimented able apply loop unrolling code generated figure 1 furthermore compile time linear loop transformations give us general technique automate prefetching data hide memory access latencies section describe dude defusedescriptor environment runtime system dude meant used either target optimizing compilers set library calls programmers use directly 1 optimize code basic model loosely based underlying concept systolic arrays like systolic arrays computation dude consists large number processing elements cells type however efficient computation commercial processors granularity computation dude much coarser implementation cells actually c objects consist operation descriptor describing region data operation applied term objects iterates array iterates make iteratecollection procedures cells systolic arrays may consist several alternative options similarly operators iterates iteratecollection may overloaded like cells systolic arrays iterates interconnected links unlike interconnection cells systolic arrays physical hardwired links links dude symbolic expression indices index space iteratecollections expression symbolic links called dependence rule derived array access patterns statements original loop therefore summarizes dependences iteration space symbolic metacomputation dependence rule determines path execution iteration space also like computation systolic arrays data processed transfered one element another pipelining since one physical processing element uniprocessor computational speedup due pipelining however temporal locality model offers expect performance improvement even uniprocessor unlike computation systolic arrays computations dude synchronized global clock sense model closer wavefront arrays 10 asynchronous computation together pipelining function applications allows system apply multiple functions block data data block leaves processors cache figure 2 dependencedriven execution model describing loops dude goal runtime system able optimize complex loops form shown equation 1 achieve goals taken objectoriented loops blocks iterations extensible first class objects put together describe complex loops putting together specializing objects user specializes system create software systolic array application hand objectoriented model based awesime 7 chores 6 runtime systems following list objects dude data descriptor data descriptors describe subsection data space example matrix divided submatrices submatrix defined data descriptor methods object sx ex sy ey etc retrieve corners submatrix iterate iterate tuple data descriptor operator user specializes iterate overloading default operator application specific operator consisting statements found body simple loop system applies virtual operator data described descriptor iteratecollection iteratecollection name implies array iterates iteratecollection represents simple loop nested loop simple function composite function performs operation entire data space dimensionality iteratecollection normally data array operates loop loop template structure used describe composite function putting together one iteratecollections user relies following methods provided loop object glue together different iteratecollections begin computation makes iteratecollection nth simple function composite function defines symbolic link dep iteratecollection ic1 ic2 symbolic link expressed terms dependence rule variables range index space iteratecollections execute executes entire loop nest described loop descriptor loops objects created defined runtime giving system flexibility describe compute complex loop nests figure 2 shows basic model runtime system uses initially system pushes unconstrained iterates onto system lifo queue allows scheduler pop iterate perform operation iterate associated completion iterate potentially enable iterates based data dependences specified setdependence based iterates completed creates cycle shown figure 2 system repeats entire loop nest completed example redblack sor describe dependencedriven execution respect example redblack sor form red n number time steps note since loops red blk operations nested within perfectly nested hence unimodular transformation apply figure 3 multiloop dependences redblack figure 4 redblack sor dude figure 3 shows original code interloop dependences red blk operations loop body simply take average elements neighboring point creating dependence shown figure figure 4 shows application would appear written dude application two iterates red blk corresponding blkmain redmain methods overload operator specialize iterate application iterates compose redcoll blkcoll collections finally collections combined loop descriptor create composite function iterates 10 iterations execute function loop figure 4 starts system pushing initially unconstrained iterates redcoll collection onto system lifo queue dependencedriven execution memory locality entire execution nested loop sensitive order initially unconstrained iterates loaded applications block memory access patterns one system loads iterates morton order 15 computation begins initial iterates loaded system scheduler pops red iterate system lifo queue applies main operator data described descriptor iterate completed system determines list sinks dependences arcs iterate based dependence rule sink system decrements counter destination iterates point execution blk iterates count zero iterate becomes unconstrained enabled dependence satisfaction engine pushes enabled iterates onto system lifo queue lifo order next time scheduler pops iterate lifo queue would blk iterate continuing completion blk iterate enable red iterate second time step forth describes depthfirst traversal iteration space since blk operation begin red operations completed note using fifo queue would enforce breadthfirst traversal order iteration space would order produced original source loop figure 5 iteration order hyperbolic 1d pde using dude described runtime system position compare compiletime transformations compiletime optimization cannot transform loop structure redblack sor revert back example hyperbolic 1d pde compare iteration order loop nest would run dude compiletime loop reordering figure 5 shows snapshot iteration order hyperbolic 1d pde runs dude code shown diagram body operator pde iterate note code much simpler code required skewingtiling shown figure 1 simpler code less conditionals runs efficiently contemporary processors deep pipelines also enables possibility optimizations shown figure 1 really two orderings consider dependencedriven execution intraiterate order indicated numbers interiterate order enforced arrows interiterate order determined dependence rule order within iterate exactly original source loop note given dependence rule causes diagonal traversal iterates much like skewing transformation support automated prefetches far discussed methods reduce number cache misses hide memory access latency cache misses unavoidable section discuss dude inserts prefetch instructions mask memory accesses latencies useful computation cases cache miss unavoidable figure 2 shows prefetch logic fits dependencedriven model system executes currently ready iterate c prefetch logic tries predict next iterate n execute would based c dependence rule prediction simply simulates dependence satisfaction engine enable new iterates following exception instead pushing newly generated iterates n onto lifo queue prefetch logic invokes prefetch command region data iterate n associated causes data needed n delivered processor cache system executing iterate c intention system finally executes n data n would available processors cache experimental results analysis measured performance six applications redblack sor oddeven sort multigrid levialdis component labeling algorithm hyperbolic 1d pde vector chain addition one would ordinarily run algorithms uniprocessor since efficient scalar algorithms exist aim ultimately run algorithm multiprocessor conducting experiments uniprocessor isolate benefits increased parallelism dependencedriven execution benefits improved temporal locality experiments conducted single processor dec 21164 running 290 mhz 16kb first level cache 4 mb second level cache cache penalties two caches 15 cycles 60 cycles respectively programs compiled dec c cxx compiler o5 option determine cycles cache miss branch mispredict useful computation etc spent used digital continuous profiling infrastructure dcpi 2 available alpha platforms dcpi runs background low overhead slowdown 13 unobtrusively generates profile data applications running machines sampling hardware performance counters available alphas cycles attributed following categories computation cycles spent useful computation static stalls stalls due static resource conflicts among instructions dependencies previous instructions conflicts functional units dcache miss stalls dynamic stalls caused dcache misses dynamic stalls sources dynamic stalls missed branch predictions icache misses itb dtb misses figure cycles breakdown various applications figure 6 shows breakdown cycles spent six applications methods relevant certain applications graphs compares fewer methods others measurements averages 15 runs negligible standard deviations redblack sor figure 7 analysis sor 2048x2048 running dude application good spatial locality since element accesses neighboring elements also potential temporal locality pipeline iterations different time steps compared using dependencedriven execution three methods unoptimized tiling row tiling block chose matrix size 2048x2048 64bit floats insure entire matrix entirely fit processors cache method used optimal block size method 256x2048 tiling row 256x256 block 32x32 dude since time steps redblack sor normally controlled loops use following done i0 i10 figure 6 shows redblack sor using unoptimized method spends much 76 time dcache stalls surprising given expensive memory accesses relative cpu cycles since tiling row creates iteration order unoptimized case little benefit using tiling rowdue access patterns access north south west east neighbors tiling block little better spatial locality shown figure dude incurs greatest overhead terms number instructions executed runtime dependence satisfaction partly responsible overheads another source overheads caused use smaller block sizes 32x32 increases number loops hence number instructions comparing overheads cycles spent dcache stalls clear overheads relatively insignificant neverthless tension overheads caused smaller block sizes benefits greater temporal locality smaller block allows algorithm explore deeper time steps improving temporal locality also increases total overhead right hand side figure 7 shows effect grain sizes application analyze cache behavior sor using various method used atom 14 instrument application lefthand side figure shows total number references l1 cache misses l2 cache misses derived instrumenting executables expected memory references required dude also suffers least l2 cache misses working set application large dependencedriven execution entirely fit l1 causing dude slight increase l1 cache misses tiling block method hyperbolic 1d pde compare runtime method skewing blocking compiler transformation also measured breakdown cycles hyperbolic 1d pde wavefront computation perfectly nested loop figure 6 shows performance three methods static runtime reordering optimization significantly improve locality static skewing transformation best locality introduces overhead dependencedriven execution control hazards introduced compiler generated code right side figure 1 increase static stalls shown figure analysis skewing code using dcpi also revealed method suffered resource conflict stalls due integer arithmetic subscript expression required compilertransformed code see right side figure 1 component labeling levialdis algorithm 13 component labeling used image processing detect connected components picture involves series phases phase consisting changing 1pixel 0pixel upper left upperleft neighbors 0pixels 0pixel changed 1pixel upper left neighbors 1pixels comparison performances various methods shown figure 6 see higher overhead determining iteration order dynamically small compared benefits avoiding stalls oddeven sort overheads dependencedriven execution proportional number dependence arcs emanating iterate application two arcs per iterate dude dramatically outperforms unoptimized method include performance tiling methods tiling would change iteration order onedimensional problem compiletime skewing transformation apply two functions odd even operations multigrid multigrid another iterative pde solver interesting one five distinct operators smooth even elements smooth odd elements restrict form prolong different dependence relations operations dimension data space also changes depending level multigrid pyramid vector chain additions measure performance dude purely static method determine iteration order analyzed performance simply adding 14 vectors length 1048576 double floats unoptimized version two vectors added entirety adding next vector tiled versions vectors broken chunks containing elements gave best performance elements 031 14 vectors added adding elements forth finally dude used chunk size consisting 512 elements dependence rule set dude incurs slightly overhead determining iteration order also benefits data prefetches effect prefetching study well system prefetches data 1 inspected footprint execution 2 compared cycles breakdown applications without enabling prefetch instruction two prefetch instruction alphas fetchm instruction documented implemented 21164 instuction load ldt ldl zero register implemented documented since running experiments 21164 used load zero register generate prefetches looking footprint execution system prefetching system executing able verify system indeed prefetching next iterate executing current one however performance result observed showed little benefit prefetching applications looked left sided 7 gives us clue prefetching effective applications figure shows hardly l2 misses lot l1 misses implies working set dependencedriven execution large fit l1 prefetching next iterate may help reduce l2 cache misses really source stalls help misses l1 conflicts working set current iterate reduce size working set reducing granularity would increase total overhead figure 8 effect prefetch oddeven sort vector chain addition applications small working sets able get 7 performance improvement prefetching shown figure 8 working set oddeven sort consists left right neighbors onedimensional array working set vector chain addition consist vector containing total sum current vector added expect efficacy prefetching would greater l1 sufficiently big enough fit working set prefetching granularity dependencedriven execution suited distributed shared memory systems larger caches larger latencies nevertheless preliminary experiment indicates prefetching automated dependencedriven execution conclusion compiletime optimizations advantage compilers apply optimizations little overhead cases total execution time runtime optimization advantage information available assuming information compiletime kept runtime information includes state computation values variables dependences satisfied dependences yet satisfied information runtime flexible flexibility comes cost instructions executed cpu cycles however modern commercial machines processor cycles cheap additional cycles used use memory system effectively reduce overall execution time application described runtime system uses symbolic dependence information determine looporder runtime also shown computation driven dependences significantly reduces number cache miss stalls adding relatively insignificant overhead furthermore cache misses cannot avoided shown system also used prefetch data avoid memory access latencies memory access costs become expensive cpu speeds continue get faster size caches continue get larger mechanism prefetching becomes better supported overhead dependencedriven execution becomes justified r automatic loop interchange continuous profiling cycles gone parallel processing largegrain data flow techniques compiler transformations highperformance computing keynote address enhanced runtime support shared memory parallel computing users guide awesime object oriented parallel programming simulation system computer architecture quantitative approach systolic arrays vlsi wavefront array processors vlsi array processors cache performance optimization blocked algorithm shrinking binary picture patterns design analysis spatial data structures improving locality parallelism nested loops high performance compilers parallel computing optimizing supercompilers supercomputers iteration space tiling tr vlsi array processors iteration space tiling computer architecture quantitative approach design analysis spatial data structures cache performance optimizations blocked algorithms chores enhanced runtime support sharedmemory parallel computing linktime optimization address calculation 64bit architecture continuous profiling shrinking binary picture patterns automatic loop interchange compiler transformations highperformance computing optimizing supercompilers supercomputers ctr suvas vajracharya dirk grunwald dependence driven execution multiprogrammed multiprocessor proceedings 12th international conference supercomputing p329336 july 1998 melbourne australia suvas vajracharya steve karmesin peter beckman james crotinger allen malony sameer shende rod oldehoeft stephen smith smarts exploiting temporal locality parallelism vertical execution proceedings 13th international conference supercomputing p302310 june 2025 1999 rhodes greece