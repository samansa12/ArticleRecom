distributed component architecture scientific applications ideal goal user dealing concurrency aspects proven hard achieve context system compiler runtime supported automatic parallelization general purpose languages applications focused approaches automatic parallelization numerical applications regular structure successful still cannot fully handle irregular applications eg solution partial differential equations pdes general geometriesthis paper describes new approach parallelization scientific codes make use objectoriented generic programming techniques order make parallelism implicit invisible user instead generating new solution based existing one take advantage application characteristics order capture concurrency infrastructure provide part solution process user goal achieve transparent concurrency giving user illusion sequential programming environment isolate user tedious aspects geometrical data representation communication patterns computation communication generation process writing parallel solver pdes user concentrates providing local numerical computations straight forward mapping numerical algorithmfurthermore describe system demonstrates approach address issues efficiency system show approach scalable b introduction scientic computing applications concerned solution partial dierential equations pdes describe physical phe nomena typical application areas computa tional uid dynamics computational biology forth solution pdes either finite element method fem finite dierence fd involves discretization physical domain computation solution discretized points computation assembled global system linear equations discrete solution algorithm pde called solver scientic computing eld concerned employing powerful computing resources solving numerical analysis problems pdes example simulating protein folding modeled pdes 10000 particles used copyright c 2002 australian computer society inc paper appeared 40th international conference technology objectoriented languages systems tools pacic 2002 sydney australia conferences research practice information technology vol 10 james noble john potter eds reproduction academic notfor prot purposes permitted provided text included time steps required would require days therefore feasible computation time frame one would need steps exam ple biological data consists 1500 protein elds protein sequences 15000 protein models order predict protein structure possible sets structures generated optimize performing selection based energy func way deal size data arising large numerical computations number iteration steps involved use parallel com puting parallel computing employed extensively scientic computing eld explicit manner parallel scientic applications use fortran language conjunction message passing paradigm message passing interface specify decomposition map ping communication synchronization reuse explored incipient phase function li braries even though limit fortran libraries account reuse fortran applications hardy extendible consequence despite similar structure parallel application redesigned scratch given process writing distributed memory applications complex errorprone means low productivity goal abstract away user distributed computing aspects give user illusion sequential programming model thesis scalable parallelizing compilers real application codes far time approach taking advantage application specic features automate parallelization process separate user data numer ical application specic data parallelization algorithm therefore capture concurrency infrastructure class application hand pde solvers dynamically use users solution process use generic programming techniques order couple user data workload partitions transparent distributed solution process reminder paper refer fem solution process since treat fd case particularization general solution process thus key features fem solvers applications data parallel loosely synchronous domain decomposition technique used break physical domain smaller subdomains treated separately method data border subdomains logically connected data subdomains distributed memory setting means data residing remote processors needed locally computation steps consist independent local com putations followed communication physical domain described geomet rical discretized structure usually translates nodes elements faces edges ie connection elements user application specic abstractions matrices vec tors etc attributes eg pressure temper ature indexed according nodes ele ments faces numerical computation consists mainly iterations entities nodes elements edges applications inherently dynamic experimentation dierent geometrical data struc turedegree freedom element shapes different numerical algorithms time discretization schemes iteration schemes etc core physical phenomena simulation numerical applications make use application domain features pde solvers objectoriented techniques solving problem transparent concurrency numerical applications 11 contributions paper makes following contributions distributed component model scien tic computation present component model suitable concurrent scientic applications enables us achieve illusion sequential programming model distinguish active passive components visibility dierent levels system user take advantage loosely synchronous feature class applications refer therefore component model allows optimal commu nication moreover use generic programming techniques order able couple user data algorithms concurrency infrastruc ture distributed component model notion global address name space remote invocations automatic data consistency introduce notion dependent independent data items dependent data needs globally con sistent independent data distinction allows us guide user invoking global consistency phase computa tion communication automatically taken care architecture scalable solution pdes solution exploits similarities applications well genericity parallelization process order capture concurrency infrastructure reused asis scientic application ie distributed pde solver programmer hardest aspects solution process dealt therefore isolated user geometrical data representation computation communication patterns communication generation reminder paper organized follows section 2 overviews existing approaches problem trying solve transparent con currency motivates approach section 3 presents system transparent concurrency parallel pde solvers section 4 describes prototype framework implementation system also discusses design rationale drove ap proach section 5 concludes paper gives directions future research existing approaches several approaches exist support parallelization scientic applications spectrum approaches lies manual parallelization one end fully automatic parallelization end despite inconveniences manual parallelization still popular approach writing concurrent scientic applications due eciency taylorability hand writing concurrent scientic applications errorprone complex task automatic parallelization one way tackle complexity reliability concurrent applications research parallelizing compilers scientic applications successful fortran applications simple data representations regular access patterns ujaldon sharma 1993 compiletime analysis cannot handle arbitrary data access patterns depend runtime information runtime analysis used address issue compiling concurrent loop nests presence complicated array references irregularly distributed arrays wu das saltz berryman hiranandani 1995 however approaches limited loop level parallelism simple data layouts arrays context fortran lan guages code excerpt gure 1 exemplies applicability compiler support parallelization loop level parallelism ne grain results lot communication also compiler support handle arbitrary access patterns context simple data layouts arrays objectorientedbased distributed systems support data parallel applications proposed chang sussman saltz 1995 hassen either support complex data representations general distribu tion many concurrency aspects still visible user complete survey models languages parallel computation found skillicorn talia 1998 refer objectoriented models skillicorn talia 1998 classied external internal models according whether parallelism orthogonal object model integrated object model interested internal object models closely related dataparallelism since top level language appears sequen tial existing approaches require communication explicit reduce burden synchronization associated model aims hide communication synchronization user prototype implementation succeed achieving extent synchronization phase triggered user anyway extend system implementation automatically detect trigger synchronization phase necessary chaos chang et al 1995 library provides support distributed arrays distributed pointerbased data structures library used directly application programmers parallelize applications adaptive andor irregular data access patterns object model based compilers regular case example 1gather data dependence info ie f303g 2data computation decomposition ie iteration space 3code communication generation based data flow information ownercompute rule runtime support irregular case example 1build communication schedule ie translation table lists home processor local address array element 2move data based schedule transformed code call datamovey ds figure 1 compiletime runtime support parallelization mobile globally addressable objects mobile object object knows pack unpack message buer globally addressable object object assigned one processor allows copies reside processors referred ghost objects rst problem see approach user expected provide implementations pack unpack functions support deep copy subclassing mobile component one hand packing unpacking tasks low level operations expose user many concurrency aspects pack pack unpack unpack hand mobile objects may contain pointer samesubobjects user make sure one copy subobject exists point program execution use globally addressable objects alleviate prob lems global object intended order support global pointer concept main problem see contents ghost objects updated explicit calls data exchange routines approach dierent one mixing concurrency aspects user level let user see active components ie associated process model also need naively transport entire content object every communication update parts objects needed subsequent computations avoid overhead associated communicating entire objects contrast generative approach compiler support parallelization use constructional approach therefore construct part solution want achieve illusion sequential programming environment opposed transforming sequential programs run par allel approach due limited compiler support dynamic analysis eciency consider ations approach based capturing concurrency infrastructure class applications reusing every new application idea similar notion skeletons ready made building blocks abstractions characteristic class applications case closer algorithmic skeletons encapsulate structure botorog kuchen 1995 explore approach algorithmic skeletons common parallelization patterns another class applications ie adaptive multigrid methods moreover botorog kuchen 1995 list series requirements language supporting algorithmic skeletons among data access control polymorphism authors introduce notion parallel abstract data type padt order account required features furthermore host language used experimentation imperative language ie c programming language argue objectoriented models generic programming naturally fulll requirements implementing algorithmic skeletons therefore concentrate ecient data parallel object model suitable high performance parallel applications contrast objectoriented distributed middleware support notion global name address space eciency important applications address methods wouldnt fulll requirement moreover giving user access distributed computing aspects communication synchro nization etc consequence achieve eciency transparency concurrency 3 view system transparent con currency section describe system transparent concurrency distributed solution pdes users perspective perspective emphasize following requirements system applicability class applications address parallelization general solution pdes fem fd etc pdes core engineering natural sciences large class applications system likely highly relevant large applied research community usability expose user small well tested well documented component set together control thread way components play together easily learned used extendibility user able use system conjunction hisher data algorithms order complete solution process eciency last least eciency important requirement scientic applica tions architectural approach driven eciency well succeeding meeting requirements accounted following achieve large applicability focus capturing concurrency infrastructure load balanced data distribution nding data needs communicated ie computing communication patterns knowing communication takes place employ highlevel mathematical interface form geometrical data description discretized physical domain solution general involve algorithmic discrete mathematics interface solution existing computational kernels eg blas dongarra croz hammarling hanson 1988 lapack angerson bai garra greenbaum mckenney du croz ham marling demmel bischof 1990 numerical library eg dipack langtangen 1999 employed user solution process existing numerical libraries distributed solution pdes still lowlevel complex lowlevel mean user still aware data distribution communication aspects well many lowlevel aspects renumbering data access set etc smith 1998 complex mean libraries provide rich mixed function ality part functionality accounts numerical abstractions linear algebra solvers time discretization schemes etc general functionality sometimes duplicated library philosophy geometrical data representation local element global mesh renumbering etc mixed also therefore libraries become large hard use learn separate parallel solution process application specic data algorithm achieve high usability designing small set well tested well documented components narrowly focused functionality solution high level reusable use encapsulation hide details concurrency user achieving reuse asis entire concurrency infrastructure also hide tedious details geometrical data representation user time componentbased design accounts reuse existing numerical software artifacts solution ecient employ truly distributed object model model notion global name address space remote invocations active objects loosely synchronous communication takes place particular times application life time optimize communication knowing exactly communication takes place aggregating data large messages main conceptssteps involved distributed solution pdes 1 geometric data representation 2 data structure creation 3 oprocessor data updates 4 local numerical computation system accounts rst three phases user responsible providing numerical algorithm particular pde 31 geometrical data representation geometrical data representation one hard aspects scientic applications use general meshes even though applications use similar geometries many dierent representations coexist practice making existing scientic codes hard un derstand modify maintain extend isolate geometrical data representation component well dened interface accessing needed geometrical attributes system level geometrical data representation easily placed without aecting system functionality requiring modications system mod ules therefore system takes task providing user geometrical data representation used implementation users application user species structure input domain input le called mesh grid sys tem user also species number processors available hisher system le describing domain prescribed well documented mat les usually obtained help tools called mesh generators 2 system reads data le internal components dierent element shapes used discretization input domain specied mesh le system uses loadbalanced partitioning algorithm provided metis 3 breaking input mesh structure data smaller regions details related geometrical data representation encapsulated system compo nent user gets access geometrical data aspects component interface subdomain system level geometrical data representation easily replaced without aect ing system functionality requiring modi cations system modules 32 data structure creation system creates number regions input data structure equal number processors available associates data region process 4 transparently user internal boundary geometrical mesh data duplicated process user access locally oprocessor data needed one computation user access geometrical data local one processor subdomain compo nent component presents user uniform view geometrical data structure employed sequential programming model implementing numerical algorithm solver distributed computing aspects component incorporates invisible user user subclass system provided component userdata dening attribute eg pressure temperature data abstraction dened mesh structure involved computation nal result user provides concrete example tool found httpwwwsfb013unilinzacat joachimnetgen 4 model single process runs single processor interface storing retrieving user dened data item tofrom specic mesh location element node etc 33 oprocessor data updates concurrency structure applications address solution pdes consists independent local computation followed communication phases therefore loosely synchronous chang et al 1995 order automatically provide oprocessor data updates need know communicate need know communication patterns generate communication system computes communication patterns user explicitly invokes update phase system performs updates transparently region associated process stored subdomain component invisible part component makes use local data order account distributed computing part component computes communication patterns creates communication data container objects maintains global data consistency transparent user user call system provided generic function update makes sure user dened data globally consistent 34 local numerical computation system treats user data dierently depending dependency attribute 1 call dependent data dened user property nal result ie unknown equations solved eg pres sure temperature etc updated another dependent data item eg coecient matrices computed based unknown 2 call independent data user data assigned result expression computed based dependent data figure shows system supports tasks transparently user user contribution completing solution process shown gure 2 employ masterworker concurrency model master process responsible reading domain data input le distributing subdomains workers actually use hybrid masterworker spmd single process multiple data concurrency model use spmd model due key observation parallelization system worker processes execute similar task local domain data class application address share feature namely data parallel gure 2 associate subdomain unique process say subdomain communication capabilities knows packunpack sendreceive inside system components similar fea tures call components active components contrast components passive capture structure data andor algorithm associated without communication ca pabilities user level passive components employed visible user sees passive interface subdomain allow user manipulate appropriate geometrical data hide geometrical data representation user system instantiates computes right subdomain worker user acts subdomain level sequential fashion system replicates user algorithm data workers workers communicate transparently user using messages gure 3 show dierence code excerpt written classical sequential manner code excerpt enriched system functionality look sequential execute dis tributed show classical concurrent model application ie mpi ver sion since assume complexity evident reader space would allow illustration gure 3 emphasize dier ence two models using grey model required modications use black similar parts easy see data items b candidates dependent data therefore code excerpt data specialize component userdata also loc data variable reects data user sees ie subdomain hand data items c independent require modication sequential algorithm important observation user one observe dierence dependent independent data proper guidance provided system documentation user experience task straight forward implemented prototype frame work johnson 1997 bassetti davis quinlan 1998 demonstrate approach using c programming language stroustrup 2000 used metis library load balanced graph partitioning irregular mesh use object oriented message passing interface library communication figure 4 depicts view prototype using uml fowler scott booch 1999 unied modeling language formalism brevity show key components interfaces uml diagram design based careful study application domain pde solvers behavior key observation applications share similar structure dierences residing nu merical problem parameters rather concurrency infrastructure therefore separating parallel algorithm geometrical data application specic parameters data algorithms able come solution automate parallelization process gure 4 useralg component hook user anchor hisher computation framework user subclasses abstract component useralg 6 provides hisher main control ow complements frameworks control ow completing particular application user also hooks data representation hisher application mentioned earlier 34 data independent dependent user dened components imported user libraries case say user extends framework composition composition rst mechanism used extend 6 particular implementation components classes user supplied application specific part input file communication worker 1 worker n mesh data master data decomposition communication metis library library mpi figure 2 main building blocks system framework user dependent data dened subclassing framework container component userdata subclassing second mechanisms used extend framework user access geometrical data subdomain interface subdomain component user algorithm component parameterized subdomain component subdomain created framework user contiguous consistent view hisher data user writes hisher application single subdo main spmd fashion framework instantiates number workers replicate user provided computation subdomains worker process modeled worker component visible user component receives work master process masterworkers fashion master component reads input data provided user discretized physical domain breaks smaller partitions sends workers based local data provided subdomain component worker sets communication patterns cooperations workers generic function update uses communications patterns subdomain container component userdata automatically generate communication every time user calls function updating user dependent data item componentbased design chosen framework due constructional ap proach ie construct part solution process generative approach would analyze existing solution generate new one eg compiler driven parallelization compiler techniques data ow analysis dynamic analysis limited regular applications use simple data layout frameworks fulll best need user able plug data representations al gorithms ie provide remaining part solution process benets architecture choice range ability automate parallelization process general class applications never achieved general irregular applications data locality communication optimization data encapsulation concept naturally provides intensively researched eciency issues data locality communication optimization come free almost least come cost whatever makes objectoriented languages slow abstraction penalty dynamic binding penalty inheritance penalty last least object oriented framework eective route reuse parsons rashid speck telea 1999 genericity important aspect design parallel structure numerical applications refer expressed independently representation concurrency infrastructure based concept generic programming use generic programming able automatically generate communication user data use containers place holders later dened user data able packunpack sendreceive data solution enables us free user distributing computing aspects data distribution data coherence consistency data communication concurrency model use hybrid masterworkers spmd spmd widely used concurrency model numerical applications since data parallel use special process master evenly divide data send work worker processes way workers approximately amount work load computation balanced validation framework two aspects usability level system open source made available researchers application domain area experiment classical sequential model fem poisson solver using tetrahedral mesh void main f computeb computepressure void computepressure f void computea f void computec f void computeb f nonclassical sequential model fem poisson solver using tetrahedral mesh void main f updatep loc data computeb computepressure void computepressure f updatep loc data void computea f void computec f void computeb f binit updateb loc data jk1loc datagetnve local datagetnve bsetatknode temp updateb loc data figure 3 comparison two sequential programming models usermain public useralg userdefined public userdata user supplied components subdomain worker commpattern master metis meshstruct useralg virtual void main oompi intboundary userdata user defined external packages internally used framework framework internals user visible template void updateuserdata subdomain mydomain figure 4 infrastructure framework implementing test suite test functionality framework documentation purposes well eciency point view interested application speedup intend run framework clusters pcs nows network workstations running linux operating system therefore measure application speedup running x sized problems increasing number processors measure dierent size problems well 5 conclusion future work paper presented new approach towards parallelization scientic codes ie constructional approach contrast generative approach egcompiler driven parallelization construct part solution instead generating new solution based existing one use component based architecture order able allow user build concurrency infrastructure approach get closer ideal goal user deal concurrency without restricting generality application class therefore able handle distributed solution pdes general geometries meshes given eciency important constraint class applications address show truly distributed component model alleviate eciency problems objectoriented middleware java rmi nd corba success stories nd distributed component object model dcom nd paper attempts explore appropriateness objects conjunction concurrency much desired association meyer 1993 context high performance computing high performance scientic computing known community traditionally reluctant objectoriented techniques poor performance implementations objectoriented languages systems future work towards bringing evidence approach scalable intended system architecture cheap exible distributed computing platform consisting clusters linux pcs nows scalable approach potentially unlimited number computers used gaining computational power r overview compiler scalable parallel machines ans sorensen lapack portable linear algebra library highperformance computers optimizations parallel objectoriented frame works algorithmic skeletons adaptive multigrid methods distributed component object model dcom n uml distiled brief guide standard object modeling language frameworks compare objectoriented reuse techniques computational partial di systematic concurrent objectoriented programming framewok transition numerical soft ware nutsandbolts abstractions tr extended set fortran basic linear algebra subprograms systematic concurrent objectoriented programming objectoriented runtime support complex distributed data structures flexible operation execution model shared distributed objects models languages parallel computation c programming language computational partial differential equations distributed memory compiler design sparse problems overview compiler scalable parallel machines algorithmic skeletons adaptive multigrid methods runtime techniques parallelizing sparse matrix problems framework object oriented frameworks design