bipartite graph partitioning data clustering many data types arising data mining applications modeled bipartite graphs examples include terms documents text corpus customers purchasing items market basket analysis reviewers movies movie recommender system paper propose new data clustering method based partitioning underlying bipartite graph partition constructed minimizing normalized sum edge weights unmatched pairs vertices bipartite graph show approximate solution minimization problem obtained computing partial singular value decomposition svd associated edge weight matrix bipartite graph point connection clustering algorithm correspondence analysis used multivariate analysis also briefly discuss issue assigning data objects multiple clusters experimental results apply clustering algorithm problem document clustering illustrate effectiveness efficiency b introduction analysis important tool exploratory data mining applications arising many diverse disciplines informally cluster analysis seeks partition given data set compact clusters data objects within cluster similar distinct clusters literature cluster analysis enormous including contributions many research communities see 6 9 recent surveys classical approaches many traditional clustering algorithms based assumption given dataset consists covariate information attributes individual data object cluster analysis cast problem grouping set ndimensional vectors representing data object dataset familiar example document clustering using vector space model 1 document represented ndimensional vector coordinate vector corresponds term vocabulary size n formulation leads socalled termdocument matrix representation collection documents ij socalled term frequency ie number times term occurs document j vector space model terms documents treated asymmetrically terms considered covariates attributes documents also possible treat terms documents firstclass citizens symmetric fashion consider ij frequency cooccurrence term document j done example probabilistic latent semantic indexing 12 1 paper follow basic principle propose new approach model terms documents vertices bipartite graph edges graph indicating cooccurrence terms documents addition optionally use edge weights indicate frequency cooccurrence cluster analysis document collections context based intuitive notion documents grouped topics one hand documents topic tend heavily use subset terms form term cluster hand topic usually characterized subset terms documents heavily using terms tend particular topic interplay terms documents gives rise call biclustering terms documents simultaneously grouped semantically co clustering algorithm computes approximate global optimal solution probabilistic latent semantic indexing relies em algorithm therefore might prone local minima even help annealing process herent clusters within bipartite graph model clustering problem solved constructing vertex graph partitions many criteria proposed measuring quality graph partitions undirected graphs 4 14 pa per show adapt criteria bipartite graph partitioning therefore solve biclustering problem great variety objective functions proposed cluster analysis without efficient algorithms finding approximate optimal solutions show bipartite graph formulation naturally leads partial svd problems underlying edge weight matrix admit efficient global optimal solutions rest paper organized follows section 2 propose new criterion bipartite graph partitioning tends produce balanced clusters section 3 show criterion leads optimization problem approximately solved computing partial svd weight matrix bipartite graph section 4 make connection approximate solution correspondence analysis used multivariate data analysis section 5 briefly discuss deal clusters overlaps section 6 describe experimental results biclustering dataset newsgroup articles conclude paper section 7 give pointers future research 2 denote graph gv e v vertex set e edge set graph graph gv e bipartite two vertex classes x edge e one endpoint x one endpoint consider weighted bipartite graph denotes weight edge vertex j let edge vertices j context document clustering x represents set terms represents set documents w ij used denote number times term occurs document j vertex partition gxy w denoted pia b defined partition vertex sets x respectively set c denotes compliment convention pair b c say pair vertices x 2 x 2 matched respect partition pia b edge x either x 2 2 b two subsets vertices ae define ie w sum weights edges one endpoint one endpoint quantity w considered measuring association vertex sets context cluster analysis edge weight measures similarity data objects partition data objects clusters seek partition association unmatched vertices small possible one possibility consider partition pia b following quantity 1 intuitively choosing pia b minimize cuta b give rise partition minimizes sum edge weights unmatched vertices context document clustering try find two document clusters b b c terms common documents b mostly use terms b c use terms c unfortunately choosing partition based entirely cuta b tends produce unbalanced clusters ie sizes andor b compliments tend small inspired work 4 5 14 propose following normalized variant edge cut 1 intuition behind criterion want partition small edge cut also want two subgraphs formed matched vertices dense possible latter requirement partially satisfied introducing normalizing denominators equation 2 biclustering problem equivalent following optimization problem min ie finding partitions vertex sets x minimize normalized cut bipartite graph gxy w 3 approximatesolutionsusing singular vectors given bipartite graph gxy w associated partition pia b let us reorder vertices x vertices b ordered vertices c respectively weight matrix w written block format ie rows w11 correspond vertices vertex set columns w11 correspond b therefore gabw11 denotes weighted bipartite graph corresponding vertex sets b ie sh sum elements h easy see definition ncut 2 natural criterion seems however shown leads svd problem set left right singular vectors order make connections svd problems first consider case w symmetric 3 easy see w symmetric denoting ncuta ncuta let e vector elements equal 1 let diagonal matrix w vector ae easy verify notice gamma w scalar se cast 4 form rayleigh quotient need find se follows equation easy see thus min ae gamma w oe drop constraints let elements take arbitrary continuous values optimal approximated following relaxed continuous minimization problem min ae gamma w oe notice follows w gamma12 wd gamma12 12 3 different proof symmetric case first derived 14 however derivation simpler transparent leads naturally svd problems rectangular case therefore 12 e eigenvector gamma12 wd gamma12 corresponding eigenvalue 1 easy show eigenvalues gamma12 wd gamma12 absolute value 1 see appendix thus optimal 5 computed second largest eigenvector gamma12 wd gamma12 return rectangular case weight matrix w let dx dy diagonal matrices e 6 consider partition pia b define ae ae let w block form 2 consider augmented 22 interchange second third block rows columns matrix obtain6 6 4 22 07 7 5 j w22 normalized cut written form resembles symmetric case 3 define v also easy see therefore min x60y 60 ae 2x wy oe 11 laplacian w used partitioning rectangular matrix context designing loadbalanced matrixvector multiplication algorithms parallel compu tation however eigenvalue problem laplacian w lead simpler singular value problem ignoring discrete constraints elements x following continuous maximization problem x60y 60 ae 2x wy oe without constraints x problem equivalent computing largest singular triplet gamma12 see appendix 6 12 gamma12 similarly symmetric case easy show singular values gamma12 1 therefore optimal pair fx yg 8 computed x x second largest left right singular vectors gamma12 respectively see appendix discus sion summerize basic approach bipartite graph clustering incorporating recursive procedure algorithm spectral recursive embedding sre given weighted bipartite graph e edge weight matrix w 1 compute dx dy form scaled weight 2 compute second largest left right singular vectors x 3 find cut points cx cy x respectively 4 form partitions vertex set 5 recursively partition subgraphs gab necessary two basic strategies used selecting cut points cx cy simplest strategy set cy 0 another computingintensive approach base selection ncut check n equally spaced splitting points x respectively find cut points cx cy smallest ncut 14 computational complexity major computational cost sre step 2 computing left right singular vectors obtained either power method robustly lanczos bidiagonalization process 8 chapter 9 lanczos method iterative process computing partial svds iterative step involves computation two matrixvector multiplications vectors u v computational cost roughly proportional nnz w number nonzero elements w total computational cost sre oc sre k svd nnz sre level recursion k svd number lanczos iteration steps general k svd depends singular value gaps w also notice nnz average number terms per document n total number document therefore total cost sre general linear number documents clustered 4 connectionstocorrespondence analysis basic form correspondence analysis applied mbyn twoway table counts w 2 10 16 let sum elements w dx dy diagonal matrices defined section 3 correspondence analysis seeks compute largest singular triplets dx iwdy j jw matrix z considered correlation matrix two group indicator matrices original w 16 show svd z closely related svd fact section 3 showed 12 e left right singular vectors w corresponding singular value one also easy show singular values w 1 therefore rest singular values singular vectors w found computing svd following rankone modification k2 constant multiple j element z fore normalizedcut based cluster analysis correspondence analysis arrive svd problems even though start completely different principles worthwhile explore deeply interplay two different points views approaches example using statistical analysis correspondence analysis provide better strategy selecting cut points estimating number clusters 5 partitions overlaps far discussion looked hard clus tering ie data object belongs one one cluster many situations especially much overlap among clusters advantageous allow data objects belong different clusters example document clustering certain groups words shared two clusters possible model overlap using bipartite graph model also find efficient approximate solutions answer seems yes results point rather preliminary illustrate possibilities basic idea computing b disregard contributions set vertices overlap specifically let b ox denotes figure 1 sparsity patterns test matrix clustering left clustering right overlap vertex subsets aox aox oy overlap b oy however make ncuta b smaller simply putting vertices overlap therefore need balance two competing quantities size overlap modified normalized cut minimizing ff regularization parameter find efficient method computing approximate optimal solution minimization problem still needs investigated close section presenting illustrative example showing situations singular vectors already automatically separating overlap sets giving coordinates carrying clustering example 1 construct sparse mbyn rectangular matrix w11 w22 relatively denser w12 w21 also add dense rows columns matrix w represent row column overlaps left panel figure 1 shows sparsity pattern w matrix obtained randomly permuting rows columns w compute second largest left right singular vectors gamma12 wd gamma12 say x sort rows columns w according values entries respectively sparsity pattern permuted w shown right panel figure 1 seen singular vectors job clustering time also concentrate dense rows columns boundary two clusters 6 experiments section present experimental results clustering dataset newsgroup articles submitted 20 news groups 5 dataset contains 20000 articles email messages evenly divided among 20 newsgroups list names newsgroups together associated group labels labels used sequel identify newsgroups ng2 compgraphics ng3 composmswindowsmisc ng4 compsysibmpchardware ng5compsysmachardware ng7miscforsale ng8 recautos ng9recmotorcycles ng10 recsportbaseball ng11recsporthockey ng12 scicrypt ng13scielectronics ng14 scimed ng15scispace socreligionchristian ng17talkpoliticsguns ng18 talkpoliticsmideast ng20 talkreligionmisc used bow toolkit construct termdocument matrix dataset specifically use tokenization option usenet headers stripped also applied stemming 13 newsgroups large overlaps example five newsgroups comp computers fact several articles posted multiple newsgroups apply clustering algorithms dataset several preprocessing steps need consid ered two standard steps weighting feature selec tion weighting considered variant tfidf weighting scheme tf log 2 ndf tf term frequency df document frequency several variations listed 1 feature selection looked three approaches 1 deleting terms occur less certain number times dataset 2 deleting terms occur less certain number documents dataset selecting terms according mutual information terms documents defined x represents term x document 15 general found traditional tfidf based weighting schemes improve performance sre one possible explanation comes connection correspondence analysis raw frequencies samples cooccurrence probabilities pre postmultiplication gamma12 gamma12 gamma12 automatically taking account weighting however found trimming raw frequencies sometimes improve performance sre especially anomalous cases words occur certain documents unusual number times skewing clustering process 5 newsgroup dataset together bow toolkit processing downloaded httpwwwcscmueduafscsprojecttheo11www naivebayeshtml table 1 comparison spectral embedding sre pddp kmeans ng1ng2 mixture sre pddp kmeans 50100 9057 sigma 311 8611 sigma 394 86 5 table 2 comparison spectral embedding sre pddp kmeans ng10ng11 mixture sre pddp kmeans purpose comparison consider two clustering methods 1 kmeans method 9 2 principal direction divisive partion pddp method 3 kmeans method widely used cluster analysis tool variant used employs euclidean distance comparing dissimilarity two documents applying kmeans normalize length document euclidean length one essence use cosine angle two document vectors measuring similarity also tried kmeans without document length normalization results far worse therefore report corresponding results since kmeans method iterative method need specify stopping criterion variant used compare centroids two consecutive iterations stop difference smaller predefined tolerance pddp another clustering method utilizes singular vectors based idea principal component analysis shown outperform several standard clustering methods hierarchical agglomerative algorithm 3 first document considered multivariate data point set document normalized unit euclidean length centered ie let w termdocument matrix w average columns w compute largest singular value triplet fu oe vg split set documents based values simple scheme let positive v go one cluster nonnegative v inot another cluster whole process repeated termdocument matrices two clusters respectively although clustering method sre pddp make use singular vectors versions termdocument matrices derived fundamentally different principles pddp featurebased clustering method projecting data points onedimensional subspace spanned first principal axis sre similaritybased clustering method two cooccurring variables terms documents context document clustering simultaneously clustered unlike sre pddp welldefined objective function minimization partitions columns termdocument matrices sre partitions rows columns significant impact computational costs pddp however advantage applied dataset positive negative values sre applied datasets nonnegative data values example 2 example examine binary clustering uneven clusters consider three pairs news groups newsgroups 1 2 wellseparated 10 11 less wellseparated lot overlap used document frequency feature selection criterion delete words occur less 5 documents datasets used kmeans pddp apply tfidf weighting together document length normalization document vector euclidean norm one sre trim raw frequency maximum 10 newsgroup pair select four types mixture articles newsgroup xy indicates x articles first group articles second group results listed table 1 groups 1 2 table 2 groups 10 11 table 3 groups list means standard deviations 100 random samples pddp kmeans also include triplet numbers indicates many 100 samples sre performs better first number second number worse third num ber corresponding methods pddp kmeans emphasize kmeans method find local minimum results depend initial values stopping criteria also reflected large standard deviations associated kmeans method three tests conclude sre pddp outperform kmeans method performance sre pddp similar balanced mixtures sre superior pddp skewed mixtures example 3 example consider easy multicluster case examine five newsgroups 2 9 10 15 also considered 15 sample 100 articles newsgroups use mutual information feature selection use minimum normalized cut cut point level recursion one sample table 4 gives confusion matrix accuracy sample 882 also tested two samples accuracy 854 812 compare favorably obtained three samples accuracy 59 58 53 reported 15 following also listed top words clusters computed mutual information table 3 comparison spectral embedding sre pddp kmeans ng18ng19 mixture sre pddp kmeans table 4 confusion matrix newsgroups f2 9 10 15 18g mideast graphics space baseball motorcycles cluster cluster cluster cluster cluster armenian israel arab palestinian peopl jew isra iran muslim kill turkis war greek iraqi adl call 2 imag file bit green gif mail graphic colour group version comput jpeg blue xv ftp ac uk list 3 univers space nasa theori system mission henri moon cost sky launch orbit shuttl physic work clutch year game gant player team hirschbeck basebal hi lost ball defens base run win 5 bike dog lock ride wave drive black articl write apr motorcycl ca turn dod insur 7 conclusions future work paper formulate class clustering problems bipartite graph partitioning problems show efficient optimal solutions found computing partial singular value decomposition scaled edge weight matrices however also shown still remain many challenging problems one area needs investigation selection cut points number clusters using multiple left right singular vec tors possibility adding local refinements improve clustering quality 6 another area find efficient algorithms handling overlapping clusters finally treatment missing data bipartite graph model especially apply spectral clustering methods problem data analysis recommender systems also deserves investigation 8 acknowledgments 6 difficult use local refinement pddp global objective function minimization work hongyuan zha xiaofeng supported part nsf grant ccr9901986 work xiaofeng chris ding horst simon supported part department energy lbl ldrd fund 9 r finding cognitive perspective search engine technology www correspondence analysis handbook principal direction divisive partitioning spectral graph theory improved spectral bisection algorithm application dynamic load balancing analysis algebraic connectivity graphs matrix computations second edition correspondence analysis practice partitioning sparse rectangular structurally nonsymmetric matrices parallel computation probabilistic latent semantic indexing toolkit statistical language modeling normalized cuts image segmentation modern applied statistics splus tr improved spectral bisection algorithm application dynamic load balancing matrix computations 3rd ed probabilistic latent semantic indexing document clustering using word clusters via information bottleneck method partitioning rectangular structurally unsymmetric sparse matrices parallel processing finding principal direction divisive partitioning normalized cuts image segmentation ctr bhushan mandhani sachindra joshi krishna kummamuru matrix density based algorithm hierarchically cocluster documents words proceedings 12th international conference world wide web may 2024 2003 budapest hungary hongyuan zha xiang ji correlating multilingual documents via bipartite graph modeling proceedings 25th annual international acm sigir conference research development information retrieval august 1115 2002 tampere finland wei xu yihong gong document clustering concept factorization proceedings 27th annual international acm sigir conference research development information retrieval july 2529 2004 sheffield united kingdom h srinivasan features unsupervised document classification proceeding 6th conference natural language learning p17 august 31 2002 long zhongfei mark zhang xiaoyun w philip yu spectral clustering multitype relational data proceedings 23rd international conference machine learning p585592 june 2529 2006 pittsburgh pennsylvania long xiaoyun wu zhongfei mark zhang philip yu unsupervised learning kpartite graphs proceedings 12th acm sigkdd international conference knowledge discovery data mining august 2023 2006 philadelphia pa usa chris ding tao li adaptive dimension reduction using discriminant analysis kmeans clustering proceedings 24th international conference machine learning p521528 june 2024 2007 corvalis oregon hua yan keke chen ling liu efficiently clustering transactional data weighted coverage density proceedings 15th acm international conference information knowledge management november 0611 2006 arlington virginia usa zhengyu niu donghong ji chewlim tan document clustering based cluster validation proceedings thirteenth acm international conference information knowledge management november 0813 2004 washington dc usa bin gao tieyan liu guang feng tao qin qiansheng cheng weiying hierarchical taxonomy preparation text categorization using consistent bipartite spectral graph copartitioning ieee transactions knowledge data engineering v17 n9 p12631273 september 2005 bin gao tieyan liu xin zheng qiansheng cheng weiying consistent bipartite graph copartitioning starstructured highorder heterogeneous data coclustering proceeding eleventh acm sigkdd international conference knowledge discovery data mining august 2124 2005 chicago illinois usa gne erkan language modelbased document clustering using random walks proceedings main conference human language technology conference north american chapter association computational linguistics p479486 june 0409 2006 new york new york zhengyu niu donghong ji chew lim tan using cluster validation criterion identify optimal feature subset cluster number document clustering information processing management international journal v43 n3 p730739 may 2007 long zhongfei mark zhang xiaoyun wu philip yu relational clustering symmetric convex coding proceedings 24th international conference machine learning p569576 june 2024 2007 corvalis oregon navaratnasothie selvakkumaran george karypis multiobjective hypergraph partitioning algorithms cut maximum subdomain degree minimization proceedings ieeeacm international conference computeraided design p726 november 0913 bin gao tieyan liu tao qin xin zheng qiansheng cheng weiying web image clustering consistent utilization visual features surrounding texts proceedings 13th annual acm international conference multimedia november 0611 2005 hilton singapore chris ding tao li wei peng haesun park orthogonal nonnegative matrix tfactorizations clustering proceedings 12th acm sigkdd international conference knowledge discovery data mining august 2023 2006 philadelphia pa usa han lee giles hongyuan zha cheng li kostas tsioutsiouliklis two supervised learning approaches name disambiguation author citations proceedings 4th acmieeecs joint conference digital libraries june 0711 2004 tuscon az usa ying zhao george karypis usama fayyad hierarchical clustering algorithms document datasets data mining knowledge discovery v10 n2 p141168 march 2005 ying zhao george karypis empirical theoretical comparisons selected criterion functions document clustering machine learning v55 n3 p311331 june 2004 han hongyuan zha c lee giles name disambiguation author citations using kway spectral clustering method proceedings 5th acmieeecs joint conference digital libraries june 0711 2005 denver co usa