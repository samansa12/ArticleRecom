factorization matrix polynomials symmetries n times n matrix polynomial llambda real complex coefficients called selfadjoint factorizations selfadjoint symmetric matrix polynomials form studied constant matrix mlambda matrix polynomial particular minimal possible size described terms elementary divisors llambda sometimes signature hermitian values llambda b introduction let matrix polynomial j j complex n theta n matrices complex parameter polynomial l called selfadjoint factorizations form constant matrix necessarily size l matrix polynomial studied literature various additional hypotheses see ja co glr1 glr2 study factorizations 11 motivated several applied problems filtering chapter 9 factorizations matrix polynomial l types symmetries studied literature well see eg lyu1 lyu2 polynomials natural seek factorizations type constant matrix necessarily size l matrix polynomial paper identify minimal possible size matrix factorization types 11 12 l appropriate symmetry cases l complex coefficients real coefficients studied l assumed real 11 12 assumed real well result concerning faculteit wiskunde en informatica vrije universiteit de boelelaan 1081 1081 hv amsterdam netherlands ydepartment mathematics college william mary williamsburg va 231878795 usa partially supported nsf grant dms9000839 nsf international cooperation grant netherlands factorization 11 generalization main result glr2 case constant signature considered additional hypothesis det l 6j 0 present also section 2 general factorization results abstract framework matrix polynomials field suitable symmetries results although independently interesting play auxiliary role paper serving essential ingredients proofs main results given sections 36 following notation used throughout paper standard notation rc denote real complex field k k theta k unit matrix resp transpose resp conjugate transpose matrix abbreviated gammat resp gamma block diagonal matrix blocks z 1 zm main diagonal denoted z 1 phi delta delta delta phi zm diag z 1 zm hermitian n theta n matrix x let x number positive resp negative zero eigenvalues x counted multiplicities thus given matrix polynomial l c general rank rl defined coincides notion general rank introduced used section 2 matrix polynomial field f points called regular points l points 0 2 c called singular clearly set singular points finite possibly empty n theta n matrix polynomial l called regular acknowledgement problem concerning minimal possible size factorizations complex selfadjoint matrix polynomials posed prof gohberg 2 symmetrix matrix polynomials general field let f commutative field let f ring polynomials f one variable matrices l entries f called matrix polynomials f wellknown see eg every theta n matrix polynomial l admits representation called smith form e f matrix polynomials sizes theta n theta n respectively constant nonzero determinants 1 r monic scalar polynomials f divides i1 1 polynomials called invariant polynomials l polynomials well number r uniquely determined l r theta r maximal size square submatrix l determinant identically zero r product 1 greatest common divisor determinants theta submatrices l number r called general rank l denoted rl section study factorizations symmetric matrix polynomials smith form main tool assume characteristic f different 2 given automorphism oe f oe consider following transformation theta n matrix polynomial e polynomials x rules used often sequel theta n matrix polynomial l called generally invertible invariant polynomials constant 1 terminology justified fact l generally invertible l generalized inverse ie matrix polynomial n fact easily proved using smith form matrix polynomial l called right resp left invertible exists matrix polynomial n ln j resp nl j state one main factorization results section theorem 21 let l n theta n generally invertible matrix polynomial let r general rank l l factorized form r theta n right invertible matrix polynomial r theta r constant matrix conversely 24 holds r theta n right invertible matrix polynomial constant matrix generally invertible general rank r proof converse statement easy indeed ei 0 e f smith form f e ei 0 e f f e uniqueness smith form l generally invertible general rank r verification 23 trivial prove direct statement observe proof easily reduced case const edf smith form l let e l matrix polynomial e l equality e ed last rows columns e zeros obviously suffice prove direct statement r theta r matrix polynomial n formed first r rows columns e l det n j const 6 0 required reduction accomplished assume det l case direct statement follows theorem 3 lyu1 see also lyu2 outline alternative procedure developed co co glr2 section 4 prove exists n theta n matrix polynomial x det x matrix polynomial either ff 11 j 0 diagonally dominant ie degree ff jj bigger degrees nonzero entries jth row jth column fact without loss generality assume either l diagonally dominant 11 entry l identically zero l diagonally dominant must constant done let 1 polynomials put c calculation shows 1 gammax gammac det 1 another straightforward calculation shows l 0 n gamma 1 theta n gamma 1 matrix polynomial thus reduced size l one complete proof induction n proof theorem 21 shows constant matrix taken diagonal l generally invertible easy examples show representation 24 size equal general rank l always possible even omit requirement right invertible however obtain factorization result generally invertible l allow polynomial special properties state prove result need concept elementary divisors let l theta n matrix polynomial invariant polynomials 1 r s1 r nonconstant l generally invertible say l elementary divisors factor irreducible pairwise relatively prime nonconstant monic scalar polynomials f collection factors f ij factor repeated many times occurs 25 called elementary divisors l positive integer ff ij called order elementary divisibility relations among invariant polynomials collection elementary divisors l determines invariant polynomials uniquely therefore invariant transformations theorem 22 let l n theta n matrix polynomial let r general rank l let ff 1 ff 1 f q ff q g collection elementary divisors l l admits factorization r theta n matrix polynomial r theta r matrix polynomial moreover collection elementary divisors ff jg subset j f1 2 qg consists precisely indices j f odd recall taken 22 proof proof theorem 21 assume ed 1 f smith form l invariant polynomials 1 r main diagonal 1 uniqueness invariant polynomials fact r factor degree appears monic part definition invariant polynomials leading coefficient degree sequel convenient denote scalar polynomial f thus observe f monic f monic replacing l f gamma1 assume without loss generality ith column l divisible n symmetry ith row l divisible let nonconstant invariant polynomials l r factor 25 uniqueness decomposition 25 obtain set ff i1 f ik must consist selfsymmetric polynomials f pairs mutually symmetric case necessarily ff ij selfsymmetric smallest index ff say exists put assume elementary divisors numbered f make subsequent formulas uniform define also 1 divisibility relations imply whenever f consequently obtain h divides h formulas 25 lead factorization sign g chosen g monic clearly g divides g i1 view 26 factorization matrix polynomial e l denote e r invariant polynomials e l equality 27 together binetcauchy formula determinants submatrices product several matrices implies following every determinant j theta j submatrix l linear combination polynomial coefficients determinants j theta j submatrices e l determinants multiplied follows 1 j divides e r equality 26 shows g 1 g j divides e hand jth entries e ij e l p ij l respectively obtain e since assuming polynomials e divisible g j also e divisible g g divides g j j symmetry e l obtain e divisible g maxij therefore determinant every j theta j submatrix e l divisible g 1 g j consequently e divides g 1 g j comparing previously obtained opposite divisibility relation conclude r fact invariant polynomials e l repeat procedure given l replaced e l finite number steps obtain matrix polynomial properties required theorem 22 3 factorization selfadjoint matrix polynomials real axis section consider matrix polynomials l c following property polynomials called selfadjoint theorem 31 let l selfadjoint n theta n matrix polynomial l admits factorization theta constant hermitian matrix theta n matrix polynomial moreover factorizations 31 minimal size 0 theta 0 matrix uniquely determined congruence max l positive eigenvalues negative eigenvalues multiplicities counted say spectral properties factor 31 set nonreal numbers called cset respect selfadjoint matrix polynomial l maximal inclusion set nonreal singular points l property 2 case cset empty excluded concept cset introduced used glr1 glr3 turns given l theorem 31 given cset exists factorization 31 0 theta 0 set nonreal singular points coincides statement follows byproduct proof given theorem 31 theorem 31 admits alternative formulation n theta n matrix polynomial called elementary positive semidefinite real difficult see fact actually particular case theorem 31 elementary form polynomial one consider elementary matrix polynomials building blocks selfadjoint matrix polynomial spirit constant rank 1 positive semidefinite matrices building blocks constant hermitian matrices theorem 32 selfadjoint n theta n matrix polynomial l admits representation elementary matrices number terms 34 greater equal 0 0 given 33 exactly max l j equal 1 exactly max gamma l j equal gamma1 obtain theorem 32 theorem 31 assume without loss generality 31 diagonal matrix sigma1s main diagonal let jth row produce formula 34 corollary 33 selfadjoint n theta n matrix polynomial admits factorization 31 representation 34 2n selfadjoint matrix polynomials example li exist representations 31 34 rest section devoted proof theorem 31 start easy direction let given factorization 31 let 0 real point must least positive eigenvalues analogously must least gamma l 1 negative eigenvalues 1 2 r chosen obtain therefore inequality 32 also clear factorization 31 0 theta 0 hermitian matrix unique congruence remains show given selfadjoint matrix polynomial l admits factorization size difficult part need preliminaries note l selfadjoint transformation defined section 2 nevertheless general results section 2 used preliminary results need proposition 34 already available literature noted however result theorem 22 plays essential role proof proposition 34 first observe exists n theta n matrix polynomial n constant nonzero determinant l 0 selfadjoint k theta k matrix polynomial theorem 324 35 proved symmetric matrices principal ideal rings n replaced n proof works produce 35 also 35 obtained without difficulties smith form l see section 2 35 assume beginning general rank l equal n ie det l 6j 0 next observation result theorem 31 known case l constant signature ie l therefore also real regular points proposition 34 glr2 let l selfadjoint n theta n matrix polynomial necessarily det l 6j 0 l admits factorization 31 n theta n size prove following lemma lemma 35 let l selfadjoint n theta n matrix polynomial det l 6j 0 defined 23 exists 0 theta 0 selfadjoint matrix polynomial e l e equivalently e l regular constant signature proof rellichs theorem r see also glr3 eigenvalues 1 n l real enumerated 1 n real analytic functions real variable clearly 0 2 r singular 0 zero least one analytic functions 1 n let 0 2 r singular let every multiplicity 0 zero j let j sign nonzero real number j suppress dependence j j 0 notation define integer q 0 f indices definition q 0 clear sufficiently small 0 easy see maximum taken regular real points 1 2 also follows 37 summation right hand side 39 singular points 0 denote righthand side 39 p construct p scalar real polynomials following properties zeros r j j real simple belong set real singular points 0 l q 0 6 0 ii every 2 exactly jq 0 j polynomials among r 1 r p 0 zeros r j r j 0 definition p ensures polynomials r 1 r p indeed constructed let e property ii view qualities 38 39 easy see number positive eigenvalues e l constant every real regular point l equality 36 therefore follows easily finish proof theorem 31 indeed given selfadjoint matrix polynomial l det l 6j 0 construct e l lemma 35 apply proposition 34 e e constant 0 theta 0 hermitian matrix 31 holds formed first n columns n 4 factorization real symmetric matrix polynomials let real symmetric matrix polynomial ie j j 0 real symmetric n theta n matrices polynomials l consider factorizations constant real symmetric theta matrix matrix polynomial real coefficients convenient state next theorem terms elementary divisors see section 2 definitions concepts related elementary divisors theorem 41 let l real symmetric n theta n matrix polynomial assume elementary divisors l powers irreducible quadratic polynomials r even orders l admits factorization 41 defined 33 moreover factorization 41 minimal possible size matrix uniquely determined congruence exactly max positive eigenvalues exactly max negative eigenvalues multiplicities counted alternatively l admits representation real elementary matrices case number 1s resp gamma1s among exactly particular theorem 41 applies singular points l real proof part easy direction proved proof theorem 31 also easily reduce proof case det l 6j 0 using theorem 22 assume elementary divisors l first degree polynomials necessarily real roots proof proceeds way theorem 31 role proposition 34 played proposition 42 proposition 42 let l real symmetry n theta n matrix polynomial elementary divisors first degree polynomials assume l admits factorization 41 n theta n size proposition 42 proved repeating arguments leading proof theorem 1 glr2 omit details hypothesis orders elementary divisors l omitted theorem 41 easy scalar examples example show result theorem 41 generally valid scalar examples show also case matrices minimal size factorizations 41 necessarily congruent 6 42 however upper bound minimal rise theorem 43 let l real symmetric n theta n matrix polynomial let 0 defined 33 every admits factorization 41 proof assume first 0 n theorem 31 0 theta 0 constant hermitian matrix chosen real without loss generality complex matrix polynomial write real matrix polynomials separating real part 43 obtain desired factorization use simple equality 5 factorization symmetric real polynomials imaginary axis section consider case n theta n matrix polynomials l l real real note polynomial selfadjoint imaginary axis ie immediate consequence theorem 31 applied li matrix polynomial admits factorization complex theta hermitian matrix complex theta n matrix polynomial shall show section taken real note contrast situation section 4 analogous factorization real symmetric matrix polynomial real factors always possible first shall deal case l regular constant signature imaginary axis general case reduced case constant signature view theorem 22 restrict attention matrix polynomials elementary divisors form real nonzero next deal case l regular constant signature theorem 51 suppose l real regular n theta n matrix polynomial satisfying constant signature imaginary axis l constant regular points 2 ir l admits factorization n theta n matrix polynomial real coefficients n theta n constant real matrix proof theorem 22 may assume l pure imaginary eigenvalues elementary divisors linear sense c first deal case elementary divisor l using smith form l write real monic scalar polynomials e f real n theta n matrix polynomials det e 22 b 11 q theta q matrix polynomial moreover b must invertible otherwise det b l hence also det l would divisible l constant signature b l means b li 2 r hermitian matrix constant signature real except finite number points using rellichs theorem r write u unitary valued analytic j analytic real functions simple zeros b l linear elementary divisors c without loss generality may assume glr2 q even exactly half numbers 0 positive half negative let u j jth column u 0 one calculates quadratic form given b positive squares q negative squares 52 ker li 0 span therefore conclude invertible matrix v block repeated q times moreover simple argument shows v taken real determinant first state prove lemma shall return proof theorem 51 lemma 52 let w complex invertible n theta n matrix real determinant let 0 nonzero real number exists real n theta n matrix polynomial constant determinant mi 0 proof decompose w product elementary matrices w j either triangular ones diagonal exactly one nonzero offdiagonal entry w j diagonal invertible matrix multiplying diagonal w j suitable complex number ff j detff j w j real assume without loss generality det w j real j use hypothesis det w real furthermore writing f0g assume every diagonal matrix w j 54 real nonzero determinant two diagonal entries different 1 located adjacent positions clearly suffice construct polynomial required fixed j w j triangular let real constant j w j finally w 1r resp 1i stands real resp imaginary part 1 2 theta 2 block position position easy verify q fact real polynomial defined 55 real matrix polynomial constant nonzero determinant mi 0 let us return proof theorem 51 let v 53 choose real q theta q polynomial constant nonzero determinant mi 0 possible lemma 52 recall det v real may replace b l e constant nonzero determinant e l matrix polynomial may write e put phi ngammaq leading block repeated q times shall show lk gamma1 polynomial note may pole sigmai 0 suffices show pole either one points moreover pole n must appear leading q theta q block leading q theta q block equals easy computation shows recalling b 11 0 see n polynomial taking determinants see n eigenvalue sigmai 0 applying argument nonzero singular point l reduce proof theorem 51 case zero possible singular point l however case similar argument shows l admits representation k real matrix polynomial n real matrix polynomial without singular points cf proof proposition 34 given glr2 reduced case l singular points case result follows theorem 21 next state main result section theorem 53 let n theta n matrix polynomial real coeffi cients real theta matrix real coefficients matrix unique congruence real orthogonal matrix analogously theorem 31 polynomial theorem 53 chosen additional spectral properties given polynomial l theorem 53 set numbers nonzero real parts called dset respect l maximal set singular points l nonzero real parts property dset may empty turns hypotheses theorem 53 every given dset exists factorization 56 set nonreal singular points coincides follows byproduct proof theorem 53 including theorem 51 theorem 22 proof uniqueness verified proof theorem 31 well fact 0 necessary existence real 56 satisfied seen proof theorem 31 remains prove sufficiency may reduce regular case section 3 case l constant signature finished using theorem 51 case l constant signature imaginary axis shown exists real 0 theta 0 matrix polynomial e l e lgamma e l regular constant signature imaginary axis indeed li selfadjoint real write using rellichs theorem r also glr3 analytic real valued u analytic unitary since r matrices li lgammai eigenvalues therefore every point 0 2 r permutation oe f1 ng neighborhood 0 r sigmai 0 singular points l proof lemma 35 follows 58 q 0 singular point l furthermore analogously 38 summation singular point l real numbers 1 2 1 2 regular points l denote number 59 p proof lemma 35 construct p polynomials real coefficients following properties real 2 r ii zeros r j pure imaginary nonzero numbers belong set pure imaginary singular points 0 l q 0 6 0 iii every 0 2 exactly jq 0 j polynomials among r 1 r p 0 zero r j 0 zero note qgamma 0 satisfied gamma 0 satisfied 0 put e l regular constant signature imaginary axis desired thus theorem 51 e l admits factorization e 0 theta 0 real matrix n 0 theta n real matrix polynomial taking matrix polynomial formed first n columns n finishes proof analogously theorem 32 result theorem 53 put terms additive representations l via elementary matrix polynomials real n theta n matrix polynomial called elementary positive semidefinite hermitian 2 ir theorem 54 let l theorem 53 l admits representation elementary matrix polynomials defined 57 moreover exactly 510 equal 1 exactly max equal gamma1 omit easy derivation theorem 54 theorem 53 6 factorization complex symmetric polynomials section consider n theta n matrix polynomials l complex coefficients symmetry fixed factorizations form mthetan matrix polynomial c constant complex symmetric matrix observe every theta complex symmetric matrix factored see eg p 159 hj therefore may assume 62 contrast sections 35 signatures hermitian matrices play role start case theorem 61 let l n theta n matrix polynomial satisfying 61 minimal size l admits factorization theta n matrix polynomial equal general rank r l proof use ideas proofs results previous sections therefore proof theorem 61 presented less detail clearly factorization 63 impossible r therefore prove factorization exists r assume fact ie det l 6j 0 apply theorem 22 gamma1 since irreducible monic complex polynomial f satisfying f theorem 22 assume replacing l elementary divisors l times k necessarily even indeed property ensures det const k even function application theorem 21 gives desired result suppose therefore k 0 using smith form l write ngammak e f n theta n matrix polynomials constant nonzero determinants replacing l assume first k columns symmetry also first k rows l divisible thus matrix polynomials respectively moreover gammal 1 claim invertible det would divisible consequently det l k det would divisible k1 impossibility l 1 0 skewsymmetric therefore admits factorization invertible matrix q let phi ngammak summand repeated ktimes matrix polynomial e l e thing immediate claim e l indeed polynomial point c e could conceivably pole phi ngammak ngammak ngammak phi ngammak clearly z analytic coefficient gamma1 laurent series z neighborhood ngammak ngammak finish proof remains apply theorem 21 z finally consider matrix polynomials l symmetry 61 theorem 62 let n theta n matrix polynomial c let r general rank l l admits factorization theta n matrix polynomial case product invariant polynomials l square complex polynomial resp square complex polynomial proof omit many details assume r n l admits factorization 65 n theta n det product invariant polynomials l must square well implies part prove part first observe suffices consider case det l square polynomial replace l f judiciously chosen scalar polynomial f det l square theorem 22 may assume elementary divisors l first degree polynomials since det l square number elementary divisors l 2 c fixed even proof theorem 61 assume matrix polynomials l 1 respectively moreover l 1 invertible symmetric therefore invertible matrix q direct summand repeated k times proof theorem 61 verify defined 64 e l matrix polynomial e e l elementary divisors form gamma apply procedure e place l using elementary divisors l b 2 c matrix polynomial l 1 apply theorem 21 get desired factorization l gamma 1 theorems 61 62 recast terms elementary matrices analogously theorem 32 n theta n matrix polynomial c called elementary 1 theta n row polynomial x 6 0 theorem 63 let l nthetan matrix polynomial satisfying 61 let r general rank l l written sum r elementary matrices unless product elementary divisors l square polynomial latter case l written sum r 1elementary matrices cannot represented sum r 1elementary matrices r linear systems spectral analysis selfadjoint matrix polynomials factorization selfadjoint matrix polynomials constant signature matrix polynomials topics matrix analysis factorization symmetric matrices elements ring involution factorization symmetric matrices elements ring involution ii perturbation theory eigenvalue problems tr