randomized cache placement eliminating conflicts abstractapplications regular patterns memory access experience high levels cache conflict misses sharedmemory multiprocessors conflict misses increased significantly data transpositions required parallelization techniques blocking introduced within single thread improve locality result yet conflict misses tension minimizing cache conflicts transformations needed efficientparallelization leads complex optimization problems parallelizing compilers paper shows introduction pseudorandom element cache index function effectively eliminate repetitive conflict misses produce cache miss ratio depends solely working set behavior examine impact pseudorandom cache indexing processor cycle times present practical solutions major implementation issues type cache conclusions supported simulations superscalar outoforder processor executing spec95 benchmarks well cache simulations individual loop kernels illustrate specific effects present measurements instructions committed per cycle ipc comparing performance different cache architectures wholeprogram benchmarks spec95 suite b introduction upward trend processor clock frequencies last ten years extrapolated next ten years see clock frequencies increase factor twenty period 1 however based current 7 per annum reduction dram access times 2 memory latency expected reduce 50 next ten years potential tenfold increase distance main memory serious implications design future cachebased memory hierarchies well architecture memory devices block main memory placed exactly one set blocks cache chosen set determined indexing function conventional caches typically extract field bits address use select one block set 2 whilst easy imple ment indexing function robust principal weakness susceptibility repetitive conflict misses example c number cache sets b block size addresses 1 2 map cache set j 1 b j c j 2 b j c 1 2 collide cache set addresses 1 2 k also collide cache integer k except two common cases happens firstly accessing stream addresses fa collides ik may mgammak conflict misses stream secondly accessing elements two distinct arrays b 0 collides b 1 j b 0 ik collides conditions outlined setassociativity help alleviate conflicts effective solution repetitive regular conflicts one best ways control locality dense matrix computations large data structures use tiled algorithm effectively reordering iteration space increases temporal locality ever previous work shown conflicts introduced tiling serious problem 3 practice meant compilers tile loop nests really ought compute maximal conflictfree tile size given values b major array dimension n cache capacity c often small make worthwhile tiling loop perhaps value n known compile time gosh et al 4 present framework analyzing cache misses perfectlynested loops affine references develop generic technique determining optimum tile sizes methods determining array padding sizes avoid conflicts methods require solutions sets linear diophantine equations depend upon sufficient information compile time find solutions table highlights problem conflict misses reference spec95 benchmarks programs compiled maximum optimization level instrumented atom tool 5 data cache similar firstlevel cache alpha 21164 microprocessor simulated 8 kb capacity 32byte lines writethrough write allocate benchmark simulated first 2 operations nowriteallocate feature tables refer load operations table shows miss ratio following cache ganizations directmapped twoway associative column associative 6 victim cache four victim lines 7 twoway skewedassociative 8 9 schemes twoway skewedassociative cache uses unconventional indexing scheme proposed author comparison miss ratio fullyassociative cache shown penultimate column miss ratio difference directmapped cache fullyassociative cache shown rightmost column table represents directmapped conflict miss ratio cmr 2 case hydro2d apsi organizations exhibit lower miss ratios fullyassociative cache due suboptimality lru replacement fullyassociative cache particular programs effectively directmapped conflict miss ratio represents dm 2w ca vc sa fa cmr tomcatv 538 481 470 266 221 125 413 su2cor 110 91 93 95 96 89 21 hydro2d 176 171 172 170 171 175 01 mgrid 38 36 42 37 41 35 03 applu 76 64 65 69 67 59 17 turb3d 75 65 64 70 54 28 47 apsi 155 133 134 107 115 125 30 fpppp 85 27 27 75 22 17 68 wave 318 317 307 201 168 139 179 go 134 82 86 109 75 48 86 gcc 106 72 73 86 66 53 53 compress 171 158 163 162 143 130 41 li 86 54 55 72 49 38 48 ijpeg 41 33 31 23 19 12 29 perl 107 73 75 93 69 52 55 vortex 53 27 27 38 18 14 39 ave ave int 922 644 667 767 566 442 480 average 159 138 136 113 866 680 914 cache miss ratios directmapped dm 2way setassociative 2w columnassociative ca victim cache vc 2way skewed associative sa fullyassociative organizations conflict miss ratio cmr also shown target reduction miss ratio hope achieve improved indexing schemes type misses compulsory capacity remain unchanged use randomized indexing schemes expected improvement 2way setassociative cache directmapped cache rather low columnassociative cache provides miss ratio similar twoway setassociative cache since former lower access time requires two cache probes satisfy hits choice two organizations take account implementation parameters access time miss penalty victim cache removes many conflict misses outperforms fourway setassociative cache finally twoway skewed associative cache offers lowest miss ratio previous work shown significantly effective fourway conventionallyindexed setassociative cache 10 paper investigate use alternative index functions reducing conflicts discuss practical implementation issues section ii introduces alternative index functions section iii evaluates conflict avoidance properties section iv discuss number implementation issues effect novel indexing functions cache access time section v evaluate impact proposed indexing scheme performance dynamicallyscheduled processor finally section vi draw conclusions study ii alternative indexing functions aim paper show alternative cache organizations eliminate repetitive conflict misses analogous problem finding efficient hashing function large secondary tertiary caches may possible use virtual address mapping adjust location pages cache suggested bershad et al 11 thus avoiding conflicts dynamically however small firstlevel caches effect achieved using alternative cache index function field interleaved memories well known bank conflicts reduced using bank selection functions simple modulopoweroftwo lawrie vora proposed scheme using primemodulus functions 12 harper jump 13 sohi 14 proposed skewing functions use xor functions parallel memory systems proposed frailong et al 15 pseudorandom functions proposed raghavan hayes 16 rau et al 17 18 schemes yield less uniform distribution requests banks varying degrees theoretical predictability implementation cost principle schemes could used construct conflictresistant cache using indexing function however cache architectures two factors critical firstly chosen indexing function must logically simple im plementation secondly would like able guarantee good behavior regular address patterns even pathological conventional index function commercial domain ibm 3033 19 amdahl 470 20 made use xormapping functions order index tlb first generation hp precision architecture processors 21 also used similar technique use pseudorandom cache indexing suggested authors example smith 22 compared pseudorandom placement setassociative place ment concluded random indexing small advantage cases advantages significant paper show certain workloads cache organizations advantages large hashing process id address bits order index cache evaluated multiprogrammed environment agarwal 23 results showed scheme could reduce miss ratio perhaps wellknown alternative cache indexing scheme class bitwise exclusiveor functions proposed skewed associative cache 8 bitwise xor mapping computes bit cache index either one bit address xor two bits two mappings required different groups bits chosen xoring case twoway skewedassociative cache consists two banks size accessed simultaneously two different hashing functions associativity help reduce conflicts skewed indexing functions help prevent repetitive conflicts occurring polynomial modulus function first applied cache indexing 10 best described first considering unsigned integer address terms binary representation interpreted polynomial defined field gf2 binary representation mbit cache index r similarly defined gf2 polynomial rx order less effectively rx irreducible polynomial order p x x mod p x generates polynomials order lower polynomials fulfil previous requirements called ipoly poly nomials rau showed computation rx accomplished vectormatrix product address n theta matrix h singlebit coefficients derived p x 18 gf2 product computed network xor gates hmatrix constant gates omitted mapping requires xor gates fanin 2 n practice may reduce number input address bits polynomial mapping function ignoring upper bits seriously degrade quality mapping function ipoly mapping functions studied previously context strideinsensitive interleaved memories see 17 18 certain provable characteristics significant value cache indexing 24 demonstrated skewed ipoly cache indexing scheme shows higher degree conflict resistance exhibited conventional setassociativity nonipoly xorbased mapping functions overall skewedassociative cache using ipoly mapping pure lru replacement policy achieved miss ratio within 1 achieved fullyassociative cache given advantage ipoly function bitwise xor function results presented paper use ipoly indexing scheme iii evaluation conflict resistance performance integer floatingpoint spec95 programs evaluated column associative twoway setassociative 2w twoway skewedassociative organizations using ipoly indexing functions cases singlelevel cache assumed miss ratios configurations shown table ii given conventional indexing function directmapped dm fullyassociative organizations display respectively lowest highest degrees conflictresistance possible cache architectures define bounds within novel indexing schemes evaluated miss ratios shown rightmost two columns table ii columnassociative cache accesstime characteristics similar directmapped cache degree pseudoassociativity address map one ipoly indexing mod 2 k col assoc 2way skewed indexing spl lru 2w plru lru fa dm su2cor 105 91 99 94 94 89 110 hydro2d 176 172 171 170 171 175 176 mgrid 51 42 38 45 41 35 38 applu 73 65 69 68 64 59 76 turb3d 81 60 48 45 42 28 75 apsi 122 112 114 110 106 125 155 fpppp 40 27 28 21 23 17 85 wave 146 138 142 139 137 139 318 go 96 66 86 75 67 48 134 gcc 82 63 72 67 61 53 106 compress 145 135 137 139 134 130 171 li 55 45 61 49 45 38 86 ijpeg 18 13 17 15 14 12 41 perl 85 67 88 71 64 52 107 vortex 27 17 20 18 16 14 53 ave ave int 668 522 626 555 509 442 922 ave 132 114 123 116 113 114 473 average 877 739 799 747 714 680 159 ii miss ratios ipoly indexing spec95 benchmarks two locations cache initially one probed column labelled spl represents cache swaps data two locations increase percentage hit first probe also uses realistic pseudolru replacement policy cache reported column labelled lru swap data columns uses unrealistic pure lru replacement policy 10 expected twoway setassociative cache capable eliminating many random conflicts ever conventionallyindexed setassociative cache able eliminate pathological conflict behavior limited associativity naive indexing function performance twoway setassociative cache improved simply replacing index function whilst retaining characteristics conventional lru replacement still used indexing function impact replacement cache organization two programs twoway ipoly cache lower miss ratio fullyassociative cache due suboptimality lru replacement fullyassociative cache common anomaly programs negligible conflict misses final cache organization shown table ii twoway skewedassociative cache proposed originally seznec 8 original form used two bitwise xorindexing functions version uses ipoly indexing functions proposed 10 24 case two distinct ipoly functions used construct two distinct cache indices address pure lru difficult implement skewedassociative cache present results cache uses realistic pseudolru policy labelled plru cache uses unrealistic pure lru policy labelled lru organization produces lowest conflict miss ratio 48 067 specint 1261 007 specfp striking performance improvement dominated three programs tomcatv swim wave effectively exhibit pathological conflict miss ratios conventional indexing schemes studies olukotun et al 25 shown data cache miss ratio tomcatv wastes 56 40 available ipc 6way 2way superscalar processors respectively tiling often introduce extra cache conflicts elimination always possible software alternative indexing functions exhibit conflict avoidance properties use avoid induced conflicts effectiveness ipoly indexing tiled loops evaluated simulating cache behavior variety tiled loop kernels present small sample results illustrate general outcome figures show miss ratios observed two tiled matrix multiplication kernels original matrices square dimensions 171 256 respectively tile sizes varied 2 theta 2 16 theta 16 show effect conflicts occurring caches directmapped a1 2way setassociative a2 fullyassociative fa skewed 2way ipoly hpsk tiled working set divided cache capacity measures fraction cache occupied single tile cache capacity 8 kbytes 32byte lines dimension 171 miss ratio initially falls caches tile size increases due increasing spatial locality point self conflicts begin occur conventionallyindexed directmapped twoway setassociative caches fullyassociative cache suffers selfconflicts miss ratio decreases monotonically less 1 50 loading behavior skewed 2way ipoly cache tracks fullyassociative cache closely qualitative difference ipoly cache conventional twoway cache clearly visible dimension 256 product array multiplicand array positioned memory crossconflicts occur addition selfconflicts hence directmapped 2way set associative caches experience little spatial locality however ipoly cache able eliminate crossconflicts well selfconflicts tracks fullyassociative cache iv implementation issues logic gf2 polynomial modulus operation presented section ii defines class hash functions compute cache placement address combining subsets address bits using xor gates means example bit 0 cache index may working set capacity miss ratio 0 10 20 30 40 50 hpsk fig 1 miss ratio versus cache loading 171 theta 171 matrix multiply working set capacity miss ratio 0 10 20 30 40 50 fig 2 miss ratio versus cache loading 256 theta 256 matrix multiply computed xor bits 0 11 14 19 original address choice polynomial determines bits included set implementation function cache 8bit index would require eight xor gates fanin 3 4 whilst appears remarkably simple consider placement function firstly function uses address bits beyond normal limit imposed typical minimum page size restriction sec ondly use pseudorandom placement multilevel memory hierarchy implications maintenance inclusion 24 explain two issues depth show virtualreal twolevel cache hierarchy proposed wang et al 26 provides clean solution problems cache memory access conventional organization normally computes effective address adding two reg isters register plus displacement ipoly indexing implies additional circuitry compute index effective address circuitry consists several xor gates operate parallel therefore total delay delay one gate xor gate number inputs depend particular polynomial used experiments reported paper number inputs never higher 5 xor gating required ipoly mapping may increase critical path length within processor pipeline however delay short since bits index computed parallel moreover show later even additional delay induces full cycle penalty cache access time ipoly mapping provides significant overall performance improvement memory address prediction also used avoid penalty introduced xor delay lengthens critical path memory addresses shown highly predictable instance 27 shown addresses 75 dynamically executed memory instructions spec95 suite predicted simple tabular scheme tracks last address produced given instruction last stride similar scheme could used give early prediction line likely accessed given load instruction outlined processor incorporates table indexed instruction address entry stores last address predicted stride recently executed load struction fetch stage table accessed program counter decode stage predicted address computed xor functions performed compute predicted cache line done one cycle since xor performed parallel computation mostsignificant bits effeec tive address instruction subsequently issued memory unit uses predicted line number access cache parallel actual address line computation predicted line turns incor rect cache access repeated actual address otherwise data provided speculative access loaded destination register number previous papers suggested address prediction means reduce memory latency 28 29 30 execute memory instructions dependent instructions speculatively 31 27 32 case missspeculation recovery mechanism similar used branch prediction schemes used squash missspeculated instructions v effect ipoly indexing ipc order verify impact polynomial mapping realistic microprocessor architectures developed parametric simulator fourway superscalar processor outoforder execution table iii summarizes functional units latencies used experiments reorder buffer contained 32 entries two separate physical register files fp teger 64 physical registers processor lockupfree data cache 33 allowed 8 outstanding misses different cache lines cache capacities 8 kb simulated 2way associativity 32byte lines cache writethrough nowrite allocate cache two ports twocycle time miss penalty 20 cycles connected 64bit data bus infinite leveltwo cache data dependencies memory speculated using mechanism similar arb multiscalar 34 hp pa8000 35 branch history table 2k entries 2bit saturating counters used branch prediction functional unit latency repeat rate simple fp 4 1 iii functional units instruction latencies memory address prediction scheme implemented directmapped table 1k entries indexed instruction address reduce cost entries tagged although increases interference ta ble entry contained last effective address recent load instruction index table entry together last observed stride addition entry contained 2bit saturating counter assign confidence prediction mostsignificant bit counter set would prediction considered correct address field updated new reference regardless prediction however stride field updated counter went two consecutive mispredictions table iv shows ipc miss ratios six configurations 1 ipc averages computed using equallyweighted harmonic mean baseline configuration 8 kb cache conventional indexing address prediction np 3rd column average ipc configuration 127 average miss ratio 1653 ipoly indexing average miss ratio falls 968 xor gates critical path ipc rises 133 nx 5th column conversely xor gates critical path one cycle penalty cache access time assumed resulting ipc 129 wx 6th column ever memory address prediction introduced wp 7th columnn ipc cache without xor gates critical path nx hence memory address prediction scheme offset penalty introduced additional delay xor gates critical path even conservative assumption whole cycle latency added load instruc tion finally table iv also shows performance setassociative cache without ipoly indexing 1 configuration simulated 10 8 instructions skipping first 2 theta 10 9 2nd column notice addition ipoly indexing 8 kb cache yields 60 ipc increase obtained doubling cache size indexing ipoly indexing su2cor 128 124 126 124 121 125 hydro2d 114 113 115 113 111 115 mgrid 163 161 163 157 155 159 applu 151 150 153 150 146 152 turb3d 185 180 182 181 178 182 apsi 113 108 109 108 107 109 fpppp 214 200 200 198 193 194 wave 137 126 128 151 148 154 go 100 087 088 087 083 084 compress 113 112 113 111 107 110 li 140 130 132 133 126 131 ijpeg 131 128 128 129 128 130 perl 145 126 127 124 119 121 vortex 139 127 128 130 125 127 ave ave int 129 119 120 120 115 117 ave 128 111 113 146 142 149 ave 138 130 132 130 127 130 average 136 127 128 133 129 133 iv comparative ipc measurements simulated ipc measurements exhibit small absolute differ ences benefit ipoly indexing perceived small subset benchmark pro grams programs spec95 exhibit low conflict miss ratios fact spec95 conflict miss ratio 8 kb 2way setassociative cache less 4 programs except tomcatv swim wave5 two penultimate rows table iv show independent ipc averages benchmarks high conflict miss ratios ave low conflict miss ratios ave highlights ability polynomial mapping reduce miss ratio significantly boost performance problem cases one see polynomial mapping provides significant 27 improvement ipc three bad programs even xor gates critical path memory address prediction used memory address prediction ipoly indexing yields ipc improvement 33 compared conventional cache capacity 16 higher conventional cache twice capacity notice polynomial mapping scheme prediction even better organization without prediction xor gates extend critical path due fact memory address prediction scheme reduces one cycle effective cache hit time predictions correct since address computation overlapped cache access computed address used verify prediction correct however main benefits observed come reduction conflict misses isolate different effects also simulated organization memory address prediction scheme conventional indexing 8 kb cache wp column 4 compare ipc organization column 3 see benefits memory address prediction scheme due solely reduction hit time almost negligible confirms improvement observed ipoly indexing scheme address prediction derives reduction conflict misses averages fifteen programs exhibit low levels conflict misses show small 17 deterioration average ipc ipoly indexing used xor gates critical path due slight increase average hit time rather overall increase miss ratio average falls 2 programs reduction aggregated miss penalty outweigh slight extension critical path length vi conclusions paper discussed problem cache conflict misses surveyed options reducing eliminating conflicts described pseudorandom indexing schemes based polynomial modulus functions shown robust enough virtually eliminate repetitive cache conflicts caused bad strides inherent spec95 benchmarks well eliminating introduced application tiling loop nests highlighted major implementation issues arise use novel indexing schemes example ipoly indexing uses address bits conventional cache compute cache index also use different indexing functions level1 level2 caches results occasional eviction level1 simply maintain inclusion explained problems solved using twolevel virtualreal cache hierarchy finally proposed memory address prediction scheme avoid penalty due small potential delay critical path introduced pseudorandom indexing function detailed simulations outoforder superscalar processor demonstrated programs significant numbers conflict misses conventional 8 kb 2way skewedassociative cache perceive ipc improvements 33 address prediction 27 without address prediction 16 higher ipc improvements obtained simply doubling cache capac ity furthermore programs analyzed experience significant conflict misses average see 17 reduction ipc ipoly indexing appears critical path computing effective ad dress address prediction used indexing logic appear critical path deterioration overall average performance experienced programs believe key contribution pseudorandom indexing resulting predictability cache behavior experiments found ipoly indexing reduces standard deviation miss ratios across spec95 1849 516 could beneficial realtime systems unpredictable timing caused possibility pathological miss ratios presents problems conflict misses eliminated miss ratio depends solely compulsory capacity misses general easier predict control conflict avoidance could also beneficial iterationspace tiling used improve data locality vii acknowledgments work supported part european commission esprit project 24942 british council grant 1016 spanish ministry education accion integrada hispanobritanica 202 cycit tic98 0511 authors would like express thanks jose gonzalez joan manuel parcerisa help simulation software anonymous referees helpful comments r national technology roadmap semiconductors computer architecture quantitative approach cache performance optimization blocked algorithms cache miss equations analytic representation cache misses atom system building customized program analysis tools columnassociative caches technique reducing miss rate directmapped caches improving directmapped cache performance addition small fullyassociative cache prefetch buffers case twoway skewed associative caches skewedassociative caches elimi nating cache conflict misses xorbased placement func tions avoiding cache conflict misses dynamically large directmapped caches prime memory system array access vector access performance parallel memories logical data skewing schemes interleaved memories vector processors xorschemes flexible data organization parallel memories randomly interleaved memo ries cydra 5 stride insensitive memory system pseudorandomly interleaved memories amdahl corp hardware design first hp precision architecture computers cache memories analysis cache performance operating systems multiprogramming design performance conflictavoiding cache case singlechip multiprocessor organization performance twolevel virtualreal cache hierarchy speculative execution via address prediction data prefetching hardware support hiding cache latency streamlining data cache access fast address calculation zerocycle loads microarchitecture support reducing load latency memory address prediction data speculation performance potential data dependence speculation collapsing lockupfree instruction fetchprefetch cache organi zation arb mechanism dynamic reordering memory references advanced performance features 64bit pa 8000 tr ctr bartolini c prete proposal inputsensitivity analysis profiledriven optimizations embedded applications acm sigarch computer architecture news v32 n3 p7077 june 2004 k patel e macii l benini poncino reducing cache misses applicationspecific reconfigurable indexing proceedings 2004 ieeeacm international conference computeraided design p125130 november 0711 2004 hans vandierendonck philippe manet jeandidier legat applicationspecific reconfigurable xorindexing eliminate cache conflict misses proceedings conference design automation test europe proceedings march 0610 2006 munich germany hans vandierendonck koen de bosschere xorbased hash functions ieee transactions computers v54 n7 p800812 july 2005 mathias spjuth martin karlsson erik hagersten skewed caches lowpower perspective proceedings 2nd conference computing frontiers may 0406 2005 ischia italy wang nelson passos improving cache hit ratio extended referencing cache lines journal computing sciences colleges v18 n4 p118123 april g e suh l rudolph devadas dynamic partitioning shared cache memory journal supercomputing v28 n1 p726 april 2004 hans vandierendonck koen de bosschere highly accurate efficient evaluation randomising set index functions journal systems architecture euromicro journal v48 n1315 p429452 may g edward suh srinivas devadas larry rudolph analytical cache models applications cache partitioning proceedings 15th international conference supercomputing p112 june 2001 sorrento italy rui min yiming hu improving performance large physically indexed caches decoupling memory addresses cache addresses ieee transactions computers v50 n11 p11911201 november 2001 bartolini c prete optimizing instruction cache performance embedded systems acm transactions embedded computing systems tecs v4 n4 p934965 november 2005