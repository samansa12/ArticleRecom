convergence class inexact interiorpoint algorithms linear programs present convergence analysis class inexact infeasibleinteriorpoint methods solving linear programs main feature inexact methods linear systems defining search direction interiorpoint iteration need solved high accuracy precisely allow linear systems solved moderate accuracy residual assumptions made accuracy search direction search space particular analysis require feasibility maintained even initial iterate happened feasible solution linear program also present numerical examples illustrate effect using inexact search directions number interiorpoint iterations b introduction since publication 6 karmarkars original interiorpoint algorithm linear programs numerous variants method developed see eg kojima mizuno yoshise 8 megiddo 13 monteiro adler 17 tanabe 21 especially interesting algorithm kojima megiddo mizuno 7 since also practically efficient see eg 9 numerical analysis manuscript 9616 bell laboratories murray hill new jersey september 1996 available www httpcmbelllabscomcsdoc96 11 inexact interiorpoint methods motivation study paper provide theoretical justification recent modifications algorithm 7 search directions computed inexactly interiorpoint iteration one feature inexact interiorpoint methods allow use iterative techniques approximately solve linear systems defining search directions example 3 employ preconditioned qmr algorithm iterative solution linear systems first describe modification algorithm 7 adapted inexact computations search directions show global convergence goal design algorithm number iterations solve given linear program reasonably inexact computations much higher algorithm 9 aware algorithm 9 improved meantime see eg 10 many recent publications however aware efficient algorithm readily extended inexact computations applications initial strictly dualfeasible solution linear program known problems 18 implementation primalinfeasible dualfeasible interiorpoint method presented results numerical experiments reported approach originates 3 distinctly different 18 particular method paper also converges even strictly dualfeasible solution 12 outline outline article follows section 2 formulate linear program standard form state assumptions section 3 describe class inexact interiorpoint methods studied paper section 4 discuss issues defining appropriate inexact search directions particular explain assume certain accuracy requirement achieve section 5 establish global convergence section 6 make concluding remarks finally appendix define certain condition number linear program explain relates analysis section 5 13 notation throughout paper use following notation lowercase letters used vectors uppercase letters used matrices vector denoted lowercase letter uppercase version means diagonal matrix whose diagonal elements components vector example diagonal matrix associated vector e denote vector vector norm x x always euclidean norm denotes corresponding euclidean matrix norm notation means components vector x positive respectively nonnegative instead x 0 also write x 2 ir n symbol 0 used denote number zero zero vector zero matrix 0 denotes zero vector zero matrix length dimension respectively always clear context capital letter used denote square identity matrix size always apparent context well 2 problem 21 formulation optimality conditions consider linear programs standard form minimize x2ir n c x subject 1 assume given real theta n matrix b c given real vectors length n respectively dual problem 1 written maximize subject 2 karushkuhntucker optimality conditions primaldual problems 1 2 stated follows equations 3 4 referred primal dual feasibility respectively nonlinear equation 5 called complementarity condition 22 assumptions sequel always assume full row rank theoretically assumption could enforced computing singular value decomposition given sparse constraint matrix done practice instead given linear program typically preprocessed interiorpoint method solution applied see eg 1 5 example simple heuristics used detect fixed variables empty rows columns redundancies certain implicit dependencies heuristics often sufficient reduce linear program size also form matrix linearly independent rows even constraint matrix 1 initial form convergence analysis inexact interiorpoint method depends smallest singular value oe min smaller oe min higher accuracy required step method briefly discuss size oe min assuming rows scaled euclidean norm 1 1 oe largest singular value oe min small linear program 1 wellconditioned however assuming oe min large say greater 01 imply problem 1 well conditioned fact also 0 oe min 1 linear program may degenerate pair primaldual problems infinite condition see appendix particular prior solving given linear program 1 problem could always transformed equivalent linear program constraint matrix 0 oe min since assumed full rank matrix admits qr factorization form q orthogonal n theta n matrix q 1 denoting first columns r 1 nonsingular upper triangular matrix means 7 equality constraints 1 rewritten follows reformulation q 1 b equality constraints obviously wellconditioned oe min q theoretically one might first compute qr factorization 7 well r gammat possibly higher accuracy standard machine precision solve transformed linear program unfortunately reformulation 8 typically destroys sparsity constraint matrix q may considerably nonzero entries therefore reformulation used practice however assume sequel positive lower bound smallest singular value original constraint matrix available 3 class inexact interiorpoint algorithms class algorithms considered paper generates sequence iterates simultaneously converge feasibility optimality guarantee convergence require iterates lie certain set n 31 infinitynormneighborhood perturbed path set n depends initial point real number 0 given x real number fi 1 neighborhood n defined set equalities 11 two sets inequalities 12 13 point belongs n fi exist vectors e closelyrelated neighborhood proposed 7 new element definition perturbation vectors b c 11 12 7 vectors b c zero unless good initial estimate solution problems 1 2 available think large number ae 0 x large vectors set n wide infinitynormneighborhood perturbed path well known exists unique solution x 1416 2 0 1 provided 3 4 6 solution full rank see eg 8 13 infinitynorm refers neighborhood respect nonlinear equation e deviation linear equalities measured euclidean norm requirement size b 12 could weakened slightly requiring kr gammat bk 2 r 1 7 8 however goal formulate method require qr factorization 7 emphasize principle formulate neighborhood terms lower bound 9 oe smallest singular value 32 newton step class interiorpoint algorithms considered paper viewed variants damped newtons method applied system equations c e nonnegative numbers adjusted iteration interiorpoint method converge zero course algorithm step lengths damped newton method suitably chosen guarantee x applying newtons method 1719 yields system linear equations deltay newton correction deltax deltay deltas denote righthand sides 2022 reordering linear system 2022 written form 2x 0 0 deltas deltax deltay5 4 3 theta 3block matrix algorithm systems 24 solved exactly given accuracy primal dual residual explain section 4 meaningful easily possible solve last equation exactly machine precision even allowing possibly larger errors x 20 21 section 4 also define appropriate values x 33 infeasibleinteriorpoint algorithm let iterate step k interiorpoint method let deltax deltay deltas solution linear system 24 improved iterate next step k 1 obtained via step lengths ff x ff chosen parameter chosen close 1 sole purpose parameter ensure possibility ff class algorithms considered paper designed support iterative solution linear systems 24 3 concept algorithm using iterative solver based following principles predictorcorrector strategy applied since solving corrector step approximately expensive solving predictor step contrast standard methods based direct solvers use sparse factorization reduced version coefficient matrix 24 predictor corrector step ffl relatively short steps ie usual 99995 way boundary taken done two reasons first search direction computed low relative accuracy long step meaningful secondly long steps might worsen condition number linear systems stopping criterion interiorpoint algorithm based error measure ck algorithm 1 inexact infeasibleinteriorpoint algorithm input parameters initial point solving linear system 24 righthand side 23 error satisfying 25 choose ff k x deltax deltas 3 n next specify choice parameters k step lengths ff k algorithm choice guarantees iterates remain neighborhood n fi see theorem 1 34 specifications algorithm quantities ff k k 3 depend three additional input parameters 1 2 3 step set k later use note number k 3 depends additional quantity fl k first number fl k chosen min set k possibility small choice fl k small ffix k allow superlinear convergence step accuracy 24 solving ax chosen x oen primal residual n dual residual x ff ant x ff ant anticipated values actual step lengths ff k x ff k respectively values need chosen general values ff ant x ff ant depend k given approximation guess deltax deltay deltas solution 24 values ff ant x ff ant computed easily example using steplength strategy 35 36 values ff ant x ff ant one 29 30 subsequently one checks current approximation deltax deltay deltas satisfies accuracy requirements 29 30 yes deltax deltay deltas accepted sufficiently accurate solution 24 one continues iterative method used inexact solution 24 stopping criteria 29 30 appropriately updated values ff ant x ff ant met step determine step lengths ff k iteration step k first compute ff k maximum point 0 ff ff see definition k 29 30 guarantees 12 holds well thus furthermore show ff k always positive bounded away zero ff k chosen satisfy x deltax deltas well fi rules 33 34 proposed 7 cheap way computing ff k also discussed ffl 3 adaptive choice step lengths ff k proposed using following strategy based two parameters 4 1 5 2 0 1 suggested default values first one determines chooses ae k one sets x ff k motivation strategy fl k small implies large reduction comple mentarity x close 1 implies large reduction infeasibility full newton step case large ae k seems profitable even though may bring iterate close boundary feasible set therefore ff k may practically efficient choice 3 1 close 1 constraint 34 step lengths fairly weak choice ff k x ff k may satisfy 34 iterations k 34 satisfied result lie n fi step lengths satisfy criteria may computed 7 main computational effort algorithm 1 lies solution systems 24 solving systems first employ stable reduction described section 41 reduce 3 theta 3block system smaller 2 theta 2block system smaller systems solved either direct method see eg 2 22 iterative method one proposed 3 35 main result main result stated theorem 1 section 5 iterates generated algorithm 1 remain neighborhood n fi furthermore iterates either converge set optimal solutions set nonempty detected optimal solution exists whose norm less given bound result iterates remain n fi consequence following two features algorithm 1 first two equality constraints 11 trivially maintained suitable update b c third equality constraint 11 trivially satisfied due choice 3 algorithm 1 ii norm constraints 12 b c guaranteed proper choice x inequality constraints 13 xs maintained selecting suitable parameters 4 inexact search directions section discuss accuracy requirement step 3 algorithm 1 satisfied chosen type accuracy requirement 41 stable reduction 3 theta 3block system show search direction satisfying accuracy requirement form 25 obtained practice first review stable reduction introduced 3 3 theta 3block system 24 linear system 2 theta 2block matrix basis stable reduction partition 1 vectors x two parts x 1 x 2 respectively x 1 moreover ease notation assume x 1 1 leading entries x ie subsection refer specific components vectors x instead x 1 2 always denote vectors containing large components x respectively partition constraint matrix conforming 37 write similarly 37 induces partition residual vectors p q defined 23 usual denote x 1 x 2 1 2 diagonal matrices associated vectors x 1 x 2 1 2 respectively instead original system 24 propose solve equivalent reduced 2 theta 2block system deltay r r furthermore new variable u connected x 1 2 via relation gammax using 3739 41 42 together one readily verifies reduced 2 theta 2block system 40 indeed equivalent original system 24 consider interiorpoint methods solve reduced system 40 iteratively low relative accuracy thus obtain approximate solution given approximate solution u deltay 40 quantity deltax 1 computed using relation 42 note stress choice partition may changed example reduce primal residual cost dual residual preliminary numerical experiments observation partitioning according x1 s110 x2 s210 might slightly efficient computing deltas 2 42 would involve inverse small matrix x 2 avoided computing deltas 2 via obtaining deltax 2 deltas 1 43 computations inverses large matrices x 1 2 used x gamma1 2 gamma1 1 furthermore remark partition x x 1 x 2 nothing guessing active indices partition merely done improve stability solving current linear system involve additional computational cost loss partition changes iteration 42 motivation inexactness requirements next motivate requirement step 3 algorithm 1 accuracy computation search directions 25 implicitly assume could compute search direction arbitrarily high precision willing invest computational effort accuracy necessary guarantee convergence interiorpoint method even inexact search directions need careful analysis errors introduced inexactness search direction assume moment set 24 deltax deltas deltay solve linear systems 24 exactly linearity r primal residual r thus norm primal residual r reduced factor 1 gamma ff x case exact solution 24 allow tolerance approximate solution 24 requiring deltax merely computed certain relative accuracy residual instead straightforward computations inexact result r inexact obtained inexact computations almost good result obtained exact computations inequality also shows size ff x important reduction r obvious maximum feasible step lengths ff sensitive functions accuracy third residual q 19 especially current iterate close boundary positive orthant therefore assume stable reduction 43 used q holds true course analogous considerations r r also hold p p finally remark criterion 44 satisfactory form following reason iterative approach solving linear systems requires allow low relative accuracy even initial residual happened zero ie ax criterion 44 allow increase residual therefore use criterion 44 appropriate modification 44 discussed next 43 analysis perturbed feasible sets consider perturbed constraints part relations defining n fi following proposition give condition perturbation vectors b c still guarantees feasibility 4648 result crucial convergence analysis next section furthermore remark lower bound 9 smallest singular value used proof result proposition 1 assume problems 1 2 optimal solution x constraints 4648 feasible solution perturbation vectors b c particular exists feasible solution x 4648 x 2 1 e e moreover chosen satisfy proof let point x feasible solution 1 2 ie satisfies constraints 3 4 6 need construct feasible solution x 4648 end first set h b denotes pseudoinverse see eg 20 vector h clearly satisfies moreover since first inequality 49 define x using 3 4 52 definition b c 10 one readily verifies point x satisfies 46 47 remains show 50 51 note 53 implies h gamma e2 together x 0 follows 54 first inequality 50 note second inequality 49 thus together 55 implies second inequality 50 finally 51 follows 54 would like stress observation section 2 theoretically one transform problem 1 equivalent problem prior applying interiorpoint method practically transformation appropriate may still anticipate 1oe moderate even 1 happened poorly conditioned particular degeneracy near degeneracy depend oe 44 required accuracy course algorithm 1 vectors reduced k b k respectively furthermore inexactness search direction new perturbation vectors b k c k introduced precisely b k c k defined follows show vectors 56 remain bounded provided step 3 algorithm 1 search directions computed accuracies defined 29 30 respectively proposition 2 iterates computed algorithm 1 associated perturbations vectors b k c k defined 56 satisfy proof proof induction k thus 57 trivially satisfied assume 57 holds k 0 show 57 also satisfied k 1 verify first relation 57 second relation treated analogously recall omitted indices 1 using 56 k replaced 58 obtain first relations 56 57 respectively taking norms 59 using 29 60 follows next recall 27 32 1 1 ff ff ant x thus together definition 1 31 follows using definition x 29 obtain inserting 62 61 using k1 desired first relation 57 k replaced k 1 remark k upper bound 62 k x reduces x relate statement relative accuracy point norm righthand side r 23 bounded 2t k 1 note k bk known k bk easily bounded suitable choice x 0 k bk zero small compared concept 44 solving certain relative accuracy restrictive 29 k bk large say k roughly means x spirit 44 except additional factor k 1 likewise p conditions implying small k 2 high relative accuracy required coincides desire higher relative accuracy final iterations interiorpoint method obtain superlinear convergence 5 convergence analysis section present proof convergence inexact interiorpoint algorithm 1 proposition 3 primal dual linear programs 1 2 optimal solution x scomponents neighborhood n fi bounded ie exists constant 1 furthermore 1 2 solution x ks x proof proposition used slightly different form 14 15 since form stated general 14 15 give complete proof let optimal solution 1 2 proposition 1 exists point x c set hence using 65 straightforward algebra leads x concludes proof 63 assume 1 2 solution x choose x opt opt minimumnorm solutions inequality 66 also note 51 proof 64 follows inequality 66 proposition 4 fi 1 0 e x proof proof straightforward using definition n fi proposition 3 1 point generated algorithm 1 ks bound kdeltaxk kdeltask 3 holds deltax deltas determined 24 23 given accuracy specified 25 proof note ka ck bounded iterates boundedness ks k k thus follows boundedness k note x bounded well deltax deltas exact solution system 24 r q perturbed bounded quantity size x thus may assume righthand sides 23 bounded proposition 4 fullrank assumption follows inverses matrices 24 uniformly bounded inverse exists x 0 0 continuous function x concludes proof next state prove main result theorem 1 iterates generated algorithm 1 contained n fi iterates generated algorithm 1 unbounded linear program 1 solution iterates generated algorithm 1 bounded stopping criterion step 1 algorithm 1 satisfied finite number iterations proof proof based ideas kojima et al 7 proposition 2 vectors b c associated x k k satisfy 57 hence 12 relation 13 guaranteed update step 4 algorithm 1 hence iterates remain n fi iterates generated algorithm 1 unbounded view proposition 3 linear program 1 solution assume sequence iterates bounded say kx ks show algorithm 1 finds approximate optimal solution finite number iterations suppose k 13 bounds 12 also ck 0 11 also therefore view 26 stopping criterion algorithm 1 satisfied finite number steps conversely long algorithm 1 running hence algorithm 1 halt proposition 4 3 0 x k 3 e k 3 e also 28 fl k bounded away zero without loss generality proposition 5 applicable 3 1 kdeltax k k kdeltas k k 3 k without loss generality assume 3 1 finally view 28 may assume independent k conclude proof show ff k bounded away zero ie note ff k x ff k chosen equal ff k thus 67 guarantees step length required 33 indeed found 34 ensures k converges zero hence showing 67 indeed completes proof convergence computation ff k depends 13 33 definition x equalities defining n fi well bounds b c maintained ff 2 0 consider iteration k verify bounds maintained bound xst 3 completeness write proof 7 notation ffdeltas clearly since x k independently k ff 1 0 xff sff 0 0 ff ff 1 consider number positive first relation 13 satisfied 45 follows fin also thus bound 68 deltax deltas note jdeltax deltas 3 jdeltax deltasnj 2 3 follows relation 68 holds provided holds bounds linking 1 3 first show ff 3 0 independent k 1 assuming 1 defined obvious way n n recall algorithm 1 either g refer first instance case latter case b case follows calculations yield 1 j deltax deltas n case b follows fit 1 6 0 independent k since fit conclude 1 3 minimum bounds yields ff 3 next show 3 expression written deltax deltas n case quantity 3 bounded away zero case b fit away zero desired result follows straightforward manner finally bounds relating 2 3 analogous ones 1 3 close noting rules 33 34 identical 7 analysis fully applies algorithm guarantees step lengths bounded away zero long algorithm stop 6 concluding remarks paper proved global convergence infeasibleinteriorpoint method stated algorithm 1 method allows linear systems iteration solved moderate relative accuracy residual accuracy requirement depends estimate oe smallest singular value oe min constraint matrix numbers oe oe min used elsewhere algorithm algorithm 1 similar algorithm paper 7 however provide analysis case search directions computed exactly large linear programs direct methods solving linear systems often prohibitively expensive iterative methods must used iterative solutions course contain nonnegligible error 3 efficient iterative method namely variant qmr algorithm 4 tailored indefinite symmetric systems discussed along different strategies preconditioning linear systems arising algorithm 1 assumptions made algorithm 1 originated motivated method 3 chose method 7 reference since adapted inexact computations without substantial loss performance since known efficient also numerical implementations see eg 9 efficient interiorpoint methods example methods based selfdual formulation linear program allow simple extension inexact computations apart specifications inexactness modification algorithm 7 made algorithm 1 slightly different choice parameters 1 2 parameters set zero 7 also set zero step 2 algorithm 1 except case corresponding residual r p already small latter case expect much loss reducing residual current iteration 16 another inexact infeasibleinteriorpoint method analyzed main difference lies choice parameters 1 2 method 16 uses positive values 1 2 must satisfy certain conditions may close zero moreover algorithm 16 uses value oe precisely certain norm bound terms oe accuracy search direction also determining certain parameter step length therefore method 16 lend actual practical numerical implementation however theoretical results method 16 somewhat stronger linear convergence could established special case also proof polynomiality given appendix forms illconditioning looking standard optimization literature found definition condition number linear program often explained books talk condition linear systems equations 11 12 condition number linear programs defined takes account perturbations righthand sides constraints convex optimization problems renegar 19 introduced conditionnumberlike distance nearest illposed degenerate primal dual empty interior problem appendix include precise definition condition number linear program explain derivation relate quantity oe used analysis condition number note described condition number different ones 11 12 19 following definition essentially taken 20 let open set ir n condition number function oe point x 2 defined lim sup deltax0 condition number defined condition defined 1 observe condition number still depends choice suitable norm obvious limit small changes x condition number lowest upper bound quotient relative change x resulting relative change oex linear programs may define map oe maps data b c set primaldual optimal solutions let open set data linear programs given b c unique solution oe function setvalued map definition condition number applied linear program given b c set primaldual optimal solutions given linear program contains one point define condition number 1 continuous completion condition number one also define condition number infeasible programs defining solution certificate primal dual program infeasible omit case remark systems linear equations condition number defined manner coincides condition number defined inverse distance nearest illposed system ie nearest singular matrix recall convex problems renegar 19 introduced distance nearest illposed problem easy see inverse distance coincide condition number definition well definition based nearest illposed problem properties one would like associate condition number optimization problem point view sensitivity analysis definition seems appropriate therefore use definition thus condition number linear program b c unique solution x defined next assume b c 2 briefly discuss norm used first observe two given positive diagonal matrices n order n respectively data b c n b n c equivalent sense x solution first problem solution second problem likewise see b c multiplied positive scalars 1 2 resulting equivalent programs multiplying x transformations encounter cancellation error condition number one hence transformation carried almost exactly prior solving given linear program ffl example consider linear program subject 1 simplicity ignore dual variables solution 1norm data 1 condition number respect 1norm least lim deltaffl0 seen restricting oneself equal changes deltaffl fflentries data note last column norm ffl 1 system rescaled rescaled version minimize subject optimal solution perfectly wellconditioned seems appropriate eliminate effect scalings definition condition linear program may example assume data scaled b c rows columns norm approximately 1 mentioned prior solving linear program one might even compute qr factorization 7 matrix stable fashion possibly higher accuracy standard machine precision partitioned square nonsingular upper triangular matrix r 1 given q 1 r gammat b right hand side stable representation equality constraints computing stable representation difficult computations solving linear program may performed using q rather stress anticipated loss sparsity qr factorization computed practice would like know however kind illconditioning linear program occur addition eliminating effects diagonal scaling also assume stable choice 1 purpose rewrite linear program follows given primal program c x subject dual written either subject c subject given 1 matrix q 2 unique general dependence q 2 q 1 however well conditioned respect euclidean norm k delta k sense lim sup ae oe since restricted sign constraint equivalent q constraint dual objective value given b thus additive constant b problem 2 equivalent 0 subject q c 0 1 b particular solution depend b r gamma1 c primaldual algorithm paper depend variable except estimating size dual residual therefore concentrate changes x due small perturbations data set vectors feasible 2 0 2 course also angles rows q particular oe min consider condition number 0 rather one 2 various sensitivities solutions x respect data p 0 2 interpreted geometrically follows primal problem identify three possible forms illconditioning characterize condition numbers c 1 c 2 c 3 1 assuming columns scaled euclidean norm 1 1 oe oe max largest singular value condition number c 1 computing point satisfying linear equality constraints depends oe min smallest singular value number c 1 interpreted inverse smallest angle two linear manifolds generated two disjoint sets rows matrix see angle 1 figure 1 point oe min aoe max invariant scaling rows columns assumption rows columns approximately constant norm reduce effect scaling oe min assuming illconditioning c 1 large occur 2 condition number c 2 refers problem computing certain vertex feasible set may interpreted inverse angle affine manifold intersects manifold spanned active inequality constraints see 2 figure 1 condition number depends particular vertex approximately expressed inverse smallest singular value matrix e selection active indices f g 3 condition number c 3 refers problem finding vertex optimal primal space depends angle objective vector c forms affine manifold submanifold f x 3 figure 1 oe min large condition number c 3 linked inverse smallest singular value e program 0 program 0 2 structure p tts constraint matrix q however perfect condition thus equivalent c 1 vanishes oe min small dependence q 2 however well conditioned fact equivalent c 1 still present problems 1 figure 1 illustration primal problem p sconsts figure 2 illustration dual problem 0 2 equivalent c 2 denoted c 4 depends inverse angles 4 figure 2 equivalent c 3 denoted c 5 corresponding angle denoted 5 figure 2 r presolving linear programming solving symmetric indefinite systems interiorpoint method linear programming qmr quasiminimal residual method nonhermitian linear systems computational view interiorpoint methods linear programming new polynomialtime algorithm linear programming primaldual infeasibleinteriorpoint algorithm linear programming primaldual interior point algorithm linear programming computational experience primaldual interior point method linear programming condition number linear inequalities linear programs lipschitz continuity solutions linear inequalities pathways optimal set linear programming polynomiality infeasible interior point algorithms linear programming infeasibleinteriorpoint algorithm using projections onto convex set interior path following primaldual algorithms truncated primalinfeasible dualfeasible interior point network flow method incorporating condition numbers complexity theory linear programming introduction numerical analysis centered newton method mathematical programming symmetric indefinite systems interior point methods tr ctr hans mittelmann interior point methods secondorder cone programming applications computational optimization applications v28 n3 p255285 september 2004 stefania bellavia sandra pieraccini convergence analysis inexact infeasible interior point method semidefinite programming computational optimization applications v29 n3 p289313 december 2004