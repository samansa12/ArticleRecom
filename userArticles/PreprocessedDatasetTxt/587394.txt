algebraic multilevel multigraph algorithm describe algebraic multilevel multigraph algorithm many multilevel components generalizations algorithms originally applied general sparse gaussian elimination indeed general sparse gaussian elimination minimum degree ordering limiting case algorithm goal develop procedure robustness simplicity use sparse direct methods yet offers opportunity obtain optimal nearoptimal complexity typical classical multigrid methods b introduction work develop multilevel multigraph algorithm algebraic multigrid methods currently topic intense research interest 17 18 20 46 12 48 38 11 44 3 4 1 2 5 16 7 29 28 27 42 41 21 excellent recent survey given wagner 49 many real world calculations direct methods still widely used 6 robustness direct elimination methods simplicity use often outweigh apparent benets fast iterative solvers goal try develop iterative solver compete sparse gaussian elimination terms simplicity use robustness provide potential solving wide range linear systems eciently yet satised method achieved goal believe reasonable rst step particular method general sparse gaussian elimination minimum degree ordering point parameter space method implies worst case method defaults wellknown widely used method among computationally ecient general sparse direct methods 26 best case however method exhibit near optimal order complexity classical multigrid method plan take well studied robust widely used procedures data structures developed sparse gaussian elimination generalize necessary use basic components multilevel solver overall iteration follows classical multigrid vcycle form contrast algebraic hierarchical basis multigraph algorithm developed 11 work focus class matrices structurally symmetric pattern nonzeros matrix symmetric although numerical values matrix elements may render nonsymmetric structurally symmetric matrices arise discretizations partial dierential equations say nite element method certain problems matrices symmetric positive denite others linear systems highly nonsymmetric andor indenite thus practice represents broad class behavior main interest scalar elliptic equations nite element code pltmg 8 algorithms formally applied structurally symmetric nonsingular sparse matrix sparse direct methods typically two phases rst initialization phase department mathematics university california san diego la jolla ca 92093 work author supported national science foundation contract dms9706090 bell laboratories lucent technologies murray hill nj 07974 equations ordered symbolic numerical factorizations computed second solution phase solution linear system computed using factorization procedure well algebraic multilevel methods also breaks naturally two phases initialization consists ordering incomplete symbolic numeric factorizations computation transfer matrices levels solution phase preconditioner computed initialization phase used compute solution using preconditioned composite step conjugate gradient cscg composite step biconjugate gradient csbcg method 9 iterative solvers often tuning parameters switches require certain level priori knowledge empirical experimentation set particular instance solver immune although tried keep number parameters minimum particular initialization phase three parameters drop tolerance used incomplete factorization called dtol code maxf il integer controls overall llin storage allowed given incomplete factorization maxlvl integer specifying maximum number levels case corresponds sparse gaussian elimina tion solution phase two additional parameters tol tolerance used convergence test maxcg integer specifying maximum number iterations within code matrices generally treated within single unied frame work eg symmetric positive denite nonsymmetric indenite problems generally specialized options besides control parameters mentioned information matrix generated sparsity pattern values nonzeros provided sparse matrix data structure variant data structure introduced yale sparse matrix package 23 10 certain block matrices user may optionally provide small array containing information block structure input limits complexity code well eliminates parameters might needed classify given matrix hand seems clear specialized solver directed specic problem class problems making use additional knowledge likely outperform algorithm particular class problems although think method provably best particular problem believe generality robustness coupled reasonable computational eciency make valuable addition collection sparse solvers rest paper organized follows section 2 provide general description multilevel approach section 3 dene sparse matrix data structures used code incomplete factorization algorithm standard drop tolerance approach modications present application described section 4 ordering procedure minimum degree algorithm implementation basically standard several modications input graph relevant application described section 5 section 6 describe construction transfer matrices used construction coarse grid correction information block structure matrix provided used coarsening procedure described section 7 finally section 8 give numerical illustrations method variety partial dierential equation matrices 2 matrix formulation let large sparse nonsingular n n matrix assume sparsity pattern symmetric although numerical values need begin describing basic twolevel method solving let b n n nonsingular matrix called smoother gives rise basic iterative method used multilevel preconditioner case b approximate factorization ie l strict lower triangular u strict upper triangular sparsity pattern l diagonal p permutation matrix given initial guess x steps smoothing procedure produce iterates second component twolevel preconditioner coarse grid correction assume matrix partitioned ff fc cf cc subscripts f c denote ne coarse respectively similar smoother partition ne coarse blocks involves permutation matrix p coarse grid matrix given ff fc cf cc cc matrices v cf w n matrices identical sparsity patterns thus symmetric sparsity pattern let cc standard multigrid terminology matrices w called restriction prolongation respectively given approximate solution xm 21 coarse grid correction produces iterate xm1 follows b axm typical multilevel methods dene twolevel preconditioner implicitly terms smoother coarse grid correction single cycle takes initial guess x 0 nal guess x 2m1 follows twolevel preconditioner dened using 23 ii xm1 dened using 27 dened using 23 generalization twolevel multilevel consists applying recursion solution equation r 27 let denote number levels recursion denote preconditioner 27 generalized b axm general level preconditioner dened follows level preconditioner directly starting initial guess x 0 compute x 2m1 using iiiv dened using 23 iv xm1 dened 28 using iterations 1 level scheme r dene initial guess dened using 23 case corresponds symmetric vcycle case corresponds symmetric wcycle note variants vcycle wcycle well types multilevel cycling strategies 30 however work code restrict attention symmetric vcycle presmoothing postsmoothing iterations coarse mesh solution procedure somewhat nontraditional instead direct solution 21 compute approximate solution using one smoothing iteration illustrate practical consequences decision section 8 symmetric level preconditioner could used preconditioner symmetric krylov space method also positive denite standard conjugate gradient method could used otherwise cscg method 9 symlq 43 similar method could used nonsymmetric case level preconditioner could used conjunction csbcg method 9 gmres 22 similar method complete denition method must provide algorithms compute permutation matrix p 22 compute incomplete factorization matrix b 22 compute necoarse partitioning compute sparsity patterns numerical values prolongation restriction matrices 26 3 data structures let n n matrix elements ij symmetric sparsity structure ij ji treated nonzero elements ie stored processed ja diagonal entries ii treated nonzero regardless numerical values data structure modied generalized version data structure introduced symmetric yale sparse matrix package 23 rowwise version data structure described 10 scheme nonzero entries stored linear array accessed integer array ja let number nonzeros strict upper triangular part row set array ja length n1 array length n1 6 array length 2 entries jai 1 n pointers dened follows locations jai jai contain column indices corresponding row strictly upper triangular matrix similar manner array dened follows 6 words diagonal stored rst followed strict upper triangle stored row wise 6 followed strict lower triangle stored columnwise since structurally symmetric column indexes upper triangle identical row indexes lower triangle hence need duplicated storage example let 11 12 13 0 0 21 22 0 24 0 43 44 0 a11 a22 a33 a44 a55 a12 a13 a24 a34 a35 a21 a31 a42 a43 a53 diagonal upper triangle lower triangle although ysmp data structure originally devised sparse direct methods based gaussian elimination also quite natural iterative methods based incomplete triangular decomposition assume symmetric sparsity structure many matrix calculations single indirect address computation ja used process lower upper triangular element example following procedure computes procedure multn ja x end k jai jai end end symmetric matrices set lmtx 0 umtx 0 also may readily computed setting lmtx 0 umtx jan data structure storing quite analogous consists two arrays ju u corresponding ja respectively rst entries ju pointers ja entries jui jui contain column indices nonzeros row u u array diagonal entries stored rst n entries entry arbitrary next nonzero entries u stored correspondence column indices ju nonzero entries l follow stored columnwise data structure use n w similar consists integer array jv real array v nonzero entries stored rowwise including rows block cc usual rst entries jv pointers entries jvi jvi contain column indices row w v array nonzero entries stored rowwise correspondence jv shifted n since diagonal part w followed nonzeros stored columnwise 4 ilu factorization incomplete ldd 1 du factorization similar row elimination scheme developed symmetric ysmp codes 23 26 simplicity begin discussing complete factorization describe modications necessary incomplete factorization without loss generality assume permutation matrix k steps elimination block factorization 11 12 21 22 11 k k 22 n k n k assume stage blocks righthand side 41 computed except schur complement given goal step k 1 compute rst row column given l dd 1 u symmetric sparsity patterns data structures take advantage symmetry clear algorithms computing practice dier assignments shifts u arrays analogous lmtx umtx procedure mult thus focus computation point also assume array ju computed socalled symbolic factorization step major substeps follows 1 copy rst column 22 stored data structures ja expanded work vector z size n 2 find multipliers given nonzeros 1 3 multiplier using column k l 21 ie 4 copy nonzeros z data structures ju u step 1 need know nonzeros rst column 22 precisely information easily accessible ja data structures step 3 need know nonzeros columns l 21 precisely information easily available data structure step 4 copy column information lower triangular portion ju u data structures indeed dicult aspect algorithm step 2 need know sparsity structure rst column u 12 information readily available data structure handled standard fashion using dynamic linked list structure discussed detail generalize incomplete factorization case rst observe ju array computed concurrently numeric factorization simply creating list entries expanded array z updated step 3 next note one may choose nonzero entries z include factorization choosing entries copy ju u data structures step 4 standard approach using drop tolerance particular neglect pair odiagonal elements j note ii yet computed well known llin generated application criterion 44 highly nonlinear matrix dependent function especially problematic present context since control llin necessary order control work per iteration multilevel iteration several authors explored possibilities controlling maximum number llin elements allowed row incomplete decomposition 35 47 31 however many cases interest particular matrices arising discretizations partial dierential equations ordered minimum degree algorithm llin complete factorization occurs later stages even rows initially number nonzeros thus seems advisable try control total llin one adaptively decide allocate llin among rows matrix algorithm addition drop tolerance user provides parameter maxf il species total number nonzeros u larger maxf il n overall strategy compute incomplete decomposition using given drop tolerance fails meet given storage bound increase drop tolerance begin new incomplete factorization continue fashion complete factorization within given storage bound course repeated factorizations computationally expensive developed heuristics allow us predict drop tolerance satisfy storage bound factorization computed make histogram approximate sizes elements exceed drop tolerance accepted factorization let denote number bins histogram code pair accepted odiagonal elements nd largest k 2 1 1 code histogram realized integer array h size h number accepted elements exceeded drop tolerance factors 1 1 1 hm contains number accepted elements exceeding drop tolerance 1 factorization reaches storage bound continue factorization allow llin however continue compute histogram based 45 proling elements would accepted space available using histogram predict new value total number elements accepted u larger maxf il n prediction course cannot guaranteed since sizes numbers llin elements depend complicated fashion specic history incomplete factorization process indeed histogram cannot even completely prole remainder factorization existing drop tolerance since elements would accepted could introduce additional llin later stages calculation well uence sizes elements computed later stages factorization implementation factor varies depending severely storage bound exceeded purpose introduce conservative bias prediction goal actual llin accepted exceed maxf il n finally note comprehensive theory regarding stability incomplete triangular decompositions certain classes matrices eg mmatrices hmatrices existence certain incomplete factorizations proved 39 25 24 40 51 however general case potentially indenite andor highly nonsymmetric matrices one must contend practical way possibility failure near failure factorization common approach add diagonal matrix often multiple identity compute incomplete factorization shifted matrix one might also try incorporate form diagonal pivoting partial complete pivoting could potentially destroy symmetric sparsity pattern matrix however sort pivoting greatly increases complexity implementation since simple essentially static data structures ja ju u appropriate environment philosophy simply accept occasional failures continue factorization ordering procedure contains heuristics directed towards avoiding least minimizing possibility failures occur failures often corrupt low dimensional subspace krylov space method conjugate gradients compensate corruption extra iterations implementation failure revealed diagonal entries becoming close zero odiagonal elements l ji u ij multiplied 1 ii solution l multiplication 1 ii purposes calculating factorization solution value 1 ii modied near zero follows 1d ii jd ii j small constant implementation machine epsilon although many failures could render preconditioner welldened essentially useless practice noted 1 ii rarely modied large class nite element matrices main target procedure 5 ordering compute permutation matrix p 22 use wellknown minimum degree algorithm 45 26 intuitively one computing incomplete factorization ordering tends minimize llin complete factorization tend minimize error particular classes matrices specialized ordering schemes developed 34 15 37 36 example matrices arising convection dominated prob lems ordering along ow direction used great success however general setting prefer use one strategy matrices reduces complexity implementation avoids problem developing heuristics decide among various ordering possibilities remark convection dominated problems minimum degree orderings perform comparably well specialized ones provided modest llin allowed incomplete factorization us seems reasonable compromise minimum degree ordering standard implementation using quotient graph model 26 standard enhancements description graph matrix main required input without going detail essentially small variant basic ja data structure used store matrix denote modied data structure jc instead storing column indices strict upper triangle ja entries jci jci jc data structure contain column indices odiagonal entries row matrix implemented two small enhancements minimum degree ordering practical matter involve changes input graph data structure jc provided minimum degree code first implemented drop tolerance similar used factorization particular edge graph corresponding odiagonal entries ij ji included jc data structure ja jj ii j 51 excludes many entries likely dropped subsequent incomplete factorization hopefully result ordering tends minimize llin created edges kept second modication involves modest priori diagonal pivoting designed minimize number failures near zero diagonal elements subsequent factorization rst remark pivoting procedures based values matrix elements viewed weights graph edges nodes would destroy many enhancements allow minimum degree algorithm run almost linear time modication best explained context simple 2 2 example let b b c 6 0 clearly nonsingular complete triangular factorization exist however b 0 c bca b suppose ii 0 jj four elements form submatrix form described seems incomplete factorization less likely fail p chosen vertex j ordered vertex done follows ii 0 determine corresponding j jj one choice choose one ja ij ji jj j maximized ensure vertex ordered vertex j replace sparsity pattern odiagonal entries row column union rows columns j denote set column indices row jc array adji although sets adji adjj modied various stages well known 53 maintained throughout minimum degree ordering process 26 every step ordering process degj degi degi degree vertex long degj degi vertex j ordered vertex minimum degree algorithm hand stage ordering process remains thereafter 53 becomes words j become socalled equivalent vertices eliminated time minimum degree algorithm see 26 details since minimum degree algorithm sees vertices equivalent ordered arbitrary fashion eliminated graph thus simple postprocessing step must scan ordering provided minimum degree algorithm exchange order rows j ordered rst exchanges result new minimum degree ordering completely equivalent terms llin original many types nite element matrices eg indenite matrices arising helmholtz equations priori scheme useless none diagonal entries close zero however type problem likely produce isolated small diagonal entries factorization process produces hand classes nite element matrices notably arising mixed methods stokes equations saddlepointlike formulations many diagonal entries small zero cases priori diagonal pivoting strategy make substantial dierence greatly reduce numbers failures incomplete triangular decomposition 6 computing transfer matrices three major tasks computing prolongation restriction matrices w 26 first one must determine sparsity structure matrices involves choosing unknowns coarse ne reduces determining permutation p 24 second one must determine coarse ne unknowns related socalled parentchild relations 49 involves computing sparsity patterns matrices v cf w fc third one must compute numerical values matrices socalled interpolation coecients 50 many existing algorithms coarsening graphs matrices arising discretizations partial dierential equations often sparsity matrix related way underlying grid problem coarsening graph matrix formulated terms coarsening grid examples given 14 13 17 18 46 12 49 case one geometry grid serve aid developing analyzing coarsening procedure also general graph coarsening algorithms 32 33 19 often used partition problems parallel computation coarsening scheme based upon another wellknown sparse matrix ordering technique reverse cuthillmckee algorithm ordering tends yield reordered matrices minimal bandwidth widely used generalized band elimination algorithms 26 assume graph ordered fashion jc data structure representing graph ordering available coarsening procedure simple postprocessing step basic ordering routine n vertices graph marked coarse f ine procedure coarsenn jc type end j jci jci end end postprocessing step coupled reverse cuthillmckee algorithm quite similar greedy algorithm computing maximal independent sets using breadthrst search procedure coarse vertices surrounded ne vertices implies matrix cc 24 diagonal matrix sparsity patterns matrices arising discretizations scalar partial dierential equations two space dimensions number coarse unknowns n typically order n4 n5 matrices nonzeros per row tend smaller values n dene parents coarse vertex take connections vertex ne vertices sparsity structure v cf 25 block cf present code pick v cf w fc according formulae ff fc ff ff diagonal matrix diagonal entries equal ff sense nonzero entries v cf w fc chosen multipliers gaussian elimi nation nonnegative diagonal matrices r ff r ff chosen nonzero rows w fc columns v cf respectively unit norms 1 finally coarsened matrix 25 sparsied using drop tolerance criterion like 51 remove small odiagonal elements empirically applying drop tolerance end coarsening procedure proved ecient eective trying independently sparsify constituent matrices number odiagonal elements upper triangle exceeds maxf il n drop tolerance modied fashion similar incomplete factorization odiagonal elements proled procedure similar incomplete fac torization case resulting histogram exact based histogram new drop tolerance computed 51 applied produce coarsened matrix satisfying storage bound 7 block matrices algorithm provides simple limited functionality handling block matrices suppose n n matrix k k block structure b subscripts ij block indices diagonal blocks jj square matrices suppose jj order matrix stored usual ja data structures described section 3 reference block structure small additional integer array ib size k 1 used dene block boundaries follows words integers range ibj ibj inclusive comprise index set associated block jj note ibk block information plays role coarsening algorithm first reverse cuthillmckee algorithm described section 6 applied block diagonal matrix b 11 akkc 72 rather practical matter involves discarding graph edges connecting vertices dierent blocks construction graph array jc used input edges straightforward determine information provided ib array coarsening algorithm applied graph produces output equivalent application procedure independently diagonal block consequence restriction prolongation matrices automatically inherit block structure particular vkkc w jj rectangular matrices structure 26 would resulted application algorithm independently jj however like matrix stored standard jv v data structures described section 3 without reference block structures complete matrix used construction coarsened matrix 25 however 71 73 1k also automatically inherits k k block structure necessary procedure forming knowledge block structure block structure computed priori graph coarsening procedure like stored standard ja data structures without reference block structure since blocks arbitrary order essentially coarsened independently likely eventually certain blocks may cease exist coarse levels since block information used discard certain edges construction graph array jc 00 diagonal blocks present diculty 8 numerical experiments section present numerical illus trations rst sequence experiments consider several matrices loosely based classical case 5point centered nite dierence approximations u uniform square mesh dirichlet boundary conditions imposed leads n n block tridiagonal system n n tridiagonal matrix simple test problem easily solved standard multigrid methods contrast example also consider block tridiagonal system eigenvectors eigenvalues although association eigenvectors eigenvalues reversed case socalled smooth eigenvectors associated large eigenvalues rough eigenvectors associated smaller eigenvalues although arise naturally context numerical discretizations partial dierential equations interest dees much conventional wisdom multigrid methods third consider block 3 3 systems form discrete laplacian symmetric positive denite stabilization matrix sparsity pattern similar however nonzeros size compared size o1 nonzero elements c x c also sparsity patterns similar matrices nonsymmetric nonzero entries size oh matrices arise stabilized discretizations stokes equations one third eigenvalues negative quite indenite addition ja arrays matrix also provided ib array described section 7 dene 33 block structure emphasize block information used computation graph input coarsening procedure involved aspect incomplete factorization smoothing procedure many small diagonal elements class matrices provides good test priori pivoting strategy used conjunction minimum degree ordering table 81 levels refers number levels used calculation implementation parameter maxlvl limits number levels allowed set suciently large eect computation drop tolerance set matrices llin control parameter maxf il set suciently large eect computation initial guess problems x table 81 parameter digits refers experiments asked six digits accuracy column labeled cycles indicates number multigrid cycles accelerated cscg used achieve indicated number digits finally last two columns labeled init solve record cpu time measured seconds initialization solution phases algorithm respectively initialization includes orderings incomplete factorizations computation transfer matrices used multigraph preconditioner solution includes time solve 21 least six digits given preconditioner experiments run sgi octane r10000 250mhz using double precision arithmetic f90 compiler analyzing results clear procedure reasonably well three classes matrices although appears rate convergence independent n seems apparent work growing faster logarithmically cpu times larger vales n aected cache performance well slightly larger number cycles highly indenite stokes matrices important also note ro bustness procedure solved problems nonzeros per row average incomplete factorization expensive compute cases ected relatively larger initialization solve times next experiment illustrate eect parameters maxlvl matrix solved problem 1 maxlvl 7 terminated iteration solution six digits performance comparison digits cycles init solve discrete laplacian stokes matrix measured 81 also provide total storage ja ju arrays matrices measured thousands entries since matrices symmetric also total oating point storage matrices approximate ldu factorizations see method behaves predictable way particular decreasing drop tolerance increasing number levels improves convergence behavior method hand timings always follow trend example case increasing number levels decreases number cycles increases time method defaults standard conjugate gradient iteration incomplete factorization preconditioner maxlvl 1 one presmoothing one postsmoothing step used largest matrix additional cost recursion overall cost preconditioner double cost case also note unlike classical multigrid method coarsest matrix solved exactly code chosen approximately solve coarsest system using one smoothing iteration using incomplete factorization maximum number levels used table 81 smallest system typically 1 1 2 2 irrelevant remark however case table 82 fact smallest system solved exactly signicantly uences overall rate convergence unlike methods coarsest system solved exactly increasing number levels tends improve rate convergence case coarsest matrix exact ldu factorization case matrix nearly diagonal setting maxlvl 5 increase number levels cases dependence convergence maxlvl discrete laplacian maxlvl digits cycles init solve 3 61 96 132 1169 1077 1119 6 7 61 56 121 649 878 2106 61 22 166 317 878 3649 used maximum 10 9 levels respectively results change signicantly case 7 also include table 82 case ination fact code uses jjajj drop tolerance user species avoid dividing zero see gaussian elimination reasonably competitive problem however generally expect initialization cost grow like 32 expect solution times grow like p p 1 best multilevel choices expect initialization solution times behave like log n nal series tests study convergence method suite test problems generated nite element code pltmg 8 example problems presented earlier work 11 complete description problems well numerical results hierarchical basis multigraph method classical amg algorithm ruge stuben 46 found group problems feature highly nonuniform adaptively generated meshes relatively complicated geometry variety dierential operators test case sparse matrix righthand side saved le serve input iterative solvers short description test problem given problem superior problem simple poisson equation homogeneous dirichlet boundary conditions domain shape lake superior classical problem fairly complicated domain solution generally smooth boundary singularities problem hole problem features discontinuous anisotropic coecients overall domain region two concentric circles domain divided three subregions inner region problem middle region equation outer region equation homogeneous dirichlet boundary conditions imposed inner hole bound ary homogeneous neumann conditions outer boundary natural continuity conditions internal interfaces solution also relatively smooth singularities exist internal interfaces problem texas indenite helmholtz equation posed region shaped like state texas homogeneous dirichlet boundary conditions imposed length scales domain roughly 16 16 problem fairly indenite problem ucsd simple constant coecient convectiondiusion equation r ru posed domain shape ucsd logo homogeneous dirichlet boundary conditions imposed boundary layers formed bottom region top various obstacles problems jcn 0 jcn 180 next two problems solutions current continuity equation taken semiconductor device modeling equation convectiondiusion equation form r ru rectangular domain however curved band interior domain jj 10 4 directed radially dirichlet boundary conditions imposed along bottom boundary along short segment upper left boundary respectively homogeneous neumann boundary conditions specied elsewhere solutions vary exponentially across domain typical semiconductor problems rst problem jcn 0 convective term chosen device forward biased case sharp internal layer develops along top interface boundary second problem jcn 180 sign convective term reversed resulting two sharp internal layers along interface boundaries summarize results table 83 perhaps important point method solved problems convergence rates independent h growth appears worst logarithmic make additional remarks table performance comparison n levels digits cycles init solve 20k 9 73 5 14e 0 94e1 hole jcn 0 jcn problems decreasing drop tolerance tend increase effectiveness preconditioner although generally also make preconditioner costly apply thus one might optimize selection drop tolerance minimize decreasing number cycles increasing cost per cycle experiments try systematic optimization adjust drop tolerance crude way dicult problems performed fashion similar easy ones problem texas far dicult test suite set problem order 80k one came close achieving storage limit well limit many averaged less 10 nonzeros per row l u factors nonsymmetric problems csbcg method used acceleration since csbcg requires solution conjugate system two matrix multiplies two preconditioning steps required itera tion noted section 3 data structures applying transposed matrix preconditioner costs applying original matrix preconditioner since dominant costs csbcg methods cost per cycle approximately double equivalent symmetric system r eigenvalue estimates block incomplete factorization methods algebraic multilevel iteration methods theory applications stabilization algebraic multilevel iteration methods algebraic multilevel preconditioning methods class hybrid algebraic multilevel preconditioning methods pltmg software package solving elliptic partial di analysis composite step biconjugate gradient method general sparse elimination requires permanent integer storage incomplete factorization multigraph algorithm hierarchical basis multigrid method incomplete lu decomposi tion orderings incomplete factorization preconditioning nonsymmetric problems towards algebraic multigrid elliptic problems second order boundary treatments multilevel methods unstructured meshes black box multigrid variational iterative methods nonsymmetric systems linear equations algorithms data structures sparse symmetric gaussian elimination stability analysis incomplete lu factorizations algebraic analysis hierarchical basis preconditioner computer solution large sparse positive de incomplete block factorization preconditioning linear systems arising numerical solution helmholtz equation algebraic hierarchical basis preconditioner incomplete decompositions theory analysis multilevel graph partitioning ordering techniques convection dominated problems unstructured three dimensional grids ordering strategies modi energy optimization algebraic multigrid bases analysis robustness incomplete factorizations stability incomplete lufactorizations characterizations hmatrices using approximate inverses algebraic multilevel methods solution sparse inde multigrid method based incomplete gaussian elimination graph theoretic study numeric solution sparse positive de ilut dual threshold incomplete lu factorization convergence algebraic multigrid based smoothed aggregation introduction algebraic multigrid energyminimizing interpolation robust multigrid methods robustness ilu smoothing tr ctr randolph e bank compatible coarsening multigraph algorithm advances engineering software v38 n5 p287294 may 2007 gh juncu e mosekilde c popa numerical experiments mg continuation algorithms applied numerical mathematics v56 n6 p844861 june 2006 j ovall hierarchical matrix techniques domain decomposition algorithm computing v80 n4 p287297 september 2007 michele benzi preconditioning techniques large linear systems survey journal computational physics v182 n2 p418477 november 2002