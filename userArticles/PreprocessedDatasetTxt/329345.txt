providing qos guarantees disk io paper address problem providing different levels performance guarantees quality ofservice disk io classify disk requests threecategories based provided level service propose integrated scheme provides different levels ofperformance guarantees single system propose andevaluate mechanism providing deterministic servicefor variablebitrate streams disk show thatthrough proper admission control bandwidth allocationrequests different categories ensured performance guarantees without getting impacted requests inother categories evaluate impact scheduling policy decisions provided service also quantify theimprovements stream throughput possible using statistical guarantees instead deterministic guarantees thecontext proposed approach b introduction system level support continuous media receiving wide attention continuous media impose timing requirements retrieval delivery data unlike traditional data text images timely retrieval delivery data requires system network pay attention notions time deadlines data retrieval handled io system file system disk drivers disks etc delivery handled network system network software network paper look data retrieval problem different levels service provided continuous media deterministic service provides guarantees required data retrieved time statistical service provides statistical guarantees data retrieval eg 99 requested blocks retrieved time data streams classified constant bit rate cbr variable bit rate vbr depending whether stream requests amount data interval storage system support requests different performance requirements based application needs continuous media applications may require deterministic performance guarantees ie guarantee requested block available within specified amount time continuously applications execution request interactive game request change sequence frames continuous media application may require request low response time ie may require latency guarantee regular file request may require besteffort service may require certain number requests served given time ie may require throughput guarantee may desirable provide deterministic service statistical service vbr streams system deterministic service may expensive systems resources user may request statistical service request deterministic service may denied due lack resources clear need supporting multiple levels performance guarantees within storage system several interesting questions need addressed multiple levels qos need supported system allocate balance resources different qos levels b control limit usage resources allocated levels c schedule different requests meet desired performance goals system level parameters design decisions affect different types requests e tradeoff performance goals higher throughput example much throughput gain statistical guarantees rather deterministic guarantees providing deterministic service disk complicated random service time costs involved disk transfers random seek latency overheads problem addressed effectively suitable disk scheduling policies 1 2 3 4 5 6 scheduling policies group number requests rounds batches service requests round using disk seek optimizing policy scan service time entire round bounded provide guarantees strategy works well cbr streams evaluation tradeoffs mediaondemand server found 7 however vbr streams workload changes round round hence approach consider variations load providing guarantees paper addresses problem providing different levels service different classes requests single system paper makes following two significant contributions 1 integrated scheme presented providing different levels performance guarantees different classes requests 2 method presented providing deterministic guarantees vbr streams exploits statistical multiplexing resources paper also presents evaluation tradeoffs providing deterministic statistical guarantees section 2 discusses approach providing different levels qos single system section 2 also proposes method providing deterministic service vbr streams allows exploitation statistical multiplexing across many request streams section 3 discusses related issues data layout section 4 presents performance evaluation schemes based tracedriven simulations section 5 summarizes results points future directions performance guarantees paper consider three different categories requests periodic requests require service regular intervals time periodic requests model behavior video playback data retrieved regular intervals time periodic requests either cbr vbr interactive requests require quick response io system interactive requests used model behavior changeofsequence requests interactive video playback application requests interactive video game requests arrive irregular intervals time aperiodic requests regular file requests paper consider deterministic statistical guarantees periodic requests b besteffort low response times interactive requests c guaranteed minimum level service bandwidth guarantees aperiodic requests approach providing qos guarantees disk shown fig 1 disk bandwidth allocated appropriately among different types requests category requests employs interactive request admission periodic request admission pool requests scheduled interactive requests requests periodic scheduled requests scheduler controller scheduler controller scheduler aperiodic request admission controller scheduler aperiodic requests figure 1 supporting multiple qos levels admission controller limit disk utilization requests allocated level provide throughput guarantees aperiodic requests limit allocated bandwidth periodic interactive requests 100 admission control aperiodic requests utilize remaining disk bandwidth similar approaches independently proposed recently 8 9 schemes employ twolevel scheduling approach proposed work 8 shares many motivations work scheduler 9 doesnt support quick response interactive requests work also proposes scheme allowing statistical multiplexing vbr streams providing deterministic guarantees admission controllers employed periodic requests interactive requests depend service provided requests next section discuss provide deterministic service periodic requests proposed approach modified implement statistical guarantees periodic requests well interactive requests treated highpriority aperiodic requests system scheduler admission controller designed provide low response times requests use leakybucket controller interactive requests bucket controller controls burstiness interactive requests allowing specified number requests given window time thus limits impact may requests admission controller class requests controls number requests entering pool requests also order requests enter pool controllers besides enforcing bandwidth allocations control policy scheduling requests class service generalized larger number request classes admission controllerscheduler disk level scheduler schedules requests request pool meet performance criteria individual requests system assumed requests identified service type scheduler scheduler designed independent bandwidth allocations done bandwidth allocation parameters admission controllers changed without modifying scheduler first describe overall functioning disk scheduler describe admission control implemented class requests 21 scheduling multiple qos levels since different classes requests strict priorities priority scheduling feasible periodic requests given priority others close missing deadlines sufficient slack time interactive requests higher priority receive lower latencies periodic requests available beginning round interactive aperiodic requests arrive asynchronously disk periodic requests given higher priority served first aperiodic interactive requests experience long response times beginning round periodic requests served moreover may possible better optimize seeks available requests considered disk scheduler uses round based scheme scheduling requests candidate pool admission controller schedules requests class releases candidate requests beginning round admission controller ensures class doesnt take time allocated round disk scheduler combines requests serves together meet performance goals individual requests requests arrive beginning round disk scheduler worry deadlines since admission controllers enforce time constraints however aperiodic interactive requests arrive asynchronously schedule requests arrive without waiting beginning next round disk scheduler uses notion subperiod disk scheduler considers available slack time periodic requests adjusts schedule incorporate arriving interactive aperiodic requests subperiod aperiodic requests queued two separate queues first queue holds requests based minimum throughput guarantee provided requests scheduling requests violate time constraints since requests within allocated bandwidth second queue holds requests waiting served scheduler considers requests second queue periodic requests interactive requests served requests utilize unused disk bandwidth scheduler merges periodic requests aperiodic requests queue 1 scan order beginning round requests grouped number subgroups based location disk surface scheduler serves subgroup requests time later arriving aperiodic requests queue 1 possible merged remaining subgroups scheduler considers serving interactive requests beginning subgroup ie disk scan order disturbed within subgroup provide quick response times interactive requests scan order may disturbed end subgroups possible scheduler groups waiting interactive request closest subgroup serves group next minimize seek overhead serving requests interactive requests queued firstcome firstserve basis limit maximum response time single request sufficient slack time exists waiting interactive requests first served moving next subgroup requests response times interactive requests hence determined burstiness interactive requests size subperiod size subperiod decreased tighter latency guarantees required arranging requests subgroups also allows scheduler communicate device driver efficient manner ensuring requests reordered scheduling algorithm within disk drive formal description scheduler given fig 2 claim group abides bandwidth allocation ie service time group combined schedule requests time allocation group within round proof need consider seek times since components service time dont change due merging requests actually rotational latencies could change since using worstcase estimates dont impact estimates without loss generality consider two groups requests group 1 requests b group 2 requests c two possible cases groups overlap disk surface case 1 overlap requests shown fig 3 disk surface two groups whiletrue f combine periodic aperiodic1 requests scan break requests subgroups service estimate requests whilenot end round f pick first interactive request combine one remaining subgroups f estimated service time slack time service waiting interactive requests serve closest subgroup else serve merged subgroup adjust slack time slack time f combine aperiodic1 requests existing subgroups adjust slack time periodic requests served f continue serving interactive aperiodic requests end round figure 2 semiformal description scheduler ddisk head group 1 ab group 2 cd figure 3 overlapping request groups b c ddisk head group 1 ab group 2 cd figure 4 nonoverlapping request groups calculate seek times ab merged seek times need show 1 merged 0a true case 2 overlap requests shown fig 4 disk surface two groups calculate seek times ab merged seek times need show 1 merged 0a clearly true since 0c bc requests arrived beginning round claim sufficient prove guarantees met individual groups observe bandwidth allocations interactive requests disturb scan schedule hence assumed require worstcase seek time servicing requests wont violate bandwidth allocations requests however aperiodic interactive requests arrive asynchronously hence slack times need considered violate deterministic guarantees vbr streams scheduling late arriving requests 22 deterministic guarantees vbr streams providing deterministic service vbr streams complicated following factors load stream system varies one round next ii scheduling first block doesnt guarantee following blocks stream scheduled ensure blocks required stream retrieved compute peak rate stream reserve enough disk bandwidth satisfy peak requirements stream resource allocation based peak demands stream underutilize disk bandwidth since peak demand observed short durations compared length duration stream however many streams served system peaks necessarily overlap may possible serve steams allowed peakrate allocation exploit statistical multiplexing increase deterministic service provided system propose approach allows system exploit statistical multiplexing providing deterministic service disk service broken fixed size time units called rounds batches round may span seconds time 1 approach application requiring service vbr stream supplies io system trace io demand data could based frame rate ie given frame frame basis could closely tied io system specifying load frame basis flexible application doesnt aware io system organized block size round size io systems block size known duration round known trace compacted specifying io load round round basis terms blocks example frame frame trace may look like 83888 9960 10008 27044 indicates number bits data needed display frame round size say 2 frames ie 112th second io system uses block size 4kb compacted trace would d83888 first entry second entry would d10008 block hence equivalent compacted trace stream would 3 1 40000 frame trace movie silence lambs 24 framessecond requires 203285 bytes frame frame basis compared 3333 byte description movie compacted knowledge round size 05 seconds block size 8kb assumed information available io system either description call demand trace compared size movie file 1 gb 90 minutes mpeg1 quality size demand trace file significant io system keeps track worstcase time committed service round disks form load trace stream admitted demand trace combined load trace appropriate disks see load one disks exceeds capacity committed time greater length round load trace system consists load traces disks sufficient period time requires knowledge placement blocks requesting stream information obtained storage volume manager stream admitted demand accommodated system possible stream cannot supported round request arrives stream scheduling policy look round stream scheduled assume stream wait maximum amount time given latency target admittance let loadij denote load disk round j let demand stream given demandj indicating number blocks retrieved stream round j stream admitted exists k loadij round time j storing data round j k startup latency latency target multiple disks may store data required stream round check needs appropriately modified verify disks support retrieval needed data function serv time estimates worstcase service time required retrieving given number blocks disk given current load disk function utilizes current load disk number requests blocks load arriving request estimate worstcase time required serve new request along already scheduled requests similar check applied buffer resources needed demand trace application may include extra block accesses needed metadata given latency target l length demand trace admission controller requires ld additions determine stream admitted worst case starting round admission controller finds last block stream cannot scheduled average admission controller requires less computation per stream necessary latency targets reduced limit time taken admission controller proposed approach allows load across disks smoothed across different streams served system individual stream smoothing considered number studies example 10 reduce variations demand single stream techniques typically prefetch blocks ahead time optimize desired characteristics reduce peak rate reduce demand variations etc individual stream possible apply individual stream smoothing techniques addition proposed technique smoothing demands different streams recent related study 11 showed individual stream smoothing didnt offer significant additional benefit applied along proposed approach 23 latency bandwidth guarantees latency guarantees provided disk scheduler explained earlier requests arrive randomly burst requests possibly disturb guarantees provided periodic requests avoid possibility interactive requests controlled leakybucket controller controls burstiness allowing certain maximum number interactive requests served given time window example interactive request service limited say 5 per second leakybucket controller ensure 5 requests released within second scheduler irrespective request arrival behavior hence interactive request experience delay controller well scheduler service sufficient bandwidth allocated requests waiting time controller limited periods requests arrive burst interactive requests scheduled fifo order limit queuing times individual requests use maximum response time performance measure requests sophisticated admission controllers take request burstiness account 12 employed necessary limit waiting times interactive requests admission controllers aperiodic requests provided bandwidth guarantees restricting periodic interactive requests certain fraction available bandwidth admission controller periodic interactive requests enforce bandwidth allocations aperiodic requests utilize remaining io bandwidth periodic interactive requests cannot utilize allocated bandwidths aperiodic requests allowed utilize available bandwidth improve response times aperiodic requests bandwidth guarantees provided aperiodic requests ensuring certain minimum number requests scheduled every round 3 issues 31 scheduling scheduling deals issue scheduling arriving vbr stream greedily scheduling stream early possible may impact possibility scheduling streams future scheduling stream immediately arrival saturates capacity disk disk would unavailable round service hence affect schedulability streams issue explored evaluating number scheduling strategies scheduling algorithms discussed use latency target parameter stream said unschedulable cannot scheduled within fixed time interval specified latency target arrival request stream arrives time slots within time l considered scheduling stream l latency target however order slots considered criterion selection among choices determined stream scheduling policy policies described starting point scheduling stream reaching l policy wraps around explores options greedy scheduling stream scheduled soon time request arrives system random start policy stream scheduled greedily random starting point within latency target window last scheduled policy stream scheduled greedily scheduled point last stream fixed distance policy stream scheduled greedily fixed time away last scheduled streams scheduled point minimal load policy stream scheduled point minimizes maximum load disk system prime hopping policy instead serially looking time slots starting point slots prime distance away considered example request arrives time 0 random starting point chosen rounds considered stream scheduled since p prime rounds within latency target window considered policies except minimal load policy worst case require old time l latency target length demand trace minimal load policy worst case requires old ln time additional oln time needed choosing slot minimizes maximal load n disks latency target impacts stream throughput two ways larger target allows us search slots find suitable starting point trace spread thus allowing future stream find enough io bandwidth scheduled scheduling problem considered two ways first given existing load system arriving stream scheduled without disturbing guarantees already scheduled streams problem consider paper scheduling decisions made one time another interesting problem arises capacity planning 13 system support load given set streams problem utilizes information streams answer question whether system support load required guarantees shown stream scheduling problem closely related bin packing problem known nphard 14 32 data layout data layout plays significant role performance disk access suggested many researchers video data striped 15 across disks load balancing improve throughput available single data stream 16 data vbr stream stored constant data length cdl units ii constant time length ctl units 17 18 cdl data distributed fixed size units say 64kb blocks ctl data distributed constant time units say 05 seconds display time cdl layout data striped across disks system data distribution straightforward since disk stores block turn cdl data retrieved varying rates based current rate stream data rate high data requested often variable rate data retrieval makes hard combine policy roundbased seek optimizing policies make possible combine cdl layout seek optimizing policies consider data retrieval separately layout policy instead retrieving one block time display content constant unit time requested io system example stream requires 2 3 blocks two consecutive rounds ctl layout blocks two disks say b round 1 b round 2 cdl layout data round 1 disks b data round 2 disks c 4 disks b c system however data layouts data required application round retrieved beginning previous round noted data required display unit time need multiple io block size since data retrieval constrained io block size system needed data rounded next block termed blockconstrained ctl data layout bctl paper bctl data distribution harder since amount data stored disk depends data rate round hence varies disk disk different data layouts considered paper show proposed mechanisms function well either data layout performance evaluation 41 simulations evaluated number issues tracedriven simulations system 8 disks simulated disk assumed characteristics seagate barracuda drive table 1 disk characteristics parameter value zero ms avg ms max ms min transfer rate 115 mbs max transfer rate 175 mbs ave latency 417 ms spindle speed 7200 rpm num cylinders 3711 19 disk drive characteristics shown table 1 disk system maintains load table depicts load disk future data block size disk varied form 32kb 256kb data striped across eight disks roundrobin order based either cdl bctl data layout policy simulations assumed first block movie stream stored random disk interactive requests aperiodic requests modeled poisson arrival periodic requests based real traces vbr movies periodic request load varied requesting streams scheduled interactive requests always ask 64kb data aperiodic requests uniformly distributed 4kb 128kb burstiness interactive requests controlled disk leaky bucket controller allowed maximum 12 interactive requests per second admission controller periodic streams employed strategy discussed section 22 cdl bctl data layout strategies considered bctl assumed stream pays latency penalty disk cdl stream pays one latency penalty disk per round example stream requires 1 block disks 1 2 3 stream pays latency penalty disks 1 2 3 round stream requires 10 blocks round 8 disks system pays latency penalty disk based assumption blocks retrieved round stream stored contiguously disk stream requests assumed arrive randomly time streams admitted however study worstcase scenario assumed requests arrive simulator tries schedule many streams possible stream cannot scheduled number streams scheduled stream throughput four different video streams considered study explained table 2 characteristics traces name mean sta dev kbsec lambs 17132 5833 news 48431 10886 asterix 52379 12450 simulations carried two different phases first phase considered vbr streams study effectiveness proposed scheduler vbr streams second phase considered integrated service three different types requests 411 traces mpeg traces university wuerzburg 20 used study frame frame trace movie constructed several versions demand trace movie study used four separate mpeg traces traces named lambs segment movie silence lambs term movie segment movie terminator news news segment trace asterix segment asterix cartoon trace contained 40000 samples frame rate 24 frames per second 27 minutes duration mixed workload based traces also constructed simulations equal probability one four traces selected scheduling ie workload consisted random mix four traces tracing selected equal probability trace different bit rate different mean variance characteristics shown table 2 block size 32 kb 64kb 128kb 256 kb 05 seconds round time used convert frame trace compact demand trace movie segment choice four block sizes get four different compact demand traces stream four different traces used study impact block size results 42 results first show results serving vbr streams alone system present results integrated service 421 vbr streams vbr admission control policy fig 5 shows impact block size data layout strategy stream throughput four different data streams mixed workload similar performance trends observed across individual streams mixed workloads observed peak rate based allocation leads significantly less throughput proposed approach peakrate based scheme utilizes peak demand stream round determining admissibility stream proposed approach achieves 130 195 stream throughput peak rate allocation improvement primarily achieved exploiting statistical multiplexing different streams requests arrive time flexible starting times latency targets allow peaks demand spread time improve throughput consider mixed workload experiments block size increased stream fetches less number blocks round hence cdl tends efficient larger block sizes due smaller seek rotational latency costs stream throughput cdl improves significantly data streams block size increased 32 kb 256 kb stream throughput drops slowly bctl block size increased due effects larger quantization service allocation request proposed approach improves stream throughput compared peakrate based scheme data layouts fig 6 shows disk utilization video streams function time figure shows load one eight disks system mixed workload even though average utilization 66 disk nearly 100 busy several seconds rounds 1800 2600 allowed video streams occasionally utilize full 100 io bandwidth system maintaining average utilization say 65 requests could get starved service long periods time case 400 seconds hence unacceptable system support multiple types requests result shows need bandwidth allocation among different classes requests peakrate peakrate cdl 300 400 500 lambs block size kb number streams peakrate peakrate cdl 300 400 500 term block size kb number streams news block size kb number streams 100 200 300 400 500 asterix block size kb number streams 100 200 300 400 500 mixed workload block size kb number streams figure 5 impact data layout block size vbr streams round number utilization video streams figure utilization vbr streams fig 7 shows impact stream scheduling policies stream throughput various block sizes results fig 7 mixed workload latency target 300 rounds greedy policy achieves least stream throughput data layout schemes observed minimal load policy achieves high stream throughput consistently bctl data layout however minimal load policy doesnt perform well cdl data layout prime hopping fixed distance random start achieve nearly stream throughput minimal load policy achieves average 15 better stream throughput three policies bctl layout observed stream scheduling policy significant impact performance example minimal load policy improves performance 80 compared greedy policy block size 32kb bctl data layout shows importance studying stream scheduling policies fig 8 shows startup latencies achieved different stream scheduling policies greedy policy nature achieves smallest startup latency however observed earlier also results lower stream throughput policies based randomness random start prime hopping fixed distance achieve average startup latencies close 150 half latency target 300 rounds considered results minimal load last scheduled achieve better latencies policies data layouts extensive results stream scheduling found 21 greedy random start last scheduled fixed distance prime hopping minimal load 100 200 300 400 500 block size kb throughput greedy random start last scheduled fixed distance prime hopping minimal load 100 200 300 400 500 block size kb throughput figure 7 impact stream scheduling statistical guarantees fig 9 shows impact statistical guarantees stream put instead requiring every block data retrieved time allowed fraction blocks stream miss deadlines provided service fraction varied among 50 various latency targets scheme admission controller decides blocks stream get dropped ie blocks dropped determined time admission otherwise would difficult provide stream isolation ie stream requesting statistical guarantees force another stream requesting deterministic service drop blocks time retrieval observed blocks allowed dropped possible achieve throughput compared deterministic guarantees stream throughput improved 20 allowing 5 blocks dropped dropping blocks effective lower latency targets higher latency targets example dropping 2 blocks improves stream throughput 145 latency target 100 rounds compared improvement 6 latency target 1000 rounds stream throughput also improved relaxing latency targets fig 9 also shows tradeoffs possible latency targets number blocks allowed dropped latency target 100 rounds 152 streams provided deterministic service achieve higher stream throughput either increase latency target allow blocks greedy random start last scheduled fixed distance prime hopping minimal load block size kb startup latency greedy random start last scheduled fixed distance prime hopping minimal load block size kb startup latency figure 8 average startup latency statistical allowance throughput latency targets statistical allowance avg utilization latency targets figure 9 effect statistical allowances dropped example increase latency target 1000 rounds 179 streams could scheduled without dropping blocks however achieve throughput latency target 100 rounds 2 blocks dropped hence desired throughput achieved either allowing larger latency targets allowing fraction blocks denied service fig 9 also shows impact average disk utilization function statistical allowances latency targets higher statistical allowances made disk utilizations improved streams supported latency targets increased 100 rounds average disk utilizations first increase decrease lower levels latency targets increased arriving stream finds choices find suitable starting spot utilize available bandwidth however latency targets increased streams scheduled farther farther future hence result decreasing disk utilizations since considering admission requests time 0 larger latency targets increase time window utilizations computed result average disk utilizations decrease continue admitting new requests times 0 earlier requests leave system disk utilizations continue improving increased latency targets usually considered statistical guarantees 99 ie dropping 1 blocks provide significant improvements stream throughput compared deterministic guarantees measurements improvements less 6 latency targets except 100 achieved improvement 11 primary reason proposed technique achieved significant statistical multiplexing streams providing deterministic guarantees 422 integrated service fig 10 shows average disk utilization periodic requests allocated 50 bandwidth aperiodic interactive requests allocated 25 bandwidth number periodic requests streams maintained maximum system support aperiodic request rate varied maintaining interactive request rate 50 requestssec request rates measured entire system 8 disks observed average utilization periodic streams stays 50 variations demand time periodic streams could admitted utilizations periodic interactive requests unaffected aperiodic request rate also observed increase aperiodic request rate aperiodic requests take bandwidth eventually utilize allocated 25 bandwidth periodic interactive requests dont make use allocated bandwidth interactive periodic total aperiodic arrival rate sec utilization figure 10 average disk utilizations across request categories aperiodic requests make use available bandwidth 25 minimum available hence achieve allocated 25 utilization disk shows disks left idle aperiodic requests waiting served fig 11 shows average maximum response times aperiodic interactive requests function aperiodic request rate number streams kept maximum allowed system interactive arrival rate kept 50 requestssec interactive response times considerably affected aperiodic arrival rate maximum interactive response time stays relatively independent aperiodic arrival rate also observed interactive requests achieve considerably better response times aperiodic requests 260 ms maximum interactive response time compared 1600 ms aperiodic requests 50 reqssec average maximum response times better interactive requests aperiodic requests even lower aperiodic arrival rates observed maximum interactive response times dependent burstiness arrival interactive requests bandwidth allocated zero percentage periodic requests missed deadlines aperiodic request rate varied fig 12 shows response times aperiodic requests interactive requests 25 requestssec number requested streams system varied 5 100 aperiodic avg interactive avg interactive max aperiodic arrival rate sec response time ms figure 11 impact aperiodic arrival rate response times considered allocation bandwidths system could support maximum 33 streams hence even number streams requested system admits 33 streams shows periodic request rate contained allow aperiodic requests interactive requests achieve performance goals observe maximum response times interactive requests considerably impacted number requested streams system fig 13 shows comparison proposed scheduling algorithm variant scan scheduling algorithm used current disks 22 figure shows average maximum response times interactive requests aperiodic request rate varied proposed method achieves better average maximum response times compared scan aperiodic arrival rate increased maximum average response times interactive requests get impacted scan scheduling policy proposed method isolates request categories maintains performance interactive requests independent aperiodic arrival rate aperiodic avg interactive avg interactive max requested stream rate response time ms figure 12 impact requested stream rate response times scan avg proposed avg proposed max aperiodic arrival rate sec response time ms figure 13 comparison scan 5 conclusions future work paper addressed problem providing different performance guarantees disk system proposed approach uses admission controllers appropriate scheduler achieve desired performance goals showed proper bandwidth allocation schedul ing possible design system one type requests impact performance another type requests proposed scheduling policy allows seek optimization achieving performance goals also proposed method providing deterministic guarantees vbr streams exploited statistical multiplexing different streams showed proposed approach provides 130195 throughput peakrate allocation also evaluated impact data layout performance showed startup latency effective tradeoff parameter improving stream throughput workloads considered statistical allowances top proposed approach provide significant improvement stream throughput work presented used static bandwidth allocations achieve performance goals currently investigating issues dynamic allocation adaptive performance guarantees also studying ways describing application load disks concisely load trace 6 acknowledgements reviewers comments greatly contributed improved presentation paper r io issues multimedia system grouped sweeping scheduling dasdbased multimedia storage management principles delaysensitivie multimedia storage retrieval fellini multimedia storage server guaranteeing timing constraints disk accesses rtmach implementation evaluation multimedia file system designing implementing highperformance mediaondemand servers disk scheduling framework next generation operating systems enhancements 44 bsd unix efficient networked multimedia project mars supporting stored video reducing rate variability endtoend resource requirements optimal smoothing computers intractability guide theory npcompleteness case redundant arrays inexpensive disks raid staggered striping multimedia information systems optimizing placement multimedia objects disk arrays scalable video data placement parallel disk arrays seagate corp mpeg trace data sets scheduling algorithms modern disk drives tr case redundant arrays inexpensive disks raid principles delaysensitive multimedia data storage retrieval io issues multimedia system scheduling algorithms modern disk drives staggered striping multimedia information systems supporting stored video cello computers intractability designing implementing highperformance mediaondemand servers realtime filesystems guaranteeing timing constraints disk accesses rtmach implementation evaluation multimedia file system enhancements 44 bsd unix efficient networked multimedia project mars optimizing placement multimedia objects disk array ctr youjip ryu handling sporadic tasks multimedia file system proceedings eighth acm international conference multimedia p462464 october 2000 marina del rey california united states ketil lund vera goebel adaptive disk scheduling multimedia dbms proceedings eleventh acm international conference multimedia november 0208 2003 berkeley ca usa javier fernndez jesus carretero felix garcia jose perez calderon enhancing multimedia caching algorithm performance new interval definition strategies proceedings 36th annual symposium simulation p175 march 30april 02 r seelam patricia j teller virtual io scheduler scheduler schedulers performance virtualization proceedings 3rd international conference virtual execution environments june 1315 2007 san diego california usa l narasimha reddy system support providing integrated services networked multimedia storage servers proceedings ninth acm international conference multimedia september 30october 05 2001 ottawa canada l n reddy jim wyllie k b r wijayaratne disk scheduling multimedia io system acm transactions multimedia computing communications applications tomccap v1 n1 p3759 february 2005