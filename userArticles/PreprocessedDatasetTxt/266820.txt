procedure based program compression cost power consumption two important design factors many embedded systems particularly consumer devices products personal digital assistants pagers integrated data services smart phones fixed performance requirements unlimited appetites reduced cost increased battery life program compression one technique used attack problems compressed programs require less memory thus reducing cost direct materials manufacturing furthermore relying compressed memory total number memory references reduced reduction saves power lowering traffic highcapacitance buses paper discusses new approach implementing transparent program compression requires little hardware support procedures compressed individually directory structure used bind together runtime decompressed procedures explicitly cached ordinary ram complete units thus resolving references within procedure approach evaluated set 25 embedded multimedia communications applications results average memory reduction 40 runtime performance overhead 10 b introduction present technique saving power reducing cost embedded systems concerned primarily datarich consumer devices used computation communications eg socalled information appliance currently product category includes devices simple personal digital assistants pagers cell phones future emerging industry vision ubiquitous multimedia devices java appliance products extremely tight constraints component cost uncommon memory one expensive components products thus providing need reduce size stored programs second important design goal low power consumption products battery powered reduced power consumption directly translated extended battery life battery life often important factor product class pager cellular phone functionally verified battery life one effective techniques product differentiation large number embedded systems power used access memory processor bus dominant factor system power consumption unlike desktop computing performance often primary factor devices information appliances classic forms missioncritical computing tend important realtime aspects example certain amount processor performance necessary decode paging message little benefit providing faced factors decided investigate benefits storing programs compressed form compressed programs may reside type memory often depending whether system supports software field upgrades basic approach store program image compressed form dynamically decompress demand effective compression scheme would reduce amount system memory required various applications thus saving cost board space static power consumption additional benefit involves significantly reduced power consumption due dynamic memory references believe effective compression scheme reduce power consumption cannot currently provide direct evidence relationship 11 previous approaches relevant previous work divided four groups whole program transformation cachebased dictionary schemes highly encoded instruction set architectures direct technique compressing programs involves explicit compression decompression complete program portion ram dedicated decompressed buffer programs expanded compressed form ram prior execution approach applied file systems 1 saving disk space virtual memory explicit file caches usually effective reducing impact decompression algorithms latency unfortunately approach well suited embedded systems information appliances single application example datarich pager verticalmarket application motorola sportstrax news device whole program decompression systems would result ram size exceeding rom size increases cost power consumption wolfe chanin kozuch presented scheme block based decompression response dynamic demands 2 3 goal improve code density generalpurpose processor architectures considered number compression algorithms concluded huffman code 4 reduced code size 74 original effective programs decompressed brought instruction cache thus compression transparent executing application one problem wolfe et al identified involves translating memory addresses program space ie decompressed compressed program backing store example program pc relative jump hits cache ordinary cache hardware resolve reference however case cache miss refill hardware must determine compressed space target stored problem requires set jump tables patch references program space compressed space link time tool used automatically generate necessary jump tables liao devadas keutzer developed dictionary approach reduce code size dsp processors 5 correlation done across basic blocks program compilation linking purpose correlation identify common instruction sequences exceed minimal length sequences written dictionary original occurrences replaced mini subroutine call sic ie procedure call arguments application code skeleton procedure calls bits uncommon code sequences approach implemented hardware support results presented indicated might achieve code size reductions approximately 12 minor modification hardware additional 4 code size reduction also achieved approach result extremely high rate procedure calls discussion impact calls performance issue could particularly significant face tight code scheduling constraints target machine texas instruments tms320c25 dsp ernst et al investigated use bytecoded machine language 6 compression approach hearkens back original goal tightly encoded isa formats cisc processors much work focused minimizing impact performance 2 procedure cache wolfe et al developed effective technique transparent code compression approach two specific features may prove disadvantageous first since compression process transparent supervisor code well application entire decompression translation process must implemented hardware dedicated decompression hardware benefit low overhead option use approach stock hardware interested schemes leverage existing hardware option necessity hardware accelerators secondly mapping problem compressed space program space complicates hardware well linking process pcache application directory rom compression utilities compression tables processor core rom hardware accelerator figure 1 embedded system architecture pcache system place dedicated hardware transparently code blocks propose using demand driven decompression triggered procedure invocations procedures decompressed atomic units stored dedicated region ram explicitly managed runtime system figure 1 approach efficiently solves problem address mapping references contained within one procedure eg loops conditional code experience shows common forms branching remaining interprocedure global references must resolved use directory service call software cache procedure cache pcache pcache able store procedure small enough fit within result goal pcache algorithms must manage variable size objects may aligned boundary convenient addressing unlike conventional hardware caches manage fixed size lines blocks issue maximum procedure size problematic number solutions present decided yet upon recommended path 21 runtime binding procedure calls bound together runtime consulting directory service linking tool translates call request unique identifier directory service looks location call target activates target proper linkage needed return operation table stored program used translate procedure identifiers addresses compressed memory case scheme wolfe et al table must generated program linked process used runtime binding broken following stages 1 source invokes directory service unique identifier target procedure 2 target pcache go step 9 3 find target address compressed memory consulting directory service 4 enough contiguous free space exists pcache target go step 8 5 enough fragmented free space exists pcache target go step 7 6 mark procedures eviction enough space available 7 coalesce fragmented space contiguous block 8 decompress target procedure assigned pcache location 9 patch state allow target return caller 10 invoke target procedure traditional execution environment binds one procedure another call instruction typically executes one memory reference updates program counter two call instructions used process one step 1 one step 10 let l represent time required lookup target procedure identifier directory service data structure step 2 let represent time required management relatively stable steady state let required decompress procedure pcache hit rate represented h significant calculation expected case performance worstcase execution time involves compacting free space identifying procedures replace followed time required decompress target procedure worst case call time expected case ie cache hit call time case clearly important increase hit rate however limiting case hit rate high directory scheme still imposes cost c l every procedure invocation better approach cache address target procedure call site avoid directory service overhead subsequent calls target similar approach used high performance objectoriented runtimes systems speculatively bind method invocations typed methods 7 runtime directory binds call sites targets patches call site subsequent invocations jump straight target test runtime type information determine processor ended right location test succeeds execution continues fails directory service consulted approach works cached target address guaranteed start valid code sequence difficult guarantee code blocks move within address space loaded approach would work pcache cache replacement compaction make alignment restrictions prohibitively expensive procedures need aligned standard boundary thus risk exists jump would end middle procedure free space alternate approach advocating test validity cached target address call site scheme involves test operations pcache testing destination since procedure single entry point may call multiple targets order test call site procedure must prologue contains procedure identifier conceptually call site loads word precedes cached target address compares target wishes invoke jumps cached address match sequence changes best case invocation sequence two jumps directory service lookup one load test conditional jump pcache large number procedures thus expensive directory service lookup cached target result performance improvement pure directory scheme possibility procedure identifier corresponds legal code sequence introducing danger false positive test problem avoided introducing tag byte identifies word procedure identifier specific tag byte use depends processor architecture must correspond illegal opcode placed proper word alignment unfortunately approach foolproof processors variable length instructions intel x86 68k cases possible guarantee target identifier match code sequence embedded data though likelihood event reduced tagging procedure identifiers also makes easy implement reference scheme order approximate lru data pcache management runtime system periodically clear tag bytes thus forcing cached targets fail invoking directory service machines 32bit words use tag bytes reduce procedure identifier space 24 bits feel range prove sufficient needs embedded systems 22 procedure returns return instructions bit complicated traditional code sequence cannot explicitly name destination return operation pcache runtime system solves problem storing three pieces data source procedure identifier predicted address start return procedure address caller time invoked active procedure offset call site start source procedure regular return procedure replaced test predicted prologue source jump address plus displacement event success failure causes directory service lookup possibly reload destination return operation jump address plus displacement 23 replacement algorithms task allocating space pcache new procedure involves two step process first pcache searched free block large enough satisfy new demand experimented best fit firstfit stage found approaches produce similar results results presented respect firstfit simplified implementation enough free space available single block runtime system must invoke pcache compactor pcache compacted moving live procedures start pcache free fragments end pcache event runtime system find must invoke replacement algorithm identify procedures evicted pcache experimented two algorithms replacement least recently used lru neighbor lru runtime system scans lru list marks procedure sequence eviction enough space freed accomplished compactor invoked coalesce free space single block large enough new procedure lru easy implement conceptually simple tend cause significant amount memory traffic pcache coalesce fragmented free space example consider case together two lru procedures enough space satisfy new request happen reside first third quadrant pcache subsequent compacting stage need move approximately half pcache data order combine space freed evicting two procedures may case third lru procedure could combined one first two resides adjoining region memory case compacting procedure trivial since intervening procedures need moved pcache primary benefit optimization reducing data movement pcache secondary benefit avoiding subsequent tag misses moved procedures resulting lookup events directory service experimented two schemes reduce amount data movement within pcache response pcache misses first scheme called neighbor involves looking sets adjacent procedures good candidates eviction set procedures evaluated basis sum squares lru values least recently used procedure lru value 1 increase sequentially approach biased toward avoiding procedures used recently though explicitly exclude consideration neighbor scans pcache adjacent blocks memory large enough new request considers free occupied space algorithm selects set blocks lowest sum squares lru values general form neighbor involves evaluating function fs set neighbors f arbitrary function advantage using sum squares easy evaluate runtime provides strong bias selecting recently used procedures modification approach use limiting term cap value set adjacent blocks exclude consideration set exceeds limit goal approach make impossible remove frequently used procedures even cases one procedures would otherwise selected eg neighbors large procedure least frequently used 3 experiments 31 approach trace driven simulation used evaluate effectiveness caching whole procedures pcache simulator must know procedure activated either directed call result return operation asynchronous transfer eg exception unix longjmp traces collected special augmented version lsim impact compilation system 8 tool allows us dynamically generate large set activation events support sophisticated trace sampling 32 applications currently exists significant void regards effective benchmarks embedded systems number industrial academic efforts proposed date little progress towards suite representative programs workloads one part problem field embedded systems covers extremely wide range computing systems difficult imagine benchmark suite would reveal useful information designers machines cellular phones drastically different uses products hope emerging unification area information appliances cohesive focus devices currently options choose unfortunate state affairs best reflected continued use dhrystones benchmark derivative metric dhrystones per milliwatt purposes paper adopted number programs mediabench benchmark suite 9 six additional programs selected five spec95 benchmark set along backwater basic interpreter figure 2 figure 3 show cumulative distribution functions cdf procedure sizes bwbasic go represent typical distribution worst case widest spread respectively data presented static program image memory well dynamic distribution seen execution data suggests modest size pcache often succeed capturing working set general dynamic data exhibits slightly slower growth static data show sharper breaks phenomena result skewed distribution call frequency among procedures0103050709static dynamic figure 2 procedure size distribution bwbasic 33 pcache miss rates table 1 shows raw miss rates lru replacement table 2 presents data neighbor used replacement miss rates calculated counting reference generated program regardless whether procedure actually cacheable ie smaller simulated pcache size significance low cache miss rates much difficult evaluate traditional hardware cache fixed size objects example significant difference missing average static procedure go 1k missing frequent procedure 12k nevertheless simulator marks single miss event0103050709static dynamic figure 3 procedure size distribution go several application particular raw audio encoder decoder achieve extremely low miss rates general trends lru neighbor similar hit rates two notable exceptions djpeg mpeg2enc show high miss rates 1k pcaches lru neighbor rates stay relatively high 2k neighbor drop lru cases specific procedure frequently called captured lru dynamics though neighbor procedure size cdf go figure suggests dynamic reference stream much larger footprint bwbasic figure 2 thus surprising bwbasic shows reduced miss rates comparable pcache sizes hand relatively small pcache size eg 16k 32k still effective miss rate data displays interesting result neighbor generally achieves lower miss rate lru certainly possible pathological pedagogical cases exhibit behavior like general lru expected achieve highest hit rates behavior consequence caching variable size objects consider case hardware cache fixed block size certain amount space must made available entire cache allocated specific number blocks must evicted cache cache lru proven effective providing best guess blocks evicted software pcache used number procedures evicted pcache depends upon specific procedures selected explain result considering three different types pcaches small medium large small pcache neighbor tend approach lru performance smaller spread lru values least recently used procedures large pcache evictions rare performance approach compulsory miss regardless replacement algorithm medium case number references satisfied available free space replacement algorithm inconsequential assume cdf procedure size correlated lru value 1 new procedure activation causes runtime invoke replacement algorithm half cases size newly activated procedure equal less size lru procedure thus lru neighbor select lru procedure remaining cases lru algorithm traverse list least frequently used procedures mark eviction amount space freed least equal new request neighbor however looks contiguous blocks good candidates according specific cost function relying squlru cost function neighbor biased combining multiple procedures best set figure 4 illustrates phenomenon assume three units space must freed lru algorithm choose first three procedures lru list procedures 23 17 87 eviction 1 may hold cases believe assumption valid general invoke compactor coalesce space hand neighbor using square lru counts select procedure 12 eviction 2 found general cases lru neighbor select different sets procedures replacement neighbor tends select fewer procedures continuing example figure 4 may good idea evict either procedure 17 87 procedure 12 seems intuitive would best evict three rather 12 proc 12 lru 4 cost proc proc 23 lru 3 cost 9 proc 35 lru 12 cost 144 proc 87 lru 2 cost 4 selected lru selected neighbor figure 4 example lru chooses optimal set neighbor evicts fewer procedures pcache miss rate gcc direct result dynamic program size cdf frequently used procedure gcc 12k bytes corresponds 8 procedure activations second common procedure 52 bytes corresponds 2 procedure activations although procedures exceed pcache size excluded still contribute count procedure activations thus gcc simulations low hit rates pcaches 64k bytes interesting phenomenon may occur one large common procedures finally admitted pcache impact introducing large procedure pcache causes lru evict huge number procedures discussed neighbor tends evict fewer resulting impact pcache miss rate lru dramatic seen gsmencode 8k 16k 34 compacting events table 3 table 4 show rate compaction events per procedure activation rather raw event counts order make presentation consistent across test programs data illustrates effectiveness neighbor algorithm neighbor lru achieve roughly comparable results pcache hit rates neighbor much effective reducing number compacting events data neighbor algorithm generally produces much 2 note position procedure 35 high lru cache blocks neighbor merging procedures 17 35 along free space adjacent 35 flatter response function pcache size performance consequence neighbor compacting pcache already enough free space procedure eviction required amount expected free space pcache monotonic pcache size rather complicated function size dynamic references fact illustrated pcache size 8k go illustrating rate compacting events actually increase response increase pcache size gcc shows sharp response soon admission 12k procedure 126gcc cjpeg djpeg gsmdecode mipmap pgpdecode rasta rawdaudio unepic figure 5 performance impact pcache operations relative base case 4 performance pcache structure reduce performance due three types events cache management including lru management directory service memory movement due compaction events within pcache decompression data transferred memory impact factors evaluated resulting performance shown figure 5 large volume memory traffic within pcache management component comparatively little impact performance byte memory moved within pcache due compaction charged half clock cycle assuming two 32bit memory operations required loop unrolling used hide loop management overhead compression technique used based algorithm requires average 22 cycles sparc compress byte sparc binaries achieves 60 compression ratio 10 however number algorithms could selected balance demands performance compression particular application huffman coding hardware briefly discussed later average slowdown applications 166 64kbyte pcache however go gcc excluded pcache average slowdown 11 numbers climb 600 36 32kbyte caches clearly important exclude illbehaved applications pcache problem easy manage embedded system software generally highly tuned execution environment 5 discussion benefit considering schemes require additional hardware pcache architecture still take advantage hardware acceleration available number researchers designed hardware instruction decompression particularly good example 11 provides 480mbs huffman decompression mips instruction stream device requires 1 cm 2 08micron process technology used hardware decompression pcache still effective increasing compression rates increasing significantly increasing block size furthermore dictionary size reduced since instead entry every possible jump target entry subroutine impossible say pcache interact traditional hardware caches without discussing specific hardware configuration pcache memory nearby highspeed sram cache ignore transparent caching hardware provide direct latency benefit consuming valuable resources hand pcache memory relatively slow cached hardware well almost sophisticated embedded processors include memory control hardware functions chipselect waitstate insertion bus sizing hardware augmented allow blocks memory become noncacheable common feature highperformance processors 6 conclusions presented new approach applying compression stored program images technique easily reduce program storage approximately 40 correspond significant cost reduction embedded products targeted consumer market compressing complete procedures rather smaller subblocks able avoid cost dedicated hardware resulting performance impact measured approximately 10 wide range sophisticated embedded applications trace driven simulation used evaluate opportunity using compression associated tradeoff points results suggest small software controlled cache perhaps 16k bytes standard sram effective caching working set reducing dynamic memory traffic additional effect compressing traffic system bus decreases main memory traffic thus helps attack problem power consumption r combining concepts compression caching twolevel filesystem executing compressed programs embedded risc architecture compression embedded system programs method construction minimum redundancy codes code density optimization embedded dsp processors using data compression techniques code compression efficient implementation smalltalk80 system impact architectural framework multipleinstruction issue processors tool evaluating multimedia communications systems extremely fast zivlempel data compression algorithm highspeed asynchronous decompression circuit embedded processors tr combining concepts compression caching twolevel filesystem impact executing compressed programs embedded risc architecture code compression compression embedded system programs code density optimization embedded dsp processors using data compression techniques highspeed asynchronous decompression circuit embedded processors efficient implementation smalltalk80 system ctr israel waldman shlomit pinter profiledriven compression scheme embedded systems proceedings 3rd conference computing frontiers may 0305 2006 ischia italy saumya debray william evans cold code decompression runtime communications acm v46 n8 august youtao zhang jun yang rajiv gupta frequent value locality valuecentric data cache design acm sigplan notices v35 n11 p150159 nov 2000 youtao zhang jun yang rajiv gupta frequent value locality valuecentric data cache design acm sigops operating systems review v34 n5 p150159 dec 2000 stacey shogan bruce r childers compact binaries code compression software dynamic translator proceedings conference design automation test europe p21052 february 1620 2004 g hallnor steven k reinhardt compressed memory hierarchy using indirect index cache proceedings 3rd workshop memory performance issues conjunction 31st international symposium computer architecture p915 june 2020 2004 munich germany keith cooper nathaniel mcintosh enhanced code compression embedded risc processors acm sigplan notices v34 n5 p139149 may 1999 jun yang youtao zhang rajiv gupta frequent value compression data caches proceedings 33rd annual acmieee international symposium microarchitecture p258265 december 2000 monterey california united states marc l corliss e christopher lewis amir roth dise implementation dynamic code decompression acm sigplan notices v38 n7 july charles lefurgy eva piccininni trevor mudge evaluation high performance code compression method proceedings 32nd annual acmieee international symposium microarchitecture p93102 november 1618 1999 haifa israel bita gorjiara daniel gajski fpgafriendly code compression horizontal microcoded custom ips proceedings 2007 acmsigda 15th international symposium field programmable gate arrays february 1820 2007 monterey california usa ozturk h saputra kandemir kolcu access patternbased code compression memoryconstrained embedded systems proceedings conference design automation test europe p882887 march 0711 2005 susan cotterell frank vahid synthesis customized loop caches corebased embedded systems proceedings 2002 ieeeacm international conference computeraided design p655662 november 1014 2002 san jose california susan cotterell frank vahid tuning loop cache architectures programs embedded system design proceedings 15th international symposium system synthesis october 0204 2002 kyoto japan oliver rthing jens knoop bernhard steffen sparse code motion proceedings 27th acm sigplansigact symposium principles programming languages p170183 january 1921 2000 boston usa marc l corliss e christopher lewis amir roth implementation evaluation dynamic code decompression using dise acm transactions embedded computing systems tecs v4 n1 p3872 february 2005 guilin chen mahmut kandemir optimizing address code generation arrayintensive dsp applications proceedings international symposium code generation optimization p141152 march 2023 2005 milenko drini darko kirovski hoi vo code optimization code compression proceedings international symposium code generation optimization feedbackdirected runtime optimization march 2326 2003 san francisco california bjorn de sutter bruno de bus koen de bosschere sifting mud low level c code reuse acm sigplan notices v37 n11 november 2002 milenko drini darko kirovski hoi vo ppmexe program compression acm transactions programming languages systems toplas v29 n1 p3es january 2007 bjorn de sutter ludo van put dominique chanet bruno de bus koen de bosschere linktime compaction optimization arm executables acm transactions embedded computing systems tecs v6 n1 february 2007 rpd beszdes rudolf ferenc tibor gyimthy andr dolenc konsta karsisto survey codesize reduction methods acm computing surveys csur v35 n3 p223267 september bjorn de sutter bruno de bus koen de bosschere linktime binary rewriting techniques program compaction acm transactions programming languages systems toplas v27 n5 p882945 september 2005