subdivision direction selection interval methods global optimization role interval subdivisionselection rule investigated branchandbound algorithms global optimization class rules allows convergence model algorithm characterized shown four rules investigated satisfy conditions convergence numerical study wide spectrum test problems indicates substantial differences rules terms required cpu time number function derivative evaluations space complexity two rules provide substantial improvements efficiency b introduction interval subdivision methods global optimization 7 21 aim providing reliable solutions global optimization problems min 1 objective function f continuously differentiable x ir n ndimensional interval many cases globally optimal solutions acceptable 4 22 local minima less important special problem structure required inclusion functions objective function gradient utilised 1 denote set compact intervals ii fa b j b b 2 irg set ndimensional intervals also called simply intervals boxes ii n call function f ii n ii inclusion function f interval x words fx f x fx range fx x inclusion function gradient fx denoted f 0 x several ways build inclusion function given optimization problem eg using lipschitz constant interval arithmetic 1 6 7 21 convenient tool constructing inclusion functions one get almost functions calculated finite algorithm ie given expressions assumed following inclusion functions isotonicity property ie x implies f x f inclusion functions 2 holds wx width interval x generality problem class modest requirement existence inclusion functions stress importance improvement efficiency department applied informatics jozsef attila university szeged arpad ter 2 hungary e mail csendesinfuszegedhu work supported grants cipa3510ct926141 cost project ec otka 28791991 mkm 4141994 z institut fur angewandte mathematik universitat karlsruhe kaiserstrae 12 d76128 karlsruhe germany email ae07rzunikarlsruhede interval global optimization methods studying effects accelerating tools 5 present paper investigates role selection interval subdivision direction 2 model algorithm subdivision direction selection rules first give simple model algorithm important common features interval subdivision methods global optimization cf 2 3 5 6 7 16 21 22 local search procedure included newtonlike steps also built since would need inclusion hessian hand cutoff monotonicity tests applied usage require additional information problem would make sense skip tests although crosseffects direction selection rules skipped steps possible investigation numerical implication subject study model algorithm follows x initialize list cutoff level z maxf x choose coordinate direction k 2 ng bisect direction k step 4 remove list l step 5 cutoff test discard pair step 6 monotonicity test discard remaining pair j 2 2 step 7 add remaining pairs list l list becomes empty stop step 8 denote pair smallest second element step 9 width f less print f stop go step 1 interval first set step 0 updated step 8 called leading box leading box iteration number denoted notice cutoff test effect convergence algorithm may decrease space complexity 5 maximal length list l interval subdivision direction selection rule step 1 target present study following describe shortly four rules discussed rules select direction using merit function ae ng oe di determined given rule rule first interval width oriented rule applied 16 21 24 chooses coordinate direction rule justified idea original interval subdivided uniform way width actual subintervals goes quickest zero also used generating subdivision direction optimization procedures eg 11 924 csendes ratz algorithm rule convergent without monotonicity test eg 5 21 rule allows relatively simple analysis convergence speed 21 chapter 3 theorem 6 usual definition rule specify one single coordinate direction maximum achieved many times 3 take smallest one sake brevity call interval subdivision direction selection rule sequel rule rule b hansen described rule initiated g w walster 7 direct aim heuristic direction selection rule find component largest mx midpoint interval factor w reflect much f varies x varies x approximated wf 0 latter upper bound w cf 7 page 131 example 2 section 3 present paper yet useful merit function rule b selects coordinate direction 3 holds noted model algorithm represents one way rule b applied 7 subdivision eg carried also many directions single iteration step rule c next rule investigation defined ratz 23 underlying idea minimize width inclusion obviously component chosen wf 0 largest thus rule c also formulated 3 important difference 5 6 rule c width multiplied intervals maximized multiplied widths respective intervals general equal short calculation righthand side 6 written maxfj minf 0 corresponds maximum smear used direction selection merit function solving systems nonlinear equations 13 case f easy see rules b c give merit function value either min f 0 worth mentioning xjg best possible estimation lipschitz constant onedimensional function fx fixed variables x subdivision direction selection interval methods global optimization 925 fig 1 remaining subintervals 100 iteration steps model algorithm direction selection rules b c sixhumpcamelback problem current box x basis available inclusion function information formulation shows model algorithm direction selection rule c related lipschitzian partition methods global optimization 19 20 rule fourth rule derivativefree like rule reflects machine representation inclusion function f x see 6 defined 3 otherwise rule called rule may decrease excess width wf inclusion function caused part floating point computer representation 926 csendes ratz 35fig 2 remaining subintervals 10 iteration steps model algorithm direction selection rules b c ex1 problem real numbers consider case component widths similar order absolute value one component dominant subdivision latter component may result worse inclusion since raster points representable numbers sparser direction typical distributions subintervals shown figure 1 discussed direction selection rules b c respectively sixhumpcamelback standard global optimization test problem 4 21 23 solved model algorithm initial box gamma20 20 2 figures show situations 100 iterations numbers subintervals 38 31 32 42 respectively figures reflect space complexity related procedures certain extent direction selection rule tends form squarelike boxes rule produces elongated intervals magnitudes coordinates differ rules b c generate similar sets subdivision direction selection interval methods global optimization 927 subintervals reflecting utilised derivative information sets subintervals closely fit respective level sets differences mainly due overestimating inclusion functions since global minimizer points remaining subintervals uncertainty place global minimum deceased substantially figure 1 shows little efficiency involved algorithms addressed later section test problem called ex1 constructed show differences caused different direction selection rules simple function minimized initial box 00 20 theta 100 120 sine terms added inhibit fast convergence due monotonicity property figure 2 provides sets subintervals 10 iterations respective model algorithms subboxes denoted selected next subdivision figures subintervals indicate age intervals 1 oldest among remaining boxes rule tends form square like boxes others produce elongated subintervals direction preferred rule different chosen often rules b c notice model algorithm rule unable delete subinterval initial box greatest volume decreases due rules b c 3 convergence direction selection rules next theoretical study define sequence intervals produced model algorithm specify property direction selection rules ensure convergence algorithm exception rule 21 similar convergence investigation published assume direction selection rules decide using exclusively information provided x f x f 0 x interval x subdivided assumption valid rules strategy utilize information collected earlier iteration steps may increase space complexity substantially definition 31 call infinite sequence intervals s0 infinite subdivision sequence nonnegative integer box s1 given s1 direction selected given rule f f 0 easy see x discarded monotonicity test set leading boxes s0 contains least one infinite subdivision sequence set s0 contains infinite subdivision sequences finite sequences subintervals end box ng latter finite sequences affect convergence procedure definition 32 call direction selection rule balanced intervals x isotone inclusion functions f x f 0 x property 2 infinite subdivision sequence x subsequence leading boxes sequence directions generated given rule contains k possible directions infinite number times name property reflects fact even though rules necessarily deliver directions uniform way yet direction distance two appearances finite number iteration steps denote set accumulation points sequence s0 global minimum fx x f set global minimizer points fx x 928 csendes ratz recall inclusion functions f x f 0 x assumed isotone property 2 holds set stopping criterion parameter zero sake convergence investigation monotonicity test may discard subintervals containing global minimizer points boundary x since main point present study investigate impact direction selection rules convergence model algorithm assume exists stationary point x 2 x wx 0 since otherwise solution requires search thus subdivision theorem 31 model algorithm converges sense lim s1 wy interval subdivision direction selection rule balanced proof 1 assume direction selection rule required property model algorithm produces infinite sequence intervals s0 global optimization problem given x f f 0 sequence s0 contain least one subsequence l l0 infinite subdivision sequence construction s0 contains union certain infinite subdivision sequences additional boxes belong subdivision sequences terminated monotonicity test latter boxes affect value lim s1 wy property balancedness holds infinite subdivision sequence l incorporated s0 implies lim l1 wy l hence proven lim s1 wy 2 assume exists infinite subdivision sequence actual direction selection rule 2 ng wx appears finite number times generated sequence directions obviously theorem 32 assume interval subdivision direction selection rule balanced model algorithm converges global minimizer points sense lim s1 f proof stationary point x 2 x fx holds subinterval z containing subintervals cannot deleted monotonicity test consequently x union boxes list l iteration s0 infinite sequence intervals inside x set accumulation points cannot empty inclusion property f x definition leading box imply f 2 f iteration number lim s1 wy according theorem 31 equation property 2 imply lim s1 wf thus also x one direction assertions theorem 31 theorem 32 generalization convergence results 21 model algorithm studied class direction selection rules opposite direction statements theorem 32 always true 6 eg holds also direction selection rule balanced notice also f 2 using special property direction selection rule theorem 33 assume model algorithm converges given problem 1 global minimizer points sense lim s1 f thus x either algorithm proceeds problem like algorithm balanced direction selection rule exists box x subdivision direction selection interval methods global optimization 929 w ng coordinate directions selected finite number times proof assume exists x property defined theorem 33 wf exists x 2 implies lim s1 wy theorem 31 obtain direction ng wx selected infinite number times main result theorem 33 exception problems x defined exists direction selection rule must balanced ensure convergence global minimizer points corollary 34 subdivision direction selection rules balanced thus model algorithm converges global minimizer points rules proof assume rules global optimization problem given s0 infinite subdivision sequence problem let ng coordinate direction wx consider first model algorithm direction selection rule di positive according 4 chosen next subdivision direction steps latest bc denotes largest integer greater argument expression gives 1 wy largest finite compact intervals wy selected subdivision direction finite number iteration steps must appear infinite number times infinite subdivision sequence consider model algorithm rule assume coordinate direction wx chosen finite number times di constant positive cf 7 finite number steps consider part sequence s1 di constant positive let j another index selected infinite number times although dj necessarily monotonously decreasing 1 exists 0 contradiction corollary 35 either subdivision direction selection rules b c choose direction 2 ng wx infinite number times thus model algorithm converges global minimizer points rules algorithm converges subinterval x positive width contains global minimizer points proof assume rules b c global optimization problem given x f f 0 let s0 infinite subdivision sequence problem ng coordinate direction wx consider model algorithm direction selection rule b means wf 0 discarded monotonicity test f 0 fx independent x latter case subdivision required respect hence assume di 0 without loss generality assume selected finite number times wy remains constant positive finite number steps let j another index chosen infinite number times wf 0 wy thus global minimum f must attained point result interval lim 1 since interval would discarded monotonicity test thus either csendes ratz algorithm converges subinterval x contains global minimizer points direction selected infinite number times consider model algorithm subdivision direction selection rule c assume j coordinate direction selected infinite number times converges zero iteration f 0 bounded isotone ng merit function di nonnegative beginning either direction selected infinitely many times lim 1 wy latter case point interval lim 1 global minimizer point example 1 want find global minimizer points problem 1 2 interval use range functions inclusion functions using direction selection rule c model algorithm w00 20gamma05 thus second coordinate selected sub division next leading box 025 procedure converges interval without single subdivision first coordinate according comment definition rule c merit function values selected directions rule b ie result interval obtained inclusion rule b example 2 algorithm rule b may become nonconvergent remove monotonicity test consider eg function 2 f 0 rule b chooses always direction 2 case lim s1 min f 6 lim s1 maxf leading box iteration number although probability phenomenon reallife problems small yet worth note behavior differs rules aimed problem class obviously wide allow meaningful theoretical comparisons studied subdivision rules next section shows results extensive numerical testing 4 numerical experiences numerical tests carried ibm risc 6000580 workstation coded fortran90 implemented interval arithmetic package handling outside rounding necessary inclusion functions authors thank r b kearfott w v walter kind help providing interval arithmetic package 12 necessary modules inclusion functions produced natural interval extension fulfils assumptions made section 1 isotonicity property 2 straightforward way transform subroutine calculating real function interval version one simply write new statement include interval module change data types real interval rename function calls procedure much simpler quicker less error prone earlier one fortran77 operations transformed function calls new data structures sophisticated inclusion functions like 10 21 would result better efficiency figures cost additional calculations preliminary reformulations involved functions inclusions gradients calculated componentwise way component calculations could skipped monotonicity test showed subdivision direction selection interval methods global optimization 931 objective function monotonous variable hand could make use possible joint computations many gradient components code gradients calculated symbolically neither automatic numerical differentiation used effects using alternative ways gradient inclusion subject future study stopping criterion parameter set 001 test list l implemented simple array list fully ordered program kept track three first list members implementation efficient short lists problems large memory complexity require data structures like avl trees search trees 9 11 implementation list affect required cpu time number objective function derivative evaluations memory complexity invariant regarding data structure terms maximal number items saved size data structure decreased using available information 11 numerical tests involved set standard global optimization problems definitions 25 numerical results 4 5 10 23 set test problems studied hansens book descriptions 7 additional test results 10 23 cases slight alterations found problem definitions expression search region first published versions chosen test program related input files found ftpjateuszegedhu per anonymous ftp directory pubmathoptimizationarticle since original schwefel 37 problem easy solve multiplied original objective function 10 4 change interpreted solving original problem problems completed three new ones first one called ex1 defined section 2 ex2 simplified real life parameter estimation problem 8 18 f 6 initial interval 00 10 2 theta 11 13 theta 00 10 2 ex3 hard global optimization problem stochastic algorithms 4 otherwise initial box ex3 gamma20 20 4 41 numerical test results test problems solved problem names tables reflect first definitions si stands shekeli hi hartman gp goldsteinprice shcb six hump camel back rcos branin rcos rb rosenbrock thcb three hump camel back li levi scij schwefel ij tables 1 4 contain efficiency measures provided solving test problems second column contains dimension problem efficiency measures obtained rules b c also expressed percentages respective figure rule last lines computational effort shown necessary solve whole set test problems solve subset 6 problems significant complexity denoted sig latter subset problems h6 gp l3 l5 sc12 required 99 computational burden percentages lines show much effort needed actual rule compared value rule 932 csendes ratz anticipated ratio improvement smaller 100 solving large set problems similar studied one average percentages aop reflects relative computational burden one expect single problem given rule used instead rule according statistical information provided set test problems table 1 contains cpu time values required test problems four direction selection rules standard time unit stu 1000 evaluations non interval shekel5 function used workstation 00036 sec large cpu times measured stu part due interval implementation cf 14 overhead list manipulation cpu values general proportional number objective function nfe derivative evaluations nde exceptions cases high memory complexity according cpu times rules b c better choices rules basis numerical study made expect 7 6 improvements respectively computation time use rule b c instead rule rule causes ninefold increase completing large set problems similar test problems rule b needs 90 less rule c 91 less rule eleven times cpu time subset hard test problems similar tendencies seen larger differences individual problems bigger cpu time values new rules table 1 basically due larger number objective function derivative evaluations table 2 shows number objective function evaluations necessary solve test problems practical applications measure together number derivative evaluations important required cpu time computation involved functions usually longer test problems see eg 15 22 according test results 7 improvement expected rules b c applied instead rule rule causes 102 higher number function evaluations sum numbers function evaluations also derivatives must interpreted care complexities test problems different similar set problems solved anticipated improvements high 72 rule b 74 rule c rule means five times function evaluations case subset hard test problems changes gamma30 gamma31 644 single problem gamma72 gamma74 426 similar set problems table 3 gives number partial derivative evaluations mentioned earlier inclusions gradients calculated componentwise ie nfe multiplied dimension problem upper bound nde remarkable stability nden nfe values 80 99 even lie 85 95 exception problem schwefel nr 12 ratio 55 63 much larger differences used direction selection rules usual monotonicity test deletes subintervals objective function proves monotonous thus ratio subintervals compared total number generated subintervals cannot high explanation relative stability nden nfe values since number derivative evaluations less n deleted subintervals according test results 7 improvement expected rules b c applied instead rule rule causes 98 derivative evaluations subdivision direction selection interval methods global optimization 933 similar set problems solved anticipated improvements high 75 rule b 77 rule c rule means three times derivative evaluations case subset hard test problems respective changes gamma28 gamma30 619 single problem gamma75 gamma77 221 similar set problems table 4 provides minimal list lengths necessary solve test problems given direction selection rules joint space complexity whole set test problems characterized maximal value rule since results identical subset hard problems line skipped according test results list length 68 714 enough solve set test problems rule list lengths rules 13 898 12 855 486 382 respectively mean gamma80 gamma81 608 differences average list length required 2 062 rule 640 rule b gamma69 616 rule c gamma70 15 645 rule 659 average percentages respectively differences performance hard problems similar average list length 13 278 rule 4 038 rule 765 average percentages hard problems 93 95 954 respectively two dominant behaviors recognized mainly tables 2 3 also smaller extent tables 1 4 half test problems differences caused changing subdivision direction selection rules moderate smaller subset test problems rule b especially rule c provide much efficient solution rule rule worst sense effects described previous paragraphs even stronger second subset problems remaining test problems 10 show various patterns 42 statistical evaluation used nonparametric wilcoxon signed rank test study effects algorithmic changes efficiency measures cpu time number objective function derivative evaluations space complexity normality test failed group data columns b c tables changes required cpu time occurred substitution rule rules b c respectively greater would expected chance statistically significant changes 0012 differences pairs eg rule b vs rule c significant substitutions rule cause significant changes cpu times regarding number objective function evaluations change due padding rule b rule c significant others significant substitutions provide significant differences number derivative evaluations p value nonsignificant case rules b c 0587 words transition inside pair rule b rule c causes significant difference nfe nde values transition pairs provides significant change subdivision rule substitution caused significant difference memory complexity statistical study repeated smaller data set harder problems cases statistically significant differences could found ones rules b rules c terms number objective function evaluations 934 csendes ratz 5 summary conclusions compared stochastic methods interval methods global optimization able provide guarantied reliability solutions cost sometimes substantially higher computational space complexity present study aimed investigate possibilities improve efficiency keeping reliability property interval subdivision rules balanced defined ensures convergence studied model algorithm lim s1 wy lim s1 f showed opposite direction also true trivial exceptions proved rules balanced thus related interval global optimization algorithms convergent senses problems rules b c fulfil requirements balancedness yet algorithms converge also cases global minimum result sets positive width intervals points global minimizers summarizing numerical experiences conclude rules b c certain cases also rule may successful alternatives rule according test results rule c definitely best choice direction selection rule closely followed rule b poor overall performance achieved rule part due fact huge differences magnitudes variables set test problems neither initial intervals global minimizer point coordinates early recognition problem type one save substantial amount computational effort using one latter rules problems application new rule result dramatic improvements efficiency measures even make possible solve problem due decreased memory complexity important features discussed algorithmic improvements must highlighted require additional information problems provide improvements wide problem class r introduction interval computations convergence two branchandbound algorithms nonconvex programming problems combining real interval methods global optimization nonlinear parameter estimation global optimization efficiency reliability impact accelerating tools interval subdivision algorithm global optimization numerical toolbox verified computing global optimization using interval analysis modeling lowfrequency pulmonary impedance dogs new lpbound multivariate lipschitz optimiza tion application unconstrained linearly constrained problems systems inequalities global minimization method multidimensional case lipschitzian optimization without lipschitz constant fortran90 environment research prototyping enclosure algorithms constrained unconstrained nonlinear equations interval step control continuation methods methodologies tolerance intervals interval analysis interval methods systems equations adamicza extended univariate algorithms ndimensional global optimization new computer methods global optimization automatische ergebnisverifikation bei globalen optimierungsproblemen computation rational interval functions tr ctr allgower melissa erdmann kurt georg complexity exclusion algorithms optimization journal complexity v18 n2 p573588 june 2002 l g casado j martnez garca experiments new selection criterion fast interval optimization algorithm journal global optimization v19 n3 p247264 march 2001 boglrka tth leocadio g casado multidimensional pruning baumann point interval global optimization algorithm journal global optimization v38 n2 p215236 june 2007 ibraheem alolyan new exclusion test finding global minimum journal computational applied mathematics v200 n2 p491502 march 2007 tibor csendes new subinterval selection criteria interval global optimization journal global optimization v19 n3 p307327 march 2001 p v nataray k kotecha algorithm global optimization using taylorbernstein form inclusion function journal global optimization v24 n4 p417436 december 2002 p nataraj k kotecha improved interval global optimization algorithm using higherorder inclusion function forms journal global optimization v32 n1 p3563 may 2005 u garciapalomares f j gonzalezcastao j c burguillorial combined global local search cgls approach global optimization journal global optimization v34 n3 p409426 march 2006 waltraud huyer arnold neumaier global optimization multilevel coordinate search journal global optimization v14 n4 p331355 june 1999 mihly csaba markt tibor csendes andrs erik csallner multisection interval branchandbound methods global optimization ii numerical tests journal global optimization v16 n3 p219228 march 2000 jos fernndez blas pelegrn using interval analysis solving planar singlefacility location problems new discarding tests journal global optimization v19 n1 p6181 january 2001 tams vink jeanlouis lagouanelle tibor csendes new inclusion function optimization kitemdashlthe one dimensional case journal global optimization v30 n4 p435456 december 2004 ingo eble markus neher acetaf software package computing validated bounds taylor coefficients analytic functions acm transactions mathematical software toms v29 n3 p263286 september chandra sekhar pedamallu linet zdamar tibor csendes symbolic interval inference approach subdivision direction selection interval partitioning algorithms journal global optimization v37 n2 p177194 february 2007 stefan ratschan search heuristics box decomposition methods journal global optimization v24 n1 p3549 september 2002 andrs erik csallner tibor csendes mihly csaba markt multisection interval branchandbound methods global optimization theoretical results journal global optimization v16 n4 p371392 april 2000 stefan ratschan efficient solving quantified inequality constraints real numbers acm transactions computational logic tocl v7 n4 p723748 october 2006