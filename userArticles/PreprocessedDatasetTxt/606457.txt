computing iceberg concept lattices titanic introduce notion iceberg concept lattices show use knowledge discovery databases iceberg lattices conceptual clustering method well suited analyzing large databases also serve condensed representation frequent itemsets starting point computing bases association rules visualization method association rules iceberg concept lattices based theory formal concept analysis mathematical theory applications data analysis information retrieval knowledge discovery present new algorithm called titanic computing iceberg concept lattices based data mining techniques levelwise approach fact titanic used general problem computing arbitrary closure systems closure operator comes along socalled weight function use weight functions computing closure systems discussed literature applications providing weight function include association rule mining functional dependencies databases conceptual clustering ontology engineering algorithm experimentally evaluated compared ganters nextclosure algorithm evaluation shows important gain efficiency especially weakly correlated data b introduction since introduction association rule mining 1 become one core data mining tasks attracted tremendous interest among data mining researchers practitioners elegantly simple problem statement find set subsets items called itemsets frequently occur many database records transactions extract rules telling us subset items influences presence another subset prototypical application associations market basket analysis items represent products records pointofsales data large grocery departmental stores kinds database generally sparse ie longest frequent itemsets relatively short however many reallife datasets dense ie contain long frequent itemsets widely recognized set association rules rapidly grow unwieldy especially lower frequency requirements larger set frequent itemsets number rules presented user many redundant true even sparse datasets dense datasets simply feasible mine possible frequent itemsets let alone generate rules itemsets datasets one typically finds exponential number frequent itemsets example finding long itemsets length 40 uncommon 2 paper show necessary mine frequent itemsets guarantee nonredundant association rules found show sufficient consider closed frequent itemsets defined later nonredundant rules found considering rules among closed frequent itemsets set closed frequent itemsets lot smaller set frequent itemsets cases 3 orders magnitude thus even dense domains guarantee completeness ie nonredundant association rules found main computation intensive step process identify closed frequent itemsets possible generate set using apriorilike 1 bottomup search methods examine subsets frequent itemset neither possible mine sets using algorithms mining maximal frequent patterns like maxminer 2 pincersearch 9 since find closed itemsets subsets maximal frequent itemsets would examined introduce charm efficient algorithm enumerating set closed frequent itemsets charm unique simultaneously explores itemset space transaction space unlike previous association mining methods exploit itemset search space furthermore charm avoids enumerating possible subsets closed itemset enumerating closed frequent sets exploration itemset transaction space allows charm use novel search method skips many levels quickly identify closed frequent itemsets instead enumerate many nonclosed subsets charm uses twopronged pruning strategy prunes candidates based subset infrequency ie extensions infrequent tested association mining methods also prunes candidates based nonclosure property ie nonclosed itemset pruned finally charm uses internal data structures like hashtrees 1 tries 3 fundamental operation used union two itemsets intersection two transactions lists itemsets contained extensive set experiments confirms charm provides orders magnitude improvement existing methods mining closed itemsets even methods like aclose 14 specifically designed mine closed itemsets makes lot fewer database scans longest closed frequent set found scales linearly number transactions also also linear number closed itemsets found rest paper organized follows section 2 describes association mining task section 3 describes benefits mining closed itemsets rules among present charm section 4 related work discussed section 5 present experiments section 6 conclusions section 7 association rules association mining task stated follows let f1 2 mg set items let ng set transaction identifiers tids input database binary relation item occurs transaction write 2 alternately typically database arranged set transaction transaction contains set items example consider database shown figure 1 used running example throughout paper fa c dt wg 6g second transaction represented fc2 d2 w 2g pairs transactions taken together form binary relation set x also called itemset set called tidset convenience write itemset c wg acw tidset f2 4 5g 245 support itemset x denoted x number transactions occurs subset itemset frequent support equal userspecified minimum support minsup value ie x minsup association rule expression x 1 itemsets x 1 support rule given ie joint probability transaction containing x 1 x 2 confidence ie conditional probability transaction contains x 2 given contains rule frequent itemset rule confident confidence greater equal userspecified minimum confidence minconf value ie p minconf association rule mining task consists two steps 1 1 find frequent itemsets 2 generate high confidence rules finding frequent itemsets step computationally io intensive consider figure 1 shows bookstore database six customers buy books different authors shows frequent itemsets cdw maximalbyinclusion frequent itemsets ie subset frequent itemset number items search space enumeration frequent itemsets 2 exponential one prove problem finding frequent set certain size npcomplete reducing balanced bipartite clique problem known npcomplete 8 18 however assume bound transaction length task finding frequent itemsets essentially linear database size since overall complexity case given n 2 l number transactions l length longest frequent itemset r number maximal frequent itemsets c w c w c w c w c w c w541 frequent itemsets w cw ac aw cd ct acw 100 50 3 dw tw act atw itemsets support ctw cdw actw items transcation jane austen agatha christie sir arthur conan doyle p g wodehouse mark twain figure 1 generating frequent itemsets generating confident rules step relatively straightforward rules form x 0 p generated frequent itemsets x minconf itemset size k potentially confident rules generated follows fact must consider subset itemset antecedent except empty full itemset complexity rule generation step thus os 2 l number frequent itemsets l longest frequent itemset note 2 l r number maximal frequent itemsets example frequent itemset acw generate 6 possible rules support 4 10 c cw 08 3 closed frequent itemsets section develop concept closed frequent itemsets show set necessary sufficient capture information frequent itemsets smaller cardinality set frequent itemsets 31 partial order lattices first introduce lattice theory concepts see 4 good introduction let p set partial order p binary relation x relation 1 reflexive x x 2 antisymmetric x x implies x z set p relation called ordered set denoted pair p write x x x 6 ordered set let subset p element u 2 p upper bound u lower bound l 2 least upper bound called join denoted greatest lower bound called meet denoted also write x join x meet ordered set l lattice two elements x l join x exist l complete lattice exist l finite lattice complete l called join semilattice join exists l called meet semilattice meet exists let p denote power set ie set subsets ordered set ps complete lattice meet given set intersection join given set union example partial orders pi set possible itemsets pt set possible tidsets complete lattices set frequent itemsets hand meetsemilattice example consider figure 2 shows semilattice frequent itemsets found example database figure 1 two itemsets meet guaranteed frequent join may may frequent follows ac aw cd ct cw dw tw acw act actw x 2456 figure 2 meet semilattice frequent itemsets well known principle association mining itemset frequent subsets also frequent example frequent join ac acdw frequent 32 closed itemsets let binary relation input database association mining let x mappings define galois connection partial orders pi pt power sets respec tively denote x tx pair x tx iy figure 3 illustrates two mappings mapping tx set transactions tidset contain itemset x similarly iy itemset contained transactions example tacw terms individual elements x2x tx iy y2y iy example galois connection satisfies following properties xx 1 example 245 2456 let set function c ps 7 ps closure operator xy c satisfies following properties subset x called closed let c x denote composition two mappings dually let c ti closure operators itemsets tidsets respectively define closed itemset itemset x closure ie x example itemset acw closed closed tidset tidset example tidset 1345 closed mappings c c ti closure operators satisfy three properties extension monotonicity idempotency also call application roundtrip figure 4 illustrates roundtrip starting itemset x example let extension property says x subset closure since c conclude ac closed hand idempotency property say map itemset tidset contains transactions items figure 3 galois connection items transactions figure 4 closure operator roundtrip map tidset back set items common tids tidset obtain closed itemset matter many roundtrips make cannot extend closed itemset example one roundtrip ac obtain closed itemset acw perform another roundtrip acw get c acw closed itemset x exists closed tidset given property conversely closed tidset exists closed itemset see x closed fact plugging thus x closed dually closed example seen closed itemset acw associated closed tidset 1345 closed itemset closed tidset pair x called concept figure 5 galois lattice concepts figure frequent concepts concept x 1 1 subconcept x 2 2 denoted let b denote set possible concepts database ordered set b complete lattice called galois lattice example figure 5 shows galois lattice example database total concepts least element concept c 123456 greatest element concept acdtw 5 notice mappings closed pairs itemsets tidsets antiisomorphic ie concepts large cardinality itemsets small tidsets vice versa 33 closed frequent itemsets vs frequent itemsets begin section defining join meet operation concept lattice see 5 formal proof set concepts database relation given b complete lattice join meet given join meet multiple concepts simply take unions joins example consider join two concepts acdw 45 cdt hand meet given acdw similarly perform multiple concept joins meets example ct 1356 define support closed itemset x concept x cardinality closed tidset closed itemset concept frequent support least minsup figure 6 shows frequent concepts tidset cardinality least 3 frequent concepts like frequent itemsets form meetsemilattice meet guaranteed exist join may theorem 1 itemset x support equal support closure ie proof support itemset x number transactions appears exactly cardinality tidset tx ie xj prove lemma show since c ti closure operator satisfies extension property ie tx c ti thus tx tc x hand since c also closure operator x c x turn implies due property 1 galois connections thus lemma states frequent itemsets uniquely determined frequent closed itemsets frequent concepts furthermore set frequent closed itemsets bounded set frequent itemsets typically much smaller especially dense datasets orders magnitude differences illustrate benefits closed itemset mining contrast figure 2 showing set frequent itemsets figure 6 showing set closed frequent itemsets concepts see 7 closed frequent itemsets 19 frequent itemsets example clearly illustrates benefits mining closed frequent itemsets 34 rule generation recall association rule form x 1 support equals confidence given j interested finding high support least minsup high confidence rules least minconf widely recognized set association rules rapidly grow unwieldy larger set frequent itemsets number rules presented user however show necessary mine rules frequent itemsets since rules turn redundant fact sufficient consider rules among closed frequent itemsets concepts stated theorem theorem 2 rule x 1 equivalent rule c x 1 proof follows immediately fact support itemset x equal support closure c x ie x using fact show typically many worst case exponential number frequent itemsets map closed frequent itemset lets assume n itemsets given set 1 whose closure c 1 itemsets given set 2 whose closure c 2 say n 1 rules two nonclosed itemsets directed 1 2 redundant equivalent rule c 1 n 1 rules directed 2 1 also redundant equivalent rule c 2 example looking figure 2 find itemsets cd map closed itemset cd itemsets w cw map closed itemset cw considering rules former latter set find rules 34 cd 34 equivalent rule closed itemsets cd 34 cw hand consider rules latter set former find w 35 equivalent rule cw 56 cd present user general rules rules specific contain one additional items antecedent consequent direction ie rules 34 w w 35 06 thus using closed frequent itemsets would generate 2 rules instead 8 rules normally generated two sets get idea number redundant rules mined traditional association mining one dataset mushroom 10 minimum support found 574513 frequent itemsets closed reduction 100 times 4 charm algorithm design implementation developed main ideas behind closed association rule mining present charm efficient algorithm mining closed frequent itemsets first describe algorithm general terms independent implementation details show algorithm implemented efficiently separation design implementation aids comprehension allows possibility multiple implementations charm unique simultaneously explores itemset space tidset space unlike previous association mining methods exploit itemset space furthermore charm avoids enumerating possible subsets closed itemset enumerating closed frequent sets rules pure bottomup search property important mining dense domains long frequent itemsets bottomup approaches practical example longest frequent itemset l bottomup search enumerates 2 l frequent subsets exploration itemset tidset space allows charm use novel search method skips many levels quickly identify closed frequent itemsets instead enumerate many nonclosed subsets charm uses twopronged pruning strategy prunes candidates based subset infrequency ie extensions infrequent itemset tested association mining methods also prunes branches based nonclosure property ie nonclosed itemset pruned finally charm uses internal data structures like hashtrees 1 tries 3 fundamental operation used union two itemsets intersection tidsets acdt acdtw cd ac acd ct act cdw ad aw cw acw adt adw atw actw acdw figure 7 complete subset lattice consider figure 7 shows complete subset lattice main parent link shown reduce clutter five items example database see figure 1 idea charm process lattice node test children frequent infrequent well nonclosed branches pruned notice children node formed combining node siblings come branch ordering example combined siblings c dt w produce children acadat aw sibling need considered already pruned infrequency nonclosure lexical ordering branches shown figure see later different branch ordering based support improve performance charm similar observation made maxminer 2 many search schemes possible eg breadthfirst depthfirst bestfirst hybrid search charm performs depthfirst search subset lattice 41 charm algorithm design section assume itemset x access tidset tx tidset access itemset iy practically generate tx iy discussed implementation section charm actually enumerates frequent concepts input database recall concept given closed itemset tx closed tidset start search concepts tidset space itemset space however typically number items lot smaller number transactions since ultimately interested closed itemsets start search single items associated tidsets u u items transactions items transactions items transactions items transactions figure 8 basic properties itemsets tidsets 411 basic properties itemsettidset pairs onetoone mapping itemsets integers two itemsets x 1 x 2 say defines total order set itemsets example f denotes lexicographic ordering itemset ac ad another example f sorts itemsets increasing order support ad ac support ad less support ac lets assume processing branch x 1 tx 1 want combine sibling x 2 tx 2 x 1 x 2 suitable total order f main computation charm relies following properties 1 tx 1 thus simply replace every occurrence x 1 consideration since closure identical closure words treat composite itemset 2 tx 1 replace every occurrence x 1 occurs transaction x 2 always occurs since tx 1 generates different closure 3 tx 1 replace every occurrence x 2 produces different closure must retained 4 case nothing eliminated x 1 x 2 lead different closures figure 8 pictorially depicts four cases see closed tidsets retained combine two itemset tidset pairs example two tidsets equal one pruned property 1 one tidset subset another resulting tidset equal smaller tidset parent eliminate parent properties 2 3 finally tidsets unequal two intersection closed example formally presenting algorithm show four basic properties itemsettidset pairs exploited charm mine closed frequent itemsets x 1345 figure 9 charm lexicographic order x 1345 figure 10 charmsorted increasing support consider figure 9 initially five branches corresponding five items tidsets example database recall used generate children item pair 1345 need combine siblings come combine two pairs resulting pair given words need perform intersection corresponding tidsets whenever combine two itemsets try extend c find property 2 true ie tc thus remove replace ac combining produces infrequent set acd pruned combination produces pair act 135 property 4 holds nothing pruned try combine w find ta tw according property 2 replace unpruned occurrences aw thus ac becomes acw act becomes actw point nothing processed branch root start processing c branch combine c observe property 3 holds ie tc td means wherever occurs c always occurs thus removed consideration entire branch pruned child cd replaces exactly scenario occurs w branches pruned replaced ct cw children c continuing depthfirst manner next process node cd combining ct produces infrequent itemset cdt pruned combination cw produces cdw since property 4 holds nothing removed similarly combination ct cw produces ctw point branches processed finally remove ctw 135 since contained actw 135 see 10 steps identified 7 closed frequent itemsets 412 charm pseudocode description illustrated workings charm example database present pseudocode algorithm algorithm starts initializing set nodes examined frequent single items tidsets line 1 main computation performed charmextend returns set closed frequent itemsets c charmextend responsible testing branch viability extracts itemsettidset pair current node set nodes x tx line 3 combines pairs come x j tx j line 5 according total order f already seen example lexical ordering figure 9 look support based ordering combination two itemsettidset pairs computed line 6 routine charmproperty tests resulting set required support also applies four properties discussed note routine may modify current node set deleting itemsettidset pairs already contained pairs also inserts newly generated children frequent pairs set new nodes newn set nonempty recursively process depthfirst manner line 8 insert possibly extended itemset x x set closed itemsets since cannot processed stage closed itemset containing x already generated return line 3 process next unpruned branch routine charmproperty simply tests new pair frequent discarding tests four basic properties itemsettidset pairs extending existing itemsets removing subsumed branches current set nodes inserting new pairs node set next depthfirst step charm minsup 1 2 charmextend nodes c charmextend nodes c 3 x tx nodes 4 5 x j tx j nodes fj fi 7 charmpropertynodes newn 8 newn 9 subsumed charmproperty nodes newn 10 jyj minsup 11 tx 12 remove x j nodes 13 replace x x 14 else 15 replace x x 16 else 17 remove x j nodes 18 add xy newn 19 else 20 add xy newn figure 11 charm algorithm 413 branch reordering purposely let itemsettidset pair ordering function line 5 remain unspecified usual manner processing lexicographic order specify total order want promising approach sort itemsets based support motivation increase opportunity nonclosure based pruning itemsets quick look properties 1 2 tells us two situations preferred two cases property 1 closure two itemsets equal thus discard x j replace x property 2 still replace x note cases insert anything new nodes thus occurrence case 1 2 fewer levels search perform contrast occurrence cases 3 4 results additions set new nodes requiring additional levels processing note reordering applied new node set starting initial branches since want tx sort itemsets increasing order support thus larger tidsets occur later ordering maximize occurrence properties 1 2 similar reasoning sorting decreasing order support doesnt work well since maximizes occurrence properties 3 4 increasing number levels processing example figure 10 shows charm works example database sort itemsets increasing order support use pseudocode illustrate computation initialize nodes fa 1345 2456 line 1 line 3 first process branch 1345 set line 4 combined remaining siblings line 5 ad frequent pruned next look since ta 6 tt simply insert newn next find ta tw thus replace occurrences aw thus means also change newn atw looking c find ta tc thus aw becomes acw newn becomes actw point charmextend invoked nonempty newn line 8 since one element immediately exit adding actw 135 set closed frequent itemsets c line 9 return branch completely processed add c branches examined turn final c produced shown figure 10 one final note pair ctw 135 produced branch closed since subsumed actw 135 eliminated line 9 42 charm implementation details describe implementation details charm departs pseudocode instances performance reasons data format given manipulating itemsettidset pairs fundamental operation intersecting two tidsets charm uses vertical data format maintain diskbased list item listing tids item occurs words data organized available disk tidset item contrast current association algorithms 1 2 3 assume horizontal database layout consisting list transactions transaction identifier followed list items transaction vertical format shown successful association mining used partition 16 maxeclat maxclique 19 shown lead good performance fact vertical algorithm 15 shown best approach better horizontal tightly integrating association mining database systems benefits using vertical format demonstrated monet 12 new highperformance database system queryintensive applications like olap data mining intersections subset testing given availability vertical tidsets itemset computation tidset intersection new combination straightforward takes linear scan two tidsets storing matching tids new tidset example main question efficiently compute subset information required applying four properties first might appear like expensive operation fact vertical format comes free intersecting two tidsets keep track number mismatches lists ie cases tid occurs one list let mx 1 mx 2 denote number mismatches tidsets itemsets four cases consider ta td see ta 6 td next consider shows ta tw thus charm performs support subset equality inequality testing simultaneously computing intersection eliminating nonclosed itemsets describe fast method avoid adding nonclosed itemsets set closed frequent itemsets c line 9 adding set x make sure doesnt exist set c x c support maxminer 2 faces similar problem eliminating nonmaximal itemsets clearly want avoid comparing x existing elements c would lead ojcj 2 complexity solution store c hash table hash function use since want perform subset checking cant hash itemset could use support itemsets hash function many unrelated subsets may support charm uses sum tids tidset hash function ie reduces chances unrelated itemsets cell hash table cell linked list sorted support primary key itemset secondary key ie lexical adding x c hash cell check x subset itemsets support x found experimentally approach adds seconds additional processing time total execution time optimized initialization one significant departure pseudocode figure 11 note initialize nodes set line 1 frequent items invoke charmextend worst case might perform nn 12 tidset intersections n number frequent items l average tidset size bytes amount data read l n n 12 bytes contrast horizontal approach reads l n bytes well known many itemsets length 2 turn infrequent thus clearly wasteful perform solve performance problem first compute set frequent itemsets length 2 add simple check line 5 combine two items j j known frequent number intersections performed check equal number frequent pairs practice closer rather 2 check done initially single items later stages describe compute frequent itemsets length 2 using vertical format noted clearly cannot perform intersections pairs frequent items solution perform vertical horizontal transformation onthefly item scan tidset memory insert item array indexed tid 2 ti example consider tidset item given read first tid insert array index 1 also insert indices 3 4 5 repeat process items tidsets figure 12 shows inversion process works addition item complete horizontal database recovered vertical tidsets item given recovered horizontal database straightforward update count pairs items using upper triangular 2d array add c add add w add add a246246246 figure 12 verticaltohorizontal database recovery memory management initialization charm scans database compute frequent pairs items note finding frequent items virtually free vertical format calculate support directly index array stores tidset offsets item index available computing frequent items take additional scan processing initial branch search lattice needs scan single item tidsets disk unpruned sibling charm fully scalable largescale database mining implements appropriate memory management phases described next example recovering horizontal database entire database clearly fit memory charm handles recovering block transactions one time fit memory support item pairs updated incrementally processing recovered block note regardless number blocks process requires exactly one database scan vertical format imagine k pointers k tidsets pointer moves forward tid points belongs current block number closed itemsets becomes large cannot hope keep set closed itemsets c memory case elimination nonclosed itemsets done offline postprocessing step instead inserting x c line 9 simply write disk along support hash value postprocessing step read close itemsets apply hash table searching approach described eliminate nonclosed itemsets since charm processes branch search depthfirst fashion memory requirements substantial retain itemsettidsets pairs levels current leftmost branches search space consider 7 example initially retain tidsets facadat awg facdact acwg facdtwg ac processed memory requirement shrinks fadat fadtwg case worst possible situation practice applications subset infrequency nonclosure properties 1 2 3 prune many branches search lattice cases even memory requirement depthfirst search exceed available memory straightforward modify charm write temporary tidsets disk example processing ac branch might write tidsets fadat awg disk another option simply recompute intersections writing temporary results expensive 43 correctness efficiency theorem 3 correctness charm algorithm enumerates closed frequent itemsets proof charm correctly identifies closed frequent itemsets since search based complete subset lattice search branches pruned either sufficient support result nonclosure based properties itemsettidset pairs outlined beginning section finally charm eliminates cases nonclosed itemsets might generated performing subsumption checking inserting anything set closed frequent itemsets c theorem 4 computational cost running time charm ol jcj l average tidset length c set closed frequent itemsets proof note starting single items associated tidsets process branch following cases might occur let x c denote current branch x sibling trying combine prune x branch tx c 1 extend x c become finally new node generated get new possibly closed set due properties 3 4 also note new node fact represents closed tidset thus indirectly represents closed itemset since exists unique closed itemset closed tidset thus charm performs order ojcj intersections confirm via experiments section 6 extra intersections performed due case charm may produce nonclosed itemsets like ctw 135 eliminated line 9 tidset average length l intersection costs 2 l total running time charm thus 2 l jcj ol jcj theorem 5 io cost number database scans made charm given jcj set closed frequent itemsets set items fraction database fits memory proof number database scans required given total memory consumption algorithm divided fraction database fit memory since charm computes order ojcj intersections total memory requirement charm ol jcj l average length tidset note perform intersections size longer itemsets tidsets shrinks rapidly ignore effects analysis thus pessimistic bound total database size l jij fraction fits memory given l jij number data scans given l jcj l note worst case jcj exponential jij rarely case practice show experiments section charm makes database scans compared longest closed frequent itemset found 5 related work number algorithms mining frequent itemsets 1 2 3 9 10 13 16 19 proposed past apriori 1 first efficient scalable method mining associations starts counting frequent items subsequent pass extends current set frequent itemsets one item frequent itemsets found since uses pure bottomup search subset lattice see figure 7 generates 2 l subsets frequent itemset length l methods including dhp 13 partition 16 ascpa 10 dic 3 propose enhancements apriori terms number candidates counted number data scans still generate subsets frequent itemset simply feasible except high support kinds dense datasets examine paper use apriori representative class methods experiments methods finding maximal frequent itemsets include allmfs 8 randomized algorithm guaranteed complete pincersearch 9 constructs candidates bottomup manner like apriori also starts topdown search time previous algorithms maxeclat maxclique 19 17 range generate frequent itemsets generate long frequent itemsets subsets maxminer 2 another algorithm finding maximal elements uses novel superset frequency pruning support lowerbounding techniques quickly narrow search space since methods mine maximal frequent itemsets cannot used generate possible association rules requires support subsets traditional approach try compute support subsets maximal frequent itemsets run problem generating 2 l subsets itemset length l dense datasets impractical using maxminer representative class algorithms show modifying compute closed itemsets renders infeasible except high supports cd ct ad ac find generators compute figure 13 aclose algorithm example aclose 14 apriorilike algorithm directly mines closed frequent itemsets two main steps aclose first use bottomup search identify generators smallest frequent itemsets determines closed itemset via closure operator c example example database c c generator acw generators found using simple modification apriori time new candidate set generated aclose computes support pruning infrequent ones remaining sets compares support frequent itemset subsets previous level support itemset matches support subsets itemset cannot generator thus pruned process repeated generators produced second step aclose compute closure generators found first step compute closure itemset perform intersection transactions occurs subset ie closure itemset x given c tid closures generators computed one database scan provided generators fit memory nevertheless computing closures way expensive operation figure 13 shows working aclose example database generating candidate pairs items determined ad dt frequent pruned remaining frequent pairs pruned support matches support subsets acaw pruned since support equal support cd pruned ct cw w pruning find candidates generated marking end first step second step aclose computes closure unpruned itemsets finally duplicate closures removed eg tw produce closure show aclose much better apriori uncompetitive charm number previous algorithms proposed generating galois lattice concepts 5 6 algorithms adapted enumerate frequent concepts studied small datasets finally problem generating basis minimal nonredundant rule set association rules discussed 18 algorithms given turn based theory developed 7 5 11 6 experimental evaluation chose several real synthetic datasets testing performance charm real datasets used maxminer 2 datasets except pums pumsb pumsb sets taken uc irvine machine learning database repository pums datasets contain census data pumsb pumsb without items 80 support mushroom database contains characteristics various species mushrooms finally connect chess datasets derived respective game steps typically real datasets dense ie produce many long frequent itemsets even high values support datasets publicly available ibm almaden wwwalmadenibmcomcsquestdemoshtml also chose synthetic datasets also available ibm almaden used benchmarks testing previous association mining algorithms datasets mimic transactions retailing environment usually synthetic datasets sparse compared real sets modified generator produce longer frequent itemsets avg record length records scaleup db size chess 76 37 3196 31960 connect 130 43 67557 675570 mushroom 120 23 8124 81240 pumsb 7117 50 49046 490460 pumsb 7117 74 49046 490460 table 1 database characteristics table also shows characteristics real synthetic datasets used evaluation shows number items average transaction length number transactions database also shows number records used scaleup experiments one see average transaction size databases much longer conventionally used previous literature experiments described performed 400mhz pentium pc 256mb memory running redhat linux 60 algorithms coded c 61 effect branch ordering figure 14 shows effect running time use various kinds branch orderings charm compare three ordering methods lexicographical order increasing support decreasing support observe decreasing order worst hand processing branch itemsets increasing order best factor 15 times better lexicographic order 2 times better decreasing order similar results obtained synthetic datasets results charm reported use increasing branch ordering since best time per closed sec minimum support chess decreasing lexicographic increasing481216955965975time per closed sec minimum support connect decreasing lexicographic increasing135715253545time per closed sec minimum support mushroom decreasing lexicographic increasing051525354555949698time per closed sec minimum support pumsb decreasing lexicographic time per closed sec minimum support pumsb decreasing lexicographic increasing figure 14 branch ordering100100001e06657585number elements minimum support chess frequent closed maximal10010000955965975number elements minimum support connect frequent closed maximal100100001e0615253545number elements minimum support mushroom frequent closed maximal101000949698number elements minimum support pumsb frequent closed maximal101000100000455565number elements minimum support pumsb frequent closed maximal figure 15 set cardinality481260708090 longest freq scans minimum support chess chesslf chessdbi chessdbl13579955965975longest freq scans minimum support connect connectlf connectdbi longest freq scans minimum support mushroom mushroomlf mushroomdbi mushroomdbl1357949698longest freq scans minimum support pumsb pumsblf pumsbdbi pumsbdbl261014455565longest freq scans minimum support pumsb pumsblf pumsbdbi pumsbdbl figure longest frequent itemset vs database scans biincreasing dbllexical order 11001000030507090total time sec minimum support chess aclose cmaxminer charm total time sec minimum support connect aclose cmaxminer charm total time sec minimum support mushroom aclose cmaxminer charm maxminer01101000758595total time sec minimum support pumsb aclose cmaxminer charm total time sec minimum support pumsb aclose cmaxminer charm maxminer1010000040812total time sec minimum support aclose cmaxminer charm maxminer1010000206114 total time sec minimum support aclose cmaxminer charm maxminer101000012total time sec minimum support aclose cmaxminer charm maxminer figure 17 charm versus apriori aclose cmaxminer maxminer 62 number frequent closed maximal itemsets figure 15 shows total number frequent closed maximal itemsets found various support values noted maximal frequent itemsets subset closed frequent itemsets maximal frequent itemsets must closed since definition cannot extended another item yield frequent itemset closed frequent itemsets course subset frequent itemsets depending support value used set maximal itemsets order magnitude smaller set closed itemsets turn order magnitude smaller set frequent itemsets even low support values find difference maximal closed remains around factor 10 however gap closed frequent itemsets grows rapidly example mushroom 10 support gap factor 100 558 maximal 4897 closed 574513 frequent itemsets 63 charm versus maxminer aclose apriori compare performance charm previous algorithms maxminer mines maximal frequent itemsets thus augmented adding postprocessing routine uses maximal frequent itemsets generate closed frequent itemsets essence generate subsets maximal itemsets eliminating itemset support equals subsets augmented algorithm called cmaxminer aclose method extant method directly mines closed frequent itemsets finally apriori mines frequent itemsets would require postprocessing step compute closed itemsets add cost running time figure 17 shows charm compares previous methods real synthetic databases find apriori cannot run except high values support even cases charm 2 3 orders magnitude better generating subsets frequent itemsets clearly takes much time aclose perform order magnitude better apriori low support values high support values fact worse apriori high support number frequent itemsets much closure computing step aclose dominates computation time like apriori aclose couldnt run low values support generator finding step finds many generators kept memory cmaxminer augmented version maxminer suffers similar fate generating subsets testing closure feasible strategy cmaxminer cannot run low supports cases run 1 2 orders magnitude slower charm maxminer able run values support charm handle except high support values charm better maxminer order magnitude faster charm typically factor 5 6 times better difference attributable fact set maximal frequent itemsets typically order magnitude smaller set closed frequent itemsets noted since maxminer mines maximal itemsets cannot used produce association rules fact attempt calculate subset frequency adds lot overhead saw case cmaxminer experiments demonstrate charm extremely effective efficiently mining closed frequent itemsets able gracefully handle low support values even dense datasets 64 scaling properties charm figure shows time taken charm per closed frequent itemset found support values ones used comparing charm methods lower support closed itemsets found time spent per element decreases indicating efficiency charm increases decreasing support figure 19 shows number tidset intersections performed per closed frequent itemset generated ideal case graph corresponds case perform exactly number intersections closed frequent itemsets ie ratio one find connect chess number intersections performed charm close ideal charm within factor 106 chess 26 mushroom times ideal confirms computational efficiency claims made charm indeed performs ojcj intersections figure shows number database scans made charm compared length longest closed frequent itemset found real datasets number database scans charm calculated taking sum lengths tidsets scanned disks dividing sum tidset lengths items database number reported pessimistic sense incremented sum even though may space memory may scanned tidset evicted memory effect particularly felt case reorder itemsets according increasing support case frequent itemset ends contributing sum multiple times even though tidset may already cached memory reason also show number database scans lexical ordering much lower sorted case even pessimistic estimates find charm makes lot fewer database scans longest frequent itemset using lexical ordering find example pumsb longest closed itemset length 13 charm makes 3 database scans00010100001 0001 time per closed sec closed frequent itemsets 10000s real datasets chess connect mushroom pumsb pumsb figure 18 time per closed frequent intersections per closed closed frequent itemsets 10000s real datasets ideal chess connect mushroom pumsb pumsb figure 19 intersections per closed total time sec number transactions 100000s synthetic datasets figure 20 size scaleup synthetic total time sec replication factor real datasets figure 21 size scaleup real datasets finally figures 20 21 show charm scales increasing number transactions synthetic datasets kept database parameters constant increased number transactions 100k 1600k find linear increase time real datasets replicated transactions 2 10 times find linear increase running time increasing number transactions conclusions paper presented evaluated charm efficient algorithm mining closed frequent itemsets large dense databases charm unique simultaneously explores itemset space tidset space unlike previous association mining methods exploit itemset space exploration itemset tidset space allows charm use novel search method skips many levels quickly identify closed frequent itemsets instead enumerate many nonclosed subsets extensive set experiments confirms charm provides orders magnitude improvement existing methods mining closed itemsets makes lot fewer database scans longest closed frequent set found scales linearly number transactions also also linear number closed itemsets found acknowledgement would like thank roberto bayardo providing us maxminer algorithm well real datasets used paper r fast discovery association rules efficiently mining long patterns databases dynamic itemset counting implication rules market basket data introduction lattices order formal concept analysis mathematical foundations incremental concept formation algorithms based galois concept lattices familles minimales dimplications informatives resultant dun tableau de donnees binaires discovering specific sentences randomized algorithms new algorithm discovering maximum frequent set mining association rules antiskew algorithms implications partielles dans un contexte effective hash based algorithm mining association rules discovering frequent closed itemsets association rules integrating association rule mining databases alternatives implications efficient algorithm mining association rules large databas es scalable algorithms association mining theoretical foundations association rules new algorithms fast discovery association rules tr algorithm insertion lattice application type classification mining association rules sets items large databases incremental concept formation approach learning databases approximate inference functional dependencies relations automatic class insertion overloading inference configuration structures source code efficiently mining long patterns databases reengineering class hierarchies using concept analysis design class hierarchies based concept galois lattices efficient mining association rules using closed itemset lattices fast algorithm building lattices mining frequent patterns counting inference levelwise search borders theories knowledge discovery automatic structuring knowledge bases conceptual clustering efficient discovery functional dependencies armstrong relations conceptual information systems discussed itsecurity tool discovering frequent closed itemsets association rules cem conceptual email manager conceptual knowledge discovery data analysis conceptual knowledge discovery databases using formal concept analysis methods fast algorithms mining association rules large databases merging inheritance hierarchies database integration io2 algorithmic method building inheritance graphs object database design towards object database approach managing concept lattices mining minimal nonredundant association rules using frequent closed itemsets toscana graphical tool analyzing exploring data intelligent structuring reducing association rules formal concept analysis mining ontologies text ctr jean diatta relation theory formal concepts multiway clustering pattern recognition letters v25 n10 p11831189 july 2004 alain casali rosine cicchetti lotfi lakhal extracting semantics data cubes using cube transversals closures proceedings ninth acm sigkdd international conference knowledge discovery data mining august 2427 2003 washington dc meiling shyu shuching chen min chen chengcui zhang unified framework image database clustering contentbased retrieval proceedings 2nd acm international workshop multimedia databases november 1313 2004 washington dc usa bradley j rhodes taxonomic knowledge structure discovery imagerybased data using neural associative incremental learning nail algorithm information fusion v8 n3 p295315 july 2007 ben yahia hamrouni e mephu nguifo frequent closed itemset based algorithms thorough structural analytical survey acm sigkdd explorations newsletter v8 n1 p93104 june 2006 xiaodong liu wei wang tianyou chai wanquan liu approaches representations logic operations fuzzy concepts framework axiomatic fuzzy set theory ii information sciences international journal v177 n4 p10271045 february 2007 gerd stumme new shores conceptual knowledge discovery processing international journal humancomputer studies v59 n3 p287325 september