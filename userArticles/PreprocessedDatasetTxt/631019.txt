infeasibility quantifying reliability lifecritical realtime software work affirms quantification lifecritical software reliability infeasible using statistical methods whether methods applied standard software faulttolerant software classical methods estimating reliability shown lead exorbitant amounts testing applied lifecritical software reliability growth models examined also shown incapable overcoming need excessive amounts testing key assumption software fault toleranceseparately programmed versions fail independentlyis shown problematic assumption cannot justified experimentation ultrareliability region subjective arguments favor sufficiently strong justify axiom also implications recent multiversion software experiments support affirmation b introduction potential enhanced flexibility functionality led ever increasing use digital computer systems control applications first digital systems designed perform functions analog counterparts however availability enormous computing power low cost led expanded use digital computers current applications introduction many new applications thus larger complex systems designed result promised increased performance minimal hardware cost however also resulted software systems contain errors sometimes impact software bug nothing inconvenience times software bug leads costly downtime impact design flaws software systems used lifecritical applications industrialplant control aircraft control nuclearreactor control nuclear warhead arming price software failure digital computers applied frequently lifecritical functions already symptoms using insufficiently reliable software lifecritical applications appearing 1 2 3 many years much research focused quantification software reliability research efforts started reliability growth models early 1970s recent years emphasis developing methods enable reliability quantification software used lifecritical functions emerged common approach offered combination software faulttolerance statistical models paper investigate software reliability problem two perspectives first explore problems arise test software black box ie subject inputs check outputs without examination internal structure examine problems arise software treated black box ie internal structure modeled either case argue associated problems intractableie inevitably lead need testing beyond practical lifecritical applications validation process must establish system reliability extremely high historically ultrahigh reliability requirement translated probability failure order 10 gamma7 10 gamma9 1 10 hour missions unfortunately probabilities create enormous problems validation convenience use following name failure rate per hour moderate reliability 10 gamma3 10 gamma7 low reliability software physically fail hardware physical failures opposed hardware design occur hardware wears breaks adversely affected environmental phenomena electromagnetic fields alpha particles software subject problems software faults present beginning throughout systems lifetime extent software reliability meaninglesssoftware either correct incorrect respect specification nevertheless software systems embedded stochastic environments environments subject software program sequence inputs time input program produces either correct incorrect answer thus systems context software system produces errors stochastic manner sequence errors behaves like stochastic point process paper inherent difficulty accurately modeling software reliability explored facilitate discussion construct simple model software failure process driver failure process external system supplies inputs program function inputs internal state program produces output software perfect internal state would correct outputs produced would correct however design flaw program manifest either production erroneous output corruption internal state may affect subsequent outputs realtime system software periodically scheduled ie program repeatedly executed response inputs unusual find iteration rates 10 100 cycles per second probability software failure per input constant say p binomial process number failures n n inputs given binomial distribution wish compute probability system failure n inputs system failure occurs converted function time transformation inputs per unit time system failure probability time p sys thus course calculation assumes probability failure per input constant time 1 binomial process accurately approximated exponential distribution since p small n large easily derived using poisson approximation binomial discrete binomial process thus accurately modeled continuous exponential process following discussion frequently use exponential process rather binomial process simplify discussion analyzing software black box traditional method validating reliability life testing life testing set test specimens operated actual operating conditions predetermined amount time period failure times recorded subsequently used reliability computation internal structure test specimens examined observable whether specimen failed systems designed attain probability failure order 10 gamma7 10 gamma9 1 hour missions longer life testing prohibitively impractical shown illustrative example simplicity assume time failure distribution exponential 2 using standard statistical methods 4 time test estimated specified system reliability two basic approaches 1 testing replacement 2 testing without replacement either case one places n items test test finished r failures observed first case device fails new device put test place second case failed device replaced tester chooses values n r obtain desired levels ff fi errors ie probability rejecting good system probability accepting bad system respectively general larger r n smaller statistical estimation errors expected time test calculated function r n expected time test replacement case r 1 probability failure per input constant reliability analysis problem even harder one would estimate pt rather p timevariant system would require even testing timeinvariant one since rate must determined function mission time system would placed random state corresponding specific mission time subjected random inputs would done time point interest within mission time thus reliability analysis intractable systems constant p unrealistic expect tractable systems nonconstant pt 2 previous section exponential process shown accurate approximation discrete binomial software failure process replicates n expected test duration table 1 expected test duration r1 mean failure time test specimen 4 expected time test nonreplacement case r even without specifying ff fi error good indication testing time determined clearly number observed failures r must greater 0 total number test specimens n must greater equal r example suppose system probability failure 10 gamma9 10 hour mission mean time failure system assuming exponentially distributed table 1 shows expected test duration system function number test replicates n 1 3 noted value r equal 1 produces shortest test time possible price extremely large ff fi errors get satisfactory statistical significance larger values r needed consequently even testing therefore given economics testing faulttolerant systems expensive rarely allow n greater 10 lifetesting clearly question ultrareliable systems technique statistical lifetesting discussed detail appendix 4 reliability growth models software design process involves repetitive cycle testing repairing program program subjected inputs fails cause failure determined program repaired subjected new sequence inputs result sequence programs sequence interfailure times usually measured number inputs goal construct mathematical technique ie model predict reliability final program p n based observed interfailure data model enables one estimate probability failure final corrected program without subjecting sequence inputs process form prediction extrapolation studied detail 5 6 7 models called reliability growth models one resists temptation correct program based last failure method equivalent blackbox testing final version one corrects final version estimates reliability corrected version based reliability growth model one hopefully increased efficiency testing process question would like examine much efficiency gained use reliability 3 expected time without replacement almost case growth model enough get us ultrareliable region unfortunately answer gain efficiency anywhere near enough get us ultrareliable region pointed several authors keiller miller write 8 reliability growth scenario would start faulty software execution software bugs discovered software modified correct design flaws represented bugs gradually software evolves state higher reliability least two general reasons unreasonable approach highlyreliable safetycritical software time required reliability grow acceptable levels tend extremely long extremely high levels reliability cannot guaranteed priori littlewood writes 9 clearly reliability growth techniques x2 survey leading reliability growth models useless face ultrahigh reliability requirements easy see even unlikely event system achieved reliability could assure achievement acceptable time problem alluded authors seen clearly applying reliability growth model experimental data data table 2 taken experiment performed nagel skrivan 10 data table obtained program a1 one six programs investigated number bugs removed failure probability per input table 2 nagel data program a1 versions represent successive stages program bugs removed loglinear growth model postulated found fit 6 programs analyzed report simple regression data table 2 yields slope yintercept gamma1415 02358 respectively line fitted log raw data shown figure 1 correlation coefficient 0913 important note context reliability growth models failure rates usually reported failure rates per input whereas system requirements given failure rates per hour probability failure specified mission duration eg 10 hours however equation 2 rearranged form used convert system requirements required failure rate per input kt system requirement probability failure 10 gamma9 10hour mission sample rate system ie k 10sec required failure rate per input p calculated number bugs removed figure 1 loglinear fit program a1 failure data follows kt 10sec3600 secshour10 hours purpose reliability growth model estimate failure rate program removal last discovered bug loglinear growth model plotted figure 1 used predict arrival rate next bug 634 theta 10 gamma5 key question course long take enough bugs removed reliability growth model predict failure rate per input 278 theta 10 gamma15 less using loglinear model find place probability drops 278 theta 10 gamma15 illustrated figure 2 based upon model 24th bug arrive rate 228 theta 10 gamma15 less goal thus according loglinear growth model 23 bugs removed model yield acceptable failure rate long take remove 23 bugs growth model predicts bug 23 failure rate 938 theta 10 gamma15 expected number test cases observing binomial event probability 938 theta 10 gamma15 107 theta 10 14 test time real time execution time test case would require 010 secs thus expected time discover bug 23 alone would 107 theta 10 13 secs 34 theta 10 5 years table 3 calculations given programs reference 10 4 examples illustrate use reliability growth model alleviate testing problem even one assumes model applies universally ultrareliable region table 5 assumes perfect fit loglinear model ultrareliable region number bugs removed figure 2 extrapolation predict ultrareliability reached program slope yintercept last bug test time a3 54526 13735 58 68 theta 10 5 years table 3 test time remove last bug obtain ultrareliability 41 low sample rate systems accelerated testing section feasibility quantifying lowsample rate systems ie systems time inputs long ultrareliable region briefly explored also potential accelerated testing discussed suppose testing rate faster real time let r test time per input since test independent trial time appearance next bug given geometric distribution thus expected number inputs next bug appears 1p expected test time given using equation 5 becomes rkt equation 6 seen low sample rate system ie system small k requires less test time high sample rate system assuming r remains constant suppose system requirement probability failure 10 gamma9 10 hour mission ie p system fast sample rate eg time required test input realtime execution time ie expected test time years suppose r remains constant k reduced note usually implies accelerated testing process execution time per input usually greater slow systems fast systems since r increased k decreased net result equivalent accelerated test process impact decreasing k holding r constant seen table 4 reports expected test time function k thus theoretically k expected test 1minute 19 theta 10 3 years 1hour 317 years 1day 132 years 1month table 4 expected test time function k slow system tested quickly ie much faster realtime quantified ultrareliable region however promising may look first value k fixed given system experimenter control example sample rate digital flight control system order 10 inputs per second faster little done slow thus theoretical result nothing alleviate testing problem furthermore real time systems typically developed exploit full capability computing system consequently although slower systems sample rate less execution time per input usually higher r much greater 010 secs used table 4 fact one would expect see r grow proportion 1k thus results table 4 optimistic also noted testing process one must also determine whether programs answer correct incorrect consequently test time per input often much greater realtime execution time rather shorter conclusion one fortunate enough slow system exploit accelerated testing process one obtain ultrareliable estimates reliability feasible amounts test times however systems usually classified realtime systems thus scope paper 42 reliability growth models accelerated testing lets revisit reliability growth model context slow system quickly tested suppose system test slow realtime system sample rate 1 input per minute failure rate per input must less 10 gamma9 gamma11 order program failure rate 10 gamma9 hour using regression results seen approximately 17 bugs must removed bug failure rate per input thus one could test 17 bugs removed remove last bug use reliability growth model predict failure rate per input 1106 theta 10 gamma11 long would take remove 17 bugs well removal last bug alone would average require approximately test cases even testing process 1000 times faster operational time per input ie would require 42 years testing thus see littlewood keiller miller see little hope using reliability growth models ultrareliable software problem restricted program universal table 5 repeats calculations rest programs reference 10 even optimistic program slope yintercept last bug test time a3 54526 13735 42 66 years table 5 test time remove last bug obtain ultrareliability improvement rates obvious reliability growth models impractical ultrareliable software 5 software fault tolerance since fault tolerance successfully used protect hardware physical failures seems natural apply strategy software bugs easy construct reliability model system designed mask physical failures using redundant hardware voting key assumption enables design ultrareliable systems less reliable components estimation 10 gamma9 probabilities failure separate redundant components fail independently nearly independence assumption used hardware fault tolerance modelling many years redundant components located separate chassis powered separate power supplies electrically isolated sufficiently shielded environment unreasonable assume failure independence physical hardware faults basic strategy software faulttolerance approach design several versions program specification employ voter kind protect system bugs voter acceptance test ie recovery blocks comparator ie nversion programming version programmed separate programming team 5 since versions developed separate programming teams hoped redundant programs fail independently nearly 11 12 version reliability estimates independence assumption system reliability estimates could calculated however unlike hardware physical failures governed laws physics programming errors products human reasoning ie actually improper reasoning question thus becomes one reasonableness assuming independence based little practical theoretical foundations subjective arguments offered sides question unfortunately subjective arguments multiple versions independent compelling enough qualify axiom reasons experimental justification independence infeasible ultrareliable quantification infeasible despite software fault tolerance discussed next section 51 models software fault tolerance many reliability models faulttolerant software developed based independence assumption accept model assumption must accepted section shown independence assumption enables quantification ultrareliable region quantification faulttolerant software reliability unlikely without independence assumption assumption cannot experimentally justified ultrareliable region 511 independence enables quantification ultrareliability following example show independence enables ultrareliability quantification suppose three different versions program control lifecritical system using software fault tolerance scheme let e ik event ith version fails kth execution suppose probability version fails kth execution p ik discussed section 2 assume failure rate constant since versions voted system fail unless coincident error ie two versions produce erroneous outputs response input probability two versions fail kth execution causing system failure using additive law probability written independence versions assumed rewritten 5 often separate programming teams called independent programming teams phrase independent programming mean thing independent manifestation errors reason independence usually assumed obvious formulaif p estimated approximately 10 gamma6 probability system failure due two coincident failures approximately 3 theta 10 gamma12 equation used calculate probability failure hour mission suppose probability system fails mission hours calculated using equation 1 number executions program hour small p following approximation accurate following typical values execution per second thus ultrareliability quantification made depended critically independence assumption different versions fail independently equation 7 must used compute failure probabilities calculation meaningless fact probability failure could anywhere 0 10 gamma2 ie 0 3pkt 6 512 ultrareliable quantification infeasible without independence consider impact able assume independence following argument adapted miller 13 simplify notation last subscript dropped referring kth execution thus using identity p rewritten rewrite formula reveals two components system failure probability 1 first line equation 11 2 last 4 lines equation 11 multiple versions manifest errors independently last four lines ie second component equal zero conse quently establish independence experimentally terms must shown 0 realistically establish adequate independence terms must shown negligible effect probability system failure thus first component represents noncorrelated contribution p sys second component represents correlated contribution p sys note terms first component p sys products individual version probabilities 6 3pkt firstorder approximation probability system fails whenever one 3 versions fail cannot assume independence back original equation 10 since p clearly p sys words order p sys ultrareliable region interaction terms ie p must also ultrareliable region establish system ultrareliable validation must either demonstrate terms small establish p sys small means could indirectly deduce terms small thus back original lifetesting problem discussion tempting conclude necessary demonstrate interaction terms small order establish p sys small however legitimate argument although interaction terms always small p sys small one cannot argue way establishing p sys small showing interaction terms small however likelihood establishing p sys small without directly establishing interaction terms small appears extremely remote follows observation without assumptions little done equation 10 seems inescapable matter 10 manipulated terms linearly unless form found terms eliminated altogether appear nonlinear form become negligible eg multiplied parameters need estimate directly remain furthermore information contained terms must appear somewhere dependency p sys formulation interaction cannot eliminated although possibility method may discovered validation software faulttolerance remains prudent recognize opportunity lies lie realm controlled experimentation hope reformulation equation 10 discovered enables estimation p sys set parameters estimated using moderate amounts testing efficacy reformulation could assessed analytically experimentation 513 danger extrapolation ultrareliability region see danger extrapolating feasible amount testing different versions independent consider possible scenarios coincident failure processes suppose probability failure single version 1 hour interval 10 gamma5 versions fail independently probability coincident error order 10 gamma10 however suppose actuality arrival rate coincident error 10 gamma7 hour one could test 100 years likely see coincident error experiments would tempting conclude different versions independent tested system 100 years seen even one coincident error make independence assumption system reliability actually system reliability approximately failure rate single version 10 gamma4 hour arrival rate coincident errors testing one year would likely result coincident errors erroneous assumption independence would allow assignment 3 theta 10 gamma8 probability failure system reality system better 10 gamma5 conclusion independence cannot assumed seems inescapable intersection events must directly measured shown occur system failure formula products alone thus must less 10 gamma12 per input order system probability failure less 10 gamma9 1 hour unfortunately testing level infeasible extrapolation feasible amounts testing dangerous since ultrareliability established requirement many systems great incentive create models enable estimate ultrareliable region thus many examples software reliability models operational ultrareliable systems given ramifications independence faulttolerant software reliability quantification unjustifiable assumptions must overlooked 52 feasibility general model coincident errors given limitations imposed nonindependence one possible approach ultrareliability quantification problem develop general faulttolerant software reliability model accounts coincident errors two possibilities exist 1 model includes terms cannot measured within feasible amounts time 2 model includes parameters measured within feasible amounts time possible construct elaborate probability models fall first class unfortunately since depend upon unmeasurable parameters useless quantification ultrareliability second case realistic approach 7 independence model example second case models belonging second case must explicitly implicitly express interaction terms equation 10 known functions parameters measured feasible amounts time known function f independence model zero function ie interaction terms p zero identically irrespective measurable parameters general model must provide mechanism makes interaction terms negligibly small order produce number ultrareliable region known functions must applicable cases multiversion software model intended clearly estimation based model would strongly dependent upon correct knowledge functions functions determined little hope deriving fundamental laws since error process occurs human mind possibility derive experimentation experimentation derive functions appropriate low moderate reliability software therefore correctness functions ultrareliable region established experimentally justifying correctness known functions requires far testing quantifying reliability single ultrareliable system model must shown applicable specified sample space multiversion programs thus must extensive sampling space multiversion programs must undergo lifetesting 100000 years order demonstrate universal applicability functions thus either case situation appears hopelessthe development credible coincident error model used estimate system reliability within feasible amounts time possible 7 first case included completeness models proposed past 53 coincidenterror experiments experiments performed several researchers investigate coincident error process first perhaps famous experiment performed knight leveson 14 experiment 27 versions program produced subjected 1000000 input cases observed average failure rate per input 00007 major conclusion experiment independence model rejected 99 confidence level quantity coincident errors much greater predicted independence model experiments produced researchers confirmed knightleveson conclusion 12 15 excellent discussion experimental results given 16 debate 16 occurred credibility experiments rather describe details debate would prefer make general observations scope limitations experiments first nversion systems used experiments must reliabilities low moderate reliability region otherwise data would obtained would relevant independence question 8 sufficient get data individual versions reliability region coincident error rate must observable reliability voted outputs must low moderate reliability region see consider following suppose 3version system replicates failure rate independently coincident error rate 3 theta 10 gamma8 hour versions moderate reliability region system potentially ie independent ultrareliable region order test independence coincident errors must observed experiment performed one year coincident errors observed one confident coincident error rate consequently system failure rate less coincident errors observed coincident error rate probably even higher coincident error rate actually 10 gamma7 hour independence assumption invalid one would test 1000 years order reasonable chance observe thus future experiments one following results depending actual reliability test specimens 1 demonstration independence assumption hold low reliability system 2 demonstration independence assumption hold systems low reliability system 3 coincident errors seen test time insufficient demonstrate independence potentially ultrareliable system system test low reliability system independence assumption may contradicted vindicated either way results apply ultrareliable systems except way extrapolation system test actually ultrareliable third conclusion would result thus experiments reveal problems model independence model inaccuracies severe manifest low moderate reliability gion however software reliability experiments demonstrate interaction model inaccurate never model accurate ultrareliable software thus negative results possible never positive results experiments performed knight leveson others useful alerting world formerly unnoticed critical assumption however important realize 8 unless one willing carry smithsonian experiment ie one requires centuries complete experiments cannot accomplish really needednamely establish scientific rigor particular design ultrareliable particular design methodology produces ultrareliable systems leaves us terrible bind want use digital processors lifecritical applications feasible way establishing meet ultrareliability requirements must either change reliability requirements level low moderate reliability region give notion experimental quantification neither option appealing 6 conclusions recent years computer systems introduced lifecritical situations previously caution precluded use despite alarming incidents disaster already occurring increasing frequency industry united states abroad continues expand use digital computers monitor control complex realtime physical processes mechanical devices potential performance advantages using computers analog predecessors created atmosphere serious safety concerns digital hardware software adequately addressed although faulttolerance research discovered effective techniques protect systems physical component failure practical methods prevent design errors found without major change design verification methods used lifecritical systems major disasters almost certain occur increasing frequency since lifetesting ultrareliable software infeasible ie quantify 10 gamma8 hour failure rate requires 10 8 hours testing reliability models faulttolerant software developed ultrareliablesystem estimates obtained key assumption enables ultrareliability prediction hardware failures electrically isolated processors fail independently assumption reasonable hardware component failures provable testable assumption reasonable software hardware design flaws furthermore model tries include level nonindependent interaction multiple versions justified experimentally would take 10 8 hours testing make sure coincident errors two versions appear rarely frequently enough degrade system reliability significant conclusions drawn observations paper since digital computers inevitably used lifecritical applications necessary credible methods developed generating reliable software nevertheless constitutes credible method must carefully reconsidered pervasive view software validation must accomplished probabilistic statistical methods shortcomings pitfalls view expounded paper based intuitive merits likely software fault tolerance used lifecritical applications nevertheless ability approach generate ultrareliable software cannot demonstrated research experiments question whether software fault tolerance effective design methodologies formal verification vice versa answered low moderate reliability systems ultrareliable applications choice software fault tolerance formal verification must necessarily based either extrapolation nonexperimental reasoning similarly experiments designed compare accuracy different types software reliability models accomplished low moderate reliability regions little reason believe model accurate moderate region accurate ultrareliable region possible models inferior models moderate region superior ultrareliable regionagain cannot demonstrated appendix section statistics life testing briefly reviewed detailed presentation found standard statistics text book mannschafersingpurwalla 4 section presents statistical test based maximum likelihood ratio 9 produced using reference extensively mathematical relationship number test specimens specimen reliability expected time test explored number test specimens observed number specimen failures ordered failure times hypothesis test constructed test reliability system alternative null hypothesis covers case system ultrareliable alternative covers case system fails meet reliability requirement ff error probability rejecting null hypothesis true ie producers risk fi error probability accepting null hypothesis false ie consumers risk two basic experimental testing replacement 2 testing without replacement either case one places n items test test finished r failures observed first case device fails new device put test place second case failed device replaced tester chooses values n r obtain desired levels ff fi errors general larger r n smaller statistical testing errors necessary assume distribution timetofailure test specimen simplicity assume distribution exponential 10 test reduced test exponential means using transformation gammalnrt expected time test calculated function r n expected time test replacement case r mean time failure test specimen expected time test nonreplacement case r order calculate ff fi errors specific value alternative mean must selected thus hypothesis test becomes 9 maximum likelihood ratio test test provides best critical region given ff error failure times follow weibull distribution known shape parameter data transformed variables exponential distributions test applied reasonable alternative hypothesis reliability 10 hours test statistic r given r nonreplacement case replacement case critical value c null hypothesis rejected determined function ff r 2rffwhere ff ff percentile chisquare distribution degrees freedom given choice r ff value best critical region determined formula fi error calculated 2r1gammafineither equations solved r determined however following formula derived given desired ff fi errors one chooses smallest r satisfies equation example 1 suppose wish test 001 smallest r satisfying equation 14 3 using chisquare table thus critical region experimenter choose value n greater r larger n shorter expected time test replacement case expected time test replicates n expected test duration hours hours even 10000 test specimens expected test time 342 years example 2 suppose wish test given fi error calculated first critical region chisquare table fi error seen greater illustrative table following relationship exists ff r fi ff r fi power test drastically changes r clearly r must least 2 reasonable value beta error acknowledgements authors grateful dr alan white many helpful comments anonymous reviewers careful reviews many helpful suggestions r software safety digital matter life death software bugs matter life liability methods statistical analysis reliability life data evaluation competing reliability predictions adaptive software reliability modeling stochastic model faultremoval computer programs hardware designs use performance software reliability growth models predicting software reliability software reliability repetitive run experimentation modeling nversion approach faulttolerant software faulttolerant software reliability modeling making statistical inferences software reliability experimental evaluation assumptions independence multiversion programming empirical comparison software faulttolerance fault elimination reply criticisms knight leveson experi ment tr software safety experimental evaluation assumption independence multiversion programming evaluation competing software reliability predictions faulttolerant software reliability modeling software bugs matter life liability empirical comparison software fault tolerance fault elimination reply criticisms knight myampersandamp leveson experiment ctr pierluigi san pietro angelo morzenti sandro morasca generation execution sequences modular time critical systems ieee transactions software engineering v26 n2 p128149 february 2000 sandro morasca angelo morzenti pieluigi sanpietro generating functional test cases inthelarge timecritical systems logicbased specifications acm sigsoft software engineering notes v21 n3 p3952 may 1996 phyllis g frankl yuetang deng comparison delivered reliability branch data flow operational testing case study acm sigsoft software engineering notes v25 n5 p124134 sept 2000 v winter kapur g fuehrer formal specification refinement safe train control function formal methods embedded distributed systems master complexity kluwer academic publishers norwell 2004 dick hamlet subdomains testing profiles components acm sigsoft software engineering notes v25 n5 p7176 sept 2000 new type security safety architecture distributed system models implementation proceedings 3rd international conference information security november 1416 2004 shanghai china j h r may lunn model code sharing estimating software failure demand probabilities ieee transactions software engineering v21 n9 p747753 september 1995 terry shepard margaret lamb diane kelly testing taught communications acm v44 n6 p103108 june 2001 john c knight aaron g cass antonio fernndez kevin g wika testing safetycritical application proceedings 1994 acm sigsoft international symposium software testing analysis p199 august 1719 1994 seattle washington united states phyllis g frankl richard g hamlet bev littlewood lorenzo strigini evaluating testing methods delivered reliability ieee transactions software engineering v24 n8 p586601 august 1998 peter amey roderick chapman static verification extreme programming acm sigada ada letters vxxiv n1 p49 march 2004 john c knight computing systems dependability proceedings 25th international conference software engineering may 0310 2003 portland oregon elisabeth strunk xiang yin john c knight echo practical approach formal verification proceedings 10th international workshop formal methods industrial critical systems p4453 september 0506 2005 lisbon portugal walter j gutjahr optimal test distributions software failure cost estimation ieee transactions software engineering v21 n3 p219228 march 1995 dick hamlet subdomain testing units systems state proceedings 2006 international symposium software testing analysis july 1720 2006 portland maine usa phyllis frankl dick hamlet bev littlewood lorenzo strigini choosing testing method deliver reliability proceedings 19th international conference software engineering p6878 may 1723 1997 boston massachusetts united states brian mitchell steven j zeil modeling reliability growth nonrepresentative annals software engineering 4 p1129 1997 john c knight dependability embedded systems proceedings 24th international conference software engineering may 1925 2002 orlando florida john c knight introduction computing system dependability proceedings 26th international conference software engineering p730731 may 2328 2004 dick hamlet dave mason denise woit theory software reliability based components proceedings 23rd international conference software engineering p361370 may 1219 2001 toronto ontario canada brian mitchell steven j zeil reliability model combining representative directed testing proceedings 18th international conference software engineering p506514 march 2529 1996 berlin germany morasca morzenti p san pietro case study applying tool automated system analysis based modular specifications written trio automated software engineering v7 n2 p125155 may 2000 dick hamlet random testing proceedings 1st international workshop random testing july 2020 2006 portland maine xiang yin echo approach formal verification proceeding 28th international conference software engineering may 2028 2006 shanghai china dick hamlet continuity software systems acm sigsoft software engineering notes v27 n4 july 2002 paul ammann dahlard l lukes john c knight applying data redundancy differential equation solvers annals software engineering 4 p6577 1997 robyn r lutz software engineering safety roadmap proceedings conference future software engineering p213226 june 0411 2000 limerick ireland manuel blum hal wasserman reflections pentium division bug ieee transactions computers v45 n4 p385393 april 1996 farokh b bastani relational programs architecture robust realtime safetycritical processcontrol systems annals software engineering v7 n14 p524 1999 john penix willem visser seungjoon park corina pasareanu eric engstrom aaron larson nicholas weininger verifying time partitioning deos scheduling kernel formal methods system design v26 n2 p103135 march 2005 james l caldwell formal methods technology transfer view nasa formal methods system design v12 n2 p125137 march 1 1998 peter amey roderick chapman industrial strength exception freedom acm sigada ada letters vxxiii n1 p19 march alena griffiths prooftest intervals safety functions implemented software proceedings eleventh australian workshop safety critical systems software p2333 august 31 2006 melbourne australia hal wasserman manuel blum software reliability via runtime resultchecking journal acm jacm v44 n6 p826849 nov 1997 terry shepard efficient set software degree programs one domain proceedings 23rd international conference software engineering p623632 may 1219 2001 toronto ontario canada adid jazaa toward better software automation acm sigsoft software engineering notes v20 n1 p7984 jan 1995