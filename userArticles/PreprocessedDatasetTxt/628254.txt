hashing methods temporal data external dynamic hashing used traditional database systems fast method answering membership queries given dynamic set objects membership query asks whether object identity k current state paper addresses general problem temporal hashing setting changes dynamic set timestamped membership query temporal predicate find whether object identity k set time present efficient solution problem takes ephemeral hashing scheme makes partially persistent solution also termed partially persistent hashing uses linear space total number changes evolution set small ologbnb query overhead experimental comparison partially persistent hashing various straightforward approaches like external linear hashing multiversion btree rtree shows provides faster membership query response time partially persistent hashing seen extension traditional external dynamic hashing temporal environment independent ephemeral dynamic hashing scheme used paper concentrates linear hashing methodology applies dynamic hashing schemes well b introduction hashing used fast method address membership queries given set objects distinguished identity attribute oid membership query asks whether object oid k set hashing applied either main memory scheme data fits mainmemory dkm88 fnss92 database systems data stored disk l80 latter form called external hashing en94 r97 hashing function maps oids buckets every object hashing function computes bucket number object stored bucket initially size page discussion assume page hold b objects ideally distinct oid mapped separate bucket however unrealistic universe oids usually much larger number buckets allocated hashing scheme b oids mapped bucket bucket overflow occurs overflows dealt various ways including rehashing try find another bucket using another hashing scheme andor chaining create chain pages overflown bucket overflows present finding whether given oid hashed set trivial simply compute hashing function queried oid visit appropriate bucket object set bucket hence hashing scheme perfect membership queries answered o1 steps one io access page bucket overflows however complicate situation data known advance worst case query performance hashing large linear size set since oids could mapped bucket g kollios dept computer information science polytechnic university brooklyn ny 11201 gkolliosparospolyedu v j tsotras dept computer science university california riverside research partially supported nsf grant iri9509527 new york state science technology foundation part center advanced technology program bad hashing scheme used nevertheless practice shown absence pathological data good hashing schemes overflows constant average case query performance usually bucket size one two pages exist one major differences hashing index schemes balanced tree b tree c79 used instead answering membership query takes logarithmic size time worst case many applications example join computations sd90 hashing scheme provides expected constant query performance one two ios preferable worst case logarithmic query performance four ios large balanced search trees static hashing refers schemes use predefined set buckets inefficient set allowed change adding deleting objects set set small number preallocated buckets large scheme using space needed set becomes large small number buckets used overflows become often deteriorating schemes performance needed dynamic hashing scheme property allocating space proportional size hashed set various external dynamic hashing schemes proposed among linear hashing l80 variation appears commonly used note even set evolves traditional dynamic hashing ephemeral ie answers membership queries current state set paper address general problem assume changes set timestamped time instant occurred interested answering membership queries state set possessed let st denote state collection objects set time membership query temporal predicate given oid k time find whether k st term problem temporal hashing new query temporal membership query motivation temporal hashing problem stems applications current well past data interest examples include accounting billing marketing taxrelated social medical financialstockmarket applications applications cannot efficiently maintained conventional databases work terms single usually current logical state instead temporal databases proposed sa85 time varying data two time dimensions used model reality namely validtime transactiontime j94 valid time denotes time fact valid reality transaction time time fact stored database transaction time consistent serialization order transactions ie monotonically increasing implemented using commit times transactions s94 rest terms time temporal refer transactiontime assume every time st changes addingdeleting objects could good ephemeral dynamic hashing scheme say linear hashing ht maps efficiently overflows oids st collection buckets bt one straightforward solution temporal hashing problem would separately store collection buckets bt answer temporal membership query oid k time need apply ht k access appropriate bucket bt would provide excellent query performance takes advantage good linear hashing scheme ht used space requirements prohibitively large n denotes number changes ss evolution flashing bt disk could easily create 2 space instead propose efficient solution similar query performance uses space linear n term solution partially persistent hashing reduces original problem collection partially persistent 1 subproblems apply two approaches solve subproblems first approach sees subproblem evolving subset set based snapshot index tk95 second approach sees subproblem evolving sublist whose history efficiently kept cases partially persistent hashing scheme observes stores evolution ephemeral hashing efficient way enables fast access ht bt note partial persistence fits nicely transactiontime database environment always increasing characteristic compare partially persistent hashing three approaches first one uses traditional dynamic hashing function map oids ever created evolution st solution distinguish among many copies oid k may created time proceeds given oid k added deleted many times creating copies k associated different time interval copies hashed bucket bucket reorganizations solve problem also observed as86 overflows eventually deteriorate performance especially number copies increases second approach sees oidinterval combination multidimensional object uses rtree store third approach assumes b tree used index st makes b tree partially persistent bgo96 vv97 ls89 experiments show 1 structure called persistent store access past states dsst89 called partially persistent structure evolves applying changes current state partially persistent hashing outperforms three competitors membership query performance minimal space overhead partially persistent b tree bgo96 vv97 ls89 technically interesting among competitor approaches corresponds extending ephemeral b tree temporal environment like ephemeral b tree supports worst case logarithmic query time temporal queries open problem whether efficient temporal extension existed hashing schemes work presented answers question positively nontemporal environment partially persistent hashing provides faster indexing expected query performance temporal membership queries result reasserts conjecture ktf98 temporal problems support transactiontime solved taking efficient solution corresponding nontemporal problem making partially persistent rest paper organized follows section 2 presents background previous work related temporal index methods interest section 3 describes basics snapshot index linear hashing description partially persistent hashing appears section 4 performance comparisons presented section 5 conclusions open problems research appear section 6 2 background previous work research temporal databases shown immense growth recent years os95 work temporal access methods concentrated indexing worst case comparison temporal indexes appears st97 best knowledge approach addresses hashing problem temporal environment among existing temporal indexes four special interest paper namely snapshot index tk95 timesplit btree tsb ls89 multiversion btree mvbt bgo96 multiversion access structure mvas vv97 simple model temporal evolution follows assume time discrete described succession nonnegative integers consider simplicity initially empty set time proceeds objects added deleted set object added ever deleted called alive represented associating object semiclosed interval lifespan form starttime endtime object alive cannot readded ie contains duplicates deletions applied alive objects object added starttime endtime yet unknown thus lifespan interval initiated variable representing always increasing current time object later deleted endtime updated objects deletion time since object added deleted many times objects oid may exist nonintersecting lifespan intervals ie objects alive different times state set given time namely st collection alive objects time assume evolution stored transactiontime database way change happens time transaction timestamp updates database various queries may ask temporal database common query puresnapshot problem also denoted proposed notation tjs98 given time find st another common query rangesnapshot problem rs given time range oids r find alive objects st oids range r categorizes temporal indexes according queries answer efficiently compares performance using three costs space query time update time ie time needed update index change happened set clearly index solves rangesnapshot query also solve puresnapshot query range provided however indicated tgh95 method designed address primarily puresnapshot query need order incoming changes according oid note evolution model changes arrive increasing time order unordered oid hence method could enjoy faster update time method designed rangesnapshot query latter orders incoming changes oid provide fast response rangesnapshot queries indeed snapshot index solves puresnapshot query ios using onb space o1 update time per change expected amortized sense clr90 hashing scheme employed iooptimal solution pure snapshot query corresponds number alive objects queried state st rangesnapshot query three efficient methods exist namely tsb tree mvbt tree mvas structure assume exists b tree indexing st time proceeds set evolves corresponding b tree evolves differ algorithms provided efficiently store access b tree evolution answering rangesnapshot query time implies accessing b tree time search nodes find oids range interest conceptually approaches take b tree make partially persistent dsst89 resulting structure form graph includes whole history evolving b tree able efficiently access past state b tree log b mvbt mvas solve rangesnapshot query ios using onb space update per change amortized sense clr90 optimal solution rangesnapshot query denotes number alive objects update takes place denotes answer size rangesnapshot query ie many objects queried st oids query range r mvas structure improves mergesplit policies mvbt thus resulting smaller constant space bound tsb tree another efficient solution rangesnapshot query practice space efficient mvbt mvas guarantee worst case query performance set evolution described additions new objects updates existing objects since purposes paper assume object deletions frequent use mvbt instead tsb 3 basics snapshot index linear hashing purposes partially persistent hashing need fundamentals snapshot index ephemeral linear hashing described next detailed descriptions refer tk95 l80 s88 en94 r97 respectively 31 snapshot index method tk95 solves puresnapshot problem using three basic structures balanced tree timetree indexes data pages time pointer structure accessforest among data pages hashing scheme timetree accessforest enable fast query response hashing scheme used update purposes first discuss updates objects stored sequentially data pages order added set particular new object oid k added set time new record form k created appended data page data page becomes full new data page used given instant one data page stores accepts records acceptor data page time acceptor page created along page address stored time tree acceptor pages created sequentially timetree easily maintained amortized o1 io index new acceptor page object additions sequence data pages resembles regular log two main differences 1 way deletion updates managed 2 use additional links pointers among data pages create accessforest log b log io object deletions added sequentially rather inplace updates object k deleted time record first located updated k k object records found using oids hashing scheme object added oid address page stores objects record inserted hashing scheme object deleted hashing scheme consulted objects record located interval updated objects oid removed hashing function storing one record object suggests time instant records objects st may dispersed various data pages accessing pages alive objects would require much io st objects may access oa pages hence records alive objects must clustered together ideally ab pages achieve good clustering introduce copying controlled manner ie way total space remains explain copying procedure need introduce concept page usefulness consider page gets full records ie stops acceptor page number alive records contains records intervals ending time instants page contains ub alive records called useful times page contains good part answer st puresnapshot query time able locate useful pages time page contribute least ub objects answer usefulness parameter u constant tunes behavior snapshot index acceptor pages special page acceptor page may contain fewer ub alive records definition also call page useful long acceptor page page may give enough answer justify accessing still access nevertheless time instant exists exactly one acceptor page let ustarttime uendtime denote pages usefulness period ustarttime time page started acceptor page page gets full either continues useful long page least ub alive records becomes nonuseful time became full page less ub alive records next step cluster alive records among useful pages page becomes nonuseful artificial copy occurs copies alive records page current acceptor page timesplit e86 ls89 nonuseful page behaves objects marked deleted copies alive records still found acceptor page copies record contain subsequent nonoverlapping intervals objects lifespan copying procedure reduces original problem finding alive objects finding useful pages solution reduced problem facilitated accessforest accessforest pointer structure creates logical forest trees among data pages new acceptor page appended end doublylinked list remains list long useful data page becomes nonuseful removed list b becomes next child page page c preceding list ie c left sibling list became nonuseful time proceeds process create trees nonuseful data pages rooted useful data pages list accessforest number properties enable fast searching useful pages time tk95 showed starting acceptor page useful pages found twice many ios practice much less ios needed find acceptor page balanced timetree searched corresponds logarithmic part query time practice search fast height balanced tree small stores one entry per acceptor page clearly onb main part query time finding useful pages performance snapshot index fine tuned changing parameter u large u implies acceptor pages become nonuseful faster thus copies created increases space also clusters answer smaller number pages ie less query io 32 linear hashing linear hashing lh dynamic hashing scheme adjusts gracefully data inserts deletes scheme uses collection buckets grows shrinks one bucket time overflows handled creating chain pages overflown bucket hashing function changes dynamically given instant two hashing functions used scheme specifically let u universe oids h 0m1 initial hashing function used load set buckets example h 0 insertions deletions oids performed using h 0 first overflow happens first overflow occurs occur bucket first bucket lh file bucket 0 split rehashed two buckets original bucket 0 new bucket attached end lh file oids originally mapped bucket 0 using function h 0 distributed buckets using new hashing function h 1 oid next overflow attach new bucket m1 contents bucket 1 distributed using h 1 buckets 1 m1 crucial property h 1 oids originally mapped h 0 bucket j remapped either bucket j bucket jm necessary property linear hashing work example hashing function h 1 overflows cause additional buckets split linear bucketnumber order variable p indicates bucket split next conceptually value p denotes two hashing functions may enabled given time applies buckets initially p0 means one hashing function used applies buckets lh file first overflow example p1 h 1 introduced suppose object oid k inserted second overflow ie p2 first older hashing function applied k bucket h 0 k split yet k stored bucket otherwise bucket provided h 0 already split newer hashing function stored bucket h 1 k searching oid similar hashing functions may involved enough overflows original buckets split marks end splitting round 0 round 0 p went subsequently bucket 0 bucket m1 end round 0 lh file total 2m buckets hashing function h 0 longer needed 2m buckets addressed hashing function h 1 note reset 0 new round namely splittinground 1 started next overflow 2m buckets introduce hashing function h 2 oid oid mod2 2 round last bucket 2m1 split general round starts hashing functions h oid oid round ends buckets split purposes use h called split functions h 0 split function h j properties ii oid either h j given time linear hashing scheme completely identified round number variable p given round variable p searching oid k performed using h otherwise h i1 used round value p increased one overflow next round i1 starts p reset 0 split performed whenever overflow occurs uncontrolled split let l denote lh files load factor ie current number oids lh file size set b page size number oids r current number buckets file load factor achieved uncontrolled splits usually 5070 depending page size l br oid distribution l80 practice achieve higher storage utilization split instead performed overflow occurs load factor upper threshold g controlled split typically achieve 95 utilization deletions set cause lh file shrink buckets split recombined load factor falls lower threshold f two buckets merged together operation reverse splitting occurs reverse linear order practical values f g 07 09 respectively 4 partially persistent hashing first describe evolvingset approach based snapshot index evolving list approach follow 41 evolvingset approach using partial persistence temporal hashing problem reduced number subproblems efficient solutions known assume ephemeral linear hashing scheme one described section 3 used map objects st st evolves time hashing scheme function time let lht denote linear hashing file time two basic timedependent parameters identify lht namely pt parameter round number time value parameter pt identifies next bucket split interesting property linear hashing buckets reused round i1 starts double number buckets round first half bucket sequence since new buckets appended end file let b total denote longest sequence buckets ever used evolution st assume b total consists buckets 012 let bt sequence buckets used time observation implies bt prefix b total addition consider bucket b j sequence b total observe collection objects stored bucket time proceeds state bucket b j time namely b j set oids stored bucket let denote number oids b j states somehow reconstructed bucket b j answering temporal membership query oid k time answered two steps 1 find bucket b j oid k would mapped hashing scheme 2 search contents b j k found first step requires identifying hashing scheme used time evolution hashing scheme lht easily maintained record form pt appended array h instants values andor pt change given hashing function used identified simply locating inside timeordered h logarithmic search second step implies accessing b j obvious way would store b j times b j changed explained earlier would easily create quadratic space requirements updating per change would also suffer since io store current state b j would proportional buckets current size namely observing evolution bucket b j note state changes evolving set adding deleting oids change timestamped time instant occurred times ephemeral linear hashing scheme may apply rehashing procedure remaps current contents bucket b j bucket b j new bucket b r assume rehashing occurred time result move v oids b j b r evolution b j b r rehashing viewed deletion respectively addition v oids time ie deletions additions timestamped time corresponding objects evolution figure 1 shows example ephemeral hashing scheme two different time instants simplicity 2 figure 2 shows corresponding evolution set evolutions various buckets time addition oid 8 bucket 3 causes first overflow rehashes contents bucket 0 bucket 0 bucket 5 result oid 15 moved bucket 5 buckets 0 evolution change considered deletion 5 addition oid 15 instant b j available searching contents oid k performed linear search process lower bounded ios since many pages least needed store b j similar traditional hashing query oid translated searching pages bucket search also linear continues oid found buckets pages searched therefore needed method given reconstruct b j effort proportional ios since every bucket b j behaves like set evolving time snapshot index tk95 used store evolution b j reconstruct b j required efficiency thus conclude given evolving set partially persistent hashing answers temporal membership query oid k time almost query time efficiency plus small overhead separate ephemeral hashing scheme existed st good ephemeral hashing scheme st would require expected o1 ios answer membership query means average bucket b j used st would limited size equivalently corresponds pages practice one two pages perspective partially persistent hashing reconstruct b j ios expected o1 small overhead incurred persistent hashing due fact stores whole history ss evolution single state st array h stores entry every time page overflow occurs even changes new oid additions number overflows upper bounded onb hence array h indexes pages searching takes ios identified hashing function appropriate bucket b j pinpointed time must searched timetree associated bucket overhead implied search bounded n j corresponds number changes recorded bucket bucket bucket b figure 1 two instants evolution ephemeral hashing scheme time split occurred mapped bucket 3 causes overflow bucket 0 rehashed using h 1 log history practice expect n changes ss evolution concentrated first b total bucket sequence simply prefix sequence always used assume ss history recorded first buckets n j behaves therefore searching b j timetree rather fast logarithmic overhead proportional number changes n common characteristic query time temporal indexes use partial persistence mvbt mvas tree answer temporal membership query oid k time ios note mvbts logarithmic bound contains two searches first appropriate btree indexes st found fast search similar identifying hashing function bucket search persistent hashing second logarithmic search mvbt finding k tree indexes st logarithmic size st instead persistent hashing finds oid k expected o1 ios figure 2 detailed evolution set time additiondeletion respectively changes assigned histories three buckets shown hashing scheme figure 1 assumed addition oid 8 causes first overflow moving oid 15 bucket 0 bucket 5 seen deletion addition respectively records stored buckets history also shown example t25 oid 10 deleted set updates lifespan oids corresponding record bucket 0s history 10 1 10 1 25 evolution set time 10 1 15 9 oid lifespan records bucket 0s history 10 1 15 9 21 oid lifespan evolution bucket 0 10 1 25 15 9 21 oid lifespan 3 4 13 17 oid lifespan records bucket 3s history 3 4 13 17 oid lifespan evolution bucket 3 13 17 oid lifespan oid lifespan records bucket 5s history 15 21 oid lifespan evolution bucket 5 15 21 oid lifespan 8 21 8 21 411 update space analysis proceed analysis update space characteristics partially persistent hashing suffices show scheme uses onb space o1 amortized expected update processing per change derived clearly array h satisfies space bound next show space used bucket histories also bounded onb recall n corresponds total number real object additionsdeletions set ss evolution however rehashing process moves objects among buckets bucket histories move seen new change deletion oid previous bucket subsequent addition oid new bucket must thus shown number moves due rehashing still bounded number real changes n purpose use two lemmas lemma 1 n overflows occur least nb1 real object additions needed proof proof based induction number overflows 1 creation first n1 overflow least b1 oid additions needed happens oids mapped bucket hold b oids bucket starts one empty page 2 assume n first overflows nb1 real object additions needed 3 must proved first overflows need least n1b1 oid additions assume true ie oid additions enough show contradiction results assumption according 2 first n n1 overflows needed nb1 real object additions hence b1 remaining oid additions create extra overflow consider page last overflow occurred bucket page exactly one record less would overflow nth overflow could achieved one less oid page overflow need least b oid additions ie remaining b1 enough n1th overflow results contradiction lemma proved note page nth overflow occurred needs considered page space additional oids cannot one oid already since overflow occurred bucket could achieved less oids q previous lemma lower bounds number real oid additions n overflows next lemma upper bounds total number copies due oid rehashings happen overflows lemma 2 n overflows create nb1 oid copies proof use induction number overflows 1 first overflow create b1 oid copies happens first overflow occurs oids bucket remapped new bucket deleted records remapped b1 oids still stored history original bucket 2 assume n first overflows nb1 oid copies 3 must shown first n1 overflows create n1b1 oid copies use contradiction hence lets assume true ie first n1 overflows create copies let n1b1x number consider last n overflows sequence overflows 2 implied overflows already created nb1 oid copies hence least b1x additional copies created first overflow however contradiction since 1 first overflow create copies q ready prove basic theorem space updating theorem 1 partially persistent hashing uses space proportional total number real changes updating amortized expected o1 per change proof assume simplicity set evolves adding oids oid additions create new records overflows hence copying deletions create overflows overflows occur linear hashing proceeds rounds first round variable p starts bucket 0 end round reaches bucket m1 point 2m buckets used copies remappings oids first round created since overflows occurred lemmas 1 2 imply must least mb1 real oid additions copies construction copies placed last buckets next round variable p start bucket 0 extend bucket 2m1 p reaches bucket 2m1 2m new overflows new overflows imply must least 2mb1 new real oid additions 2mb1 copies created additions also mb1 copy oids first round purposes second round seen regular oids copy oid copied second round original oids copies created first round cannot copied second round represent deleted records corresponding buckets hence maximum number copies second round 2mb1 total number copies c total created ith round 012 upper bounded represents copies per round equivalently ith round total number real oid additions total lower bounded equivalently ii ii derived exists positive constant const since total bounded total number changes n prove partially persistent hashing o1 expected amortized updating per change note real change occurs directed appropriate bucket structures snapshot index updated o1 expected time rehashings carefully examined rehashing bucket caused single real oid addition one created overflow results bunch copies made new bucket worse whole current contents rehashed bucket sent new bucket however using space bound prove sequence n real changes create copies extra work equivalently o1 amortized effort per real change q 412 optimization issues optimizing performance partially persistent hashing involves load factor l ephemeral linear hashing usefulness parameter u snapshot rt denote size evolving set number buckets used clearly good ephemeral linear hashing scheme try equally distribute oids among buckets hence average size oids bucket b j satisfy total mb 1 2mb 1 total mb 2 k c total total const l one advantages snapshot index ability tune performance usefulness parameter u index distribute oids b j among number useful pages since useful page except acceptor page contains least ub alive oids oids occupying pages actually lu ideally would like answer snapshot query contained single page plus probably one acceptor page good optimization choice keep conceptually load l gives measure size bucket alive oids time alive oids stored data pages snapshot index recall artificial copy happens number alive oids data page falls ub point remaining ub1 alive oids page copied new page keeping l u expect alive oids split page copied single page minimizes number ios needed find hand usefulness parameter u affects space used snapshot index return overall space persistent hashing scheme mentioned section 3 higher values u imply frequent time splits ie page copies thus space hence would advantageous keep u low implies even lower l return lower l would mean buckets ephemeral hashing fully utilized low l causes set st distributed buckets may fully occupied first requirement seems contradictory however purposes partially persistent hashing low l still acceptable recall low l applies ephemeral hashing scheme whose history partially persistent hashing observes accumulates even though single time instants b j ts may fully utilized whole time evolution many object oids mapped bucket counts partially persistent scheme total number changes accumulated per bucket due bucket reuse bucket gather many changes creating large history bucket thus justifying use partially persistent scheme findings regarding optimization verified experimentation results appear next section 42 evolvinglist approach elements bucket b j also viewed evolving list lb j alive oids observation consistent way buckets searched ephemeral hashing ie linearly buckets contents belong list practice bucket expected one two pages long accessing bucket state b j reduced reconstructing lb j equivalently evolving list oids made partially persistent l u bucket b j first created empty page assigned list lb j list page two areas first area used store oid records size b r b r b second area size accommodates extra structure array nt explained shortly first oid k added bucket b j time record k appended first list page additional oid insertions create record insertions list pages appended needed oid k deleted bucket record list found serial search among list pages endtime updated logical deletion snapshot index need notion page usefulness page called useful long contains least v alive objects last page list otherwise nonuseful page following discussion assume except last page list useful page become nonuseful oid deletion bring number alive oids page threshold last page turn useful nonuseful gets full records event caused oid insertion time pages total number alive oids less l page becomes nonuseful otherwise continues regular useful page last page gets full new last page added list finding state b j equivalent finding useful pages lb j use two extra structures first structure array ft j time provides access first useful page lb j entries array ft j form time pid pid page address first useful page list changes new entry pid new first useful page appended ft j array implemented multilevel paginated index since entries added increasing time order find remaining useful pages lb j every useful page must know next useful page list achieved second structure implemented inside every list page particular structure form array stored page area size b r let nta array inside page array maintained long page useful entries nta also form time pid pid corresponds address next useful page useful page usefulness period page next useful page changes many times nta become full assume scenario happens time let c useful page page page artificially turned nonuseful even still v alive records replaced copy page call process artificial since caused oid insertiondeletion page rather due change page ahead new page alive records empty nt new entry added ntc pid first entry nt pid useful page page useful list pages page nt arrays full time process artificially turning useful pages nonuseful propagate way top list reaches first useful page list copy created array ft j updated however happen often figure 3 shows example arrays nt ft j maintained need artificial creation copy page faster query processing ntc array enables finding next useful page c various time instants assume moment new copy page created instead nta allowed grow available area page additional pages last entry ntc would still point page locating next page c time would lead page serial search among pages array nta needed clearly approach inefficient useful page front page changes often use artificial copies guards similar situations next useful list page time interest found one io technique generalization backward updating technique used tgh95 special care needed page turns useful nonuseful due oid deletion figure 3 example evolution useful pages list lb j b corresponding ft j nt arrays page nt array shown example bb entries since page front page changes often nta array fills time 6 artificial copy page created array nta array ntc also updated artificially created new page f f f f b artificial entry insertion page achieve good answer clustering alive oids page merged alive oids sibling useful page sibling exists create one two depending number alive oids new useful pages new useful pages may full record oids ie future oid insertions accommodated result new oid inserted list useful pages serially searched new oid added first useful page found space b r area accommodate details described appendix answer temporal membership query oid k time appropriate bucket b j oid would mapped hashing scheme must found part evolvingset approach reconstructing state bucket b j performed two steps first using first useful page lb j found searching array ft j corresponds searching timetree bucket evolvingset approach search bounded remaining useful pages lb j thus oids b j found locating nt array subsequent useful page instead evolvingset approach uses access forest snapshot index since useful pages except last list lb j least v alive oids answer oids b j found additional ios space used evolvinglist structures j b two differences evolvinglist evolvingset approaches first updating using snapshot index remains constant evolving list whole current list may searched adding deleting oid second nature reconstructing b j different evolvinglist reconstruction starts top list pages evolvingset reconstruction starts last page bucket may affect search given oid depending whether placed near top near end bucket 5 performance analysis compared partially persistent hashing pph linear hashing particular atemporal linear hashing discussed later mvbt rtree implementation experimental setup described 51 data workloads 52 findings 53 51 method implementation experimental setup set size page hold 25 oid records b25 oid record following form oid starttime endtime ptr first field oid second starting time third ending time oids lifespan last field pointer actual object may additional attributes log first discuss atemporal linear hashing alh clarified alh ephemeral linear hashing whose evolution partially persistent hashing observes stores rather linear hashing scheme treats time another attribute scheme simply maps objects buckets using object oids consequently sees different lifespans oid copies oid implemented alh using scheme originally proposed litwin lin80 split functions used hashing division functions h get good space utilization controlled splits employed lower upper thresholds namely f g values 07 09 respectively another approach atemporal hashing would scheme uses combination oid starttime endtime attributes however approach would still problems alh temporal membership queries example hashing starttime help queries time instants starttimes multiversion btree mvbt implementation based bgo96 fast updating mvbt uses buffer stores pages path last update lru buffer replacement policy used buffering updating advantageous since updates directed current btree small part whole mvbt structure experiments set buffer size 10 pages original mvbt uses buffer queries however fair comparison methods measuring query performance mvbt invalidate buffer content previous queries thus measured query performance independent order queries executed finally original mvbt process answering query starts root array every time array identifies root btree time ie search query start even though root increase time small enough fit main memory thus count io accesses searching root snapshot index page mvbt alive long least q alive records number alive records falls q page merged sibling called weak version underflow extreme page already b records alive new record added page splits page overflow conditions need special handling first timesplit happens like copying procedure snapshot incorporated structure mvbt requires number alive records new page qe e predetermined constant constant e works buffer guarantees new page split merged least e new changes values q e b possible must satisfy constraints details refer bgo96 implementation set 4 directory pages mvbt format data pages partially persistent hashing implemented setevolution pphs listevolution pphl approaches approaches observe ephemeral linear hashing lht whose load lt lies f01 g02 array h identifies hashing scheme used time kept mainmemory io access counted using structure similar keeping root array mvbt main memory experiments size array h never greater 15 kb unless otherwise noted pphs implemented various values usefulness parameter u also examined since entries timetree associated bucket half oid record size timetree page hold 50 entries pphl implementation space oid records b r hold 20 records value v set equal 5 since means page list useful long number alive oids page greater equal 5 remaining space list page size 5 oid records used pages nt array similarly timearrays nt arrays entries half size ie page hold 10 nt entries reason pages ft j array hold 50 entries rtree method used two implementations one intervals ri twodimensional space another points threedimensional space rp ri implementation assigns oid lifespan interval one dimension used oids one lifespan intervals new oid k added set time record k ptr added rtree data page oid k deleted record updated k ptr directory pages include one attribute per record represent oid range rp implementation similar format data pages assigns separate dimensions starttime endtime objects lifespan interval hence directory page record seven attributes two oid starttime endtime one pointer updating rtree implementations use buffer 10 pages keep pages path leading last update mvbt buffer used query phase 52 workloads various workloads used comparisons workload contains evolution dataset temporal membership queries evolution specifically workload defined triplet wueq u universe oids set unique oids appeared evolution set e evolution set collection queries set queries corresponds oid k evolution starts time 1 finishes time maxtime changes given evolution first generated per object oid merged first object oid k number k different lifespans object evolution chosen choice n k made using specific random distribution function namely uniform exponential step normal whose details described next section starttimes lifespans oid k generated randomly picking n k different starting points set 1 maxtime endtime lifespan chosen uniformly starttime lifespan starttime next lifespan oid k since lifespans oid k disjoint finally whole evolution e set created merging evolutions every object another mix lifespans also created evolution picks starttimes length lifespans using poisson distributions called poisson evolution temporal membership query query set q specified tuple oidt number queries q k every object oid k chosen randomly 10 20 thus average form kt query tuples corresponding time instants selected using uniform distribution set 1 maxtime maxtime set 50000 workloads workload described distribution used generate object lifespans number different oids total number changes evolution n object additions deletions total number object additions nb total number queries 53 experiments first behavior implementations tested using basic uniform workload number lifespans per object follows uniform distribution 20 40 total number distinct oids number real changes object additions hence average number lifespans per oid nb refer workload uniform30 number queries 115878 figure 4a presents average number pages accessed per query methods pph methods best performance two pages per query alh approach uses query io 15 times example larger buckets creates mvbt uses twice many ios pph approaches since tree traversed per query ri uses ios per query mvbt mainly due node overlapping larger tree height ri structure relates total number oid lifespans mvbt corresponds number alive oids time specified query problem node overlapping even greater query performance rp tree figure 4a truncated fit graph rp used average 44 ios per query experiment rp alive oids endtime causes clustered together even though different oids overlapping extends oid dimension well observed elsewhere ktf98 transactiontime lifespans maintained efficiently plain rtrees figure 4b shows average number ios per update best update performance given pphs method mvbt second best update performance larger pphs since mvbt traversing tree update instead quickly finding location updated element hashing update ri follows larger mvbt since size tree traversed related oid lifespans size mvbt tree traversed related number alive oids time update alh pphl used even larger update processing alh lifespans oid thrown bucket thus creating large buckets searched serially update pph l nt array implementation inside page limits actual page area assigned storing oids thus increases number pages used per bucket rp tree uses even larger update processing due bad clustering common endtime space consumed method appears figure 4c alh approach uses smallest space since stores single record per oid lifespan uses controlled splits high utilization f g values pph methods also good space utilization pph close alh pphl uses space pphs nt array implementation reduces page utilization rtree methods follow rp uses slightly less space ri paginating intervals putting bounding rectangles demanding points note similarly alh r methods use single record per oid lifespan additional space mainly average rtree page utilization 65 mvbt largest space requirements twice space alh figure 4 query b update c space performance implementations uniform workload b c alh pphs pphl mvbt ri rp10305070 avg number io per update50001500025000alh pphs pphl mvbt ri rp number pages50150alh pphs pphl mvbt ri rp avg number io per query pphs methods summary pphs best overall performance similarly comparison ephemeral hashing btrees mvbt tree behaves worse temporal hashing pphs temporal membership queries alh slightly better pphs space requirements even though significantly rtree based methods much worse pph three performance criteria consider effect lifespan distribution approaches compared using four additional workloads namely exponential step normal poisson workloads number distinct oids number queries 115878 similar n 05m parameters exponential workload generated n k lifespans per oid using exponential distribution probability density function mean 30 total number changes 487774 total number object additions 245562 307 step workload number lifespans per oid follows step function first 500 oids 4 lifespans next 500 8 lifespans ie every 500 oids number lifespans advances 4 workload 34 normal workload used normal distribution parameters poisson workload first lifespan every oid generated randomly time instants 1 500 length lifespan generated using poisson distribution mean 1100 next start time given oid also generated poisson distribution mean value 500 workload 31 main characteristic poisson workload number alive oids time vary small number large proportion u ie time instants number alive oids hundreds time instants almost distinct oids alive figure 5 presents query update space performance new workloads simplicity ri method presented among rtree approaches uniform load rp used consistently query update ri similar space results resemble previous uniform workload pphs approach best overall performance using slightly space minimal space alh pphl query performance comparable space pphs uses much updating note figure 5a query performance ri truncated fit graph average ri used 10 13 per query exponential step normal poisson workloads respectively similarly figure 5c space mvbt truncated mvbt used 26k 29k 25k 355k pages respective workloads effect number lifespans per oid tested using eight uniform workloads varying average number lifespans used different oids number queries 115k parameters shown following table results appear figure 6 query performance atemporal hashing deteriorates nb increases since buckets become larger figure 6a pphs pphl mvbt methods query performance independent nb three methods nb lifespans given oid appear different time instants thus interfere query performance ri much higher truncated fig 6a interestingly ri query performance decreases gradually nb increases 126 ios 94 ios ri clustering improves nb increases records key pphs outperforms methods update performance figure 6b querying updating pphs pphl mvbt basically independent nb better clustering increased nb updating ri gradually decreases contrast increased nb implies larger bucket sizes updating alh increases space methods increases nb changes n per evolution table 1 alh lower space followed pphs mvbt steeper space increase nb values 80 100 mvbt used 68k 845k pages effect number distinct oids used evolution examined considering three variations uniform workload number distinct oids u 5000 8000 table 1 workload n nb nb figure 5 query b update c space performance alh pphs pphl mvbt ri methods using exponential step normal poisson workloads 8k oids n 05m nb 30 b c exponential normal poisson103050 avg number io per query alh pphs pphl mvbt step exponential step normal poisson10305070 avg number io per update alh pphs pphl mvbt ri40001200020000 number pages exponential normal poisson step figure query b update c space performance alh pphs pphl mvbt ri methods using various uniform workloads varying nb b c 100103050avg number io per query1030507090 avg number io per update avg number lifespans per oid nb number pages alh pphs pphl mvbt alh pphs pphl mvbt 12000 respectively workloads similar average number lifespans per distinct oid nb 30 parameters appear table 2 results appear figure 7 query performance pphs pphl independent u contrast increases mvbt ri ri used 104 12 13 ios per query reason increase oids stored tree structures thus increasing structures height evident ri oids appear tree theory alh also independent universe size u slight increase alh figure 7a due controlled splits policy constrained alh given space utilization similar observations hold update performance finally space methods increases n increases table 2 experiments pphs method appears competitive performance among solutions mentioned section 412 pphs performance optimized setting usefulness parameter u figure 8 shows results basic different values u expected best query performance occurs u greater maximum load observed ephemeral hashing experiments maximum load 02 asserted figure 8a query time minimized 03 update similarly minimized figure 8b us 02 since point alive oids compactly kept pages updated easier smaller us alive oids distributed pages increases update process figure 8c shows space pphs us maximum load alive oids distributed among data pages hence page becomes nonuseful contains less alive oids thus less copies made resulting smaller space consumption using optimization space pphs made similar alh expense increase queryupdate performance 6 conclusions open problems paper addressed problem temporal hashing equivalently support temporal membership queries timeevolving set efficient solution termed partially persistent workload n nb queries figure 7 query b update c space performance alh pphs pphl mvbt ri methods using various uniform workloads varying u b c avg number io per query alh pphs pphl mvbt alh pphs pphl mvbt alh pphs pphl mvbt avg number io per update number pages number distinct oids u thousands hashing pph presented queries updates scheme behaves separate ephemeral dynamic hashing scheme available every state assumed set time however method still uses linear space hashing oids various buckets time pph reduces temporal hashing problem reconstructing previous bucket states two flavors partially persistent hashing presented one based evolvingset abstraction pphs one evolvinglist pphl similar query comparable space performance pphs uses much less updating methods compared straightforward approaches namely traditional atemporal linear hashing scheme two rtree implementations multiversion btree experiments showed pphs robust performance among approaches partially persistent hashing seen extension traditional external dynamic hashing temporal environment methodology independent ephemeral dynamic hashing scheme used paper considers linear hashing applies dynamic hashing schemes well various open interesting problems figure 8 query b update c space performance pphs uniform workload varying values usefulness parameter u b c avg number io per query pphs205215225235 avg number io per update pphs u110001300015000number pages pphs traditionally hashing used speed join computations currently investigate use temporal hashing speed temporal joins ssj94 another problem extend temporal membership queries time intervals find whether oid k states set interval discussion paper assumes temporal membership queries linear transactiontime evolution interesting investigate hashing branched transaction environments lst95 acknowledgments would like thank b seeger kindly providing us r mvbtree code part work performed vj tsotras sabbatical visit ucla would thus like thank carlo zaniolo comments hospitality r performance evaluation temporal database management system asymptotically optimal multiversion btree rtree efficient robust access method points rectangles ubiquitous btree introduction algorithms dynamic perfect hashing upper lower bounds making data structures persistent fundamentals database systems nonoblivious hashing rtrees dynamic index structure spatial searching consensus glossary temporal database concepts designing access methods bitemporal databases linear hashing new tool file table addressing lha scalable distributed data structure access methods multiversion data historical queries along multiple lines time evolution temporal realtime databases survey database management systems prentice hall timestamping commit taxonomy time databases tradeoffs processing complex join queries via hashing multiprocessor database machines branched temporal index structures efficient evaluation validtime natural join comparison access methods timeevolving data efficient management timeevolving databases extensible notation spatiotemporal index queries snapshot index iooptimal access method timeslice queries efficient multiversion access structure tr ctr huanzhuo ye hongxia luo kezhen song huali xiang jing chen indexing moving objects based 2 n index tree proceedings 6th conference 6th wseas int conf artificial intelligence knowledge engineering data bases p175180 february 1619 2007 corfu island greece sy chien v j tsotras c zaniolo efficient schemes managing multiversionxml documents vldb journal international journal large data bases v11 n4 p332353 december 2002