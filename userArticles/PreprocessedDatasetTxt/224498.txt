timeconstrained code compaction dsps abstract dsp algorithms cases subject hard realtime constraints case programmable dsps meeting constraints must ensured appropriate code generation techniques processors offering instructionlevel parallelism task code generation includes code compaction exact timing behavior dsp program known compaction therefore realtime constraints taken account compaction phase known dsp code generators rely rigid heuristics phase paper proposes novel approach local code compaction based integer programming model obeys exact timing constraints due general problem formulation model also obeys encoding restrictions possible sideeffects b introduction r esearch electronic cad currently taking step towards systemlevel design automation economical reasons contemporary embedded vlsi systems heterogeneous nature comprising hardware software components form asics embedded programmable processors consequently systemlevel cad tools need provide support integrated hardware software synthesis software synthesis task extracting pieces functionality system specifi cation assigned programmable proces sors mapping pieces executable processor specific machine code general optimization goal hardwaresoftware cosynthesis embedded vlsi systems minimize amount custom hardware needed implement system given performance constraints due fact implementation software provides flexibility lower implementation effort better opportunities reuse hand software synthesis turns bottleneck design systems comprising programmable digital signal processors dsps dsp software still coded assemblylanguage level 1 spite wellknown drawbacks lowlevel pro gramming although highlevel language compilers theshelf dsps available execution speed overhead compilergenerated code several hundred percent compared handcrafted code 2 mostly unacceptable reason overhead compilers hardly capable exploiting highly dedicated irregular architectures dsps furthermore still desig authors affiliation university dortmund department computer science 12 44221 dortmund germany email leupersjmarwedells12informatikunidortmundde nated standard programming language dsps situation even worse applicationspecific dsps asips since typically lowvolume productspecific designs highlevel language compilers asips hardly ex ist nevertheless asips expected gain increasing market shares relation standard dsps 1 current research efforts overcome productivity bottleneck dsp code generation concentrate two central issues 3 code quality order enable utilization highlevel language compilers code overhead must reduced order magnitude achieved means new dspspecific code optimization techniques reaching beyond scope classical compiler construction classical optimization tech niques intended large programs generalpurpose processors primarily focus high compilation speed thus limited effect constrast generation efficient dsp code justifies much higher compilation times therefore large opportunities new optimization techniques aiming high quality code generation within reasonable amount compilation time retargetability order introduce highlevel language compilers code generation asips necessary ensure flexibility code generation tech niques compiler quickly retargeted new processor architecture compiler development become economically feasible even lowvolume dsps ideal case compiler supports retargeting reading analyzing external user editable model target processor code generated way retargetability would permit asip designers quickly study mutual dependence hardware architectures program execution speed already processor level purpose paper present code optimization technique aims thoroughly exploiting potential parallelism dsp machine programs exact local code compaction although code compaction welltried concept vliw machines effective compaction techniques dsps typically show rather restrictive type instructionlevel parallelism hardly ported compaction technique proposed paper takes account peculiarities dsp instruction formats well time constraints imposed machine pro grams furthermore completely retargetable within class instruction formats defined later paper since perform exact code compaction runtimes significantly higher heuristic approaches nev ertheless demonstrated compaction technique capable solving problems relevant size within acceptable amounts computation time whenever tight time constraints demand extremely dense code exact code compaction thus feasible alternative heuristic compaction remainder contribution organized fol lows section ii gives overview record compiler system employs proposed code compaction technique order compile highquality dsp code retargetable manner section iii provide background local code compaction outline existing techniques discuss limitations previous work motivates extended dspspecific definition code compaction problem presented section iv section v specifies formal model code compaction means integer programming reallife examples experimental results given section vi section vii concludes summary results hints research ii system overview currently carried university dortmund based experiences gained earlier retargetable compilers integrated mimola hardware design system 4 5 record retargetable compiler dsps main objective find reasonable compromise antagonistic goals retargetability code quality current version record addresses fixedpoint dsps singlecycle instructions compiles dsp algorithms written dfl language 6 machine instructions externally specified target processor model coarse compiler architecture depicted figure 1 code generation process subdivided following phases intermediate code generation source program analyzed compiled controldataflow graph cdfg representation basic cdfg entities expression trees ets maximum size obtained dataflow analysis common subexpressions ets resolved heuristically node duplication 7 instructionset extraction hardware description language hdl model target processor analyzed converted internal graph rep resentation currently mimola 41 hdl 8 used processor modelling adaptation towards vhdl subset would straightforward internal processor model instructionset extraction ise performed order determine complete set register transfer rt patterns available target processor 9 10 additionally extracted rt patterns annotated possibly multiple binary encodings partial instructions partial instruction bitstring 2 f0 1 xg l l denotes instruction wordlength x dont care value compared related retargetable dsp compiler sys tems mssq 4 chess 11 codesyn 12 concept ise unique feature record accepts target processor models real hdl dsp source program dfl language target processor model mimola language cdfg generation instructionset extraction tree parser generation code selection register allocation integrated scheduling spilling mode register setting address assignment code compaction vertical code augmented agu operations transformation rule library available rt patterns versions rts nops alternative encoding application specific rewrite rules expression trees expression trees covered rt patterns vertical code targetspecific tree parser fig 1 architecture record compiler provides convenient interface cad frame works furthermore processors may modelled different abstraction levels ranging purely behavioral instructionset descriptions rtlevel netlists consisting functional units registers busses logic gates due usage binary decision diagrams bdds 13 control signal analysis ise performed efficiently also eliminates undesired effects resulting syntactic variances processor models way ise provides necessary link hardwareoriented processor models advanced code generation techniques extracted rt patterns form set tree templates represents primitive singlecycle processor operation operation reads values regis ters storages input ports performs computation writes result register storage cell output port tree parser generation extracted rt pat terns fast processorspecific tree parser automatically generated means iburg code generator generator 14 generated tree parser computes optimal implementations expression trees respect number selected rt patterns includes binding values specialpurpose registers well exploitation chained operations multiplyaccumulates advantages tree parsing means integrated code selection register allocation irregular processor architectures already pointed 15 16 ise tree parser generation performed new target processor reused different 3source programs code selection register allocation ets intermediate format consecutively mapped processorspecific rts tree parser high speed efficiency tree parsing permits consideration different semantically equivalent alternatives et alternative ets generated based usereditable library transformation rules transformation rules rewrite rules necessary cope unforeseen idiosyncrasies target processor also increase code quality exploitation algebraic rules simple algebraic rules commutativity already incorporated tree parser virtually extra cost compilation speed see also 17 18 set alternative ets one smallest number required rts selected vertical code generation code selection register allocation tree parsing yield registertransfer tree represents covering et processorspecific rt patterns vertical code generation registertransfer trees heuristically se quentialized minimize spill requirements register files limited capacity necessary spill reload code inserted well additional rts adjusting possibly required mode register states arith metic modes shift modes mode registers store control signals need changed rarely area microprogramming mode registers correspond concept residual control mode register requirements rts determined together partial instructions instructionset extraction vertical code generation machine program consists set rtlevel basic blocks address assignment generated rtl basic blocks augmented rts ensure effective utilization parallel address generation units agus memory addressing accomplished computing appropriate memory layout program variables 19 20 code compaction address assignment rts necessary implement desired program behavior generated one block time passed code compaction phase subject paper code compaction potential parallelism instruction level exploited obeying interrt dependencies conflicts imposed binary encodings rt patterns result executable processorspecific machine code iii local code compaction c ode compaction deals parallelizing set rts given dependency relations constraints assigning rts control steps set rts assigned control step form machine instruction general optimization goal minimize number control steps local compaction starts rtl basic block sequence rts generated previous compilation phases contrast global code compaction permits rts moved across basic block boundaries paper consider local compaction following reasons 1 effective global compaction techniques need employ local techniques subroutines however indicated experimental surveys 2 even local compaction wellsolved problem dsps fore seems reasonable first study local techniques detail 2 popular global techniques trace scheduling 21 percolation scheduling 22 mutation scheduling 23 shown effective mainly highly parallel regular architectures particular vliws contemporary dsps however highly parallel tend irregular architecture 3 order preserve semantical correctness compacted programs global techniques need insert compensation code moving rts across basic blocks compensation code may lead significant increase code size contradicts goal minimizing onchip program rom area local code compaction sufficient represent rt pair r tion r set read locations write read locations registers memory cells processor io ports pair r rts basic block following dependency relations need obeyed order preserve semantical correctness datadependent r r dd r produces program value consumed r j outputdependent r r od gamma r j dataantidependent r r exists rt r k dd gamma r r k od dependency relations impose partial ordering represented dag definition rtl basic block rt dependency graph rdg edgelabelled directed acyclic graph fdddadodg hardware model used record rts singlecycle operations registers permit one write access per cycle registers written read within cycle leads following basic definition code compaction problem parallel schedule rdg mapping cs ng n rts control steps r dd od code compaction problem constructing schedule cs assoonaspossible time asap r rt r defined dd od maxfg 1 critical path length l c rdg provides lower bound minimum schedule length aslateaspossible time alap r rt r defined dd od dad minfg l c rt r lies critical path rdg case unlimited hardware resources code compaction efficiently solved topological sorting real target architectures however impose resource limitations may inhibit parallel execution pairwise independent rts limitations captured incompatibility lation comprising pairs rts cannot executed parallel due resource conflict incompatibilities impose additional constraint code compaction case compaction becomes resourceconstrained scheduling problem known nphard 24 heuristic code compaction techniques became important appearance vliw machines early eighties popular heuristics include firstcome firstserved critical path list scheduling three 2 algorithms empirically evaluated mallett et al 25 concluded algorithm capable producing closetooptimum results cases differing speed simplicity quality relation basic block length n nevertheless techniques essentially developed horizontal machines restrictions imposed instruction format ie resource conflicts mainly caused restricted datapath resources iv compaction requirements dsps dsps particular standard components show horizontal strongly encoded instruction formats order limit silicon area requirements onchip program roms instruction format strongly encoded instruction wordlength small compared total number control lines rtlevel processor components consequence instruction encoding prevents much potential parallelism exposed pure datapath considered interrt conflicts actually arise encoding conflicts instructionlevel parallelism restricted special cases assumed provide highest performance gains respect dsp requirements machine instruction maximum parallelism typically comprises one two arithmetic operations data moves address register updates however full orthogonality operations types certain arithmetic operation executed parallel data move certain specialpurpose register address register update cannot executed parallel data moves forth thus compaction algorithms dsps scan relatively large search space order detect sets rts qualified parallelization special demands code compaction techniques dsps discussed following conflict representation presence datapath resource encoding conflicts desirable uniform conflict representation already observed earlier mimolabased compilers 5 checking interrt conflicts case singlecycle rts performed uniform way checking conflicts partial instructions associated rts two partial instructions conflicting exists 2 lg approach partial instructions automatically derived external processor model instructionset extraction encoding conflicts obviously represented partial instructions holds datapath resource conflicts control code datapath resources assumed adjusted instruction word assumption hold two special cases firstly may conflicts respect required mode register states rts record mode register states adjusted compaction inserting additional rts therefore parallel scheduling rts conflicting mode requirements prevented additional interrt dependencies second special case occurs presence tristate busses processor model unused bus drivers need deactivated control step order avoid unpredictable machine program behavior due bus contentions deriving necessary control code settings bus drivers already instructionset extraction possible map bus contentions usual encoding conflicts b alternative encoding versions general rt r associated unique partial instruction set alternative encodings g alternative encodings may arise alternative routes moving value datapath cases alternatives due instruction format tms320c2x dsp 26 instance permits execution address register updates parallel different arithmetic data move instructions address register update represented different opcode resulting number alternative encodings considered also holds operations instance partial instruction alternative encodings rt namely loading register memory compatibility rts strongly depends selected encoding versions three may pairwise compatible versions scheduling r parallel may impossible fore careful selection encoding versions compaction outstanding importance dsps 25 version shuffling proposed technique version selection integrated heuristic algorithms whenever rt r assigned control step cross product versions r versions rts already assigned checked combination compatible versions however version shuffling permit remove obstructive rt control step bound therefore limited optimization effect c side effects side effect undesired rt may cause incorrect behavior machine program compaction approaches assume instruction format side effects excluded advance however arbitrary instruction formats handled two kinds side effects must considered code compaction horizontal side effects occur weakly enocoded instruction formats several instruction bits remain dont care control step whenever dont care bit steers register memory may contain live value cs register must explicitly deac tivated accomplished scheduling operations nops unused registers nops special partial instructions ensure certain registers disabled loading new value certain control step partial instructions nops computed byproduct instructionset extraction rts alternative nop encoding versions present register however nops necessarily exist registers eg architectures extensive datapath pipelining case compaction must permit tolerate side effects registers containing live values taken account already compaction code generation likely fail although solution might exist second type side effects call vertical side effects occurs presence strongly encoded instruction formats vertical side effect exposed encoding version e ik rt r covered version e jk 0 another rt r j selection e ik r implies r j executed control step happens rt ready scheduled side effect exploited hand version selection must discard version e ik whenever case r j might destroy live value vertical side effects exemplified tms320c2x instruction set partial instructions lta ltd lts shown side effect accumulator register version selection completed nops packed vertical side effects prevented coincidence special aspect vertical side effects multiply accumulates macs dsps mac executes two operations single cycle dsps instance motorola dsp56xxx 27 macs datastationary ie multiplication addition executed chained mode contrast tms320c2x incorporates timestationary macs case value p buffered register code generation point view strong difference mac types datastationary macs already captured parsing expression trees generation timestationary macs must postponed code compaction turn demands compaction methods capable handling vertical side effects time constraints cases dsp algorithms subject realtime constraints techniques hardware synthesis time constraints available incorporation time constraints code generation hardly treated far unfortunate decisions code selection register allocation may imply given maximum time constraint cannot met backtracking may necessary however prerequisite timeconstrained code selection register allocation availability timeconstrained code compaction techniques due fact compaction makes critical path thus worstcase execution speed machine program exactly known therefore compaction techniques de sirable parallelize rts respect given max time constraint tmax machine cycles might case locally suboptimal scheduling decision leads satisfaction tmax rigid optimization heuristic fails e approaches dsp code compaction heuristic compaction algorithms adopted several recent dsp code generators wess compiler 15 uses critical path algorithm achieves code size reductions compared vertical code adsp210x dsp range possible instruction formats handled however reported codesyn compiler 12 compaction horizontal machines described chess compiler 11 uses list scheduling algorithm takes account encoding conflicts alternative versions vertical side effects horizontal side effects bus conflicts priori excluded due limitations processor modelling language 28 motorola 56xxx specific compaction method described however excluding outof order execution ie schedule satisfies two rts r independent dependency relations exact nonheuristic compaction method take account time constraints reported wilson et al 29 proposed integer programming approach integrates code selection register allocation compaction ip model comprises alternative versions vertical side effects bus conflicts horizontal side effects furthermore ip model least entirety turned complex realistic target processors requires large amount manual description effort graphbased compaction technique presented timmer 30 achieves comparatively low runtimes exact code compaction time constraints pruning search space advance pruning procedure based assumption interrt conflicts fixed compaction case rts partitioned maximum sets pairwise conflicting rts separate sequential schedules constructed ef ficiently timmers techniques produced good results family reallife asips restricted capabilities respect alternative versions side effects abovementioned assumption implies incompatibility versions e ik rt r e jk 0 rt r j implies pairwise incompatibility versions r r j limitations existing dsp compaction techniques motivate extended definition code compaction prob lem captures alternative versions side effects time constraints rtl basic block r set alternative encodings furthermore let denote set nooperations registers appear destinations rts bb let fnop g set alternative versions nop j 2 nop parallel schedule bb sequence r r j bb following conditions hold ffl cs 2 cs subset r ffl exists exactly one cs 2 cs contains encoding version r notation csr dd gamma r j r od dd gamma r j control steps contain nop version destination r ffl two encoding nop versions r control step cs 2 cs rtl basic block bb whose rt dependency graph critical path length l c timeconstrained code compaction tcc problem computing schedule cs given tmax 2 fl ng tcc decision variant optimal code compaction extended alternative encodings side effects thus npcomplete poses question problem sizes treated within acceptable amount computation time next section present solution technique permits compact basic blocks relevant size retargetable manner v integer programming formulation r ecently several approaches published map npcomplete vlsidesign related problems integer linear programming model eg 31 32 order study potential gains optimal solution methods compared heuristics ip problem computing setting n integer solution variables objective function fz minimized constraint integer matrix integer vector b although ip nphard thus excluding exact solution large problems modelling intractable problems ip promising approach following reasons ffl since ip based relatively simple mathematical notation easily verified ip formulation problem meets problem specification ffl ip suitable method formally describing heterogeneously constrained problems constraints often straightforward representation form linear inequations solving ip means constraints simultaneously taken account easily achieved problemspecific solution algorithm ffl since ip among important optimization problems commercial tools available ip solv ing ip solvers rely theoretical results operations research therefore considerably fast even relatively large integer programs using appropriate ip formulation thus often permits optimally solve nphard problems practical relevance approach tcc therefore largely based ip contrast wilsons approach 29 ip instances created manually automatically derived given compaction problem target processor model externally specified time constraint furthermore focusses problem code compaction extends size basic blocks handled practice given instance tcc first mobility range determined rt r tmax upper bound alap times rts solution variables ip model encode rt versions selected control step dependencies incompatibility constraints represented linear inequations solution variables defined control step numbers tmax constraint satisfaction required ip solution represents parallel schedule tmax control steps possibly padded nops turn nonexistence ip solution implies nonexistence schedule meeting maximum time constraint setting solution variables also accounts nops scheduled order prevent undesired side effects permit arbi trary multipleversion instruction formats meet following assumptions exists least one nop version addressable storage elements register files memories however nop sets single registers may empty a2 storage element written certain control step cs nop version scheduled independently rt versions assigned cs assumptions satisfied realistic processors permit insert nop versions compaction means version shuffling mechanism solution space compaction affected solution variables solution variables subdivided two classes indexed decision 01 variables vvariables tripleindexed r encoding version set e following vvariables version variables used interpretation vvariables rt r scheduled control step number version nvariables doubleindexed set nooperations following n variables nop variables used interpretation nvariables control step number contains nop destination register b constraints correctness conditions encoded ip constraints follows rt scheduled exactly ensured sum vvariables rt r equals 1 outputdependencies violated r data outputdependent r j scheduled control step cs r must scheduled earlier control step ie interval captured follows dd od dataantidependencies violated data antidependencies treated similarly previous case except r may also scheduled parallel r j live values destroyed side effects value single register x live control steps production consumption nop must activated x control steps contrast rigid handling side effects previous work 5 permit tolerate side effects ie nops registers activated two datadependent rts scheduled consecutive control steps conversely enforce schedule rts consec utively nop corresponding destination register exists modelled following constraints dd left hand side inequation becomes 1 exactly r scheduled r j scheduled case nop version x must activated cs nop present register replaced zero mechanism useful single registers tolerating side effects addressable storage elements possible n variables introduced element file different elements must distinguished however would imply intolerable explosion number ip solution variables instead mentioned earlier assume nop present addressable storage element compatibility restrictions violated two rts potential conflict least one pair conflicting versions nondisjoint mobility ranges neither datadependent outputdependent following constraints en sure one two conflicting versions scheduled control step cs c search space reduction ip model given compaction problem easily constructed corresponding rt dependency graph set partial instructions ip solution actual schedule immediately derived vvariables set 1 settings account detailed control step assignment selected encoding version rt based scheduling information nop versions packed control step means version shuffling control step cs demands nop register x indicated setting nvariables nop version nop js 2 nop determined compatible rts assigned cs existence version guaranteed assumptions a1 a2 x addressable storage nop version scheduled control step x written done independently setting nvariables computation times ip generation nop version shuffling negligible however important keep number solution variables low possible order reduce runtime requirements ip solv ing number solution variables reduced discarding redundant variables contribute solution space obviously nvariables occurring live value constraints superfluous elim inated vvariables redundant potentially increase parallelism efficiently checked advance selecting encoding version e im rt r control step cs useful exists rt could scheduled parallel ie r j meets following conditions 1 2 r 3 r j version e jm 0 compatible e im r j exists variables v imt equivalent terms parallelism sufficient single arbitrary representative advance pruning search space achieved computing tighter mobility ranges application ad hoc rules instance two rts r dad gamma r j cannot scheduled parallel encoding versions r r j pairwise conflicting efficacy ad hoc rules however strongly processordependent vi examples results tms320c25 first example consider code generation tms320c25 dsp also focussing interaction code compaction preceding code generation phases tms320c25 shows restrictive type instructionlevel parallelism making compaction nontrivial task even small programs demonstrate exploitation potential parallelism complex multiply program taken dspstone benchmark suite 2 computes product two complex numbers consists two lines code ar br ai bi vertical code generated code selection register allocation scheduling shown figure 2 real imaginary parts computed sequentially employing registers tr pr accu results stored memory next step insertion rts memory addressing record makes use indirect addressing capabilities dsps based generic model address generation units agus based variables access sequence basic block permutation variables memory cells computed maximizes agu utilization form autoincrementdecrement operation address registers 20 complex multiply computed ar ar br ar br ai bi ar br ai bi ar ar bi ar bi fig 2 vertical code complex multiply program address assignment ar insertion agu operations vertical code consists 25 rts shown figure 3 tms320c25 eight address registers turn addressed address register pointer arp case address register ar0 used optimized address assignment ensures address register updates realized autoincrementdecrement operations ar0 critical path length l c imposed interrt dependencies 15 table shows experimental data cpu seconds 1 number v nvariables ipbased compaction complex multiply code tmax values 15 21 theoretical lower bound tmax 15 solution exists actual lower bound schedule constructed less 1 cpu second beyond cpu time rises minutes due large search space investigated ip solver infavorable effect inherent ipbased formulation timeconstrained scheduling prob lem computation time may dramatically grow 1 integer programs solved ibms optimization subroutine library osl v12 ibm risc system 6000 point 5 ar point 1 br point 2 ai point 3 bi point 4 cr point 5 ar point 3 bi point 2 ai point 1 br point 0 ci fig 3 vertical code complex multiply program address assignment experimental results ipbased compaction complex multiply tms320c25 code solution vvars nvars 22 yes 281 64 number control steps even though scheduling problem intuitively gets easier therefore favorable choose relatively tight time constraints ie close actual lower bound tight time constraints ipbased compaction produces extremely compact code within acceptable amounts computation time figure 4 shows parallel schedule constructed tms320c25specific c compiler manual assembly programming yield higher code quality dspstone project 2 b motorola dsp56k ipbased code compaction specific code generation techniques used record essentially fig 4 parallel tms320c25 code complex multiply applied piece vertical machine code processors satisfying instructionset model second example consider compaction motorola 56000 code generated gnu c compiler gcc 33 compared tms320c2x m56000 regular instruction set parallelization arithmetic operations data moves hardly restricted encoding conflicts consequence number ip solution variables required computation time grow less strongly number control steps table ii exemplified rtl basic block length 23 extracted mpeg audio decoder program critical path length case 14 actual lower bound 19 control steps experimental results three blocks given table iii indicate exact compaction may save significant percentage instructions compared purely vertical compilergenerated code note case m56000 higher exploitation parallelism achieved late assignment variables different memory banks compaction 28 yet included approach c horizontal instruction formats permissible basic block length ipbased compaction inversely related degree instruction encoding weakly encoded formats compaction constraints mainly induced interrt dependencies critical path length close actual lower ii compaction runtimes gccgenerated m56000 machine code relation tmax solution vvars nvars 14 028 84 38 22 yes 222 92 22 67 yes 268 104 iii experimental results compaction m56000 machine code bound schedule length case runtime requirements low even larger blocks tight time constraints chosen hand weakly encoded instruction formats represent worst case presence loose time constraints due fact encoding constraints permit early pruning search space explored ip solver whenever rts large mobility ranges table iv demonstrated audio signal processing asip purely horizontal instruction mat experimental results given sumofproducts computation consisting 45 rts including agu opera tions critical path length 14 asip executes 4 rts per machine cycle actual lower bound meets theoretical limit tmax 2 14 17 schedules computed fast beyond much higher also less predictable previous experiments summary results indicate complex standard dsps tms320c2x m56000 represent upper bound processor complexity ipbased compaction reasonable processors blocks small medium size compacted within amounts computation time may often acceptable area code generation embedded dsps asips lower combinational delay design effort tend weakly encoded instruction format also larger blocks compacted however higher sensitivity towards specification time constraints context retargetable code generation limitations compensated high flexibility iv compaction runtimes asip horizontal instruction format relation tmax 26 347 68 22 85 390 72 general definition compaction problem ip formulation immediately applies complex dsp instruction sets exact compaction techniques reported far indicated previous work 30 significant runtime reductions expected restricted classes instruction formats vii conclusions f uture systemlevel cad environments need incorporate code generation tools embedded processors including dsps order support hard waresoftware codesign vlsi systems satisfactory compilers available generalpurpose processors yet case dsps partially due missing dedicated dsp programming languages causes mismatch highlevel language programs dsp architectures contrast generalpurpose computing compilation speed longer primary goal dsp code generation therefore largest boost dsp compiler technology expected new code optimization techniques expense high compilation times explore comparatively vast search spaces code generation also retargetability become increasingly important issue diversity applicationspecific processors creates strong demand flexible code generation techniques quickly adapted new target architectures contribution motivated described novel approach thorough exploitation potential parallelism dsp programs proposed ip formulation local code compaction timeconstrained problem based problem definition designated dsps removes several limitations previous work approach applies high quality code generation standard dsps asips capable optimally compacting basic blocks relevant size due general problem def inition peculiarities alternative encoding versions side effects captured provides retargetability within large class instruction formats since existing solutions guaranteed found believe exact code compaction feasible alternative heuristic techniques presence high code quality requirements research necessary extend timeconstrained code generation towards global constraints local techniques may serve subroutines turn demands closer coupling code compaction preceding code selection register allocation scheduling phases also mutual dependence retargetability code quality compilation speed studied detail order identify feasible compromises acknowledgments authors would like thank birger landwehr helpful comments integer programming issues steven bashford careful reading manuscript work partially supported european union esprit project 9138 chips r trends embedded systems technology code generation embedded processors verification hardware descriptions retargetable code generation dsp architect dfl users reference manual mimola language v 41 instruction set extraction programmable structures chess retargetable code generation embedded dsp processors flexware flexible firmware development environment embedded systems symbolic manipulation boolean functions using graphical representation efficient code generator generator automatic instruction code generation based trellis diagrams optimal code generation embedded memory nonhomogeneous register architectures code selection regular controlled term rewriting optimal code generation expression trees storage assignment decrease code size algorithms address assignment dsp code generation technique global microcode compaction development environment horizontal microcode unified code generation approach using mutation scheduling computers intractability guide theory npcompleteness experiments local microcode compaction horizontal chines motorola inc memory bank register allocation software synthesis asips integrated approach retargetable code generation conflict modelling instruction scheduling code generation inhouse dsp cores optimal vlsi architectural synthesis oscar optimum simultaneous scheduling using porting gnu cc v2 tr software scheduling cosynthesis reactive realtime systems oscar conflict modelling instruction scheduling code generation inhouse dsp cores instruction set definition instruction selection asips integrated approach retargetable code generation graph based retargetable microcode compilation mimola design system code generation embedded processors bddbased frontend retargetable compilers constrained software generation hardwaresoftware systems ctr r leupers p marwedel instruction selection embedded dsps complex instructions proceedings conference european design automation p200205 september 1996 geneva switzerland anne mignotte olivier peyran reducing complexity ilp formulations synthesis proceedings 10th international symposium system synthesis p5864 september 1719 1997 antwerp belgium luiz c v dos santos j heijligers c j van eijk j j van eijndhoven j g jess constructive method exploiting code motion proceedings 9th international symposium system synthesis p51 november 0608 1996 rainer leupers peter marwedel retargetable generation code selectors hdl processor models proceedings 1997 european conference design test p140 march 1720 1997 luiz c v dos santos j heijligers c j van eijk j van eijnhoven j g jess codemotion pruning technique global scheduling acm transactions design automation electronic systems todaes v5 n1 p138 jan 2000 peter marwedel code generation core processors proceedings 34th annual conference design automation p232237 june 0913 1997 anaheim california united states rainer leupers code generation embedded processors proceedings 13th international symposium system synthesis september 2022 2000 madrid spain gert goossens johan van praet dirk lanneer werner geurts augusli kifli clifford liem pierre g paulin embedded software realtime signal processing systems design technologies readings hardwaresoftware codesign kluwer academic publishers norwell 2001