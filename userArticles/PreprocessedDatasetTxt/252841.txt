view likelihood stability abstractwe define two measures views view likelihood view stability view likelihood measures probability certain view given 3d object observed may used identify typical characteristic views view stability measures little image changes viewpoint slightly perturbed may used identify generic views definitions shown identical prior probability camera orientations determined 2d metric used compare images analytically derive stability likelihood measures two featurebased 2d metrics stable likely view shown flattest view 3d shapeincorporating view likelihood stability 3d object recognition 3d reconstruction increases chance robust performance particular propose use measures enhance 3d object recognition 3d reconstruction algorithms adding second step likely solution selected among feasible solutions applications demonstrated using simulated real images b introduction paper address systematic way loose notions characteristic views generic views precisely defining computing view likelihood view stability incorporating measures object recognition 3d reconstruction argue increases chance robust predictable performance illustrate point start intuitive example consider three images shown top row fig 1 given three objects database illustrated bottom row fig 1 cube flat box elongated box recognition research sponsored arpa us office naval research grant n000149311202 rt project code 442434101 system asked match object image images produced way left image actually picture cube middle image picture flat box right image elongated box typical good computer vision recognition system would correctly produce output shown fig 1 white arrows however human looking images would prefer following interpretation left image flat box middle image elongated box right image cube shown fig 1 thin black arrows would humans make mistake answer seems good computational reason b c figure 1 three polyhedral objects cube dimensions 1 theta 1 theta 1 cm b flat box dimensions 5 theta 5 theta 1 cm c elongated box dimensions 5 theta 1 theta 1 cm top three images objects obtained special viewpoints extracted features shown dark circles bottom polyhedral objects viewed typical viewpoint geometrybased recognition system would correctly recognize image top row instance object illustrated bottom row matching shown thick white arrows maximum likelihood recognition system would recognize images top row elongated box right cube matching shown thin black arrows thus motivate work paradoxical example although wrong black arrows fig 1 give statistically optimal answer example words system gives wrong answer example behaves better overall mislead solutions imply special viewing positions problem illustrated fig 1 limited simple artificial objects generally applies many complex natural objects whose images may ambiguous take fig 2 example based matching alone recognition system database models water bottles figure 2 non generic unlikely image waterbottle viewed often interpreted image glass saucer frisbee frisbees glass saucers cannot determine object depicted image enhanced recognition system examine three solutions choose likely one either frisbee glass saucer reject correct less generic waterbottle solution unless given good reason favor existence water bottles scene thus problem dealing general would plague recognition system deals large databases problem arises 3d object recognition 3d reconstruction algorithms address geometrical matching issue 3d interpretation object described given 2d image many cases good matching algorithm correctly provide list feasible solutions objects reconstructed scenes consistent image uncertainty value arising measurement errors select among solutions necessary enhance algorithm disambiguation criteria similar used humans interpreting images fig 1 propose use disambiguation measures view likelihood stability choose typical generic solution view likelihood measures probability certain view given object observed characterizes typical view view stability characterizes generic view measures little image changes viewpoint slightly perturbed show measures identical prior probability camera orientations show obtain view stability view likelihood 2d metric used compare images rest paper organized follows reviewing related work section 2 define concepts stability likelihood images general objects section 3 general case provide fairly simple expressions describing likelihood stability views one needs plug particular 2d metric tells images apart section 4 develop explicit analytical expressions stability likelihood views objects feature points depend three principal second moments object stable likely view shown flattest view object section 5 demonstrate usefulness theory 3d reconstruction object recognition using examples simulated real objects show measures view likelihood stability 1 easy use 2 enhance performance incorporated existing 3d reconstruction object recognition techniques previous work review comparison recent studies attempted approach formal way issues related ones discussed paper bayesian image understanding freeman 10 11 suggested use measure view stability interpretation ambiguous scenes see also 21 bayesian scheme interpretation involves stable generic viewpoint preferred freemans approach closest following differences one hand freeman uses complete probabilistic framework image errors due fact image instance object transformed probabilities taken account prior models also taken account hand freeman computes image likelihood using jacobian transformation viewing parameters image measurements true view likelihood image measurements normalized uncertainty form euclidean space rarely case see section 35 definition view likelihood therefore general allows computation view likelihood given 2d metric used compare images using observation likelihood measure incorporated freemans bayesian probabilistic scheme taking role conditional image probability measuring likelihood view likelihood angles computed using numerical simulations benarie 3 burns et al 6 dickinson et al 8 empirically found likely views particular objects decomposed geons earlier work analysis likelihood carried simple image measurements either discrete qualitative 1dimensional angles note however general problem requires numerical estimation likelihood image measurements change continuously viewing parameters computation harder requires numerical estimation limits thus simulation work described 3 6 8 cannot readily generalized compute view likelihood general objects provide simple expression used numerically estimate stability likelihood profiles general objects identify likely stable views object measuring stability binford levitt 4 defined concept quasiinvariants local minima change image changing viewing parameters studies proposed measure stability via lie derivatives group transformations describing motion camera 15 earlier work analysis stability rarely went beyond basic definitions different definition another line work may superficially appear similar addresses different question practically probabilistic approaches image understanding take account image likelihood defined exception 10 rather goal transform optimization problem maximum likelihood problem achieved defining probability function large error small vice versa see eg 17 thus likely solution selected end solution minimizes measurement error using terminology introduced introduction probabilistic schemes still try accomplish first step recognition seek solution minimizes error predicted image observed image address problem choose among equally plausible solutions namely choose among solutions achieve roughly error thus approaches object recognition readily enhanced view likelihood measure using finetune probability space take account error minimization high plausibility genericity qualitative analysis presented identifies stable likely views objects suitable images used objects characteristic views concept characteristic views appears viewercentered approaches 3d shape representation three dimensional information represented explicitly rather shape object represented implicitly list 2d characteristic views eg 7 study first give computational analysis makes images characteristic 3 stability likelihood views general define measures view likelihood stability assigned general 3d object denoted projection along specific viewing direction measures depend variability images object thus depend 2d metric used compare images eg featurebased intensitybased section general problem 2d metric yet fixed addressed assume general three dimensional objects including opaque objects self occlusions 31 images viewing sphere first describe parameterize possible different views 2d images 3d objects obtained parameterization different viewpoints camera orientations 3d object observed viewing sphere imaginary sphere around centroid object assume perspective projection therefore viewing sphere describes possible different orientations camera respect object since camera orientation corresponds point viewing sphere objects images completely parameterized two angles following denotes azimuth longitude denotes elevation colatitude range parameterizes half viewing sphere let v denote viewpoint viewing sphere elevation azimuth let denote 2d image view object obtained viewpoint v define second parameterization viewing sphere parameterization relative respect given viewpoint v relative parameterization ffi denotes azimuth denotes elevation time measured respect viewpoint dy viewing sphere centroid object qj dy viewing sphere centroid object qj figure 3 two views viewing sphere v v ffi v serves pole see fig 3 danger notation abuse denote viewpoints parameterized v ffi let ffio denote 2d image view object obtained viewpoint v ffi 32 images differ stability likelihood view fundamentally depend similar views object intuitively typical generic view one similar many views object vice versa therefore need able measure similarity views henceforth assume lack similarity measured distance measure takes two views arguments returns distance distance measure present discussion section 3 develop dependence view likelihood stability distance function whichever may later section 4 compute view likelihood stability specific cases substituting specific distance measures view likelihood stability image measured answer question assume optical axis camera initially oriented along viewpoint v camera rotated ffi observe object viewpoint v ffi depending initial camera orientation v difference initial final images ffio may large small words rotated camera fixed amount ffi image object may change slightly fig 4ab change may large fig 4de intuitively view stable difference ffio small fig 4ab unstable difference large fig 4de rotating camera away original viewpoint v say likely cause much larger change rotating 4ac clearly affect magnitude view likelihood stability therefore use normalized distance ffi limit ffi vanishes let ffi denote 2d distance 2 views ffio intuitively good indicator view likelihood stability obtained normalized distance ffi limit denote function note since ffi b c e f figure 4 top stable view cube b view obtained camera rotated 10 c view obtained camera rotated 20 bottom less stable view cube e view obtained camera rotated 10 f view obtained camera rotated 20 0 viewpoint following holds discussion view stability likelihood made precise 33 stability views view stability image measures much image changes viewpoint v slightly perturbed quantity takes larger values image change much cameras position changed specifically ffi dffio measures normalized similarity 2 images obtained 2 camera orientations separated ffi view stability defined average normalized similarity small neighborhood viewpoints limit area neighborhood vanishes precisely 0 rsinffidffid assuming 6 0 8 0 rsinffidffid 34 likelihood views view likelihood probability induced images object projection process given prior distribution camera orientations viewpoints different probability induced views projection process implies example even different camera orientations equally likely images equally likely induced probability depends 3d structure object almost never uniform specifically denote prior distribution camera orientations fv distribution induces via projection process different distribution images denote l l conditional probability see particular image given image known object definition therefore view likelihood first note l density function order compute value density function l point x one proceed computing cumulative distribution appropriate random variable differentiate obtain density random variable cumulative distribution typically easier compute measures probability real rather infinitesimal event probability random variable obtains value interval x gamma case event j ffi j namely compute probability camera obtains viewpoint object appears different less denoting b function returns 1 b true 0 otherwise sinffidffid 2 1 follows near substituting 2 assuming 6 0 8 get 3 measures cumulative distribution corresponding area viewing sphere corresponding density function proportional rate increase area precisely 0 substituting 3 4 computing value limit 0 get following expression view likelihood object 5 recall f denotes prior distribution camera orientations 35 likelihood views numerical evaluation rest paper primarily use 5 obtain analytical expressions view likelihood stability however distance images complex numerical estimation view likelihood possible integral 5 may hard evaluate thus derive another expression view likelihood depends derivatives 2d image distance respect viewpoint parameters keep focus paper derivations briefly described thinking projection 3d space 2d image transformation coordinates obtained f using jacobian transformation euclidean spaces jacobian measures area element one coordinate system viewing sphere changes another coordinate system image space specifically image represented vector x 2 r n transformation image space r n euclidean distance 2 images x l 2 norm area element viewing sphere sin dd locally deforms det mm general metric case distance 2 images x arbitrary good local area deformation shown det mgxm 1 note 4 cumulative probability divided 2 parameter space 2dimensional thus differentiation obtained dividing infinitesimal area element length agood metric locally approximated first order euclidean distance elements matrix mgxm kl x l substituting 6 area deformation becomes det mgm image likelihood corresponds area deformation caused inverse mapping image space viewing sphere therefore 36 likelihood stability views summary let denote 2d distance 2 images ffio view likelihood l view stability image following 8 view stability likelihood also computed following expression also interested 2 qualitative characterizations views likely view satisfies stable view satisfies follows 9 1 prior distribution camera orientations given object uniform namely viewpoints equally likely 1 view stability likelihood functions 2 stable likely views image result able restrict discussion henceforth view stability order obtain view likelihood expression multiplied prior distribution camera orientations 4 stability likelihood views featurebased metrics previous section derived dependence view stability likelihood 2d metric used compare images show usefulness general approach derive explicit forms view likelihood stability given two specific featurebased 2d matching metrics given objects composed feature points exist natural 2d metrics compare images objects 20 affine metric aff two images first aligned best 2d affine transformation sum squared distances pair matching feature points taken similarity metric sim two images first aligned best 2d similarity transformation sum squared distances pair matching feature points taken simplified expressions metrics derived next using coordinate system rotated v 00 flattest view object flattest view view image achieves maximal spread obtained viewing direction along three dimensional object minimal spread 41 image representation denote coordinates object features initial camera coordinate system r 3 three dimensional representation object 3 theta n matrix whose ith column vector describing world coordinates ith feature object image object approximated rigid transformation object camera followed weak perspective scaled orthographic projection three dimensional space two dimensional image image object therefore set n image points equivalent representation image 2 theta n matrix p whose ith column p vector image coordinates ith feature object 42 2d image comparison given two images two matrices p q question comparing equivalent matrix comparison using usual metric frobenius norm difference matrix euclidean distance points images tr denotes trace matrix henceforth shall omit subscript f matrix norm frobenius norm default taking norm difference images want remove differences due irrelevant effects size image arbitrary scaled orthography exact location object eg due arbitrary translation rotation object image particular consider equivalent images obtained one following two groups two dimensional transformations similarity group includes 2d rotations translations scale affine group includes 2d linear transformations translations readily shown optimal translation measuring distance sum square differences similarity affine equivalence puts centroid object origin image therefore assume wlog images centered centroid object first moment image 0 20 defined image metrics compare images p q taking account desired image equivalences discussed get following expressions similarityequivalence metric sim p q affineequivalence metric aff sim denotes pseudoinverse matrix 43 flattest view image p obtained viewpoint v object weak perspective projection v 3d orthogonal matrix let denote 3 theta 3 symmetric autocorrelation scatter matrix object viewpoint v definition 1 flattest view view obtained parallel projection object viewpoint v whose scatter matrix diagonal eigenvalues diagonal ordered decreasing order let f denote scatter matrix flattest view b c 0 b c 3 principal second moments object recall symmetric matrix always diagonalized similarity transformation orthogonal matrix diagonalization initial scatter matrix 00 equivalent rotation coordinate system defining object shape matrix p thus easy compute rotation object initial representation flattest view correspond v 00 rotation orthogonal matrix diagonalizes original scatter matrix object 00 unique rotation around optical axis camera henceforth assume wlog viewing sphere initially parameterized v 00 flattest view example consider three dimensional straight corner object composed points 1g centering object three principal second moments note 1 flattest view object shown fig 5 figure 5 flattest view straight corner 44 distance two views defined section 31 let v v ffi denote 2 viewpoints viewing sphere given object let ffi denote image distance corresponding images ffio ffi one two distance metrics defined 13 simplified expressions affine distance aff ffi similarity distance sim ffi given appendix general expressions given 16 17 derived object whose 3 principal moments 3 eigenvalues autocorrelation matrix feature points abc ab cos immediately follows similarity affine metrics ffi depends 3 principal second moments b c object regardless number features object distribution space result shows 3 principal second moments object completely characterize stability likelihood views regardless particular shape object note result assumption analysis 45 view likelihood stability substituting aff sim definition 8 similar results obtained substituting 13 10 obtain view stability object whose 3 principal moments b c image metric defines different measure abc follows expressions eg differentiation 3 characteristic views ffl aspect affine similarity 2d metrics b c stable view unique flattest view v 00 ffl stability flattest view ab c similarity metric ab c affine metric ffl stability viewpoint v decreases monotonically geodesic distance flattest view affine similarity 2d metrics proof result follows immediately 1415 clearly maximum point aff sim object b c differentiating respect shown functions everywhere monotonically decreasing corollary 4 given 2d image without additional information 3d structure likely interpretation flattest view implying image represents frontoparallel flat object corollary justifies heuristic assigns depth 0 points whose depth unknown optimal decision based available information one image fact heuristic typically employed iterative reconstruction algorithms assign depth 0 default value first iteration eg 13 5 applications enhanced object recognition reconstruction following examples illustrate various applications view likelihood object recognition 3d reconstruction start computing characteristic views section 51 section 52 demonstrate maximum likelihood 3d object recognition using simulated images section 53 demonstrate maximum likelihood 3d reconstruction applications take advantage dependence view likelihood l object treating l function estimate using maximum likelihood estimation object maximizes view likelihood chosen among possible objects 51 characteristic views seems plausible choose characteristic view aspect object stable likely view aspect section 4 identify characteristic view n features flattest view features frontoparallel view 3 features illustrate result shall compute flattest view aspect specific objects aspect includes views object features visible first obtain representation canonical coordinate system assumed section 43 1 translate coordinate system centroid visible feature points aspect 0 0 0 2 rotate coordinate system scatter matrix visible feature points diagonal matrix diagonal elements decreasingly ordered given square nontransparent pyramid whose nodes f0 0 2 1 0 0 0 analyze aspect 4 feature points 3 basis nodes f1 0 0 0 top pyramid 0 0 2 visible flattest view aspect shown fig 6 flattest view box one aspects also shown fig 6 fig 5 shows flattest view straight corner 52 maximum likelihood object recognition return example discussed introduction illustrated fig 1 given large database includes 3 polyhedral objects shown bottom row fig 1 object database represented coordinates set feature points 8 vertices case 3 polyhedral objects recognize 3 images shown top row fig 1 proceed follows figure flattest views two opaque objects square pyramid box dimensions 40 theta 30 theta 25 step 1 geometrical object recognition featurebased object recognition technique eg alignment 14 geometric hashing 16 first used compute list candidate objects match given images order predict objects system finds without simulating actual algorithm perform following metaanalysis compute modeltoimage distances 3 described 2 evaluate well object fits image objects achieve small modeltoimage distance feasible matches geometrical object recognition methods therefore assume objects achieve subthreshold modeltoimage distance chosen object recognition method choice modeltoimage distances given table 1 left image middle image right image cube elongated box 00005 0 0009 0 0 0 table 1 modeltoimage distances 3 objects database cube flat box elongated box 3 images shown top row fig 1 distances 2d similarity transformation given whereas distances 2d affine transformations given parentheses whenever numbers small means exists viewpoint object appears similar image 2d rotation scale follows affinebased recognition algorithm geometric hashing linear combination 18 produce set 3 objects feasible matches image assuming error threshold tolerance 005 similaritybased algorithm alignment produce shorter lists ffl left image fcube flat box elongated boxg ffl middle image fflat box elongated boxg ffl right image felongated box cubeg 3 modeltoimage distance measures distance closest view object given image 2d image transformation first object list matches image exactly corresponds matching shown thick white arrows fig 1 second object list predicts image quite well difference illustrated fig 7 corresponds matching shown thin black arrows fig 1 b c figure 7 images top row fig 1 matched likely object illustrated thin black arrows fig 1 matching precise image difference closest view recognized object image shown step 2 maximum likelihood object recognition view likelihood used select best interpretation list produced geometrical object recognition algorithm assume uniform prior l computed obtained possible solution step 1 likelihood closest view object image computation one feasible objectimage pair described detail appendix b table 2 contains view likelihood values objectimage left image middle image right image cube 224 116 26 136 312 16 flat box 132 194 116 036 112 176 elongated box 009 048 276 612 015 01 table 2 entry table corresponds pair objectimage two numbers given entry similarity stability defined 15 affine stability defined 14 closest view object image nonfeasible solutions lists produced step 1 algorithm given parentheses thus mostlikely moststable interpretation image based either affine similarity metrics left image flat box least 6 times likely object middle image elongated box order magnitude likely object suggested alignment method right image cube according similarity metric affine metric cannot decide cube flat box return likely solutions reading table 2 rows see likelihood images cube symmetrical object vary much less likelihood images flat box elongated box eigenvalues cube differ much less note limit images object equally likely 53 maximum likelihood reconstruction exist cues 3d structure many reconstructions feasible view likelihood may used select best among solutions consideration cf 10 describe 2 examples process one object fiducial points shaded smooth object examples assume prior viewing sphere uniform thus view stability view likelihood identical used interchangeably 531 object matching using fiducial points figure 8 battery charger real dimensions depth 225 length 28 height 19 cm normalized length maximum likelihood estimation dimensions gives depth 195 height 21 consider battery charger picture shown fig 8 text object know object battery charger presumably know battery chargers boxlike shape task compute dimensions scale charger image coordinates 7 visible vertices chargers enveloping box follows computation described appendix c likely interpretation picture box dimensions 195 theta 21 theta 28 whereas actual dimensions charger 226 theta 191 theta 28 cm thus picture interpreted bit flatter shorter really 532 matching smooth objects using grey levels order compute stability likelihood gray level images assume fixed lighting source knowledge reflectance map object distance similarity normalized gray level pictures pictures normalized scale say 1 main axis aligned along xaxis example taken sum squared differences gray levels computed stability distance function numerically lambertian ellipsoids consider ellipsoids fig 9 length first two axes ellipsoid left immediately measurable picture height depth derived gray levels want select best interpretation height ellipsoid given picture noisy pick likely height distance rendered pictures small less 5 gray level values per pixel average results choosing flatter ellipsoid parameters 1 2 32 instead 1 2 5 flattening effect consistent psychological evidence humans 5 note human judgment takes account many priors heuristics kind shapes one likely encounter thus expect see correspondence human performance stable views rather simple impoverished conditions images lambertian ellipsoids figure 9 left rendering ellipsoid principal axes length 5 right rendering likely reconstruction left picture ellipsoid principal axes length 1 2 32 6 summary described obtain characteristic views one use view likelihood measures typical image view stability measures generic image measures identical prior distribution camera orientations uniform showed compute measures general case given 2d metric tells images apart elaborated two examples featurebased image metrics incorporation measures 3d object recognition 3d reconstruction likely increase robustness system appendices affine similarity distances using maple c fl simplified ffi two metrics defined 13 similarity metric get sim ffi sin sin ffi sin cos sin sin affine metric get sin sin sin cos calculating view likelihood stability go details computation l one ob jectimage pair flat box left image fig 1 1 take stored 3d coordinates set 7 matching vertices flat box translate rotate described appendix 43 v 00 flattest view let p denote 3 theta 7 matrix representing model flat box whose 3 principal eigenvalues 025 7 visible vertices flat box transformation canonical system are6 4 02 gamma02 gamma02 02 02 02 gamma02 gamma12 gamma12 019 021 16 021 019 024 gamma016 gamma024 016 0076 016 gamma0247 5 2 using algorithm described 2 compute view similarity transformation flat box closest left image let p denote 2 theta 7 matrix representing image 035 047 14 13 gamma059 gamma15 gamma14 gamma099 gamma12 070 087 15 gamma037 gamma054 difference view flat box left image 001 see table 1 fig 7a shows closest view flat box superimposed left image 3 compute angles sin cos 0 pi orthographic projection matrix scalar 2 0 2 representing rotation object image plane therefore need solve following denotes pseudoinverse p equation unique solution range 2 0 2 0 2 since started matrix p real projection rotation matrix p simplest way compute solve matrix equality elementbyelement matrices p p flat box get substitute values radians 1415 obtain measures view likelihood view stability left image compared flat box c maximum likelihood reconstruction denote dimensions charger shown fig 8 theta h theta 28 depth charger h height 28 length front face scales remaining measurements find best reconstruction charger search parameter space h 2 stages 1 first compute modeltoimage distance model picture gives us function shown fig 10 picture correct model obtains small image error shown fig 11leftdh20000 figure 10 modeltoimage distances function parameters h picture shown fig 8 coordinates drawn log scale ranges 2 14 86 h 2 145 gamma 41 figure 11 left view correct model obtains small modeltoimage distance superimposed image original vertices charger right view likely model superimposed original vertices clearly interpretations match data reasonably well 2 estimate upper bound noise image 4 times 3daffine distance model image 4 among models whose modeltoimage distance smaller noise threshold choose likely one based view likelihood best view model fig 12 shows likelihood interpretations modeltoimage distance smaller noise threshold function computed described object recognition example section 52dh005015025 figure 12 likelihood picture shown fig 8 function parameters h coordinates drawn log scale ranges 41 likelihood set 0 parameter values modeltoimage distance larger noise threshold left image gives l aff right l sim acknowledgments thank bill freeman davi geiger amnon shashua yuval peres yael karshon dror barnathan many useful discussions suggestions r informational aspects visual perception distance metric 3d models 2d images recognition classification probabilistic peaking effect viewed angles distances application 3d object recognition theory exploitation interaction different modules depth perception view variation pointset line segment features characteristic views basis threedimensional object recognition quantitative study shape pattern perception exploiting generic view assumption estimate scene parameters generic viewpoint assumption framework visual perception measures silhouettes resemblance representative silhouette curved object perceptual buildup threedimensional structure motion recognizing solid objects alignment image group theoretical methods image understanding geometric hashing general efficient recognition scheme distributed bayesian object recognition linear combinations models distance metric 3d models 2d images recognition classification similarity affine distance point sets role structure vision tr ctr lance c burton raghu machiraju donna reese dynamic viewdependent partitioning structured grids complex boundaries objectorder rendering techniques proceedings 1999 ieee symposium parallel visualization graphics p8996 october 2526 1999 san francisco california united states stanislav l stoev wolfgang straer case study automatic camera placement motion visualizing historical data proceedings conference visualization 02 october 27november 01 2002 boston massachusetts ronen basri yael moses possible identify 3d objects single images using class constraints international journal computer vision v33 n2 p95116 sept 1999 sven j dickinson john k tsotsos david wilkes computational model view degeneracy ieee transactions pattern analysis machine intelligence v21 n8 p673689 august 1999 ariel tankus yehezkel yeshurun sceneconsistent detection feature points video sequences computer vision image understanding v97 n1 p129 january 2005 chang ha lee amitabh varshney david w jacobs mesh saliency acm transactions graphics tog v24 n3 july 2005 yoram gdalyahu daphna weinshall flexible syntactic matching curves application automatic hierarchal classification silhouettes ieee transactions pattern analysis machine intelligence v21 n12 p13131328 december 1999 christopher cyr benjamin b kimia similaritybased aspectgraph approach 3d object recognition international journal computer vision v57 n1 p522 april 2004