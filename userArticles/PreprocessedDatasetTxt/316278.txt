stabilized sequential quadratic programming recently wright proposed stabilized sequential quadratic programming algorithm inequality constrained optimization assuming mangasarianfromovitz constraint qualification existence strictly positive multiplier possibly dependent constraint gradients proved local quadratic convergence result paper establish quadratic convergence cases strict complementarity mangasarianfromovitz constraint qualification hold constraints stabilization parameter relaxed linear convergence demonstrated parameter kept fixed show analysis method carried using recent results stability variational problems b introduction let us consider following inequality constrained optimization problem minimize fz subject cz 0 z 2 r n 1 f realvalued c r n lagrangian l defined denote current approximation local minimizer z associated multiplier 1 sequential quadratic programming sqp algorithm new approximation z k1 z given z deltaz deltaz local minimizer following quadratic problem z subject cz k various ways specify new multiplier often k1 multiplier associated constraint quadratic problem 2 typical convergence theorem 2 example see robinsons paper 16 states z neighborhood solutionmultiplier pair z associated 1 iteration quadratically convergent following conditions hold r1 gradients active constraints linearly independent r2 multipliers associated active constraints strictly positive exists scalar ff 0 z lz w ffkwk 2 3 w satisfying rc z constraint gradients linearly dependent quadratic convergence sqp algorithm lost even simplest cases example consider problem subject z 2 0 4 unique solution z nonnegative number multiplier approximation k held fixed 0 z 0 0 0 1 iteration reduces z iteration reduces z either case convergence linear wrights stabilized sequential quadratic programming algorithm 19 obtained applying rockafellars augmented lagrangian 18 quadratic program 2 penalty parameter iteration k z local minimax problem min z z wright shows method locally quadratically convergent following conditions hold w1 mangasarianfromovitz 15 constraint qualification mfcq holds context inequality constrained problem 1 means exists cz rcz 0 exists multiplier vector whose components associated active constraints strictly positive fixed ff 0 coercivity condition 3 holds choices satisfying following firstorder conditions r z lz w4 parameter ae k tends zero proportional error z notice w1 weaker r1 since may exist cz even constraint gradients linearly dependent hand mfcq hold example 4 cases equality constraint written pair inequalities let us consider stabilized iteration 5 example 4 z 0 near z two cases consider depending choice sufficiently large example z 2 solution 5 maximizing positive successive iterates given z hence ae error step k z implies local quadratic convergence solution z second case corresponds situation maximizing 5 van ishes happen must z 2 k new iterate z ae z cases convergence solution z locally quadratic also notice example choosing ae k much smaller error step slow convergence particular ae max changed sup 5 scheme 5 reduces usual sqp iteration 2 convergence example 4 linear hand still obtain fast convergence even ae k much larger error step k example convergence likewise initial inequality 8 implies z 2 combines 9 give z k1 z 3 either case ae k 0 fixed obtain cubic convergence near solution z hence implementational viewpoint large ae k safer small one example quadratic convergence preserved stabilized sqp scheme even though strict complementarity mfcq violated fact strict complementarity violated convergence one step paper show general wrights stabilized scheme locally quadratically convergent even though mfcq strict complementarity violated contrast wrights assumption w3 secondorder condition holds multipliers give paper local analysis secondorder condition required hold given solutionmultiplier pair z strict complementarity violated secondorder condition slightly stronger usual secondorder condition assume z lz w satisfying rc z strengthened form secondorder sufficient condition first appears robinsons study 17 lipschitz stability optimization problems dontchev rockafellar show condition along linear independence active constraint gradients necessary sufficient lipschitz stability solution multipliers canonical perturbations problem constraints cost function strong secondorder sufficient condition stable sense holds r 2 z lz rc z replaced nearby matrices usual secondorder condition unstable problem perturbations usual secondorder sufficient condition imposes w 10 additional constraint rc z w 0 every c z must hold w set usual secondorder condition holds pair z perturb constraint cz 0 cz otherwise perturbed problem z satisfies first order conditions however active constraints perturbed problem precisely constraints unperturbed problem positive multipliers therefore even though usual secondorder sufficient condition holds z small perturbations constraints yield problem whose stationary point satisfy condition analysis 5 based application tools stability analysis introduce parameters iteration map study map depends parameters using stability result established 4 lemma 21 understand iteration map depends parameters write convergence theorem applications stability theory convergence algorithms analysis discretizations appear 3 4 5 6 11 analysis 5 also leads new expression error iterate particular show linear convergence achieved ae k fixed small paper revised version report 12 another approach dealing degeneracy nonlinear programming developed fischer 9 approach original quadratic program 2 retained however multiplier estimate gotten solving separate quadratic program fischer obtains quadratic convergence assuming mfcq secondorder sufficient optimality condition constant rank condition active constraint gradients neighborhood z condition concerning representation cost function gradient terms constraint gradients although assumptions seem stringent used analysis wrights method parameters like ae k fischers method must specified iteration 2 convergence theory let z denote local minimizer 1 let associated multiplier satisfying firstorder conditions 6 state assumptions partition c g h components h correspond components c associated strictly positive components components g remaining components c associated components could zero let denote set multipliers associated local minimizer z 1 letting b ffi z denote ball center z radius ffi main result theorem 1 suppose f c twice lipschitz continuously differentiable neighborhood local minimizer z 1 associated multiplier 0 z lz w rhz choice constant oe 0 sufficiently large exist constants oe 1 ffi fi property oe 0 ffi oe 1 starting guess z z k1 strict local minimizer stabilized problem 5 k1 unique maximizer 5 associated z z k1 ae k scalar satisfies condition moreover following estimate holds k1 closest elements k k1 respectively theorem 1 letting ae k go zero proportional total error leads local quadratic convergence techniques estimating error current iterate found 13 19 since theorem 1 local convergence result assume without loss generality cz constraint inactive z simply discard constraint apply theorem 1 reduced problem obtaining neighborhood iterations converge holds constraint included c shown z near z associated component maximizing multiplier 5 vanishes hence iterates obtained either without inactive constraint included c identical although equality constraint appear explicitly 1 include equality constraint writing pair inequalities ez 0 one constraint functions included g h infinite number multipliers associated pair constraint functions linearly dependent gradients always arranged associated component strictly positive throughout paper k delta k denotes euclidean norm fi denotes generic positive constant different values different equations bounded terms derivatives second order f c neighborhood z terms fixed constants like ff 11 order prove theorem 1 recast 5 form perturbed variational inequality let function defined r z lz r 2 z ae regarded parameters since later impose constraint ae terms p 12 make ae explicit argument study properties solutions following inclusion relative parameters find z n usual normal cone 0 2 n 0 analyzing solutions 15 depend p establish theorem 1 z local solution 5 solution 15 case 15 represents firstorder optimality conditions associated 5 explicitly 15 implies z conditions 17 18 equivalent saying k1 achieves maximum 5 corresponding z z k1 standard rules differentiating maximization see 2 derivative extremand 5 respect z obtained computing partial derivative respect z evaluating resulting expression extremand maximized hence 16 equivalent saying derivative extremand respect z vanishes observe arbitrary element solution 15 section apply following stability result describing solution 15 changes p changes obtain theorem 1 proof stability result given next section lemma 1 hypotheses theorem 1 choice constant oe 0 sufficiently large oe 1 0 exist constants fi ffi oe 0 ae satisfying 15 unique solution z moreover every p 1 satisfying 19 associated solutions 15 three parts proof theorem 1 initially show estimate 13 holds z solution associated next show z sufficiently close z construct sequence z contained fixed ball centered z unique solution n ae k finally show unique solution z 15 z k1 local minimizer 5 part 1 error estimate let oe 1 0 fixed scalar independent let oe 0 ffi chosen accordance lemma 1 lemma 1 exists property unique solution z ae scalar satisfies condition apply lemma 1 taking k near k near since k suppose close enough p ae note 19 holds assuming ae chosen 19 holds follows 20 z expanding e k taylor series around z gives fi generic positive constant second inequality 25 obtained using relation ab combining 22 23 25 establishes estimate z k1 theorem 1 dividing 24 ae gives utilizing lower bound ae oe 0 kz k gamma z k follows hence dividing 22 ae referring 26 deduce triangle inequality combining 27 gives shows k1 near z show order establish exploit lipschitz continuity r z l bound 22 observation k1 near obtain expanding r z lz taylor series around z k substituting 16 gives kr z lz z z z triangle inequality squaring gives shown squaring combining 31 32 34 gives kr z lz combining 30 yields completes proof 29 prove 33 focus individual components relation three cases consider components 35 triviality complementary slackness 18 expanding cz k taylor expansion around z k1 utilizing 32 taking absolute values yields dividing 36 ae utilizing 37 26 gives 35 dividing ae utilizing 37 26 gives 35 completes proof 33 29 consider following system linear equations inequalities r z lz system feasible since 2 solution 29 result hoffman 14 closest solution k1 38 k1 satisfies hoffmans result states linear system inequalities feasible distance given point set feasible points bounded constant times norm constraint violation given point 29 norm constraint violation fi e k k1 follows distance k1 closest solution 38 bounded constant times cz solution 38 contained closest element k1 relations 25 39 combine complete proof 13 part 2 containment collecting results shown sufficiently close p unique solution z n ae ae scalar satisfying 21 z k1 k1 satisfy 13 k1 also satisfies 28 oe 1 ffi lemma 1 decreases constant fi 20 kept fixed since set ae p satisfies constraints lemma becomes smaller 20 holds one set ae p values holds subsets let fi constant appearing 13 estimated part 1 using lemma 1 given positive ffl 1 let us choose oe 1 ffi lemma 1 small enough analysis part 1 13 28 exists unique solution z 15 fi 0 denotes specific constant fi appearing 28 show inductive fashion z sufficiently close z exists sequence z unique solution 15 n ae k corresponding ae k satisfying 40 particular let r 0 chosen small enough starting z 0 z proceed induction suppose contained b r 1 exists unique solution z follows 42 43 combining 43 44 yields hence z z induction complete part 3 local minimizer finally show z k1 local minimizer 5 since taking r 0 sufficiently small k complementary slackness 18 noted 18 z solution 15 achieves maximum 5 z z k1 since maximizing 5 continuous function z see 3 lemma 4 conclude z near z k1 maximizing 0 hence complementary slackness z near z k1 maximizing given making substitution 5 cost function minimax problem decomposed sum convex function z strongly convex part z first part convex since extremand linear function z max sum less equal sum maxs second part strongly convex since hessian matrix z ae k positive definite ae k r 0 sufficiently small lemma 3 appendix hence cost function 5 strongly convex function z neighborhood z k1 since derivative vanishes z k1 16 z k1 local minimum completes proof theorem 1 3 stability linearized system proof lemma 1 based following result variation lemma 21 4 lemma 2 let x subset r n let k delta k ae denote norm x given words w intersection closure x ball center w radius suppose f maps w subsets r p set let p theta n matrix let j ffl fl denote positive numbers fflfl 1 following properties hold set n oe ft w following problem unique solution find x 2 x lx x denotes solution corresponding p 2 p exists unique w 2 w w p 2 f w moreover every denotes w associated p proof fix denote solution 45 corresponding observe w contraction w contraction constant ffl assumption w given w 2 w since banach contraction mapping principle exists unique w 2 w equivalent w p 2 f w w 2 w conclude unique w 2 w w denote associated solutions w p 2 f w rearranging inequality proof complete proof lemma 1 order apply lemma 2 defined 14 identify w x pair z identify p triple z choose set p chosen later neighborhood z presenting linearization l lemma 2 partition constraint function c multiplier components g h respectively linearization l delta p around w given z c b z lz order apply lemma 2 function 14 need establish lipschitz property 46 leads us consider problem find x 2 x lx 2 f x since l three components partition linearized problem takes form find z 2 x last equation 50 exploit fact 0 z 2 x order analyze linearization 4850 introduce following auxiliary problem min z z 11 lemma 3 appendix matrix positive definite smallest eigenvalue least ff2 ae sufficiently small ff appears 11 hence extremand 51 strongly convex z strongly concave 8 prop 22 p 173 max min interchanged fixed min 51 attained solution z following linear equation qae substituting z 51 obtain equivalent strongly concave maximization problem variable parameters r appear linearly cost function since strongly concave maximization problems lipschitz continuous functions linear parameters cost example see 3 lemma 4 maximizing lipschitz continuous function parameter 52 minimizing z also lipschitz continuous function since 4850 firstorder conditions solution 51 since firstorder conditions necessary sufficient optimality convexconcave setting conclude 4850 unique solution z depending lipschitz continuously parameters r apply 10 theorem 21 order determine precisely lipschitz constant z depends ae defining set follows 10 theorem 21 fl 1 fl 2 satisfy constants work 1 2 substituting 52 using relation az see z z satisfies qae c gotten augmenting b rows components r associated 2 c let ur denote orthogonal decomposition c r right triangular 1 linearly independent rows u orthonormal columns substituting 54 obtain equivalent system r gammaaei z gamma second equation tae system definition first equation system 54 since coefficient matrix nonsingular ae sufficiently small see 1 lemma 127 z lipschitz continuous functions lipschitz constant independent ae ae sufficiently small let v orthonormal columns chosen matrix u vector satisfies 50 components 0 associated satisfy analogous relation 53 hence multiplying u ae u multiplying u since lipschitz continuous function follows 56 0 lipschitz continuous functions remaining components rectangular matrix vanish therefore c give us estimates fi independent ae ae sufficiently small 10 theorem 21 estimate valid arbitrary choices parameters given fixed positive scalar oe 1 assume ae always oe 1 hence multiplying 58 ae adding 57 conclude constant fl independent ae choice 4850 solution z defining parameter follows 59 combining 59 conclude 45 unique solution 46 holds given arbitrary scalar oe 1 0 positive scalars oe 0 ffi chosen shortly define choosing oe 0 sufficiently large ffi sufficiently small satisfy condition fflfl 1 lemma 2 choosing ffi smaller necessary remaining conditions lemma 2 satisfied r z lz z expanding taylor series around p gives p 2 p since right side 62 bounded fi ffi constant j p1 made arbitrarily small taking ffi small ffl positive number small enough fflfl 1 fl appears 59 observe z z lz assumed lipschitz continuity derivatives 61 p 2 p choice w 1 w 2 choose oe 0 large enough ffi small enough factor multiplying kw 63 ffl establishes p2 fflfl 1 choosing ae set w lemma 2 62 63 w 2 w since smaller necessary delta defined 60 hence 64 w 2 w w 2 w completes proof p3 since already showed 45 unique solution satisfying 46 finally let us consider condition lemma 2 pg recalling utilizing 62 see 65 satisfied z factor fl1 gamma fflfl 65 absorbed fi assuming small enough fik rearrange 66 obtain equivalent relation definition p ae oe 67 satisfied choosing ffi small enough 68 satisfied follows 67 holds implies turn 65 since assumptions lemma 2 satisfied almost directly neighborhood n ae lemma 1 coincides w lemma 2 ball b ffi lemma 1 ball appearing definition p 61 constant fi lemma 1 expression fl1 gamma fl ffl 47 appendix matrix bound lemma 3 given matrices q b q symmetric suppose given ffi 0 exists oe 0 neighborhoods b b q q ae v 2 r n proof w lies null space b 69 exists scalar 0 kb uk kuk u row space b hence u row space b arbitrary vector v 2 r n orthogonal decomposition row space b w null space b since b ae utilizing inequality ab ffla inserting 70 ae let us choose oe small enough oe v oe since expression boe continuous function b q exists neighborhoods q q b b v oe taking 2ffl proof complete r new york generalized gradients applications lipschitzian stability nonlinear control optimization lipschitzian stability state constrained nonlinear optimal control euler approximation state constrained optimal control characterizations strong regularity variational inequalities polyhedral convex sets convex analysis variational problems modified wilson method nonlinear programs nonunique multipliers lipschitz continuity constrained processes approximations multiplier method convergence wrights stabilized sqp algorithm stability presence degeneracy error estimation approximate solutions systems linear inequalities fritzjohn necessary optimality conditions presence equality inequality constraints perturbed kuhntucker points rates convergence class nonlinearprogramming algorithms strongly regular generalized equations multiplier method hestenes powell applied convex programming superlinear convergence stabilized sqp method degenerate solution tr lipschitzian stability nonlinear control optimization lipschitzian stability state constrained nonlinear optimal control superlinear convergence stabilized sqp method degenerate solution convex analysis variational problems characterizations strong regularity variational inequalities polyhedral convex sets ctr hiroshi yamashita hiroshi yabe quadratic convergence primaldual interior point method degenerate nonlinear optimization problems computational optimization applications v31 n2 p123143 june 2005 goldfarb r polyak k scheinberg yuzefovich modified barrieraugmented lagrangian method constrained minimization computational optimization applications v14 n1 p5574 july 1999 jinbao jian superlinearly convergent implicit smooth sqp algorithm mathematical programs nonlinear complementarity constraints computational optimization applications v31 n3 p335361 july 2005 andreas fischer houyuan jiang merit functions complementarity related problems survey computational optimization applications v17 n23 p159182 december 2000