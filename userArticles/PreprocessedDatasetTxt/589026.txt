secondorder algorithms generalized finite semiinfinite minmax problems present two secondorder algorithms one solving class finite generalized minmax problems one solving semiinfinite generalized minmax problems algorithms make use optimality functions based secondorder approximations cost function corresponding search direction functions reasonable assumptions prove algorithms converge qsuperlinearly rate least 32this paper continuation e polak l qi sun comput optim appl 13 1999 pp 137161 b introduction also case ordinary minmax problems generalized minmax problems either finite semiinfinite form smooth function n nonsmooth vectorvalued function case finite minmax problems components form 2 functions f continuously dierentiable sets q j 1 2 q j finite cardinality 3 semiinfinite generalized minmax problems components form functions finite generalized minmax problems obviously special case semiinfinite generalized minmax problems since sets define functions f jk x best known generalized minimax problem occurs optimization problem max function cost equality inequality constraints set solution using exact penalty functions results unconstrained optimization problem f 0 x 11 form r e two positive penalty parameters another simple example occurs least squares problem involving max functions case denote components vector superscripts elements sequence set subscripts 3 given positive integer q use notation q 1 2 q j x 13 last example trying approximate structural optimization problem aim minimize sum probability failure 4 plus cost steel structure using linearizations statelimit function obtained cost function form ub ball radius centered origin space random variables u gx u smooth statelimit function defined boundary outcomes result structural failure functions form f 0 14 best known example quasidierentiable functions treated depth 4 hence generalized minmax problems solved using algorithms developed quasidierentiable functions see eg 2 3 6 7 8 9 11 21 additional assumption f yy j 0 generalized minmax problems solved using transformations 5 smooth constrained nonlinear programming problem see eg 1 5 12 direct methods depend assumption f yy j 0 found example 6 9 20 consider semiinfinite generalized minmax problems following hypotheses assumption 11 assume functions f j j j least continuously dier b exists positive number c f 0 f yy j c sets j either compact sets infinite cardinality sets finite cardinality form given 15 2 parts b assumption 11 ensure f j convex function f 0 also convex addition see parts assumption 11 hold function f 0 subgradient 20 fact used defining optimality function associated descent direction problem 4 probability failure given gxu0 udu normal probability density function 5 transformations result smooth problem variables nonsmooth prob lem fair bit anecdotal evidence induce considerable illconditioning smooth problem introduce arbitrary scaling general solving nonsmooth problems using transformation techniques appears less ecient using algorithms exploit problem structure p extending pshenichnyipironneaupolak ppp algorithm 41 17 see also 22 13 14 finite generalized minmax problems polakhe ppp rate preserving algorithm 349 17 see also 15 semiinfinite generalized minmax problems paper show techniques used 18 19 constructing q superlinearly converging algorithms solving finite semiinfinite minmax problems form 11 12 extended construct qsuperlinearly converging algorithms solution finite semiinfinite generalized minmax problems section 2 present continuous optimality function associated search direction function together backstepping rule constitute backbone algorithms section 3 extend polakmaynehiggins newtons method 18 solving finite minmax problems generalized finite minmax problems prove qsuperlinear convergence extention section 4 section 5 make use theory consistent approximations developed 17 algorithm presented section 3 develop algorithm solving generalized semiinfinite minmax problems prove convergence qsuperlinear convergence section 6 devoted numerical results demonstrate behavior proposed algorithms sum concluding section 7 2 optimality conditions present optimality conditions semiinfinite generalized minmax problem problem defined 11 12 14 classical form terms optimality function leads superlinearly converging secondorder algorithm lemma 21 20 suppose f continuously dierentiable locally lipschitz continuous function directional derivatives every x n let f defined given x n direction vector h n function f 0 directional derivative df 0 x h given suppose assumption 11 satisfied follows lemma 21 directional derivative f 0 point x n direction h given f f sets j 15 23 assumes form f functions f jk defined sets q j x hence following result obvious theorem 22 suppose x local minimizer problem 11 12 14 h n f f furthermore 28 holds 0 f 0 x subgradient f 0 x given f since 28 necessary condition optimality point x n satisfies 28 called stationary sets j form 15 expressions 28 29 assume following f f xf jk x 211 definition 23 say optimality function problem 11 12 upper semicontinuous c holds assumption 24 assume functions 11 12 14 twice lipschitz continuously dierentiable bounded sets b functions locally lipschitz continuous c exist constants 0 c c j 213for sake convenience x h n w define ux h w f x vx h w 1 reason introduction artificial variable w follows function perfectly good secondorder approximation f x h unfortunately always convex hence leads problems developing algorithm solving semiinfinite generalized minmax problems introducing artificial variable w define function later see convex secondorder approximation f x hence much useful algorithm construction define function n associated search direction function n min min h w 220 note shortly see function optimality function problem 11 12 14 let lemma 25 suppose assumptions 11 24 satisfied let solution set 222 nonempty compact w proof since f 0 2 f positive semidefinite w 0 w nonempty compact suppose w w satisfies following firstorder optimality conditions follow directly equivalent kkt conditions ie w f 2 f yy clearly 226 implies w f 2 f yy 2 f yw 0 227lemma 26 suppose assumptions 11 24 satisfied z n exists 0 h n h x n x z ie defined 217 proof since h convex quadratic function w satisfying following firstorder conditions w f x 2 f x solution 218 f yy j c f every uniformly continuous compact set see z n exists 0 h n h x n x z implies h x hence proof complete 2 lemma shows identical suciently small fact used proving superlinear convergence results general convex h show convex h lemma 27 suppose assumptions 11 24 satisfied fixed convex function moreover f 0 continuous proof first show convex function easy verify sy concave function subgradient given 234 solution set 233 follows 232 locally lipschitz continuous subgradient gradient given 235 since lemma 25 w conclude every convex composition convex function positive elements subgradient vector function whose components convex next prove continuous first since f yy j c f 0 positive semidefinite j 1 follows 222 uniformly bounded neighborhood given point z follows corollary 542 polak 17 f continuous hence implies continuous n x following theorem shows indeed optimality function problem 11 12 14 setvalued function h descent direction function theorem 28 suppose assumptions 11 24 satisfied consider functions h defined 219 220 respectively x n ii x n df 0 x h directional derivative f 0 x direction h 2 iii x n 0 f 0 x subgradient f 0 x defined 29 moreover x n iv set valued map h bounded bounded sets b compact valued c outersemicontinuous ie x n hx closed every compact set hx exists 0 hz z bx n x v function continuous proof admissible 219 x 0 x n directly definition x 219 h hx f thus shown 240 holds iii x n let min ux h ux h 0 242 first prove easy see hence need show suppose exists h n j 1 thus exists constant c 0 implies exists constant c 1 since ux 0 convex function ux 0 suciently small contradicts next f 0 x subgradient f 0 x defined 29 emulating proof lemma 255 17 prove x n 0 f 0 x therefore finally show x n sake contradiction suppose exists x n 0 exist 0 ux h w together fact vx h w 0 implies ux h w 0 hence conclude ux h ux h w 0 contradicts 243 however implies h 0 strongly convex h ux 0 iv according definition h n exists wh together facts f 0 vx h wh 0 implies since j 1 h n follows 251 bounded neighborhood x consequently x n hx nonempty bounded h bounded bounded sets since continuous lemma 27 follows hx closed next prove every x n every compact set exists 0 hz exists x n compact set hx sequence x converging x hx hence exists sequence h compact set without loss generality assume definition hx f 0 continuous follows 255 implies h hx contradicts hx thus shown h outersemicontinuous v finally follows corollary 542 polak 17 continuous 2 introducing additional variable rewrite expression x defined 219 follows problem 257 quadratic problem quadratic constraints suitable assump tions 257 actually convex quadratic problem convex quadratic constraints hence provides convenient means computing optimality function value x associated search direction h hx theorem 29 suppose assumptions 11 24 satisfied sets j 15 x n let x solution set 257 ie p h x solves 257 problem 257 convex quadratic problem convex quadratic constraints ii x n x nonempty compact outersemicontinuous bounded bounded sets iii z n exist neighborhood nz z 0 p h x x nz proof conditions assumptions 11 24 2 f x positive semidefinite j 1 2 strongly convex hence 257 convex quadratic problem convex quadratic constraints ii since bounded neighborhood nx x j 1 2 follows nx p p h 261 hence x n x nonempty compact bounded bounded sets outersemicontinuity follows fact continuous constraint set 257 outersemicontinuous iii since z n z x n kkt conditions 257 subgradient respect h suppose p h z iii theorem 28 hence follows 262 fact implies positive semidefinite thus proved since outer semicontinuous follows x z p h x follows 262 264 fact f yy j exists neighborhood nz z x nz multiplier kkt 262 must components positive hence x nz kkt conditions 257 become thus x nz j 1 2 exist nonnegative numbers jk satisfying kq j p h x k q j conclude 265 266 267 x nz p h x p last inequality follows fact f jk x j x k q j shrinking nz necessary conclude 267 270 assumptions 11 24 exists positive number 0 x nz 3 algorithm solving generalized finite minmax problems algorithm solving generalized finite minmax problems obviously interest right however also need subroutine algorithms solving generalized semiinfinite minmax problems hence time assume sets j form 15 functions f jk 26 result generalized finite minmax problem assumes form 11 12 14 min view assumption 11 functions f f jk j k q j continuously dierentiable f jk defined 26 ready state algorithm solving generalized finite minmax prob lems algorithm generalization polakmaynehiggins newtons algorithm solving finite minmax problems 18 algorithm 31 solves problem 31 parameters 0 1 0 1 0 step step 1 compute optimality function value x search direction h according formulae 219 220 step 2 else compute stepsize n 0 1 2 step 3 set replace step 1 2 lemma 32 20 suppose assumption 11 holds lemma 33 20 suppose assumptions 11 24 satisfied exists constant 0 x x n 0 1 theorem 34 suppose assumptions 11 24 satisfied j form 15 problem 11 12 14 reduces problem 31 x i0 infinite sequence generated algorithm 31 x unique solution 31 x i0 converges x proof suppose x i0 infinite sequence generated algorithm 31 since f strongly convex lemma 33 sequence x i0 bounded suppose x accumulation point sequence since cost function f 0 continuous f 0 x accumulation point cost sequence hence since construction cost sequence f 0 sake contradiction suppose x 0 since x n hx compact h bounded bounded sets outersemicontinuous iv theorem 28 follows theorem 537 b polak 17 exists subsequence j i0 integers x x h j h hx follows ii iii theorem 28 0 1 follows definition directional derivative f 0 exists k n hence 0 310 1 since f 0 continuous h j h exists 0 x shows x next since continuous exists 0 x therefore follows stepsize rule 32 x x 312 implies f 0 contradicting fact f 0 hence conclude therefore strongly convex whole sequence x converges x 2 4 rate convergence algorithm 31 proposition 41 suppose assumptions 11 24 satisfied x unique solution f 0 x n proof lemma 33 f 0 strongly convex function hence x n f f c f c q j x defined 27 follows 25 42 proposition 42 suppose assumptions 11 24 satisfied compact convex set exists 0 x z defined 217 proof first follows polak 17 lemma 254 18 exists constant x z n compact set let l 2 lipschitz constant 2 f z f z l 2 46 x z l 3 ml 2 l 1 6 since assumption compact follows exists positive number l 4 x z hence x z 4 412 similarly prove x z thus shown 44 holds 2 theorem 43 suppose assumptions 11 24 satisfied j form15 problem 11 12 14 reduces problem 31 sequence constructed algorithm 31 solving problem 31 x i0 converges superlinearly qorder least 32 proof first prove finite number iterations stepsize stabilizes 1 eventually x holds sequence x i0 complete proof making use results 17 corollary 258 follows theorem 34 sequence x i0 converges unique minimizer x f 0 hence conclude theorem 28 view conclude lemma 26 exist positive number 0 nonnegative integer 0 suppose 0 suciently large ensure x 416 making use 41 find 415 follows proposition 42 exists 0 theorem 29 exist positive integer 1 0 next proposition 42 415 imply hence 420 419 follows 421 fact h 0 suciently large therefore conclude 17 corollary 258 18 418 419 x i0 converges x superlinearly qorder least 32 2 5 algorithm solving generalized semiinfinite minmax problems ready tackle generalized semiinfinite minmax problems defined 11 12 14 problems solved discretization techniques use discretizations result consistent approximations defined section 33 17 use conjunction master algorithm calls algorithm 31 subroutine see reasonable assumption resulting algorithm retains rate convergence algorithm 31 51 consistent approximations let n 0 strictly positive integer n n 0 n 0 finite cardinality subsets j j jn jn1 n closure set lim jn equal j j define family approximating problems pn n n 0 follows pn min n x j clear approximating problems pn form 31 one define optimality functions n form 15 refer original problem 11 12 14 p definition 51 17 say pairs pn n sequence pn n nn0 consistent approximations pair p problems pn epiconverge p ie epigraphs f 0 n converge epigraph f 0 sense defined definition 536 17 infinite sequence xn nk k n 0 assumption 52 assume follows every n n 0 problem 51 solution b exists strictly positive valued strictly monotone decreasing function n n 0 n k every exists jn kn 54for example j j unit cube j ie define 2 nn 0 case easy see constructions obtained polyhedral sets x h n w define un x h w f n x infer 219 optimality functions n problems pn following form min h w 59 since cardinality sets jn finite obvious n x evaluated also done polakmaynehiggins ratepreserving method 19 see also 20 use alternative optimality function problems pn precision adjustment algorithm optimality function defined f f 0 constant similarly 20 define alternative optimality function problem p f f 0 constant 511 proposition 53 20 suppose assumptions 11 52 satisfied n defined 52 n 510 let n bounded subset let l lipschitz constant valid functions j x j q exists constant c x n n 0 52 superlinear rate preserving algorithm algorithm 54 solves problem 11 12 14 parameters 0 1 0 0 3 step step 1 compute optimality function value according 510 511 ie f f n step 2 go step 3 else replace n n 1 go step 1 step 3 compute second optimality function value n according 59 ie min corresponding search direction h according min step 4 compute stepsize go step 5 step 5 set step 1 2 remark follows proposition 53 loop consisting step 1 step 2 algorithm 54 yields finite discretization parameter n simplicity assume algorithm 54 produce iterate x b note work needed compute x algorithm 54 increases iteration number 2 lemma 55 suppose assumptions 11 24 52 satisfied algorithm 54 constructed sequence x i0 together corresponding sequence discretization parameters n i0 sequence x i0 least one accumulation point n proof sake contradiction suppose sequence x i0 accumulation point x sequence n i0 bounded n i0 monotonically increasing sequence integers exists 0 n hence construction sequence x i0 carried algorithm 31 applied problem 51 furthermore follows 518 exists 0 however follows theorem 34 n continuity n x infinite subsequence x ik converges contradicts previous finding hence completes proof 2 theorem 56 suppose assumptions 11 24 52 satisfied algorithm 54 constructed bounded sequence x i0 every accumulation point x x i0 satisfies proof applying theorem 3323 17 theorems section 5 16 lemma 55 algorithm 54 obtain desired result 2 theorem 57 suppose assumptions 11 24 52 satisfied algorithm 54 constructed bounded sequence x i0 x converges unique x f 0 qorder 32 proof first theorem 56 fact f 0 unique minimizer x whole sequence x converges x hence one deduce theorem 43 proof 17 theorem 3420 x converges x qorder 32 since derivation straightforward omit details 2 6 numerical results present numerical results illustrate behavior algorithm proposed section 5 generalized semiinfinite programming problems algorithm implemented matlab throughout computational experiments parameters used algorithm 31 examples used starting point 1 1 iteration algorithm stopped x n meshsize n 0005 n developed 24 based smoothing newton method 23 variational inequalities used solve search direction finding subproblem 257 example 1 case f 0 example 2 case functions f also defined example 1 f defined numerical results summarized table 1 table 2 two tables first column gives residue x x used last iterate substitute x discretization level meshsize present level decreased half previous one refined master algorithm ith step clear numerical results rate convergence superlinear iteration discretization level table 1 numerical results example 1 iteration discretization level table 2 numerical results example 2 7 conclusion presented two superlinearly converging algorithms one solving finite generalized minmax problems form 11 12 13 one solving generalized semiinfinite minmax problems form 11 12 14 algorithms obtained making use concepts underlying construction polakmayne higgins newtons method 18 polakmaynehiggins ratepreserving method 19 respectively construction algorithms depends cost unction subgradient rate convergence depends convexity second order smooth ness hence assumption 24 essential numerical results consistent theoretical prediction algorithms converge qsuperlineary acknowledgement authors wish thank prof r rockafellar suggesting function way get around possible nonconvexity function h well formula 257 shows optimality function defined quadratically constrained quadratic programming problem r nondierentiable optimization via approximation quasidierentiable functions necessary conditions descent directions algorithm minimizing certain class quasidierentiable functions smooth transformation generalized minimax problem quadratic approximation method minimizing class qua sidierentiable functions linearization method minimizing certain quasidierentiable functions randomized search directions descent methods minimizing certain quasidierentiable functions descent methods quasidierentiable minimization proximal control bundle methods convex nondierentiable minimization method common descent certain class quasidierentiable functions algorithms class nondierentiable problems rate convergence certain methods centers basics minimax algorithms ratepreserving discretization strategies semiinfinite programming optimal control use consistent approximations solution semiinfinite optimization optimal control problems optimization algorithms consistent approximations superlinearly convergent algorithm minmax problems extension newtons method semiinfinite minimax problems firstorder algorithms generalized finite semiinfinite minmax problems minimization quasidierentiable function subject equalitytype quasidierentiable constraints numerical methods extremal problems chislennye metody v ekstremalnykh zadachakh new look smoothing newton methods nonlinear complementarity problems box constrained variational inequalities numerical experiments class squared smoothing newton methods box constrained variational inequality problems tr ctr huang defeng sun gongyun zhao smoothing newtontype algorithm stronger convergence quadratically constrained convex quadratic programming computational optimization applications v35 n2 p199237 october 2006