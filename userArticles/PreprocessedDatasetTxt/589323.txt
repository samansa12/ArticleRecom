complexity practical interiorpoint method theory selfconcordance convex optimization used analyze complexity interiorpoint methods based newtons method large problems may impractical use newtons method analyze truncatednewton method approximation newton search direction used addition practical interiorpoint methods often include enhancements extrapolation absent theoretical algorithms analyzed previously derive theoretical results apply algorithm one similar sophisticated computer implementation barrier method results single barrier subproblem satisfying extension results newtons method extrapolation used overall barrier method however results limited indicate theoretical arguments examples elaborate results may difficult obtain b introduction 1993 book 16 nesterov nemirovsky derive complexity results convex optimization problems basic algorithm interiorpoint method subproblem solved using damped newton method nonlinear optimization problem large hence complexity important issue newtons method normally used computational costs results might considered primarily theoretical interest goal paper derive comparable complexity results algorithms closely resemble practical interiorpoint algorithms largescale optimization see eg 1 9 10 11 13 19 23 interiorpoint method analyze strongly related barrier method 13 essential features algorithm barrier subproblem solved approximately using truncatednewton method solutions subproblems extrapolated obtain initial guess new subproblem many enhancements discussed 13such preconditioning specialized matrixvector product numerically stable formula search directionfit theoretical framework used major exception line search see derive bound number truncatednewton iterations required solve barrier subproblem within tolerance truncatednewton iteration involves approximate solution newton equations via say conjugategradient method requiring 3 computations exact arithmetic although typically number computations would 2 problems hessian matrix sparse algorithm analyzed prescribed step length used line search theoretical practical algorithms received editors month date 199 accepted publication revised form month 1997 yoperations research engineering department george mason university fairfax va 22030 work author supported national science foundation grant dmi9414355 zoperations research engineering department george mason university fairfax va 22030 work author supported national science foundation grant dmi9414355 g nash ariela sofer differ since practical method would likely use adaptive line search based minimizing onedimensional approximation barrier function ignoring computations evaluating gradient hessian algorithm determines solution within tolerance number operations polynomial problem dimensions polynomial algorithms exist evaluate gradient hessian overall algorithm barrier subproblem polynomial dimensions optimization problem theoretical result obtain reduces result newtons method inner convergence tolerance truncatednewton method set zero reason consider result satisfying extension theory newtons method second major part paper analyze simple linear extrapolation scheme accelerate algorithm providing improved initial guesses subproblem show improved performance achieved algorithm based linear extrapolation barrier subproblems solved exactly also indicate via example may difficult derive complexity results either subproblems solved inexactly higherorder extrapolation used analysis based framework established nesterov nemirovsky 1993 nemirovsky 1994 adapted us book 14 rest paper cite theoretical results algorithm based newtons method results due nesterov nemirovsky although frequently cite 14 discussion closely follows organization notation book related discussions found 3 8 22 barrier method assume barrier function self concordant property define selfconcordant barrier functions introduced 16 recent work topic includes 4 6 7 8 17 linear programs convex quadratic programs ordinary logarithmic barrier function used related barrier functions used semidefinite programming 18 20 21 24 possible prove convex feasible region properties specify exists appropriate selfconcordant barrier function although general may practical computation thus results describe provide general theoretical approach solving convex programming problems two major results required prove overall algorithm polynomial algorithm first states truncatednewton method applied single barrier subproblem initial guess close solution number iterations required find approximate solution subproblem bounded topic section 3 second states linear extrapolation improve initial guess next subproblem topic addressed section 4 two results less obvious might first seem constraint convex programming problem binding solution solution boundary feasible region barrier function singular ity since standard convergence results newtontype methods assume hessian solution bounded condition number traditional analysis appropriate analyze behavior newtontype methods case must manner take singularity account define norm kdeltak x terms hessian barrier function evaluated point x measure closeness terms norm norm depends hessian changes variables change complexity practical interiorpoint method 3 norm useful rate change hessian matrix must great reasoning leads imposition bound third derivatives barrier function terms hessian see section 2 bound required prove first major result corresponding behavior truncatednewton method single barrier subproblem prove approximate solution one subproblem far solution next subproblem necessary values barrier functions change quickly barrier parameter changes guarantee impose bound first derivatives barrier functions terms hessian see section 4 measuring quantities terms hessian able circumvent difficulties associated singularity barrier function solution barrier function properties interiorpoint method designed optimal solution convex programming problem found within tolerance using polynomial number truncatednewton iterations practical experience suggests improved barrier method obtained approximate solutions subproblems extrapolated produce initial guess next subproblem analyze idea section 4 able derive theory support idea case linear extrapolation used subproblems solved exactly example suggest may difficult obtain comparable result either elaborate algorithm higherorder extrapolation realistic algorithm subproblems solved inexactly 2 basics section define self concordance establish basic lemmas extensive discussion theory self concordance given book nesterov nemirovski 16 presentation parallels book 14 let bounded closed convex subset n nonempty interior int assumption bounded important since could modify optimization problem adding artificial large bounds variables let f convex function defined set assume f three continuous derivatives f self concordant barrier property f along every sequence f x g ae int converging boundary point ii differential inequality f satisfies x 2 int definition thirdorder directional derivative f example logarithmic barrier function loga self concordant set psi 4 stephen g nash ariela sofer constant 2 definition arbitrary instead constant c scaled function concordant number 2 used definition function f log x self concordant without scaling make several assumptions simplify discussion essential fact almost identical results proved without assumptions assume r 2 f x nonsingular x 2 int see theorem 211 16 approach avoids assumption allows us define norm follows also assume f minimizer x 2 int f convex assumptions guarantee x unique minimizer f following lemmas indicate basic properties selfconcordant functions first shows thirdorder directional derivative bounded using norm lemma 1 f selfconcordant x 2 int proof see 8 16 next lemma bounds rapidly selfconcordant function f x hessian change step taken whose norm less one first result analog taylor series expansion selfconcordant function second bound rapidly norm change x changes lemma 2 let f self concordant let x 2 int suppose khk x 1 x lower bound 1 satisfied even khk x 1 furthermore g 2 n proof see 16 convergence results barrier subproblem phrased terms quantity called newton decrement defined newton decrement measures norm newton direction indirectly interpreted proximity measure distance barrier trajectory use newton decrement place traditional measures convergence complexity practical interiorpoint method 5 x 2 int pn newton direction f x newton decrement f x consider taylor series approximation f newton direction pn minimizes approximation solution optimal value taylor series approximation indicating ffi f x called newton decrement following lemma lemma 3 newton decrement satisfies proof see 16 obtain bounds f terms newton decrement also measure progress iteration truncated newton method terms newton decrement thus statements convergence method terms newton decrement indirectly provide us information convergence measured traditional ways 3 convergence truncatednewton method study consequences using truncatednewton method rather newtons method minimize selfconcordant function minimize f previous section truncatednewton method search direction p computed satisfies acceptance criterion x current estimate solution barrier subproblem pn newton direction ffl tolerance simplicity assume tolerance ffl fixed although similar results could derived case ffl varied iteration iteration important search direction computed long number arithmetic operations polynomial dimensions problem practical truncatednewton methods often use conjugategradient method exact arithmetic guaranteed converge newton direction finite number operations thus exact arithmetic would appropriate procedure 6 stephen g nash ariela sofer acceptance criterion 2 impractical since involves newton direction pn however closely related practical rules terminating inner iteration truncatednewton method define value quadratic model f x p x x 12 recommended inner iteration truncatednewton method terminated based value quadratic model barrier method 13 uses related rule practical acceptance rules based value relative residual form tolerance j 2 straightforward derive thatp cond 2 r 2 f x condition number r 2 f x 2norm inequalities provide demonstration relationship 2 practical termination rules inner iteration truncatednewton method useful consequences acceptance criterion 2 stated following lemma lemma 4 suppose acceptance criterion 2 satisfied x proof first result straightforward consequence 2 second obtained squaring acceptance criterion complexity practical interiorpoint method 7 function f minimized using damped truncatednewton method step taken along truncatednewton direction specified step length less one denote search direction x p method defined p reason including step length resulting displacement always norm less one lemma 2 applies also guarantees damped truncatednewton step welldefined sense iterates remain int method converges truncatednewton direction approaches zero step length approaches one asymptotically rapid rates convergence attained rest section develops properties damped truncatednewton method next lemma gives lower bound much function f decreased step damped truncatednewton method lemma 5 x result damped truncatednewton iteration proof let step length using lemma 2 4 obtain x desired result rearrangement last inequality lemma provides lower bound f lower bound zero kpk positive strictly increasing kpk x 0 derivative righthand side respect kpk x positive result gives lower bound much progress made truncatednewton iteration figure 1 illustrates lower bound various values ffl kpk x remains large truncatednewton method must decrease value f x nontrivial amount since function bounded cannot go indefinitely kpk x must ultimately become small next theorem analyzes convergence method case related 3 two results provide bound number truncatednewton iterations required solve optimization problem within tolerance argument made precise theorem 7 theorem also determines bound kx gamma x k x terms ffi f x thus shows ffi f x small norm error small well theorem 6 x 2 int let x minimizer f assume ffi 8 stephen g nash ariela sofer figure bound f various values ffl bound bound bound bound proof proof two parts proving results turn part 1 derive bound ffi f x let p truncatednewton direction x pn newton direction x ffp h 2 n define function twice continuously differentiable lemma 1 lemma 2 xtp x note z ffh z x x x dt x x khk x complexity practical interiorpoint method 9 x khk x x x khk x x since true h completes part 1 proof part 2 proof found 14 15 conclude summary theorem provides bound number truncatednewton iterations required minimize f within tolerance theorem 7 let bounded closed convex subset n nonempty terior let f x convex function self concordant given initial guess x0 2 int damped truncatednewton method defined recurrence p approximation newton direction pn tolerance 0 f iteration must every j g nash ariela sofer number truncatednewton steps required find point x bounded constant c depends ffl decreases ffl 0 number steps bounded constant c proof bound f derived 16 remaining conclusions consequences earler results formulas constants c c derived follows let first iteration index must exist since f bounded 3 follows lemma 5 thus number initial iterations progress later iterations described theorem 6 j hence number later iterations summing two bounds determines constant c later iterations similar analysis determines c truncatednewton method computes newton direction theorem reported newtons method 14 15 establishes polynomiality truncatednewton method applied barrier subproblem see section 1 details 4 extrapolation section 3 analyzed behavior truncatednewton method applied single barrier subproblem consider overall interiorpoint method based solving sequence subproblems main concern effects extrapolating approximate solutions several subproblems obtain improved initial guess next subproblem complexity practical interiorpoint method 11 complexity results overall method depend additional assump tion bound firstderivative barrier function although make much direct use assumption paper underlies many comments state let set properties section 3 following 16 self concordant function f selfconcordant barrier function x 2 int h 2 n may assume without loss generality 1 function f barrier function function loga selfconcordant barrier function set psi selfconcordant barrier function exists closed convex set 16 evaluating barrier function may computationally practical however also assume convex program written following standard subject x 2 c 6 0 optimization problem general nonlinear objective function converted form adding additional variable constraint problem p solved using pathfollowing method following form ae 0 define f selfconcordant barrier function set parameter 1 hessian f nonsingular x 2 int nonsingularity assumption essential see 16 let x ae minimizer f ae x x 2 int method generate x complexity result particular algorithm based approach theorem 7 proved 14 15 algorithm x 2 int accepted approximate minimizer f ae 2 x used initial guess minimizing f ae i1 theorem 8 suppose solve problem p bounded closed convex domain using pathfollowing method described f self concordant barrier function parameter 1 let 1be parameter acceptance test assume penalty parameters updated via g nash ariela sofer assume method initialized ae 0 x0 2 int x0 satisfies acceptance test f ae 0 ae 0 truncatednewton method based 2 used minimize f ae within proximity number truncatednewton iterations required find approximate solution subproblem exceed constant n ffl depending ffl particular total number truncatednewton iterations required find x satisfying c bounded log constant c ffl depending ffl possible better initial guess subproblem hence better algorithm obtained extrapolation previous solutions technique extrapolationinitially proposed fiacco mccormick 5approximates barrier trajectory xae polynomial degree q coefficients polynomial computed solutions q subproblems used predict solution barrier subproblem new value ae results 5 indicate extrapolation powerful computational tool computational experiments 13 also indicate better initial guesses better overall perfor mance obtained extrapolating solutions sequence subproblems example illustrating usefulness extrapolation summarized table 1 details see 13 case use cubic extrapolation reduces number truncatednewton iterations factor 21 number gradient evaluations factor 27 complexity results predictorcorrector method found 15 predictorcorrector method form extrapolation appears less practical large nonlinear programs technique used clear predictorcorrector approach extended effectively truncatednewton method lemma gives theoretical support computational results technique extrapolation may limitations however shall discuss latter part section first examine linear extrapolation assume x linear extrapolation predicts generally delta considered search direction along barrier tra jectory lemma result shows linear extrapolation used produce initial guesses least good extrapolation used simplicity choose fl j fl although would easy extend result case fl constant lemma uses general complexity practical interiorpoint method 13 table effect cubic extrapolation iter number truncatednewton iterations ng number gradient evaluations based 13 elaborate barrier algorithm test problem 51 1000 variables extrapolation extrapolation ae iter ng iter ng 28 277 totals 51 367 107 982 assumption r 2 f positive definite r 2 f positive semidefinite lemma still true assumption c delta 6 0 lemma 9 let ae assume x define linear extrapolation direction delta descent direction f i1 x define specific upper bound provided 1 proof first prove c x series expansion gives x 6 x positive definite last term positive since 14 stephen g nash ariela sofer implies f similarly switching roles x x igamma1 obtain multiply first inequalities ae second ae igamma1 rearrange combining results use result prove delta descent direction since x using results obtain completes first part proof second part proof relies 1 using formulas upper bound 1 becomes note assumptions lemma solve oe 0 obtain solution straightforward verify oe 00 ff local minimizer oe obtain x since upper bound f i1 decreasing local minimizer upper bound completes proof complexity practical interiorpoint method 15 result could extended case subproblems solved exactly long magnitudes sufficiently small interfere inequalities lemma appears difficult generalize result greatly however discussion indicates lemma 9 shows appropriate step along extrapolation direction produce decrease objective value barrier function updated barrier parameter however taking full extrapolation step fl fl guaranteed beneficial matter slight change barrier parameter true even subproblems solved exactly see let consider extrapolated point effect extrapolation described 0 thus small change barrier parameter ie first order improvement objective value new barrier function extrapolated point somewhat insight obtained analyzing 00 0 second term positive convexity first term less equal zero see lemma 9 define write 5 comments obtain g nash ariela sofer kvk x lower bound 00 0 positive hence improvement objective value obtained thus full extrapolation step guaranteed useful far considered linear extrapolation indicate via example higherorder extrapolation may lead predicted solutions far worse obtained without extrapolation example consider exact approximate solutions subproblems approximate solution x barrier subproblem accepted x 2 int 0 consider onevariable problem subject x 0 problem already standard form logx used barrier function easy analyze example solution optimization problem solution barrier subproblem x 1ae norm value jhxj newton decrement xaej solution subproblem accepted penalty parameter updated via ae use four values 05 choice corresponds solving subproblems exactly initialize penalty parameter ae case approximate solution subproblem chosen upper bound acceptable range choice consistent class theoretical algorithms study paper plausible practical algorithm figure 2 show results applying quadratic extrapolation prob lem exact solutions first seven barrier subproblems marked theta vertical bars indicate range x values satisfy acceptance criterion subproblem dotted lines show path extrapolated approximate solutions used indicate extrapolated initial guess four cases extrapolated values exceedingly poor initial guesses next subproblem fact extrapolation paths move away rather toward solution next subproblem figure 3 show results applying linear extrapolation case approximate solutions chosen lower bound acceptable values first subproblem upper bound second subproblem allowed theory think unlikely practical algorithm could produce approximate solutions case even linear extrapolation extrapolated points sufficiently large point away solution next subproblem hence extrapolation worse nothing mentioned expect circumstances arise practical algorithm nevertheless complexity theory complexity practical interiorpoint method 17 figure quadratic extrapolation approximate solutions rho x quadratic kappa0 rho x quadratic kappa1 rho x quadratic kappa25 rho x quadratic kappa5 figure linear extrapolation approximate solutions rho x rho x rho x rho x algorithm would rule possibility hence would based elaborate theoretical framework used example suggests algorithm uses extrapolation must monitor effectiveness extrapolation scheme must use blindly also suggests algorithm would carefully designed inaccuracies solutions barrier subproblems interfere performance extrapolation scheme able derive complexity results elaborate algorithm type example leads us think would difficult enterprise g nash ariela sofer r computational experience penaltybarrier methods nonlinear programming interior point approach linear sufficient condition selfconcord ance sequential unconstrained minimization techniques osman g uler two interiorpoint algorithms class convex programming problems interior point methods via selfconcordance relative lipschitz condition practical interiorpoint method convex pro gramming unconstrained optimization technique largescale linearly constrained minimization problems assessing search direction within truncatednewton method barrier method largescale constrained optimiza tion linear interior point polynomial time methods convex programming homogeneous interiorpoint algorithms semidefinite program ming infinitely summable series implementation interiorpoint methods long step pathfollowing method semidefinite programming complexity issues interior methods constrained optimization extending primaldual interior point algorithms linear programming semidefinite programming tr