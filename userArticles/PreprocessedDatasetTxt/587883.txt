methods large scale total least squares problems solution total least squares tls problems minefeff subject aexbf generic case obtained right singular vector corresponding smallest singular value sigman1 b large sparse structured method based rayleigh quotient iteration rqi suggested bjrck method problem reduced solution sequence symmetric positive definite linear systems form atabarsigma2izg barsigma approximation sigman1 linear systems solved em preconditioned conjugate gradient method pcgtls tls problems large sparse possibly incomplete cholesky factor ata usually computed provides efficient preconditioner resulting method used solve much wider range problems possible solve using lanczostype algorithms directly singular value problem paper rqipcgtls method developed choice initial approximation termination criteria discussed numerical results confirm given algorithm achieves rapid convergence good accuracy b introduction estimation parameters linear models fundamental problem many scientific engineering applications statistical model often realistic assume parameters x determined satisfy linear relation 2 r mthetan b 2 r known e f error matrix rows independently identically distributed zero mean variance satisfy assumption data b may need premultiplied appropriate scaling matrices see golub van loan 10 statistics model known errorsinvariables model estimate true unknown parameter vector x model 11 obtained solution total least squares tls problem min subject department mathematics university linkoping s581 83 linkoping sweden email akbjomathliuse pontusmatstomsvtise work authors supported swedish research council engineering sciences tfr department informatics university bergen n5020 bergen norway email pinariiuibno denotes frobenius matrix norm minimizing pair e f found problem 12 x satisfying said solve tls problem due recent advances data collection techniques ls tls problems large sparse structured frequently arise eg signal image processing applications solution ls problem direct methods based sparse matrix factorizations iterative methods well developed see 2 excellent treatment theoretical computational aspects tls problem given van huffel vandewalle 25 solving tls problem requires computation smallest singular value corresponding right singular vector b large sparse much difficult problem computing ls solution example usually feasible compute svd twosided orthogonal factorization since factors typically sparse iterative algorithms computing singular subspace matrix associated smallest singular values applications tls problems slowly varying data previously studied van huffel 24 27 3 new class methods based rayleigh quotient iteration developed efficient solution large scale tls problems related methods toeplitz systems studied kamm nagy 14 paper methods 3 developed numerical results given similar algorithms solving large scale multidimensional tls problems considered forthcoming paper 4 section 2 recall solution tls problem expressed terms smallest singular value corresponding right singular vector compound matrix b discuss conditioning ls tls problems illustrate tls problem rapidly become intractable section 3 first reviews newton iteration solving secular equation method converge tls solution strict conditions initial approximation satisfied derive rayleigh quotient method ultimately achieves cubic convergence choice initial estimates termination criteria discussed preconditioned conjugate gradient method developed section 4 efficient solution resulting sequence sparse symmetric linear systems finally section 5 numerical results given confirm rapid convergence numerical stability class methods preliminaries 21 tls problem tls problem 12 equivalent finding perturbation matrix e f minimal frobenius norm lowers rank matrix b hence analyzed terms singular value decomposition singular values b note minmax characterization singular values follows singular values oe 0 interlace b ie assume following full rank oe minimum attained rank one perturbation ke fk solution obtained right singular vector z x tls provided 6 0 tls problem called nongeneric solution case cannot occur oe following always assume condition holds characterization 22 follows n1 system nonlinear equations b x x putting n1 first block row system equations written viewed normal equations tls problem note assumption oe 0 n oe n1 follows gamma oe 2 n1 positive definite 22 conditioning tls problem evaluation accuracy stability algorithms presented need know sensitivity tls problem perturbations data first recall x ls 6 0 condition number ls problem see 2 sec 14 n note condition number depends b large residual problems second term may dominate condition number problem ls tls beta kappa kappa ls kappa tls figure 21 condition numbers ls tls function equation 24 shows tls problem always worse conditioned ls problem 23 multiplying left inequality wek shows kx tls k 2 large kr ls k 2 ae oe 0 n golub van loan 10 showed approximate condition number tls problem tls condition number much greater relation two condition numbers 25 27 depend relation kr ls k 2 oe n1 quite intricate study relation another context see paige strakos 17 illustration consider following small overdetermined system trivially ls solution take 28 oe independent fi hence reflect illconditioning tls solution similar size ls solution long jfij oe 0 2 however jfij ae oe 0 2 26 follows kx tls k 2 large fig 21 two condition numbers plotted function jfij note ls increases proportionally jfij second term 25 condition number tls grows proportionally jfij 2 verified kx tls k 2 also grows proportionally jfij 2 3 newton rayleigh quotient methods 31 newton method equation 23 constitutes system n equations x one way proceed see 14 eliminate x obtain rational secular equation method applied 31 leads iteration iteration converge monotonically rate asymptotically quad ratic convergence method improved using rational interpolation similar 6 solve secular equation however case converge oe 2 n1 x k tls solution initial approximation satisfies general hard verify assumption special case toeplitz tls problem kamm nagy 14 use bisection algorithm based fast algorithm factorizing toeplitz matrices find initial starting value satisfying 34 32 rayleigh quotient method main drawback newton method unless 34 satisfied converge wrong singular value different newton method obtained applying newtons method full system remarked 20 closely related inverse itera tion one widely used methods refining eigenvalues eigenvectors rayleigh quotient iteration rqi inverse iteration shift equal rayleigh quotient rqi cubic convergence symmetric eigenvalue problem see 18 sec47 superior standard newton method applied 35 eigenvalue problem 23 rayleigh quotient equals let x k current approximation ae k corresponding rayleigh quotient next approximation x k1 rqi scaling factor fi k obtained symmetric linear system j k positive definite solution obtained block gaussian elimi nation gammaz follows x 2 reformulation made express solution terms residual vectors 35 r uses following formulas compute rqi iteration defined equations 310313 33 initial estimate global convergence parlett kahan 19 shown almost initial vectors rayleigh quotient iteration converges singular value vector pair however general cannot say singular vector rqi converge ls solution known suitable starting approximation may conditions ensure rqi converge tls solution starting approximation aex ls x ls general difficult verify often satisfied practice however contrast simple newton iteration section 31 method may converge tls solution even rayleigh quotient aex ls large overestimate oe 2 n1 residual norm kr ls k 2 large kx ls k 2 reflect illconditioning note typical illconditioned least squares problems righthand side kx ls k 2 large example least squares problems arising illposed problems usually satisfy called picard condition guarantees righthand side property see 11 sec 123 szyld 23 suggested one steps inverse iteration could applied initially switching rqi order ensure convergence smallest eigenvalue inverse iteration oe 2 n1 corresponds taking oe rqi algorithm starting x x ls first step inverse iteration simplifies follows using 39 310 ae z new approximation becomes several steps inverse iteration may needed ensure convergence rqi smallest singular value however since inverse iteration converges lin early taking one step usually hold rapid convergence rqi therefore recommend general steps default value illustrate situation consider small 3 theta 2 system 28 ls solution x reflect illconditioning initial rayleigh quotient approximation equals interlacing property oe 3 oe 0 2 since jfij ae oe 0 2 clear rayleigh quotient fails approximate oe 2 3 illustrated figure 31 aex ls 12 oe 3 plotted function jfij easily verified however one step inverse iteration aex inv close oe 0 2 5 beta sqrtr ls figure 31 rayleigh quotient approximation oe 3 34 termination criteria rqi rqi algorithm tls problem defined 310313 rqi iteration terminated suggest two different criteria first based key fact proof global convergence normalized residual norm always decreases fl k1 fl k k thus increase norm occurs must caused roundoff makes sense continue iterations suggests terminate iterations x k1 second criterion based observation since condition number computing oe n1 equals 1 expect obtain oe n1 full machine precision since convergence rqi cubic criterion could stop change approximation oe n1 order oe 1 u 1p similar criterion used kamm nagy 14 terminating newton iteration however evident numerical results section 5 full accuracy x tls general requires one iteration oe n1 converged therefore recommend stop either 316 satisfies u machine unit c suitable constant summarize rqi algorithm one step inverse iteration cf algorithm 31 rayleigh quotient iteration solve solve solve 35 rounding errors stability rqi iteration converges f k g k fi k tend zero consider rounding errors occur evaluation residuals 311 let u unit roundoff see 13 chap 3 computed residual vector satisfies obviously convergence cease residuals 311 dominated roundoff assume perform one iteration exact solution x tls r tls n1 first correction current approximation obtained solving linear system 313 becomes correction gives estimate estimate consistent condition estimate tls problem note equations 318 similar form appear corrected seminormal equations ls problem see 1 2 sec 665 detailed roundoff error analysis similar done ls problem would become complex attempted seems reasonable conjecture oe 0 2 suffice solve linear equations correction w k using cholesky factorization methods solution linear systems considered detail section 4 4 solving linear systems rqi method formulated previous section main work consists solving step two linear systems form oe approximation oe n1 varies step step provided system 41 symmetric positive definite 41 direct linear solvers system 41 solved computing sparse cholesky factorization matrix gamma oe 2 note formed symbolic phase factorization repeated however big disadvantage new numerical factorization computed step rqi algorithm greater accuracy stability solving ls problems often preferred use qr factorization instead cholesky factorization however since tls normal equations term oe 2 subtracted straightforward cholesky factor matrix gamma oe 2 obtained qr factorization matrix ioei imaginary unit downdating problem qr factorization performed using stabilized hyperbolic rotations see 2 pp 143144 hyperbolic householder transformations see 22 however sparse case attractive alternative since would require nontrivial modifications existing software sparse qr factorization 42 iterated deregularization solve tls normal equations using single factorization adapt iterated regularization scheme due riley analyzed golub 9 scheme solve tls normal equations iteration affi lim k1 x b iteration converge linear rate equal ae n provided ae 1 iteration may implemented efficiently qr decomposition available pursue method since advantage preconditioned conjugate gradient method developed 3 43 preconditioned conjugate gradient algorithm performing change variables given nonsingular matrix multiplying left gammat system 41 becomes system symmetric positive definite provided oe oe 0 n hence conjugate gradient method applied use preconditioners developed ls problem survey see 2 ch 7 following consider special choice preconditioner complete cholesky factor r r qr decomposition unless huge often feasible choice since efficient software sparse cholesky sparse qr factorization readily available 2 ch 7 using ar preconditioned system 42 simplifies note although disappeared system equations matrixvector multiplications matrices used compute righthand side f inverse iteration step used initialization solution obtained two triangular solves standard conjugate gradient method applied system 42 formulated terms original variables w resulting algorithm slightly simplified version algorithm pcgtls given 3 algorithm 41 pcgtls preconditioned gradient method solving using cholesky factor r preconditioner initialize w ks ks j1 k 2fi denote original preconditioned matrix e respectively simple calculation shows condition number transformed system reduced factor spectrum c clustered close 1 particular limit eigenvalues e c lie interval note relation condition number tls hence unless oe 0 expect choice preconditioner work well solving shifted system 41 positive definite oe oe 0 n case pcgtls division computing ff k always carried n system 42 positive definite division zero occur avoided including test ensure equivalently kp cg iterations considered failed rqi step repeated new smaller value oe 2 eg accuracy tls solutions computed rayleigh quotient iteration basically depend accuracy residuals stability method used solve linear systems 41 note cg method cgls1 ls problem related pcgtls shown good numerical stability properties see 5 44 termination criteria pcgtls rqi iteration using pcgtls inner iteration solving linear systems inexact newton method solving system nonlinear equa tions methods studied dembo eisenstat steihaug 7 consider problem terminate iterative solver rate convergence outer newton method preserved consider iteration r k residual error 7 shown maintaining convergence order 1 requires k 1 residuals satisfy inequalities forcing sequence practice asymptotic result turns little practical use context asymptotic cubic convergence realized ultimate accuracy possible double precision already achieved prac tical ad hoc termination criterion pcgtls iterations described together numerical results reported remark second linear system solved rqi righthand side converges x tls hence tempting use value u obtained last rqi initialize pcgtls next step however experience slows convergence compared initializing u zero 5 numerical results 51 accuracy termination criteria numerical tests performed matlab sun sparc station 10 using double precision unit roundoff initial testing used contrived test problems similar 5 generated following way 1 let e z random orthogonal matrices let ax ensures norm solution reflect illconditioning add random perturbations note since oe perturbation e makes rank deficient therefore realistic consider perturbations test termination criteria inner iterations iterations log0x figure 51 errors problem ps3015 systems solved pcgtls iterations iterations log0x figure 52 errors systems solved pcgtls used problem p 30 15 oe 0 linear systems arising rqi solved using pcgtls cholesky factor preconditioning criterion 46 shows linear systems solved accurately rqi method converges rate convergence depends ratio oe n1 oe 0 n see 44 usually rapid used simple strategy kth step rqi test problems neither large sparse iterations performed 0 parameter chosen figure 51 show results 2 plots almost indistinguishable whereas delay convergence indeed problem taking iterations pcgtls suffices give result using exact direct solver since refactorizations performed object minimize total number pcgtls iter ations based considerations test results recommend taking work well problems ratio oe n1 oe 0 n smaller rarely 23 rqi iterations needed figure 52 show results problem ps3015 different error levels respectively needed achieve accuracy 10 gamma11 x tls since oe 0 equal best limiting accuracy expected note also error oe n1 converges machine precision usually one less iteration supports use criterion 317 terminate rqi 52 improvement inverse iteration show improvement resulting including initial step inverse iteration figure 53 show results problem considered first two error levels one rqi iteration suffices highest error level oe n1 converges two iterations x tls three 22 iterations log0x figure 53 errors one step inverse iteration linear systems solved pcgtls k 1 iteration consider second test problem 14 defined 2 r nthetangamma1 e vector entries generated randomly normal distribution mean 00 variance 10 scaled jjejj 001 condition numbers 2527 respectively problem features similar small illcondi tioned example discussed previously section 22 although norm solution x ls large 22 iterations log0x figure 54 second test problem 0001 rqi withoutwith one step inverse iteration applying rqi algorithm obtained results shown figure 54 initial approximation aex ls far outside interval oe n1 oe 0 n thus matrix gamma oe 2 initially positive definite cannot guarantee existence cholesky factor however algorithm pcgtls still break shown figure 54 limiting accuracy obtained five rqi iterations surprisingly good performance rqi explained fact even though x ls approximate x tls well angle small cosine equals 098453 performing one step inverse iteration applying rqi algorithm gives much improved convergence one initial step inverse iteration suffices give initial approximation interval oe n1 oe 0 n compared 1223 steps bisection needed achieve starting approximation see 14 three rqi iterations give solution x tls error close limiting accuracy see fig 54 note cases obtained oe n1 full machine precision also relative error norm tls solution consistent condition 53 problem signal restoration toeplitz matrix used example comes application signal restoration see 14 example 3 specifically n theta n gamma 2 convolution matrix constructed entries first column given exp zero otherwise entries first row given zero otherwise 8 toeplitz matrix righthand side vector g constructed e e random toeplitz matrix structure e random vector entries e e generated randomly normal distribution mean 00 variance 10 scaled 14 problems convergence reported however due choice righthand side 1 taken vector ones unperturbed problem vector orthogonal space spanned left singular vector corresponding smallest singular value therefore magnitude component direction initial vector x ls small order fl also although quite well conditioned least squares residual large tls problem therefore close nongeneric problem thus illconditoned extreme illconditioning righthand side behavior solution method becomes sensitive particular random perturbation added therefore instead chosen righthand side g 2 given tls problem much better conditioned see table 51 convergence obtained two iterations see figure 55 table 51 condition numbers test problem 3 righthand sides g 2iterations log0x figure 55 third test problem rqi one step inverse iteration 6 summary developed algorithm solving large scale tls problems based rayleigh quotient iteration computing right singular vector defining solution main work method consists solving sequence linear systems matrix gamma oe 2 oe current approximation smallest singular value oe n1 b large sparse tls problems linear systems solved preconditioned conjugate gradient method efficient preconditioner given possibly incomplete cholesky factorization qr factorization termination criteria inner outer iterations given conjecture described method almost always computes tls solution accuracy compatible backward stable method although detailed error analysis given conjecture supported numerical results methods solving tls problem necessity complex linear ls problem algorithm contains several ad hoc choices limited set test problems tried failed almost singular problems total least squares model relevant used method perturbation e rank one matrix general dense sometimes desired find perturbation e preserves sparsity structure newton method difficult problem developed rosen park glick 21 however complexity algorithm limits fairly small sized problems recently method potential applied large sparse problems given yalamov yun yuan 26 algorithm converges linear rate may suffice obtain low accuracy solution r improving accuracy computed singular values numerical methods solving least squares problems analysis total least squares problem survey condition number estimation triangular matrices accuracy stability numerical algorithms total least squares method toeplitz systems equations minimum eigenvalue symmetric positivedefinite toeplitz matrix rational hermitian interpolation sparse qr factorization matlab symmetric eigenvalue problem convergence practical qr algorithm total least norm formulation solution structured problems stability pivoting criteria combining inverse rayleigh quotient iteration iterative algorithms computing singular subspace matrix associated smallest singular values total least squares problem computational aspects analysis successive least squares method structured total least squares iterative methods least squares total least squares problems tr ctr computing smallest singular triplets implicitly restarted lanczos bidiagonalization applied numerical mathematics v49 n1 p3961 april 2004