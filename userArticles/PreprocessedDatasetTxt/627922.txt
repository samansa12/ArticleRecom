performance analysis three textjoin algorithms abstractwhen multidatabase system contains textual database systems ie information retrieval systems queries global schema multidatabase system may contain new type joinsjoins attributes textual type three algorithms processing type joins presented io costs analyzed paper since type joins often involves document collections large size important find efficient algorithms process three algorithms differ whether documents inverted files documents used process join analysis simulation results indicate relative performance algorithms depends input document collections system characteristics input query algorithm type input document collections algorithm likely perform well identified integrated algorithm automatically selects best algorithm use also proposed b introduction researches multidatabase system intensified recent years 4 5 9 13 12 16 19 paper consider multidatabase system contains local systems manage structured data eg relational dbss local systems manage unstructured data eg information retrieval ir systems handling text global schema multidatabase system integrated local database schemas provides overall picture sharable data local systems global query language used specify queries global schema referred global queries thereafter retrieve data represented global schema example global schema relational data model sql used global query language since multidatabase system considered paper contains 1 department computer science state university new york binghamton binghamton ny 139026000 email mengcsbinghamtonedu 2 department electrical engineering computer science university illinois chicago chicago il 60607 email yueecsuicedu 3 computer science department ucla los angeles ca 90024 email weiwangcsuclaedu 4 school computer science florida international university miami fl 33199 email rishenfiuedu components relational components global query language must capable accommodating structured data unstructured data sqlbased query language serve purpose proposed 1 paper extend features language specify queries database frontend global users may submit queries contain joins attributes textual type motivating example presented section 2 likely join comparator textual attributes similar matches objects similar textual contents based similarity function since textual object essentially document join pair similar documents among two document collections corresponding two textual attributes although types comparators textual attributes may exist similar operator key operator textual data therefore concentrate operator paper processing joins nontextual attributes studied extensively much research reported processing joins textual attributes literature 6 authors reported case study automating assignment submitted papers reviewers reported study requires match abstract submitted paper number profiles potential reviewers problem essentially process join two textual attributes since document collections involved small efficient processing strategy join concern instead emphasis work accuracy automated match somewhat related problem consecutive retrieval problem 7 17 determine given set queries q set records r whether exists organization records query q relevant records loosely similar records stored consecutive storage locations interpret q r two document collections consecutive retrieval problem deals storage aspect efficient retrieval relevant documents one collection document another collection however major difference consecutive retrieval problem join processing problem former assumes knowledge documents r relevant document q latter needs find documents one collection similar document another collection another related problem processing set queries document collection batch several differences batch query problem join problem 1 former many statistics queries important query processing optimization frequency term queries available unless collected explicitly unlikely since batch may need processed unlikely cost effective collect statistics 2 special data structures commonly associated document collection inverted file unlikely available batch reason given see paper availability inverted files means applicability certain algorithms clustering problem ir systems 14 requires find document documents similar document collection considered special case join problem described two document collections involving join identical straightforward way exists processing joins textual attributes multidatabase environ ment method described follows treat document one collection query process query collection independently find similar documents however method extremely expensive since either documents one two collections searched inverted file collection utilized processing document collection example consider smart system 3 developed cornell university smart system uses inverted file process user queries collection whose documents used queries large number documents using inverted file collection process query independently easily incur cost several orders magnitude higher better join algorithm see section 6 therefore important develop efficient algorithms processing joins textual attributes paper following contributions 1 present analyze three algorithms processing joins attributes textual type 2 cost functions based io cost algorithms provided 3 simulation done compare performance proposed algorithms investigation indicates one algorithm definitely better algorithms circumstances words algorithm unique value different situations 4 provide insight type input document collections algorithm likely perform well give algorithm determines one three algorithms used processing textjoin aware similar study reported rest paper organized follows motivating example presented section 2 section 3 include assumptions notations need paper three join algorithms introduced section 4 cost analyses comparisons three algorithms presented section 5 section 6 simulation carried compare proposed algorithms suggest algorithm use particular situation integrated algorithm automatically selects best algorithm use also included section conclude discussion section 7 motivating example assume following two global relations obtained schema integration applicantsssn name resume positionsp title job descr relation applicants contains information applicants job positions relation positions resume job descr type text consider query find position applicants whose resumes similar positions description query expressed extended sql follows select pp ptitle assn aname positions p applicants aresume similar pjob descr whereclause query contains join attributes textual type type joins appear traditional database systems note aresume similar pjob descr pjob descr similar aresume different semantics former find resumes job description latter find job descriptions resume job descriptions listed output former however job description may listed output latter among similar job descriptions resume later see asymmetry operator similar impact evaluation strategy important differences joins relational database systems join two textual attributes consider relational join r1a r2a comparator given tuple t1 r1 tuple t2 r2 t1a t2a true immediately know t1 t2 satisfy join however given resume r given job description j way us know immediately whether r similar j true since sure r among resumes similar j resumes considered process join comparing job description resumes job description compared resumes resumes similar identified partial result produced however process join comparing resume job descriptions resume compared job descriptions partial result generated case many intermediate results ie similarity values resumes job descriptions need maintained main memory observation indicates comparing job description resumes natural way process textual join due selection conditions attributes relations contain textual attributes possible subset set documents collection need participate join example consider query find position whose title contains engineer applicants whose resumes similar positions description select pp ptitle assn aname positions p applicants ptitle like engineer aresume similar pjob descr selection ptitle like engineer evaluated first job descriptions whose position title contains engineer need participate join paper interested studying algorithms used process following query select r1x1 r2y2 r1 r1c1 similar r2c2 c1 c2 attributes representing two document collections collection 1 collection 2 respec tively clearly join evaluated form c1 similar c2 impact selections also addressed 3 assumptions notations using vector representation 14 document represented list terms together number occurrences document term associated weight indicating importance term document usually terms identified numbers save space assume document consists list cells form w called documentcell dcell term number w number occurrences term document dcells document ordered ascending term numbers size dcell jtj number bytes contain x practice sufficient multidatabase environment different numbers may used represent term different local ir systems due local autonomy several methods may used overcome problem one method use actual terms rather term numbers disadvantage size document collection become much larger another method establish mapping corresponding numbers identifying term mapping structure usually table two columns stored main memory substantially degrade performance assuming approximately 150 pages size 4kb needed mapping structure accommodate 100000 distinct terms since total size mapping structure less 1mb likely mapping structure held memory attractive method standard mapping terms term numbers local ir systems use mapping standard beneficial improving performance multidatabase system save communication costs actual terms needs transferred processing costs efficient compare numbers compare actual terms need search mapping table simplify presentation assume number always used represent term local ir systems note assumption simulated always keeping mapping structure memory different numbers used represent term different local systems remaining discussion terms term numbers used interchangeably common terms documents d1 d2 let u un numbers occurrences terms d1 d2 respectively similarity d1 defined realistic similarity function divide similarity norms documents incorporate use inverse document frequency weight 14 assigns higher weights terms occur fewer documents normalization carried precomputing norms documents storing performing divisions processing documents inverse document frequency weight precomputed term storing parts list heads inverted files sake simplicity presentation use number occurrences instead weights given term given document collection c inverted file entry consists list icells short invertedfilecell form w document number w number occurrences document number assume icells inverted file entry ordered ascending document numbers size icell jdj jwj icells dcells approximately size use following notations discussion number documents collection size available memory buffer pages number terms collection size btree collection pages assume tightly packed ie space left unused page except possibly last page probability term collection c1 also appears collection c2 q probability term collection c2 also appears collection c1 ff cost ratio random io sequential io bytes 4kb average number terms document collection average size inverted file entry collection pages 5 k n p size inverted file collection pages j assume tightly packed average size document collection pages 5 k size collection pages n assume tightly packed inverted file entry term collection operator similar used fraction similarities nonzero assume documents collection stored consecutive storage locations therefore documents collection scanned storage order total number pages read also total io cost hand documents collection read one time random order document kept memory processed total number pages read approximately n ds e total cost approximately n ds e ff dxe denotes ceiling x ff cost ratio random io sequential io due additional seek rotational delay random read similarly assume inverted file entries collection stored consecutive storage locations ascending term numbers typically dj e pages read inverted file entry brought memory random order note given document collection document numbers term numbers size total size total size corresponding inverted file paper io cost used analyze compare different algorithms centralized environment io cost dominates cpu cost cost analysis comparisons distributed environment conducted future algorithms section present three algorithms processing joins textual attributes algorithms analyzed compared next two sections assume existence inverted file document collections depending documents andor inverted files used evaluate join three basic algorithms constructed first algorithm use documents process join second algorithm use documents one collection inverted file another collection evaluate join third algorithm uses inverted files collections job collection documents represented documentterm matrix rows documents columns terms inverted file entries terms therefore name first algorithm horizontalhorizontal nested loop hhnl second algorithm horizontalvertical nested loop hvnl third algorithm verticalvertical merge vvm 41 algorithm hhnl straightforward way evaluating join compare document one collection every document collection although simple method several attractive properties first one two collections reduced selection conditions remaining documents need considered second documents generally read sequentially resulting sequential ios discussion section 2 know natural process join comparing document c2 documents c1 natural use c2 outer collection c1 inner collection join evaluation call order forward order reverse order backward order backward order efficient c1 much smaller c2 consider forward order first adopt policy letting outer collection use much memory space possible case lets inner collection use much memory space possible equivalent backward order discussed later memory allocation policy algorithm hhnl described follows reading next x documents c2 main memory integer x determined scan documents c1 document c1 memory compute similarity document every document c2 currently memory document d2 c2 keep track documents c1 processed d2 largest similarities d2 rigorously c2 outer collection need reserve space accommodate least one document c1 ds 1 e pages memory need reserved c1 also need reserve space save similarities document c2 currently memory assume similarity value occupies 4 bytes number documents c2 held memory buffer size b estimated size page bytes present algorithm hhnl documents c2 read fif unprocessed documents c2 left input next x1 unprocessed documents c2 main memory else input remaining unprocessed documents c2 main memory unprocessed d2 c2 memory document d1 c1 fcompute similarity d2 d1 greater smallest largest similarities computed far d2 freplace smallest largest similarities new similarity update list documents c1 keep track documents largest similarities d2 large heap structure used find smallest largest similarities algorithm consider backward order c1 used outer collection evaluate join c2 scanned set documents c1 currently memory let d1 first document c1 read memory c2 scanned n 2 similarities d1 every document c2 computed since document c2 need find documents c1 similar need keep track documents c1 largest similarities document c2 means need keep track n 2 similarities backward order evaluation words need memory space size 4 n 2 p keep similarities compared forward order requires 4 x1p pages keep track needed similarities memory space needed save similarities backward order adverse impact performance backward order result forward order likely perform better backward order two document collections size however c1 much smaller c2 backward order still outperform forward order example c1 entirely held memory one scan collection needed process join backward order matter large c2 42 algorithm hvnl algorithm uses documents one collection inverted file collection compute similarities information retrieval system processing user query considered document find documents system similar user query one way process query compare document system method requires almost nonzero entries documentterm matrix accessed efficient way use inverted file document collection process query method used smart system 3 advantage method needs access nonzero entries columns documentterm matrix correspond terms query since number terms query usually small fraction total number terms documents system inverted file based method accesses small portion documentterm matrix algorithm hvnl straightforward extension method situation need find similar documents one collection every document another collection process using inverted file compute similarities document c2 documents c1 described follows let w next dcell considered let inverted file entry corresponding c1 fd 1 w 1 n wn g document numbers processed similarity document accumulated far u accumulated similarity considered w w contribution due sharing term i1n terms processed similarities documents c1 computed documents c1 similar identified note last dcell processed intermediate similarities documents c1 need saved amount memory needed purpose proportional n 1 analysis reveal using inverted file c2 process join needs memory space store intermediate similarities amount proportional n 2 practice nonzero similarities need saved use ffi denote fraction similarities nonzero straightforward way process join go process document c2 independently read document c2 turn memory read inverted file entries c1 corresponding terms process note terms necessarily appear c1 problem straightforward method lack coordination processing different documents c2 result term appears k documents c2 inverted file entry term assume also appears c1 c1 read k times algorithm hvnl designed reuse inverted file entries read memory processing earlier documents process later documents save io cost due space limitation usually inverted file entries read earlier kept memory therefore algorithm also needs policy replacing inverted file entry memory new inverted file entry let frequency term collection number documents containing term known document frequency document frequencies stored similarity computation ir systems extra effort needed get replacement policy chooses inverted file entry whose corresponding term lowest frequency c2 replace reduces possibility replaced inverted file entry reused future make best use inverted file entries currently memory new document d1 c2 processed terms d1 whose corresponding inverted file entries already memory considered first means newly read document scanned twice memory first scan find terms whose corresponding inverted file entries already memory second scan process terms list contains terms whose corresponding inverted file entries memory maintained note inverted file entries read earlier kept memory still possible read inverted file entry one time note also worst case scenario algorithm hvnl document c2 consideration none corresponding inverted file entries currently memory case algorithm hvnl deteriorates straightforward method present algorithm hvnl document c2 ffor term also appears c1 inverted file entry c1 1 memory accumulate similarities term also appears c1 fif inverted file entry c1 1 memory available memory space accommodate tread else find inverted file entry memory lowest document frequency replace accumulate similarities find documents c1 largest similarities inverted file btree used find whether term collection present corresponding inverted file entry located one possible way improve algorithm improve selection next document process intuitively always choose unprocessed document c2 whose terms corresponding inverted file entries c1 largest intersection inverted file entries already memory next document process likelihood inverted file entry already memory reused increased example consider three documents three terms t5g suppose terms smaller subscripts lower document frequencies suppose memory buffer large enough hold three inverted file entries d1 d2 d3 processed given order inverted file entry needs read exactly however processing order d1 d3 d2 inverted file entry corresponding t2 read twice inverted file entries read exactly clearly example order fd1 d2 d3g better order fd1 d3 d2g order optimal incurs minimum io cost question optimal order found efficiently unfortunately shown proposition problem finding optimal order nphard proposition problem finding optimal order documents c2 best performance achieved nphard proof shown 11 following problem known optimal batch integrity assertion verification obiav find optimal order verifying set integrity constraints verifying constraint requires set pages brought secondary storage memory nphard problem seen optimal order problem case essentially optimal order problem obiav following correspondences two problems easily established processing document c2 corresponds verifying integrity constraint need read set inverted file entries processing document c2 corresponds need bring set pages verifying integrity constraint inverted file entry read processing one document may used processing another document corresponds page brought verifying one integrity constraint may used verifying another integrity constraint therefore optimal order problem case also nphard decide pursue issue finding optimal order addition nphard nature another problem associated optimal order reading documents order rather storage order expensive random ios incurred 43 algorithm vvm algorithm vvm uses inverted files collections compute similarities strength algorithm needs scan inverted file compute similarities every pair documents two collections regardless sizes two collections provided memory space large enough accommodate intermediate similarity values case algorithm vvm least good algorithm hhnl algorithm hhnl needs scan document collection least size inverted file collection size collection algorithm vvm tries compute similarities every pair documents two collections simultaneously result needs save intermediate similarities thus memory requirement saving similarities proportional n 1 n 2 independent number terms document large algorithm vvm run summary algorithm vvm likely perform well document collections large size none entirely held small number documents possible document large size another situation algorithm vvm may well vocabularies two document collections different example one collection medicine computer science case number nonzero similarities documents two collections likely small algorithm vvm described follows scan inverted files two collections parallel scan two inverted file entries correspond term invoke similarity accumulating process recall assumed inverted file entries stored ascending term numbers therefore one scan inverted file sufficient much like merge phase merge sort similarity accumulating process described follows let um g two inverted file entries term two collections respectively two inverted file entries processed similarity documents r p q accumulated far u pq u p v q u pq accumulated similarity r p q considered extend algorithm vvm follows tackle problem insufficient memory space intermediate similarities suppose sm total number pages needed store intermediate similarities pairs documents two collections considered time suppose available memory space storing intermediate similarities sm divide collection c2 dsmme subcollections compute similarities documents subcollection documents c1 one subcollection time since subcollection one scan original inverted files collections needed extension incurs cost dsmme times higher memory large enough hold intermediate similarities detailed cost analysis see section 53 5 io cost analysis section provide analysis io cost algorithm presented section 4 51 algorithm hhnl let x number documents c2 held memory buffer size b defined section 41 since x documents c2 c1 needs scanned total io cost hhnl estimated first term cost scanning c2 second term cost scanning c1 dn 2 xe number times c1 needs scanned cost formula assumes ios sequential ios ie c1 c2 sequentially scanned reasonable document collection read dedicated drive little interference io requests case ios may become costly random ios first consider case n 2 x following interleaved io cpu patterns observed x documents c2 read document c1 read cpu take time compute similarities x documents cpu computation io resources may allocated jobs case next document c1 use random io readin next x documents c2 words worst case documents c1 read using random io every x documents c2 random io number actual random ios scanning documents c1 also depends document size estimated minfd 1 used otherwise n 1 used therefore n 2 x worst scenario total io cost estimated follows entire collection c2 scanned sequentially held memory remaining memory space used hold documents c1 therefore c1 read dd 1 blocks block read sequentially case 52 algorithm hvnl recall btree maintained document collection quickly locating inverted file entry given term size btree estimated follows typically cell btree occupies 9 bytes 3 term number 4 address 2 document frequency document collection n terms size btree approximately 9np leaf nodes considered size terribly large example document collection 100000 distinct terms btree takes 220 pages size 4kb assume entire btree read memory inverted file needs accessed incurs onetime cost reading btree let x number inverted file entries c1 held memory memory buffer fully used addition x inverted file entries memory size b also needs contain document c2 size ds 2 e btree size bt 1 nonzero similarities values document c2 currently processing documents c1 list containing terms whose corresponding inverted file entries main memory size xjtjp therefore x estimated follows c assume readin documents c2 incurs sequential ios io cost hvnl estimated follows first case corresponds case x greater equal total number inverted file entries c1 ie 1 case either read entire inverted file c1 sequential order corresponds first expression minfg read inverted file entries needed process query number 2 q random order corresponds second expression minfg memory large enough since x second case corresponds case memory large enough hold inverted file entries c1 large enough hold necessary inverted file entries last expression case memory large enough hold needed inverted file entries c1 case second term cost finding reading inverted file entries c1 correspond terms documents c2 memory fully occupied suppose memory large enough hold inverted file entries c1 corresponding terms first documents c2 fraction x1 inverted file entries corresponding terms sth document c2 ie inverted file entries c1 corresponding terms first documents c2 held memory let number new inverted file entries need read new document c2 processed memory fully occupied third term total cost reading new inverted file entries processing remaining documents c2 discuss x1 estimated first number distinct terms documents c2 estimated therefore smallest satisfying q fm x note x gamma q fs gamma 1 number inverted file entries still held memory inverted file entries c1 corresponding terms first documents c2 read q number new inverted file entries need read sth document c2 processed x1 estimated finally estimated q fs discussed section 51 possible ios reading documents c2 random ios due obligations io device inverted file entries accommodated still memory space left remaining memory space used sequentially scan multiple documents c2 time based observation random ios considered total io cost hvnl estimated would easier understand formula compared formula computing hvs first expression minfg remaining memory space inverted file entries accommodated slight modification similarity accumulation c1 used outer collection process query case memory space needed store intermediate similarities 4ffin 2 p cost backward order estimated way case forward order 53 algorithm vvm avoid much higher cost random ios simply scan inverted files two collections parallel scan two inverted file entries correspond term invoke similarity accumulating process recall assumed inverted file entries stored ascending term numbers therefore one scan inverted file sufficient compute similarities memory large enough accommodate intermediate similarities therefore ios sequential ios total io cost algorithm vvm ios could actually random ios due obligations io device worst case scenario ie ios random ios total io cost algorithm vvm estimated algorithm vvm usually requires large memory space save intermediate similarity values nonzero similarities stored memory space storing intermediate similarity values algorithm vvm 4ffi n 1 n 2 p memory space large enough accommodate intermediate similarity values simple extension algorithm vvm made see section 43 case total cost estimated multiplying vvs vvr dsmme total number pages needed store intermediate similarities pairs documents two collections considered time e available memory space storing intermediate similarities therefore general formula estimating total io cost ios sequential ios given general formula estimating total io cost ios random ios 54 comparisons algorithm hhnl uses two document collections input two document collections needs scanned least constitutes lower bound io cost algorithm algorithm hhnl use special data structures inverted files btrees thus easily applicable easier implement since algorithm hhnl uses documents directly similarity computation benefits quite naturally possible reductions number documents either one collections resulted evaluation selection conditions nontextual attributes relevant relations memory space requirement algorithm storing intermediate similarity values generally small compared algorithms algorithm hvnl uses one document collection one inverted file btree corresponding inner collection input document collection always scanned access inverted file entries complex one hand inverted file entries need read fact inverted file entries whose corresponding terms also appear document collection need accessed hand inverted file entries may read many times due appearances multiple documents c2 although effort made algorithm reuse inverted file entries currently memory expected algorithm competitive one following two situations 1 one document collection say c2 much smaller collection case likely small fraction inverted file entries inverted file needs accessed means small portion documentterm matrix corresponding c1 accessed case contrast algorithm hhnl used entire matrix needs accessed least even c2 held entirely memory c2 contains one document situation becomes extreme case processing single query document collection mentioned using inverted file process single query shown ir superior using documents directly note originally large document collection may become small conditions attributes relevant relation evaluated 2 collection documents used close documents storage order share many terms nonclose documents share terms increases possibility reusing inverted file entries memory reduces possibility rereading inverted file entries could happen documents collection clustered algorithm hvnl accesses inverted file entries random order two negative effects io cost one random ios expensive sequential ios even inverted file entry occupies small fraction page whole page containing entry read words e size inverted file entry need read dee even e small say 01 therefore size inverted file entry close integer competitiveness algorithm hvnl increased algorithm hvnl uses primarily two data structures one inverted file btree terms one disadvantage using inverted file size file remains even number documents corresponding document collection reduced selection unless construct another inverted file reduced set highly unlikely due cost involved memory space requirement algorithm hvnl storing intermediate similarities higher algorithm hhnl lower algorithm vvm algorithm vvm uses two inverted files input discussed algorithm nice onescan property namely needs scan inverted file compute similarities regardless sizes two collections provided memory space large enough accommodate intermediate similarity values memory space large enough accommodate intermediate similarity values algorithm vvm least efficient algorithm hhnl far io cost concerned major drawback algorithm vvm needs large memory space save intermediate similarities two situations algorithm vvm likely perform well first document collections large size small number documents second vocabularies two document collections different two situations number nonzero similarities documents two collections likely small another disadvantage algorithm vvm sizes inverted files remain even number documents corresponding document collections reduced 6 simulation results due large number parameters cost formulas algorithms presented difficult compare performance algorithms based formulas directly section algorithms compared based simulation results computed cost formulas derived section 5 objective identify impact variations parameters algorithms words would like find situation algorithm performs best statistics three document collections collected arpanist 8 namely wsj wall street journal fr federal register doe department energy used simulation statistics collections shown table 1 last three rows estimated us based among three document collections fr fewer larger documents doe smaller documents number documents wsj lies fr doe average size documents wsj simulations page size p fixed 4kb fraction similarities nonzero ffi fixed 01 fixed 20 note algorithm hhnl backward order algorithm involve none really sensitive large say hundreds probability q computed follows wsj fr doe documents 98736 26207 226087 terms per doc 329 1017 89 total distinct terms 156298 126258 186225 collection size pages 40605 33315 25152 avg size document 041 127 0111 avg size inv fi en 026 0264 0135 table 1 statistical information several document collections formula says given number distinct terms c2 ie 2 smaller number distinct terms c1 1 smaller probability term c2 also appears c1 much larger 2 q become closer 1 otherwise q 08 probability p computed similar manner parameters b memory size ff assign base value impact parameter studied vary values parameter let parameter use base value present following five groups simulation results group 1 group real collection used collection c1 collection c2 since three real collections wsj fr doe two parameters b ff six simulation results collected group 2 group different real collections used c1 c2 b vary ff use base value three real collections six simulations designed group 3 group c1 c2 continue use real collections small number documents c2 used participate join experiments used investigate impact local selections simulations group use base values two parameters since three real collections three simulation results collected group group 4 group c1 continue use real collections c2 collections small number documents difference group 3 group 4 former uses small number documents c2 originally large collection c2 latter uses originally small collection c2 difference following impacts cost 1 documents c2 need read randomly former still read sequentially latter 2 size inverted file size btree collection c2 former computed based original collection documents used impact cost algorithm vvm experiments real collection chosen c1 c2 derived c1 simulations group use base values two parameters since three real collections three simulation results collected group group 5 group collection c1 collection c2 use new collections remain identical new collection derived real collection reducing number documents real collection increasing number terms document real collection factor collection size remains simulations group especially aimed observing behavior algorithm vvm base values two parameters used three simulation results collected group since three real collections space consideration simulation results backward order approach presented notice backward order approach makes difference hhnl hvnl used see discussions section 41 section 52 compared forward order backward order requires memory space store intermediate similarities result backward order outer collection inner collection a2 incurs somewhat higher cost forward order outer collection b1 inner collection b2 a1 b1 collection a2 b2 collection figures section value k yaxis equivalent 10 k sequential page ios figures 1 3 4 unit xaxis equivalent 10000 pages simulation results group 1 following simulations conducted group simulation 1 changes 10000 50000 increment 5000 simulation 2 changes 10000 50000 increment 5000 simulation 3 changes 10000 50000 increment 5000 simulation 4 changes 3 10 increment 1 simulation 5 changes 3 10 increment 1 simulation changes 3 10 increment 1 following observations made result simulation 1 see figure 1 1 algorithm hhnl outperforms two algorithms especially b small 2 several reasons algorithm hvnl performs poorly first outer document collection many documents n causes repeated readins many inverted file entries c1 second algorithm hvnl requires random ios third 2 j 1 close integers result document inverted file entry read algorithm hvnl incurs twice much cost algorithm hhnl 1 versus 041 document 1 versus 026 inverted file entry 3 main reason algorithm vvm performs poorly memory requirement storing intermediate similarities 952031 pages much greater available memory result many scans two inverted files needed process join 4 algorithms perform better larger available memory larger one document collection inverted file held memory entirety happens algorithm hhnl algorithm hvnl similar performances since case algorithm hhnl scans two document collections algorithm hvnl scans one document collection one inverted file size document collection similar observations made result simulation 1 also made results simulation 2 simulation 3 shown relatively speaking performance algorithm vvm simulation 2 largest improvement due larger size documents fewer number documents however memory requirement storing intermediate similarities case 67071 pages still large available memory handle least two scans two inverted files used process join surprisingly relative performance algorithm vvm simulation 3 become much worse due smaller size documents larger number documents io cost hhs 3 hvr theta theta theta theta theta theta theta theta theta theta vvs 4 figure 1 result simulation 1579 ff io cost hhs 3 hvr theta theta theta theta theta theta theta theta theta vvs 4 figure 2 result simulation 4 following observations made result simulation 4 1 algorithm hhnl best performer among three algorithms 2 hhs vvs independent ff involve random ios 3 others become worse ff increases 4 algorithm hvnl sensitive larger ff similar observations made results simulation 5 6 simulation results group 2 group different real collections used c1 c2 base values used b ff three real collections following six simulations designed simulation 7 changes 10000 50000 increment 5000 simulation 8 changes 10000 50000 increment 5000 simulation 9 changes 10000 50000 increment 5000 simulation 10 changes 10000 50000 increment 5000 simulation 11 changes 10000 50000 increment 5000 simulation 12 changes 10000 50000 increment 5000 comparing result simulation 7 result simulation 8 see figures 3 4 following observations made 1 algorithm hhnl best performer simulation 7 algorithm hvnl sometimes beats hhnl simulation 8 reason algorithm hhnl lets outer collection use much memory space possible algorithm hvnl lets inner collection use much memory space possible example consider figure 4 figure case entire inverted file fr held memory result algorithm hvnl used one scan wsj inverted file fr needed process join however algorithm hhnl used memory large enough hold entire outer collection wsj result one scan wsj two scans inverted file fr needed process join algorithm hhnl used 2 change cost algorithm vvm completely symmetric two document collections 3 none two collections entirely held memory get mixed results algorithm hhnl sometimes better result simulation 7 simulation 8 sometimes opposite true smaller collection held memory better performance achieved using smaller collection outer collection reason algorithm hhnl better result simulation 7 simulation 8 b becomes 35000 larger observation also supports earlier argument section 41 backward order outperform forward order backward order implies much smaller outer collection 4 situation algorithm hhnl reversed algorithm hvnl reason algorithm hhnl lets outer collection use much memory space possible algorithm hvnl lets inner collection use much memory space possible similar observations made result simulation 7 result simulation 8 also made result simulation 9 result simulation 10 well result simulation 11 result simulation 12 results simulations 9 12 shown simulation results group 3 group c1 c2 continue real collections small number documents c2 used participate join let number documents c2 since n 2 read documents individually random order result cost reading documents ds 2 e ff based following new formula hhs io cost hhs 3 hvr theta theta theta theta theta theta theta theta theta theta vvs 4 figure 3 result simulation 7579 io cost hhs 3 hvr theta theta theta theta theta theta theta theta theta theta vvs 4 figure 4 result simulation 8 since small likely documents c2 held memory addition remaining memory space used read many documents c1 possible result following formula hhr compute hvs hvr need estimate number distinct terms documents number estimated fm cost formula hvs section 52 except 2 replaced ds 2 e ff 2 replaced fm let new formula denoted hvs2 since ios hvs become random ios cost formulas vvs vvr remain however memory requirement storing intermediate similarities reduced 4 n 1 deltap quantities size inverted file entries size btree collection c2 remain following three simulations carried simulation 13 changes 5 50 increment 5 simulation 14 changes 5 50 increment 5 simulation 15 changes 5 50 increment 5 following observations obtained result simulation 13 see figure 5 1 small 30 algorithm hvnl outperforms others expected algorithm hhnl becomes best performer becomes larger 2 since small documents easily fit memory result algorithm hhnl requires one scan inner document collection addition reading documents outer collection 3 case memory able accommodate intermediate similarities algorithm vvm reason algorithm vvm incurs much higher cost algorithm hhnl size inverted file collection c2 change although small number documents c2 io cost hhs 3 hvs 22 theta theta theta theta theta theta theta theta theta theta vvs 4 figure 5 result simulation io cost hhs 3 hvs 22 theta theta theta theta theta theta theta theta theta theta vvs 4 figure simulation comparing result simulation 14 shown result simulation 13 noticeable difference relative performance algorithm hvnl deteriorated algorithm hvnl becomes worse algorithm hhnl reaches 10 document fr contains much terms document wsj therefore inverted file entries need read algorithm hvnl processing document fr comparing result simulation 15 shown result simulation 13 noticeable difference relative performance algorithm hvnl improved algorithm hvnl outperforms algorithm hhnl even reaches 50 document doe contains much fewer terms document wsj therefore fewer inverted file entries need read algorithm hvnl processing document doe space consideration present simulation results situations numbers documents collections reduced selections however difficult see comparing situation one collection reduced algorithm hhnl benefit collections reduced simulation results group 4 group c1 continue use real collections c2 collections small number documents since real collections contain small number documents derive collection real collection turns quite easy given document collection first keep document size decide number documents want new collection number say number distinct terms new collection computed fm key statistics new collection become available statistics cost formulas section 5 used find cost algorithm following three simulations conducted group simulation changes 5 50 increment 5 simulation 17 changes 5 50 increment 5 simulation changes 5 40 increment 5 comparing result simulation 16 see figure 6 simulation 13 see figure 5 following observations made 1 little change algorithm hhnl since small reading documents sequentially randomly makes little difference 2 algorithm hvnl degraded somewhat effect q probability term collection c2 also appears collection c1 simulation 13 q computed based original 1 2 simulation 16 q computed based original 1 new fm since fm much smaller 1 q 092 099 computed using formula higher q values imply inverted file entries collection c1 need read result performance algorithm hvnl 3 cost algorithm vvm reduced substantially main reason behind reduction reduction size inverted file c2 simulation 13 size computed based original c2 simulation 16 size computed based reduced collection similar observations made simulation 17 simulation 18 simulation results group 5 group c1 c2 use new collections remain identical new collection derived real collection reducing number documents increasing number terms document real collection factor f ensure collection size remains following three simulations carried simulation 19 derived wsj 5 decreasing increasing factor changes 1 13 increment 2 simulation 20 derived fr 5 decreasing increasing factor changes 1 5 increment 1 simulation 21 derived doe 5 decreasing increasing factor changes 1 28 increment 3 following observations made result simulation 19 see figure 7 1 factor f small 5 algorithm hhnl outperforms algorithms however f 7 larger sequential version algorithm vvm ie vvs becomes best performer 2 vvs decreases rapidly f increases expected f reaches 11 intermediate similarities held memory result vvs reaches lower bound inverted file scanned number documents collection reduced 8976 number terms document becomes 3619 3 hvs hvr insensitive changes 4 hhr decreases f increases f increases number documents c1 decreases since number random ios bounded number documents c1 hhr decreases result similar observations simulation 19 made simulation 20 difference vvs reaches minimum faster latter reason number documents fr originally much smaller wsj similar observations simulation 19 made simulation 21 difference vvs reaches minimum slower latter reason number documents doe originally much larger wsj 61 summary simulation results following main points summarized extensive simulations f io cost hhs 3 hvr theta theta theta theta theta theta theta theta vvs 444 4 figure 7 result simulation 19 1 cost one algorithm one situation differ drastically another algorithm situation example simulation 1 algorithm hvnl incurs cost 4000 times higher algorithm hhnl memory buffer small simulation 13 cost incurred algorithm hhnl 5 times higher algorithm hvnl result important choose appropriate algorithm given situation 2 number documents one two document collections say originally small becomes small selection algorithm hvnl good chance outperform algorithms although small small enough mainly depends number terms document outer collection likely limited 100 70 simulation 15 3 number documents two collections large roughly n 1 document collections large none entirely held memory algorithm vvm sequential version outperform algorithms 4 cases simple algorithm hhnl performs well 5 costs random versions algorithms depict worst case scenario io devices busy satisfying different obligations time except algorithm vvm costs impact ranking algorithms overall simulation results match well analysis section 54 62 integrated algorithm since one algorithm definitely better algorithms circumstances desirable construct integrated algorithm automatically determine algorithm use given statistics two collections query parameters selectivities predicates nontextual attributes integrated algorithm sketched follows none two collections inverted file case hhnl used fcompute hhs using formula hhs1 compute bhhs counterpart hhs backward order used formula shown hhs bhhs use forward order hhnl else use backward order hhnl one collection inverted file hhnl hvnl used case fif selection fcompute hhs using formula hhs1 compute bhhs compute hvs using formula hvs1 compute bhvs counterpart hvs backward order used formula shown else festimate number documents participate join using selectivities compute hhs using formula hhs2 compute bhhs compute hvs using formula hvs2 compute bhvs use algorithm lowest estimated cost collections inverted file fif selection fcompute hhs using formula hhs1 compute bhhs compute hvs using formula hvs1 compute bhvs counterpart hvs backward order used formula shown compute vvs using formula vvs else festimate number documents participate join using selectivities compute hhs using formula hhs2 compute bhhs compute hvs using formula hvs2 compute bhvs compute vvs using formula vvs use algorithm lowest estimated cost 7 concluding remarks paper presented analyzed three algorithms processing joins attributes textual type analysis simulation identified algorithm type input document collections algorithm likely perform well specifically found algorithm hvnl competitive number documents one two document collections isbecomes small algorithm vvm perform well number documents two collections large document collections large none entirely held memory cases algorithm hhnl likely top performer since one algorithm definitely better algorithms proposed idea constructing integrated algorithm consisting basic algorithms particular basic algorithm invoked lowest estimated cost also indicated standardization term numbers useful multidatabase environments studies area include 1 investigate impact availability clusters performance algorithm 2 develop cost formulas include cpu cost communication cost 3 develop algorithms process textual joins parallel 4 conduct detailed simulation experiment acknowledgments would like thank anonymous reviewers valuable suggestions improve paper research supported part following grants nsf grants iri9309225 iri9509253 air force afosr 9310059 nasa nagw4080 aro bmdo grant daah040024 r adt approach full text query processing system distributed databases sdd1 automatic retrieval locality information using smart view definition generalization database integration multidatabase system query optimization heterogeneous databases automating assignment submitted manuscripts reviewers file organization consecutive retrieval property overview first text retrieval conference interoperability multiple autonomous databases introduction combinatorial mathematics scheme batch verification integrity assertions database system query processing multidatabase systems theory translation relational queries hierarchical queries introduction modern information retrieval design integrated information retrievaldatabase management system federated database systems managing distributed heterogeneous autonomous databases consecutiveretrieval problem incremental updates inverted lists text document retrieval translation objectoriented queries relational queries tr ctr nikos mamoulis efficient processing joins setvalued attributes proceedings acm sigmod international conference management data june 0912 2003 san diego california gltekin zsoyolu ismail sengr altingvde abdullah alhamdani selma aye zel zgr ulusoy zehra meral zsoyolu querying web metadata native score management text support databases acm transactions database systems tods v29 n4 p581634 december 2004