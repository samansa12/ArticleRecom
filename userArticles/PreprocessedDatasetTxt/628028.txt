automatic text categorization application text retrieval abstractwe develop automatic text categorization approach investigate application text retrieval categorization approach derived combination learning paradigm known instancebased learning advanced document retrieval technique known retrieval feedback demonstrate effectiveness categorization approach using two realworld document collections medline database next investigate application automatic categorization text retrieval experiments clearly indicate automatic categorization improves retrieval performance compared categorization also demonstrate retrieval performance using automatic categorization achieves retrieval quality performance using manual categorization furthermore detailed analysis retrieval performance individual test query provided b introduction text categorization recently become active research topic area information retrieval objective text categorization assign entries set prespecified categories document document refers piece text categories may derived sparse classification scheme large collection specific content identifiers categories may expressed numerically phrases individual words traditionally categorization task performed manually domain experts incoming document read comprehended expert assigned number categories chosen set prespecified categories inevitable large amount manual effort required instance medline corpus consists medical journal articles requires considerable human resources carry categorization using set mesh medical subject headings categories 11 promising way deal problem learn categorization scheme automatically training examples categorization scheme learned used classifying future documents involves issues commonly found machine learning problems since document may assigned one category scheme also requires assignment multiple categories growing body research addressing automatic text categorization instance probabilistic model early work lewis 8 makes use bayesian independence classifiers categorization mainly studies effect feature selection clustering automatic categorization newswire articles masand et al 10 adopt memorybased reasoning strategy classify news stories k best documents retrieved weight associated categories obtained summing similarity scores near matches yang 20 develops technique known expert network network links terms document categories weight link approaches masand et al yang similar approach based variants nearest neighbor algorithm however mention model parameter selection methods decision trees 1 linear classifiers 9 contextsensitive learning 3 learning combining classifiers 7 also proposed approaches typically construct classifier category categorization process becomes binary decision problem particular category contrast approach learns categories document one time recently lewis et al 9 compare three categorization algorithms rocchios widrowhoff exponential gradient heart disease subset medline test collection yang 21 also tests expert network method heart disease collection well different medline test collection compare categorization results later section recent efforts automatic text categorization focused categorization task alone one useful application automatic categorization support effective text retrieval apart studying effectiveness automatic categorization directly second objective paper investigate application categorization process text retrieval particular wish study whether automatically assigned categories improve retrieval performance compared categorization also investigate whether automatic categorization improve reduce effect retrieval performance achieved using manual categorization furthermore analyze retrieval performance basis individual test query gain insight interaction automatic categorization text retrieval approaches paper organized two parts part focuses directly automatic categorization approach part ii focuses application categorization text retrieval part description categorization approach given section 2 following section discusses different categorization quality metrics followed section presenting experimental results automatic categorization two document collections namely hersh 5 ohsumed 6 test collections part ii section 5 presents text retrieval approach based upon automatic categorization approach followed section describing series text retrieval experiments hersh corpus finally section 8 provides conclusions paper part description categorization approach 21 outline approach basic components automatic categorization approach consists two processes namely category extraction process parameter selection process category extraction process responsible extracting appropriate categories input document central process category learning model model provides algorithm identify categories new document collection existing precategorized document examples propose approach derived combination machine learning technique known instancebased learning text retrieval technique known retrieval feedback retrieval feedback discussed 2 4 13 16 17 technique different traditional relevance feedback technique essentially retrieval feedback supports kind automatic query refinement procedure require manual relevance judgments users traditional relevance feedback many existing approaches build separate classifier category new document processed classifier determine corresponding category appropriate contrast approach operates document level set categories identified document single run category extraction process operates according category learning model learning model requires operational parameters selected advance parameter selection process process also makes use category learning model embedded category extraction process pose parameter selection task simple optimization problem specifically parameters chosen performance categorization process measured metric optimized use tuning set approach achieve task interaction components categorization approach illustrated figure 1 given domain first invoke parameter selection process determine appropriate parameter values step carried offline beginning step determine categories new document via category extraction process done efficiently parameters learning category extraction new document set categories offline online category learning category learning model model training document instances parameter selection process process figure 1 automatic categorization approach online category learning model presented first since used processes followed description parameter selection process category extraction process 22 category learning model recall objective model select appropriate categories input document adopt extension instancebased learning collection precategorized documents used training document contains freetext portion typically title abstract set categories manually assigned document training collection considered instance exemplar represented c c denote representations freetext categories document respectively adopt vector space technique central representation framework model thus vector terms p total number unique terms collections freetext domain weight reflecting relative importance term characterizing document standard automatic document indexing techniques information retrieval employed extract terms docu ment typically term word phrase aside common function words word stemming applied term extraction process category learning model imposes restriction word stemming methods similarly c vector representing categories assigned document c weight category q total number unique categories number weighting schemes used vectors c instance use product term frequency inverse document frequency weight terms term frequency number occurrences term document inverse document frequency related rarity term document collection details two quantities found 15 vector c use category frequency weight usually category frequency binary vectors normalized processing done let denote incoming document needs categorized since freetext document available represent vector terms weight term weighting scheme must one used representation vector also normalized instancebased learning document matched instance ie document training collection according similarity function delta function delta produces score training document instance higher score higher similarity document instance simple effective choice function note vectors normalized calculation based score rank document instances descending order instancebased learning categories associated similar document ie highest score learned categories instead approach gather top n document instances form set psi note jpsij n categories associated documents psi considered think document query set psi viewed set containing n relevant documents retrieved query retrieval feedback query automatically refined expanded using terms psi categorization task wish find appropriate categories query ie document inspired retrieval feedback technique expand query categories selected associated documents psi weight c 0 first calculated category associated psi weight computed c ki 1 c ki weight category kth document set psi rank categories according two criteria first categories ranked descending order number documents psi occur next ranked descending order computed weight c 0 finally top categories extracted learned categories document note n two parameters involved learning process category extraction process selected value parameter required instead using arbitrary values propose parameter selection process good values parameters determined advance also allows parameters capture characteristics document collection 23 parameter selection process purpose parameter selection process determine suitable parameter values used category extraction process make use tuning set approach achieve able capture specific distinct characteristics document collection process conducted offline needs performed given document collection recall gather set documents known categories training document collection training document collection partitioned two parts one part denoted upsilon treated set exemplars part denoted theta tuning set document theta categorized based exemplars upsilon using categorization learning model described since correct categories ie manually assigned categories available documents theta measure categorization performance comparing learned categories correct categories using quality metric allows us evaluate categorization performance particular choice parameters repeat tuning process systematic way different combination parameters algorithm parameter selection process summarized follows 1 choose initial set parameter values 2 document theta 21 invoke category learning model using exemplar set upsilon 3 evaluate overall category performance using quality metric 4 update best parameter values better performance found 5 choose next set parameter values 6 go step 2 unless termination criterion reached step 5 variety ways choose next set parameters experiments use generateandtest scheme basically selects parameter values within specified range predefined manner advanced schemes adopted hillclimbing scheme bestfirst search scheme step 3 need quality metric measure categorization perfor mance several quality metrics proposed namely category perspective metric document perspective metric decision perspective metric metrics described next section 24 category extraction process process responsible extracting categories newly arrived document usually need accomplish online fashion illustrated figure 1 make use category learning model learn desired categories parameters learning model previously computed parameter selection process evaluate categorization performance using new set documents test collection different training collection test collections correct manually assigned categories also known documents therefore measure categorization performance comparing categories learned known categories using quality metric similar parameter selection process variety quality metrics used however essential metric parameter selection process stays consistent metric used evaluation process maintain consistency within experimental run 3 categorization quality metrics 31 category perspective metric evaluation metric operates category focal point category categorization goal viewed binary classification problem given category algorithm decides whether document category single category focus let number documents assigned category manually automatically number documents assigned category automatically manually number documents assigned category manually automatically two common measures namely recall r precision p defined use fmeasure weighted combination recall precision proposed 9 basis quality metric common usage measure set fi 1 hence c 2 f 1 score computed category domain scores averaged determine mean f 1 score since score averages performance across categories refer metric category perspective metric 32 document perspective metric evaluation approach adopted yang 19 categorization results assessed document focal point since categories associated document certain strength see equation 1 categories may ranked context document greater ability rank manually assigned categories higher others better categorization technique summary measure assessing ability 11avgp 11point average precision score 10avgp 10point average precision score 14 scores assess ranking categories document take average across documents experiments compute 10avgp 11avgp scores 33 decision perspective metric evaluation scheme derives early work lewis 8 given document category categorization decision made determine whether assign category document automatic categorization conducted number decisions made decisions may match manual decisions others may metric compares automated decisions manual ones assignment defined positive decision assign category document let number correct assignments made automatically number assignments made automatically number assignments made manually define micro recall micro precision micro f fi measure follows current literature yet indicate three metric perspectives appropriate text retrieval thus use three perspectives expectation retrieval experiments offer insights options 4 experimental results categorization 41 hersh corpus conducted series experiments using 2344 medical documents medline database referred hersh corpus 5 document includes freetext portion set manually assigned mesh medical subject headings categories experiments individual words extracted mesh phrases stemmed henceforth refer stemmed words categories approach justified since retrieval strategy operates level word stems conducted automatic categorization collection evaluated performance categorization process randomly divided hersh corpus two partitions namely training collection referred tr 586 documents test collection referred te 1758 documents division corpus experiments done previous work 19 20 performance comparison made make use training collection tr parameter selection process divided randomly two sets first set containing 146 documents set exemplars upsilon training set containing 440 documents forms tuning set theta make size theta three times size upsilon since size te three times size tr parameter selection process whole training set 586 documents used set exemplars categorization evaluate categorization performance used test collection te conducted experiments quality metric mentioned results presented 411 category perspective results hersh corpus three experimental runs labeled c0 c35 c50 conducted differ pool categories involved c0 run involves manually assigned categories exist set training collection tr test collection te c35 c50 runs limit category pool c0 occur tr document frequency greater 35 50 respectively document frequency number documents specific category assigned tables present mean f 1 scores obtained different parameter combinations c0 c35 c50 runs respectively parameter selection process parameter ranges 10 60 steps 10 parameter n ranges 5 steps 5 tables indicate desirable values n 5 50 respectively c0 run 5 respectively c35 run respectively c50 run parameter values used final categorization process table 4 summarizes results achieved parameter selection categorization processes three experimental runs size category pool diminishes drastically c0 c35 seen table frequency threshold category set increases f 1 score improves docs table 1 parameter selection mean f 1 scores hersh corpus c0 run docs table 2 parameter selection mean f 1 scores hersh corpus c35 run docs table 3 parameter selection mean f 1 scores hersh corpus c50 run parameter selection based categorization evaluation based tr collection run categories f 1 score n categories f 1 score 43 0509 43 054 table 4 summary runs based category perspective hersh corpus 412 document perspective results hersh corpus perspective categories ranked context document thus parameter relevance table 5 presents parameter selection process based document perspective metric run represents experiment concerning categories appearing either training testing document collection trn run represents experiment concerning categories appearing training document collection experiments optimal parameter value 15 parameter selection process table 6 summarizes runs based document perspective metric run 10avgp 11avgp testing collection 04326 04789 respectively table 5 parameter selection document perspective scores hersh corpus run parameter selection based categorization evaluation based tr collection run cat 10avgp 11avgp n cat 10avgp 11avgp table summary runs based document perspective hersh corpus docs table 7 parameter selection mean micro f 1 scores hersh corpus l0 run docs table 8 parameter selection mean micro f 1 scores hersh corpus l35 run docs table 9 parameter selection mean micro f 1 scores hersh corpus l50 run parameter selection based categorization evaluation based tr collection run cat recall precision f 1 n cat recall precision f 1 43 0723 0514 0601 15 20 43 0715 0520 0602 table 10 summary runs based decision perspective hersh corpus 413 decision perspective results hersh corpus similar category perspective metric three different experimental runs l0 l35 l50 conducted based pool categories used c0 c35 c50 runs respectively tables 7 8 9 show mean micro f 1 scores achieved l0 l35 l50 runs parameter selection process tables optimal values n 15 respectively l0 run 15 20 respectively l35 run 15 20 respectively l50 run table 10 gives summary parameter selection categorization evaluation runs based decision perspective metric table includes microrecall microprecision scores clear scores improve frequency threshold increases 42 ohsumed corpus conducted series experiments using much larger document test corpus known ohsumed 6 subset medline database consists medical documents 1987 1991 documents also manually assigned mesh categories experiment used documents abstract mesh categories assigned number documents year 36890 1987 47055 1988 49805 1989 49481 1990 50216 1991 thus total number documents ohsumed corpus 233447 ohsumed corpus divided training collection test collection chronologically used 183231 documents 1987 1990 training collection also used parameter selection process documents 1991 used test collection 183231 documents training collection divided two sets parameter selection process first set consists 133750 documents 1987 1989 used set exemplars upsilon training set consists 49481 documents 1990 used tuning set theta 421 experimental results ohsumed experiment ohsumed corpus conducted using category perspective metric limited category pool occur corresponding exemplar set frequency greater 75 table 11 presents mean f 1 scores obtained different parameter combinations tested parameter selection process indicates desirable values n 20 30 respectively parameter values used categorization evaluation process table 12 summarizes results achieved experiment shows mean f 1 score categorization process 0441 docs 15 0303 0378 0419 0432 0426 0410 0388 table 11 parameter selection mean f 1 scores ohsumed corpus category perspective parameter selection based evaluation based training set testing set run categories f 1 score n categories f 1 score ohsumed 2725 0435 20 table 12 summary runs ohsumed corpus 43 comparative performance yang similar experiment hersh corpus using training testing collections 20 10avgp obtained yang based document perspective 0349 compared result performance quite encouraging since 10avgp approach 04326 however difference studies yang uses complete mesh phrase single category contrast categories single word stems generated mesh phrases ohsumed corpus lewis et al conducted experiment using training testing collections categories associated heart disease 9 obtained f 1 score 053 based category perspective using widrowhoff algorithm yang also conducted experiment corpus partition using llsf technique 21 f 1 score obtained 055 however lewis yang used 119 categories associated heart disease experiments used whole set 2725 categories experiment comparisons difficult since work complete ohsumed collection moreover used phrases categories adopt word stem approach since focus retrieval based word stems part ii 5 categorization text retrieval automatic categorization method described part support variety applications text classification 7 text filtering 12 text retrieval 16 second part paper investigate application automatic categorization text retrieval text retrieval aims retrieving relevant documents document corpus given query expressing information need user compare text retrieval performance using documents automatically categorized performance using manually categorized documents also assess retrieval performance baseline categories documents 51 document query representations similar categorization documents queries text retrieval represented vectors however representation manipulation vectors different ones used categorization document represented two vectors namely freetext vector category vector freetext vector derived freetext portion document eg title abstract category vector derived categories assigned document essence document represented follows represents weight term j p vocabulary size freetext portions documents corpus similarly c ij represents weight category j document q vocabulary size categories choose representation scheme retrieval purposes based upon previous work 16 however technique previously assumed manual assignment categories document instead apply automatic categorization technique described part manual assignment step eliminated particularly useful human experts categorization available affordable query similar document represented freetext vector category vector freetext vector constructed method used freetext vectors documents since natural language queries arrive search criteria identified use two different ways design category vectors queries ffl simplequery design querys freetext vector copied form querys category vector ffl advancedquery design querys category vector constructed applying category learning model described part specifically freetext vector used conduct initial retrieval run corpus top u documents retrieved analyzed terms categories top v categories extracted form category vector strategy explored successfully medline collection previous work 16 52 retrieval model retrieval step conducted computing similarity document query q follows freegammatext category freetext vector category vector respectively similarly q freegammatext q category freetext vector category vector q respectively parameter allows one control relative emphasis two types vectors retrieval technique allows retrieved documents ranked query retrieval experiment documents ranked respect query evaluate retrieval performance compute average precision scores queries 11 recall points starting 00 10 steps 01 average 11 precision scores computed get single measure measure becomes 11point average precision 11avgp score evaluating retrieval performance averaging technique yields macro average data wherein query allowed contribute equally overall performance score system 14 6 experimental design hersh corpus categorization experiment part also used text retrieval experiment automatic categorization strategies yielded best performance part form basis retrieval experiments retrieval experiment conducted test collection subset te composed 1758 documents hersh corpus part ii refer collection rtt retrieval test collection hersh corpus accompanied set queries form simple natural language expressing information need query set relevant documents manually judged thus retrieval performance measured comparing documents retrieved system ones manually judged chose queries least one relevant document rtt collection 73 queries satisfying requirement best strategies within three evaluation perspectives category decision document tested retrieval performance strategy assessed two baselines baseline 1 b1 retrieval without mesh categories ie retrieval using freetext alone ffl baseline 2 b2 retrieval using free text manually assigned mesh categories conduct text retrieval experiments make use smart system 14 since supports 2 note stems individual words mesh phrases form domain categories experiments vector space model 61 document representations smart allows wide variety weighting schemes computing term weights scheme represented triple abc represents term frequency component ie number times term occurs document b represents inverse document frequency component increases rarity term database c represents normalization component length document based results prior experimentation test corpus 16 18 used atn schemes documents stands augmented term frequency represents inverse document frequency factor n represents normalization length describe scheme precisely weight term document given r number documents rtt collection n number documents contain term considered tf frequency term document maximum tf value current document objective division normalize term frequency maximum tf observed document term logrn corresponds inverse document frequency weight total 9 different document representations tested representations include freetext vector difference mesh category vectors representation 1 baseline 1 mesh category vector representation 2 baseline 2 mesh category vector formed manual categorization representations 35 mesh category vector derived automatic categorization based category perspective metric described section 411 three best strategies one c0 c35 c50 tested representations 68 mesh category vector derived automatic categorization based decision perspective metric described section 413 three best strategies one l0 l35 l50 tested representation 9 mesh category vector derived automatic categorization based document perspective metric described section 412 62 query representations 73 test queries arrives simple natural language expression information need queries expressed full sentences others incomplete case freetext vector derived analogous document representation equation 3 based previous work 16 term weights determined using atc scheme smart similar atn used document representation due common difference term weights due c factor normalized following factor weight term query p size freetext vector 63 retrieval strategies given retrieval strategy may defined combination document representation strategy query representation strategy total 17 retrieval strategies tested 8 document representations involving freetext mesh category vectors may combined simplequery design advancedquery design baseline 1 strategy involves free text two parameters u v used advancedquery design varied independently across 5 10 15 20 parameter varied across 075 10 125 15 175 20 thus total 96 different parameter combinations tested experimentation involving advanced queries simplequery design parameter involved thus 6 parameter combinations tested 7 retrieval results table 13 shows retrieval results measured 11avgp score 17 different retrieval strategies tested table includes scores baseline 1 b1 baseline 2 b2 baseline scores reported different simplequery design advancedquery design options note although two design options identical document representations differ query representations remaining rows represent performance different automatic categorization strategies example row 11 reports results best document categorization strategy part c0 framework combined advancedquery design yields 11avgp score 05619 offers significant 93 improvement baseline 1 performance significantly worse gamma79 baseline 2 performance 06098 row also indicates query created using querys initial freetext vector retrieve top documents mesh categories assigned 20 documents analyzed best used create querys mesh category vector also indicates parameter equation 4 set 125 retrieval seen table 13 manual strategies rows 2 10 significantly superior baseline 1 strategy consistent previous results suggesting mesh ignored retrieval 16 similarly 95 improvement manual strategies one moves simple advanced queries result also consistent previous studies shown investing retrieval feedback query design yields good returns 16 regards automatic strategies continue see improvements moving simple query design advancedquery design best simplequery performance 05106 advancedquery 05619 100 improvement table indicates automatic categorization performs worse manual categorization analysis underlying vocabularies yields explanation specifically since automatic categorization done based set exemplar documents categorization vocabularies freetext mesh automatic collection limited vocabularies training collection however manual runs vocabularies come original vocabulary set much larger size thus example mesh category vectors diff diff row mesh approach 11avgp wrt b1 wrt b2 u v simplequery design 6 l0 05083 12 97 na na 20 9 05080 12 98 na na 175 advancedquery design 14 l0 05526 74 94 20 20 125 table 13 retrieval performance vocabulary differences controlled asterisk denotes difference significant p 001 using nonparametric wilcoxon signed rank test matched samples na denotes applicable assigned manually rows 2 10 rtt collection generated using mesh vocabulary 2968 word stems however mesh category vectors generated automatically collection produced 586 documents training collection hersh corpus part mesh vocabulary base contains 1604 word stems difference underlying vocabularies may explain difference performance order conduct meaningful comparison repeated retrieval experiment involving 17 retrieval strategies controlling vocabulary difference words mesh categories existing training collection removed manually generated representations rtt documents table 14 presents result second set retrieval runs table indicates vocabulary differences controlled automatic retrieval runs better retrieval without mesh 3 simple advanced queries show better performance results without controlling 3 interestingly manual mesh combined simple queries row 2 yield improved results compared mesh approach diff diff row 11avgp wrt b1 wrt b2 u v simplequery design 6 l0 05402 70 64 na na 20 9 05456 80 74 na na 175 advancedquery design table 14 retrieval performance vocabulary differences controlled asterisk denotes difference significant p 001 using nonparametric wilcoxon signed rank test matched samples na denotes applicable vocabulary differences 71 effect parameter values retrieval performance results tables 13 14 reveal piece picture regarding retrieval particular row presents best performance achieved parameter combinations u v relevant tested row advancedquery design u number top ranking documents examined v number mesh categories added query participates retrieval processes freetext mesh involved example 05448 score row 4 table 14 represents best result 6 parameter values similarly 05754 score row 12 represents best 96 parameter combinations tested c50 advanced query framework get complete picture present querybyquery analysis explores effect parameter combinations retrieval performance explain analysis strategy reference table 15 table provides results querybyquery statistical analysis 96 parameter combinations tested c0 combined advancedquery design compares retrieval performance achieved using automatic strategy retrieval performance achieved using baselines b1 b2 indicates automatic strategy significantly better corresponding manual strategy statistically indicates manual strategy significantly better automatic strategy statistically indicates significant difference two statistically statistical analysis based queryby query analysis using wilcoxon signed rank test straightforward counts indicate c0 always significantly better b1 moreover better b2 43 cases worse 44 cases equivalent remaining 9 cases thus observed within c0 advancedquery design framework automatic strategy always performs better baseline retrieval mesh involved also across 96 parameter combinations tried automatic categorization equivalent baseline 2 manual categorization table provides querybyquery analysis c35 table shows c35 also possesses mesh row 1 result different results previous study 16 also explained vocabulary differences u table 15 statistical analysis c0 vocabulary differences controlled implies automatic method significantly better statistically implies automatic method significantly worse implies statistically similar similar balance better 45 cases parameter settings worse 51 cases perform querybyquery analysis situation vocabularies controlled table 17 shows summary comparison b2 different automatic categorization strategies tested retrieval also noted automatic strategies almost always significantly better b1 statistically table provides interesting results allows us differentiate perspectives clear c0 c35 distinct remaining perspectives fact decision document perspectives yielded poor results based querybyquery analysis consider behind query lies distinct user study recommends use category perspective metric metrics text retrieval hersh corpus u table statistical analysis c35 controlled vocabulary represents automatic method significantly better statistically represents automatic method significantly worse represents statistically similar number instances strategy strategy better b2 similar b2 worse b2 43 9 44 table 17 summary querybyquery analysis comparing b2 different automatic categorization strategies vocabulary differences controlled 8 conclusion develop new approach automatic text categorization categorization model learned used classifying future documents categorization approach derives machine learning paradigm known instancebased learning advanced document retrieval technique known retrieval feedback demonstrate effectiveness categorization approach using two test collections namely hersh corpus ohsumed corpus apart developing automatic categorization approach also investigate application categorization process advanced text retrieval experiments clearly indicate categorization process effective improves retrieval performance compared categorization also achieves retrieval performance equivalent results using manual categorization concluded basis analyzing retrieval performance individual test query statis tically moreover study indicates category perspective metric one suited text retrieval hersh corpus finally paper shows automatic categorization effective advanced text retrieval r automated learning decision rules text catego rization automatic query expansion using smart trec3 report contextsensitive learning methods text categorization overview third text retrieval conference trec3 performance failure analysis saphire medline test ohsumed interactive retrieval evaluation new large test collection research combining classifiers text categorization feature selection feature extraction text categorization training algorithms linear text classifiers classifying news stories using memory based reasoning national library medicine multilevel approach intelligent information filtering model systems evaluation okapi trec 3 smart system experiments automatic document processing transformation query expansion medline optimal documentindexing vocabulary medline retrieval feedback medline examplebased mapping method text categorization retrieval expert network effective efficient learning human decisions text categorization retrieval evaluation statistical approaches medline indexing tr ctr ali selamat sigeru omatu web page feature selection classification using neural networks information sciencesinformatics computer science international journal v158 n1 p6988 january 2004 guiraude lame categorization method french legal documents web proceedings 8th international conference artificial intelligence law p219220 may 2001 st louis missouri united states innovating web page classification reducing noise journal computer science technology v17 n1 p917 january 2002 miguel e ruiz padmini srinivasan hierarchical text categorization using neural networks information retrieval v5 n1 p87118 january 2002 dina gorenbar tsvi kuflik supporting usersubjective categorization selforganizing maps learning vector quantization journal american society information science technology v56 n4 p345355 15 february 2005 hsinchang yang chunghong lee automatic category theme identification hierarchy generation chinese text categorization journal intelligent information systems v25 n1 p4767 july 2005 hsinchang yang chunghong lee mining text documents thematic hierarchies using selforganizing maps data mining opportunities challenges idea group publishing hershey pa b barla cambazoglu evren karaca tayfun kucukyilmaz ata turk cevdet aykanat architecture gridenabled web search engine information processing management international journal v43 n3 p609623 may 2007 fabrizio sebastiani machine learning automated text categorization acm computing surveys csur v34 n1 p147 march 2002