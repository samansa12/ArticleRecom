relative loss bounds temporaldifference learning foster vovk proved relative loss bounds linear regression total loss online algorithm minus total loss best linear predictor chosen hindsight grows logarithmically number trials give similar bounds temporaldifference learning learning takes place sequence trials learner tries predict discounted sums future reinforcement signals quality predictions measured square loss bound total loss online algorithm minus total loss best linear predictor whole sequence trials difference losses logarithmic number trials bounds hold arbitrary worstcase sequence examples also give bound expected difference case instances chosen unknown distribution linear regression corresponding lower bound shows expected bound cannot improved substantially b introduction consider following model temporaldifference learning learning proceeds sequence trials trial gamma learner receives instance vector x 2 r n gamma learner makes prediction gamma learner receives reinforcement signal r 2 r pair called example learner tries predict outcomes 2 r fixed discount rate parameter fl 2 0 1 discounted sum st future reinforcement signals 1 example r profit company month interpreted approximation companys worth time discounted sum takes account profits distant future less important short term profits note outcome defined 11 welldefined reinforcement signals bounded episodic setting one also define outcomes finite discounted sums discussed briefly section 7 strategy chooses predictions learner called online learning algorithm quality prediction measured square loss loss learner trial loss learner trials 1 want compare loss learner losses linear functions linear function represented weight vector loss w trial ideally want bound additional loss learner loss best linear predictor arbitrary sequences examples ie want bound arbitrary arbitrary sequences examples first sum 12 total loss learner trials 1 argument infimum total loss linear function alternatively could defined 1 gamma fl st rs makes convex combination reinforcement signals r r t1 alternate definition amounts simple rescaling outcomes predictions relative loss bounds temporaldifference learning 3 w trials 1 thus 12 additional total loss learner total loss best linear function following vovk 1997 also examine general problem bounding fixed constant 0 akwk 2 measure complexity w ie infimum 13 includes charge complexity linear function larger values obviously easier show bounds 13 bounds 12 13 hold arbitrary sequences examples called relative loss bounds relative loss bounds temporaldifference learning setting first shown schapire warmuth 1996 overview results given section 4 also show algorithms minimize 12 used value function approximation markov processes important problem reinforcement learning also called policy evaluation markov processes continuously many states represented real vectors one wants predict state values instances x correspond states environment action values predicted instance corresponds state environment action agent introduction reinforcement learning see sutton barto 1998 paper organized follows discuss previously known relative loss bounds linear regression temporaldifference learning sections 3 4 section 5 propose new second order learning algorithm temporaldifference learning tls algorithm prove relative loss bounds algorithm section 6 section 7 adapt tls algorithm episodic case trials divided episodes outcome discounted sum future reinforcement signals discuss previous second order algorithms temporaldifference learning section 8 give lower bounds relative loss section 9 2 notation preliminaries set ndimensional real vectors mn 2 n r mthetan set real matrices rows n columns paper vectors x 2 r n column vectors x 0 denotes transpose 4 j forster k warmuth x scalar product two vectors wx 2 r n w euclidean norm vector x 2 r n recall basic facts positive semidefinite matrices nthetan called positive definite x holds vectors x 2 r n n f0g nthetan called positive semidefinite gamma sum two positive semidefinite matrices positive semidefinite sum semidefinite matrix positive definite matrix positive definite every positive definite matrix invertible gamma matrices b 2 r nthetan write b b gamma positive semidefinite case x 0 ax x 0 bx vectors x 2 r n gamma shermanmorrison formula see press flannery teukolsky holds every positive definite matrix 2 r nthetan every vector example unit matrix 2 r nthetan positive definite every vector x 2 r n matrix xx 0 2 r nthetan positive semidefinite find vector w 2 r n minimizes term appears relative loss 13 define ks 22 convex w minimal gradient zero ie 0 invertible unique vector minimizes 22 relative loss bounds temporaldifference learning 5 might invertible equation might unique solution solution smallest euclidean norm pseudoinverse definition pseudoinverse matrix see eg rektorys 1994 also shown pseudoinverse matrix computed singular value decomposition give number properties pseudoinverse appendix 0 applying shermanmorrison formula 21 shows 3 known relative loss bounds linear regression first note linear regression special case setup since standard algorithm linear regression ridge regression algorithm predicts x trial relative loss bounds algorithm similar bounds given two theorems proven foster 1991 vovk 1997 azoury warmuth 1999 bounds obtained ridge regression weaker ones proven new algorithm developed vovk give simple motivation algorithm discuss relative loss bounds proven seen section 2 best linear functions trials 1 ie linear function minimizes 22 would make prediction b 0 x trial note via b prediction depends examples however examples instance x known learner makes prediction trial set unknown outcome zero get prediction b 0 prediction introduced vovk 1997 using different motivation motivation follows azoury warmuth 1999 forster 1999 gives alternate game theoretic motivation vovk proved following bound 13 prediction algorithm theorem 31 consider linear regression sequence examples r n predictions 6 j forster k warmuth x ti ith component vector x vovks version theorem 31 term x 2 n replaced larger bound supremum norms instances last inequality theorem 31 follows z first inequality holds geometric mean always smaller arithmetic mean azoury warmuth 1999 forster 1999 give following refined bound vovks linear regression algorithm case 0 considered show case 0 theorem 32 follows case 0 letting go zero theorem 32 consider linear regression sequence examples r n theta r 0 predictions ii 0 vectors x relative loss bounds temporaldifference learning 7 proof show equality also holds case 0 showing sides equality continuous 2 0 1 lemma a2 check 2 tg term continuous 2 0 1 x 2 x tgamma1 follows lemma a2 otherwise x lemma a3 expression 31 zero 0 show 31 converges zero 0 0 rewrite 31 applying 25 b 0 factor b 0 converges lemma a2 lemma a4 term x 0 goes zero 0 together shows 31 indeed goes zero learning algorithm theorem 31 theorem 32 second order algorithm uses second derivatives simpler first order algorithm called widrowhoff least mean square algorithm widrow stearns 1985 algorithm maintains weight vector w 2 r n predicts weight vector updated gradient descent w learning rates method setting learning rates purpose obtaining good relative loss bounds given cesabianchi long warmuth 1996 kivinen warmuth 1997 method learner needs know upper bound x euclidean norms instances needs know parameters w k vector w 2 r n norm kwk w loss vector w bound holds noted vovk 1997 bound incomparable bounds theorem 31 see also next section bound 33 also holds ridge regression algorithm hassibi kivinen war muth 1995 parameter set depending w k believe proper tuning bounds also hold vovks 8 j forster k warmuth 4 known relative loss bounds temporaldifference learning case discount rate parameter fl assumed zero schapire warmuth 1996 given number different relative loss bounds learning algorithm td first order algorithm td essentially generalization widrowhoff algorithm slight modification learning algorithm td proposed sutton 1988 schapire warmuth show loss td 1 specific setting learning rate c loss algorithm td 0 specific setting learning rate every vector w 2 r n kwk w setting learning rate depends upper bound x euclidean norms instances w k learner needs know parameters advance loss best linear function often grow linearly eg examples corrupted gaussian noise case relative loss bounds 33 41 42 grow like second order learning algorithm propose temporaldifference learning advantage relative loss bounds prove grow logarithmically also algorithm need know parameters like k w however needs know upper bound absolute values outcomes td sensitive choice another advantage algorithm choose parameter like td algorithm 5 new second order algorithm temporaldifference learning section propose new algorithm temporaldifference learning setting call algorithm temporal least squares algorithm shorter tls algorithm relative loss bounds temporaldifference learning 9 assume absolute values outcomes bounded constant ie assume bound discount rate parameter fl parameter known learner knowing learner clip real number 2 r using function 51 motivation tls algorithm new secondorder algorithm temporaldifference learning given table call algorithm temporal least squares tls algorithm motivation tls algorithm motivation azoury warmuth 1999 gave vovks prediction linear regression section 3 use equality ks holds best linear function trials 1 minimizes 22 would make prediction ks trial set unknown outcome zero get prediction e ks tls algorithm predicts clipping function assures prediction lies bounded range following show relative loss 13 tls j forster k warmuth table temporal least squares tls algorithm trial learner knows ffl parameters fl ffl instances ffl reinforcement signals tls predicts ks rk cy given 52 clips prediction interval gammay invertible inverse gamma1 must replaced pseudoinverse use result get worst average case relative loss bounds easier interpret 52 implementation tls algorithm case 0 straightforward implementation tls algorithm would need 3 arithmetic operations trial compute inverse matrix table ii give implementation needs 2 arithmetic operations per trial achieved computing inverse iteratively using shermanmorrison formula 25 implementation makes correct predictions end forloop follows shermanmorrison formula 25 equality relative loss bounds temporaldifference learning 11 table ii implementation tls 0 inv 1 2 r nthetan z receive instance vector x 2 r n inv inv gamma inv x predict receive reinforcement signal r 2 r z 6 relative loss bounds tls algorithm temporaldifference learning setting know outcomes need predict trial cannot run vovks linear regression algorithm uses outcomes pre diction tls algorithm approximates vovks prediction setting future reinforcement signals zero also clips prediction range gammay show loss tls algorithm much worse loss vovks algorithm good relative loss bounds known start showing two lemmas first technical lemma use proving second lemma bound absolute values differences vovks prediction b 0 unclipped prediction e tls algorithm lemma 61 0 vectors x proof follows 0 pseudoinverses inverses shermanmorrison formula 25 shows j forster k warmuth thus gamma1 x 0 proves lemma 0 case 0 use lemma a2 let go 0 2 lemma 62 proof note thus lemma 61 yt z z show main result theorem 61 consider temporaldifference learning 0 let sequence examples r n theta r outcomes lie real interval gammay predictions tls algorithm relative loss bounds temporaldifference learning 13 proof let know ie relative loss bound theorem 32 also holds clipped predictions c p thus suffices show holds 4y lemma 62 next two subsections apply theorem 61 show relative loss bounds worst case average case 61 worst case relative loss bound corollary 61 consider temporaldifference learning 0 1 0 let sequence examples r n theta r outcomes lie real interval gammay predictions tls algorithm 14 j forster k warmuth proof first inequality follows theorem 61 theorem 32 ii second follows theorem 31 2 62 average case relative loss bound assume outcomes lie gammay instances iid unknown distribution r n show upper bound expectation relative loss 12 trials 1 depends n fl particular need term akwk 2 measures complexity vector w relative loss 13 need assume instances bounded show result use theorem 61 bound sums terms x 0 following theorem tra trace square matrix dimx dimensionality vector space x theorem 62 vectors x linear span proof first look case choose orthonormal basis e em x also written means interpret matrix nthetan linear function r n r n identity function x assertion case 0 follows 1ijm 1ijm 1ijm relative loss bounds temporaldifference learning 15 1jm 1jm 1jm 1jm prove theorem case 0 choose arbitrary orthonormal basis e apply result 0 vectors x 1gamman first note s1gamman x x 0 case s1gamman x 0 since vectors fx 1gamman rank n equality 0 follows s1gamman x 0 first inequality case 0 follows atra gamma1 corollary 62 consider temporaldifference learning setting assume instances x iid unknown distribution r n outcomes given 11 lie real interval gammay predictions tls algorithm expectation 12 proof theorem 61 expected relative loss iid theorem 62 proves first inequality corollary 62 second follows j forster k warmuth table iii temporal least squares tls algorithm episodic learning trial tls predicts rk cy given 52 clips prediction interval gammay startk first trial episode trial k belongs invertible inverse gamma1 must replaced pseudoinverse 7 episodic learning studied setting outcomes st discounted sums future reinforcement signals use algorithm policy evaluation reinforcement learning corresponds looking continuing tasks see sutton barto 1998 episodic tasks trials partitioned episodes finite length outcome depends reinforcement signals belong episode let trial first trial episode trial denoted startt last endt notation discount rate parameter fl 2 0 1 outcome episodic setting defined st replaces definition given 11 continuous setting definitions relative loss 12 13 remain un changed note continuous setting essentially episodic setting one episode infinite length motivation section 5 get tls algorithm episodic learning presented table iii implementation algorithm given table iv check correctness implementation verifying relative loss bounds temporaldifference learning 17 table iv implementation tls episodic learning inv 1 2 r nthetan new episode starts trial set z 0 2 r n receive instance vector x 2 r n inv inv gamma inv x predict receive reinforcement signal r 2 r z hold every iteration forloop follows 25 equality note practitioner 0 small matrix might invertible algorithm uses pseudoinverse practice suggest use 0 tune parameter always invertible calculation pseudoinverses avoided also conjecture clipping needed practical data show relative loss bounds episodic learning assume bound outcomes known learner advance proof following theorem similar proof theorem 61 theorem 71 consider temporaldifference learning episodes length let 0 let sequence examples r n theta r outcomes given 71 lie real interval gammay predictions tls algorithm table iii j forster k warmuth 0 72 bounded instances x iid unknown distribution r n expectation 72 lower bound corresponding 73 shown theorem 92 note theorem 71 exploit fact different episodes varying length related theorems depend actual lengths episodes easily developed 8 second order algorithms second order algorithms temporaldifference learning proposed bradtke barto 1996 boyan 1999 compare algorithms episodic setting algorithms maintain weight vectors w predict trial bradtke bartos leastsquares td shorter lstd algorithm uses weight vectors r x boyans lstd algorithm considers case parameter 2 0 1 like td algorithm uses weight vectors z contrast tls algorithm uses weight vectors relative loss bounds temporaldifference learning 19 prediction tls algorithm trial formulas inverse must replaced pseudoinverse matrix invertible note tls algorithm parameter like td lstd case algorithms lstd identical important difference tls algorithm td lstd use differences definition covariance matrix bradtke barto boyan experimentally compare algorithms td comparatively strong assumptions bradtke barto also show w algorithm converge asymptotically tls algorithm proposed paper designed minimize relative loss 13 relative loss bounds show tls well know whether similar relative loss bounds hold lstd lstd algorithms experimental comparison would useful 9 lower bounds section give lower bounds linear regression episodic temporaldifference learning first consider case linear regression ie case outcomes equal reinforcement signals outcomes lie gammay corollary 62 gives upper bound expected relative loss 12 examples iid respect arbitrary distribution next theorem show bound 91 cannot improved substantially proof similar proof theorem 2 vovk 1997 however dimension n instances greater one examples proof generated stochastic strategy iid theorem 91 consider linear regression constant c distribution set examples r n theta gammay every learning algorithm expectation relative loss 12 examples iid distribution j forster k warmuth proof fixed parameter ff 1 generate distribution examples following stochastic strategy vector 2 0 chosen prior distribution betaff ff n ie components iid distribution betaff ff distribution example n example n e unit vectors r n trial examples generated iid calculate bayes optimal learning algorithm expectation loss trials 1 minimal expectation relative loss algorithm gives lower bound theorem 91 details proof given appendix 2 consider setting discussed section 7 trials partitioned episodes outcomes given st following lower bound proven reduction previous lower bound linear regression theorem 92 consider episodic temporaldifference learning episodes fixed length let gammay range outcomes every 0 constant c stochastic strategy generates instances x 1 x reinforcement signals r 1 outcomes lie gammay divisible every learning algorithm expectation stochastic choice examples relative loss 12 proof modify stochastic strategy used proof theorem 91 strategy generates instance x outcome trial generate whole episode trials instances reinforcement signals outcomes episode fl consider qth trials episode fore 1 q trials learner essentially processes scaled examples lower bound theorem 91 applies factor fl 2gammaq choices q lead factor 1 lower bound 2 relative loss bounds temporaldifference learning 21 10 conclusion open problems proposed new algorithm temporaldifference learning tls algorithm contrary previous second order algorithms new algorithm use differences definition covariance matrix see discussion section 8 main question whether differences really helpful proved worst average case relative loss bounds tls algorithm would interesting know tight bounds practical data bounds class linear functions serves comparison class use second order algorithm additional loss loss best comparator logarithmic number trials conjecture even linear regression first order algorithm adaptive learning rates additional loss logarithmic number trials algorithms analyzed applied case instances expanded feature vectors dot product two feature vectors given kernel function see saunders gam merman vovk 1998 also fourier wavelet transforms used extract information instances see walker 1996 graps 1995 linear transforms one reduce dimensionality comparison class leads smaller relative loss bounds far compared total loss online algorithm total loss best linear predictor whole sequence examples suppose comparator produced partitioning data sequence k segments picking best linear predictor segment aim bound total loss online algorithm minus total loss best comparator form bound obtained herbster warmuth 1998 case linear regression using firstorder algorithms would like know whether simple secondorder algorithm linear regression requires 2 update time per trial additional loss grows sums logs section lengths paper focused continuous learning outcome infinite discounted sum future reinforcement signals section 7 discussed tls algorithm adapted setting outcomes depend reinforcement signals episode st applications might make sense let outcomes convex combinations future reinforcement signals 22 j forster k warmuth episode define st case outcome would average future reinforcement signals know relative loss bounds case defined 101 technical level would like know really necessary clip predictions temporaldifference algorithm proposed proofs reductions previous proofs linear regression direct proofs might avoid clipping another open technical question discussed end section 3 conjecture parameter vovks linear regression algorithm tuned obtain bounds form 33 proven first order widrowhoff algorithm similarly believe parameter new second order learning algorithm paper tuned obtain bound 41 proven first order td algorithm schapire warmuth finally note lower bounds continuous setting fl 0 possible show lower bound expected relative loss 12 see theorem 92 corresponding lower bound episodic case acknowledgements jurgen forster supported daad doktorandenstipendium im rahmen des gemeinsamen hochschulsonderprogramms iii von bund und landern manfred warmuth supported nsf grant ccr9821087 thanks nigel duffy valuable comments r relative loss bounds online density estimation exponential family distributions linear analysis introductory course relative loss bounds generalized linear regression prediction worst case introduction wavelets unpublished manuscript department computer science tracking best regressor additive versus exponentiated gradient updates linear prediction numerical recipes pascal survey applicable mathematics ridge regression learning algorithm dual variables worstcase analysis temporaldifference learning algorithms learning predict methods temporal differences reinforcement learning introduction competitive online linear regression fast fourier transforms adaptive signal processing tr