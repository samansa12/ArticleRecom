predicting data cache misses nonnumeric applications correlation profiling maximize benefit minimize overhead softwarebased latency tolerance techniques would like apply precisely set dynamic references suffer cache misses unfortunately information provided stateoftheart cache miss profiling technique summary profiling inadequate references intermediate miss ratios results either failing hide latency else inserting unnecessary overhead overcome problem propose evaluate new technique correlation profiling improves predictability correlating caching behavior associated dynamic context experimental results demonstrate roughly half 22 nonnumeric applications study potentially enjoy significant reductions memory stall time exploiting least one three forms correlation profiling consider b introduction disparity processor memory speeds continues grow memory latency becoming increasingly important performance bottleneck cache hierarchies essential step toward coping problem complete solution tolerate latency number promising softwarebased techniques proposed example compiler tolerate modest latencies scheduling nonblocking loads early relative results consumed 12 tolerate larger latencies inserting prefetch instructions 7 9 softwarebased techniques provide latencyhiding benefits also typically incur runtime overheads example aggressive scheduling nonblocking loads increases register lifetimes lead spilling softwarecontrolled prefetching requires additional instructions compute prefetch addresses launch prefetches benefit technique typically outweighs overhead whenever miss tolerated overhead hurts performance cases reference would enjoyed cache hit anyway therefore maximize overall performance would like apply latencytolerance technique precise set dynamic references would suffer misses previous work addressed problem numeric codes 9 paper focuses difficult important case isolating dynamic miss instances nonnumeric applications 11 predicting data cache misses nonnumeric codes overcome compilers inability analyze data locality nonnumeric codes instead make use profiling information one simple type profiling information precise miss ratios static memory references throughout remainder paper refer approach summary profiling since miss ratio memory reference summarized single value summary profiling indicates significant memory reference instructions ie executed frequently enough make nontrivial contribution execution time miss ratios close 0 100 isolating dynamic misses trivialwe simply apply latencytolerance technique static references always suffer misses contrast important references intermediate miss ratios eg 50 sufficient information distinguish dynamic instances hit miss since information lost course summarizing miss ratio current stateoftheart approach dealing intermediate miss ratios treat static memory references miss ratios certain threshold though always miss always hit respectively 2 however allornothing strategy fail hide latency references predicted hit actually miss induce unnecessary overhead references predicted miss actually hit rather settling suboptimal performance would prefer predict dynamic hits misses accurately 111 correlation profiling exposing caching behavior directly user informing memory operations 6 enable new classes lightweight profiling tools collect sophisticated information simply perreference miss ratios example cache misses correlated information recent controlflow paths whether recent memory references hit missed cache etc help predict dynamic cache miss behavior refer approach correlation profiling figure 1 illustrates correlation profiling information might exploited load instruction shown figure 1 overall miss ratio 50 however depending dynamic context load may see predictable behavior example contexts b result high likelihood load missing whereas contexts c hence would like apply latency tolerance technique within contexts b c dynamic contexts shown figure 1 viewed simply nonoverlapping sets dynamic instances load grouped together share common distinguishable pattern paper consider three different types information used distinguish contexts first controlflow informationie sequence n basic block numbers preceding load two based sequences cache access outcomes ie hit miss previous memory references self correlation considers cache outcomes previous n dynamic instances given static reference global correlation refers previous n dynamic references across entire program note load context c context context figure 1 example correlating cache misses dynamic context may improve predictability xy means x misses dynamic references analogous forms three types correlation profiling explored previously context branch prediction 4 10 15 16 12 objectives overview goal paper determine whether correlation profiling predict data cache misses accurately nonnumeric codes summary profiling translate significant performance improvements applying softwarebased latency tolerance techniques greater precision focus specifically predicting load misses paper load latency fundamentally difficult tolerate store latency hidden buffering pipelining although rely simulation capture profiling information study correlation profiling practical technique since could performed relatively little overhead using informing memory operations 6 remainder paper organized follows begin section 2 discussing three different types history information use correlation profiling section 3 present qualitative analysis expected performance benefits section 4 present experimental results quantify performance advantages correlation profiling collection 22 nonnumeric applications addition section 5 report memoryaccess behaviors individual applications explain correlation profiling effective section 6 compare performance software prefetching guided summary correlation profiling modern superscalar processor finally discuss related work present conclusions sections 7 8 profiling techniques section propose motivate three new correlation profiling techniques predicting cache outcomes controlflow correlation self correlation global correlation 21 controlflow correlation first profiling technique correlates cache outcomes recent controlflow paths collect information profiling tool maintains n recent basic block numbers fifo buffer matches pattern hitmiss outcomes given memory reference intuitively controlflow correlation useful detecting cases either data reuse cache displacement likely path leads data reuseeither temporal spatialthen next reference likely cache hit consider example shown figure 2ab graph traversed recursive procedure walk cyclic paths eg abcda pqrsp result temporal reuse pdata example controlflow correlation potentially detect last four traversal decisions lead cycle eg right left high probability next pdata reference enjoy cache hit controlflow paths may increase likelihood cache miss displacing data line reused example x 0 condition true figure 2c subsequent loop likely struct node f int data struct node left right void walknode p f go leftpdata elsif go rightpdata elsif go elsif go else p null walkp r left right code data reuse b example graph c code cache displacement figure 2 examples controlflow correlation detect data reuse cache displacement control flow profiled loads underlined void preordertreenode p f p null f preorderpleft preorderpright preorder traversal self cache outcomes pdata example code b tree constructed traversed preorder figure 3 example using selfcorrelation profiling detect spatial locality pdata consecutively numbered nodes adjacent memory displace p primary cache loaded note paths access large amounts data obvious problems displacement might also due mapping conflict 22 self correlation self correlation profile load l correlating cache outcome n previous cache outcomes l approach particularly useful detecting forms spatial locality apparent compile time example consider case figure 3 tree constructed preorder assuming consecutive calls memory allocator return contiguous memory locations cache line large enough hold exactly two treenodes depending traversal order extent tree modified created may experience spatial locality tree subsequently traversed example tree also traversed preorder expect pdata suffer misses everyother reference cache line boundaries crossed therefore despite fact overall miss ratio pdata 50 compiler would difficulty recognizing form spatial locality self correlation profiling would accurately predict dynamic cache outcomes pdata 23 global correlation contrast self correlation idea behind global correlation correlate cache outcome load l previous n cache outcomes regardless positions within program profiling tool maintains pattern using single ndeep fifo updated whenever dynamic cache accesses occur 1 f register int register listnode curr null f g r adata anext bdata bnext gdata gnext rdata rnext adata anext bdata bnext h h h memory global cache outcomes global htab10a example code b hash table accesses figure 4 example using globalcorrelation profiling detect bursty cache misses currdata note since earlier instances l may appear global history pattern global correlation may capture behavior self correlation particularly extremely tight loops intuitively global correlation particularly helpful detecting bursty patterns misses across multiple references one example situation move new portion data structure accessed long time hence displaced cache case fact first access object suffers miss good indication associated references neighboring objects also miss figure 4 illustrates case large hash table large fit cache organized array linked lists case might expect strong correlation whether htabi list head pointer misses whether subsequent accesses currdata list elements also miss similarly entry accessed twice within short interval eg htab10 fact head pointer hits strong indicator list elements eg adata bdata also hit summary correlating cache outcomes context reference occurseg surrounding control flow cache outcomes prior referenceswe potentially predict dynamic caching behavior accurately possible summarized miss ratios qualitative analysis expected benefits presenting quantitative results later sections begin section providing intuition correlation profiling improve performance key factor dictates potential performance gain ratio latency tolerance overhead v cache miss latency l extreme cases v point applying latency tolerance technique selectively since either cost benefit applying selectively may important figure 5a illustrates average number effective stall cycles per load cpl varies function v l various strategies applying note cpl metric includes overhead associated applying include single cycle executing load instruction never applied cpl simply ml average miss ratio extreme always apply latency always hidden references even normally hit suffer hence note v better never apply rather always applying figure 5b shows alternative view cpl plotted function fixed v l observe choice whether always never apply depends value relative v l achieve better performance allornothing approach apply decisionmaking process ie comparing miss ratio v l refined sets loads ideal case would consider optimize dynamic reference individually resulting cpl mv shown figure 5 however since impractical softwarebased techniques must consider aggregate collections references since summary profiling provides single miss ratio per static reference finest granularity cpl never cpl singleactionperload ideal multipleactionsperload cpl always cpl cpl singleactionperload ideal multipleactionsperload cpl always cpl never cpl vs v figure 5 illustration cpl different approaches applying latency tolerance scheme overall average load miss ratio latency tolerance overhead load miss latency decide whether apply dynamic instances given static reference figure 5 illustrates potential shape single action per load curve bounded cases never always ideally applied since correlation profiling distinguishes different sets dynamic instances static load based path information allows us make decisions finer granularity summary profiling therefore potentially achieve even better performance illustrated multiple actions per load curve figure 5 details actual cpl equations summary correlation profiling cases found appendix quantitative evaluation performance gains section present experimental results quantify performance benefits offered correlation profiling begin measuring understanding potential performance advantages generic latency tolerance scheme later section 6 focus softwarecontrolled prefetching specific case study 41 experimental methodology measured impact correlation profiling following 22 nonnumeric applications entire spec95 integer benchmark suite additional integer benchmarks contained spec92 suite uniprocessor versions two graphics applications splash2 14 eight applications olden 11 suite pointerintensive benchmarks standard unix utility awk table 1 briefly summarizes applications including input data sets run completion case table 2 shows relevant dynamic statistics applications compiled application o2 optimization using standard mips c compilers irix 53 used mips pixie utility 13 instrument binaries piped resulting trace detailed performance simulator increase simulation speed simplify analysis model perfectlypipelined singleissue processor similar mips r2000 section later section 6 model modern superscalar processor mips r10000 reduce simulation time simulator performs correlation profiling selected subset load instructions criteria profiling load must rank among top 15 loads terms total cache miss count miss ratio must 10 90 using criteria focus significant loads intermediate miss ratios refer loads correlationprofiled loads fraction dynamic load references application correlation profiled shown table 2 table 1 benchmark characteristics suite name description input data set cache size integer perl unix script language perl train scrabbl 128 kb go computer game go train 8 kb ijpeg graphic compression decompression train 8 kb vortex database program train 8 kb compress compresses decompresses file memory train li lisp interpreter train 8 kb integer espresso minimization boolean functions cps eqntott translation boolean equations truth tables int pri 3eqn 8kb raytrace raytracing program car 4kb radiosity light distribution using radiosity method batch 8kb olden bh barneshuts nbody forcecalculation 4k bodies 16kb mst finds minimum spanning tree graph 512 nodes 8kb perimeter computes perimeters regions images 4k x 4k image 16kb health simulation columbian health care system max level 5 16kb tsp traveling salesman problem 100000 cities 8kb bisort sorts merges bitonic sequences 250000 integers 8kb em3d simulates propagation em waves 3d object 2000 hnodes 32kb 100 enodes voronoi computes voronoi diagram set points 20000 points 8kb unix awk unix script language awk extensive test 32kb utilities awks capabilities attempt maintain much history information possible sake correlation controlflow correlation typically maintained path length 200 basic blocksin cases resulted large number distinct paths forced measure 50 basic blocks self global correlation experiments maintained path length previous cache outcomes either self global focus predictability single level data cache two levels makes analysis compli cated choice data cache size important either large small relative problem size predicting dynamic misses becomes easy either always hit always miss therefore would like operate near knee miss ratio curve predicting dynamic hits misses presents greatest challenge although could potentially reach knee altering problem size greater flexibility adjusting cache size within reasonable range chose data cache size follows first used summary profiling collect miss ratios loads within application different cache sizes ranging 4kb 128kb chose cache size resulted largest number significant loads intermediate miss ratiosthese sizes shown table 1 cases model twoway setassociative cache lines 42 improvements prediction accuracy performance figure 6 shows three correlation profiling schemescontrolflow c self global g improve prediction accuracy correlationprofiled loads bar normalized respect number mispredicted references summary profiling p broken two categories top section predict hit actual miss represents lost opportunity predict reference hits thus attempt tolerate latency actually misses predict miss actual hit section accounts wasted overhead apply latency tolerance reference actually hits discussed earlier section 3 threshold deciding whether apply latency tolerance reference miss ratio must exceed v latency tolerance overhead l miss latency summary profiling threshold applied overall miss ratio instruction correlation profiling applied groups dynamic references along individual paths figure 6 shows results two values v summary profiling tends apply latency tolerance aggressively thus resulting noticeable amount wasted overhead contrast v summary profiling tends conservative thus resulting many untolerated misses overall correlation table 2 dynamic benchmark statistics column insts number dynamic instructions column loads number dynamic loads percentage insts also given column load miss rate datacache miss rate loads column cp loads fraction dynamic loads correlation profiled column cp load misses fraction load misses correlation profiled suite name dynamic statistics insts loads load miss rate cp load refs cp load misses integer perl 79m 15m 18 123 21 95 go 568m 121m 21 71 10 23 ijpeg 1438m 266m 18 27 2 17 vortex 2838m 830m 29 33 7 48 compress 39m 8m 20 39 6 87 gcc 282m 61m 22 14 2 40 li 228m 54m 24 40 8 73 integer espresso 560m 112m 20 22 6 70 raytrace 2105m 588m 28 48 10 53 radiosity 996m 236m 24 04 1 32 olden bh 2326m 667m 29 10 3 82 mst 90m 14m 16 69 17 91 perimeter 123m 17m 14 23 5 88 health 8m 2m 25 90 20 84 tsp 825m 239m 29 10 1 37 bisort 732m 132m 18 25 6 74 em3d 420m 73m 17 14 4 98 voronoi 263m 87m 16 13 4 57 unix utilities awk 70m 9m 7 76 16 90 profiling significantly reduce types misprediction quantify performance impact increased prediction accuracy figure 7 shows resulting execution time four profiling schemes assuming cache miss latency 50 cycles bar normalized execution time without latency tolerance broken four categories bottom section busy time section predict miss actual miss useful overhead paid tolerating references normally miss top two sections represent misprediction penalty including wasted overhead predict miss actual hit untolerated miss latency predict hit actual miss degree improved prediction accuracy translates reduced execution time 1 depends relative importance load stalls also fraction loads correlation profiled factors favorable eg eqntott see large performance improvementswhen either factor small eg perimeter tsp performance gains modest despite large improvements prediction accuracies 5 case studies develop deeper understanding correlation profiling succeeds examine number applications greater detail addition discussing memory access patterns applications also show impact correlationprofiled loads three performance metrics miss ratio distribution stall cycles per load cpl due correlationprofiled loads overall cpl cp measure impacts execution time miss ratio distribution gives us insight effectively correlation profiling isolated dynamic hit miss instances static load instructions failing hide miss expensive wasting overhead possible improve performance replacing expensive less expensive mispredictions even total misprediction count increases eg raytrace controlflow correlation v predict miss actual hit predict hit actual miss normalized misprediction awk 200 basic blocks normalized misprediction bh 200 basic blocks normalized misprediction bisort 200 basic blocks normalized misprediction compress 200 basic blocks normalized misprediction em3d 200 basic blocks normalized misprediction eqntott 50 basic blocks normalized misprediction espresso 200 basic blocks normalized misprediction gcc 200 basic blocks normalized misprediction 100 104 108 100 100 93 go 50 basic blocks normalized misprediction health 50 basic blocks normalized misprediction ijpeg 100 basic blocks normalized misprediction li 100 basic blocks normalized misprediction normalized misprediction 22 10872 28 2215191001410019 25 mst 200 basic blocks normalized misprediction perimeter 200 basic blocks normalized misprediction 71 7078 perl 200 basic blocks normalized misprediction radiosity 200 basic blocks normalized misprediction raytrace 50 basic blocks normalized misprediction sc 200 basic blocks normalized misprediction tsp 200 basic blocks normalized misprediction voronoi 200 basic blocks normalized misprediction vortex 200 basic blocks figure number mispredicted correlationprofiled loads normalized summary profiling summary profiling controlflow correlation global correlation maximum path lengths used controlflow correlation indicated next benchmark names 51 li half total load misses caused two pointer dereferences thisn flags mark pn flags sweep illustrated pseudocode figure 8 access patterns behave follows procedure mark traverses binary tree three loops shown figure 8a starting particular node first inner loop continues descending treechoosing either left right child goesuntil reaches either marked node leaf node point backup node continue descending search predict hit actual miss predict miss actual hit predict miss actual miss busy normalized exec time 88 87 85 85 100 95 95 95 awk 200 basic blocks normalized exec time 97 97 97 97 99 99 99 99 bh 200 basic blocks normalized exec time 94 92 92 92 100 96 96 96 bisort 200 basic blocks normalized exec time 86 84 86 86 95 90 95 95 compress 200 basic blocks normalized exec time 96 96 94 95 em3d 200 basic blocks normalized exec time 94 eqntott 50 basic blocks normalized exec time 96 95 92 93 99 98 96 97 espresso 200 basic blocks normalized exec time gcc 200 basic blocks normalized exec time 96 94 95 95 99 99 99 99 go 50 basic blocks normalized exec time 81 79 78 79 95 94 94 94 health 50 basic blocks normalized exec time ijpeg 100 basic blocks normalized exec time 92 88 86 88 100 96 94 97 li 100 basic blocks normalized exec time normalized exec time 86 80 79 7988 86 87 mst 200 basic blocks normalized exec time 95 94 93 93 100 98 96 97 perimeter 200 basic blocks normalized exec time 72 70 69 69 93 perl 200 basic blocks normalized exec time radiosity 200 basic blocks normalized exec time 90 raytrace 50 basic blocks normalized exec time 91 87 87 89 sc 200 basic blocks normalized exec time 97 94 93 94 98 97 96 97 tsp 200 basic blocks normalized exec time voronoi 200 basic blocks normalized exec time 93 vortex 200 basic blocks figure 7 impact profiling schemes execution time assuming 50 cycle miss latency l summary profiling controlflow correlation performed second inner loop tree allocated preorder similar one shown figure 3 except much larger therefore enjoy spatial locality long continue following left branches tree spatial locality disrupted whenever backup second inner loop illustrated figure 8c three types correlation profiling provide better cache outcome predictions summary profiling thisn flags reference mark li self correlation detects form spatial locality effectively global correlation accurate summary profiling less accurate self correlation case cache outcomes references help predict reference consume wasted space global history pattern controlflow correlation also performs well void marknode ptr f true f outer loop true f 1st inner loop thisn flags mark break marked node else f else livecdrthis f right gelse break leaf node ends ifelse ends 1st innerwhile true f 2nd inner loop backup point continue descending ends 2nd inner 1st outer procedure mark pn flags b procedure sweep tree pointer c tree traversal order mark figure 8 procedures mark sweep li memory access patterns mark note consecutively numbered nodes part c correspond adjacent addresses memory observes thisn flags likely suffer miss begin iterating first inner loop immediately following backup performed second inner loop preceding outer loop iteration finally reference pn flags sweep shown figure 8b fact array reference written pointer form self correlation global correlation detect spatial locality caused accessing consecutive elements within array although compiler could potentially recognize spatial locality static analysis recognize pn flags effectively array reference always possible cases figure 9 shows detailed performance results li miss ratio distribution figure 9a ten ranges miss ratios contains four bars corresponding fraction total dynamic correlationprofiled load references fall within range bars summary profiling represent inherent miss ratios load instructions three cases represent degree correlation profiling effectively group together dynamic instances loads separate paths similar cache outcome behavior correlation scheme effective would like see ushaped distribution references isolated always high low miss ratioswe refer case strongly biased contrast references clustered around middle distribution say weakly biased correlation profiling outperform summary profiling increasing degree bias observe figure 9a summary profiling 80 loads profile 2 miss ratios range 3050 include thisn flags pn flags references shown earlier figure 8 contrast self correlation 2 recall profile loads miss ratios 10 90 among top 15 ranked loads terms contributions total misses therefore summary profiling case never loads outside miss ratio range cpl summary global controlflow self cpi summary global controlflow self ideal b cpl due correlationprofiled loads c overall cp figure 9 detailed performance results li profiling 27 isolated loads miss ratios 3050 range 45 either 10 90 three correlation schemes increase degree bias case increased degree bias correlationprofiled loads translates reduction cpl shown figure 9b cpl due correlationprofiled loads plotted range overheadtolatency assuming miss latency 50 cycles discussed section 3 correlation profiling partially closes gap summary profiling ideal prediction overall cp also shown figure 9c 511 eqntott figure shows detailed performance results eqntott see three forms correlation profiling successfully increase degree bias reduce cpl hence cp focus memory access behavior load misses caused four loads cmppt shown figure 11a two array references ptandi b ptandi clearly spatial locality enjoyed two array references detected self correlation hence global correlation however access patterns two loads a0ptand b0ptand complicated procedure cmppt multiple call sites two say 1 2 invoke frequently whenever cmppt called 1 a0 likely unchanged b0 new value contrast whenever cmppt called 2 b0 likely unchanged a0 new value moreover 1 2 repeatedly call cmppt callsite dependent behavior results streams cache outcomes illustrated figure 11b self correlation captures streaming behavior controlflow correlation also predicts cache outcomes accurately distinguishing two call sites cmppt cache outcomes a0ptand also help predict ptandiif a0ptand hit implies array ptand loaded recently therefore ptandi references likely also hit similar correlation also exists b0ptand b ptandi hence global correlation quite effective case controlflow correlation also predicts cache outcomes ptandi cpl summary controlflow global self ideal 1121416 cpi summary controlflow global self ideal b cpl due correlationprofiled loads c overall cp figure 10 detailed performance results eqntott extern int ninputs noutputs int cmppt b pterm b f register int aa bb register int ptand b ptand famous correlated branches return 0 a0ptand b0ptand procedure cmppt causes b callsite dependent load misses cache outcome patterns figure 11 memory access behavior eqntott make loads explicit rewrite two expressions a0ptandi b0ptandi original cmppt four loads ie a0ptand ptandi b0ptand b ptandi shown b ptandi indirect fashion virtue predicting a0ptand b0ptand cpl summary controlflow global self ideal 09810210611114118 cpi summary controlflow global self ideal b cpl due correlationprofiled loads c overall cp figure 12 detailed performance results perimeter161 middleright left right middleleftmore spatial locality found bottom void middle firstquadtree p f p null return middle firstpmiddle left middle firstpmiddle right middle middle quadtree allocated preorder b code traversing quadtree figure 13 example case spatial locality found bottom tree example assumes one cache line hold three tree nodes tree allocated preorder nodes consecutive numbers adjacent memory 512 perimeter bisort figure 12 shows detailed performance results perimeter main data structures used perimeter bisort trees quadtrees perimeter binary trees bisort trees allocated preorder orders traversed rather arbitrary result see regular cache outcome patterns one illustrated figure 3 applications cpl summary controlflow global self cpi summary controlflow global self ideal b cpl due correlationprofiled loads c overall cp figure 14 detailed performance results mst nevertheless still considerable amount spatial locality among consecutively accessed nodes traversing around bottom tree allocated preorder example traverse quadtree using procedure middle first shown figure 13 miss twice upon accessing nodes 156 160 trees bottom assuming nodes 156 158 one cache line nodes 159 161 another contrast relatively little spatial locality traversing middle tree self correlation hence global correlation discover whether currently region tree enjoys spatial locality controlflow correlation also potentially detect whether close bottom tree noticing number levels recursive descent 513 mst misses mst see detailed performance results figure 14 caused loads hashlookup tmpedgehash load bluerule illustrated figure 15 mst application consists two phases creation phase computation phase phases invoke hashlookup creation phase causes misses calls hashlookup check whether key already exists hash table allocating new entry computation phase much data already brought cache hence relatively misses self correlation global correlation accurately predict cache outcomes two distinct phases since appear repeated streams either hits misses controlflow correlation also effective since distinguish call chains invoke hashlookup load tmpedgehash bluerule accesses linked lists whose nodes fact allocated contiguous memory locations consequently self correlation detects spatial locality accurately controlflow correlation helpful void hashlookupint key hash hash f int j hashentry ent ent entkey key ent return ententry return null static bluereturn bluerule f tmpvlistnext tmp prevtmptmptmpnext f figure 15 pseudo codes drawn mst total correlationprofiled miss ratio controlflow global self miss ratio distribution correlationprofiled load references0050150250350 cpl summary controlflow global self ideal cpi summary controlflow global self ideal b cpl due correlationprofiled loads c overall cp figure detailed performance results raytrace 514 raytrace tsp raytrace refer figure 16 performance results 30 load misses caused pointer dereference tmpbv prims box2 see figure 17 subdiv bintree two calls prims box2 copy part array pe current node btn arrays btn1pe btn2pe btn1 btn2 children btn process copying pe performed recursively whole tree create bintree result prims box2 called upon node n may used values array pe referred pepa prims box2 n antecedent n hence hopefully data loaded tmpbv already cache case references tmpbv hit cache contrast values pepa new tmpbv references miss hence self correlation captures streams hits streams misses theory controlflow correlation could also achieve good predictions observing whether copying occurred parent nodeunfortunately profiling tool cannot record enough state across many controlflow changes subdiv bintree prims box2 know decisions made parent node element prims box2pepa f computes ovlap change pepaj ovlap 1 f return npepa void subdiv bintreebtnode btn f btn1 btn2 btns children prims box2btnpe prims box2btnpe void create bintreebtnode root f f subdiv bintreeroot create bintreerootbtn0 create bintreerootbtn1 figure 17 pseudo codes drawn raytrace tree tsptree tint sz f tsize sz return conquert return mergeleftval rightval static tree conquertree f l ldonext f figure codes drawn tsp procedure makelisttree slings list consisting nodes similar raytrace tsp also traverses binary tree recursively data read current node read descendents illustrated figure 18 procedure tsp recursively traverses tree calls conquert size greater sz procedure conquert uses makelistt sling every node list traversed loop therefore since descendents brought cache whenever conquert called subsequent recursion tleft tright within tsp results many cache hits hence ldata references either mainly hit mainly miss given node self correlation captures pattern effectively controlflow correlation also quite effective observe number times conquer called given recursive descentmost misses occur first time invoked 515 voronoi compress controlflow correlation offers best prediction accuracy applications misses voronoi caused loading bnext splice called three different places merge illustrated figure 20a splice called call site 1 bnext hit since ldinext loaded data cache prior call splice called two call sites bnext likely miss hence controlflow correlation distinguishes behavior different call sites accurately self correlation less effective since bnext regular cache outcome patterns compress see figure 19 performance results roughly half misses caused hash total correlationprofiled refs summary4 0 10 20 30 40 50 60 70 80 90 100 miss ratio controlflow global self miss ratio distribution correlationprofiled load references005015025035 cpl summary global self controlflow cpi summary global self controlflow ideal b cpl due correlationprofiled loads c overall cp figure 19 detailed performance results compress table access htabofi procedure compress see figure 20b index hash table htab function combination prefix code ent new character c combination seen hash probe test htabi fcode trueif seen recently load htabi likely hit cache since input file use provided spec generated frequency distribution common english texts strings appear often others expect condition htabi fcode true quite frequently many common strings entered htab last tests htabi fcode false probability next one true high also implies next reference htabi likely hit therefore controlflow correlation make accurate predictions examining last several outcomes branch 516 espresso vortex m88ksim go four applications correlation profiling mainly improves cache outcome predictions array references espresso see figure 21 detailed performance results many load misses due array references written pointer form variable strides figure 22a shows one example inside loop p incremented bbwsize whose value depends call chain setup bb cc ranges 4 24 bytes different values result different degrees spatial locality captured self correlation hence global correlation controlflow correlation also make enhanced predictions exploiting callchain information vortex m88ksim go many load misses caused array references located inside procedures array indices passed procedure parameters see figure 22b example drawn vortex procedures multiple call sites cache outcomes array references mainly callsite dependent explains controlflow correlation offers highest cache outcome prediction accuracy three benchmarks vortex array index parameter values given call close even identical time values passed different call sites quite different consequently references made call sites enjoy temporal andor spatial edge pair merge f call site 1 dereferences ldj call site 2 dereferences ldk call site 3 splicequad edge quad edge b f htabi fcode f else f store fcode htab code fragment voronoi b code fragment compress figure 20 pseudo codes drawn voronoi b compress locality made different call sites since procedure usually invoked multiple times call site invoked another call site results streaming pattern miss followed several hitshence self correlation also performs well vortex capturing cache outcome patterns 52 lessons learned case studies although global correlation makes excellent predictions cases correlating behavior across different load instructions eg eqntott cases essentially assimilates self correlation perform quite well since records less history given load self correlation often successful since recognizes forms spatial locality recognizable compile time eg li perimeter bisort mst also long runs either hits misses eg eqntott mst tsp raytrace often find four previous cache outcomes per reference sufficient achieve good predictability self correlation capturing call chain information controlflow correlation distinguish behavior based call sites eg eqntott espresso vortex m88ksim go mst voronoi depth recursion traversing tree eg perimeter bisort tsp roughly half applications enjoy significant improvements controlflow self correlation many cases observe load references successfully predicted forms correlation good news since controlflow correlation profiling easiest case exploit practice using procedure cloning 5 distinguish callchain dependent behavior 6 applying correlation profiling prefetching demonstrate practicality correlation profiling used summary correlation profiling guide manual insertion prefetch instructions three applications eqntott tsp raytrace case correlation profiling used procedure cloning 5 isolate different dynamic instances static reference adapted prefetching strategy accordingly respect call sites assumed v deciding whether insert prefetches 3 performed fullydetailed simulations processor similar mips r10000 8 details memory hierarchy shown figure 23a 3 assume average prefetch overhead v two cycles average miss latency l 20 cycles total correlationprofiled refs summary26 miss ratio controlflow global self miss ratio distribution correlationprofiled load references002006010140 cpl summary controlflow global self ideal cpi summary controlflow global self ideal b cpl due correlationprofiled loads c overall cp figure 21 detailed performance results espresso void setup bb ccpcover bb pcover ccf lastpbbcountbbwsize boolean chkgetchunknumtype chunknum f code fragment espresso b code fragment vortex figure 22 pseudo codes drawn espresso b vortex figure 23b shows resulting execution times normalized case without prefetching applications summaryprofiling directed prefetching actually hurts performance due overheads unnecessary prefetches contrast correlation profiling provides measurable performance improvements isolating dynamic hits misses effectively thereby achieving similar benefits significantly less overhead would also like point numbers represent limit correlation achieve example 8kb primary data cache correlation profiling offers 10 speedup summary profiling case eqntott 7 related work abraham et al 2 investigated using summary profiling associate single latency tolerance strategy ie either attempt tolerate latency profiled load used approach reduce memory parameters mips r10000 simulator primary instr data caches 32kb 2way setassoc unified secondary cache 2mb 2way setassoc line size 32b primarytosecondary 12 cycles miss latency primarytomemory miss latency data cache miss 8 handlers mshrs data cache banks 2 data cache fill time 4 cycles requires exclusive access main memory bandwidth 1 access per 20 cycles normalized exec time load stall113 eqntott tsp raytrace store stall inst stall busy memory parameters b execution time figure 23 impact correlation profiling prefetching performance prefetching prefetching directed summary profiling prefetching directed correlation profiling cache miss ratios nine spec89 benchmarks including integer floatingpoint programs followup study 1 also report improvement effective cache miss ratio contrast earlier work study focused correlation profiling novel technique provides superior prediction accuracy relative summary profiling ammons et al3 used path profiling techniques observe large fraction primary data cache misses spec95 benchmarks occur along relatively small number frequently executed paths three forms correlation explored study controlflow self global inspired earlier work using correlation enhance branch prediction accuracies 4 10 15 16 branch outcomes cache access outcomes quite different interesting observe correlationbased prediction works well cases conclusions achieve full potential softwarebased latency tolerance techniques proposed correlation profiling technique isolating dynamic instances static memory reference likely suffer cache misses evaluated potential performance benefits three different forms correlation profiling wide variety nonnumeric applications experiments demonstrate correlation profiling techniques always outperform summary profiling increasing degree bias miss ratio distribution improved prediction accuracy translate significant reductions memory stall time roughly half applications study detailed case studies individual applications show self correlation works well cache outcome patterns individual references often repeat predictable ways controlflow correlation works mainly many cache outcomes callchain dependent although global correlation offers superior performance cases part mainly assimilates self correlation finally observe correlation profiling offers superior performance summary profiling prefetching superscalar processor believe promising results may lead innovations optimizing memory performance nonnumeric applications appendix derivation stall cycles per load cpl five latencytolerance schemes denote cpl particular tolerance scheme cpl let cpl cpl load program f fraction references made load total references loads theta f 1 let l cycles stalled upon load miss v overhead applying latencytolerance technique load reference miss ratio load overall miss ratio loads load reference stalled cache miss fully tolerates latencies load references always incurs overhead cpl single action per load miss ratio decides whether applied load single action per load ae l ie apply otherwise ie apply 4 cpl single action per load single action per load theta f single action per load theta f set loads miss ratios v l na set loads miss ratios v l cpl multiple actions per load applied references load belong contexts miss l formula cpl multiple actions per load simply obtained adding extra level equation 5 capture notion contexts within load multiple actions per load set contexts load miss ratios v set contexts load miss ratios v miss ratio context j load f ij fraction references load context j cpl multiple actions per load obtained substituting multiple actions per load equation 1 loadmiss latencies fully tolerated overhead incurred miss references r predicting load latencies using cache profiling predictability loadstore instruction latencies exploiting hardware performance counters flow context sensitive profiling branch classification new mechanism improving branch predictor performance methodology procedure cloning informing memory operations providing memory performance feedback modern processors mips technologies inc design evaluation compiler algorithm prefetching improving accuracy dynamic branch prediction using branch correlation supporting dynamic data structures distributed memory machines software support speculative loads tracing pixie splash2 programs characterization methodological considerations comparison dynamic branch predictors use two levels branch history improving accuracy static branch prediction using branch correlation tr software support speculative loads design evaluation compiler algorithm prefetching improving accuracy dynamic branch prediction using branch correlation comparison dynamic branch predictors use two levels branch history branch classification improving accuracy static branch prediction using branch correlation supporting dynamic data structures distributedmemory machines splash2 programs informing memory operations predictability loadstore instruction latencies exploiting hardware performance counters flow context sensitive profiling ctr aleksandar milenkovic achieving high performance busbased sharedmemory multiprocessors ieee concurrency v8 n3 p3644 july 2000 craig zilles gurindar sohi executionbased prediction using speculative slices acm sigarch computer architecture news v29 n2 p213 may 2001 k tan k raghunathan g lakishminarayana n k jha highlevel software energy macromodeling proceedings 38th conference design automation p605610 june 2001 las vegas nevada united states young michael smith better global scheduling using path profiles proceedings 31st annual acmieee international symposium microarchitecture p115123 november 1998 dallas texas united states jeffrey dean james e hicks carl waldspurger william e weihl george chrysos profileme craig b zilles gurindar sohi understanding backward slices performance degrading instructions acm sigarch computer architecture news v28 n2 p172181 may 2000 adi yoaz mattan erez ronny ronen stephan jourdan speculation techniques improving load related instruction scheduling acm sigarch computer architecture news v27 n2 p4253 may 1999 chihung chi junli yuan chinming cheung cyclic dependence based data reference prediction proceedings 13th international conference supercomputing p127134 june 2025 1999 rhodes greece abhinav das jiwei lu howard chen jinpyo kim penchung yew weichung hsu dongyuan chen performance runtime optimization blast proceedings international symposium code generation optimization p8696 march 2023 2005 young michael smith static correlated branch prediction acm transactions programming languages systems toplas v21 n5 p10281075 sept 1999 martin burtscher amer diwan matthias hauswirth static load classification improving value predictability datacache misses acm sigplan notices v37 n5 may 2002 jaydeep marathe frank mueller tushar mohan bronis r de supinski sally mckee andy yoo metric tracking inefficiencies memory hierarchy via binary rewriting proceedings international symposium code generation optimization feedbackdirected runtime optimization march 2326 2003 san francisco california chikeung luk tolerating memory latency softwarecontrolled preexecution simultaneous multithreading processors acm sigarch computer architecture news v29 n2 p4051 may 2001 tor aamodt paul chow optimization data prefetch helper threads pathexpression based statistical modeling proceedings 21st annual international conference supercomputing june 1721 2007 seattle washington jiwei lu howard chen rao fu weichung hsu bobbie othmer penchung yew dongyuan chen performance runtime data cache prefetching dynamic optimization system proceedings 36th annual ieeeacm international symposium microarchitecture p180 december 0305 chikeung luk robert muth harish patil richard weiss p geoffrey lowney robert cohn profileguided postlink stride prefetching proceedings 16th international conference supercomputing june 2226 2002 new york new york usa jaydeep marathe frank mueller tushar mohan sally mckee bronis r de supinski andy yoo metric memory tracing via dynamic binary rewriting identify cache inefficiencies acm transactions programming languages systems toplas v29 n2 p12es april 2007 characterizing memory behavior java workloads structured view opportunities optimizations acm sigmetrics performance evaluation review v29 n1 p194205 june 2001 mark horowitz margaret martonosi todd c mowry michael smith informing memory operations memory performance feedback mechanisms applications acm transactions computer systems tocs v16 n2 p170205 may 1998