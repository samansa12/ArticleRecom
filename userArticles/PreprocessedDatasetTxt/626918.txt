comparison tracesampling techniques multimegabyte caches paper compares tracesampling techniques set sampling time sampling using multibillion reference traces borg et al 1990 apply techniques multimegabyte caches sampling valuable evaluate whether either technique meets 10 sampling goal method meets goal least 90 time estimates traces true misses per instruction spl les10 relative error using spl les10 trace results traces caches show set sampling meets 10 sampling goal time sampling also find coldstart bias time samples effectively reduced technique da wood et al 1991 nevertheless overcoming coldstart bias requires tens millions consecutive references b introduction computer designers commonly use tracedriven simulation evaluate alternative cpu caches smit82 cache sizes reach one megabyte traditional tracedriven simulation requires long traces eg billions references determine steadystate performance bokw90 ston90 long traces expensive obtain store use avoid simulating long traces using tracesampling techniques let cache performance small portion trace observation collection observations sample sampling theory tells 1 r e kessler supported part summer internship digital equipment corporation graduate fellowships national science foundation university wisconsin alumni research foundation employed cray research inc mark hill supported part national science foundation mips8957278 ccr8902536 bell laboratories cray research foundation digital equipment corporation david wood supported part national science foundation ccr9157366 university wisconsin graduate school time cache sets timespace diagram memory references vertical slice horizontal slice figure 1 sampling vertical horizontal timespace slices figure shows timespace diagram simulation short trace time position within trace cache set reference marked observation set sampling cache performance one set references determine single sets performance appear horizontal slice figure observation time sampling cache performance interval consecutive references references appear vertical slice figure predict cache performance full trace given random sample unbiased observations mifj90 additional assumptions also estimate far true value likely estimate two important tracesampling techniques set sampling heis90 puza85 time sampling lapi88 laha88 observation set sampling cache performance references single set depicted horizontal slice figure 1 observation time sampling cache performance references single timecontiguous trace interval vertical slice figure 1 2 study first compare set sampling time sampling using billionreference traces large workloads include multiprogramming operating system references bokw90 examine well methods predict mean misses per instruction mpi multimegabyte caches say sampling method effective meets following goal 2 laha et al lapi88 wood et al wohk91 referred observation references timecontiguous interval sample use sample refer collection observations consistent statistics terminology mifj90 definition 1 10 sampling goal sampling method meets 10 sampling goal using 10 references trace estimates traces true mpi 10 relative error least 90 confidence setsampling find several results first calculating mpi sample using instruction fetches sets much accurate using instruction fetches sampled sets second instead selecting sets sample random selecting sets share several index bit values reduces simulation time facilitates simulation cache hierarchies still accurately predicts traces mpi third important set sampling effective traces caches typically meets 10 sampling goal timesampling first compare techniques overcoming coldstart bias easf78 ie determining mpi particular trace interval without knowing initial cache state consider leaving coldstart bias unchanged recording metrics second half interval recording metrics initialized sets lapi88 ston90 stitching intervals together aghh88 wood et als model predicting initialization reference miss ratio wohk91 obtain two results first average technique wood et al minimizes coldstart bias better techniques second multimegabyte caches stu died interval lengths tens millions instructions larger needed reduce effects coldstart using wood et als technique mitigate coldstart bias show time sampling fails meet 10 sampling goal 1 many intervals needed capture workload variation 2 long intervals necessary overcome coldstart bias thus traces caches set sampling effective time sampling estimating mpi time sampling still preferred however caches timedependent behavior eg prefetching interactions sets eg single write buffer consider nonsampling techniques reduce trace data storage mache samp89 stack deletion snapshot method smit77 trace tape stripping puza85 wanb90 exploiting spatial locality agah90 techniques used addition sampling considered study also consider przybylskis prefix technique przy88 prepends previouslyreferenced unique addresses timeobservation method seems unattractive multimegabyte caches time observation requires prefix prefix must large programs exercise multimegabyte caches section 2 describes methods section 3 4 examine set sampling time sampling respectively finally section 5 summarizes results 2 methodology section describes traces cache configurations performance metric use later sections 21 traces traces used study collected dec western research laboratory wrl bokl89 bokw90 dec wrl titan niel86 loadstore risc architecture trace consists execution three six billion instructions large workloads including multiprogramming operating system references traces reference eight one hundred megabytes unique memory locations traces sufficiently long overcome coldstart intervals even large caches considered study chose programs large memory requirements since predict large application sizes common main memories hundreds megabytes become available traces multiprogrammed workloads represent actual execution interleaving processes traced system mult2 trace includes series compiles printed circuit board router vlsi design rule checker series simple programs commonly found unix 3 systems executing parallel megabytes active time average 134000 instructions executed process switch mult22 trace mult2 workload switch interval 214000 instructions mult1 trace includes processes mult2 trace plus execution system loader last phase compilation scheme lisp variant program 75 megabytes active switch interval 138000 instructions mult12 trace mult1 workload switch interval 195000 instructions trace vlsi timing verifier 96 megabytes sor uniprocessor successiveoverrelaxation algorithm uses large sparse matrices 62 megabytes tree scheme program searches large tree data structure 64 megabytes lin power supply analyzer uses sparse matrices 57 megabytes 22 cache configuration assumptions study focuses multimegabyte unified mixed caches expect trace sampling useful vary size setassociativity caches range 1megabyte 16megabytes directmapped fourway caches prefetching use writeback writeallocate policies 128byte blocks nondirectmapped caches use random replacement policy expect 3 trademark att bell laboratories replacement policy affect sampling accuracy since example leastrecentlyused replacement eliminates 15 cache misses caches kess91 caches use virtualindexing pidhashing approximation realindexing 4 also examined several realindexed caches found produced results similar paper surprising since realindexed cache performance often close virtualindexed cache performance since multimegabyte caches likely used cache hierarchy simulate alternative secondary caches placed behind fixed primary cache configuration primary caches split separate instruction data caches 32kilobytes directmapped 32byte blocks prefetching use virtual indexing writeback writeallocate policies evaluate primary cache tradeoffs study since secondary cache performance unaffected primary caches sizes differ least factor eight prhh89 23 performance metric misses per instruction measure cache performance misses per instruction mpi rather miss ratio 5 since use mpi compare performance alternative unified secondary caches mpi equivalent przybylskis global miss ratio prhh89 specifically caches mpi equal global miss ratio times average number processor references instruction fetches data references per instruction 3 set sampling first examine set sampling observation mpi single set sample collection singleset observations section 31 discusses compute set samples mpi contain random sets section 32 examines well set sampling predicts mpi long mpi full trace 4 caches use virtualindexing select set reference using references virtual address use realindexing select real address pidhashing means exclusiveor upper eight index bits virtual address process identifier pid currently executing process 5 mpi better miss ratio comparing performance contributions several caches system eg instruc tion data secondary mpi implicitly factors often cache accessed furthermore mpi times caches average miss penalty directly gives cycles per instruction cpi lost caches misses henp90 31 constructing set samples 311 calculating mpi sample consider cache sets numbered 0 1 set let miss instrn number misses instruction fetches set let sample containing n sets consider two ways calculate mpi sample mpi sampledinstructions method divides mean misses sets sample mean instruction fetches sets sample 6 mpi allinstructions method divides mean instruction fetches sets mpi compare two methods computing coefficients variation across set samples j obtained constantbits method described section 312 long long number samples experimental results illustrated table 1 show allinstructions method performs much better never coefficient variation onetenth sampledinstructions method difference infinite sor lin traces loops confine many instruction fetches sets also investigated normalizing miss total references per set data references per set kess91 methods 6 consider calculating mpi n miss puzak puza85 showed estimating miss ratio arithmetic mean perset miss ratios inferior dividing misses sampled sets references sampled sets missratio equivalent sampledinstructions method sample containing sets puzaks work also implies miss long coefficient variation percent trace mpi long 1000 allinstructions sampledinstructions mult12 069 19 289 mult22 059 13 243 sor 754 03 tree 059 68 1919 lin table 1 accuracy mpi computations table illustrates accuracy computing full trace mpi column two several traces allinstructions sampledinstructions methods accuracy evaluated coefficient variation equation 1 mpi estimates 4megabyte directmapped secondary cache samples 116 full trace set samples constructed constant bits method described next section results show allinstructions method far superior sampled instructions method perform similarly sampledinstructions method well allinstructions method minor disadvantage allinstructions method gathering references sample must also count instruction fetches sets since believe drawback outweighed experimental results use allinstructions method throughout paper 312 constantbits method examine two methods selecting sets form sample use example show disadvantage selecting sets random introduce constantbits method overcome disadvantage assume want evaluate three caches samples contain 116th references full trace let caches choose references set bit selection ie index bits leastsignificant address bits block offset following parameters cache 32kilobyte directmapped cache 32byte blocks therefore index bits bits 145 assuming references byte addresses bit 0 leastsignificant cache b 1megabyte twoway setassociative cache 128byte blocks index bits 187 cache c 16megabyte directmapped cache 128byte blocks index bits 237 one method selecting sets sample choose random puza85 evaluate cache references random sets randomly select 64 1024 sets 116th filter full trace extract e three filtered simulate cache sets cache filter random selecting sets random cache b selecting sets share constant bits traces full trace one filtered simulate cache trace constant bits filter four figure 2 two methods selecting sets sample figure illustrates selecting sets samples three alternative caches b c using random sets b constant bits sets selected random simulation must begin filtering full trace constantbits hand filtered trace drive simulation cache whose index bits contain constant bits references sets simulate cache cache b select 128 2048 sets filter simu late similarly cache c use 8192 131072 sets illustrated figure 2a selecting sets random requires simulation begin extracting references full trace furthermore since primary secondary caches usually different sets clear simulate hierarchy cache sets selected random introduce new method called constantbits selects references rather sets constantbits method forms filtered trace includes references value address bits filtered trace used simulate cache whose index bits include constant bits 7 kess91 example filter trace retaining references binary value 0000 one 15 7 description assumes bit selection ie setindexing bits come directly address memory access smit82 scenario complicated simple bitselection cache indexing particular since use pidhashing study ensured hashed index bits overlap constant bits note though use virtualindexing one apply constantbits technique realindexed caches hierarchical configurations real virtual indexed caches constant bits page boundary e one filtered secondary cache trace constant bits filter four simulate primary cache simulate one filtered trace cache p figure 3 using constantbits samples hierarchy figure illustrates use constantbits samples simulate primary cache p three alternative secondary caches b c values address bits 118 filtered trace used cache select sets binary index xxx0000xxx x either 0 1 since index pattern six xs identifies 64 2 6 1024 sets cache caches b c filtered trace selects sets indices xxxxxxx0000x xxxxxxxxxxxx0000x respectively generally use filtered trace select 116th sets cache whose block size 256 bytes less whose size divided associativity exceeds 2 kilo bytes include primary caches 32byte blocks kilobytes directmapped secondary caches 128byte blocks 116 megabytes 14way setassociative considered paper constantbits samples two advantages random samples first illustrated figure 2b using constantbits samples reduces simulation time allowing filtered trace drive simulations one alternative cache second constantbits samples make straightforward simulate hierarchies caches caches index constant bits illustrated figure 3 may simulate primary cache use trace misses simulate alternative secondary caches potential disadvantage constantbits samples may work poorly workloads use address space systematically eg frequent accesses large fixed stride vector experimental evidence ever suggests constantbits sampling effective figure 4 illustrates accuracy constant bits sampling instructions executed billions312misses perinstructions setsampled mult12 mpi time figure 4 set sampling mult12 trace every 100 million instructions figure shows actual mpis solid line predicted mpis 16 different set samples dotted lines mult12 trace 4megabyte directmapped cache sample includes references value address bits 118 ie bits 118 constant bits assuming references byte addresses bit 0 leastsignificant since four bits used select references 16 samples contains average 116th trace mult12 trace every 100 million instructions plots true mpi interval mpi obtained 16 set samples 116 references full trace example set samples almost indistinguishable true mpi generally found constantbits samples equally accurate random samples multimegabyte caches kess91 thus use constantbits method construct set samples throughout rest paper 32 fraction full trace needed section examines well set samples estimate mpi full trace reasons discussed construct samples constantbits method calculate mpi estimate sample instructions method first look accuracy set sampling mpi long known show construct confidence intervals mpi long known figure 4 saw qualitatively one trace cache sample size mpi variations set samples mpi long modest compared temporal variations table 2 quantifies long run error samples mpi long several traces directmapped cache sizes sample sizes measure errors coefficient variation calculated using equation 1 table 3 gives corresponding results twoway setassociative caches setsampling coefficients variation percent fraction sets sample trace size mpi long 1000 14 116 164 mult12 mult22 1m 263 07 19 na 4m 754 01 03 07 sor 1m 216 41 56 na tree lin table 2 set sampling coefficients variation direct mapped table shows actual mpi full trace mpi long directmapped caches coefficient variation setsampling mpi estimates calculated using equation 1 construct samples constantbits method samples containing 14 sets cache bits 98 constant samples 116 164 use bits 118 127 respectively entries marked na available pid hashing overlapped constant bits except marked dagger least 90 samples relative errors less equal 10 key result data fourway setassociative caches shown set sampling generally meets 10 sampling goal consider columns labeled 116 tables 2 3 correspond samples using 116th sets therefore contain less 10 trace average lin tree 4megabyte directmapped caches marked daggers fail least 90 samples relative errors less equal 10 2 16 samples 10 relative error also observe two interesting trends data first reducing fraction sets sample hence number sets per sample 14 116 116 164 increases coefficient variation perset mpis independent identically distributed reducing number sets sample setsampling coefficients variation percent fraction sets sample trace size mpi long 1000 14 116 164 mult12 mult22 1m 231 02 06 na sor tree lin table 3 set sampling coefficients variation 2way table shows mpi full trace twoway setassociative caches coefficient variation mpi estimates similar table 2 except marked dagger least 90 samples relative errors less equal 10 four double coefficient variation mifj90 ston90 indeed good evidence case see example row mult12 4megabyte cache second increasing associativity directmapped twoway reduces corresponding coefficients variation 50 conjecture set sampling works better twoway setassociative caches fewer conflict misses directmapped caches hils89 high rate conflict misses sets make sets poor predictors overall behavior finally practical applications set sampling want estimate error mpi estimate using information contained within sample ie using knowledge mpi long tables 2 3 using 90 confidence intervals calculated sample mean sample standard deviation standard technique mifj90 estimate sample standard deviation includes finite population correction important sample size substantial fraction population eg 90 confidence intervals contain mpi long fraction sets sample trace 14 116 164 fraction percent fraction percent fraction percent mult12 44 100 1616 100 6064 94 mult22 44 100 1616 100 6364 98 sor 44 100 1616 100 6464 100 tree 24 50 1216 75 4764 73 lin 44 100 1616 100 6264 97 89 93 91 table 4 setsampling error prediction 4megabyte directmapped secondary cache various traces fraction sets table gives fraction percent 90 confidence intervals contained mpi long since percentages near 90 confidence intervals usefully estimate far mpi likely mpi long sample includes 14th sets kess91 mifj90 large sampling theory predicts 90 90 confidence intervals contain true mean various constantbits set samples 4megabyte directmapped cache table 4 displays fraction 90 confidence intervals actually contain mpi long since results table 4 usually similar 90 confidence interval calculation useful method estimating error setsample given information within sample alone 33 advantages disadvantages set sampling important advantage set sampling simulations meets 10 sampling goal definition 1 set sample automatically includes references many execution phases individual sample accurately characterize mpi full trace including temporal variability reduced trace data requirements set sampling allow simulation longer traces therefore algorithmic phases smaller amount time besides data reduction set sampling also reduces memory required simulate cache set sample containing 116 full trace needs simulate 116 sets sampling limitations even constant bits method full trace must retained one wishes study caches index constant bits furthermore set sampling may accurately model caches whose performance affected interactions references different sets effectiveness prefetch one set example may depend many references made sets prefetched data first used similarly performance cache write buffer may affected often write buffer fills due burst writes many sets 4 time sampling alternative set sampling time sampling observation mpi sequence time contiguous references called interval section 41 discusses determining mpi sample section 42 examines using sample estimate mpi full trace 41 reducing coldstart bias time samples significantly reduce trace storage simulation time must estimate true mpi interval without knowledge initial cache state ie cache state beginning interval problem simply wellknown coldstart problem applied interval easf78 examine well following five techniques mitigate effect coldstart problem multimegabyte caches cold cold assumes initial cache state empty assumption affect misses full sets hits set causes cold overestimate mpi references appear miss nonfull sets may may misses simulated true initial cache state potential misses often called coldstart misses easf78 half half uses first half instructions interval partially initialize cache estimates mpi remaining instructions prime prime estimates mpi references initialized sets set directmapped cache initialized filled ston90 set setassociative cache initialized filled nonmostrecentlyused block referenced lapi88 stitch stitch approximates cache state beginning interval cache state end previous interval aghh88 thus one creates trace sample stitching intervals together initmr like cold initmr simulates interval beginning empty initial cache state instead assuming coldstart misses miss however initmr uses wood et als split estimate fraction coldstart misses would missed initial cache state known wohk91 estimate based 1 fraction time cache block frame holds block referenced replaced 2 fraction cache loaded coldstart simulation interval could estimate 1 references interval assume 07 particular trace cache evaluate coldstart technique follows select number instructions interval called interval length collect sample n 30 intervals spaced equally trace use coldstart technique estimate mpi interval mpi calculate mpi estimate sample mpi since full trace simulate interval initial cache state determine intervals true mpi mpi calculate true mpi sample mpi n evaluate well technique reduces coldstart bias sample 9 important note mpi mpi long section 42 examine well time sample predicts full trace mpi seek mitigate coldstart bias mpi evaluate bias five coldstart techniques eight traces four interval lengths 100 thousand 1 mil lion 10 million 100 million instructions three cache sizes 1 4 16 megabytes two associativities directmapped fourway since space precludes us displaying 192 cases coldstart technique present several subsets data 10millioninstruction interval length tables 5 6 display bias directmapped fourway setassociative caches respectively data show several trends first cold half stitch tend overestimate mpi cold assumes coldstart misses miss similarly half tends 8 since time sampling interval number instructions meaningful compute mpi arithmetic mean mpi 9 calculate bias prime secondary caches local miss ratio rather mpi counting number instructions straightforward sets initialized others since bias relative er ror expect calculating local miss ratio comparable calculating mpi cache trace size mpi 1000 cold half prime stitch initmr mult12 mult22 1m 255 4 0 33 32 2 sor 1m 200 13 0 10 29 1 tree lin table 5 bias coldstart techniques directmapped caches table displays bias five coldstart techniques eight traces interval length 10 million instruc tions three directmapped cache sizes 1 4 16 megabytes overestimate mpi first half trace sufficiently fill cache half underestimate samples mpi however second half samples intervals lower mpi whole interval believe stitch overestimates mpi due temporal locality references less likely miss simulated intervals true initial state final state previous interval wood90 second prime underestimates mpi directmapped caches prime calculates mpi effectively assuming coldstart misses likely miss reference wood et al wohk91 shown however assumption false coldstart misses much likely miss randomlychosen references prime accurate fourway setassociative caches heuristic ignoring initial references mostrecentlyreferenced block mitigates underestimation third initmr consistently underestimate overestimate mpi finally large biases lin trace 4 16 megabyte caches probably important true mpis small e trace size mpi 1000 cold half prime stitch initmr mult12 mult22 1m 214 4 2 22 32 2 sor tree lin table 6 bias coldstart techniques fourway setassociativity table displays bias five coldstart techniques eight traces interval length 10 million instruc tions three fourway setassociative cache sizes 1 4 16 megabytes table 7 addresses coldstart technique best five coldstart techniques compute bias 192 cases award point 10 category biases less 10 award one win category coldstart technique closest unbiased multiple points awarded case ties final row table 7 gives totals half initmr twice 10 score approaches initmr wins approaches combined half performs well many cases initmr performs best overall table 8 illustrates well initmr performs three directmapped caches 1 4 four interval lengths 100000 1000000 10000000 100000000 instructions expected reduces bias effectively interval lengths get longer cache size gets smaller coldstart becomes less dominant striking aspect data initmr best method still performs terribly intervals containing 100000 1000000 instructions surprising since number block frames caches eg 8192 1megabyte caches far exceeds number true misses cache interval cold half prime stitch initmr length size mill 10 win 10 win 10 win 10 win 10 win table 7 scoring different coldstart techniques table displays scores coldstart techniques 192 cases eight traces four interval lengths million 100 million instructions three cache sizes 1 4 bytes two associativities directmapped fourway award point 10 category 10 bias 10 award one win category coldstart technique closest unbiased log bias closest zero multiple points awarded case ties intervals eg 1550 equals 1000000 instructions times 000155 mpi mult1 furthermore appears initmr adequately mitigate coldstart bias unless interval lengths least 10 million instructions 1megabyte caches 100 million instructions 4megabyte caches 100 million instructions 16megabyte caches results consistent ruleofthumb trace length increased factor eight time cache size quadruples ston90 table 8 also illustrates however determine initmr likely perform well marked entry table asterisk average interval length sufficient fill least half cache b least many misses full sets coldstart misses values bias marked asterisk less 10 nevertheless imply multimegabyte caches interval contain instructions previously present many full traces cache interval length millions instructions trace size mpi long 1000 mult12 1m 145 103 21 2 0 mult22 1m 118 127 24 1 0 sor 1m 1477 41 3 0 0 4m 754 27 44 6 0 tree 1m 216 249 36 1 0 lin 1m 116 30 14 16 1 table 8 accuracy initmr timesample mpi estimates table displays bias initmr eight traces four interval lengths three directmapped cache sizes 1 4 16 megabytes mark entries asterisk average interval lengths sufficient fill least half cache b least many misses full sets coldstart misses fraction full trace data10ratio estimate full trace mpi initmr estimates 100 million instructions million instructions fraction full trace data unbiased10a cones mpi b cones mpi hat figure 5 cones time sampling mult12 figure displays cones mpi left mpi right mult12 trace 4megabyte directmapped cache interval length sample size whose product gives fraction trace used height cone displays range middle 90 estimates many samples 42 fraction full trace needed section examines accurately time samples estimate mpi long mpi full trace estimate mpi sample mpi arithmetic mean mpi estimates interval sample use initmr reduce coldstart bias interval figure 5a illustrates summarize data 10 mult12 traces 4megabyte directmapped cache plots mpi mpi long logarithmic yaxis fraction full trace contained sample logarithmic xaxis consider cone far left use 3000 1millioninstruction intervals calculate shape left edge near 000025 gives fraction trace used sample one interval determine endpoints left edge empirical distribution mpi singleinterval samples upper endpoint gives 95th percentile lower gives 5th percentile thus length left edge 10 use visual display instead coefficient variation believe provides insight use visual display set sampling enough samples smooth data range middle 90 mpi compute vertical slices similarly vertical line shown cone example gives range middle 90 mpi samples 40 intervals two cones interval lengths 10 million instructions 300 inter vals 100 million instructions 30 intervals right graph gives similar data mpi calculate mpi interval true initial cache state time sample would meet 10 sampling goal definition 1 samples size times length interval less 10 trace eg left xaxis value 01 figure 5a lower point appropriate cone falls 09 11 yaxis unfortunately none three cones mult12 qualify cone 1millioninstruction intervals narrow enough biased far 10 cones 10 million 100 million instructions wide found similar results rest traces displayed figures 6a 6b cones multiprogrammed traces similar mult12 although mult2 mult22 coldstart bias cones single applications tree tv sor lin idiosyncratic reflecting applicationspecific behavior cones sor example skewed sors behavior alternating low high mpi period around 300 million instructions bokw90 traces caches directmapped fourway 1 16megabyte caches kess91 time sampling fails meet 10 sampling goal nevertheless data provides several insights time sampling first cones mpi figure 5b vertically centered 10 shape similar mpi left data data traces shown suggest mpi mpi different means similar distributions therefore appears looking better ways mitigating coldstart bias interval sample decoupled examining well samples tend predict mpi long second height cones tends vary one square root sample size number intervals per sample suggests mpi behaving independent identically distributed random variables mifj90 third even eliminate coldstart bias accurate estimates mpi long must use hundred millions instructions capture temporal workload variations mult12 4megabyte directmapped cache figure 5b shows mpi within 10 mpi long 90 samples examined samples 200 intervals length 1 million instructions 10millioninstruction intervals 20 100millioninstruction intervals 11 roughly factor three decrease sample size interval length multiplied ten 11 much smaller caches laha et al found sample size 35 intervals sufficient lapi88 finally investigate whether error mpi estimated information within sample calculate 90 confidence intervals mifj90 investigate whether contain true mean approximately 90 time cases however 90 confidence intervals contain mpi long 90 time coldstart bias removed initmr prevents distribution mpi centered mpi long furthermore confidence intervals provide information magnitude coldstart bias confidence intervals work cases samples contained 30 intervals interval lengths long enough make coldstart bias negligible kess91 cases however failed meet 10 sampling goal samples contained much 10 trace confidence intervals also worked mpi whose expected value mpi long coldstart bias samples contain least 43 advantages disadvantages time sampling major advantage time sampling sampling technique available caches timingdependent behavior eg prefetch lockupfree krof81 shared structures across sets eg write buffers victim caching joup90 furthermore coldstart techniques time sampling applied fulltrace simulation since full trace long observation systems workload however simulations time sampling fails meet 10 sampling goal multimegabyte caches needed long intervals mitigate coldstart bias many intervals capture temporal workload variation results suggest unless researchers develop better coldstart techniques set sampling effective time sampling estimating mpi multimegabyte caches fraction full trace data10ratio estimate full trace mpi initmr estimates mult111 fraction full trace data initmr estimates mult2101 fraction full trace data10ratio estimate full trace mpi initmr estimates mult22101 fraction full trace data initmr estimates tree10figure 6a cones time sampling mult1 mult2 mult22 tree similar figure 5a figures display cones mpi mult1 mult2 mult22 tree traces fraction full trace data101ratio estimate full trace mpi initmr estimates tv101 fraction full trace data initmr estimates sor101 fraction full trace estimate full trace mpi initmr estimates lin10figure 6b cones time sampling tv sor lin similar figure 5a figures display cones mpi tv sor lin traces note lin uses different yaxis scale 5 conclusions straightforward application tracedriven simulation multimegabyte caches requires long traces strain computing resources resource demands greatly reduced using set sampling time sampling sampling estimates cache performance using information collection sets time sampling uses information collection trace intervals study first apply techniques large caches useful use billionreference traces large workloads include multiprogramming operating system references bokw90 set sampling obtained several results first calculating mpi misses per instruction sample using number instruction fetches sets much accurate using number instruction fetches sample second constructing samples sets share common index bit values works well since samples used accurately predict mpi multiple alternative caches caches hierarchies third sets behave sufficiently close normal confidence intervals meaningful accurate last important set sampling meets 10 sampling goal using 10 references trace estimates traces true mpi 10 relative error least 90 confidence results sampling include following first wood et als split effective technique reducing coldstart bias although using half references trace interval partially initialize cache often performed well second interval lengths must long mitigate coldstart bias 10 million instructions 1megabyte caches 100 million instructions 4megabyte caches 100 million instructions 16megabyte caches third important traces caches time sampling meet 10 sampling goal needed 10 trace get trace interval lengths adequately mitigated coldstart bias enough intervals sample make accurate predictions thus found traces set sampling effective time sampling estimating mpi multimegabyte caches time sampling preferred however set sampling applicable caches timedependent behavior eg prefetching structures used many sets eg write buffers experimental work results sure hold specific cases examined neverthe less expect results extend similar cache configurations usermode traces similar workloads open questions whether results apply traces dominated operating system activity radically different usermode workloads 6 acknowledgments would like thank western research laboratory digital equipment corporation especially anita borg david wall traces used study joel bartlett renato de leone jeremy dion norm jouppi bob mayo stark tremendous help providing traceable applications paul vixie colleen hawk helped store traces paul beebe systems lab able satisfy enormous computing needs mike litzkow miron livny adapted condor requirements simulations harold stone gave comments earlier version work sarita adve vikram adve garth gibson scrutinized paper 7 r cache performance operating system multiprogramming workloads blocking exploiting spatial locality trace compaction long address traces risc machines generation analysis generation analysis long address traces coldstart vs warmstart miss ratios parallel tracedriven cache simulation time partitioning computer architecture quantitative approach evaluating associativity cpu caches improving directmapped cache performance addition small fullyassociative cache prefetch buffers analysis multimegabyte secondary cpu cache memories lockupfree instruction fetchprefetch cache organization accurate lowcost methods performance evaluation cache memory systems accurate lowcost methods performance evaluation cache memory systems probability statistics engineers titan system manual performancedirected memory hierarchy design characteristics performanceoptimal multilevel cache hierarchies analysis cache replacement algorithms mache noloss trace compaction two methods efficient analysis memory address trace data cache memories efficient tracedriven simulation methods cache performance analysis design evaluation incache address translation model estimating tracesample miss ratios tr cache performance operating system multiprogramming workloads accurate lowcost methods performance evaluation cache memory systems accurate lowcost methods performance evaluation cache memory systems characteristics performanceoptimal multilevel cache hierarchies mache noloss trace compaction evaluating associativity cpu caches highperformance computer architecture 2nd ed efficient tracedriven simulation method cache performance analysis blocking exploiting spatial locality trace compaction model estimating tracesample miss ratios analysis multimegabyte secondary cpu cache memories generation analysis long address traces improving directmapped cache performance addition small fullyassociative cache prefetch buffers cache memories coldstart vs warmstart miss ratios lockupfree instruction fetchprefetch cache organization design evaluation incache address translation analysis cache replacementalgorithms performance directed memory hierarchy design ctr patrick crowley jeanloup baer use trace sampling architectural studies desktop applications acm sigmetrics performance evaluation review v27 n1 p208209 june 1999 michel dubois jaeheon jeong ashwini nanda shared cache architectures decision support systems performance evaluation v49 n14 p283298 september 2002 greg hamerly erez perelman brad calder use simpoint pick simulation points acm sigmetrics performance evaluation review v31 n4 p2530 march 2004 p foglia mangano c prete cache design high performance embedded systems journal embedded computing v1 n4 p587597 december 2005 andrew r pleszkun techniques compressing program address traces proceedings 27th annual international symposium microarchitecture p3239 november 30december 02 1994 san jose california united states lieven eeckhout koen de bosschere yet shorter warmup combining nostateloss mrrl sampled lru cache simulation journal systems software v79 n5 p645652 may 2006 lieven eeckhout smal niar koen de bosschere optimal sample length efficient cache simulation journal systems architecture euromicro journal v51 n9 p513525 september 2005 thomas conte mary ann hirsch wenmei w hwu combining trace sampling single pass methods efficient cache simulation ieee transactions computers v47 n6 p714720 june 1998 niki c thornock j kelly flanagan facilitating level three cache studies using set sampling proceedings 32nd conference winter simulation december 1013 2000 orlando florida luk van ertvelde filip hellebaut lieven eeckhout koen de bosschere nslblrl efficient cachewarmup sampled processor simulation proceedings 39th annual symposium simulation p168177 april 0206 2006 uri lublin dror g feitelson workload parallel supercomputers modeling characteristics rigid jobs journal parallel distributed computing v63 n11 p11051122 november yue luo lizy k john lieven eeckhout sma selfmonitored adaptive cache warmup scheme microprocessor simulation international journal parallel programming v33 n5 p561581 october 2005 rong xu zhiyuan li samplebased cache mapping scheme acm sigplan notices v40 n7 july 2005 aditya toomula jaspal subhlok replicating memory behavior performance prediction proceedings 7th workshop workshop languages compilers runtime support scalable systems p18 october 2223 2004 houston texas humayun khalid validating tracedriven microarchitectural simulations ieee micro v20 n6 p7682 november 2000 lieven eeckhout koen de bosschere efficient simulation trace samples parallel machines parallel computing v30 n3 p317335 march 2004 roland e wunderlich thomas f wenisch babak falsafi james c hoe statistical sampling microarchitecture simulation acm transactions modeling computer simulation tomacs v16 n3 p197224 july 2006 fast datalocality profiling native execution acm sigmetrics performance evaluation review v33 n1 june 2005 changkyu kim doug burger stephen w keckler adaptive nonuniform cache structure wiredelay dominated onchip caches acm sigplan notices v37 n10 october 2002 j l peterson p j bohrer l chen e n elnozahy gheith r h jewell kistler r maeurer malone b murrell n needel k rajamani rinaldi r simpson k sudeep l zhang application fullsystem simulation exploratory system design development ibm journal research development v50 n23 p321332 march 2006