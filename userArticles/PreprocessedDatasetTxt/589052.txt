convergence theory trustregionbased algorithms equalityconstrained optimization recent paper dennis elalem maciel proved global convergence stationary point general trustregionbased algorithm equalityconstrained optimization general algorithm based appropriate choices trustregion subproblems seems particularly suitable large problemsthis paper shows global convergence point satisfying secondorder necessary optimality conditions general trustregionbased algorithm results given seen generalization convergence results trustregions methods unconstrained optimization obtained mor sorensen behavior trust radius local rate convergence analyzed interesting facts concerning trustregion subproblem linearized constraints quasinormal component step hard case presentedit shown results applied class discretized optimal control problems b introduction trustregion algorithms proved efficient robust techniques solve unconstrained optimization problems excellent survey area 22 classical references convergence results carter 3 sorensen 23 powell 26 shultz schnabel byrd 29 standard techniques handle trustregion subproblems dogleg algorithm powell 25 conjugate gradients steihaug 32 toint 33 newtonlike methods computation locally constrained optimal steps gay 15 sorensen 23 sorensen 30 see also book dennis schnabel 9 recent new algorithms compute locally constrained optimal step words step satisfies fraction optimal decrease trustregion subproblem promising large problems proposed rendl wolkowicz 28 sorensen 31 since mid eighties significant effort made address equality constrained optimization problem references celis dennis tapia 4 vardi 34 see also elhallabi 14 byrd schnabel shultz 2 powell yuan 27 elalem 13 fundamental questions associated application trustregion algorithms equalityconstrained optimization decomposition step choice trustregion subproblems choice merit function first stages research conducted area clear answer questions properly however examine carefully recent department computational applied mathematics rice university houston texas 77005 usa email dennisriceedu support author provided doe contract doefg0393er25178 nsf cooperative agreement ccr9120008 afosr contract f49620 9310212 departamento de matematica universidade de coimbra 3000 coimbra portugal work developed author graduate student department computational applied mathematics rice university email lvicentematucpt support author provided invotan nato scholarship ccla fulbright scholarship flad nsf cooperative agreement ccr9120008 references byrd omojokon 24 dennis elalem maciel 7 elalem 12 13 lalee nocedal plantenga 21 observe decomposition step normal quasinormal tangential components trustregion subproblems trustregion subproblem linearized constraints trustregion subproblem lagrangian reduced tangent subspace explained great detail section 2 paper unconstrained case conditions component satisfy way computed might course differ algorithm algorithm see also recent references merit function used either 2 penalty function without constraint term squared cases 21 24 augmented lagrangian function consider equalityconstrained optimization eco problem minimize fx subject n functions f c assumed least twice continuously differentiable domain interest 7 dennis elalem maciel considered general trustregionbased algorithm solution eco problem 11 general algorithm much like algorithm proposed byrd omojokon 24 1 mentioned step decomposed n quasinormal component step associated trustregion subproblem linearized constraints tangential component associated trustregion subproblem lagrangian reduced tangent subspace component step required satisfy fraction cauchy decrease corresponding trustregion subproblem another key feature general algorithm choice augmented lagrangian merit function use elalems scheme 11 update penalty parameter appropriate assumptions shown exists subsequence iterates driving zero norm residual constraints norm gradient lagrangian reduced tangent subspace see 7section 8 important remark global convergence result obtained mild conditions components step multipliers estimates hessian approximations thus dennis elalem maciel 7 result similar global result given powell 26 unconstrained optimization one purposes paper show global convergence point satisfying secondorder necessary optimality conditions class algorithms result similar results established sorensen 23 30 trustregion algorithms unconstrained optimization accomplish imposing fraction optimal decrease tangential component step using exact secondorder information imposing conditions quasi normal component n lagrange multipliers 1 thesis 24 directed professor r h byrd trustregion algorithm proposed usually referred byrd omojokon algorithm 2 byrd schnabel shultz proposed trustregion algorithm equalityconstrained optimization established global convergence point satisfying secondorder necessary optimality conditions however algorithm belong class trustregion algorithms considered result obtained use exact normal component leastsquares multipliers update require paper differences use 1 penalty function merit function analysis carried using orthogonal nullspace basis recent papers coleman yuan 6 elalem 12 proposed trustregion algorithms prove global convergence points satisfying firstorder secondorder necessary optimality conditions algorithms use exact normal component orthogonal nullspace basis leastsquares multipliers update conditions need impose assure limit point sequence iterates satisfies secondorder necessary optimality conditions k quasinormal component step k k trustregion radius case kcx k k small compared first condition implies increase quadratic model lagrangian x k x k n k offi 2 see relevant recall fraction optimal decrease imposed tangential component k yielding decrease offi 2 quadratic model second condition needed reasons appears definition predicted decrease show conditions satisfied either exact normal component leastsquares multipliers used ii reasonable choices quasinormal component multipliers made class discretized optimal control problems former result agreement result obtained elalem 12 gill murray wright 17 elalem 10 considered analyses k latter work assumption used prove local convergence results former establish properties augmented lagrangian merit function point assumption implies r x x k since k offi k assume n k okcx k k also prove algorithm converges point reduced hessian positive definite penalty parameter ae k uniformly bounded trustregion radius ffi k uniformly bounded away zero desired property trustregion algorithm case particular choices multipliers components n lead us qquadratic rate convergence x detailed treatment global convergence theory given vicente 35 structure trustregion subproblem linearized constraints exploited obtain interesting results introduce quasinormal component satisfies fraction optimal decrease trustregion subproblem linearized constraints show exact normal component shares property also prove algorithm well behaved instance trust radius uniformly bounded away zero subproblem natural tendency fall socalled hard case review notation used paper lagrangian function associated eco problem 11 defined x lagrange multiplier vector matrix rcx given rc x represents gradient function c x let hessian matrices fx c x respectively use subscripted indices represent evaluation function particular point sequences fx k g f k g instance f k represents fx k k vector matrix norms used 2 norms l represents identity matrix order l finally 1 denotes smallest eigenvalue symmetric matrix structure paper follows section 2 introduce trustregion subproblems outline general trustregion algorithm general assumptions section 3 present global convergence theory class discretized optimal control problems introduced section 4 justification general form algorithms theory sections 5 6 analyze respectively behavior trust radius local rates convergence trustregion subproblem linearized constraints studied section 7 end paper summary conclusions 2 algorithm general assumptions trustregion algorithm analyzed dennis elalem maciel 7 solution eco problem 11 consists computing iteration k step k decomposed components n k required satisfy given conditions step k accepted algorithm continues setting x k1 x step rejected x 21 decomposition step suppose kc k k 6 0 component k called quasinormal quasivertical component k required satisfy fraction cauchy decrease trustregion subproblem linearized constraints defined subject ks n k r 2 0 1 ffi k trust radius words n k satisfy k socalled cauchy point trustregion subproblem ie c n k optimal solution subject c n 2 spanfgammarc k c k therefore component n k also required satisfy condition ks n 1 positive constant independent iterate k algorithm condition saying close feasibility quasinormal component small paper require quasinormal component n k also satisfy 2 positive constant independent iterates important consequence condition kc k k small compared ffi k increase quadratic model lagrangian along quasinormal component n k offi 2 two choices n k given sections 41 42 satisfy conditions 21 22 23 choices suggested 7 20 component k tangential horizontal component must satisfy ie must lie null space n rc k rc k let w k n theta n gamma matrix whose columns form basis n rc quadratic model approximation r 2 since 2 n rc k exists 2 ir ngammam consider also given kg k k 6 0 k required satisfy fraction cauchy decrease trustregion subproblem minimize subject ks n note standard trustregion subproblem n k might orthogonal n rc might center trust region steepestdescent direction associated 2 norm gamma g k take account scaling matrix w k steepestdescent direction kw k delta k norm given gammaw k consider steepestdescent direction gamma g k ks n require k satisfy oe 0 k cauchy point 2 norm given ks n equivalent saying max maximum step length along n allowed inside trust region defined ffi k easy verify results given paper hold also c k defined along gammaw provided sequence fkw valid also coupled trustregion constraint ks n decoupled ks k ffi k latter case parameter r defining quasinormal component n k positive value step k satisfies requirement computed using powells dogleg algorithm 25 conjugategradient algorithm adapted trust regions steihaug 32 toint 33 see also 7 8 21 order establish global convergence point satisfying secondorder necessary optimality conditions need k satisfy fraction optimal decrease following trustregion subproblem minimize subject kw k words require k satisfy following conditions k optimal solution trustregion subproblem 25 accomplished applying gqtpar routine sorensen 23 using algorithms recently proposed rendl wolkowicz 28 sorensen 31 k satisfies fraction optimal decrease trustregion subproblem 25 ks k k ks n k required satisfy fraction cauchy decrease ks k ks n combine cases write ks ks n also important note definition assures fraction optimal decrease 26 implies fraction cauchy decrease 24 provided 22 general trustregion algorithm introduce merit function corresponding actual predicted decreases merit function used augmented lagrangian ae penalty parameter actual decrease areds k ae k iteration k given predicted decrease see 7 following preds update penalty parameter ae k use scheme proposed elalem 11 lagrange multipliers k required satisfy 3 positive constant independent k condition necessary global convergence stationary point general trustregion algorithm given algorithm 21 general trustregion algorithm r ae 0 r 2 0 1 21 kc given 210 stop algorithm use x k solution eco problem 11 22 set n satisfying 21 22 23 ks n kw satisfying 26 k 23 compute k1 satisfying 28 24 compute preds preds set ae otherwise set ae 25 areds k ae k preds k ae k ks k k reject k otherwise accept k choose ffi k1 26 k rejected set x otherwise set x important understand role ffi min reset ffi k step k accepted course finding step trust radius decreased ffi min knowledge zhang kim lasdon 37 first suggest modification remark rules update trust radius previous algorithm much complicated given suffice prove convergence results understand trustregion mechanism direct consequence way penalty parameter updated following result lemma 21 sequence fae k g satisfies ae k ae preds order establish global convergence results use general assumptions given 7 assumptions a1a4 however global convergence point satisfies secondorder necessary optimality conditions also need assumption a5 assume iterations k x k x omegagamma omega open subset ir n general assumptions a1 functions f c twice continuously differentiable omegagamma a2 gradient matrix rcx full column rank x 2 omegagamma a3 functions f rf r bounded omegagamma matrix rcx rcx gamma1 uniformly bounded omegagamma a4 sequences fw k g fh k g f k g bounded a5 hessian approximation h k exact ie h lipschitz continuous omegagamma assumptions a3 a4 equivalent existence positive constants 9 jfxj 0 krfxk 1 kr 2 fxk 2 kcxk 3 23 predicted decrease along tangential component consider trustregion subproblem 25 use general assumptions structure subproblem obtain lower bound predicted decrease along tangential component step follows karushkuhntucker conditions exists fl k 0 positive semidefinite 0 turns conditions also sufficient k solve trustregion subproblem 25 see gay 15 sorensen 30 consequence hence 3 global convergence dennis elalem maciel 7 proved assumptions a1a4 conditions 21 22 24 lim inf 0 section assume k satisfies fraction optimal decrease 26 trustregion subproblem 25 well conditions 23 28 a5 respectively show 31 extended 0 proof 32 although simpler structure proof given 7 prove result contradiction supposition k start analyzing fraction cauchy optimal decrease conditions lemma 31 let general assumptions hold moreover since k satisfies fraction optimal decrease trustregion subproblem 25 positive constants independent iterate k proof conditions 34 35 application powells result see 26 theorem 4 22 lemma 48 followed general assumptions condition 36 restatement 211 following inequality needed forthcoming lemmas lemma 32 general assumptions hold positive constant independent k proof term q k k bounded using 22 23 assumption a4 following way ks n hand follows 28 krc combine two bounds get 37 following technical lemma gives us upper bounds difference actual decrease predicted decrease proof follows similar arguments proof lemma 63 11 lemma 33 let general assumptions hold exist positive constants independent k ks k k 3 ks k ae k 3 ks k k 3 ks k k 2 ks k ae k 6 ks k k 3 ks k k 2 proof add subtract x 1 1 using taylor expansion write 1 expand c general assumptions give us estimate 38 positive constants inequality 39 follows 38 ae k 1 following three lemmas bound predicted decrease correspond respectively lemmas 76 77 78 given 7 lemma 34 let general assumptions hold predicted decrease merit function satisfies preds 3 also preds ae 0 proof two conditions 310 311 follow direct application 37 two different lower bounds 35 36 q k n lemma 35 let general assumptions hold assume kw ff min ae ffl tol min ae 7 ffl tol oe 9 ffl tol oe predicted decrease merit function satisfies either preds preds ae 0 proof kw first bound ff given 312 get thus either kw us first assume kw ffl tol follows second bound ff given 312 using 310 third bound ff given 312 obtain preds suppose establish 314 combine 311 last bound ff given 312 get preds set ae ae kgamma1 lemma 35 conclude kw ffl tol kc k k ffffi k penalty parameter current iterate need increased see step 24 algorithm 21 proof next lemma follows argument given proof lemma 35 show either kg k k 1ffl tol fl k 1ffl tol holds lemma 36 let general assumptions hold assume kw 312 exists constant preds proof lemma 35 know either 313 314 holds set first case use kg preds second case use preds hence 315 holds ae 6 ffl tol min ae 7 ffl tol oe 9 ffl toloe next prove supposition 33 penalty parameter ae k bounded lemma 37 let general assumptions hold kw k ae k ae ae depend k thus fae k g fl k g bounded sequences proof ae k increased iteration k updated according rule ae write ae ki applying 34 left hand side 35 37 right hand side obtain aei ae k increased iteration k lemma 35 certainly know kc k k use fact establish proved fae k g bounded general assumptions conclude fl k g also bounded prove also supposition 33 trust radius bounded away zero lemma 38 let general assumptions hold kw k depend k proof kgamma1 acceptable step ffi k ffi min ks consider cases kc 312 cases use fact areds preds case kc lemma 36 inequality 315 holds thus use ks areds preds ks thus ks case ii kc case 29 34 preds rg use ae time last two lower bounds preds preds ks ae ks ae ks hence ks result follows setting ffi g next result needed also forthcoming theorem 31 lemma 39 let general assumptions hold kw k acceptable step always found finitely many trial steps proof let us prove assertion contradiction assume given k k means lim k1 steps rejected iteration k see steps 25 26 algorithm 21 consider cases appeal arguments similar used lemma 38 conclude case preds 15 positive constant independent iterates since assuming lim k1 areds k ae k preds k ae k 1 contradicts rules update trust radius see step 25 algorithm 21 finally state first asymptotic result theorem 31 general assumptions sequence iterates fx k g generated algorithm 21 satisfies lim inf 0 proof suppose exists ffl tol 0 kw k iteration k either kc k k ffffi k kc k k ffffi k ff satisfies 312 first case appeal lemmas 36 38 obtain preds ae k 1 29 34 lemma 38 preds hence exists positive constant 16 depending k preds k lemma 39 ignore rejected steps work successful iterates without loss generality let k go infinity contradicts boundedness fl k g result state global convergence result existence limit point sequence iterates generated algorithm satisfying secondorder necessary optimality conditions result generalizes obtained unconstrained optimization sorensen 30 sorensen 23 theorem 32 let general assumptions hold assume w x x continuous functions fx k g bounded sequence generated algorithm 21 exists limit point x positive semidefinite n rcx moreover x r x x x satisfies secondorder necessary optimality conditions proof let fk g index subsequence considered 316 since fx k g bounded subsequence fx k j g converges point x lim 0 continuity cx get cx use continuity w x rfx obtain since 1 delta continuous function use 210 lim j1 continuity w x x second derivatives fx c x obtain 0 shows r 2 positive semidefinite n rcx continuity orthogonal null space basis discussed 1 5 16 class nonorthogonal null space basis described section 41 equation r x x x consistent updates lagrange multipliers like leastsquares update 47 adjoint update 43 4 examples 41 class discretized optimal control problems introduce important class eco problems find convenient matrices w k quasi normal components n k multipliers k satisfying requirements needed analysis numerical solution many discretized optimal control problems involves solving eco problem subject cy see 8 19 20 variables state variables variables u control variables applications include parameter identification inverse flow problems design optimization many situations bounds control variables considered another interesting aspect problems rcx partitioned c x square matrix order class problems following assumption traditionally made partial jacobian c x nonsingular inverse uniformly bounded omegagamma consequence columns gammac ngammam form basis null space rcx usual choice k problems socalled adjoint multipliers follows directly continuity rcx uniformly boundedness continuously x furthermore continuous function x bounded derivatives using structure problem define quasinormal component n see references 8 19 20 kcy see section 7 quasinormal component 44 satisfies fraction optimal decrease hence fraction cauchy decrease trustregion subproblem linearized constraints choices quasinormal components given 20 quasi normal components form lemma 41 n verifies 45 k given 43 conditions 23 28 satisfied proof 43 45 see r condition 23 trivially satisfied condition 28 follows existence bounded derivatives 42 normal component leastsquares multipliers consider general eco problem 11 component n k step k orthogonal null space rc k multiple rc k rc also require n lies inside trust region radius rffi k given quasinormal component n k step given 46 called normal see section 7 normal component 46 satisfies fraction optimal decrease hence fraction cauchy decrease trustregion subproblem linearized constraints lemma 42 quasinormal component 46 leastsquares update satisfy conditions 23 28 proof easily confirmed r x condition 28 holds since bounded derivatives omegagamma 5 behavior trust radius sections 5 6 longer need consider tangential component k satisfies fraction optimal decrease trustregion subproblem 25 suffices assume fraction cauchy decrease condition 24 assume component n k satisfies conditions 21 22 need strengthen conditions 23 28 following way ks k k ks k k ks n ks k k 3 0 4 positive constants independent iterates choices n k k suggested section 4 satisfy requirements well see lemmas 41 42 first two conditions obvious normal component 46 satisfy 53 quasinormal component 44 also satisfies 53 see 35lemma 561 next theorems show lim k1 x positive definite n rcx penalty parameter ae k uniformly bounded trust radius ffi k uniformly bounded away zero theorem 51 let general assumptions hold w x x continu ous fx k g converges x r 2 positive definite n rcx fae k g bounded sequence proof first since r 2 positive definite n rcx continuous functions x exists neighborhood n x x fl 0 x n x xx x xw x fl since ks thus k x k 2 n x flks ks implies ks using 35 54 k x k 2 n x 17 ks 1r g let kc k k ff 0 ks k k positive constant ff 0 defined later using similar arguments lemma 32 follows 22 51 52 kc k k ff 0 ks k k assumption a4 ks k k 3 22 kc k k ff 0 ks k k also get ks ks n ks 2ks n ks together 55 56 implies preds ks ks ks k k ae 0 need impose following condition ff set ae ae kgamma1 57 conclude penalty parameter need increased kc k k ff 0 ks k k see step 24 algorithm 21 hence ae k increased kc ks k k holds using 5153 obtain ks k k 00 3 recall proof lemma 37 ae k increased ae r ks k k oe ae 4 ks k k kc k k turn implies ae r ae k 00 ae 4 completes proof theorem theorem 52 let general assumptions hold w x x continu ous fx k g converges x r 2 positive definite n rcx ffi k uniformly bounded away zero eventually iterations successful proof proof theorem based boundedness fae k g consider cases kc ks k k kc k k ff 0 ks k k ff 0 satisfies 58 ks k k 27 29 34 find preds ks g case follows 39 510 ae k 1 preds ks suppose kc k k ff 0 ks k k 57 preds ks k use 39 ae k ae get preds ks follows theorem 84 7 lim inf 0 result continuity cx convergence fx k g obtain finally 511 512 limits lim k1 x finally get lim preds rules updating trust radius step 25 algorithm 21 shows ffi k uniformly bounded away zero 6 local rate convergence order obtain qquadratic local rates convergence require reduced tangential component k satisfy 24 following h k positive definite k 61 discretized optimal control formulation consider problem 41 assume problem structure described section 41 use theorem 52 obtain local rate convergence theorem 61 suppose eco problem form 41 let general assumptions assumption 42 hold assume fx k g converges x addition let k k given 61 44 43 r 2 xx x positive definite n rcx x k converges qquadratically x proof shown appealing theorem 84 7 r x x follows theorem 52 ffi k uniformly bounded away zero thus exists positive integer k k k gammac rate convergence follows 19 62 normal component leastsquares multipliers consider general eco problem 11 suppose quasinormal component normal component 46 k given 47 use theorem 52 obtain desired local rate convergence assumed orthogonal nullspace basis continuous function x theorem 62 let general assumptions hold assume fx k g converges x addition let k k given 61 46 47 r 2 xx x positive definite n rcx x k converges qquadratically x proof shown appealing theorem 84 7 r x x follows theorem 52 ffi k uniformly bounded away zero thus exists positive integer k k k qquadratic rate convergence follows 18 36 7 trustregion subproblem linearized constraints section investigate aspects trustregion subproblem linearized constraints subject ks n k first prove normal component 46 quasinormal component always give fraction optimal decrease trustregion subproblem theorem 71 let general assumptions hold normal component 46 satisfies fraction optimal decrease trustregion subproblem linearized constraints ie exists positive constant fi n 1 k optimal solution 71 ii addition assume assumption 42 quasinormal component 44 satisfies fraction optimal decrease 72 proof krc k rc solves 71 result holds positive value fi n 1 0 1 case since krc k rc also ks ks ks since krc k rc ks k combining last inequality 73 get completes proof ii kc solves 71 72 holds positive value fi n 1 case uniform bound kc rest proof follows consequence theorem immediately normal component 46 quasinormal component 44 give fraction cauchy decrease trustregion subproblem linearized constraints compute step n k gives fraction optimal decrease trustregion subproblem linearized constraints also use techniques proposed 23 28 31 next theorem show trustregion subproblem 71 due particular structure tends fall hard case latest stages algorithm result relevant opinion since algorithms proposed 23 28 31 deal hard case trustregion subproblem 71 rewritten subject ks n k matrix rc k rc k always positive semidefinite general assump tions rank let e k 0 denote eigenspace associated eigenvalue 0g hard case defined two following conditions v k b krc k rc theorem 72 general assumptions lim k1 exists k h k k h trustregion subproblem 75 falls hard case defined b proof first show holds every iteration algorithm v k 2 multiplying sides rc k gives us thus v k prove exists k h b holds every k k h since monotone strictly decreasing function lim equivalent g k rffi k 0 also singular value decomposition rc k obtain lim hence holds 0 krc k rc since lim k1 exists k h kc k completes proof theorem complete section following corollary corollary 71 general assumptions lim k1 kc k trust radius uniformly bounded away zero exists k h k k h trustregion subproblem 75 falls hard case defined b proof lim k1 kc k trust radius uniformly bounded away zero lim k1 theorem 72 applied 8 concluding remarks theorems 31 32 established global convergence point satisfying secondorder necessary optimality conditions general trustregionbased algorithm considered paper theorem 52 proved trust radius sufficient secondorder optimality conditions bounded away zero help result analyzed local rates convergence different choices steps multipliers believe results complement theory developed dennis elalem maciel 7 proves global convergence stationary point also given detailed analysis trustregion subproblem linearized constraints acknowledgments thank mahmoud elalem many discussions contents paper also grateful referees careful insightful reading paper r continuity null space basis constrained optimiza tion trust region algorithm nonlinearly constrained optimization global convergence trust region algorithms using inexact gradient information trust region strategy nonlinear equality constrained optimization note computation orthonormal basis null space matrix new trust region algorithm equality constrained optimiza tion global convergence theory general trustregionbased algorithms equality constrained optimization numerical methods unconstrained optimization nonlinear equations global gonvergence theory class trust region algorithms constrained optimization global convergence theory arbitrary norm trustregion algorithms equality constrained optimization computing optimal locally constrained steps properties representation basis null space theoretical properties augmented lagrangian merit function newtons method constrained optimization projected sequential quadratic programming methods analysis inexact trustregion interiorpoint sqp algorithms implementation algorithm largescale equality constrained optimization trust region algorithms optimization nonlinear equality inequality constraints new algorithm unconstrained optimization trust region algorithm equality constrained optimization semidefinite framework trust region subproblems applications large scale minimization family trustregionbased algorithms unconstrained minimization strong global convergence properties newtons method model trust region modification conjugate gradient method trust regions large scale optimization towards efficient sparsity exploiting newton method minimization trust region algorithm equality constrained minimization convergence properties implementation numerical methods nonlinearly constrained optimization improved successive linear programming algorithm tr ctr zhensheng yu changyu wang jiguo yu combining trust region linesearch algorithm equality constrained optimization journal computational applied mathematics v14 n12 p123136 1 january 1986 detong zhu nonmonotonic backtracking trust region interior point algorithm linear constrained optimization journal computational applied mathematics v155 n2 p285305 15 june