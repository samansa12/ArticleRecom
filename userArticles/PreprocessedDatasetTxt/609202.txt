combining program data specialization program data specialization always studied separately although aimed processing early computations program specialization encodes result early computations new programsemi data specialization encodes result early computations data structuresin paper present extension tempo specializer performs program data specialization show two strategies integrated single specializer new kind specializer provides programmer complementary strategies widen scope specialization illustrate benefits limitations strategies combination variety programs b introduction program data specialization aimed performing computations depend early values however dioeer way result early computations encoded one hand program specialization encodes results residual program hand data specialization encodes results data structures precisely program specialization performs computation relies early data inserts textual representation result residual program surrounded computations depending late values essence new program constructed early computations encoded furthermore new program constructed pruned residual program corresponds control aeow could resolved given available data consequence program specialization optimizes control aeow since fewer control decisions need taken however requires new program constructed program specialization lead code explosion size specialization values large example situation occur loop needs unrolled number iterations high code explosion cause code size problems also degrades execution time specialized program dramatically instruction cache misses dual notion specializing programs specializing data strategy consists splitting execution program two phases rst phase called loader performs early computations stores results data structure called cache instead generating program contains textual representation values data specialization generates program perform second phase consists late computations parameterized respect result early computations cache corresponding program named reader reader parameterized respect cache shared specializations strategy fundamentally contrasts program specialization decouples result early computations program exploits consequence size specialization problem increases cache parameter increases program practice data specialization handle problem sizes far beyond reach program specialization thus opens new opportunities demonstrated knoblock ruf graphics applications 7 4 however data specialization denition optimize control aeow limited performing early computations expensive enough worth caching reader valid cache passed early control decision leading costly early computation needs part loader well reader loader decides whether costly computation much cached reader control decision determines whether cache needs looked fact data specialization apply programs whose bottlenecks limited control decisions typical example situation interpreters lowlevel languages instruction dispatch main target specialization programs data specialization completely ineoeective perhaps apparent dioeerence nature opportunities addressed program data specialization led researchers study strategies isolation consequence attempt ever made integrate strategies specializer exist experimental data assess benets limitations specialization strategies paper study relationship program data specialization respect underlying concepts implementation techniques applicability precisely study program data specialization applied separately well combined section 2 furthermore describe specializer integrate program data specialization components common strategies components dioeer practice achieved integration extending program special izer named tempo phases needed perform data specialization section 3 finally assess benets limitations program data specialization based experimental data collected specializing variety programs exposing various features section 4 2 concepts program data specialization section basic concepts program data specialization presented limitations strategy identied illustrated example finally combination program data specialization introduced 21 program specialization partial evaluation community mainly focusing specialization programs given inputs program partial evaluation generates residual program encodes result early computations depend known inputs although program specialization successfully used variety applications eg operating systems 10 11 scientic programs 8 12 compiler generation 2 6 shown limitations one fundamental limitations code explosion occurs size specialization problem large let us illustrate limitation using procedure displayed lefthand side figure 1 example stat considered static whereas dyn dynamic static constructs printed boldface assuming specialization process unrolls loop variable becomes static thus gi procedures ie g1 g2 g3 fully evaluated even gi procedures correspond nonexpensive computations program specialization still optimizes procedure f simplies control aeow loop one conditionals eliminated possible specialization procedure f presented righthand side figure 1 however beyond number iterations unrolling loop computations enables pay size resulting specialized program number depends processor features fact shown later specialized program even get slower unspecialized program larger size residual loop body earlier phenomenon happens void f int stat int dyn int void f1int dyn int int j edyn dj source program b specialized program figure 1 program specialization domains like graphics scientic computing applications beyond reach program specialization specialization opportunities rely large data iteration bounds would cause code explosion loops traversing data unrolled situation data specialization may apply 22 data specialization late eighties alternative program specialization called data specialization introduced barzdins bulyonkov 1 explored malmkjr 9 later knoblock ruf studied data specialization subset c applied graphics application 7 data specialization aimed encoding results early computations data structures residual program execution program divided two stages loader rst executes early computations saves result cache reader performs remaining computations using result early computations contained cache let us illustrate process example displayed figure 2 lefthand side gure procedure f repeatedly invoked loop rst argument c vary thus considered second argument loop index k varies iteration procedure f also passed dioeerent vector iteration assumed late procedure called repeatedly rst argument data specialization used perform computations depend context many computations performed namely loop test estat invocation gi procedures course caching expression assumes execution cost exceeds cost cache reference measurements shown caching expressions simple eg variable occurrence simple comparisons actually cause resulting program slow example let us assume like loop test cost expression estat expensive enough cached however gi procedures assumed consist expensive computations invocations need examined potential candidate caching since rst conditional test estat early put loader whenever evaluates true invocation procedure g1 cached similarly reader cache looked conditional test evaluates true however invocation procedure g2 cannot cached according knoblock rufs strategy since dynamic control thus caching result would amount performing speculative evaluation 7 finally invocation procedure g3 needs cached since unconditionally executed argument early resulting loader reader procedure f presented righthand side figure 2 well invocations extern int wnm extern int wnm struct datacache int val1 int val3 cachemax fload c cache f c k wk fread c k wk cache void fload statcache int stat void f int stat int dyn int struct datacache cache int j int j edyn dj int stat dyn struct datacache cache int j edyn dj source program b specialized program figure 2 data specialization study limitations data specialization consider program computations cached expensive enough amortize cost memory reference example assume gi procedures correspond computations control aeow procedure f remains target specialization 23 combining program data specialization shown benets limitations program data specialization main parameters determine strategy ts specialization opportunities cost early computations size specialization problem obviously within program even procedure fragments may require program specialization others data specialization simple example consider procedure consists two nested loops innermost loop may require iterations thus allow program specialization applied whereas outermost loop may iterate vector whose size large may prevent program specialization applied data specialization exploiting opportunities concretely performing program data specialization done simple way one approach consists data specialization rst applying program specializer either loader reader idea code explosion may issue one components result program specialization optimize loader reader simplifying control aeow performing speculative specialization example reader may consist loop whose body small situation may thus allow loop unrolled without causing residual program large applying program specializer reader loader may possible fragments program may cause code explosion made dynamic alternatively program specialization performed prior data specialization combination requires program specialization applied selectively fragments cause code explosion specialized fragments ooeering specialization opportunities processed data specialization shown section 4 practice combining program data specialization allows better performance pure data specialization prevents performance gain dropping quickly case program specialization problem size increases integrating program data specialization present tempo extended perform data specialization let us brieaey describe features relevant data specialization experiments presented next section 31 tempo ooeline program specializer c programs specialization preceded preprocessing phase phase aimed computing information guide specialization process main analyses tempos preprocessing phase alias analysis sideeoeect analyses bindingtime analysis action analysis rst two analyses needed imperative nature c language whereas bindingtime analysis typical ooeline specializer action analysis unusual computes specialization actions ie program transformations performed specialization phase output preprocessing phase program annotated specialization actions given specialization values annotated program used specialization phase produce residual program compile time traditionally done partial evaluators addition tempo specialize program run time tempos runtime specializer based templates eoeciently compiled standard c compilers 3 12 tempo successfully used variety applications ranging operating systems 10 11 scientic programs 8 12 32 extending tempo data specialization tempo includes bindingtime analysis propagates binding times forward backward forward analysis aims determining static computations propagates binding times denitions uses variables backward analysis performs propagation opposite direction uses variable static dynamic denition annotated staticdynamic annotation indicates denition evaluated specialization time run time process introduced hornof et al allows bindingtime analysis accurate analysis said use sensitive 5 denition staticdynamic occurs control construct eg control construct becomes staticdynamic well specialized program code constructs expressions annoted static evaluated specialization time result introduced residual code constructs expressions annoted dynamic staticdynamic rebuilt residual code perform data specialization analysis inserted forward analysis backward analysis essence new phase identies frontier terms static terms occurring dynamic staticdynamic context cost frontier term given threshold dened parameter data specializer forced dynamic staticdynamic furthermore data specialization perform speculative evaluation static computations dynamic control made dynamic adjustments done backward phase bindingtime analysis determines nal binding times program later process static computations included loader dynamic computations reader frontier terms cached rest data specializer knoblock rufs performance evaluation section compare performance obtained applying dioeerent specialization strategies set programs set includes several scientic programs system program 41 overview machine compiler measurements presented paper obtained using sun model 170 448 mega bytes main memory running sunos version 551 times measured using unix system call getrusage include iuserj isystemj times figure 3 displays speedups size increases compiled code obtained dioeerent specialization strategies benchmark give program invariant used specialization approximation time complexity code sources included appendices programs compiled gcc o2 higher degrees optimization make dioeerence programs used experiment specialization strategies evaluate performance dioeerent specialization meth ods speedup ratio execution times specialized program original one size increases ratio size specialized program original one data displayed figure 3 correspond behavior following specialization strategies ffl psct program program specialized compile time ffl psrt program program specialized run time ffl ds program data specialized psct program data specialized program specialized compile time loops manipulate cache data specialization kept dynamic avoid code explosion psrt program data specialized program specialized run time previous strategy loops manipulate cache kept dynamic avoid code explosion source programs consider variety source programs onedimensional fast fourier transformation fft chebyshev approximation romberg integration smirnov integration cubic spline interpolation berkeley packet lter bpf given specialization strategies available programs classied follows control aeow intensive program mainly exposes control aeow computations data aeow computations inexpensive case program specialization improve performance whereas data specialization expensive calculations cache data aeow intensive program based expensive data aeow computations result program specialization compile time well data specialization improve performance program control data aeow intensive program contains control aeow computations expensive data aeow computations program good candidate program specialization compile time applied small values wellsuited data specialization applied large values analyze performance specialization methods turn benchmark programs 42 results data specialization executed compile time run time run time loader cache executed execution specialized program compile time cache constructed compilation cache used specialized program execution programs data specialization yields greater speedup program specialization run time combination two specialization strategies make better result section characterize dioeerent opportunities specialization illustrate method three categories program 421 program specialization analyze two programs performance better program specialization berkeley packet lter bpf interprets packet respect interpreter program cubic spline interpolation approximates function using third degree polynomial equation characteristics bpf program consists exclusively conditionals whose tests branches contain inexpensive expressions cubic spline interpolation program consists small loops whose small body evaluated part concretely program mainly depends control aeow graph whose leaves contain calculations partially reducible good candidate program specialization program specialization control aeow graph reduced calculations eliminated since static calculation expensive enough eoeciently cached data specialization specialized program mostly original one kind programs program specialization gives signicant improvements reduces control aeow graph produces small specialized program applications bpf appendix f specialized respect program size n mainly consists conditionals time complexity linear size program contain expensive data computations program contain loop size specialized program mostly original one figure 3f program specialization compile time run time yields good speedup whereas data specialization improves performance marginally combination program data specialization improve performance cubic spline interpolation appendix e specialized respect number points n xcoordinates contains three singly nested loops time complexity rst two loops half computations body completely evaluated cached specialization including real multiplications divisions nevertheless expensive calculation cache data specialization improve performance signicantly unrolled loop really increase code size small complexity program small body loop consequence number points n figure 3 program data combined specializations speedup specialization barely changes figure 3e program specialization compile time produces good speedup whereas program specialization run time improve performance data specialization obtains minor speedup cached calculations expensive 422 program specialization data specialization analyze two programs performance identical program specialization data specialization polynomial chebyshev approximates continuous function known interval smirnov integration approximates integral function interval using estimations characteristics two programs contain loops expensive calculations doubly nested loops cubic spline interpolation section 421 half computations body loop completely evaluated cached specialization contrast cubic spline interpolation static calculations chebyshev smirnov expensive allow data specialization yield major improvements combined specialization data specialization applied innermost loop program specialization applied rest program kind programs program data specialization give signicant improvements however speedup code size program produced program specialization hundred times larger specialized program using data specialization applications chebyshev approximation appendix c specialized respect degree n generated polynomial program contains two calls trigonometric function cos one singly nested loop call doubly nested loop since program mainly consists data aeow computations program specialization data specialization obtain similar speedups see figure 3c smirnov integration appendix specialized respect number iterations n program contains call function fabs returns absolute value parameter function contained doubly nested loop time complexity program om n case chebyshev program data specialization produce similar speedups see figure 3d 423 combining program specialization data specialization finally analyze two programs performance improves using program specialization values small data specialization values large fft romberg tegration fft converts data time domain frequency domain romberg integration approximates integral function interval using estimations characteristics two programs contain several loops expensive data aeow computations doubly nested loops however half computations loop body cannot evaluated beyond number iterations program specialization unrolls loops increases code size specialized program degrades performance specialized program becomes slower code size furthermore beyond problem size specialization process cannot produce program size contrast data specialization caches expensive calculations unroll loops improves perfor mance result code size program produced program specialization hundred times larger specialized program using data specialization speedup gain 20 combined specialization delays occurrence code explosion data specialization applied innermost loop contains cache computations program specialization applied rest program applications fft appendix specialized respect number data points n contains ten loops several degrees nesting one loops complexity contains four calls trigonometric functions evaluated program specialization cached data specialization due elimination expensive library calls program specialization data specialization produce signicant speedups see figure 3a however case program specialization code unrolling degrade performance contrast data specialization produces stable speedup regardless number data points n smaller 512 data specialization obtain better result comparison program specialization however n greater 512 program specialization becomes impossible apply specialization time size residual code situation data specialization still gives better performance unspecialized program program also contains conditionals combined specialization innermost loop unrolled improves performance better data specialization alone romberg integration appendix b specialized respect number iterations used approximation romberg integration contains two calls costly function intpow called twice singly nested loop another time doubly nested loop specialization strategies eliminate expensive library calls speedup consequently good fft loop unrolling causes program specialization speedup decrease whereas data specialization speedup still remains even increases figure 3b 5 conclusion integrated program data specialization specializer named tempo importantly data specialization reuse phases ooeline program specializer tempo ooeers program data specialization experimentally compared strategies combination evaluation shows one hand program specialization typically gives better speedup data specialization small problem size however problem size increases residual program may become large often slower unspecialized program hand data specialization handle large problem size without much performance degradation strategy however ineoeective program specialized mainly consists control aeow computations combination program data specialization promising produce residual program eoecient data specialization alone without dropping performance dramatically program specialization problem size increases acknowledgments thank renaud marlet thoughtful comments earlier versions paper well compose group stimulating discussions substantial amount research reported paper builds work done authors scott thibault berkeley packet lter julia lawall fast fourier transformation r mixed computation translation linearisation decomposition compilers tutorial notes partial evaluation specializing shaders partial evaluation automatic program genera tion data specialization faster fourier transforms via automatic program specialization program data specialization principles fast optimized sun rpc using automatic program specialization scaling partial evaluation optimizing sun commercial rpc protocol tr ctr jung gyu park myongsoon park using indexed data structures program specialization proceedings asian symposium partial evaluation semanticsbased program manipulation p6169 september 1214 2002 aizu japan vytautas tuikys robertas damaeviius metaprogramming techniques designing embedded components ambient intelligence ambient intelligence impact embedded system design kluwer academic publishers norwell mads sig ager olivier danvy henning korsholm rohde obtaining knuth morris pratts string matcher partial evaluation proceedings asian symposium partial evaluation semanticsbased program manipulation p3246 september 1214 2002 aizu japan charles consel julia l lawall annefranoise le meur tour tempo program specializer c language science computer programming v52 n13 p341370 august 2004 torben amtoft charles consel olivier danvy karoline malmkjr abstraction instantiation stringmatching programs essence computation complexity analysis transformation springerverlag new york inc new york ny 2002