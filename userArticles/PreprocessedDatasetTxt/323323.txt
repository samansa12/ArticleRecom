leadingone prediction concurrent position correction abstractthis paper describes design leadingone prediction lop logic floatingpoint addition exact determination shift amount normalization adder result leadingone prediction technique calculate number leading zeros result parallel addition however prediction might error one bit previous schemes correct error result delay increase design presented incorporates concurrent position correction logic operating parallel lop detect presence error produce correct shift amount describe error detection part overall lop perform estimates delay complexity compare previous schemes b introduction leadingone prediction used floatingpoint adders eliminate delay determination leadingone position adder output critical path determination needed perform normalization result since latency floatingpoint addition significant many applications prediction might practical importance direct way perform normalization illustrated figure 1a result computed leadingone detector lod 1 counts codes number leading zeros result left shifted however procedure slow since necessary wait result computed determine shift amount alternatively shown figure 1b normalization shift determined parallel significands addition leadingone predictor anticipates amount shift normalization operands result addition obtained normalization shift performed since shift already determined approach used recent floatingpoint unit design commercial processors 3 7 8 9 11 18 19 described basic schemes developed leadingone predictor give position possible error one bit second step consists detecting correcting error step increases overall delay avoid delay increase propose correction procedure detects error parallel 1 lod also called lzd leading zero detector 2 lop also called lza leading zero anticipator lod input input b result result input input b significand adder sub shift coding b adder sub significand shift coding figure 1 magnitude addition normalization floatingpoint adder unit determination position correction performed concurrently first stage shifter evaluation comparison presented show plausible achieved specific implementation single datapath double datapath cases 11 previous work several lops recently proposed literature 4 17 19 briefly discuss lop described 19 general structure shown figure 2a described detail section 2 preencoding examines pairs bits operands produces string zeros ones leading one position corresponding leading one addition result string used lod produce encoding leadingone position characteristics preencoding resulting leadingone position might error one bit therefore necessary correct error additional one bit left shift called compensate shift performed basic normalization shift compensate shift increases delay floatingpoint addition design 19 performed case alignment step operands compared swapped result subtraction always positive simplifies implementation adder lop however cannot used case floatingpoint adders double datapath explained section 5 b b b compensate shift normalization lod adder p preencoding adder lod preencoding p adder detection tree c shift lod p correction preencoding normalization shift carry select correction shift normalization shift carries figure 2 lop architectures without concurrent correction b concurrent correction based carry checking c concurrent correction based parallel detection tree 4 lop concurrent position correction based carry checking de scribed general structure shown figure 2b designed part multiplyaddfused maf unit 5 9 previous scheme lop possibility wrong prediction one position perform correction carry adder going anticipated leadingone position checked position corrected according carry value correction done last stage normalization shift therefore principle correction increase delay however show section 5 carry detection slow introduces additional delay floatingpoint addition similar scheme proposed 17 12 contribution main contribution paper propose evaluate method perform correction one position error basic lop normalization shift without producing delay degradation achieved detecting error condition concurrently basic lop therefore significands adder describe development detection correction scheme systematic way since description much common description basic lop also include latter proposed lop operates general case output adder positive negative version case operands adder previously compared result subtraction always positive described 1 approach figure 2c basic lop similar 19 extended case output adder positive negative based location bit patterns producing leadingone binary coding position means binary tree moreover include another preencoding trees detect occurrence error basic lop output trees used correct output lod correct shift performed since detection correction performed last stage normalization shift delay addition increased since almost floatingpoint processors 6 10 13 use ieee standard 15 consider case signandmagnitude representation operands paper organized follows section 2 structure lop presented different modules lop described leadingone position encoding section 3 concurrent position correction section 4 section 5 design evaluated compared lops finally section 6 effect floatingpoint addition latency discussed general structure give overview structure leadingone predictor propose following sections consider individual modules stated introduction two significands signandmagnitude lop applicable effective operation subtraction shown figure 1b lop predicts position leadingone result parallel subtraction significands lop operates significands alignment denote 0 b 0 significant bits operation performed magnitude adder ja gamma bj 3 develop lop general case either 3 note consider positive aligned significands consider signs floatingpoint operands correct normalization concurrent correction leadingone encoding string symbols n symbols string 0s 1s n bits detection vlog n bits correct module coarse b adder normalized figure 3 general structure proposed lop b contrast simplified lop considering b proposed 19 added concurrent correction 1 extension necessary lops described 19 1 suitable floatingpoint adders operands swapped obtain always positive result case effective subtraction discussed section 5 effective singledatapath floatingpoint adders comparator parallel alignment shift contrast lop propose incorporated also floatingpoint adders swap operands depending exponent difference cases result effective subtraction may negative exponents equal shown figure 3 lop divided two main parts encoding leadingone position correction position moreover parts composed following components encoding ffl preencoding module provides string zeros ones defining leadingone position leading one immaterial rest string ffl encoding tree also called leadingone detector lod encode position mostsignificant 1 drive shifter normalization addi tion bit v indicates result 0 correction ffl preencoding module providing string symbols used determine whether correction needed indicated figure 3 significant commonality preencoding modules ffl detection tree determine whether position indicated encoding tree corrected incremented one ffl correction module performs correction necessary parallel operation barrel shifter sections 3 4 describe two parts corresponding modules trees 3 position encoding 31 preencoding module indicated figure 3 module produces string zeros ones first step production string perform radix2 signeddigit subtraction significands obtain operation done bit slice without carry propagation clarity gamma1 represented 1 consider string w determine position leading one mally determination position requires conversion signeddigit representation conventional binary representation however see conversion actually required simplify discussion consider separately cases w notation used throughout paper following x denotes arbitrary substring 0 k 1 k 1 k denote strings k 0s 1s 1s respectively k 0 alternative situations location leading one described diagram figure 4 last level diagram indicates possible combinations w radix 2 signeddigit nonredundant binary representations together location leadingone since w 0 first digit w different 0 equal 1 therefore top diagram shows w string 0 k 1x substring x two situations identified follows s1 digit w following first 1 either 0 1 case leading one located position k 2 shown considering two cases see 1 digit following first 1 1 clearly conversion w conventional representation 1 position k1 since borrow produced negative x absorbed 1 position k 2 situation leading one position identified substring 2 digit following first 1 0 two possibilities exist respect x namely ffl x positive zero position leading one k 1 since borrow x ffl x negative position leading one borrow produced x problem situation possible detect inspecting digits w since depends number zeros 1 consequently assume position k1 correct later leading 1 position identified substring 0 ae ae ae ae ae ae ae ae ae z z z z z z z z z z 0kj 0 ae ae ae ae ae ae ae ae ae z z z z z z z z z z 0k omega omega omega omega omega omega omega omega omega omega omega positive negative zerok 0xomega omega omega omega omega omega omega omega omega omega omega positive negative zerok correction correction assume position patterns 1 assume position patterns 11 figure 4 bit patterns w 0 table 1 leadingone position w 0 bit pattern leadingone position substring first 10fpositive zerog first first 0 last 1 string k 0fpositive zerog last 1 string k first 0 last correction needed summary s1 leading one position identified substrings s2 first 1 w followed string 1s string 1s length j position leading 1 depending similar situation s1 consequently using approach assume position k correct later leading one position identified substrings discussion summarized table 1 combining s1 s2 cases leadingone position determined substrings case analysis extended determine leading one position w 0 achieved exchanging role 1 1 w 0 case therefore leadingone position identified following substrings case case leading one encoding tree provide signal indicating situation therefore immaterial encoding 311 string identify leadingone position produce string zeros ones first one leadingone call string corresponding bit f obtained combining substrings described simplify description f values digit w equal 1 0 1 called respectively bit position input operands following functions defined notation substrings ffl w 0 ffl figure 5a 5b show examples computation f pos f neg according equations 2 3 would possible use strings f pos f neg encode position leading one separate lods choose sign known however efficient combine strings single lod 4 simplest way combine would two expressions however produces incorrect result instance 1 f neg signal leadingone position correct positive w example given figure 5c abovementioned problem use also w igamma1 substrings ored produce combined f figure 4 see substring w w identifies leading one w similarly substring w w identifies position w consequently extended expression e contrast discussed section 4 use two separate strings detection pattern correction b w w f c fpos b fneg combined f b w w figure 5 computation intermediate encoding similarly negative string combining equations obtain transformed e example calculation string f given figure 5d note case postpone description implementation module discussed also preencoding concurrent correction since modules share components figure design 8bit lod tree implementation b logic structure 4bit lod block 32 encoding tree string f obtained position leading one f encoded means lod tree 14 19 figure 6a shows structure 8bit lod following scheme notation described 14 bit v lod block indicates 1 group bits consideration block p encodes relative position 1 example figure 6b shows logic structure 4 bit lod block block lod4 tree note logic structure lod8 block similar multiplexer 2 bit inputs 3 bits output relative position 1 inside group obtained concatenation depending 1 block v 0 v 1 respectively final p encodes position leading one case obtain final indicates shift n bits performed 4 concurrent position correction explained section 3 position leading one predicted input operands one bit error following patterns w 1 tree tree positive preencoding logic correct negative correction g g positive encoding negative encoding concurrent correction present pattern present pattern present pattern negative positive figure 7 detection correction pattern 2 cases position corrected adding 1 encoding calculated tree therefore concurrent position correction two steps 1 detection necessary correct 2 correction position encoding first step carried parallel leadingone encoding second one normalization shifting 41 detection figure 7 shows general scheme detection correction pattern explained detection performed two modules preencoding module detection tree preencoding logic two different strings obtained g p used detect presence positive correction pattern case w detect negative correction pattern case w 0 done position encoding previous section possible combine strings one tree detect types patterns however found complicates substantially tree opted using two different trees g p processed positive tree g n negative tree describe modules table 2 relation w g p b g n otherwise z otherwise z 411 preencoding module preencoding use w string obtained two new encodings constructed carry detection g p detect positive correction pattern g n detect negative one cases necessary distinguish digit values 1 1 therefore digits string g p g n take values fgamma1 0 1g simplify notation use n z p 1 0 1 respectively specifically positive case detect two patterns w construct string g p detect pattern similarly g n detect pattern let us consider g need detect pattern consisting leading one followed zeros terminating 1 follows ffl use f p string described expression 2 section 3 give us leading one followed zeros ffl combination w give us position 1 resulting relation substrings w digits g p shown table 2a note substrings w n g p set according previous discussion cases interpreted n interpretation performed positive detection tree figure 8 indicates pattern w corresponding string g p seen g p pattern z k pz q n cases correction needed correction needed c correction needed f figure 8 patterns string g p w 0 case similar way preencoding g n obtained table 2b shows relation w digits g n 412 implementation preencoding module implements expressions f g p g n namely ffl f ffl g p ffl g n implementation shown figure 9 413 detection tree detect one two patterns correction present binary tree used input tree intermediate encoding g however single tree used detect positive pattern pz k n negative one nz k p number values node tree would large resulting complex slow hardware implementation therefore propose use two different trees one detect positive pattern positive tree detect negative pattern negative tree shown figure 7 two trees operate parallel one patterns present corresponding tree detect positive tree positive tree receives input string g p detect pattern z k pz q nx present node tree five possible values z p n u representing figure 9 implementation preencoding logic following substrings indicates pattern detected u indicates string incompatible pattern node tree receives input output two nodes preceding level produces combined value figure 10a illustrates nodes different level combined table 3a shows function table node tree left input node represented first column table right input first row output result combination left p right n value value set combination right input results table 3 node functions positive tree b negative tree z u u u u u u z u u u u u u since string found mostsignificant digits string leastsignificant digits effect figure 10b shows example detection pattern case pattern z 5 pz 8 n x present string result position corrected value note first digit different z g p n examining negative w string positive tree value obtained output last level tree n simple implementation encode five values four variables assign code 0000 value u encoding logic equations input right input respectively negative tree negative tree obtained exchanging role p n positive tree receives input g n string node function shown table 3b similarly positive detection tree positive w string processed final value obtained p string g p leastsignificant digits node node level level z p z n n z z z z z z z z z left right z z z z z z z p z z z z z string detected mostsignificant digits figure 10 binary tree detect correction pattern implementation hardware implementation nodes positive tree equations 7 negative tree shown figure 11 42 correction normalization shift last step lop propose correction leadingone position correction done incrementing one shift amount done 19 reduce delay shifter convenient decode shift amount parallel adder sufficient time moreover implementation constraints shifter one stage shown figure 12 stages organized coarsest finest last one performs shift one several contiguous positions say 0 k f binary positions indicated figure perform correction last stage shifter modified shift 0 positions negligible effect delay last stage notice selection correction nocorrection made parallel previous stages shifter z p n z figure hardware implementation tree node 5 evaluation comparison section lop architecture propose evaluated terms delay critical path added hardware complexity compare implementations two schemes discussed section 11 namely lop without concurrent correction lop concurrent correction based carry checking 51 evaluation evaluate lop carry timing analysis architecture critical path addition normalization shift bits calculated moreover estimate additional hardware needed concurrent correction timing analysis estimate delay differents blocks architecture using unit delay simple gate 2input nand delays summarized table 4a estimations obtained 19 thorough comparison performed lops described 19 4 delay preencoding logic f g p g n calculated according hardware implementation proposed figure 9 compute delay lod detection tree considered trees six levels first level decoder decoder ls bits decoder partial shift f leadingone position ms bits unnormalized b first stage shifter shifter second stage last stage shifter normalized b correction correct tree detection shift partial shift partial shift figure 12 concurrent correction leadingone position lod composed gates delay remaining levels determined 2input multiplexer however levels 3 4 5 6 control input multiplexers known advance inputs obtained previous level 14 therefore delay levels estimated 2 nand results total delay lod 12 nand delay level detection tree determined twolevel nand nand network see figure 11 note z output load 7 gates however load slowest path node output 1 gate therefore load z affect global delay node consider normalization shift carried two stages coarse shift fine shift operating three bits shift amount consequently shifter implemented 8input multiplexers moreover buffers needed control input shifters due heavy load lines figure 13a shows general structure delay parallel paths adder lop shifter note slowest path goes adder table 4 delay basic components lop b gate count lop buffer 3 2input mux 3 preencoding f 6 preencoding g p g n 4 detection tree 12 shift correction 3 adder coarse shifter 5 fine shifter 5 values obtained 19 element gates preencoding f 650 preencoding g p g n 320 detection tree 1000 shift decoding correction 34 nand whereas path preencoding f lod tree almost delay 33 nand path detection tree lower delay pointed concurrent correction critical path hardware components evaluate hardware complexity concurrent correction include components lop estimation includes active components gates interconnections table 4b summarizes total count logic gates bits gate count preencoding logic f g p g n obtained implementation shown figure 9 count logic f includes gates except gates exclusive compute g p g n therefore bit consider 12 gates devoted compute f 6 compute g p g n said lod detection tree composed dlog 2 n number bits significands lod different modules level tree thus module except first level composed gate 2input multiplexer however number bits multiplexer inputs depends level 54 bits total number 2input multiplexers 49 modules first level multiplexer number gates level coarse select adder adder c preencod adder detect correct carries preencod lod coarse control lines buffer comp coarse lod preencod lod correct adder fine buf detection tree g f buf26lodcoarse5 dec shift corr adder f buf26lod coarse fine5 shift compbuf dec shift adder fine coarse f6prefix tree7 finecarries 22 7corr buf select carry dec coarse buf dec c figure 13 general structure critical path delay lop concurrent correction based detection tree b lop without concurrent correction c lop concurrent correction based carries checking detection tree derived implementation figure 11 included also gate count shift decoding shift correction 52 comparison section compare lop architecture concurrent correction two lop alternatives lop without concurrent correction lop correction scheme based utilization addition carries use estimates module delays number gates three schemes main characteristics following 1 lop without concurrent correction figure 13b extension one described 19 case output adder either positive negative since lod determines position leadingone within error one bit compensation shift included normalization performed estimated delay compensate shifter 2 nand addition delay buffer required shift control corresponding delay diagram shown figure 13b 2 lop concurrent correction based carries figure 13c discussed 4 17 error leadingone position detected checking carry corresponding position therefore scheme carries adder calculated explicitly corresponding carry selected according output lod accomplish selection preferable lod output consist string 1s followed 0s therefore lod implemented prefix tree carry selection performed set 2input gates followed gate characteristics lod output delay fine decoder larger schemes however critical path note carry selection shift correction done parallel coarse shifter convenient reduce much possible delay fine shift accomplish done 4 coarse shifter hexadecimal figure 13c shows corresponding timing diagram table 5 summarizes critical paths three schemes shows estimations lop concurrent correction presented results reduction 13 estimation number gates lop two schemes comparing given table 6 total gate count three lops summarized table 7 lop concurrent correction presented larger number gates almost doubles gate count lop without concurrent correction approximately 10 larger gate count lop concurrent correction table 5 comparison critical path delay lop without lop concurrent lop concurrent correction correction based carries critical path delay 34 nand improvement 13 13 table gate count lop without concurrent correction b lop concurrent correction based carry checking element gates preencoding f 650 coarse shift decoding 40 fine shift decoding 120 compensate shift 160 element gates preencoding f 650 prefix tree 1100 carry selection 110 coarse shift decoding 40 fine shift decoding 120 correction based carry checking however gate count small part number gates floatingpoint adder 53 actual implementations put perspective comparison estimations presented briefly summarize actual lop implementations recently described literature 19 implementation floatingpoint adder using lop without concurrent correction presented includes compensate shifter normalization floatingpoint adder fabricated 05 cmos process technology triple metal interconnections main difference respect lop without concurrent correction described section 52 comes fact 19 result subtraction always positive preencoding logic simplified delay lop 8 ns time devoted compensate shifter 1 ns therefore concluded incorporating concurrent correction based detection tree consequently eliminating compensate shifter delay table 7 gate count concurrent correction lop gates lop detection tree 2260 lop without concurrent correction 1200 lop carry checking 2050 lop could improved 7 ns 5 9 implementation ibm rs6000 floatingpoint unit 1 cmos technology using triplelevel metal described incorporates floatingpoint multiplyaddfused unit uses lop concurrent correction based carry checking lod designed accommodate partialdecode scheme used shifters normalization shift accomplished two stages first stage produces hexadecimal shift second stage fine shift 0123 lod calculates hexadecimal position leadingone string 1s followed 0s necessary decode binary position leadingone configuration used kind lop comparison lop design detailed 4 leadingone position anticipation carriedout digitwise input data processed blocks 4 bits provides shift signal block shift signals constitute coarse shift obtain shift signals prefix tree used receives input generate g inputs 1 propagate p one input 1 zero z inputs 0 signals also used adder output tree specifies leadingone position inside group four bits signals used control shifters selection carries 6 floatingpoint addition latency reduction consider effect proposed concurrent correction overall latency floatingpoint addition depends delay parts adder pipelined implementation processor cycle time consider separately effect singledatapath doubledatapath implementations latency reduction singledatapath floatingpoint adders figure 14a shows block diagram singledatapath floatingpoint adder using lop without concurrent position correction 10 13 adder pipelined five stages done 19 significand addition performed ones complement signif signif exp exp stages mux mux muxexponent difference correction concurrent detection concurrent without sign exp diff exp diff adder adder ones comp ones comp 1bit shift msb 1bit shift sign bit msb bit invert msb sign bit shift correct control sign addsub right bit invert control mux output aligner incr exp compensation control bit invert output aligner mux figure 14 single datapath floatingpoint adder without comparison included concurrent rounding b reduced latency single datapath floatingpoint adder without comparison concurrent rounding lop concurrent correction form 5 way result negative recomplementation consists bit inversion alternatively compound adder could used 2 16 fourth stage perfoms rounding normalization adder result note inverters recomplement result also included stage shown figure operations performed two parallel paths 19 one inversion massive left shift 1bit shift rounding possible 1 value computed significand adder negative whe exponent difference zero case full normalization left shift may needed rounding required consequently bit inverters operate parallel rounding logic 2 hand exponent difference larger zero two situations occur ffl two mostsignificant bits adder result zero occur exponent difference one zero case analyzed separately normalization left shift one bit needed result exact rounding required mux selects output shift module addition result ffl least one two mostsignificant bits adder result one situation occurs exponent difference note normalized adder result included situation maximum normalization shift one normalized result rounded limited normalization shift carried 1bit shift module mux selects output round module result case effective addition rounding always required never normalization left shift however significand overflow occur needing one bit rightshift normalization right shift also carried 1bit shift module figure adder lop concurrent correction similar except compensation shifter exponent incrementer fifth stage eliminated might permit merge two last stages shown figure 14b note merging might possible without concurrent correction delay compensate shifter exponent incrementer similar scheme latency reduction obtained single datapath floatingpoint adder comparison 6 19 case comparator included second stage assure case effective subtraction smaller operand subtracted larger one therefore result always positive latency reduction obtained kind adder analyzed 1 rounding additionsubtraction0 signif exp signif exp exponent difference sign bit lop without correction concurrent effective subtraction rounding 1bit shift msb msb far close exp diff effect oper eff add sign exp diff control addsub sign control shift eff sub adder compound bit 1bit shift bit inverter right bit inverter compound adder alignment 1bit shift exp incr control mux output aligner exp incr shift compensate figure 15 latency double datapath floatingpoint adder latency reduction doubledatapath floatingpoint adders figure 15 shows doubledatapath architecture 11 12 far datapath computes effective subtractions exponent differences larger one well effective additions hand effective subtractions exponent difference equal smaller one computed close datapath pipelining adder four stages derived transforming pipelined single datapath floatingpoint adder without comparison figure 14 considering components delays specified 19 section 5 paths additionsubtraction combined rounding compound adder 2 11 16 adder computes selects one perform rounding moreover close datapath used perform twos complement result bitwise inversion 11 16 array half adders included compound adder far datapath compute required rounding infinity significand overflow however 2 describes modification replaces array right shift operands one position effective addition way result either normalized one leading zero situation subtraction consequently rounding performed way addition subtraction shift operands implemented right shifter parallel 1bit shifter modification reduces delay since eliminates de array half adders far datapath assure positive result adder smaller operand complemented effective subtraction way result conversion eliminated moreover path fulllength normalization required since maximum left shift result one bit respect close datapath case equal exponents result negative alignment right shift result exact rounding necessary case exponent difference equal one maximum alignment shift one bit complete alignment shifter required hand cases may require fulllength normalization shift therefore lop needed close datapath note datapath effective operation always subtraction bit inverters smaller operand included inside compound adder since case effective subtraction operands equal exponents result negative negative result converted sign andmagnitude representation converted result formed bitinverting output b compound adder way result conversion reduced bitwise inversion output compound adder since 1bit alignment shift 1bit normalization shift small delay implementation shorter critical path single datapath case figure 14 determine influence lop concurrent correction latency analyze total delay two paths using lops without concurrent correction see expected elimination compensation shifter close datapath reduces total delay path described flexibility pipeline two paths several stages latency reduced considering blocks close far paths see paths almost modules signif exp signif exp exponent difference compound adder four levels adder compound sign bit msb exp diff effect oper control mux far close sign exp diff eff sub concurrent lop detection control addsub sign eff add control shift shift corr bit 1bit shift bit inverter 1bit shift shift right compound adder two levels exp incr mux 1bit shift output aligner bit inverter figure double datapath floatingpoint adder reduced latency close exponent difference operand swapping 1bit right shifter alignment compound adder bit inverter normalization left shifter compensate shifter mux output aligner far exponent difference operand swapping alignment right shifter bit verter compound adder 1bit left shifternormalization mux output aligner difference two datapaths compensate shift close datapath consequently concurrent correction used compensate shift eliminated paths delay allowing pipelining four stages smaller stage delay might even possible obtain three stage pipeline shown figure 16 7 conclusions presented leadingone prediction lop algorithm implementation obtain exact prediction normalization shift floatingpoint adders prediction permits reduce delay adder since lop operating parallel adder normalization shift known result significand addition lop algorithm presented general since operate adders result positive negative predicted leading one position error one bit approach includes logic necessary concurrently detect prediction wrong correct normalization shift permits elimination compensation shifter required adders lop includes concurrent shift correc tion although concurrent correction increases number gates required lop increase significant since lop small portion overall floatingpoint adder detection correction logic operates parallel lop significant adder introduce additional delay adder improves performance respect lops concurrent correction based checking carries significand adder logic necessary carry checking introduces additional delay estimated delay significant addition normalization shifter reduced approximately 13 using lop algorithm respect lop without concurrent correction lop concurrent correction based carry checking improvement used reduce latency pipelined floatingpoint adder shown latency single datapath adder reduced five four cycles maintaining critical path delay similarly latency double datapath floatingpoint adder reduced four three cycles r rounding floatingpoint addition using compound adder ultrasparc next generation superscalar 64bit sparc design ibm risc system6000 floatingpoint execution unit snap project design floatingpoint arithmetic units variable latency pipelined floatingpoint adder algorithmic novel design leading zero detector cir cuit comparison logic synthesis computer architecture improved algorithm highspeed floatingpoint addition design implementation snap floating point adder tr ctr r v k pillai alkhalili j alkhalili shah low power approach floating point adder design dsp applications journal vlsi signal processing systems v27 n3 p195213 march 1 2001 chi huang xinyu wu jinmei lai chengshou sun gang li design high speed double precision floating point adder using macro modules proceedings 2005 conference asia south pacific design automation january 1821 2005 shanghai china khalid h abed raymond e siferd cmos vlsi implementation lowpower logarithmic converter ieee transactions computers v52 n11 p14211433 november