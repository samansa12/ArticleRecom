decision analysis augmented probability simulation provide generic monte carlo method find alternative maximum expected utility decision analysis define artificial distribution product space alternatives states show optimal alternative mode implied marginal distribution alternatives drawing sample artificial distribution may use exploratory data analysis tools approximately identify optimal alternative illustrate method important types influence diagrams b introduction 11 decision analysis simulation decision analysis provides framework solving decision making problems uncer tainty based finding alternative maximum expected utility conceptually simple actual solution maximization problem may extremely involved eg probability model complex set alternatives continuous sequence decisions included therefore particular probability models studied multivariate gaussian shachter kenley 1989 inclusion continuous variables simple problems carried discretization miller rice 1983 smith 1991 summaries first moments derivatives smith 1993 approximations means gaussian mixtures poland 1994 complicated problems may hope exact solution method may turn approximate methods specifically simulation observed pearl 1988 p311 cooper 1989 principle simulation method solve bayesian networks bn may used solve decision problems represented influence diagrams id means sequentially instantiating decision nodes computing expected values cooper notes given instantiation decision nodes computation expected value value node reformulated computation posterior distribution artificially created additional random node problem solving bns summarized example shachter peot 1990 exact algorithms eg using clique join trees lauritzen spiegelhalter 1988 cutset conditioning pearl 1986 arc reversal shachter 1986 1988 proved intractable many realworld networks leading approximate inference algorithms based simulation methods include short run algorithms logic sampling henrion 1988 likelihood weighting shachter peot 1990 improved modifications bounded variance aa algorithms pradhan dagum 1996 long run algorithms using markov chain monte carlo methods like gibbs sampling pearl 1987 hrycej 1990 york 1992 hybrid strategies brewer et al 1996 however matzkevich abramson 1995 note couple outlines simulation methods specifically ids jenzarli 1995 charnes shenoy 1996 whereas first one combines stochastic dynamic programming gibbs sampling latter simulates iid observations small set chance variables decision node instead using entire distribution become intractable continuous decision spaces included recent statistical literature problem ie finding optimal action decision problem considered muller parmigiani 1996 carlin kadane gelfand 1998 among others approaches use monte carlo simulation evaluate expected utility given instantiations nodes 12 augmented probability simulation paper propose scheme differs important ways mentioned approaches since use simulation evaluate expected utilities losses given instantiations decision nodes accomodate continuous variables especially decision variables unless discretization carried probability distributions conjugate framework contrast go step define artificial distribution nodes including decision nodes show simulation artificial augmented probability model equivalent solving original decision problem specific strength proposed method generality algorithm principle accomodate arbitrary probability models utility functions long possible pointwise evaluate probability density utility function chosen value involved nodes evaluation probability density constant factor suffices idea augmenting probability model transform optimization problem simulation problem entirely new example shachter peot 1992 proposed similar approach involves augmenting probability model include decision nodes thus transforms original optimization problem simulation problem best knowledge approach described first solve simulation problem systematically exploiting markov chain monte carlo simulation methods recently developed statistical literature method starts considering artificial distribution space alternatives states distribution defined way marginal space alternatives proportional expected utility alternative consequently optimal alternative coincides mode marginal proposed simulation based strategy follows steps draw sample artificial distribution ii marginalise space alternatives iii find mode sample way approximating optimal alternative key issue sample artificial distribution introduce markov chain monte carlo mcmc algorithms see example smith roberts 1993 tierney 1994 tanner 1994 review mcmc methods section 2 describes basic strategy simple example section 3 technical nature provides generic methods sample approximately artificial distribution identify mode sample section 4 discusses application examples section 5 compares method alternative schemes identifies situations call different approaches 2 basic approach outline basic approach assume choose uncertainty alternative set set states theta propose optimal alternative maximum expected utility ud p ud utility function modeling preferences consequences p probability distribution modeling beliefs possibly influenced actions problem structurally complicated say heavily asymmetric dense large influence diagram continuous nongaussian random variables non quadratic utility functions andor continuous sets alternatives decision nodes finding exact solution might analytically computationally intractable might need approximate solution method shall provide approximation based simulation assume p 0 pairs ud positive integrable define artificial distribution product space athetatheta density h proportional product utility probability specifically hd ud delta p note artificial distribution h chosen marginal alternatives hd hence optimal alternative coincides mode marginal artificial distribution h space alternatives consequence solve expected utility maximization problem approximately following simulation based draw random sample distribution hd ii convert random sample marginal hd iii find mode sample augmented probability model simulation conceptually different simulation algorithms reviewed earlier simulation used pointwise evaluate expected utilities decision alternative instead simulation generates artificial probability model hdelta augmented state vector key steps iii ii since use simulation generate hd get marginal sample hd simply discarding simulated values iii rely mainly tools exploratory data analysis describe section 33 shall introduce generic markov chain simulation methods underlying idea simple wish generate sample distribution certain space cannot directly suppose however construct markov chain state space straightforward simulate whose equilibrium distribution desired distribution simulate sufficiently many iterations dropping initial transient phase may use simulated values chain approximate sample desired distribution shall provide several algorithms constructing chains desired equilibrium distribution case artificial distribution h section 32 rest section shall provide algorithm simple example readers may grasp basic idea without entering technical details readers familiar mcmc simulation may skip directly section 3 strategy propose simple may undertaken limited cases suppose conditional distributions hdj hjd available efficient random variate generation suggest following scheme known gibbs sampler statistical literature gelfand smith 1990 start arbitrary value steps ii iii convergence judged consequence results tierney 1994 roberts smith 1994 proposition 1 utility function positive integrable p 0 pairs theta intervals ir n scheme defines markov chain stationary distribution h impossible give generally applicable results terminate iterations markov chain monte carlo simulations well known difficult theoretical problem see eg robert 1995 polson 1996 discuss approaches find number iterations ensure convergence total variation norm within given distance true stationary distribution however practical convergence may judged number criteria see eg cowles carlin 1996 brooks roberts 1999 methods implemented coda best et al 1995 used examples practical convergence judged say may record next n iterations simulation output use approximate sample hd may try assess mode illustrate approach artificial example adapted shenoy 1994 example 1 physician determine policy treating patients suspected suffering disease causes pathological state p turn causes symptom exhibited physician observes whether patient exhibiting symptom based information either treats patient p 0 physicians utility function depends p shown table 1 value 0001 changed original value 0 adapt general result proposition 1 probability disease 1 01 patients known suffer 80 suffer p 1 hand table 1 probability model pd physicians utility function ut hd probabilities used steps ii iii markov chain monte carlo scheme described text proportional entries appropriate column row respectively h section right table patients known suffer 0 15 suffer p patients known suffer p patients known suffer assume probabilistically independent given p implement proposed algorithm need find conditional distributions hjd hdj case decision taken symptom exhibited 0 exhibited means treat treat patient let pd probabilities given description hd proposed method goes follows start arbitrary decision 0 steps ii iii convergence judged convergence judged record next n iterations algorithm use approximate sample marginal artificial distribution leave values recorded avoid serial correlation since alternatives finite number need inspect histogram approximate mode simulated sample size 1000 find optimal decision treat symptom present treat symptom absent note example proposed augmented probability model simulation differs simulation methods proposed solution ids use one simulation joint space simulate hdelta instead many small simulations evaluate expected utilities possible decision one time course previous example extremely simple able sample hdj hjd inspection histogram may approximate modes next sections deal complex cases 3 sampling artificial distribution shall provide generic method sample artificial distribution hdelta typ ically distribution straightforward simulate requiring generation possibly high dimensional models including complex probability utility functions continuous decision chance nodes possibly conditioning observed data mcmc simulation schemes commonly used methods known accomodate gen hence choose given enormous interest ids tool structuring solving decision problems see eg matzkevich abramson 1995 concentrate structures id directed graph representation decision problem probability network additional nodes representing decisions values notational purposes shall partition set nodes five subsets differentiating three types chance nodes decision nodes representing decisions made ii chance nodes including random variables x observed prior making decision ie data available time decision making yet observed random variables ie data observed making decisions unobservable random variables ie unknown parameters iii one value node u representing utility function ud x figure 1 provides simple generic id scheme id solved determining decision maximum expected utility x phi oe r deltaff figure 1 generic influence diagram scheme requires marginalizing chance nodes conditioning x maximizing see shachter 1986 complete description algorithm solve ids method propose applicable ids nonsequential structure ie decision nodes must chance nodes predecessors distributions depending turn decision nodes except technical conditions requirements 31 probability model defined influence diagrams id defines conditional distributions pxj p p yj joint distribution x via p x ppxjp yj given observed nodes x typically x independent given allowing given factorization p depend particular problem fit setup modifications proposed algorithm straightforward context probability model solving id amounts maximizing expected utility p yjx relevant distribution compute expectation summary solving id amounts finding z shall solve problem approximately simulation augment probability measure probability model defining joint pdf mode implied marginal distribution hd r corresponds optimal decision underlying rationale method simulate markov chain defined h asymptotic distribution big enough simulated values successive states simulated process provide approximately monte carlo sample h note simulation defined augmented probability model hd rather p possible instantiation actions traditional methods considering marginal distribution monte carlo sample infer optimal decision using methods discussed section 33 key issue definition markov chain desired limiting distribution h capitalise recent work numerical bayesian inference concerning application markov chain monte carlo methods explore high dimensional distributions allow analytic solutions expectations marginal distributions etc 32 markov chain monte carlo simulation shall provide general algorithm valid ids satisfying structural conditions specified minor technical conditions discussed algorithm describe metropolis type tierney 1994 generate new candidate states probing distribution move new state stay old one according certain probabilities transition three steps require able evaluate utility function ud x probability distributions p yj p pxj relevant x typically possible since definition id includes explicit specification distributions ie modeler likely specify wellknown distributions scheme requires specification probing distributions g 1 g 2 g 3 choice probing distributions g j j conceptually arbitrary constraint resulting markov chain irreducible aperiodic shall argue whenever possible assume symmetric probing distributions ie satisfying example gajb could multivariate normal distribution nb sigma sigma details choice probing distribution discussed appendix algorithm 1 1 start values parameters outcomes set 2 let u generate proposal djd compute hd probability 1 set otherwise keep 3 let u generate proposal compute probability 2 set 4 let u generate proposal compute u3 probability 3 set 5 1 repeat steps 2 4 chain judged practically converged algorithm defines markov chain h stationary distribution generality algorithm comes price namely possible slow convergence depending application long simulation runs might required attain practical convergence however fully general algorithm rarely required many problems allow simpler algorithms based using pjx p yj generate proposals algorithm 2 given requires probing distribution g djd evaluation utility function algorithms generate pjx p yj simulating p yj typically straightforward simulating pjx gen eral distribution explicitly specified id needs computed repeated applications bayes formula several arc reversals language ids however note simulating pjx amounts solving statistical inference problem generating posterior distribution given data x hence appeal versions posterior simulation schemes appropriate variety important inference problems recently discussed bayesian literature see eg smith roberts 1993 tanner 1994 tierney 1994 starting algorithm described generate sufficiently large monte carlo sample pjx whatever simulation method appropriate algorithm 2 1 start values 2 evaluate u 3 generate djd igamma1 p djd igamma1 p jxp yj 4 evaluate x 5 compute hd 7 convergence practically judged step 3 generation pjx done using simulated monte carlo sample generated algorithm 3 algorithm simplifies x missing id ie data given time decision associated algorithm 3 would stated algorithm 2 proposal distribution step 3 replaced djdp yj sampling p feasible general since distributions defined explicitly id 33 finding optimal solution mcmc simulation provides us approximate simulated sample fd deduce approximate sample marginal hd mode hd approximation optimal alternative case discrete alternatives problem simple since count number times element appeared choose one highest frequency may worthwhile retaining one several frequent decisions study detail way conducting sensitivity analysis case continuous alternatives first approach may use graphical exploratory data analysis tools especially low dimensional decision vectors decision vector one two dimensional may produce histogram smooth version inspect identify modes higher dimensional decision vectors propose consider problem one cluster analysis modes hd correspond ds higher density suggests looking regions higher concentration sampled ds leads us compute hierarchical cluster tree simulated points since assuming h density respect lebesgue measure ir n interested identifying regions optimal alternative might lie suggest using complete linkage euclidean distance classification tree cut certain height obtain corresponding clusters location largest cluster indicates area best decision may useful keep several larger clusters explore corresponding regions result course would depend cutting height exploring several heights may able identify several decisions interest illustrate approach section 42 41 example 2 medical decision making problem illustrate algorithm case study concerning determination optimal aphere sis designs cancer patients undergoing chemotherapy palmer muller 1998 describe clinical background solve problem large scale monte carlo integration pretreatment start chemotherapy stem cells cd34 collected allow later reconstitution white blood cell components depending pretreatment first stem cell collection process apheresis scheduled fifth seventh day pretreatment decision made days pretreatment treatment schedule stem cell collections collect target number cells ii minimize number aphereses data 22 past patients first day new patient denote observed cd34 count patient day ij also shall designate iths patient data combined data vector palmer muller 1998 specify following probability model process likelihood based observation typical profile stem cell counts days shows first rise pretreatment reaches maximum slowly declines back towards base level shown figure 2 model shapes use nonlinear regression model let gt gamma probability density function parameters chosen imply mean variance matching e 2 rescaled use gdelta e parametrize nonlinear regression profiles time prior model patient specific parameters hierarchical patient undergoes one two possible pretreatments x 2 f1 2g serves covariate specify first level prior nj x hyperprior second level common cases 2 model completed prior v oe figure shows observed counts ij fitted profiles typical patients new patient 1 denote unknown stem cell counts days first day 0 already count h0 using notation introduced beginning section 3 observed figure 2 three typical patients dashed lines connect data points solid curve plots fitted profile using described probability model data vector future data vector unobservable parameters model given typical profile optimal decision schedule aphereses days initial day 0 final day 1 ie decision parameter let event failing collect target number stem cells g l h volume blood processed stem cell collection new pa tient let n number scheduled stem cell collections utility function ud x c sampling cost p penalty underachievement target need maximize expected utility r note probability model ppx yj depend decision nodes data x influencing belief model since pjx may actually sampled markov chain monte carlo method described palmer muller 1998 use algorithm 2 solve problem ensure positive utility function add constant offset udelta found optimal design future patient belief preference model 100 patient undergoing treatment x first observation 5 optimal apheresis schedule remaining six days found given decision space two dimensional simple inspection histogram figure 3 plots estimated distribution figure 3 grey shades show histogram simulated medical problem inspection hd reveals optimal decision 42 example 3 water reservoir management problem rios insua et al 1997 describe complex multiperiod decision analysis problem concerning management two reservoirs lake kariba k cahora bassa c solve simplified version using proposed mcmc approach simulate augmented probability model want find given month optimal values announced release k c turbines spillgates k respectively actual amounts water released depend water available uncertain since uncertainty inflows k c reservoirs forecasting model k c latter dependent water released k incremental inflows inc turn depend parameter fi preference model combines utilities k c k depend energy deficit def final storage sto k amount water spilled spi c depend energy produced ene final storage sto c initial storages k c influence well actual releases figure 4 shows influence diagram representing problem nodes double border either known values deterministic functions predecessors required compute value node u show probability model terms rel sto k c ene sto c gammapsi deltaff phi phi phi phi phi phi phi phi au deltaff j bbbbbbbn gammapsi theta theta theta theta theta theta theta j omega omega omega omega omega omega omega oe phi phi phi phi z z z z z ae ae ae ae ae r au b ae figure 4 influence diagram reservoir problem notation problem includes four decision nodes nodes k fi figure 5 shows profiles histogram simulated hd generated algorithm 3 decision parameter four dimensional hence used four dimensional cells record four dimensional histogram simulated states simple inspection empirical distribution allows read optimal release 200g solution based 100000 simulated values markov chain monte carlo scheme figure 5 illustrates also another feature method simple sensitivity analysis procedure extra cost darkness figure 5b suggests expected utility rather flat releases turbines fixed optimal values hence suggesting insensitivity respect changes spill hand figure 5a one dark area estimated optimum suggests expected utility fairly peaked release turbines hence sensitive changes energy releases alternatively discussed section 33 consider hierarchical cluster tree simulation output dots figure 5 show solution based cutting hierarchical cluster tree 1000 simulated values hd height 2000 finding cluster members optimum found 476g comes reasonably close optimum estimated earlier 51 comparison alternative schemes scheme described algorithms 1 2 3 transforms original expected utility maximization problem 1 simulation problem scheme generic sense accomodating arbitrary probability models discrete continuous utility fd k figure 5 expected utility function release energy k spill fixed optimal levels b function spill k release turbines fixed optima diamond indicates optimal decision dots indicate simulations largest cluster hierarchical clustering tree cut height 2000 functions long probability density probability mass function utility function pointwise evaluable main difference simulation schemes earlier considered literature instead using simulation evaluate expected utilities losses possible instantiation decisions use simulation artificial auxiliary model augments original probability model include artificial distribution decision nodes whether one approach efficient depends specifics considered decision problem general comparisons possible even specific examples performance depend heavily arbitrary choices like amount discretization necessary many methods run length involved monte carlo simulations chosen mcmc scheme etc however general observations relative efficiency methods possible problems alternatives analytic solutions using methods like arc reversal shachter 1986 simulation methods use simulation pointwise evaluate expected utilities like likelihood weighting shachter peot 1990 typically efficient simulation auxiliary probability model bielza shenoy 1998 discuss decision problem reactor problem 6 possible actions chance nodes less 10 possible joint outcomes exact solution using shachters 1986 algorithm requires one arc reversal largest state space used solution phase contains 4 variables comparison implemented example using augmented probability simulation following algorithm 3 used 100000 iterations mcmc simulation computational effort one iteration approximately comparable one arc reversal thus exact solution clearly far efficient terms computing time alternatively consider simulation compute expected utility six possible actions using example likelihood weighting considering involved numerical standard errors monte carlo simulation sizes around 1000 simulations alternative decision would adequate thus also likelihood weighting dominates simulation augmented probability model problems optimal decision computed conditional already available data x comparison changes especially posterior distribution unknown parameters significantly different initial prior distribution ie low prior probability evidence x consider example application reported section 41 amenable exact methods using monte carlo simulation compute expected utilities alternative decisions longer generate independent samples following jenzarlis 1995 proposal could use gibbs sampling compute expected util ities depending specific choices implemented mcmc scheme termination criteria one would typically use order 10000 iterations palmer muller 1998 discretizing sample space one could principle also use logic sampling henrion 1988 however logic sampling would advisable problem since fraction simulated experiments generate variables corresponding actual observations would close zero ie px notation shachter peot 1990 similar reasons likelihood weighting shachter peot 1990 would fail since leaf nodes observed sample scores would proportional likelihood function ie scheme would amount importance sampling using prior probability model importance sampling function however addressed using bounded variance type algorithms discussed example pradhan dagum 1996 finally many decision problems involve continuous decision variables like example considered section 42 continuous decision parameters create problem simulation augmented probability model would allow straightforward application scheme based evaluating expected utilities one decision time even discretization used say grid resulting number alternative actions renders schemes difficult use 52 conclusion complex decision problems may render impossible application exact methods obtain optimal decisions consequence look approximation methods including simulation proposed simulation based strategy approximating optimal decisions decision analysis experiments examples suggest approach may powerful implementation algorithms fairly straightforward based schemes provided specific cases may require simple modifications ones suggested section 32 exploration sample search modes may done standard statistical software mentioned discussion example 3 one feature method provision simple sensitivity analysis features extra cost number challenging problems remain particularly perhaps extension scheme sequential decisions straightforward approach expanding model nonsequential normal form may applied number decision nodes small another challenging problem would develop computational environment based approach would also interesting develop methods look modes multivariate settings similar ideas may pursued solve traditional statistical optimal design problems formal point view optimal design problem described stochastic optimization problem 1 explored clyde muller parmigiani 1995 special case algorithm 3 continuous sample spaces nonsequential setup appendix implementation choice probing distributions g j j algorithm 1 conceptually arbitrary constraint resulting markov chain irreducible aperiodic statement proofs proposed algorithms assumed g symmetric arguments ie continuous parameter propose use normal kernel g appropriately chosen covariance matrix sigma example diagonal matrix diagonal entries corresponding reasonable step sizes decision parameters good values step size found trial error values particular setup gelman roberts gilks 1996 show optimal choice step size result average acceptance probabilities around 25 similarly parameters discrete simple choice g djd could generate 05 course many problem specific choices possible example 2 eg define choosing probability 16 one six possible moves increase 0 1 1 day ii decrease 0 1 1 iii increase 0 1 iv decrease 0 etc symmetry g violated additional factor gdj djd would added expressions acceptance probabilities would correspond metropolishastings steps rather metropolis steps convergence proofs proposed scheme simple based results tierney 1994 roberts smith 1994 acknowledgments research suported grants national science foundation cam cicyt iberdrola foundation parts took place peter muller visiting upm david rios insua visiting cnriami grateful discussions mike wiper r comparison graphical techniques asymmetric decision problems comparison hybrid strategies gibbs sampling mixed graphical models assesing convergence markov chain monte carlo algo rithms approaches optimal sequential decision analysis clinical trials forward monte carlo method solving influence diagrams using local computation exploring expected utility surfaces markov changes method using belief networks influence diagrams markov chain monte carlo convergence diagnostics comparative review efficient metropolis jumping rules bayesian statistics 5 sampling based approaches calculating marginal densities propagating uncertainty bayesian networks probabilistic logic sampling gibbs sampling bayesian networks solving influence diagrams using gibbs sampling local computations probabilities graphical structures application expert systems decision analytic networks artificial intelligence discrete approximations probability distributions optimal design via curve fitting monte carlo experi ments bayesian optimal design population models hematologic data fusion propagation structuring belief networks probabilistic reasoning intelligent systems decision analysis continuous discrete variables mixture distribution approach convergence markov chain monte carlo algorithms optimal monte carlo estimation belief network inference bayesian methods reservoir opera tions zambezi river case convergence control methods markov chain monte carlo algorithms simple conditions convergence gibbs sampler metropolishastings algorithms probabilistic inference influence diagrams gaussian influence diagrams simulation approaches general probabilistic inference belief net works decision making using probabilistic inference methods comparison graphical techniques decision analysis bayesian computational methods moment methods decision analysis bayesian computation via gibbs sampler related markov chain monte carlo methods tools statistical inference markov chains exploring posterior distributions discussion use gibbs sampler expert systems tr