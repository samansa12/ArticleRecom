efficient adaptive lagrangemultiplier methods nonlinear continuous global optimization lagrangian methods popular solving continuous constrained optimization problems paper address three important issues applying lagrangian methods solve optimization problems inequality constraintsfirst study methods transform inequality constraints equality constraints existing method called slackvariable method adds slack variable inequality constraint order transform equality constraint disadvantage search trajectory inside feasible region satisfied constraints may still pose effect lagrangian function leading possible oscillations divergence local minimum lies boundary feasible region overcome problem propose maxq method carries effect satisfied constraints hence minimizing lagrangian function feasible region always leads local minimum objective function also study strategies speed convergencesecond study methods improve convergence speed lagrangian methods without affecting solution quality done adaptivecontrol strategy dynamically adjusts relative weights objective lagrangian part leading better balance two faster convergencethird study tracebased method pull search trajectory one saddle point another continuous fashion without restarts overcomes one problems existing lagrangian methods converges one saddle point requires random restarts look new saddle points often missing good saddle points vicinity saddle points already foundfinally describe prototype novel nonlinear optimization via external lead implements proposed strategies present improved solutions solving collection benchmarks b introduction many applications engineering decision science operation research formulated optimization problems applications include digital signal processing structure optimization engineering design neuralnetwork learning computeraided design vlsi chemical control processing highquality solutions applications may significant economical impacts leading lower implementation maintenance costs improving quality outputs constrained nonlinear global optimization problems study take following form subject gx fx objective function set k inequality constraints set equality constraints fx gx hx assumed nonlinear differentiable realvalued continuous functions global minimization looks solution satisfies constraints larger local minimum challenging problem may enough time find feasible solution even feasible solution found way show minimal practice one seeks many local minima possible satisfy constraints pick best local minimum active research past three decades produced variety methods find solutions constrained nonconvex nonlinear continuous optimization problems 29 10 7 general divided transformational nontransformational methods nontransformational approaches include discarding methods backtofeasibleregion methods enumerative methods discarding methods 11 15 drop solutions found backtofeasibleregion methods 12 attempt maintain feasibility reflecting moves boundaries moves go current feasible region methods combined global search involve transformations relax constraints last enumerative methods 10 generally expensive apply except problems linear objectives constraints bilinear programming problems 1 transformational approaches hand transform problem another form solving wellknown methods include penalty barrier lagrangemultiplier methods 14 penalty methods transform constraints part objective function require tuning penalty coefficients either search barrier methods similar except barriers set prevent solutions going feasible regions methods difficulties start infeasible region feasible solutions hard find however combined methods improve quality lagrangemultiplier methods lagrangian methods introduce lagrange variables gradually resolve constraints iterative updates exact methods optimize objective using lagrange multipliers meet kuhntucker conditions 14 view advantages use constraint relaxation paper given optimization problem equality constraints minimize fx 2 subject corresponding lagrangian function augmented lagrangian function defined set lagrange multipliers use augmented lagrangian function paper provides better numerical stability according classical optimization theory 14 extrema 4 called saddle points whether local global roots following set firstorder necessary conditions conditions necessary guarantee local optimality solution 2 saddle point local minimum lagrangian function lx originalvariable x space local maximum lx lagrangemultiplier space obtained solving following dynamic system equations dt dt perform descents originalvariable space x ascents lagrangemultiplier space goal paper develop new strategies improve convergence speed solution quality lagrangian methods achieve three approaches first study section 2 methods eliminate oscillations inequality constraints transformed equality constraints help improve convergence time compared existing methods adding slack variables second present section 3 method improve convergence speed lagrangian methods adaptively adjusting relative weights objective constraints third discuss section 4 globalsearch method looks multiple saddle points continuous trajectory without restarting search random starting points also present prototype novel integrates strategies finally show section 5 new improved results collection benchmarks handling inequality constraints lagrangian methods work well equality constraints cannot directly deal inequality constraints 1 except simple cases one directly solve firstorder equations closed form general inequality constraints first transformed equivalent equality constraints lagrangian methods applied 21 transformation using slack variables one possible transformation 14 handle inequality constraint add slack variable z transform equality constraint g xz 2 simplification 14 augmented lagrangian function problem 1 becomes lagrange multipliers way 6 saddle point 7 reached descents x space ascents space balance descents ascents depends magnitudes lagrange multipliers play role balancing objective fx constraints hx gx controlling indirectly convergence speed solution quality lagrangian method saddle point forces due descent ascent reach balance appropriate lagrange multiplier values emphasize relative weights affect convergence speed solution quality introduce additional weight w 7 get weight objective original lagrangian function corresponding dynamic system follows dt dt dt starting initial point x0 0 0 solve dynamic equations 911 using ordinary differential equation solver lsode 1 observe search trajectory xt saddle point boundary feasible region true problems benchmark collection 6 dynamic equation approaches inside outside feasible region observe three behaviors search trajectory ffl trajectory gradually reduces oscillations eventually converges ffl trajectory oscillates within range never converges ffl magnitude oscillations increases trajectory eventually diverges illustrate three behaviors divergence oscillations without convergence reduction oscillations convergence apply 911 solve problem 23 6 quadratic programming problem linear inequality constraints problem given follows minimize 2subject 2x 2 quadratic nonlinear programming problem linear inequality constraints set 0 initial point 0 middle search space ie x 1 lsode solver firstorder ordinary differential equations publicdomain package available httpwwwnetliborg objective iterations 1000051525 violation iterations 1000 figure 1 objective maximum violation oscillate using slackvariable method w 1 122 114 112 104 102 objective iterations 1000002006010 violation iterations 1000 figure 2 objective maximum violation converge oscillations subside using slack variable method set maximum logical time lsode divided small units resulting maximum 10 5 iterations max 4t stopping condition 911 lyupunov condition dynamic system stops converges reaches maximum number iterations quickly infinity meaning original lagrangian method diverge scale objective 10 ie objective value oscillates within range gamma17 gamma10 maximum violation v max 0 04 shown figure 1 v max time defined reduce w 115 oscillations subside trajectory eventually converges see figure 2 intuitively occurrence oscillations explained follows suppose start infeasible point initially search progresses corresponding increases pushes trajectory towards feasible region time inequality constraint g xt 0 satisfied current point xt point negative hence trajectory decelerates continues move feasible region even corresponding constraint g xt satisfied movement trajectory inside feasible region eventually stops local minimum boundary corresponding force due descents objective space pushes trajectory outside feasible region likewise trajectory outside feasible region force due constraints pushes trajectory inside feasible region two forces well balanced search may diverge oscillate without convergence 22 transformation using maxq method avoid oscillations method based slack variables would like search converge local minimum without oscillations boundary feasible region trajectory outside feasible region done proposed maxq method without loss generality ignore equality constraints following discussion sim plicity knowing equality constraints handled way described section 1 maxq method transforms inequality constraint follows q control parameters determined later given x augmented lagrangian function important choose suitable control parameters q affect convergence speed method one easily show q 1 inequality constraint equivalent equality constraint suppose q constant using dynamic system similar 911 solve lagrangian function 16 need evaluate partial derivative 5x p x x continuous derivative l q x continuous g however continuity derivatives required differentialequation solvers lsode reason require q 1 15 one way selecting q make close 1 namely 1 point dynamic system approach feasible region slowly saddle point boundary feasible region true p 0 independent far current point x away feasible region thus larger control parameters q needed fast convergence current point x far feasible region contrast choose meaning lsode converges slowly towards saddle point boundary feasible region taking facts account order fast convergence adapt q dynamically search goes saddle point since different inequality constraints may different convergence rates saddle point associate inequality constraint g x 0 control parameter q parameter updated dynamically based value g x q large g x ae 0 q gradually reduced value approaching 1 search close saddle point boundary one possible choice q follows two parameters control shape function q x g x approaches 0 q approach 1 dynamic equation solve 16 dt dt proof assume q takes form 17 2 choice fast 1 0 near saddle point making difficult lsode find suitable step size order reach saddle point let gradient change smoothly set note 16 similar 7 sense use max function main difference 16 avoids case 7 inequality constraint g xt 0 satisfied time g xt also appears lagrangian function g xt satisfied meaningful minimize fx independent value g xt 23 convergence properties maxq method two types saddle points x shown figure 3 saddle point x within feasible region ie means equilibrium point dynamic system 1819 given dt dt thus trajectory controlled 1819 converge saddle point x saddle point x boundary feasible region shown figure 3b asymptotically approached outside feasible region right side figure 3b order prove need show x asymptotically regular point constraints transformed equivalent equality constraint x boundary feasible region addition x gamma x 1 taking limits obtain lim lim therefore lim xx 5 according 20 means asymptotically regular point x p x original constraint g x 0 since saddle point exists must regular point g x 14 x asymptotically reached dynamic system 1819 feasible region feasible region b figure 3 relationship saddle point feasible region saddle point within feasible region b saddle point boundary feasible region 24 dynamic conversion inequality constraints equality ones maxq discussed solution x boundary feasible region ie equals zero dynamic system 1819 cannot reach point exactly point approached precision proportional convergence condition lsode solver however may take long time even q changed dynamically happens violation constraint g x small current point xt close boundary x right side figure 3b consequently increment corresponding lagrange multiplier small leading slow progress towards saddle point suppose know g j x solution case faster convergence achieved consider g j x equality constraint rather inequality constraint difficulty however impossible know advance inequality constraints g j x 0 satisfy boundary condition ie solution boundary utilize property xt close boundary respect particular inequality constraint g j xt positive close zero convergence constraint slow likely saddle point boundary respect constraint point dynamically convert inequality constraint g j xt 0 equality constraint g j improve convergence rate since solve dynamic system using lsode let x x 0 points two successive iterations conversion inequality constraint occurs following two conditions satisfied ffl dynamic system converges point x changes little window 10 iterations define current point slow convergence fmax experiments ffl dynamic system converges boundary g j x close zero experiments conditions important without first condition trajectory xt occasionally passes boundary g j xt would erroneously cause inequality constraints con verted makes sure trajectory really changes little period time second condition guarantees inequality constraints close boundary converted equality ones note dynamic conversion happen many inequality constraints time long satisfy two conditions dynamic conversion performed inequality constraint g j x 0 terrain lagrangian function l q x changed totally different maintain search direction originalvariable space x adjust lagrange multiplier j let current point conversion x j lagrangian term associated inequality constraint according conversion conditions derivative l j x j respect x j ih point conversion means apply equality constraint current point lagrangian term related g j derivative respect x j since control parameter q j close 1 search direction lagrangemultiplier space changes little meaning 5 j independent value j retain search direction originalvariable space x set 5 x l j x get 25 illustration maxq method slackvariable method introduce additional weight w original augmented lagrangian function maxq method weight objective lagrange multiplier equality constraints lagrange multiplier inequality constraints show maxq avoids divergence oscillations occur slackvariable method consider problem 23 defined 12 6 starting point middle search space used slackvariable method three cases tested scaling scaling objective 10 ie scaling objective 15 converge similar behavior figure 4 shows second case obviously maxq smoother better convergence property compared slackvariable method solution problem 23 boundary feasible region shown figure 3b since lagrange multipliers zero initially objective function fx takes effect lagrangian function causing trajectory move away feasible region lagrange objective iterations 1000 violation iterations 1000 figure 4 objective maximum violation converge smoothly using maxq problem 23 defined 12 6 w 1 number iterations required large 94000 multipliers increase pushing trajectory back towards boundary hence objective function value increases value maximum violation decreases see figure 4 note gap current implementation maxq theoretic result sense analytic proof requires 17 lsode uses 30 gap causes maxq method converge slowly sometimes like case shown figure 4 requires 94000 iterations example maxq reduces constraint violation quickly beginning slowly afterwards problem solved two approaches first use another differentialequation solver insensitive quick changes gradients making analytic result hold search investigated future second adaptively adjust relative weight w objective constraints search soon detect divergence oscillations slow convergence w adjusted accordingly apply strategy slackvariable method 34 able eliminate divergence reduce oscillations greatly speed convergence discuss application strategy maxq method next section 3 adaptive lagrangemultiplier method last section studied two methods handle inequality constraints shown slackvariable method sensitive relative weights objective constraints implementation may diverge oscillate converge although maxq method oscillate sensitive relative weights careful weighting may help accelerate convergence speed proper weights fast convergence however problemdependent impossible choose advance section describe strategy maxq dynamically adapt weights based behavior search progress based strategy developed slackvariable method 34 31 dynamic weightadaptation strategy lagrangian methods rely two counteracting forces resolve constraints find highquality solutions constraints satisfied lagrangian methods rely gradient descents objective space find local minima hand constraints methods rely gradient ascents lagrangemultiplier space order increase penalties unsatisfied constraints force constraints satisfaction 1 set control parameters time interval 4t initial weight maximum number iterations max 2 set window size 3 iteration number 4 j max stopping condition satisfied 5 advance search trajectory 4t lsode get x 6 trajectory diverges reduce w restart algorithm going step 2 7 record useful information calculating performance metrics 8 j mod nw test whether w modified end window 9 compute performance metrics based data collected 10 change w conditions satisfied 11 end figure 5 framework dynamic weightadaptation algorithm balance gradient descents gradient ascents depends magnitudes lagrange multipliers play role balancing objective fx constraints hx gx controlling indirectly convergence speed solution quality lagrangian method saddle point forces due descent ascent reach balance appropriate lagrangemultiplier values combining augmented lagrangian functions 8 25 get general augmented lagrangian function follows w relative weight lagrange multiplier equality constraints inequality constraints l ineq x depends way deal inequality constraints slackvariable method maxq starting initial point x0 0 0 dynamic system find saddle points dt dt dt figure 5 outlines algorithm basic idea first estimate initial weight step 1 measure performance metrics search trajectory xt periodically adapt wt improve convergence time solution quality let max total logical time search max divided small units time 4t maximum number iterations assume stopping condition search stop max step 4 given starting point set initial values lagrange multipliers zero ie point th iteration v max maximum violation defined 14 objective iterations 1000 violation iterations 1000 figure objective maximum violation converge 756 iterations maxq using dynamic weight adaptation initial monitor progress search trajectory divide time nonoverlapping windows size nw iterations step 2 window compute metrics measure progress search relative previous windows q th window calculate average value v max using 14 iterations window search employ lsode solve dynamic system 2729 advance trajectory time interval 4t iteration order arrive point x point test whether trajectory diverges step 6 divergence happens maximum violation v max larger extremely large value eg 10 20 happens reduce w large amount say w w10 restart algorithm iteration also record statistics v max used calculate performance metrics window step 7 end window every nw iterations step 8 decide whether update w based performance metrics 30 step 9 current implementation use average value maximum violation v max general applicationspecific metrics also used based measurements adjust w accordingly step 10 explained section 25 major problem maxq sometimes slow convergence measured fast maximum violation decreases therefore monitor reduction v q average value maximum violation found decrease slowly ie threshold eg reduce weight w half w w2 effect put weight constraints thus pushing trajectory quickly feasible region note comparing values two successive windows q must use weight w otherwise comparison meaningful terrain may different hence adapting w wait least two windows changing 32 illustration weightadaptation strategy maxq use dynamic weightadaptation method set time interval size corresponding figure 4 start initial weight starting point x0 0 0 figure 6 shows resulting search profile search converges using 756 iterations significantly better 94000 iterations without weight adaptation important note solution quality figure 4 obtain objective value gamma1125 search converges remaining issue algorithm choose good starting value large difficult constraints satisfied resulting slow convergence maxq w0 small objective underweighted search may converge worse saddle point studying many benchmark problems 6 found set starting points search ones given 6 slackvariable maxq methods work well suggests us start experiments small number problems may still need adaptation w search 4 global search saddle points lagrangian method presented last two sections looks single saddle point behaving like local search find multiple saddle points globalsearch methods needed bring search local saddle points section present global search strategy followed description tracebased search method first describe previous work solving unconstrained nonlinear optimization problems since dynamic system solving lagrangian formulation treated unconstrained nonlinear optimization problem 41 previous work unconstrained nonlinear optimization unconstrained nonlinear optimization general multimodal following features flat regions may mislead gradientbased methods b gradients may differ many orders magnitude making difficult use gradients gradientbased search method c existence many local minima may trap search methods leading suboptimal solutions based observations global search methods able use gradient information descend local minima able escape local minima gets search methods classified local global local search algorithms gradientdescent newtons methods find local minima efficiently work best unimodal problems globalsearch algorithms contrast employ heuristic systematic strategies look global minima stop finding local minimum 18 29 14 note gradients hessians used local globalsearch methods 29 localsearch algorithms difficulty surface flat gradients close zero gradients large range surface rugged gradients vary greatly search may progress slowly gradients small may overshoot gradients large function surface rugged local search randomly chosen starting point likely converge local minimum near starting point results solution worse global minimum moreover algorithms may require properly chosen parameters incorrectly chosen parameters may cause slow unstable convergence avoid getting stuck local minima localsearch methods many globalsearch methods developed methods rely local search determine local minima focus bringing search local minima gets deterministic methods developed apply deterministic heuristics bring search local minimum covering generalized descent methods 29 24 10 deterministic methods work well search space large covered adequately 29 9 4 trajectory methods rely internal force momentum trajectory continue move trajectory gets local minimum work well gradients steep search space rugged probabilistic methods hand rely probability make decisions simplest probabilistic algorithm uses restarts bring search local minimum little improvement made locally 20 35 36 advanced methods rely probability indicate whether search ascend local minimum simulated annealing one methods accepts uphill movements 22 30 2 3 21 13 based probability stochastic methods rely probability decide intermediate points interpolated new starting points random recombinations mutations evolutionary algorithms 8 algorithms weak either local search 14 global search 9 29 24 23 instance gradient information useful local search well used simulated annealing evolutionary algorithms contrast gradientdescent algorithms multistart weak global search probabilistic methods utilize sampling determine terrain decide search 24 16 29 31 strategies may fail terrain rugged search gets trapped deep suboptimal basin happens clustering methods whose performance similar random restarts terrain rugged 24 28 bayesian methods also work well samples collect randomly error surface close average error value samples inadequate model behavior minimal points 27 17 29 31 addition computationally expensive usually applicable problems twenty variables 42 novel tracebased search method find saddle points 26 eq 27 performs descents originalvariable space locate local minima objective function constraints satisfied whereas 2829 perform ascents lagrangemultiplier space constraints violated interested move trajectory one saddle point feasible space another without restart search add external force pull search saddle point originalvariable space continuously escapes without restarts 32 26 three features exploring solution space locating promising regions finding saddle points exploring solution space search guided continuous terrainindependent trace get trapped local saddle points trace usually aperiodic continuous function runs bounded space continues move search space independent local gradients locating promising regions tracebased method uses local lagrangian search attract search saddle point relies trace pull little improvement found finally tracebased method selects one initial point promising local region uses initial points lagrangian search find saddle points exploring search space trace plays important role discovering regions new local saddle points trace continuous aperiodic function logical time generates trajectory time trace trajectory start point trace moves point x 1 point x 2 trajectory moves point 1 2 2 function local gradient 1 distance x 1 1 see figure 7 two forces descent local saddle point attraction exerted trace form composite vector represents route taken trajectory trace function trajectory 1 trajectory 2 trajectory 3 trace trace direction moving direction gradient direction trajectory figure 7 novel two phases global search local refinement globalsearch phase trajectory combines lagrangian search pull exerted moving trace localsearch phase trajectory sampled collect starting points pure lagrangian searches dealing constrained problems formulated lagrangian functions two different sets variables original variables x lagrange multipliers intuitively need trace lagrangian space lagrange multipliers responsible bring trajectory feasible region involve finding local minima trace pulls search local saddle point enters infeasible region corresponding lagrange multipliers automatically increased based dynamic system push trajectory back feasible region sense lagrange multipliers passive since change constraints one also uses trace function lagrangian space force imposed trace lagrange multipliers may contradict short trace affect search lagrangemultiplier space defined 28 29 strategy corrects problem original tracebased strategy presented 32 uses trace lagrangian space overall dynamic system nonlinear constrained optimization follows dt dt dt g constants controlling relative weights local search global exploration note proposed method trajectorybased method differs existing trajectorybased methods rely internal forces modify trajectory instead uses external force traveling problemindependent trace pull trajectory local minima design good trace function tx important method relies travel solution space four criteria considered first trace aperiodic return starting points regenerates possibly trajectory second trace needs continuous order differentiable allows generated trajectory follow terrain continuous manner without restarting new starting points third trace bounded explore unwanted regions last trace designed travel coarse fine examines search space greater details time allowed since analytic approach design good trace function intractable studied heuristic functions finetuned 25 following summarize observations ffl tracebased method finelevel global search sense search space covered trace grows linearly length trace therefore time complete algorithm however search space grows exponentially respect number dimensions hence tracebased method give good coverage search space large overcome limitation method may need combined coarselevel global searches simulated annealing genetic algorithms hybrid approach work well constrained optimization problems existing coarselevel globalsearch algorithms generally difficulty satisfying constraints starting points constraints violated usually lead good feasible solutions ffl tracebased method relies distance current position trace trajectory pull trajectory local saddle points local gradients large external force due trace may enough pull trajectory local saddle points address problem developed dynamic variable scaling method scales variable dimension gradient trajectory dimension exceeds threshold eg scaling reduces local gradient trajectory also increases distance trace trajectory thereby providing adequate force pull trajectory local saddle points controlling scaling factor able explore larger search space based substantial experiments designed aperiodic trace function follows represents ith dimension ae coefficient specifying range n dimension original variable space x described tracebased method using one trace function general method cascaded using output trajectory one stage trace next stage bootstrapping allows trajectories later stages go deeper local region thereby providing better starting points localsearch phase figure 7 shown three stages globalsearch phase outputs trajectory based 31 first stage global search userdefined trace function leads trajectory form trajectory 1 figure 7 second third stages global search trace function tx trajectory previous stage using trajectories output three stages identify set promising starting points perform local lagrangian searches final result best solution among local searches implementation output trajectory collection discrete sample points continuous trajectory interpolations performed form continuous trace next stage generally weights g different values different global stages example set large values relative g first stage global search emphasized later stages g larger values search focused local region simplest case g set constants values stages experiments set g 1 stages implemented maxq adaptive weighting tracebased search prototype novel nonlinear optimization via external lead extends previous work tracebased search 32 26 prototype solve nonlinear constrained well unconstrained optimization problems applied solve design problems signal processing 33 neuralnetwork learning 26 benchmark problems operations research results latter presented next section 5 experimental results section describe experimental results existing benchmarks 6 benchmarks challenging model practical applications studied extensively past result improvements generally difficult use common set parameters including step size trace function solve problems reason tuning parameters avoid bias good solutions always obtained sufficient tuning set starting points novel suggested benchmark set exception problemspecific search range trace set manually based solutions reported benchmarks practice reasonable search ranges generally known cases search range available use trial error starting small range gradually increasing improvement solutions found globalsearch phase novel used three stages produce three trajectories see figure 7 using chose 100 starting points trajectory based lagrangian values lagrangian searches 300 lagrangian searches report best solution table 1 summarizes results found novel column 1 lists problem identifications appear benchmark collection 6 column 2 shows problemdependent search range trace covers column 3 shows best known solutions reported 6 column 4 solutions reported epperly 5 symbol gamma means method unable find solution corresponding problem column 5 shows results obtained novel using slackvariable method dynamic weightadaptation strategy described section 3 used without using adaptive weights half problems cannot solved due divergence oscillations described section 21 last column shows results obtained novel using maxq results bold font improved novel best known results improvements 10 results indicate novel robust discovering new regions escaping local traps 6 conclusions paper studied three strategies improve lagrangian searches solving nonlinear constrained optimization problems first studied new method called maxq convert inequality constraints equality constraints lagrangian search using new constraints approaches saddle points boundaries feasible regions without oscillations overcomes problems oscillations divergence inequality constraints converted adding slack variables second developed method adaptively adjust relative weights objective constraints lagrangian formulation show adaptive weighting improve convergence speed lagrangian methods without affecting solution quality finally applied tracebased search bring trajectory one saddle point another continuous fashion method generates informationbearing trajectories table 1 results collection constrained optimization benchmarks 6 comparing novel using maxq novel using slackvariable method epperlys method 5 search times cpu seconds sun ss 1051 improved solutions found maxq indicated bold font symbol gamma means method able find solution corresponding problem problem novel search best known epperlys slack variable maxq id range solutions solutions solutions solutions 21 10 gamma1700 gamma1700 gamma1700 gamma1700 22 100 gamma21300 gamma21300 gamma21300 gamma21300 23 100 gamma1500 gamma1500 gamma1500 gamma1500 24 100 gamma1100 gamma1100 gamma1100 gamma1100 25 10 gamma26800 gamma26800 gamma26800 gamma26800 26 10 gamma3900 gamma3900 gamma3900 gamma3900 272 400 gamma88475 gamma88475 gamma88475 gamma88475 28 250 1599000 1599000 1563900 1563900 31 32 500 gamma3066550 gamma3066550 gamma3066550 gamma3066550 33 100 gamma31000 gamma31000 gamma31000 gamma31000 34 50 gamma400 gamma400 gamma400 gamma400 43 50 gamma451 gamma451 gamma451 gamma451 44 50 gamma2217 gamma2217 gamma2217 gamma2217 45 50 gamma1196 gamma1340 gamma1340 gamma1340 46 50 gamma551 gamma551 gamma551 gamma551 47 50 gamma1674 gamma1674 gamma1675 gamma1675 52 500 1567 gamma 1567 1567 54 500 186 gamma 186 186 62 1000 40000 40000 40000 40000 63 1000 60000 60000 60000 60000 64 1000 75000 75000 75000 75000 72 1000 5682500 gamma 5682500 5682500 73 74 global search based userdefined trace function samples trajectories good starting points local search overcomes problem using random restarts trajectory already vicinity good saddle points applied maxq adaptive weighting tracebased search novel 32 26 global optimization system developed earlier solve constrained well unconstrained optimization problems tested many benchmark problems derived manufacturing computed aided de sign engineering applications compared maxq method based slack variables 14 epperly 5 results show maxq robust convergence found solutions either better existing solutions future work area finding better trace functions parallelizing execution massively parallel computers studying challenging applications neuralnetwork learning signal processing r global minimization reducing duality gap generalized simulated annealing function optimization minimizing multimodal functions continuous variables simulated annealing algorithm extended continuous newton method global optimization nonconvex nonolinear programs using parallel branch bound collection test problems constrained global optimization algorithms recent advances global optimization introduction simulated evolutionary optimization global optimization using interval analysis global optimization deterministic approaches adaptive simulated annealing asa adaptive simulated annealing algorithm global optimization continuous variables random tunneling means acceptancerejection sampling global optimization genetic algorithms bayesian approach global optimization application bayesian approach numerical methods global stochastic optimization complexity numerical optimization constrained global optimization algorithms applica tions pure adaptive search monte carlo optimiza tion combined multistartannealing algorithm continuous global optimization simulated annealing constrained global optimization convergence baba dorea random optimization methods stochastic techniques global optimization survey recent advances global search methods solving nonlinear optimization problems global optimization neural network training global search method optimizing nonlinear systems topographical global optimization monte carlo simulated annealing approach optimization continuous variables global optimization qmf filterbank design using novel improving performance weighted lagrange multiple methods constrained nonlinear optimization pure adaptive search global optimization improving hitandrun global optimization tr ctr global optimization algorithm using lagrangian underestimates interval newton method journal global optimization v24 n3 p349370 november 2002