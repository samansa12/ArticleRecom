mining constrained gradients large databases many data analysis tasks viewed search mining multidimensional space mds mdss dimensions capture potentially important factors given applications cells represent combinations values factors systematically analyze data mds interesting notion called cubegrade recently introduced imielinski et al check end sentence focuses notable changes measures mds comparing cell refer probe cell gradient cells namely ancestors descendants siblings call queries gradient analysis queries gqs since mds contain billions cells important answer gqs efficiently study focus developing efficient methods mining gqs constrained certain weakly antimonotone constraints instead conducting independent gradientcell search per probe cell inefficient due much repeated work propose efficient algorithm livesetdriven algorithm finds good gradientprobe cell pairs one search pass utilizes measurevalue analysis dimensionmatch analysis setoriented manner achieve bidirectional pruning sets hopeful probe cells hopeful gradient cells moreover adopts hypertree structure hcubing method compress data maximize sharing computation performance study shows algorithm efficient scalable addition data cubes extend study another important scenario mining constrained gradients transactional databases item associated measures price transactional databases viewed sparse mdss items represent dimensions although significantly different characteristics data cubes outline efficient mining methods problem paper b introduction recently growing interests multidimensional analysis relational databases transactional databases data warehouses analysis involve data cubebased summary transactionbased association analysis however many interesting applications one may want analyze changes measures multidimensional space example one may want ask associated significant changes average house price vancouver area year 2000 compared 1999 answer could include statements form average price sold professionals west end went 20 sold business people metrotown went 10 etc expressions professionals west end correspond cells data cubes describe sectors business modeled data cube problem mining changes sophisticated measures multidimensional space first proposed imielinski et al ika02 cubegrade problem viewed generalization association rules data cubes studies changes set measures aggregates interest associated changes underlying characteristics sectors changes sector characteristics expressed terms dimensions cube limited specialization drilldown generalization rollup mutation change one cubes dimensions example one may want ask kind sector characteristics associated major changes average house prices vancouver area 2000 answer pairs sectors associated major changes average house prices including example sector professional buyers west end area vancouver vs sector buyers entire area vancouver specialization cubegrade query significantly expressive association rules since captures trends data handles arbitrary measures count association rules problem interesting broad applications trend analysis answering whatif questions discovering exceptions outliers etc however also poses serious challenges understandability results computational eciency scalability illustrated 1 data cube may many dimensions even though dimension may involve small number values total number cells data cube may still quite huge example data cube 20 dimensions containing 99 distinct values high level cells even one nonempty cell every cells cube huge precomputed stored reasonable resources transactional database consider item milk bread one independent dimension ika02 may need handle thousands dimensions curse dimensionality even worse classical data cubes usually contain dozens dimensions eective compromise problem compute iceberg cubes instead complete cubes br99 end need introduce significance constraint pruning huge number trivial cells answer set 2 cubegrade problem needs compare cell cube associated cells generated specialization generalization mutation even considering iceberg cubes may still generate large number pairs since analysis task user often interested examining small subset cells cube desirable enforce certain probe constraints select subset cells called probe cells possible cells focus points examination using constraint one focused cells relationships corresponding siblings ancestors descendants 3 user usually interested certain types changes cells sectors comparison example one may interested cells whose average profit increases 40 compared probe cells etc changes specified threshold form ratiodierence certain measure values cells comparison call cell captures change probe cell gradient cell call constraints gradient interestingness constraints discussion one see mine interesting gradients multidimensional space often necessary following three kinds constraints 1 significance constraint ensures produce cells certain statistical significance data containing least certain number base cells least certain total sales 2 probe constraint confines set probe cells gradient analysis focus 3 gradient constraint specifies users range interest gradient ie measure change paper consider significance constraints specified using thresholds measures antimonotone weakly antimonotone see section 2 restrict probe constraints nonnested sql queries enforcing constraints may lead interesting clearly understandable answers well possibility derive ecient methods gradient analysis multidimensional space context problem multidimensional gradient analysis constraints represents confined interesting version cubegrade problem call constrained multidimensional gradient analysis paper study ecient scalable methods constrained gradient analysis multidimensional space study focused mining constrained gradients data cubes however also examine extend method mining constrained gradients transactional databases mining constrained gradients data cubes first consider naive approach computes gradients conducting search gradient cells per probe cell 1 approach inecient large amount repeated work dierent probe cells avoid problem propose ecient algorithm called livesetdriven algorithm utilizes constraints early computation computing pairs cells algorithm first computes set significant probe cells processes potential gradient cells low dimensional cells high dimensional ones computation set probe cells bundled together set live probe cells used pruning introduce method determine optimal set probe cells needs used pruning potential gradient cell descendants takes consideration dimensional relationship cells gradient constraint respect set probe cells moreover compressed hypertree structure used represent base table data cube hcubing method used achieve maximal sharing computation among dierent cells even though naive algorithm also prunes much possible livesetdriven algorithm much better uses setoriented processing ii setoriented pruning iii onepass search probegradient pairs performance study shows livesetdriven algorithm makes good use constraints ecient scalable large data sets finally extend scope study ecient mining constrained gradients transactional databases outlined probebased fpgrowth method constrained gradient mining rest paper organized follows section 2 defines constrained gradient analysis problem presents example section 3 presents methods mining constrained gradients data cubes including livesetdriven algorithm covers techniques pruning probe cells gradient cells section 4 reports results experiments performance study section 1 since gradient constraint pairs cells whereas significance probe constraints individual cells believe significance probe constraints combined usually restrictive gradient constraint consider approaches first use significance probe constraints restrict search space 5 discusses variations method extends scope study mining constrained gradients transaction databases compares related work finally conclude study section 6 problem definition assumptions let relational table called base table given cube set attributes partitioned two subsets dimensional attributes dim measure attributes measure attributes functionally depend dimensional attributes defined context data cube using five sql aggregate functions count sum avg max min tuple schema multidimensional space ie context data cube called cell given three distinct cells c 1 c 2 c 3 c 1 ancestor c 2 c 2 descendant c 1 every dimensional attribute either c 1 c 2 share value c 1 value indicates ie aggregated highest level dimension c 2 sibling c 3 vice versa c 2 c 3 identical values dimensions except one dimension neither value cell k non values called kd cell tuple c called base cell base cell descendant cell c aggregated cell ancestor base cell aggregated cell c values measure attributes derived complete set descendant base cells c mentioned section 1 specification constrained gradient analysis problem requires three constraints significance constraint c sig probe constraint c prb gradient constraint c grad c sig c prb unary defined cells cell c significant cell c sig c true cell c probe cell c significant c prb true complete set probe cells denoted p significance constraints usually defined threshold conditions measure attributes constraints antimonotonic 2 example measure defined avg aggregate function hpdw01 methods deriving weaker antimonotonic constraints 3 2 antimonotonicity useful pruning states cell c satisfy antimonotonic significance constraint csig none cs descendants example constraint count 10 antimonotone anti monotonicitybased pruning forms foundation algorithms computing iceberg cubes 3 call constraints one derive weaker antimonotone constraints weakly antimonotone nonantimonotonic constraints eciently computing iceberg cubes discussed use weaker antimonotonic constraints pruning candidate cells assume probe constraint onelevel sql query without nested query select set userdesired cells query involve dimensional attributes well measure attributes gradient constraint binary defined pairs cells form c grad c v constant value g gradient function gc g c p defined c g either ancestor descendant sibling c p gradient cell c g interesting respect probe cell c p p c g significant c grad c g c p paper mainly consider gradient constraints defined using ratio two measure values mc g mc p v mc measure value cell c results derived ratio easily extended dierence mc g mc p v see section 5 problem definition given base table significance constraint c sig probe constraint c prb gradient constraint c grad c g c p constrained gradient analysis problem find complete set interesting gradientprobe pairs c g c p c grad c g c p example 1 constrained average gradient let base table sales table schema city cust grp prod grp cnt avg price attributes year city cust grp prod grp dimensional attributes cnt avg price measure attributes table 1 set base aggregated cells table 1 shows set base aggregated cells tuple c 1 base cell tuple c 2 aggregated cell value cnt aggregated cell c sum corresponding values complete set descendant base cells c value avg price c average price complete set descendant base cells c constraints tuple c 3 sibling c 2 c 4 ancestor c 2 c 1 descendent c 2 suppose significance constraint c sig cnt 100 cells including base aggregated ones cnt less 100 regarded significant suppose probe constraint c prb cust set probe cells p contains set aggregated tuples sales business customer group vancouver every product group provided cnt tuple greater equal 100 easy see c 2 p let gradient constraint c grad c 14 constrained gradient analysis problem specified three constraints find pairs c g c p c p probe cell p c g sibling ancestor descendant c p c g significant cell c g average price least 40 c p data cube completely materialized aggregated cells computed stored without considering constraints query posed example 1 becomes relatively simple retrieval pairs computed cells satisfy constraints unfortunately number aggregated cells often huge precomputed stored thus assume base table available task compute gradientprobe pairs eciently confine discussion first develop ecient methods computing constrained average gradients posed example 1 extend scope general cases section 5 3 mining constrained gradients data cubes section examine ecient methods mining constrained gradients data cubes first outline relatively rudimentary algorithm allsignificantpairs analyze deficiencies propose better algorithm called livesetdriven uses set relevant probe cells called liveset prune potential gradient cells iterative exploration moreover htree structure developed ecient computation minimal replication data rough analysis given last subsection compare runtime two algorithms discussed section 1 believe often case significance probe constraints combined restrictive gradient constraint consider approaches first use significance probe constraints restrict search space 31 rudimentary allsignificantpairs constrained gradients mined rudimentary algorithm called allsignificantpairs first computes iceberg cube p consisting significant probe cells using significance constraint c sig probe constraint c prb probe cell c p p computes set gradient cells using gradient constraint c grad c g c p steps carried using ecient iceberg method use constraints prune search one use ecient iceberg cube computation algorithm buc br99 hcubing hpdw01 see brief descriptions section 34 implementation used latter method computation first step use significance constraint c sig probe constraint c prb computation second step uses gradient constraint c grad c g c p optimization explored prune search ancestors andor descendants probe cell c p based antimonotonic relationships gradient measure antimonotonic function count sum positive items one explore following property measure cell c greater none cs descendants measure greater measure cell c less none cs ancestor measure less gradient measure antimonotonic function average sum positive negative elements one explore weaker antimonotonic constraint prune ancestors andor descendants example average one explore property topk average 4 hpdw01 topk average base cells cell c greater k significance constraint threshold value none cs significant descendants average value greater similarly one derive many interesting properties facilitate pruning constraints involving complex measures example 2 allsignificantpairs lets examine perform constrained gradient analysis problem specified example 1 using allsignificantpairs method first compute significant probe cells data cube applying ecient iceberg cube computation algorithm hcubing hpdw01 significance constraint c sig cnt 100 probe constraint c prb cust 4 multiset values define topk average average topk values multiset example top3 average multiset 2 4 5 5 8 6 topk average cell topk average measure values cell yield set probe cells eg c business pc 800 1900 let set significant probe cells p probe cell c p p compute set gradient cells using gradient constraint performing possible pruning ancestors andor descendants gradient cell currently examination computation proceeds toplevel ie first computing highlevel cells descendants cell c g topk average value 5 100 minimum support threshold ie significance constraint c p 14 c g descendants pruned since none satisfy gradient constraint algorithm summarized follows algorithm 1 allsignificantpairs input base relational table significance constraint c sig probe constraint c prb gradient constraint c grad output complete set gradientprobe pairs data cube derived satisfy three constraints 1 apply iceberg cube computation algorithm hcubing compute set p using significance constraint c sig probe constraint c prb 2 probe cell c p p compute ancestor descendant sibling cells based cell gradient constraint c grad c g c p computation also carried way similar hcubing search c p descendants ancestors pruned c p satisfy certain transformed constraints obtained c grad c g c p c p measures algorithm suers following major deficiency search gradient cells done onesearchloopperprobecell fashion huge amount repeated work performed probe cells similar may involve computing set gradient cells p times p number probe cells p costly subsequent discussion propose better algorithm overcome deficiencies 5 ecient computation topk average discussed hpdw01 detailed also section 4 32 livesetdriven algorithm avoid waste resource computing cells unrelated probe cells could preferable first compute set iceberg probe cells p using probe significance constraints second step use set derived iceberg probe cells p eciently constrain search interesting gradientprobe cell pairs using gradient constraint similar golden rule pushing selection deeply relational query processing aim design algorithm additional bonus second step algorithm check significant cells allsignificantpairs examine significant cell ie one pass use probe cells constrain search optimized way make computation second step ecient several techniques developed outlined 1 using sets probe cells constrain processing avoid costly repetition computation allsignificantpairs algorithm propose use setoriented processing optimization roughly speaking associate gradient cell set possible probe cells might cooccur interesting gradientprobe pairs descendants gradient cell use set prune future gradient cell search space 2 lowtohigh dimension growth multidimensional space explored progressive confined manner using iceberg growth approach start lower dimensional cells proceed higher dimensional ones advantageous usually smaller number lower dimensional cells higher dimensional ones antimonotonicity property significance constraints weaker versions transformed gradient cell constraints used prune remaining search space kd cell fails satisfy constraint descendants higher dimensional cells three types constraints ie probe significance gradient constraints used iceberg growth process 3 dynamic pruning probe cells growth dimension growth process increasingly probe cells fail associated higher dimensional gradient cells due dimension value mismatch relevant measure value gradient range thus one prune set probe cells associated gradient cells growth search terminates either significant gradient cells generated none probe cells proceed pruning probe cells increases power prune gradient cells 4 incorporation compressed data structure htree ecient iceberg growth algorithm hcubing ecient computation iceberg cubes also incorporate compressed data structure htree extend ecient iceberg growth algorithm hcubing data structure algorithm shown highly ecient computing iceberg cubes complex measures hpdw01 allow us maximal sharing cells computation enhances eciency constrained gradient analysis 321 pruning gradient cells probe cells using gradient constraints suppose p set probe cells computed next step computation determine cell gradient cell associated probe cell produce valid gradientprobe pairs computation start low dimensions proceed higher dimensions depthfirst manner information low dimension gradient cells used prune higher dimension cells study pruning performed need introduce concepts liveset probe cells potential cell gradient cells 1 live set gradient cell c g denoted livesetc g set probe cells c p possible c g c p interesting gradientprobe pair descendant cell c g c g definition clear smaller liveset gradient cells pruned determination liveset involves gradient constraint matches dimensions gradient probe cells section deals former next section extends deal latter interestingly pruning done directions livesetc g c obviously livesetc g used determine c g descendants potential interesting gradient cells wrt probe cell livesetc g c g pruned b information c g also used prune probe cells c p livesetc g involves checking whether c g descendants potential interesting gradient cells wrt c p answer c p pruned livesetc g make precise meaning potential interesting gradient cells wrt set probe cells gradient cell c p set probe cells c grad gradient constraint say c g descendants potential interesting gradient cells wrt c p following true 1 gradient constraint antimonotone sum constraint c grad c g c p satisfied c p c p 2 gradient constraint antimonotone avg pricec g avg pricec f transformed weaker constraint potentially satisfied c p c p represents topk average k minimum support threshold ie significance constraint observe avg k constraint weaker antimonotonic constraint constructed nonantimonotonic avg constraint say gradient cell c g potential cell potential grow c g significant ii c g descendants potential interesting gradient cells wrt livesetc g observations nonantimonotonic constraint though cannot used pruning transformed weaker antimonotonic constraint pruning 2 use avg k pricec g upper estimate avg pricec g significant descendant cells c g c g illustrate example example 3 using schema example 1 suppose c grad c 14 assume set probe cells p derived using two constraints c sig c prb let c g 1d cell 00 assumed significant suppose initially 6 livesetc g following subset c v ancouver business 2800 1500 c p 2 oronto education pc 450 2000 illustrate two scenarios potential grow however 25003000 25002000 14 c p 2 c p 3 pruned livesetc g 6 next section discuss liveset derived potential grow thus pruned lets consider use set c p probe cells prune gradient cells avg pricec p known every c p c p given gradient cell c g clearly ecient check individual probe cells c p liveset whether condition avg k pricec g avg pricec p 14 holds fortunately one derive overall gradient cell constraint set c p c gcell c p specifies range measure values average prices c g must satisfied gradient cell c g c g might cooccur interesting gradientprobe pairs probe cell c p example minimal avg price c p c p 1200 optimal gradient cell constraint c gcell c upper estimate avgc significant descendant cell c g avg k c g cannot satisfy constraint avg k c g 1680 none descendants satisfy either c g pruned gradient constraint analysis general following property 31 gradient cell constraint set probe cells c grad mc g mc p v v constant value mc p 0 gradient cell constraint corresponding set probe cells c p c gcell c p property used derive gradient cell constraint set probe cells 322 pruning probe cells dimension matching analysis previous subsection described use gradient constraint prune probe cells gradient cells subsection describe probe cells associated gradient cell prune associated probe cells processing goes gradient cell descendant one dimensionmatching perspective dimension matching analysis made possible assumption interested gradientprobe pairs involving ancestordescendant descendantancestor siblingsibling pairs let c g gradient cell recall livesetc g denotes set probe cells c p possible c g c p interesting gradientprobe pair descendant cell c g c g hence dimensional perspective probe cell c p livesetc g c p ancestor descendant c g c g ii c p sibling descendant c g sibling c g turns conditions captured notion matchable defined next probe cell c gradient cell number solidmismatches two cells c p c g number dimensions values matched ie dierent values number mismatches c p c g number dimensions c p c g observe notion mismatches symmetric cells playing certain roles probe cell c p matchable gradient cell c g either c g c p solidmismatch exact one solidmismatch mismatch give example illustrate notion matchability example 4 consider 4d probe cell c matchable ancestor gradient cell c since c g1 contains neither mismatch solidmismatch c p matchable sibling c since c g2 contains one solidmismatch mismatch c p matchable c since c g3 contains one solidmismatch mismatch observe c g3 sibling parent c p c p matchable c since c g4 contains solidmismatch observe c p c g4 common descendant b c also c p matchable descendant c since c g5 contains one mismatch however matchable e since c g6 contains one solidmismatch one mismatch property 32 correctness dimension analysis c p matchable c g c p c g ancestor c g descendant c g sibling c g descendant c g rationale suppose c p matchable c g two cases arise c g c p solidmismatch let c obtained taking specific value dimension c g c p non values comparable non value specific value c descendant c g c descendant c p hence c p ancestor descendant c g special cases c ancestor c b c g c p exactly one solidmismatch mismatch let c obtained taking specific value dimension c g c p except c takes value c g dimension solidmismatch c descendant c g since mismatch c p c g specific value also occurs c p clearly c p c exactly one solidmismatch c p sibling c observe c c g case c p sibling c g omit details nontrivial cases illustrated example 4 discuss dimension analysis used pruning liveset processing goes gradient cell descendant one property 33 relationship livesets ancestordescendant cells let c g1 c g2 two gradient cells c g2 descendant c g1 livesetc g2 rationale let c p probe cell c g3 c p might exist interesting gradientprobe cell pair descendant cell c g3 c g2 since c g3 descendant c g1 well fact last statement implies c p also livesetc g1 property ensures produce liveset descendant cell ancestor cell way simply dimension matching analysis plus gradientbased pruning illustrate dimensionmatching based pruning using following example example 5 let c gradient cell let c descendant c g1 suppose livesetc g1 ie result pruning b1 c1 livesetc g1 notice expansions gradient cells follow particular order usually case pruning probe cells done example dimensions expanded left right descendants c g processed c g processed observe ancestordescendant relationship manytomany instance c descendant c g sibling c p b c1 would processed earlier c g depthfirst order thus c p counted liveset c g deal issue algorithmically call c g depthfirst descendant 7 c g c g descendant c g 7 provide syntactic definition depthfirst descendant let two mdimensional gradient cells roughly speaking cd depthfirst descendant cp cd expansion cp left ie common sux cd result instantiating remainder cp formally cd depthfirst descendant cp exists 1 p1 p2 c g processed later c g depthfirst order dimensionbased analysis need restrict liveset cell c depthfirst descendants c study assume set probe cells hence liveset usually small set sorted value ascending order according certain measure values see next subsection facilitate pruning using gradient constraint case large set tree structure hash table adopted fast accessing 33 livesetdriven algorithm based discussion livesetdriven algorithm worked computing gradientprobe pairs satisfy constraints first give informal description using example formal algorithm eciency issues regarding data structure htree manipulation hcubing discussed next subsection method starts 0d cell cube carrying initial set probe cells p liveset proceeds higher dimensional gradient cells along way uses given constraints prune gradient cells cannot satisfy liveset prune cells liveset cannot pass either gradient constraints dimensional matching analysis processing along branch terminates liveset becomes empty gradient cell potential generate interesting pairs lets examine example detail example 6 livesetdriven base table schema example 1 examine perform constrained gradient analysis livesetdriven algorithm let gradient constraint c grad c g c p ave pricec g avg pricec p 12 significance constraint c sig cnt 100 let set p probe cells given table 2 sorted avg price ascending order notice order important since probe cell table cannot satisfy gradient constraints cells following cannot satisfy either since carry even larger measure value thus pruned immediately set probe cells p initial liveset 0d gradient cell c 1500 lowest avg price value among current probe cells taken global gradient lower bound suppose top100 average 0d cell c 0 4000 count 50000 montreal business pc 1500 8000 edmonton ski 2000 10000 w hisler ski 1000 10050 table 2 set probe cells p c 0 potential grow 4000 12 top100 average c 0 used prune probe cells generate tighter liveset c 0 since fourth cell edmonton ski 2000 10000 cannot satisfy gradient constraint due 4000 12 10000 cell probe cells avg price higher 10000 liveset pruned actual average value c 0 decide probe cell paired cell become interesting gradientprobe pair computation proceeds process 1d cells 2d cells depth first manner avoid repetition sake clarity show processing done typical 3d cell suppose first three probe cells alive processing 2d gradient cell c oronto processing goes 2d cell 3d cell c probe cell mismatches montreal business pc 1500 8000 1 1 table 3 number mismatches probe cells first prune liveset c 2 using dimensionality matching c 3 number mismatches probe cell wrt c 3 presented table 3 1 indicates one solid mismatch 1 indicates one mismatch table 3 indicates first two probe cells remain alive respect 3d gradient cell c 3 actual average value c 3 decides probe cell paired cell become interesting gradientprobe pair avg pricec 3 first probe cell form interesting gradientprobe cell pair c 3 second minimum average cells liveset 1500 top100 average c 3 decide continue processing descendants c 3 top100 average c 3 less computation stops branch top100 average c 3 higher equal computation continues suppose top100 average c 3 1900 go back prune current liveset c 3 1900 1800 12 indeed prune second probe cell namely 99 oronto pc 4000 1800 liveset summary see processing gradient cell c involves steps derive initial liveset liveset ancestor cell c using dimension matching necessary measures topk average measures c computed checked liveset answers decide descendants c may require processing processing descendants needed prune liveset using gradient constraint topk average values present livesetdriven algorithm algorithm 2 livesetdriven input output algorithm 1 1 apply iceberg cube computation algorithm compute set iceberg probe cells p using significance constraint c sig probe constraint c prb 2 derive gradient cell constraint c gcell 3 initialize potential gradient cell 4 use bottomup depthfirst iceberg cubing method find interesting gradientprobe pairs depthfirst processing values dimension ordered dimensions also ordered every value dimension c significant live probe cell c p livesetc output gradientprobe pair c c p pair passes gradient cell constraint 2 use measure transformed measure topk value c prune livesetc 3 livesetc empty c potential grow terminate branch backtrack process next cell according depthfirst order 4 c potential grow expand next level according depthfirst order descendant cell c c processed expansion derive livesetc livesetc using matchability test 34 hcubing ecient data storage manipulation via htree shown br99 hpdw01 bottomup computation cubes ecient allows us use lowdimension cells prune high dimension cells one important issue realizing eciency much data copied around much computation shared section review spirit hypertree called htree structure hcubing algorithm allows us use minimal copying data maximal sharing computation tools useful computing iceberg queries hpdw01 constrained gradient analysis believe useful many types data cube computations backbone structure htree basic tree gives compressed representation base table uses auxiliary structures store necessary information facilitates sharing computation roughly speaking nodes hyper tree labeled attribute values prefix subpaths tree shared whenever possible auxiliary structures include header tables sidelinks quantitative information quantinfo quantinfo used help incrementally maintain information needed checking expensive constraints using weaker versions topk average one design quantinfo topk average constraint use small number bins estimate safe lower bound topk average value details found hpdw01 illustrate tree using example small base table schema customergroup month city price hypertree four tuples jan oronto 1200 520 inserted order shown figure 1 quantinfo shown designed deal topk average measures given base table attributes 1 htree defined follows 1 attributes 1 sorted cardinalityascending order r j 1 jm promote quantinfo business household education sum 2285 attribute value quantinfo sidelink montreal vancouver feb jan toronto header table root household education business jan march jan feb toronto vancouver toronto montreal bins figure 1 htree sharing since number values attribute roughly proportional number nodes level attribute 2 htree root node labeled null every node tree labeled attribute value quantinfo sidelink attached node necessary explained 3 htree header table h three fields attributevalue quantinfo sidelink attributevalue pair one row h omitted attributes figure 1 conciseness 4 tuple table inserted tree follows tuple jm p derived projecting attributes j 1 jm b path root j 1 jm used register tuple maximal prefix already existent tree used path lower subpath existing tree created c use p update quantinfo 1 leaf node path 2 entries j 1 jm header table h 5 leaf nodes common label linked together queue sidelinks sidelink field row jm jm header table h head queue jm jm htree several interesting properties facilitate computation data cube particular constructed scanning database sharing paths size usually small fact actual size tree notably smaller shown experimental results section 6 hpdw01 moreover one easily reconstruct information original table htree obtain ecient sharing carrying data cube computations associate multiple header tables one basic tree header table register information corresponding computation group cells sharing common structure example figure 2 header table left associated cells oronto montreal whereas header table right associated cells jan oronto f eb oronto business feb montreal household root jan toronto education jan toronto march header table h education household business jan feb march toronto montreal attrval quantinfo sidelink education household business jan feb march header table h toronto attrval quantinfo sidelink figure 2 htree oronto first illustrate computing done using htree suppose wish process cell oronto done using htree figure 1 quantinfo htree tells us topk average average cells form c city c row oronto header table h htree get avg k price avgprice oronto discuss reuse computation achieved hcubing htree first considering processing jan oronto descendant oronto create new header table call ht oronto figure 2 associated sidelinks contain information paths tree related city toronto sidelink oronto header table h links paths related city toronto traversing sidelinks 1 make copy quantinfo every leafnode labeled oronto parent node tree 2 build new header table h oronto collects quantinfo every attributevalue wrt city toronto 3 link parent nodes leafnodes labeled oronto identical labels updated tree shown figure 2 every parent node leaf node labeled oronto figure 2 copy quantinfo oronto leaf node new header table h oronto attribute values dimension customer group month needed quantinfo row jan collects complete quantinfo sales january toronto illustrate computation reused considering processing jan descendant involves rollup quantinfo dimension month every leaf node htree merges quantinfo parent node accepting quantinfo children parent node resets quantinfo nodes labeled common month matter children linked sidelinks also linked corresponding row header table h optimization quantinfo child node indicates avg k child passes average measure threshold parent node marked topk ok sum count information collected nodes binning needed since pass topk average checking already quantinfo rolling parent nodes nodes marked topk ok also similarly marked even though htree compresses database assume htree arbitrary database always held main memory discussion address problem handling large databases given hpdw01 35 rough comparison two algorithms since execution two algorithms depend data parameter settings hard impossible give closed formulas runtime however able oer rough comparison runtime follows observe algorithms use hcubing algorithm dierence performance due onepass setoriented processing pruning livesetdriven repeated computation allsignificantpairs let p denote set probe cells considered probe c p p let cc p denote set gradient cells examined allsignificantpairs algorithm let c denote set gradient cells examined livesetdriven algorithm c equal cpp cc p however note allsignificantpairs algorithm may examine gradient cell number times let rp denote average numbers moreover note livesetdriven algorithm incurs overhead order setoriented processing pruning let ovhd denote average overhead gradient cell see runtime livesetdriven roughly 1 runtime allsignificantpairs roughly rpc hence speedup livesetdriven algorithm roughly rp 1ovhd experiments show speedup usually approximately 10 fold performance analysis section report experimental results computing gradients data cubes results show livesetdriven algorithm scalable much faster allsignificantpairs algorithm see soon speed roughly proportional number probe cells noted earlier algorithms use probe significance constraints restrict set probe cells dierence execution times due following reasons allsignificantpairs algorithm independent search probe cell result leads much repeated search dierent probe cells hand livesetdriven algorithm bundles gradientcell search probe cells one pass uses techniques twoway pruning ie pruning probe cells using information gradient cell consideration pruning gradient cells using set probe cells experiments conducted pc intel pentium iii 700mhz cpu 256m main memory running microsoft windowsnt programs coded microsoft visual c 60 experiments conducted synthetic data sets generated using data generator described hpdw01 parameters generator include number n tuples base table number dimensions cardinality dimension min max range measure repeat factor dictates number tuples generated based model tuples uniform distribution noise factor percentages represent fraction n tuples generated using random distribution distort repeat factor generator uses rand function generates numbers range 0 1 following uniform distribution works repeatedly adding number new tuples 1 r get enough tuples using steps 14 follows dimensions randomly picked 1 dm 2 let 1 values randomly picked dimensions 1 used repeating values randomly generate randomly generate measure values 1 r normal distribution mean conducted experiments various synthetic datasets generated generator results similar limited space except performance respect number tuples report results typical data sets 10 dimensions 10 00020 000 tuples cardinality every dimension set 10 8 measures range 100 1000 noise factor set 20 repeat factor 200101000 runtime number probes allpairs livesetdriven figure 3 scalability number probe cells100 50 100 150 200 runtime significance threshold allpairs livesetdriven figure 4 scalability wrt significance threshold first data set used 10 000 tuples tested scalability algorithms respect number probes figure 3 significance threshold figure 4 gradient threshold figure 5 figure 3 shows scalability two algorithms allsignificantpairs livesetdriven respect number probe cells set significance threshold 10 number bins 3 topk average gradient threshold 2 number probes varies 1 1 000 number probes small algorithms similar performance however number probes grows pruning power livesetdriven algorithm takes eect one pass combines searches probe cells prunes unfruitful searches keeps runtime low contrast allsignificantpairs algorithm scale well large number probes one independent search probe cell figure 4 shows scalability algorithms respect significance threshold gradient threshold set 12 number bins 3 number probes 50 livesetdriven achieves good scalability pruning many cells search whereas allsignificantpairs checks huge number pairs cells 8 smaller cardinality denser data cube thus larger number cells satisfy constraints runtime gradient threshold allpairs livesetdriven figure 5 scalability wrt gradient runtime number tuples thousands allpairs livesetdriven figure scalability wrt number tuples figure 5 shows scalability allsignificantpairs livesetdriven respect various gradient thresholds fixed significance threshold 10 number bins 3 number probes 50 gradient threshold goes number cells allsignificantpairs check increases dramatically thus runtime increases dramatically well figure 6 shows scalingup experiment respect various number tuples varying 20 000 set significance threshold 1 number tuples gradient threshold 12 number bins 3 number probes 100 algorithms scalable livesetdriven naturally ecient1000001e07 number cells explored gradient threshold allpairs livesetdriven figure 7 using gradient pruning50000015e0625e0635e06 number cells explored significance threshold allpairs livesetdriven figure 8 significance threshold pruning also analyzed number cells explored algorithm mining process 10 000tuple dataset 50 probe cells figure 7 presents number cells two algorithms explored respect various gradient thresholds confirms livesetdriven achieves better pruning allpairs shown figure livesetdriven average explores one tenth cells allsignificantpairs explains dierence eciency scalability two algorithms similar statements made figure 8 significance threshold varies 10 1 000 livesetdriven explores substantially smaller set cells allsignificantpairs section examine various alternatives constraints gradients gradient mining data cubes extend scope mining constrained gradients transactional databases discuss related work 51 variations mining constrained gradients data cubes last two sections presented ecient method mining constrained gradients multidimensional space discuss possible extensions refinements method various kinds alternative situations follows 1 finding constrained gradients among ancestors descendants siblings algorithm 2 livesetdriven searches three kinds relationships ancestors descendants siblings time applications people may interested one two kinds kinds modify algorithm ensure ecient computation want find siblings ancestors descendants easily addressed modifying definition liveset potential gradient cells special case remove probe cells general case accordance userrestrictions cells comparable need change parts algorithm result algorithm ecient similar extensions worked user would like find constrained gradients relevance small subset dimension combinations j data cube case starting 0d cell set non gradient cells considered tested confined subset dimensions j 2 finding multidimensional gradients constrained interval algorithm searches multidimensional gradients checking single gradient constraint c grad c v constant value g gradient function many cases desired constraint could interval 25 cases one modify gradient testing part algorithm testing lower bound topk average measure ie less also upper bound bottomk average measure ie 25 avgc p clearly computation bottomk average similar topk average whether ecient prune search space using upper lower bounds using one postponing evaluation constraint evaluation depend gradient constraint values data set 3 replacing ratiobased gradients dierences gradient constraint although algorithm handles ratiobased gradients slight modification one handle gradients defined dierences suppose new gradient constraint c dif grad let grad basically need change algorithm c div grad replacing 14 400 respectively example avg pricec g 14 avg pricec p replaced algorithm previous discussion still hold 4 finding similar stable patterns ie measures similar dimension values change similar stable defined one following two ways grad grad observe similar cells expected similar measure values hence number similar cells normally large pairs similar cells interesting find interesting pairs one impose constraints uninteresting pairs eliminated algorithm adapted deal constrained similar cell queries may better compute nonconstrained similar cell query displayed number range queries 5 happen replace avg sum count using measure average gradient analysis natural define interesting gradients substantial changes measure average however replace avg sum count ancestor cell naturally much bigger sum count values descendants case simple gradient definition gc g c p v may interesting case normalized definition gradients make sense example one may compare cells siblings ancestors descendants relatively comparable size ie containing almost number cells expected values sumcount based proportional size similar average substantially larger smaller expected values caught interesting cells context algorithm also made work minor modifications 6 ways define comparable cells discussion confined finding large ratios dierences among ancestors descen dants 1d siblings could many ways define comparable cells example one may want find comparable cells 2dimensional mutations find groups comparable cells userspecified explicit constraints corresponding modifications definition rules derivation liveset make algorithm adaptable cases 52 mining constrained gradients transactional databases examine extend model mining constrained gradients transactional databases comparison mining transactionbased association rules ais93 as94 distinct feature mining constrained gradients measure confined frequency counting ie support extended complex measures sum sales average sales price profit lets examine example example 7 gradient mining transactional databases suppose database ecity stores large set customer shopping history tuple representing one customer contains set items bought together sales price item tuples shown customer items bought c table 4 set transactions customer shopping history ecity database example constrained gradients query find situations average sales price one kind product digital camera may substantially higher situations one may find following relationships could interesting 1 average price digital cameras sold 20 higher usual customer also bought buy laptop pcs 2 average price color tvs sold 60 higher customers also bought buy dvd players comparison situations customers also bought buy repair kit transactional database significance constraint may correspond minimum number transactions containing itemset consideration probe constraint users inter est single items digital camera itemsets color tv dvd player gradient constraint ratio 12 means least 20 higher one average sales price point view one see constrained transaction gradient problem shares lot similarities constrained cube gradient problem discussed mine constrained gradients transaction database using method developed mining constrained gradients data cubes principle model algorithm developed constrained gradients data cubes still applicable mining transactionbased gradients complex measures however since transaction database may contain large number distinct items may correspond huge number dimensions since transaction usually contains small portion possible items transaction database ie sparse data cubebased method may lead ecient solution moreover previously proposed htree structure appropriate storing mining gradients due sparsity data large number dimensions overcome diculty propose probebased fpgrowth method described 1 scan transaction database find frequent single items sort single items itemfrequency descending order obtain f list 2 probe itemset p construct ps fptree follows transaction containing p following f list ordering insert every frequent item p tree update corresponding node 1 incrementing count 2 adding current price sum ps sales notice sum ps sales new node first initialized zero 3 call fpgrowth algorithm hpy00 similar frequent pattern mining algorithms calculate count sum sales itemsets ps fptree print whose support gradient less corresponding thresholds note ensure cover ancestordescendant pairs desired probe itemsets also build fptree subset probe itemset 4 optimization node may store ps count sum sales partitioned according price range bins way discussed topk optimization explored prune search based heuristic topk average itemset less avgp gradient threshold projected database need mined correctness eciency method easily verified similar way discussed section 3 left interested readers exercise 53 related work closest work related study multidimensional gradient analysis cubegrade problem imielinski et al ika02 cubegrade query asks associationtype rules describe changes measure values associated changes dimension descriptions cuboids deals questions cube changes associated significant measure changes cubegrade queries also constraints restrict attributes gradient cells allowed rollup drilldown mutation constrained gradient analysis userdefined constraints gradient cells however shown discussion easily dealt adding power prune liveset thus adding userdefined constraints actually lead ecient processing main contributions ika02 cubegrade framework proposed language considered relativized notion monotonicity wrt cube constrained cube socalled structural monotonicity tested quite eciently evaluation strategy proposed paper uses multiple loops probe cell search entire space potential gradient cells serious eciency problem generalize notion comparable cells discussed search space per probe cell large search repeated per probe cell constraints may used pruning eect pruning eciency clear paper general proposed method ika02 similar allsignificantpairs approach al gorithm 1 based performance analysis livesetdrive method leads ecient solution due grouped processing live probe cells pruning search space pushing various kinds constraints deeply also studies ecient exploration interesting cells data cubes interesting rules multidimensional space reference sam98 considers discoverydriven exploration olap data cubes computes anticipated values cell using neighborhood values cell cell considered exception value significantly dierent anticipated value rather dierent studied paper interestingness defined based userspecified gradient ratio relevance cells ancestors descendants siblings therefore computational methods adopted two studies rather dierent former sam98 based statistical analysis neighborhood values cell determine whether exception whereas latter study cubebased computation constrained gradients also former interactive exploration computed cube cells whereas latter computing nonmaterialized cells exactly pairs cells satisfying certain constraints definitions may find corresponding applications interesting issue see whether computation used filtering process feed results statistical analysis neighborhood cells reduce overall processing cost discoverydriven exploration olap data cubes recently ss01 considered socalled intelligent rollup operation datacubes allows analyst discover specific generalizations pair cells interesting properties approaches proposed authors dierent dl99 considers mining socalled emerging patterns patterns whose frequency change ratio two datasets larger certain threshold data cube environment two base tables first extracted base data cube one base cells satisfying one property base cells satisfying another property emerging patterns aggregated cells measure changes significantly two corresponding data cubes notice unlike model constructed study method developed dl99 cannot handle arbitrary measures avg still research issue eciently compute complex gradients association mining environment considers statistics measure one group tuples diers measure supergroup shows adopting dierence ratio measure number association rules reduced substantially interesting rules preserved shares similar motivation study however study provides general mechanism specify constraints kind measures andor gradients relevance ancestors descendants siblings thus provides general model well ecient constraintpushing computation method believe method serve ecient preprocessing step subsequent statistical studies mined interesting gradients rules study also closely related 1 data cube iceberg cube computation methods proposed previous studies hru96 aad hpdw01 well 2 constraintbased data mining methods sva97 nlhp98 glw00 phl01 study considered 1 extension data cube computation mining interesting gradients 2 extension constraintbased mining toward mining constrained gradients data cubes thus extension integration mechanisms towards ecient multi dimensional constrained gradient analysis 6 conclusions paper studied issues methods ecient mining multidimensional constrained gradients data cubes constrained gradients substantial changes set measures aggregates interest associated changes underlying characteristics cube cells changes characteristics expressed terms dimensions limited specialization generalization 1d mutation ensure interesting changes relevant cells studied show necessary introduce three kinds constraints significance constraints probe constraints gradient constraints ecient algorithm livesetdriven developed explores setoriented processing maximal pushing constraints deeply possible early stage mining process prune search space moreover also adopt compressed hypertree structure represent base table data cube achieve maximal sharing computation among dierent cells performance study shows method ecient scalable outperforms another method relies iceberg cube computation allsignificantpairs furthermore briefly introduced mining constrained gradients transaction databases well alternatives gradient mining integration constrained gradient mining discoverydriven exploration data cubes sam98 interesting issue future research r computation multidimensional aggregates mining association rules sets items large databases statistical theory quantitative association rules fast algorithms mining association rules overview data warehousing olap technology computing iceberg queries e data cube relational aggregation operator generalizing groupby mining frequent patterns without candidate generation implementing data cubes e generalizing association rules exploratory mining pruning optimizations constrained associations rules mining frequent itemsets convertible constraints fast computation sparse datacubes intelligent rollups multidimensional olap data mining association rules item constraints arraybased algorithm simultaneous multidimensional aggregates tr ctr topological approaches covering rough sets information sciences international journal v177 n6 p14991508 march 2007 riadh ben messaoud sabine loudcher rabasda omar boussaid rokia missaoui enhanced mining association rules data cubes proceedings 9th acm international workshop data warehousing olap november 1010 2006 arlington virginia usa