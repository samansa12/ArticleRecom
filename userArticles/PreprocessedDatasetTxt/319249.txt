classifying facial actions abstractthe facial action coding system facs 23 objective method quantifying facial movement terms component actions system widely used behavioral investigations emotion cognitive processes social interaction coding presently performed highly trained human experts paper explores compares techniques automatically recognizing facial actions sequences images techniques include analysis facial motion estimation optical flow holistic spatial analysis principal component analysis independent component analysis local feature analysis linear discriminant analysis methods based outputs local filters gabor wavelet representations local principal components performance systems compared naive expert human subjects best performances obtained using gabor wavelet representation independent component representation achieved 96 percent accuracy classifying 12 facial actions upper lower face results provide converging evidence importance using local filters high spatial frequencies statistical independence classifying facial actions b introduction facial expressions provide information affective state also cognitive activity temperament personality truthfulness psychopathology facial action coding system 23 leading method measuring facial movement behavioral science facs currently performed manually highly trained human experts recent advances image analysis open possibility automatic measurement facial signals automated system would make facial expression measurement widely accessible tool research assessment behavioral science medicine system would also applications humancomputer interaction paper presents survey comparison recent techniques facial expression recognition applied automated facs encoding recent approaches include measurement facial motion optic flow 44 64 54 26 15 43 analysis surface textures based principal component analysis pca 17 48 40 addition number methods developed representing faces identity recognition may also powerful expression analysis approaches also included present comparison include gabor wavelets 20 39 linear discriminant analysis 8 local feature analysis 49 independent component analysis 5 4 techniques compared single image testbed analysis focuses methods face image representation generation feature vectors representations compared using common similarity measure classifier 11 facial action coding system facs developed ekman friesen 23 1978 objectively measure facial activity behavioral science investigations face provides objective description facial signals terms component motions facial actions facs developed determining palpation knowledge anatomy videotapes contraction facial muscles changed appearance face see fig 1 ekman friesen defined action units aus correspond independent motion face trained human facs coder decomposes observed expression specific aus produced expression facs coded video code provides precise specification dynamics duration onset offset time facial movement addition morphology specific facial actions occur facs continues leading method measuring facial expressions behavioral science see 25 review system used example demonstrate differences genuine simulated pain 19 differences people telling truth versus lying 22 differences facial signals suicidal nonsuicidally depressed patients 34 although facs promising approach major impediment widespread use time required train human experts manually score video tape takes 100 hours training achieve minimal competency facs minute video tape takes approximately one hour score automating facs would make widely accessible research tool would increase speed coding would also improve reliability precision temporal resolution facial measurement figure 1 facial action coding system decomposes facial motion component actions upper facial muscles corresponding action units 1 2 4 6 7 illustrated reprinted permission ekman friesen 1978 aspects facs incorporated computer graphic systems synthesizing facial expressions eg toy story 38 facial muscle models parameterizing facial movement 55 44 important distinguish facs facial muscle models employ aspects facs particular tendency confuse facs candide 55 facs performed human observers using stopmotion video although clearly defined relationships facs underlying facial muscles facs imagebased method facial actions defined image changes produce video sequences face images 12 automated facial expression measurement recent advances made computer vision automatic recognition facial expressions images approaches explored include analysis facial motion 44 64 54 26 measurements shapes facial features spatial arrangements 40 66 holistic spatial pattern analysis using techniques based principal component analysis 17 48 40 graylevel pattern analysis using local spatial filters 48 66 methods relating face images physical models facial skin musculature 44 59 42 26 image analysis techniques systems relevant present goals systems limited use behavioral science investigations face see 31 discussion many systems designed objective classifying facial expressions basic categories emotion happy sad surprised basic science investigations facial behavior studying difference genuine simulated pain objective detailed measure facial activity facs needed several computer vision systems explicitly parameterize facial movement 64 relate facial movements underlying facial musculature 44 26 known whether descriptions sufficient describing full range facial behavior example movement parameters estimated posed prototypical expressions may appropriate descriptors spontaneous facial expressions differ posed expressions morphology dynamics 31 furthermore relationship movement parameters internal state investigated extent facs 20 years behavioral data relationships facial action codes emotion state variables deceit interest depression psychopathology addition providing tool basic science research system outputs facial action codes would provide strong basis humancomputer interaction systems natural interaction prototypic expressions basic emotions occur relatively infrequently annoyance example may indicated lowering brows tightening mouth facs provides description basic elements facial movement analogous phonemes speech facial action codes also provide detailed information facial behavior including information variations within emotional category eg vengeance vs resentment variations intensity eg annoyance vs fury blends two emotions eg happiness disgust smug facial signals deceit signs boredom interest conversational signals provide emphasis speech information syntax explicit attempts automate facial action coding system involved tracking positions dots attached face 35 37 system detects facial actions image sequences without requiring application dots subjects face would much broader utility efforts recently turned measuring facial actions image processing video sequences 6 4 15 cohn colleagues 15 achieved success automated facial action coding feature point tracking set manually located points face image fiducial points explore image representations based full field analysis face image displacements selected feature points techniques employing 2d filters image graylevels proven effective featurebased representations identity recognition 13 40 expression recognition 66 previous work automatic facial action coding 6 3 2 found fullfield representations image textures image motion provided reliable indicators facial actions taskspecific feature measurements increase facial wrinkles specific facial regions several facial expression recognition systems employed explicit physical models face 44 59 42 26 numerous factors influence motion skin following muscle contraction difficult accurately account deterministic model take imagebased approach facial action classes learned directly example image sequences actions bypassing physical model imagebased approaches recently advocated 11 successfully accomplish tasks previously assumed require mapping onto physical model expression synthesis face recognition across changes pose synthesis across pose 12 61 overview paper explores compares approaches face image representation section 3 presents image database used comparative study image preprocessing techniques examined number techniques presented literature processing images faces compare performance task facial action classification approaches grouped following classes analysis facial motion holistic spatial analysis local spatial analysis section 4 examines representation facial motion based optic flow technique correlationbased method subpixel accuracy 58 local smoothing commonly imposed flow fields clean signal also examined effects local smoothing classification facial motion holistic spatial analysis approach employs imagedimensional graylevel texture filters many approaches employ datadriven kernels learned statistics face image ensemble approaches include eigenfaces 60 17 48 40 local feature analysis lfa 49 kernels learned unsupervised methods based principal component analysis pca eigenface lfa kernels derived secondorder dependencies among image pixels whereas independent component analysis ica learns kernels highorder dependencies addition secondorder dependencies among pixels 5 4 2 another class holistic kernel fishers linear discriminants fld 8 learned supervised methods finds classspecific linear projection images section 5 compares four representations derived holistic spatial analysis eigenfaces pca lfa ica fld local spatial analysis approach spatially local kernels employed filter images include predefined families kernels gabor wavelets 20 39 66 datadriven kernels learned statistics small image patches local pca 48 section 6 examines two representations based outputs local spatial filters local pca gabor wavelet representation two local representations compared via hybrid representation local pca jets section 7 provides benchmarks performance computer vision systems measuring ability naive expert human subjects classify facial actions 3 image database collected database image sequences subjects performing specified facial actions full database contains 1100 sequences containing 150 distinct actions action combinations 24 different subjects sequence contained six images beginning neutral expression ending high magnitude muscle contraction trained facs experts provided demonstrations instructions subjects perform action selection images based facs coding stop motion video images coded three experienced facs coders certified high intercoder reliability criterion acceptance images requested action requested action present sequences containing rigid head motion detectable human observer excluded investigation used data 20 subjects attempted classify 12 actions 6 upper face actions 6 lower face actions figure 2 summary actions examined total 111 action sequences 9 10 18 20 5 18 respectively six upper face actions 8 4 4 5 4 6 six lower face actions actions divided upper lowerface categories facial actions lower face little influence facial motion upper face vice versa 23 allowed us treat separately face located first frame sequence using centers eyes mouth upper face inner brow raiser outer brow raiser 4 brow lower 5 upper lid raiser 6 cheek raiser 7 lid tightener lower face 9 nose wrinkler upper lip raiser lower lip depressor stretcher figure 2 list facial actions classified study left right example cropped image highest magnitude action ffi image obtained subtracting neutral frame first image sequence action unit number action unit name coordinates obtained manually mouse click accurate image registration critical holistic approaches principal component analysis alignment procedure similar one found give accurate image registration feret test 50 variance assigned feature location using procedure 04 pixels 640 theta 480 pixel images coordinates frame 1 used register subsequent frames sequence found pilot investigations rigid head motion smaller positional noise registration procedure three coordinates used align faces rotate eyes horizontal scale finally crop window 60 theta 90 pixels containing region interest upper lower face aspect ratios faces warped eye mouth centers coincided across images found identity recognition performance using principal component based approaches successful images warped remove variations facial shape 11 62 control variation lighting frames sequence different sequences applied logistic filter parameters chosen match statistics grayscale levels sequence 46 procedure enhanced contrast performing partial histogram equalization images 4 optic flow analysis majority work facial expression recognition focused facial motion analysis optic flow estimation early exploration facial expression recognition mase 44 used optic flow estimate activity subset facial muscles essa pentland 26 extended approach using optic flow estimate activity detailed anatomical physical model face motion estimates optic flow refined physical model recursive estimation control framework estimated forces used classify facial expressions yacoob davis 64 bypassed physical model constructed midlevel representation facial motion right mouth corner raises directly optic flow midlevel representations classified one six facial expressions using set heuristic rules rosenblum yacoob davis 54 expanded system model full temporal profile facial expressions radial basis functions initiation apex relaxation cohn et al 15 developing system automatic facial action classification based featurepoint tracking displacements 36 manually located feature points estimated using optic flow classified using discriminant functions optic flow fields estimated employing correlationbased technique developed singh 58 algorithm produces flow fields subpixel accuracy comprised two main components 1 extraction using luminance conservation constraints 2 local smoothing 41 local velocity extraction start sequence three images time use recover velocity information available locally pixel px central image small window w p 3 theta 3 pixels formed around p 2 search area w 5 theta 5 pixels considered around location x two images 3 correlation w p corresponding window centered pixel w computed thus giving matching strength response pixel search window w end process w covered response distribution r response point gives frequency occurrence likelihood corresponding value velocity employing constant temporal model response distributions two windows corresponding r r1 combined velocity estimated using weighted least squares estimate 1 figure 3 shows example flow field obtained algorithm 42 local smoothing refine conservation constraint estimate u cc u v obtained local neighborhood estimate velocity u defined weighted sum velocities neighborhood p using 5 theta 5 gaussian mask figure 3 optic flow au1 extracted using local velocity information extracted correlationbased technique spatial smoothing optimal estimate u u v combine two estimates u cc u conservation local smoothness constraints respectively since u point u v space distance u weighted covariance matrix represents error smoothness constraint estimate similarly distance u u cc weighted cc represents error due conservation constraints computing u amounts simultaneously minimizing two errors since know true velocity estimate must computed iteratively update field use equations 58 u k estimate derived smoothness constraints step k iterations stop 43 classification procedure following classification procedures used test efficacy representation comparison facial action recognition image analysis algorithm produced feature vector f employed simple nearest neighbor classifier similarity training feature vector f novel feature vector f n measured cosine angle classification performances also evaluated using euclidean distance instead cosine similarity measure template matching instead nearest neighbor classifier templates consisted mean feature vector training images similarity measure classifier gave best performance indicated technique algorithms trained tested using leaveoneout crossvalidation also known jackknife procedure makes maximal use available data training procedure image representations calculated multiple times time using images one subject training reserving one subject testing procedure repeated 20 subjects mean classification accuracy calculated across test cases table presents classification performances medium magnitude facial actions occur middle sequence performance consistently highest medium magnitude actions flow fields calculated frames 2 3 4 image sequence performance brightness based algorithms presented frame 4 sequence class assignment considered correct consistent labels assigned human experts image collection consistency human experts image set indicated agreement rates also shown table 1 44 optic flow performance best performance optic flow approach obtained using cosine similarity measure template matching classifier correlationbased flow algorithm gave 856 correct classification performance since optic flow noisy measure many flowbased expression analysis systems employ regularization procedures smoothing quantizing found spatial smoothing improve performance instead degraded 531 appears high spatial resolution optic flow important facial action classification addition motion facial expression sequences nonrigid highly discontinuous due formation wrinkles smoothing algorithms sensitive boundaries disadvantageous variety choices flow algorithms singhs correlationbased algorithm one also possible adding data flow field estimate could improve performance results obtained however comparable performance facial expression recognition systems based optic flow 64 54 optic flow estimates also refined kalman filter estimationand control framework eg 26 comparison addresses direct imagebased representations incorporate physical model sequences flow fields also analyzed using dynamical models hmms radial basis functions eg 54 dynamical models could also employed texturebased representations compare representations using classifiers 5 holistic analysis number approaches face image analysis employ datadriven kernels learned statistics face image ensemble approaches eigenfaces 60 employ principal component analysis unsupervised learning method based secondorder dependencies among pixels secondorder dependencies pixelwise covariances representations based principal component analysis applied successfully recognizing facial identity 18 60 classifying gender 17 29 recognizing facial expressions 17 48 6 penev atick 49 recently developed topographic representation based secondorder image dependencies called local feature analysis lfa representation based lfa gave highest performance march 1995 feret face recognition competition 51 lfa kernels spatially local paper class technique holistic since imagedimensional kernels derived statistical analysis whole image another holistic image representation recently shown effective identity recognition based fishers linear discriminants fld 8 fld supervised learning method uses secondorder statistics find classspecific linear projection images representations pca eigenfaces lfa fld address highorder statistical dependencies image representation based independent component analysis ica recently developed based highorder addition secondorder dependencies images 5 4 2 ica representation found superior eigenface pca representation classifying facial identity holistic spatial analysis algorithms examined section found set ndimensional datadriven image kernels n number pixels image analysis performed difference ffi images figure 2 obtained subtracting first image sequence neutral frame subsequent frames sequence advantages difference images include robustness changes illumination removal surface variations subjects emphasis dynamic aspects image sequence 46 kernels derived low medium high magnitude actions holistic kernels upper lowerface subimages calculated separately methods section begin data matrix x ffiimages stored row vectors x j columns zero mean following descriptions n number pixels image n number training images p number principal components retained build final representation 51 principal component analysis eigenactions approach based 17 60 primary distinction performed principal component analysis dataset difference images principal components obtained calculating eigenvectors pixelwise covariance matrix ffiimages x eigenvectors found decomposing orthogonal matrix p diagonal matrix examples figure 4 first 4 principal components difference images upper face actions lower face actions b components ordered left right top bottom eigenvectors shown figure 4 zeromean ffiframes sequence projected onto first p eigenvectors p producing vector p coefficients image best performance holistic principal component representation 793 correct obtained first principal components using euclidean distance similarity measure template matching clas sifier previous studies eg 8 reported discarding first 1 3 components improved performance discarding components degraded performance 52 local feature analysis lfa local feature analysis lfa defines set topographic local kernels optimally matched secondorder statistics input ensemble 49 kernels derived principal component axes consist sphering pca coefficients equalize variance 1 followed rotation pixel space begin zeromean matrix ffigammaimages x calculate principal component eigenvectors p according defined set kernels k eigenvalues rows k contain kernels kernels found spatially local properties topographic sense indexed spatial location 49 kernel matrix k transforms x lfa output kx see figure 5 note matrix v inverse square root covariance matrix principal component coefficients transform spheres principal component coefficients normalizes output variance unity minimizes correlations lfa output another way interpret lfa output image reconstruction using sphered pca coefficients 521 sparsification lfa lfa produces n dimensional representation n number pixels images since outputs described p n linearly independent variables residual correlations output b c figure 5 original ffiimage b corresponding lfa output ox c first 155 filter locations selected sparsification algorithm superimposed mean upper face ffiimage penev atick presented algorithm reducing dimensionality representation choosing subset outputs decorrelated possible sparsification algorithm iterative algorithm based multiple linear regression time step output point predicted poorly multiple linear regression points added due topographic property kernels selection output points equivalent selection kernels representation methods 49 addressed image representation address recognition sparsification algorithm 49 selected different set kernels image problematic recognition order make representation amenable recognition selected single set kernels images time step kernel corresponding pixel largest mean reconstruction error across images added step kernel added chosen kernel corresponding location rec reconstruction complete output using linear predictor subset outputs generated kernels linear predictor form vector regression parameters subset corresponding points n images 1 fi calculated equation 8 also expressed terms correlation matrix outputs 49 termination condition figure 5 shows locations points selected sparsification algorithm upperface images evaluated classification performance using first kernels selected sparsification algorithm local feature analysis representation attained 811 correct classification performance best performance obtained using first 155 kernels cosine similarity measure nearest neighbor classifier classification performance using lfa significantly different performance using global pca although face recognition algorithm related lfa outperformed eigenfaces march 1995 feret competition 51 results suggest aspect algorithm lfa representation accounts difference performance exact algorithm used feret test disclosed 53 fisheractions approach based original work belhumeur others 8 showed classspecific linear projection principal components representation faces improved identity recognition performance method based fishers linear discriminant fld 28 projects images subspace classes maximally separated fld assumes linear separability classes identity recognition approach relied assumption images face different viewing conditions lie approximately linear subspace image space assumption holds true changes lighting face modeled lambertian surface 56 32 dataset lighting conditions fairly constant variation suppressed logistic filter linear assumption facial expression classification ffigammaimages facial action across different faces lie linear subspace fishers linear discriminant projection subspace maximizes betweenclass scatter minimizing withinclass scatter projected data let delta set data divided c classes class composed variable number images x 2 r n betweenclass scatter matrix sb interclass scatter sw defined c c mean image class mean data w opt projects r n 7 r cgamma1 satisfies fw g solutions generalized eigenvalues problem sbw following 8 calculations greatly simplified first performing pca total scatter matrix project feature space r p denoting pca projection matrix w pca project sw sb pca sbw pca pca original fld problem thus reformulated pca figure projections three lowerface action classes onto two dimensions fld projections slightly offset visibility fld projected class single point 11 13 w fld fw 0 g calculated using sw fullrank p best performance obtained choosing principal components first reduce dimensionality data data projected 5 dimensions via projection matrix w fld best performance 757 correct obtained euclidean distance similarity measure template matching classifier clustering fld compared pca figure 6 example three lower face actions projected c dimensions using fld pca fld projection virtually eliminated withinclass scatter training set exemplars class projected single point three actions example 17 18 925 contrary results obtained 8 fishers linear discriminants improve classification basic pca eigenfaces despite providing much compact representation data optimized linear discrimination suggests linear subspace assumption violated catastrophically dataset dataset 8 consisted faces different lighting conditions another reason difference performance may due problem generalization novel subjects fld method achieved best performance training data close 100 generalized poorly new individuals consistent reports poor generalization novel subjects 14 also h wechsler personal communication good performance fld obtained images test subject included training set low dimensionality may provide insufficient degrees freedom linear discrimination classes face images 14 class discriminations approximately linear high dimensions may linear projected 5 dimensions 54 independent component analysis representations eigenfaces lfa fld based secondorder dependencies image set pixelwise covariances insensitive highorder dependencies image set highorder unknown sources images separated sources w unknown mixing process learned weights figure 7 image synthesis model ica representation dependencies image include nonlinear relationships among pixel grayvalues edges phase alignment across multiple spatial scales elements shape curvature task facial expression analysis much relevant information may contained highorder relationships among image pixels independent component analysis ica generalization pca learns highorder moments data addition secondorder moments direct comparison face representation based ica outperformed pca identity recognition methods section based 5 4 2 independent component representation obtained performing blind separation set face images 5 4 2 image synthesis model figure 7 ffi images rows x assumed linear mixture unknown set statistically independent source images unknown mixing matrix sources recovered learned unmixing matrix w approximates gamma1 produces statistically independent outputs u ica unmixing matrix w found using unsupervised learning algorithm derived principle optimal information transfer neurons 9 10 algorithm maximizes mutual information input output nonlinear transfer function g discussion information maximization leads independent outputs found 47 9 10 let x column image matrix x gu update rule weight matrix w given employed logistic transfer function 1e gammau giving convergence greatly speeded including sphering step prior learning 10 zeromean dataset x passed whitening filter 2 removes first secondorder depen figure 8 sample ica basis images dencies data full transform therefore weight obtained information maximization equation 14 projection image set onto weight vector w produced image statistical dependencies weight vector learned images rows output matrix u examples shown figure 8 rows u independent components image set provided basis set expression images ica representation consisted coefficients linear combination basis images u comprised face image x coefficients obtained rows estimated mixing matrix delta number independent components extracted ica algorithm corresponds number input images two hundred independent components extracted upper 155 lower face image sets since 200 upper face images ica performed 200 linear mixtures faces without affecting image synthesis model first 200 pca eigenvectors chosen linear mixtures since give combination images accounts maximum variability among pixels eigenvectors normalized unit length details available 4 2 unlike pca inherent ordering independent components dataset therefore selected ordering parameter class discriminability compo nent let k overall mean coefficient k jk mean action j ratio betweenclass withinclass variability r coefficient defined oe within oe variance j class means oe sum variances within class first p components selected class discriminability comprised independent component representation best performance 955 obtained first 75 components selected class discriminability using cosine similarity measure nearest neighbor classifier independent component analysis gave best performance among holistic classifiers note however independent component images figure 8 local nature lfa ica algorithm analyzed images whole basis images algorithm learned local two factors contributed local property ica basis images statistical dependencies spatially proximal image locations secondly ica algorithm produces sparse outputs 10 6 local representations approaches described section 5 kernels representation learned statistics entire image evidence number sources local spatial filters may superior global spatial filters facial expression classification padgett cottrell 48 found eigenfeatures consisting principal components image subregions containing mouth eyes effective global pca fullface eigenfaces facial expression recognition furthermore found set shiftinvariant local basis functions derived principal components small image patches effective eigenfeatures global pca finding supported gray movellan found similar local pca representation gave better performance global pca lipreading video principal component analysis image patches sampled random locations image statistics stationary patch describes amplitude spectrum 27 53 alternative adaptive local filters local pca predefined wavelet decompositions families gabor filters gabor filters obtained modulating 2d sine wave gaussian envelope filters remove variability images due variation lighting contrast closely model response properties visual cortical cells 52 36 21 20 representations based outputs families gabor filters multiple spatial scales orientations spatial locations proven successful recognizing facial identity images 39 50 direct comparison face recognition algorithms gabor filter representations gave better identity recognition performance representations based principal component analysis 65 gabor representation also effective representation based geometric locations facial features expression recognition 66 section 6 explores local representations based filters act small spatial regions within images examined three variations local filters employ pca compared biologically inspired gabor wavelet decomposition simple benchmark local filters consisted single gaussian kernel ffi images convolved 15 theta 15 gaussian kernel output downsampled factor 4 dimensionality final representation n 4 output basic local filter classified 703 accuracy using euclidean distance similarity measure template matching classifier 61 local pca approach based local pca representation found outperform global pca expression recognition 48 shiftinvariant local basis functions employed 48 derived b figure 9 shiftinvariant local pca kernels first 9 components ordered left right top bottom b shiftvariant local pca kernels first principal component shown image location principal components small image patches randomly sampled locations face image set 7000 patches size 15 theta 15 taken random locations ffi images decomposed using pca first p principal components used convolution kernels filter full images outputs subsequently downsampled factor 4 final dimensionality representation isomorphic r pthetan4 local pca filters obtained set lowerface ffiimages shown figure 9 performance improved excluding first principal component best performance 734 obtained principal components 230 using euclidean distance template matching unlike findings 48 shift invariant basis functions obtained local pca effective global pca facial action coding performance local pca technique significantly higher obtained using single 15x15 gaussian kernel local pca implementation differed global pca two properties spatial locality image alignment repeated local pca analysis fixed spatial locations pca locationindependent images captures amplitude information without phase whereas alignment images provides implicit phase information 27 10 local pca fixed image locations related eigenfeatures representation addressed 48 eigenfeature representation 48 differed shiftinvariant local pca image patch size compare shiftinvariant shiftvariant versions local pca controlling patch size images divided n fixed regions principal components region calculated separately image thus represented p theta coefficients final representation consisted principal components regions classification performance tested using first 30 components patch best performance 783 obtained first 10 principal components image patch using euclidean distance nearest neighbor classifier trend phase alignment improve classification performance using local pca difference statistically significant contrary findings 48 neither local pca representation outperformed global pca representation proposed local representations reduce sensitivity identityspecific aspects face image 48 30 success global pca could attributable use ffi images reduced variance related identity specific aspects face image another reason difference findings could method downsampling padgett cottrell selected filter outputs 7 image locations eyes mouth whereas downsampling performed gridwise fashion 48 image locations 62 gabor wavelet representation examine predefined local filters based gabor wavelet decomposition representation based methods described 39 given image ix transform j defined convolution z family gabor kernels plane wave characterized vector k enveloped gaussian function parameter determines ratio window width wavelength first term square brackets determines oscillatory part kernel second term compensates dc value kernel 39 vector k defined 2 parameters define frequency orientation kernels used 5 frequencies 8 orientations final representation following methods 39 example filters shown figure 10 gabor filters applied ffiimages outputs fj g 40 gabor filters downsampled factor q reduce dimensionality 40 theta n q normalized unit length performed divisive contrast normalization tested performance system using found yielded best generalization rate best performance obtained cosine similarity measure nearest neighbor classifier classification performance gabor filter representation 955 performance significantly higher approaches comparison except independent component analysis tied finding supported zhang yan lades 65 found face recognition gabor filter representation superior holistic principal component based representation determine frequency ranges contained information action classification repeated tests using subsets high frequencies low frequencies performance b c figure 10 original ffiimage b gabor kernels low high frequency magnitude filtered image right c local pca kernels large small scale corresponding filtered image high frequency subset 928 almost performance low frequency subset 838 finding higher spatial frequency bands gabor filter representation contain information lower frequency bands consistent analysis optic flow reduction spatial resolution optic flow smoothing detrimental effect classification performance appears high spatial frequencies important task 63 pca jets next investigated whether multiscale property gabor wavelet representation accounts difference performance obtained using gabor representation local pca representation test hypothesis developed multiscale version local pca representation pca jets principal components random subimage patches provide amplitude spectrum local image regions multiscale local pca representation obtained performing pca random image patches five different scales chosen match sizes gaussian envelopes see figure 10 patch sizes chosen sigma3oe yielding following set 9theta9 15theta15 23theta23 35 theta 35 49 theta 49 number filters matched gabor representation retaining principal components scale total 80 filters downsampling factor also chosen match gabor representation gabor representation performance tested using cosine similarity measure nearest neighbor classifier best results obtained using eigenvectors 2 17 patch size performance 649 five scales 721 three smaller scales 622 three larger scales multiscale principal component analysis pca jets improve performance single scale local pca appears multiscale property gabor representation account improvement performance obtained representation local representations based principal component analysis 7 human subjects performance human subjects provided benchmarks performances automated systems computer vision systems test performance prototypical expressions emotion naive human subjects classify 90 agreement eg 45 facial action coding detailed analysis facial behavior discriminating prototypical expressions ability naive human subjects classify facial action images set gives simple indication difficulty visual classification task provides basis comparing results presented systems literature since longterm goal project replace human expert coders automated system second benchmark provided agreement rates expert human coders images benchmark indicated extent automated systems attained goal reaching consistency levels expert coders naive subjects naive subjects ten adult volunteers prior knowledge facial expression measurement upper lower face actions tested separately subjects provided guide sheet contained example image six upper lower face actions along written description action list image cues detecting discriminating actions 23 subject given training session facial actions described demonstrated image cues listed guide sheet reviewed indicated example images subjects kept guide sheet reference task face images preprocessed identically automated systems described section 3 printed using high resolution hp laserjet 4si printer 600 dpi face images presented pairs neutral expression image test image presented side side subjects instructed compare test image neutral image decide actions subject performed test image ninetythree image pairs presented upper lower face tasks subjects instructed take much time needed perform task ranged minutes one hour naive subjects classified images 779 correct presenting uncropped face images improve performance expert coders expert subjects four certified facs coders task identical naive subject task following exceptions expert subjects given guide sheet additional training complete face visible would normally facs scoring although complete action visible cropped images experts experienced full face images cropping may bias performance removing contextual information one hundred fourteen upperface image pairs ninetythree lowerface image pairs presented time complete task ranged 20 minutes 1 hour 15 minutes rate agreement expert coders assigned labels 941 optic flow correlation 856 sigma 33 smoothed 531 sigma 47 pca 793 sigma 39 holistic lfa 811 sigma 37 spatial analysis fld 757 sigma 41 ica 955 sigma 20 gaussian kernel 703 sigma 4 spatial analysis pca shiftvar 783 sigma 39 pca jets 721 sigma 42 gabor jets 955 sigma 20 human subjects naive 779 sigma 25 expert 941 sigma21 table 1 best performance classifier pca principal component analysis lfa local feature anal ysis fld fishers linear discriminant ica independent component analysis shiftinv shiftinvariant shiftvar shiftvariant compared number different image analysis methods difficult classification problem classification facial actions several approaches facial expression analysis presented literature little direct comparison methods single dataset approaches include analysis facial motion 44 64 54 26 holistic spatial pattern analysis using techniques based principal component analysis 17 48 40 measurements shapes facial features spatial arrangements 40 66 investigation compared facial action classification using optic flow holistic spatial analysis local spatial representations also included comparison number representations developed facial identity recognition applied first time facial expression analysis representations included gabor filters 39 linear discriminant analysis 8 local feature analysis 49 independent component analysis 4 best performances obtained local gabor filter representation independent component representation achieved 96 correct classification performance two methods equaled agreement level expert human subjects images image representations derived secondorder statistics dataset pca lfa performed well naive human subjects image classification task 80 accuracy range performances using lfa fld significantly differ pca spatially local implementations pca correlationbased optic flow performed level naive expert human subjects 86 classification accuracies obtained compared favorably systems developed emotion classification despite additional challenges classifying facial actions classifying prototypical expressions reviewed 31 obtained converging evidence local spatial filters important analysis facial expressions two representations significantly outperformed others gabor representation 39 independent component representation 4 based local filters ica classified holistic algorithm since analysis performed images whole basis images algorithm produced however local results also demonstrated spatial locality image filters alone insufficient good classification local principal component representations lfa local pca performed better global pca representation eigenfaces also obtained multiple sources evidence high spatial frequencies important classifying facial actions spatial smoothing optic flow degraded performance 30 secondly classification high frequencies gabor representation superior classification using low spatial frequencies similar result obtained pca jets findings contrast recent report information recognizing prototypical facial expressions carried predominantly low spatial frequencies 66 difference findings highlights difference task requirements classifying facial actions versus classifying prototypical expressions emotion classifying facial actions detailed level analysis findings predict example high spatial frequencies would carry important information discriminating genuine expressions happiness posed ones differ presence au 6 cheek raiser 24 relevance high spatial frequencies implications motionbased facial expression analysis since optic flow noisy measure many flowbased expression analysis systems employ regularization procedures smoothing quantizing estimate principal direction motion within image region analysis presented suggests high spatial resolution optic flow important analysis facial behavior level facial action coding addition spatial locality ica representation gabor filter representation share property redundancy reduction relationships representations visual cortex response properties primary visual cortical cells closely modeled bank gabor filters 52 36 21 20 relationships demonstrated gabor filters independent component analysis bell using ica filters produced independent outputs natural scenes spatially local oriented edge filters similar bank gabor filters also shown gabor filter outputs natural images least pairwise independent 57 holds responses undergo divisive normalization neurophysiologists proposed takes place visual cortex 33 length normalization gabor representation form divisive normalization gabor wavelets pca ica provide way represent face images linear superposition basis functions gabor wavelets employ set predefined basis functions whereas pca ica learn basis functions adapted data ensemble pca models data multivariate gaussian basis functions restricted orthogonal 41 ica allows learning nonorthogonal bases allows data modeled nongaussian distributions 16 noted number relationships gabor wavelets basis functions obtained ica gabor wavelets specialized particular data ensemble would advantageous amount data small estimate filters ica representation performed well gabor representation despite two orders magnitude fewer basis functions large number basis functions appear confer advantage classification pcajet representation matched gabor representation number basis functions well scale performed 72 correct local representations underwent downsampling effect downsampling generalization rate examined gabor representation found downsampling improved generalization per formance downsampling done gridwise fashion manual selection facial features comparison representations based individual facial features fiducial points addressed recent work zhengyou zhang 66 showed multiresolution gabor wavelet coefficients give better information geometric positions fiducial points facial expression recognition 9 conclusions results comparison provided converging evidence importance using local filters high spatial frequencies statistical independence classifying facial actions best performances obtained gabor wavelet decomposition independent component analysis two representations related employ graylevel texture filters share properties spatial locality independence relationships response properties visual cortical neurons majority approaches facial expression recognition computer focused exclusively analysis facial motion motion important aspect facial expressions cue although experiments pointlight displays shown human subjects recognize facial expressions motion signals alone 7 recognition rates chance substantially lower reported recognizing similar set expressions static graylevel images eg 45 comparison best performances obtained representations based surface graylevels future direction work combine motion information spatial texture information perhaps combining motion graylevel information ultimately provide best facial expression recognition performance human visual system 7 63 acknowledgements research supported nsf grant bs9120868 lawrence livermore national laboratories intrauniversity agreement b291436 howard hughes medical institute nih grant 01 indebted facs experts linda camras wil irwin irene mcnee harriet oster erica rosenberg time assistance project thank beatrice golomb wil irwin jan larsen contributions project initiation claudia hilburn methvin image collection laurenz gary cottrell valuable discussions earlier drafts paper r retina know natural scenes face image analysis unsupervised learning redundancy reduction measuring facial expressions computer image analysis independent component representations face recog nition viewpoint invariant face recognition using independent component analysis attractor networks classifying facial action emotion recognition role facial movement relative importance upper lower areas face eigenfaces vs fisherfaces recognition using class specific linear projection informationmaximization approach blind separation blind deconvolution independent components natural scenes edge filters image representations visual learning example based image analysis synthesis face recognition features versus templates discriminant analysis face recognition automated face coding computervision based method facial expression analysis independent component analysis new concept signal processing face recognition using unsupervised feature extraction complete discrete 2d gabor transform neural networks image analysis compression spatial vision telling lies clues deceit marketplace facial action coding system technique measurement facial movement smiles lying face reveals basic applied studies spontaneous expression using facial action coding system facs goal sensory coding use multiple measures taxonomic problems neural network identifies sex human faces comparison local versus global image decomposition visual speechreading essential behavioral science face gesture computer scientists need know deformable model face recognition arbitrary lighting conditions nonlinear model neural responses cat visual cortex faces suicidal depression translation evaluation two dimensional gabor filter model simple receptive fields cat striate cortex automated coding facial behavior humancomputer interactions facs serious business automatic interpretation coding face images using flexible models inferring sparse recognition facial expression optical flow emotional expression upsidedown faces evidence configurational componential processing visual speech recognition stochastic networks representing face images emotion classification local feature analysis general statistical theory object representation feret database evaluation procedure facerecognition algorithms phase relationship adjacent simple cells visula cortex digital image processing human expression recognition motion using radial basis function network architecture candide parametrized face geometry photometry 3d visual recognition statistical models images compression optic flow computation analysis synthesis facial image sequences using physical anatomical models eigenfaces recognition linear object classes image synthesis single example image separation texture shape images faces image coding synthesis effects distortion spatial temporal resolution video stimuli emotion attri butions recognizing human facial expressions long image sequences using optical flow face recognition eigenface tr ctr lijun yin johnny loi wei xiong facial expression representation recognition based texture augmentation topographic masking proceedings 12th annual acm international conference multimedia october 1016 2004 new york ny usa b braathen bartlett g littlewort j r movellan first steps towards automatic recognition spontaneous facial action units proceedings 2001 workshop perceptive user interfaces november 1516 2001 orlando florida ce zhan wanqing li philip ogunbona farzad safaei facial expression recognition multiplayer online games procedings 3rd australasian conference interactive entertainment p5258 december 0406 2006 perth australia masakazu matsugu katsuhiko mori yusuke mitari yuji kaneda subject independent facial expression recognition robust face detection using convolutional neural network neural networks v16 n56 p555559 june chaofa chuang frank shih rapid brief communication recognizing facial action units using independent component analysis support vector machine pattern recognition v39 n9 p17951798 september 2006 tianming hu liyanage c de silva kuntal sengupta hybrid approach nn hmm facial emotion classification pattern recognition letters v23 n11 p13031310 september 2002 shyichyi cheng mingyao chen hongyi chang tzuchuan chou semanticbased facial expression recognition using analytical hierarchy process expert systems applications international journal v33 n1 p8695 july 2007 v ioannou amaryllis raouzaiou vasilis tzouvaras theofilos p mailis kostas c karpouzis stefanos kollias emotion recognition facial expression analysis based neurofuzzy network neural networks v18 n4 p423435 may 2005 jiajun wong siuyeung cho facial emotion recognition adaptive processing tree structures proceedings 2006 acm symposium applied computing april 2327 2006 dijon france lisa gralewski neill campbell barry thomas colin dalton david gibson university bristol statistical synthesis facial expressions portrayal emotion proceedings 2nd international conference computer graphics interactive techniques australasia south east asia june 1518 2004 singapore dan roth minghsuan yang narendra ahuja learning recognize threedimensional objects neural computation v14 n5 p10711103 may 2002 ira cohen nicu sebe ashutosh garg lawrence chen thomas huang facial expression recognition video sequences temporal static modeling computer vision image understanding v91 n12 p160187 july yingli tian takeo kanade jeffrey f cohn recognizing action units facial expression analysis multimodal interface humanmachine communication world scientific publishing co inc river edge nj 2002 yingli tian takeo kanade jeffrey f cohn recognizing action units facial expression analysis ieee transactions pattern analysis machine intelligence v23 n2 p97115 february 2001 benjamn hernndez gustavo olague riad hammoud leonardo trujillo eva romero visual learning texture descriptors facial expression recognition thermal imagery computer vision image understanding v106 n23 p258269 may 2007 hatice gunes massimo piccardi tony jan face body gesture recognition visionbased multimodal analyzer proceedings pansydney area workshop visual information processing p1928 june 01 2004 yongmian zhang qiang ji active dynamic information fusion facial expression understanding image sequences ieee transactions pattern analysis machine intelligence v27 n5 p699714 may 2005 muchun su yijwu hsieh deyuan huang simple approach facial expression recognition proceedings 2007 annual conference international conference computer engineering applications p456461 january 1719 2007 gold coast queensland australia matthew n dailey garrison w cottrell curtis padgett ralph adolphs empath neural network categorizes facial expressions journal cognitive neuroscience v14 n8 p11581173 november 2002 masood mehmood khan michael ingleby robert ward automated facial expression classification affect interpretation using infrared measurement facial skin temperature variations acm transactions autonomous adaptive systems taas v1 n1 p91113 september 2006 chengjun liu gaborbased kernel pca fractional power polynomial models face recognition ieee transactions pattern analysis machine intelligence v26 n5 p572581 may 2004 maja pantic leon j rothkrantz automatic analysis facial expressions state art ieee transactions pattern analysis machine intelligence v22 n12 p14241445 december 2000 douglas w cunningham mario kleiner heirich h blthoff christian wallraven components conversational facial expressions proceedings 1st symposium applied perception graphics visualization august 0708 2004 los angeles california bruce draper kyungim baek marian stewart bartlett j ross beveridge recognizing faces pca ica computer vision image understanding v91 n12 p115137 july douglas w cunningham mario kleiner christian wallraven heinrich h blthoff manipulating video sequences determine components conversational facial expressions acm transactions applied perception tap v2 n3 p251269 july 05 aleix martnez recognizing imprecisely localized partially occluded expression variant faces single sample per class ieee transactions pattern analysis machine intelligence v24 n6 p748763 june 2002 jeremy n bailenson andrew c beall jack loomis jim blascovich matthew turk transformed social interaction decoupling representation behavior form collaborative virtual environments presence teleoperators virtual environments v13 n4 p428441 august 2004 rosalind w picard elias vyzas jennifer healey toward machine emotional intelligence analysis affective physiological state ieee transactions pattern analysis machine intelligence v23 n10 p11751191 october 2001 zhonglong zheng fan yang wenan tan jiong jia jie yang fast communication gabor featurebased face recognition using supervised locality preserving projection signal processing v87 n10 p24732483 october 2007 florent perronnin jeanluc dugelay kenneth rose probabilistic model face transformation application person identification eurasip journal applied signal processing v2004 n1 p510521 1 january 2004 minghsuan yang david j kriegman narendra ahuja detecting faces images survey ieee transactions pattern analysis machine intelligence v24 n1 p3458 january 2002 sylvie c w ong surendra ranganath automatic sign language analysis survey future beyond lexical meaning ieee transactions pattern analysis machine intelligence v27 n6 p873891 june 2005 w zhao r chellappa p j phillips rosenfeld face recognition literature survey acm computing surveys csur v35 n4 p399458 december florent perronnin jeanluc dugelay kenneth rose probabilistic model face mapping local transformations application person recognition ieee transactions pattern analysis machine intelligence v27 n7 p11571171 july 2005 r w picard papert w bender b blumberg c breazeal cavallo machover resnick roy c strohecker affective learning manifesto bt technology journal v22 n4 p253269 october 2004