optimal processor assignment class pipelined computations availability largescale multitasked parallel architectures introduces followingprocessor assignment problem given long sequence data sets whichis undergo processing collection tasks whose intertask data dependencies forma seriesparallel partial order individual task potentially parallelizable aknown experimentally determined execution signature recognizing data sets bepipelined task structure problem find good assignment ofprocessors tasks two objectives interest us minimal response time per data setgiven throughput requirement maximal throughput given response timerequirement approach decompose seriesparallel task system essentialserial parallel components problem admits independent solution andrecomposition component provide algorithms series analysis use algorithm due krishnamurti parallel analysis p processor system seriesparallel precedence graph n constituent tasks give onpsup 2 algorithm finds optimal assignment broad class ofassignments response time optimization problem find assignmentoptimizing constrained throughput onpsup 2 log p time techniques areapplied task system computer vision b introduction recent years much research devoted problem mapping large computations onto system parallel processors various aspects general problem studied including different parallel architectures task structures communication issues load balancing 8 13 typically experimentally observed performance eg speedup response time tabulated function number processors employed function sometimes known execution signature 10 response time function paper use functions determine number processors allocated several tasks tasks part pipelined computation problem natural given growing availability multitasked parallel ar chitectures pasm 29 ncube system 14 intels ipsc system 5 possible map tasks processors allow parallel execution multiple tasks different logical partitions consider problem optimizing performance complex computation applied member sequence data sets type problem arises instance imaging systems image frame analyzed sequence elemental tasks eg fast fourier transform convolution applications include network software packets pipelined welldefined functions checksum computations address decoding framing given data dependencies computations multiple tasks may exploit parallelism pipelining data sets task structure applying multiple processors individual tasks fundamental tradeoff assigning processors maximize overall throughput measured data sets per unit time assigning processors minimize single data sets response time manage tradeoff maximizing one aspect performance subject constraint certain level performance must achieved aspect assumptions n tasks statically assigned subset dedicated processors individual tasks response time function completely characterizes performance even using shared resources communication network show p processors assigned seriesparallel task structure onp 2 minimize response time achieving given throughput also able find assignment maximizes throughput achieving given minimal response time onp 2 log p time assumption static assignment arises naturally realtime applications overhead swapping executable task code processors memory threatens performance assumption optimization problem becomes much difficult method involves decomposing seriesparallel graph series parallel components using standard methods present algorithms analyzing series components use krishnamurthy mas algorithm 20 analyze parallel components assume costs communication tasks completely captured given responsetime functions thus techniques expected work well computebound task systems example application representative class computation communication ratio 100 techniques may applicable communication costs depend particular sets processors assigned task eg contention contribute significantly overall performance large literature exists topic mapping workload processors see instance 1 3 4 6 15 17 18 23 24 26 27 31 33 new problem recently emerged scheduling tasks multitasked parallel architectures task assigned set processors formulations consider scheduling policies goal achieving good average response time good throughput given arrival stream different independent parallel jobs eg 28 another common objective exemplified 2 11 20 25 find schedule processor assignments minimizes completion time single job executed problem consider different specifically parallel job repeatedly executed consider issues arising need pipeline repeated executions get good throughput well apply parallel processing constituent tasks get good perexecution response time yet another distinguishing characteristic problem underlying assumption processor statically assigned one task implication every task always assigned least one processor two previously studied problems close formulation assignment processors set independent tasks considered 20 single objective minimization makespan minimizes response time tasks considered part single parallel computation maximizes throughput tasks considered form pipeline problem assigning processors independent chains modules considered 7 assignment minimizes response time component tasks considered parallel maximizes throughput component chains considered form pipelines pipeline computations also studied 19 30 30 heuristics given scheduling planar acyclic task structures 19 methodology presented analyzing pipeline computations using petri nets together techniques partitioning computations discovered treatments address optimal processor assignment general pipeline computations although solution approach dynamic programming related 3 33 paper organized follows section x2 introduces notation formalizes responsetime problem throughput problem section x3 presents algorithms series systems x4 shows optimally assign processors seriesparallel systems section x5 shows problem maximizing throughput subject responsetime constraint solved using solutions responsetime problem section x6 discusses application techniques actual problem section x7 summarizes work problem definition consider set tasks comprise computation executed using identical processors long stream data sets every task applied every data set assume tasks seriesparallel precedence relation constraining order may apply tasks given data set tasks unrelated partial order assumed process duplicated copies different elements given data set assumptions may pipeline computation different tasks concurrently applied different data sets task potentially parallelizable let f n execution time using n identical processors f called responsetime function also known execution signature 10 assume f 0 f n1 dummy tasks serve respectively identify initiation completion computation correspondingly take f 0 conditions ensure processor ever assigned 0 least one processor assigned every task example response time functions computation 5 tasks 8 processors shown table 1 row table response time function particular task observe number processors tasks 43 table 1 example response time functions table gives tasks execution time seconds function number processors used individual functions need convex monotonic may describe assignment numbers processors task function ai gives number processors statically exclusively allocated feasible assignment one given execution time f ai maximal data set throughput g response time data set obtained computing length ra longest path graph node weighted f ai edges defined seriesparallel precedence relation given throughput constraint processor count q define q set feasible assignments use q processors achieve responsetime problem find f p minimum response time feasible assignments p response time assignment ra mimimal assignments p fewer processors achieve throughput greater problem arises data sets must processed least fast known rate avoid losing data wish minimize response time among assignments achieve throughput similarly given response time constraint fl processor count q define r fl q set feasible assignments using q processors achieving ra fl throughput problem find 2 r fl p maximized problem arises realtime control applications data set must processed within maximal time frame order meet gammapsi r gammapsi r r gammapsi gammapsi figure 1 example seriesparallel task system processing deadlines focus solutions response time problem first later show may used solve throughput problem since responsetime function completely defines task elemental composite also use term task refer compositions elemental tasks let denote composite task let f optimal response time function general approach illustrated example consider seriesparallel task figure 1 responsetime functions given table dummy tasks may think 2 3 forming parallel subtaskcall 1 given response time functions 2 3 construct optimal response time function called f 1 1 need never explicitly consider 1 2 separately otherf 1 completely captures need know next view 1 1 series task call 2 compute optimal response time function process identifying series parallel subtasks constructing responsetime functions continues left single response time function describes optimal behavior tracking processor assignments necessary achieve optimal response times step able determine optimal processor allocations solution method parallel tasks already given 20 present algorithms series tasks assume every responsetime function monotone nonincreasing since argued 20 responsetime function made decreasing disregarding assignments processors cause higher response times also observe response time functions may include inherent communication costs due parallelism well communication costs suffered communicating predecessor successor tasks assumptions reasonable communication bandwidth sufficiently high us ignore effects due contention pairs communicating tasks methods may produce good results assumption hold 3 individual parallel tasks series tasks problem determining optimal responsetime function parallel tasks already essentially solved literature 20 describe solution briefly let tasks used compose parallel task know u number processors needed every elemental task involved responsetime greater 1 initialize allocating processors run processors first processor allocation meet throughput requirement otherwise initial allocation uses fewest possible number processors meet requirement incrementally add remaining processors tasks way step response time maximum task response times reduced maximally algorithm op log p time complexity series task structures interesting many pipelines simple linear chains 19 first describe algorithm constructs optimal response time function f linear task structure function f x convex x convexity elemental functions intuitive nonconvex responsetime functions arise parallel task compositions consequently different algorithm series compositions nonconvex responsetime functions developed later like parallel composition algorithm first assign minimal number processors needed meet throughput requirement mechanism identical supposing step exhaust processor supply define x number processors currently assigned initialize x x total number processors already allocated set f reflect inability meet throughput number processors table 2 response time function f 1 parallel task 1 requirement set f next change response time achieved allocating one processor build maxpriority heap 16 priority jdi x j finally enter loop iteration task highest priority allocated another processor new priority computed priority heap adjusted iterate available processors assigned iteration loop allocates next processor task stands benefit allocation individual task response functions convex response time function f greedily produces optimal since algorithm essentially one due fox 12 reported 32 simple inspection reveals algorithm op log n time complexity unlike similar algorithm parallel tasks correctness depends convexity component task response times need treat nonconvex responsetime functions arises behavior composed parallel tasks return example figure 1 consider parallel composition 1 elemental tasks 2 3 throughput requirement 001 responsetime function f 1 shown table 2 note f 1 convex even though f 2 f 3 nonconvexity due peculiar nature maximum two functions cannot avoided dealing parallel task compositions show nonconvexity handled additional cost complexity begin allocating enough processors throughput constraint met assuming denote subchain comprised compute optimal response time function c j subject throughput constraint using principle optimality9 write recursive definition u min dynamic programming equation understood follows suppose already computed function c j gamma1 implicitly asserts know optimally allocate number processors j gamma1 next given x processors distribute tasks j every combination subject throughput constraints processors j x gamma processors principle optimality tells us leastcost combination gives us optimal assignment x processors j since equation written recursion computation actually build response time tables bottom starting task 1 first part equation procedure requires onp 2 time unable find solution gives better worstcase behavior cases difficulties one encounters may appreciated study previous example consider construction 2 comprised series composition let f 1 denote response time function 1 table 3 gives values 8 set possible sums associated allocating fixed number processors x lie assignment diagonal moving lower left assign processors 1 one 1 upper right assign one processor 1 table illustrated use common typeface diagonal brute force computation 2 x consists generating sums associated diagonal choosing allocation associated least sum general case equivalent looking minimum function known sum function decreases eg f 1 one increases eg unlike case functions known convex well general sum special structure exploitthe minimum achieved anywhere implying look everywhere would seem dynamic programming may offer leastcost solution problem note passing straightforward optimization may reduce running time 29 43 72 59 54 table 3 sum response time functions f 1 f 1 minimum value assignment diagonal marked better asymptotic complexity functions summed convex minimum values adjacent assignment diagonals must adjacent row column fact considerably accelerate solution time since given minimum xprocessor assignment diagonal find minimum diagonal generating comparing two additional entries consequence greedy algorithm described earlier although cannot general assume functions convex view piecewise convex thus 1 convex b 1 convex c convex b theta c efficiently find minima assignment diagonals restricted subdomain working details straightforward one finds complexity approach ornp r maximum number convex subregions spanned given assignment diagonal course worst case leaving us still onp 2 algorithm 4 seriesparallel tasks algorithms analysis series parallel task structures used analyze task structures whose graphs form seriesparallel directed acyclic graphs show response c c c ae ae figure 2 binary decomposition tree time function graph n nodes computed onp 2 time number different equivalent definitions seriesparallel graphs exist one use taken 34 seriesparallel dag parsed binary decomposition tree bdt time proportional number edges leaves tree correspond dag nodes internal tree nodes describe either parallel p series compositions figure 2 illustrates bdt labeling p nodes task names used discussion corresponding task figure 1 structure bdt specifies precise order apply analyses idea build overall optimal responsetime function bottom conceptually mark every bdt node computed leaf nodes ones marked initially enter loop iteration identify unmarked bdt node whose children marked apply series composition parallel composition childrens responsetime functions depending whether node type p mark node algorithm ends root node marked example 1 response time function generated using parallel algorithm 2 3 series composition applied 1 1 composite task 2 composed via another series composition 4 creating 3 finally 5 combined via parallel composition 3 create response time function overall task structure step one must record actual number processors assigned task order compute optimal assignment straightforward needs discussion see cost determining optimal assignment bdt onp 2 every responsetime function composition worst case cost op 2 compositions performed 5 throughput problem real time applications often require processing every data set meet responsetime deadline system design time becomes necessary assess maximal throughput possible constraint throughput problem section show solutions responsetime problem used solve new problem onp 2 log p time approach depends fact minimal response times behave monotonically respect throughput constraint lemma 51 pipeline computation let f p minimal possible response time using p processors given throughput constraint assumption static processortotask mapping every fixed p f p monotone nondecreasing function proof let p fixed let u minimum number processors required elemental tasks comprising meet throughput constraint every monotone nondecreasing function recall p set assignments meet throughput constraint using p processors whenever must p monotonicity u since f p minimum cost among assignments p f 2 p result viewed generalization bokharis graphbased argument monotonicity minimal sum cost given bottleneck cost 4 suppose given pipeline computation able solve f p given set possible throughput values f1f needed generate sort given response time constraint fl tentative throughput may determine whether f p fl since f p monotone use binary search identify greatest f p fl associated processor assignment maximizes throughput using p processors subject response time constraint fl olog p solutions responsetime problem complexity throughput problem onp 2 log p 6 application section report results applying methods motion estimation system computer vision motion estimation important problem goal characterize motion moving objects scene computational point view continually generated images camera must processed number tasks primary goal ensure computational throughput meets input data rate subject constraint desire response time small possible application described detail 8 21 noted many approaches solving motion estimation problem interested example therefore following algorithm presented best way perform motion estimation comprehensive digest papers topic motion understanding found 22 following subsection briefly describes underlying computations 61 motion estimation system example problem linear pipeline nine stages stage task data sets input task system continuous stream stereo image pairs scene containing moving vehicles tasks perform wellknown vision computations 2d convolution extracting zero crossings feature matching similar computations image understanding benchmark 35 nine tasks implemented distributed memory machine intel ipsc2 hypercube 5 applied system problem using outdoor images 8 relevant responsetime functions shown table 4 selected processor sizes measurements include overheads computation time communication times response times individual tasks sec task 1 task 2 task 3 task 4 task 5 task 6 task 7 task 8 task 9 proc 64 212 011 0007 061 212 011 0007 413 071 table 4 completion times individual tasks intel ipsc2 various sizes seconds indicates extrapolated values figure 3 minimal response time function throughput constraint 62 experimental results applied series task algorithm using table 4 range possible throughput constraints example output generated algorithm table 5 shows processor assignment individual tasks various sizes intel ipsc2 last row table also shows minimum response time given constraint framessecond response times shown predicted algorithms nevertheless observed response times using computed allocations observed excellent agreement figuresthe relative error less 5 measurable cases processor allocation behavior intuitive tasks 1 5 8 much larger response times others increasingly processors allocated problem three tasks receive lions share additional processors figure 3 illustrates tension response time throughput plotting minimal response time function entire pipeline computation function throughput con straint problem throughput min achieved processors allocated entirely minimize response time flat region curve lies throughput constraints min response time curve turns sometimes dramatically throughput constraint moves region response time must traded increased throughput multiprocessor size procs task proc time proc time proc time proc time asgn sec asgn sec asgn sec asgn sec table 5 example processor allocation minimizing response time several sizes ipsc2 processors allocated individual tasks shown summary paper consider performance optimization seriesparallel pipelined computations problem arises system individually parallelizable tasks applied repeatedly long sequence data sets given large supply processors parallelism exploited pipelining data sets task structure allocating multiple processors individual tasks treat dual problems minimizing response time subject throughput constraint maximizing throughput subject response time constraint showed problems p processors n tasks satisfying seriesparallel precedence constraints solved loworder polynomial time response time subject throughput constraint minimized onp 2 time throughput subject response time constraint maximized onp 2 log p time place work realistic setting evaluated performance assignment algorithms problem stereo image matching results predicted analysis observed close measured actual systems future endeavors include provision algorithms general task structures investigation dynamic assignment algorithms also believe results extended task models include branching encountered case statements feature essentially forces us treat response times throughputs stochastic also believe approach extended consider effects certain types communication contention r partitioning strategy nonuniform problems multiprocessors scheduling multiprocessor tasks minimize schedule length shortest tree algorithm optimal assignments across space time distributed processor system partitioning problems parallel benchmarking ipsc2 hypercube multiprocessor embedding rectangular grids hypercubes algorithms mapping partitioning chain structured parallel com putations parallel architectures parallel algorithms integrated vision systems dynamic programming models applications dynamic partitioning transputer environment complexity scheduling parallel task systems discrete optimization via marginal analysis solving problems concurrent processors vol architecture hypercube supercomputer embedding arbitrary meshes boolean cubes expansion two dilation two fundamentals computer algorithms mapping systolic algorithms onto hypercube multistage linear array assignment problem pipelined dataparallel algorithms processor partitioning problem specialpurpose partitionable systems point matching time sequence stereo image pairs motion understanding embedding rectangular grids square grids dilation two improved algorithms mapping parallel pipelined computa tions utilizing multidimensional loop parallelism large scale parallel processor systems minimal mesh embeddings binary hypercubes characterizations parallelism applications use scheduling scheduling algorithms pipe pipelined imageprocessing engine multiprocessor scheduling aid network flow algorithms optimal partitioning cache memory allocating programs containing branches loops within multiple processor system recognition series parallel digraphs integrated image understanding benchmark parallel computers tr allocating programs containing branches loops within multiple processor system scheduling multiprocessor tasks minimize schedule length partitioning strategy nonuniform problems multiprocessors nearestneighbor mapping finite element graphs onto processor meshes solving problems concurrent processors vol 1 general techniques regular problems partitioning problems parallel pipeline distributed computing scheduling algorithms pipe pipelined imageprocessing engine minimal mesh embeddings binary hypercubes embedding rectangular grids hypercubes characterizations parallelism applications use scheduling complexity scheduling parallel task systems utilizing multidimensional loop parallelism large scale parallel processor systems embedding rectangular grids square grids dilation two dynamic partitioning transputer environment multistage linear array assignment problem darpa image understanding benchmark parallel computers improved algorithms mapping pipelined parallel computations optimal partitioning cache memory dynamic programming computer algorithms parallel architectures parallel algorithms integrated vision systems motion understanding mapping systolic algorithms onto hypercube pipelined data parallel algorithmsii ctr ian foster david r kohr jr rakesh krishnaiyer alok choudhary double standards bringing task parallelism hpf via message passing interface proceedings 1996 acmieee conference supercomputing cdrom p36es january 0101 1996 pittsburgh pennsylvania united states jaspal subhlok gary vondran optimal mapping sequences data parallel tasks acm sigplan notices v30 n8 p134143 aug 1995 jaspar subhlok gary vondran optimal latencythroughput tradeoffs data parallel pipelines proceedings eighth annual acm symposium parallel algorithms architectures p6271 june 2426 1996 padua italy g srinivasa n prasanna compilation parallel multimedia computationsextending retiming theory amdahls law acm sigplan notices v32 n7 p180192 july 1997 thomas gross david r ohallaron jaspal subhlok task parallelism high performance fortran framework ieee parallel distributed technology systems technology v2 n3 p1626 september 1994 weikeng liao alok choudhary donald weiner pramod varshney performance evaluation parallel pipeline computational model spacetime adaptive processing journal supercomputing v31 n2 p137160 december 2004 sandeep koranne note systemonchip test scheduling formulation journal electronic testing theory applications v20 n3 p309313 june 2004 jaspal subhlok david r ohallaron thomas gross peter dinda jon webb communication memory requirements basis mapping task data parallel programs proceedings 1994 conference supercomputing p330339 december 1994 washington dc united states jaspal subhlok david r ohallaron thomas gross peter dinda jon webb communication memory requirements basis mapping task data parallel programs proceedings 1994 acmieee conference supercomputing november 1418 1994 washington dc john w chinneck vitoria pureza rafik goubran gerald karam marco lvoie fast tasktoprocessor assignment heuristic realtime multiprocessor dsp applications computers operations research v30 n5 p643670 april martin fleury andrew c downton adrian f clark performance metrics embedded parallel pipelines ieee transactions parallel distributed systems v11 n11 p11641185 november 2000 jinquan dai bo huang long li luddy harrison automatically partitioning packet processing applications pipelined architectures acm sigplan notices v40 n6 june 2005