performance synchronized programs distributed networks random processing times transmission delays synchronizer compiler transforms program designed run synchronousnetwork program runs asynchronous network behavior simplesynchronizer also represents basic mechanism distributed computing forthe analysis marked graphs studied even rajsbaum 1990 theassumption message transmission delays processing times constant westudy behavior simple synchronizer processing times transmissiondelays random main performance measure rate network ie theaverage number computational steps executed processor network per unittime analyze effect topology probability distributions therandom variables behavior network random variables exponentialdistribution provide tight ie attainable bounds study effect abottleneck processor rate b introduction consider network processors communicate sending messages along communication links network synchronous global clock whose beats heard processors simultaneously time interval clock beats long enough messages reach destinations local computational steps completed clock beats network asynchronous global clock transmission times messages unpredictable computer science department present address instituto de matematicasunam ciudad universitaria df 04510 mexico rajsbaumredvax1dgscaunammx electrical engineering department moshetechsel general program designed synchronous network run correctly asynchronous network instead designing new program asynchronous network possible use synchronizer a1 ie compiler converts program designed synchronous network run correctly asynchronous network synchronizers provide useful tool programs synchronous networks easier design debug test programs asynchronous networks furthermore important use synchronizers design efficient asynchronous algorithms a2 problem designing efficient synchronizers studied past eg a1 ap90 pu89 worst case time complexity distributed algorithm usually computed assuming processing times message transmission delays equal constant represents upper bound durations goal paper study effect random processing times transmission delays performance synchronous programs running asynchronous network control simple synchronizer compare results deterministic case er1 er2 processing times well message delays constant bounded operation synchronizer follows processor waits message arrive incoming links performing next computational step computational step completed random time sends one message outgoing links implementation synchronizer may require instance every message followed endofmessage marker even message empty endofmessage markers model flow information must exist every pair processors connected link computational step a2 processor knows wait message sent message sent use synchronizer analysis since simple yet captures essence synchronizer methodology ie ensures processor initiate new phase computation knowing messages sent previous phase already arrived moreover synchronizer equivalent marked graph eg chep initial marking one token per edge ra91 rm92 relationship synchronizers marked graphs studied shown simple synchronizer model behavior marked graph synchronizers a1 distributed schedulers bg89 mmz88 thus work closely related problems stochastic petri nets due huge size state space solution techniques often rely simulation eg m1 m2 ma89 many distributed protocols based simple synchronizer example snapshot algorithm cl85 clock synchronization algorithms eg bs88 og87 synchronizers a1 distributed schedulers bg89 mmz88 optimistic synchronizer grst92 synchronizer similar synchronizer ff a1 used also directed networks opposed synchronizers suggested a1 require links bidirectional er1 er2 benefits using synchronizer initialization procedure described main results paper devoted performance analysis strongly connected directed networks controlled simple synchronizer transmission delays well time takes processor complete computational step random variables main performance measure rate computation r v ie average number computational steps executed processor network per unit time facilitate presentation first assume transmission delays negligible end paper describe extend results networks nonnegligible delays section 3 study case random variables general probability distributions consider two approaches first section 31 analyze effect topology rate use stochastic comparison techniques compare rate networks different topologies give examples networks different topologies rate section 32 analyze networks topology different processing times defining partial order set distributions show deterministic ie constant processing times maximize rate computation case shown er1 processing times equal gamma1 rate network regardless number processors network topology next section show case processing times random unbounded rate may degraded logarithmic factor number processors occurs case exponentially distributed processing times however section show exponential worst among large natural class distributions yields minimum rate within class distributions section 4 concentrate case processing times exponentially distributed random variables mean gamma1 prove rate 4 logffi maximum minimum vertex indegree outdegree hence regulardegree either outdegree networks rate theta logffi compute exact rate stationary probabilities extreme cases directed cycle complete graph finally study effect one processor runs slower rest processors show sense directed cycle network sensitive bottleneck processor complete network last section show easy extend results networks nonnegligible transmission delays consider exponential distribution case show adding transmission delays regular degree network may reduce rate constant factor provided larger wrt partial order processing times networks processing times exponentially distributed mean 1 larger delays mean gamma1 compare results er2 shown corresponding deterministic case rate probabilistic case regulardegree network rate least theta log ffi thus cases small large delays rate bounded degree network reduced constant factor previous work exist several results related results section 32 literature stochastic petrinets instance dominance results rather general stochastic petrinets obtained ba89 recently bl91 using subadditive ergodic theory eg k73 noted however proofs provide simple synchronizer different much simpler require heavy mathematical tools stochastic ordering studies exist papers acyclic networks forkjoin queues pv89 bm89 bms89 bmt89 respectively closed queueing networks effect increasing service rate subset stations systems distribution number works station product form solution studied sy86 model similar model section 4 considered bt89 claimed rate 1 log ffi regular networks outdegree equal ffi identically exponentially distributed transmission delays mean 1 negligible processing times bs88 lower bound theta1 log ffi rate given regular networks indegree equal ffi negligible transmission delays identically exponentially distributed processing times recently shown bk91 subadditive ergodic theory used derive general lower bounds rate bottleneck problem related considered b88 asymptotic analysis cyclic queues number costumers grows presented asymptotic performance stochastic marked graphs number tokens grows studied m2 class networks exponentially distributed processing times belongs general model stochastic petri nets see ma89 survey usually assumed state space exponential size case given network modeled finite directed strongly connected graph gv e ng set vertices graph e v theta v set directed edges vertex graph corresponds processor running program directed edge corresponds communication link processor u processor v case shall say u inneighbor v v outneighbor u network processors communicate sending messages along communication links facilitate presentation assume message transmission delays negligible end briefly discuss case nonnegligible transmission delays initially processors quiescent state send messages perform computations processor leaves quiescent state never reenters considered awake awakened processor operates phases described sequel assume arbitrary time tv processor v leaves quiescent state enters first processing state ps 0 may caused message another processor signal outside world considered model processor v remains units time transits first waiting state ws 0 time let ps k ws k k 0 denote processing state waiting state respectively kth phase observe concerned rate computation network nature computation concern us thus take liberty denoting symbol kth processing state processors transition rules states follows processor v transits state ps k ws k sends one message outgoing edges messages denoted note labeling needed implementation protocol used analysis v sends k messages say v completed kth processing step processor v state ws k received message k incoming edges removes one message incoming edges transits state ps k1 remains k1 v units time transits state ws k1 otherwise least one incoming edge k yet arrived processor v remains state ws k receives message inneighbors operates described processing times k v correspond time takes processor v complete kth computation step processing times k v k 0 positive realvalued random variables defined probability space k v k v whenever g understood kth completion time ie time processor v sends messages k network g let inset vertex v g g v simply inv set vertices g edge v including v fvg notation operation processor follows v sent message k time k v waits processors edge send message k starts 1st computation step maximum k u u 2 inv starts 1st computation step takes units time sends k1 reason shall assume rest paper vertex v edge v v e evolution network described following recursions 1 interesting note completion times k v simple graph theoretic interpretation vertex v let k v set directed paths length k ending v 0 path length 0 ending v consists v path p vg thus set random variables one sum k1 random variables note random variables independent even vs independent explicit computation k v follows theorem 21 every proof induction k note path length 0 v v ie vg hence assume theorem holds k 0 recursion inductive hypothesis gives desired result performance measures important performance measures investigated paper completion times k v k 0 v 2 v related performance measure interest counting process v simply n v associated processor v defined n v number computation steps minus 1 completed v time highest index k message sent v time similarly denotes total number processing steps minus n executed network time following claim indicates processor advance terms executed processing steps far ahead processor 22 let diameter directed strongly connected graph g proof denote l length simple path u v simple inductive argument l shows fact last message sent u time mn u implies argument simple path v u proves n u gamma n v another important performance measure computation rate r g v simply rv processor v network g defined whenever limit exists similarly computation rate network defined r delta 22 implies every u 3 general probability distributions section compare performance different networks general distributions processing times k v first show adding edges network arbitrary topology slows operation processors network show theory graph embedding used compare rates different networks example present graphs rate constant factor general distributions although different topologies finally compare networks arbitrary topology different distributions processing times specifically show determinism maximizes rate exponential distributions minimize rate among large class distributions 31 topology network 311 monotonicity show adding edges network arbitrary topology slows operation processors network basic methodology used sample path comparison compare evolution message transmissions different networks every instance realization random variables k v yields stochastic ordering various networks ro83 s84 theorem 31 let gv e graph e set directed edges let graph obtained g adding edges assume processor v awakens g h time tv every realization random variables k v k 0 1 v n following inequalities hold proof proof induction k basis induction trivial since induction hypothesis g v need show g v equation 1 since g v h v follows therefore follows 2 g k1 v v previous theorem implies immediately corollary 32 conditions theorem 31 n g v r g v r h v limits exist v 2 v also n g remark 1 notice assumption made random variables k v partic ular need independent remark 2 sample path proof implies random variable n g stochastically larger random variable n h denoted n g ff remark 3 implies one starts simple directed cycle strongly connected graph least number edges successively adds edges complete graph obtained without ever increasing rate 312 embedding theory graph embedding used model notion one network simulating another general computational task see example r88 show notion graph embedding helpful comparing behavior rates different networks controlled synchronizer embedding graph g graph h specified onetoone assignment ff nodes g nodes h routing ae eg pathsh edge g along distinct path h dilation embedding maximum amount routing ae stretches edge g dilation measure delay incurred simulation according embedding following theorem generalization theorem 31 theorem 33 let ff ae embedding dilation graph gvg eg graph distribution every realization random variables following inequalities hold proof path length k 0 g one use ae construct path h length less equal k delta ffv 0 ffv k passing ffv 1 moreover path length exactly k delta since one revisit vertices vertex selfloop time pair vertices ffv ffv i1 less edges path aev path h assuming realization k every u 2 vg follows every path p g k exists path p h kd thus theorem 21 g kd ffv corollary 34 conditions theorem 33 delta n g ffv limits exist v 2 vg remarks 13 hold case simple corollary theorem 33 g subgraph h n g g subgraph h embedding g h dilation 1 addition number vertices g h equal dilation embedding g dspanner h eg ps89 pu89 following corollary 35 h dspanner g r g r h r g motivation theory embedding simulation namely one expects embedding ff ae g h dilation architecture h simulate steps architecture g general computation order delta steps routing messages according ae approach compare performance g h synchronizer without using ae embedding used purpose proving statements performance networks consider example following two results theory embedding r88 proposition 36 one embed order n shuffleexchange graph order n debruijn graph dilation 2 one embed order n debruijn graph order n shuffleexchange graph dilation 2 proposition 37 one embed order n cubeconnectedcycles graph order n butterfly graph dilation 2 one embed order n butterfly graph order n cubeconnectedcycles graph dilation 2 theorem 33 average rate graphs proposition 36 37 equal constant factor 2 provided processing times corresponding processors distributions regardless distributions 32 probability distributions 321 deterministic processing times compare networks say gv eand hv e arbitrary topology operate different distributions random variables k v end assume processing times g independent finite mean e g v say v potential rate v would rate v would wait messages inneighbors processing times h distributed g except subset v 0 v processors processing times assumed deterministic ie h specific realization random variables g assumed processors awakened time networks theorem 38 conditions processors v k 0 expectation taken respective distributions processing times processors g v 0 proof proof induction k basis observe induction hypothesis h k v need show h 1 jensens inequality implies induction hypothesis since e g remark 4 theorem 38 holds also processing times h k v processors v h v 0 deterministic necessarily every k processing times network h deterministic computation network rate longer stochastic problem combinatorial one thus conclusion theorem 38 case computation rate h obtained via combinatorial techniques er1 er2 yields upper bound average rate g furthermore times h k v computed give lower bound et g k v every k 0 322 variable processing times generally study effect substituting random variable network eg processing time given processor given computational step given distribution random variable another distribution rate network define ordering among probability distributions recall function h convex distribution fx said variable random variable distribution f denoted x c fx c f ehx ehy increasing convex functions h partial order c called convex order eg ro83 s84 intuitively x variable fx gives weight extreme values f instance ex convex function compare networks say gv e hv e arbitrary topology processing times g variable corresponding processing times h ie ks vs g k v processing times distributions graphs g processing times g h independent following holds theorem 39 conditions following holds processors v k 0 proof theorem 21 directed path length k ending v fact positive max convex increasing functions follows k v convex increasing function arguments f vg use proposition 854 ro83 proposition 854 independent rv independent rv increasing convex function g convex arguments proof theorem follows since assumption g independent h independent h note random variables independent corollary 310 conditions n g v r g v r h v r g r h next section show processing times independent exponential distribution mean gamma1 rate network least jv log jv j conclude subsection characterizing set distributions lower bound holds assume expected time processor finishes processing step given already working step ff time units less equal original expected processing time step namely assume distributions processing times k v new better used expectation nbue eg ro83 s84 processing time let g v e network deterministic processing times let g e v e network corresponding processing times mean independent exponentially distributed let gv e network corresponding processing times mean independent nbue distribution following theorem follows fact deterministic distribution minimum exponential distribution maximum respect ordering c among nbue distributions ro83 s84 theorem 311 every holds gd v examples distributions less variable exponential appropriate parameters gamma weibull uniform normal conclude section pointing interested reader find similar results rather general stochastic petrinets ba89 bl91 section assume processing times k v k 0 independent exponentially distributed mean gamma1 first consider general topologies derive upper lower bounds expected values k v thus obtain upper lower bounds rate network bounds depend indegrees outdegrees processors network number processors exploring markov chain underlying process derive exact rates two extreme topologies directed ring fully connected complete network two topologies study also effect single slower processor within network 41 upper lower bounds denote v v number edges going v g let v v ffi min v2v v lemma 41 lower bound every k 0 exists processor v 2 v ii every k 0 every v 2 v following holds log ffi proof present detailed proof part proof part ii discussed end start proving every k 0 exists necessarily simple path assume statement holds k 0 prove k 1 proof basis identical let v k1 processor processing time computational step maximum among outneighbors v k ie start 1st computational step v k finishes kth computational step k1 v k1 maximum least ffi independent identically distributed exponential random variables mean gamma1 well known eg bt89 d70 mean maximum c random variables least gamma1 log c follows chose v 0 one latest waking time tv 0 thus et 0 v therefore every k 0 exists processor v completing proof proof part ii evolves along lines except start v k move backwards along path remark 5 proof one see lemma 41 holds distribution f processing times expected value c maximum c independent rv distribution f exists case implies r v 1m c remark 6 lemma 41 implies exponential case slowdown rate least logarithmic maximum degree g remark 5 distributions nbue theorem 311 slowdown larger example f slowdown least square root maximum degree g d70 pp 58 lemma 42 upper bound every k 1 every processor v log delta ii every k 1 every processor v proof restrict proof part recall theorem 21 states every v also path p moment let proposition d2 appendix pr ck log delta ck log delta every c 4 since log 2 log delta 1 follows pr ck log delta ck log delta e gammak c log delta every c 4 z 4k log log delta e gammak c log delta log combining lemma 41 lemma 42 obtain theorem 43 log log 42 exact computations theorem 43 implies following bounds rate directed cycle c n complete graph k n number processors 036 r cn v 4 log n log n section shall compute exact values rates c n k n end consider markov chain associated network markov chain denoted number messages stored buffer edge time number edges network note processor positive number messages incoming edges processing state processor completes processing exponential time one message deleted incoming edges one message put outgoing edges denote 0 state x thus network represented marked graph eg chep number states markov chain finite say n transition chain change total number messages circuit network moreover network strongly connected markov chain irreducible therefore limiting probabilities states chain exist positive sum equal 1 eg c67ro83 however shall see n exponential n therefore infeasible compute rate directly solving markov chain show solve markov chain two network classes without produce entire chain hope combinatorial approach could applied networks well let gx denote transition diagram directed graph markov chain x consider bfs breadth first search tree gx rooted 0 level lv vertex v equal distance 0 v thus ls 0 0 set vertices level l number levels gx 421 simple directed cycle study performance simple directed cycle n processors c difficult observe markov chain associated c n corresponds closed queuing network return approach later choose use combinatorial approach theorem 44 states associated c n limiting probability ii graph g simple directed cycle hold proof proof follows two observations first symmetry states one level probability second indegree state transition diagram equal outdegree simple inductive argument used prove part ii g cycle node v st v 1 let two nodes edges v consider state reached 0 processing completion marked graphs terminology firing vertex v outdegree equal n gamma 1 apart v vertices still enabled indegree n gamma 2 firing v 1 v 2 possible reach since messages edges v therefore proved 6 consider balance equation holds state p limiting probabilities states edge limiting probability proved k 6 n gamma 1 follows possible probabilities last equation equal next theorem states processor c n works least half potential rate regardless value n theorem 45 rate rv processor c n limiting probability state 1n n number states associated chain proof number states least one message edge going processor say v running rate mn times expected firing rate v enabled 0 messages input edge since states probability theorem 44 percent time enabled simply mn number ways putting n objects k places difficult see gives desired results 422 complete graph let k n complete graph n processors recall n number states associated markov chain let 0 state edge one token state level l 0 l reached 0 firing l processors limiting probability state level l denoted p l theorem 46 rate processor k n log n proof simpler proof derived proof theorem 410 give combinatorial proof also yields number limiting probabilities states associated markov chain consider markov chain similar markov chain associated network k n root 0 state message edge state one son one enabled processors state son corresponds state arrived firing completion processing step one enabled processors state note chain several vertices corresponding state chain associated k n number states level l nn gamma l time processor fires fire rest processors fired thus number n states number states given processor enabled level l enl edges level l level l 1 level l nn gamma l gamma 1 enabled processors symmetry processor enabled number times level let us denote p l limiting probability state level l one show follows percent time processor enabled l rate delta ut corollary 47 network k n proof noted may two states correspond state say k n fact state reached 0 firing sequence processors length k k permutations processors sequence constitute valid firing sequence leads state thus limiting probability state level l number different states level l nln gamma l total number different states corollary 48 asymptotically rate network n processors n2 n log n observe best possible rate processor 23 potential rate case cycle two processors adding processors lower rate 12 yet rate network grows linearly n case complete graph rate processor reduces n grows also total number computational steps executed per unit time n log n grows n 43 bottlenecks suppose potential rate processors graph except one lower rate shall show bottleneck stronger effect network directed cycle one complete graph consider case simple directed cycle n vertices cb n processors rate one processor rate using standard techniques queuing theory prove following theorem 49 rate processor cb n ae n number messages buffer incoming edge processor total number messages cycle equal n since closed queueing system limiting probability system state given following product form ro equal 0 otherwise k normalization constant guarantees sum probabilities equal 1 thus probability l messages incoming edge processor n lg hence k 0 normalization factor determined condition finally ae l observe rate simply rate processor messages incoming edge processor n several conclusions derived theorem 49 first observe rate cycle cannot exceed n thus slow processor bounds rate network moreover fixed n slow processor 0 ae 1 rate network ae gamman namely ae increases rate approaches upper bound n next consider case graph complete graph kb n continue assume rate processors nth processor slower operating rate shall show fixed number processors n grows infinity influence slow processor diminishes limit rate network network processors running rate theorem 410 rate processor kb n least proof suppose network state 0 given time time 1 returns state time 2 returns ft sequence nonnegative independent random variables common distribution f expected value et denote nt number events returning 0 time counting process renewal process therefore probability 1 see example ro83 moreover since time process returns 0 processor network completed exactly one computational step follows rate network 1et proceed bound et expected time takes return 0 form 1 j n depending slow processor completes computational step system leaves 0 slow processor completed computational step et ff 1 general jth 1 j n processor complete computational step leaving slow processor et ff j probability et j equal ff j necessarily every j case holds ff j ff j1 thus gives upper bound time et takes return 0 1ff n lower bound rate processor network log n see et log n thus rkb n least 1 fixed r v theta log n observe rate network cannot exceed however number processors n increases infinity rate network decreases proportion 1 log n slower processor network briefly discuss case nonnegligible transmission delays model processing times random transmission delays also random denote transmission delay message k k 0 along edge follows behavior system described recursions note system equal one bt89 processing times negligible delays nonnegligible selfloop processor model processing delay v path length k easy see modify definition p k thus theorem similar theorem 21 holds corresponding results general distributions consider case processing times well transmission delays exponentially distributed mean say 1 easy see lemma 41 still holds lemma 42 holds factor 2 namely theorem 39 regular network nonnegligible delays runs rate network constant factor provided delays less equal convex order processing times er1 show network negligible delays deterministic processing times equal 1 rate network equal 1 thus case random processing times degrade rate logarithmic factor maximum degree processor consider case processing times mean 1 delays exponentially distributed rate deterministic case equal er2 thus theorem 33 case rate one prove using proposition d2 also case nonnegligible delays rate degraded logarithmic factor maximum degree processor respect optimal deterministic case nbue distribution exact computations networks average processing times delays exponentially distributed mean 1 rate simple cycle computed using tools queuing theory used case negligible delays compute rate complete network k n things straightforward structure markov process complicated arguments rate 18 log n 1 log n however using ideas embedding let us show rate k n least 14 log n let k 0 n complete network negligible delays construct g n inserting one vertex edges theorem 31 also 39 rate processor g leastlogn one show rate processor v k n greater equal half rate corresponding processor g using using fact embedding k n g dilation 2 therefore rate v k n least 14 log n 6 conclusions paper studied behavior synchronizers networks random transmission delays processing times attempted present selfcontained general study synchronizer performance view point distributed algorithms rather providing deep mathematical study underlying stochastic process particular interested comparing behavior synchronizers random delays opposed usual approach analyzing distributed algorithms bounded delays main conclusion delays belong natural class nbue distributions rate network degraded small local vertex degree factor presented several properties behavior synchronizer general probability distributions described techniques useful compare rate synchronizer running networks different topologies exponential distributions showed expected duration round computation depends logarithm vertex degree hence rate computation diminishes number processors network presented techniques prove upper lower bounds rate obtain exact computations hope combinatorial approach techniques applied rings complete networks regular degree networks used future obtain results topologies well following proposition similar pp 672 bt89 used prove lower bounds rate network proposition 71 d2 let x sequence independent exponential random variables mean gamma1 every positive integer k c 4 log 2 pr ck proof fix fi 2 0 let fl positive scalar direct calculation yields z 1e fixgammafl e gammax particular choose fl sufficiently large e theta 1 satisfies last equation using independence random variables x obtain e fi using markov inequality obtain e fikm pr e fi turn implies pr pr pr fi2 choose fi 2 acknowledgments would like thank gurdip singh gil sideman helpful comments r complexity network synchronization reducing complexities distributed maxflow breadthfirst search algorithms means network synchronization network synchronization polylogarithmic head sojourn times cyclic queues influence slowest server ergodic theory stochastic petri networks concurrency heavily loaded neighborhood constrained systems estimates cycle times stochastic petri nets comparison properties stochastic decision free petri nets queueing models systems synchronization constraints forkjoin queue related systems synchronization constraints stochastic ordering computable bounds acyclic forkjoin queueing networks investigations faulttolerant networks computers parallel distributed computation markov chains stationary transition probabilities marked directed graphs distributed snapshots determining global states distributed systems order statistics lack global clock slow computation distributed networks use synchronizer yields maximum rate distributed networks tentative definite distributed computations optimistic approach network synchronization subadditive ergodic theory stochastic petri nets elementary introduction analysis distributed scheduler communication networks performance analysis using stochastic petri nets fast bounds stochastic petri nets generating global clock distributed system graph spanners optimal synchronizer hypercube stochastic bounds execution times task graphs shuffleoriented interconnection networks stochastic marked graphs analysis distributed algorithms based recurrence relations comparison methods queues stochastic models effect increasing service rates closed queueing network tr complexity network synchronization parallel distributed computation numerical methods investigations faulttolerant networks computers acyclic forkjoin queuing networks concurrency heavily loaded neighborhoodconstrained systems optimal synchronizer hypercube stochastic petri nets elementary introduction unison distributed networks use synchronizer yields maximum computation rate distributed networks upper lower bounds stochastic marked graphs distributed snapshots fast bounds stochastic petri nets analysis distributed algorithms based recurrence relations preliminary version tentative definite distributed computations analysis distributed scheduler communication networks shuffleoriented interconnection networks ctr julia lipman quentin f stout performance analysis local synchronization proceedings eighteenth annual acm symposium parallelism algorithms architectures july 30august 02 2006 cambridge massachusetts usa omar bakr idit keidar evaluating running time communication round internet proceedings twentyfirst annual symposium principles distributed computing july 2124 2002 monterey california jeremy gunawardena maxplus algebra nonexpansive mappings nonlinear theory discrete event systems theoretical computer science v293 n1 p141167 3 february