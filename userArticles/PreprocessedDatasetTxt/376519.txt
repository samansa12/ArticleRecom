maximumlikelihood strategy directing attention visual search abstracta precise analysis entire image computationally wasteful one interested finding target object located subregion image useful attention strategy reduce overall computation carrying fast approximate image measurements using results suggest promising subregion paper proposes maximumlikelihood attention mechanism attention mechanism recognizes objects made parts parts different features works proposing object part image feature pairings highest likelihood coming target exact calculation likelihood well approximations provided attention mechanism adaptive behavior adapts statistics image features experimental results suggest average attention mechanism evaluates less 2 percent partfeature pairs selecting actual object showing significant reduction complexity visual search b introduction object recognition algorithms often two phases selection phase region subset image features chosen verication phase algorithm veries whether object present chosen region algorithm speed depends strategy used selecting regions call strategy attention strategy since task direct computational attention promising parts image classical object recognition algorithms xed attention strategies example template matching hough transform process image xed raster fashion 1 fixed strategies slow speed practical implementations employ adhoc preprocessing color thresholding adhoc procedures really attention strategies since purpose direct computation promising regions image adhoc preprocessing techniques useful two serious limitations 1 adhoc never sure best done 2 adhoc techniques usually unable adapt image statistics example consider strategy thresholding color object prominent red part image may thresholded specic hue red problematic background also contains red objects case may better threshold color provided part object color capacity adapt attention mechanism statistics image critical good attention algorithm know human visual attention system capacity adhoc algorithms easily confounded faced certain backgrounds interpretation trees search subtrees xed priority aim propose attention algorithm overcome two limitations replace adhoc strategies strategies based probabilistic decision theory particular investigate strategy based maximumlikelihood ml decision rule ml rule turns give adaptive strategy formulate problem follows assume object recognition system composed three subsystems 1 preattentive system 2 attention mechanism 3 postattentive system preattentive system fast feature detector operates entire image detects simple image features color edge roughness corner angles etc detected features come target object rest come objects image called distractors assume object composed parts part gives rise single feature image role attention mechanism choose object part pair image feature hypothesize pairing due presence object image hypothesis passed postattentive system uses full geometric knowledge object explores image around feature nd object postattentive system traditional object recognition algorithm indicates attention mechanism whether hypothesis valid hypothesis valid attention mechanism takes account proposes next hypothesis postattentive system focuses region image process terminates either object found features image exhausted postattentive system preattentive system attention mechanism features hypothesis validation object model slow processing region interest figure 1 attention visual search make following assumptions attention mechanism 1 features detected preattentive system available time simply another way saying preattentive system fast enough process entire image detailed search postattentive system begins 2 attention mechanism uses values features detected preattentive system attention mechanism evaluate additional geometric constraints looking pairs image features example imposing geometric constraints computationally expensive wish avoid expense 2 3 attention mechanism greedy every stage chooses partfeature pair highest likelihood coming object image likelihood evaluated taking account previous pairs rejected postattention mechanism make assumptions particular assume specic pre post attentive systems strategy derive used range usersupplied modules demonstrate experiments use corner detectors well color detectors preattentive systems postattentive systems slow precisely evaluate geometric constraints paper address 2d object recognition kept formulation simple possible design want emphasize basic ideas certain approximations theory paper made sophisticated adding features considering multiple spatial resolutions clustering preattentive features etc alternatives pursued paper human visual attention human vision known attention strategy highly eective 14 22 28 human visual attention adaptive sense discussed cognitive scientists yet complete understanding human visual attention partial understanding emerged many models proposed cognitive scientists similar model gure 1 22 28 models preattentive system fast capable extracting primitive image features color edge smoothness size postattentive system slower analyze image regions detail use complete geometric denition target object recognition human attention mechanism uses primitive features produced rst system direct second key aspect human visual seems use feature values local feature density directing attention appear evaluate geometric constraints primitive features behavior human visual attention two conditions called popout camou age particularly interesting image contains target whose primitive features suciently dierent distractor features time required nd target independent number distractors image 22 popout condition condition target seems pop image hand target features similar distractors time required nd target grows linearly number distractors call camou age condition section 5 show theoretically popout camou age emergent properties algorithm section 6 conrm experimentally relation previous work researchers presented strong cases using attention vision algorithms 23 24 researchers proposed specic computational mechanisms model known human visual search 10 11 others proposed search algorithms specic cues parallelline groups 17 color 5 18 texture 19 prominent motion 25 blobs scale space 12 intermediate objects 27 authors considered attention scene interpretation 16 others applied passive tracking 21 active vision systems 2 15 aim quite dierent studies wish implement specic biologybased attention algorithm one tailored particular cue instead ask whether possible derive attention strategy rst principles applied range cues finally wish address source confusion algorithm sometimes compared interpretation tree algorithm object recognition 1 6 7 confusion arises apparent similarity two attempt match object parts image however similarity supercial substantial dierences two algorithms 1 two algorithms operate dierent level concerned interaction pre post attentive modules rather organizing geometric comparison parts features interpretation trees concerned latter 2 interpretation trees match entire object edges image algorithm concerned evaluating likelihood single part matching single feature given object present image 3 interpretation tree explicitly geometric algorithm purpose systematically evaluate geometric relations image edges hand attention mechanism concerned geometric relations works arbitrary feature types many enforce geometric constraints parts comments meant criticism interpretation trees simply meant show two dierent goals fact two used together interpretation tree serving postattentive system capable fully recognizing object organization paper paper organized follows section 2 contains denitions notations section 3 contains likelihood calculations calculation exact likelihood computationally expensive section 4 contains approximations section 5 analyzes behavior ml attention strategy special case demonstrates adaptive nature section 6 contains experimental results section 7 concludes paper denitions 21 features parts begin dening features feature mean primitive element image color corner etc found simple feature detectors feature value rgb triple color angle corner etc belongs feature space v set features image f refer value k th feature f k features image come instance object wish detect target features others come objects image distractor features object recognized parts fs j set parts p parts need dened geometric way requirement union parts entire object part may visible may completely occluded image prior probability part j visible image probability complete occlusion part 1 p j assume visible part gives rise single feature image thus multiple parts cannot contribute feature part cannot give rise multiple features part visible may still partially occluded feature value may change due partial occlusion model saying jth part visible feature value random variable probability density function p j f assume distractor feature values realizations uniform poisson process feature space make assumption knowledge distractors would like treat values uniformly distributed v probability density obtaining n distractor feature values given process intensity v feature space volume 22 attention mechanism attention mechanism iterative works follows iteration mechanism chooses partfeature pair likely due target choice passed postattentive system evaluates whether pairing really due occurrence object due object object found search terminates attention mechanism takes information account suggests next likely pair denote pairing part sm feature fn sm fn since set parts object p set image features f set possible partfeature pairings p f refer declared incorrect postattention mechanism rejected pair set rejected pairs till j th iteration algorithm denoted r j thus j th iteration set part feature pairs rejected p f r j notation pseudocode attention algorithm written 1 preprocess extract f set image features 2 initialize set empty set 3 loop condition set pairs remain tested j th iteration pf r j set empty terminate iteration declare object present image 4 candidate selection set pf r j choose pair greatest likelihood coming target image likelihood pair sm fn comes target image given set parts set image features set rejected pairs ml decision 5 object verication pass selected pair postattentive system verification hypothesis correct object found terminate search else 6 bookkeeping set r 1 go step 3 3 likelihood need formula ps execute algorithm begin simple calculation 31 parts visible assume moment rejected pairs parts object visible ie prior probability suppose n features feature set f rst evaluate likelihood specic set features came object parts rest features distractors describe pairing features parts introduce part mapping function indices parts indices features function says parts mapped features f 1 f 2 likelihood rest feature set accounted distractors expressions occur frequently analysis use special notation denote expression g features matched respectively h set distractor features notation likelihood f likelihood single comes target object sum likelihoods parts paired features restriction part sm always paired part fn mn sum functions satisfy next suppose set rejected pairs r j empty calculate likelihood sm fn due target must avoid summing part mappings give rise rejected partfeature pair say part mapping compatible set r j using notion write likelihood ps mn sum part mapping functions compatible r j satisfy 32 occluded parts next consider possibility parts may completely occluded prior probabilities p j necessarily equal 1 take account introduce additional features called null features part mapped null feature say completely occluded augment feature set f adding null features feature set n elements likelihood expressed mn sum compatible part mapping functions function given q j h evaluate likelihoods feature values come parts distractors taking account prior probability occlusion null features j null feature number nonnull features h far ignored fact know intensity distractor process required equation 7 however estimate data follows since p probability part visible average number visible parts thus average number distractors number must equal v average number distractors derived poisson distribution equations 48 completely dene likelihood 4 approximations likelihood equations 48 computationally expensive evaluate contain combinatorics mapping 1 parts n 1 features section propose two approximations rst involves using normal approximation poisson distribution allows us simplify expression likelihood eliminating terms second radical approximation involves using reduced number parts consider smaller objects formed taking rtuples parts original object calculate likelihood partfeature pair comes least one simpler objects nd practice simple case satisfactory results use approximation experiments completeness report calculations general r 1tuple case 41 normal approximation poisson distribution distractor values approximated normal distribution number distractors large 8 recall term summed equation 4 factor hh arising equation 5 appendix show n number null features mapped onto parts hh approximated exp exp exp c part expression independent n referring back equation 5 see term c common factor terms need evaluated interested nding partfeature pair maximizes likelihood equation 4 likelihood becomes mn function given exp c number null features j null feature g j null feature 12 last step equation 11 dropped c term included exp term denition r j 42 matching simpler models proceed second approximation recall calculating exact likelihood sm fn account combinatorics rest parts match features approximation considered account r 1 rest parts consider simpler objects formed part sm r 1 tuples parts evaluate likelihood sm fn comes least one simpler objects 43 approximate likelihood case simplied objects object exactly one unique part likelihood comes least one simpler parts equal likelihood comes object sm single part likelihood r f n 44 approximate likelihood case simplied objects object two parts part sm one part calculate likelihood pair sm fn comes least one simpler parts one specic part using equations 10 12 joint likelihood pair comes simplied object mn sum part mapping functions 1 map part index set fm ig feature index set 2 compatible r j 3 satisfy n functions r dened equation 12 expression easily rewritten mn right hand side sum feature indices k k 6 n pair therefore joint likelihood pair sm fn comes one 2part objects sum likelihood computational complexity expression onm 45 higher order approximations consider likelihood pairing sm due least one simplied object formed part sm r 1 parts original object expression likelihood messy simplify presentation adopt following convention represent ordered set r indices fs 1 one simplied object two dierent sets type represent two dierent combinations r parts object repeating calculation equation 13 get ii mm imn i2i rst sum second sum part mapping functions map feature index set compatible r j n complexity evaluating likelihood equation 14 oc n 1 r 1 calculations give us likelihoods used attention algorithm practice completes description algorithm next turn investigate adaptibility attention algorithm xdetected feature values figure 2 maximumlikelihood explanation popout 5 adaptation popout camou age 51 adaptation understand adaptive behavior algorithm consider following simple case 1 model two parts 1 2 neither part ever completely occluded ie 2 feature space one dimensional parts uniform feature distributions disjoint intervals probability density 1 occurs feature value f similarly probability density 2 occurs feature value f consider two situations 6 features image rst case suppose occur 1 sixth feature f 6 occurs 2 illustrated gure 2 second case reverse situation features f occur 2 sixth feature f 6 occurs 1 rst case likelihood 2 matches f 6 sum terms term corresponds 2 matching matching one feature ff 1 f 5 g rest features distractors term isl 2 hence likelihood consider likelihood single term corresponding 1 matching f 1 2 matching f 6 distractor features likelihood single likelihood 1 matches feature occurring 1 clearly likelihood 2 matches f 6 greater likelihood 1 matches f 1 feature 1 attention mechanism chooses former simply repeat calculation features f 2 one feature f 6 1 get likelihood part 1 matching feature f 6 asl 2 likelihood 2 matching features 2 isl 2 former clearly greater latter 1 2 ranges red blue colors two cases interpreted follows object two parts one colored red blue rst case image one blue feature red features second case image one red feature blue features attention algorithm chooses investigate blue feature rst case red feature second case thus algorithm adapts distribution features image chooses investigate feature least like distractor ie background features precisely adaptative behavior want attention algorithm calculation shows ml decision imparts algorithm easy check use approximation calculation algorithm adapt fact easy check general adaptation statistics features image possible r 2 finally recall popout camou age conditions human visual system nds target constant time time grows linearly number distractors popout achieved target feature suciently dierent distractors camou age occurs target features similar distractor features adaptive behavior discussed demonstrates popout since ml attention mechanism always chooses feature least like distractors contrast target distractor similar features say three features 1 2 likelihoods partfeature pairs would identical would reason prefer one search case would proceed without strong bias towards choosing particular pair time nd target similar blind serial search grow linearly number distractors camou age thus appears ml attention mechanism emulate popout camou age 6 experimental results next report experiments evaluate performance attention mechanism real images conducted three sets experiments experiment obtained number images target object present image calculated net number partfeature pairings possible used attention mechanism propose partfeature pairings set number partfeature pairings suggested attention mechanism till object found expressed fraction total number partfeature pairings taken performance measure attention algorithm preattentive system attention mechanism implmented c hand verication whether proposed partfeature pair belonged target object performed manually likelihood calculation priors p j set 10 61 corner features target object used rst experiment shown figure 3 cardboard cutout sh fifty images containing target produced placing model 30cm 30cm area commonly occurring laboratory tools tossed model images taken way model scale range 05 20 cases model partially occluded image model heavily occluded two 50 images none corners visible images discarded algorithm tested remaining 48 images figure 4 shows two 48 images figure 3 model preattentive system used corners edge contours image features corners dened points local maxima curvature edge contour together two arms abut point arms extend next point high curvature along contour length arm arc length figure 5a shows example curve parsed corners corners arms extracted images automatically edge detection followed edge linking curvature calculation figure 4 example images corner feature parameterized vector 2 parameters length shorter arm average angle deviation two arms see figure 5b target six corners chosen object parts distribution model features calculated follows target corner occluded software smaller arm length occlusion 100 80 60 unoccluded smaller arm length partial occlusion feature value calculated values represent samples distribution partial occlusion definition part b features part part longer arm shorter arm average angular deviation figure 5 features used experiments figure attentive search object percentage hypothesis evaluated1030 frequency figure 7 histogram percentage hypothesis evaluated recognition unit magnication process duplicated changing magnication software model 20 1707 05 set obtained wat fed standard nonparametric density estimator obtain probability distribution corner parameters part results approximate ml decision rule used r set 1 2 3 respectively figure 6 shows typical result ml visual search 2 gure shows sequence corners algorithm analyzed turn suggested target corner successful match also shown gure similar behavior obtained mentioned evaluate eectiveness ml attention mechanism measured average percentage hypotheses processed correct hypothesis suggested average rule processed 467 possible hypotheses processed 197 possible hypotheses processed 273 possible hypotheses clearly latter two rules outperformed rst rule since rule exhibit adaptation discussed section 5 dropped consideration since performed similarly r 3 rule slower execution rule appears good compromise eectiveness ability adapt computational complexity figure 7 shows histogram percentage hypotheses processed rule nd correct match mentioned average 197 possible hypotheses processed correct hypothesis found absence attention mechanism expected proportion hypotheses evaluated would 50 shows attention mechanism signicantly shortened search time popout camou age second experiment examined performance ml attention mechanism popout camou age conditions used approximate likelihood 2 simulate popout camou age conditions created similar dissimilar distractors dissimilar distractors created cutting triangular pieces cardboard similar distractors created duplicating target model cutting duplicates half along random lines figure 8 shows image model present along triangular dissimilar distractors popout condition figure 9 shows camou age condition multiple images obtained popout camou age conditions increasing number distractors figures 8 9 show typical sequences image features searched till target suggested popout camou age conditions figure 10 shows number hypotheses processed target suggested attention algorithm function total number features image popout case rst hypothesis always correct one camou age case number hypotheses increased monotonically number features image figure 8 search popout figure 9 search camou age 50 150 250 number features image1030 number fixations find object camouflage figure 10 number hypotheses evaluated vs image features b figure 11 search paths two ronaldo images ronaldo found immediately b ronaldo squatting lower left 62 color features third experiment used color features nding people photographs video stills object model 2 parts feature part color distribution pixels rgb space first conducted series experiments nding member brazilian soccer team luiz ronaldo variety backgrounds two parts correspond yellow blue teams uniform color distributions estimated taking sample color several images subject histogramming samples coarse 32 3 rgb cube smoothing normalizing fifty images containing ronaldo gathered internet images varying sizes images acquired frames mpeg movies criteria used select images 1 subject uniform visible image 2 images closeups case candidate selection task would much easy scale subject varied height range 5 100 pixels figure 11 shows two 50 images used single pixels image features image sampled grid points image 5 instances allowed player fall gaps sampling sampling quadrupled pixels although suggests many 4800 2 match hypotheses image reality selected pixels rgb values could produced either color distribution pixels discarded count potential hypotheses results experiment 086 possible hypotheses evaluated attention algorithm average correct hypothesis found figure 11 shows extreme examples popout camou age ronaldos shirt yellow object image immediately pops largely green background b camou aged teammates oer equally good matches color distributions wheres waldo nal example evaluated eectiveness ml attention wellknown wheres waldo game childrens book series goal nd title character pages lled highly detailed illustrations similar attempt also reported 13 implementation described used color densities waldos shirt shorts waldo small gure image pixels sampled full resolution 610 338 194380 2 non zeroprobability partpixel match possibilities 28 0007 examined algorithm suggested target location waldo total time entire search process aside object verication took figure 12 wheres waldo 018 seconds 266mhz singleprocessor pentium ii figure 12 search sequence nding waldo overlaid top image 3 experiments indicate ml attention strategy eective 2 furthermore mentioned section 1 strategy works geometric well nongeometric preattentive features conclusions paper proposed maximumlikelihood technique directing attention technique uses simple features found fast preattentive module direct slower accurate postattentive module attention mechanism recognizes target object made parts attempts nd pairing object part image feature likely come target image resulting attention strategy adaptive choice partfeature pair depends image feature statistics furthermore attention strategy demonstrates popout camou age two important properties human visual attention experiments real world images attention strategy signicantly reduces number hypotheses required evaluated target found acknowledgements greatly beneted discussions profs drew mcdermott anand rangarajan lisa berlinger yale university 3 particular image found httpwwwndwaldocomcitycityasp r hyper new approach recognition positioning twodimensional objects ferrier n finding waldo localizing overlapping parts searching interpretation tree object recognition computer handbook poisson distribution selective attention vision brown c wang j mudge ballard cave k tr ctr toshiyuki kirishima kosuke sato kunihiro chihara realtime gesture recognition learning selective control visual interest points ieee transactions pattern analysis machine intelligence v27 n3 p351364 march 2005 fred h hamker emergence attention populationbased inference role distributed processing cognitive control vision computer vision image understanding v100 n12 p64106 october 2005 h bozma g akirolu soyer biologically inspired cartesian noncartesian filters attentional sequences pattern recognition letters v24 n910 p12611274 01 june c fang c fuh p yen cherng w chen automatic road sign recognition system based computational model human recognition processing computer vision image understanding v96 n2 p237268 november 2004 soyer h bozma istefanopulos apes attentively perceiving robot autonomous robots v20 n1 p6180 january 2006