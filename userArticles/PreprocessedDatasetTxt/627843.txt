efficient bulkloading gridfiles abstractthis paper considers problem bulkloading large data sets gridfile multiattribute indexing technique propose rectilinear partitioning algorithm heuristically seeks minimize size gridfile needed ensure bucket overflows empirical studies synthetic data sets data sets drawn computational fluid dynamics applications demonstrate algorithm efficient able handle large data sets addition present algorithm bulkloading data sets large fit main memory utilizing sort entire data set creates gridfile without incurring overflows b introduction developing scientific database support retrieval subsets computational fluid dynamics cfd data sets retrieval subsets required visualization data exploration data two threedimensional thus requires multiattribute indexing specifically interested partially qualified fully qualified point queries gridfiles well known multiattribute indexing technique 5 basic idea partition attribute range subranges thereby inducing multidimensional rectilinear partitioning entire multiattribute space enough partitions chosen ensure tuples sharing subrange dimension fit disk page point query satisfied two disk accesses one fetch pointer data page one fetch data page data wish store contained files created cfd simulations size data sets anticipated extensive use data sets require provide fast organization new data fast retrivial existing data two dimensional data typically large set tuples form current data sets measure tens megabytes projected 23 orders magnitude larger soon although specifically concerned cfd data sets large physically oriented data sets common outputs wide spectrum scientific computations paper show quickly load entire data files gridfile indexing structure termed bulk loading note similar functionality required relational databases reloading relations changing platforms recovery reorganization relational database relation analogous data set work main contributions paper 1 partitioning algorithm requires two four orders magnitude less cpu time known algorithm partitioning data gridfile blocks provide experimental results partitioning algorithm 2 efficient algorithm aggregate underutilized logical gridbuckets achieve better disk uti lization provide expermental results demonstrate utility aggregation phase 3 complete algorithm bulkloading large data sets significantly larger main memory guarantees bucket overflows rest paper organized follows next section relate work prior efforts section 3 present general problem detail provide example section 4 present existing partitioning algorithm new algorithm aggregation algorithm section 5 experimentally compare execution times two algorithms variety data sets including highly skewed cfd data sets also demonstrate effectiveness aggregation technique section 6 present two phase bulkloading algorithm end conclusions plans future work previous work bulkloading b trees 6 investigated recently bulkloaded grid files considered single paper aware li rotem srivastava 2 main emphasis bulkloading parallel grid files ie grid files distributed across multiple sites shared nothing environment define logical partitioning gridfile among sites database system physical partitioning portion gridfile located one site buckets compose portion gridfile solution based dynamic programming logical partitioning physical partitioning parallel gridfiles physical partitioning objective function minimize bucket overflow concerned physical partitioning single site although modified version algorithm could used logical partitioning li et al algorithm optimally partitions one dimension given specific number partitions fixed partitioning dimension likely equally spaced details fixed partition lacking li et al paper algorithm dynamically finds number partitions finds partitioning much quickly directly addresses issue selecting fixed partition uniformly distributed data may sufficient assume equally spaced partitioning case data skewed show dynamic programming approach inefficient considered large grid files li et al recognize problem suggest sampling 7 8 accelerate algorithm however sampling may introduce overflows handling may significant bucket overflows additional bucket must created grid directory split number overflows within bucket larger bucket capacity multiple new buckets need created grid directory split multiple times earlier work inadequately assesses risks sampling focusing probability block overflows rather say average number blocks overflow average total number overflow tuples problem specification given li et al ie given fixed partitioning fixed number partitions dynamic programming formulation excellent approach propose better reformulate problem find smallest number partitions total overflow zero freedom introduced allowing arbitrary number partitions enables us use fast heuristic algorithm instead expensive dynamic programming algorithm possibly larger number buckets resulting increased number partitions reduced via low cost aggregation algorithm thus partitioning algorithm capable handling much larger grid files still guarantee overflows achieving good bucket utilization although data set large fit main memory data must first sorted furthermore consider extensive data sets earlier work better understand effects positionally skewed clustered data typical cfd data sets partitioning algorithm modification rectilinear partitioning algorithm developed nicol4 purposes loadbalancing irregular dataparallel computations two principle differences algorithm earlier one number subranges dimension considered fixed present context upper limit number tuples bucket 3 general problem description considering algorithmic issues let us first examine general problem exposition twodimensional case algorithms generalize immediately higher dimensions also assume attributed range partitioned number subranges rigorously necessary addressed one would choose desired relationship number subranges dimension let set tuples 1 2 q attributes 1 2 indexed attributes q rest tuple specific data sets 1 2 x coordinates q array 35 floating point values representing physical quantities pressure density directional derivative information chemical composition ease exposition assume domain 1 2 integers 2 algorithms extend straightforward fashion realvalued attributes generalized ranges empirical results report based extensions let f n theta n frequency matrix entry contains number tuples coordinate e use following notation number tuples data set number partitions dimension maximum number tuples bucket hold number unique coordinate values dimension vector cuts dimension specifically c 1 vector horizontal cuts c 2 vector vertical cuts p theta p occupancy matrix resulting applying cut vectors c 1 c 2 total seek pair c overflow equals zero whose number cuts minimized make concepts intuitive left hand side figure 1 partitioned data set horizontal 26 partitioning c divides domain 9 bins note dashed lines c slightly offset clearly show occupancy bins case bin 1 contains points 11 22 bin 2 contains 13 14 bin 3 contains 28 bin 4 contains 42 51 72 bin 5 contains 43 53 74 bin 6 contains 39 bin 7 contains 93 bin 9 contains 88 thus occupancy matrix ij figure 1 partitioning example left total overflow equals 1 right total overflow equals 0 assume 2 total overflow partitioning 2 bins 4 5 contain 3 points move position second cut c 1 position 6 e let c shown right hand side figure 1 total overflow would zero 4 algorithm descriptions describe algorithm li et al implementation earlier algorithm presented 41 detail provide detail lacking li et al paper wish show weve made every effort optimize performance dynamic programming solution section 42 gives partitioning algorithm 43 describes method aggregating underutilized buckets 41 dynamic programming solution dynamic programming equation described precisely one given li et al 2 reword formulation describe specifics optimized algorithm solving equation assumed already partitioned horizontal dimension ie c 1 fixed task find vector c 2 minimizes total overflow let ri j n theta j f obtained restricting 2 2 j consider column bins resulting partitioning horizontally c 1 let ov 1 j sum member column bin overflow example matrix left figure 1 ov 1 2 since middle bin 4 tuples overflow observed two bins reduce overflows might consider partitioning ri vertically l gamma 1 cuts thereby creating p theta l submatrix bins attendant total overflow value may many ways partitioning columns j ri l minimum possible total overflow cost among possibilities principle optimality 1 asserts 1 particular interest value tov partition achieves cost solution equation aided precomputing values ov 1 j derived op time follows c 1 partitions f p submatrices k column sum entries column indices 1 j inclusive pair column indices j r k computed single subtraction ov 1 j computed op time set values computed time proportional n logp slightly computation sort dimension accommodate tuple sets sparse relative n theta n project data set onto coordinate axis sort essentially working theta array containing nonzeros indices describe paper may thought ordinal positions data projections axis take advantage sparse structure still compute proportional logp dynamic programming equation expresses recursion column index j number cuts l approach unravel recursion j inner index l outer one specifically start solving tov 1 1 j 1 j given solve tov 1 1 j 2 j l 1 solving tov 1 1 j l must make comparisons actually must make one comparison every nonzero column f columns l gamma 1 1 tuple sets sparse relative n theta n complexity inner loop recursion op n 2 outer loop executed giving complexity op 2 n 2 addition complexity initial precalculation thus total complexity op 2 data sets sparse relative n theta n complexity reduced op 2 u 2 number unique attribute values dimension 2 additional logt sorting tuples needed maintain sparse representation rest paper assume data sets sparse relative n theta n sparse data sets especially relevant since coordinates unstructured cfd data sets reals asymptotic complexity omaxfp 2 u 2 henceforth call algorithm dp algorithm speed algorithm increased precalculating storing values 8j complexity op u 2 precalculation ov 1 proportional op u 2 2 thus included term storage cost significant hence limits applicability optimization example u 2 5000 space required storing ov 1 j 95 megabytes henceforth call algorithm dp2 algorithm described calculate optimal overflow cost partitioning given fixed partitioning c 1 far difference work li et al provided details implementation dynamic programming problem come first contribution paper determine fixed partitionings determine number partitions assume number partitions dimension thus resulting square gridfile directories presume existence algorithm given fixed set cuts one dimension finds good set cuts dimension paper li et al provides one neglects specify origin fixed cut set follow nicol 4 using algorithm basis iterative method given fixed cuts one dimension find good cuts treat new cuts fixed find better ones previously fixed dimension iterations maintained termination mechanism triggers initial fixed cut uniformly spaced gridfile application idea application cutfinding algorithm attempts find cuts yield zero overflow buckets termination partitioning session defined either overflowfree cutset discovered specified number iterations use 20 cutset discovered sole parameter partitioning session number partitions p dimension partitioning session may viewed probe determines whether quickly discovered overflowfree partitioning using cuts dimension overall strategy intelligent search p find smallest value quickly determine desirable partitioning cut assignment might used approach results later report use dynamic programming solution li et al algorithm reported within framework skewed data sets may advantageous number partitions dimension differ aggregation phase described later minimizes poor efficiency using square regions future intend investigate nonsquare regions given square region strict lower upper bounds number partitions needed dimension thus binary search find minimal number partitions p lowerbound p upperbound total overflow equal zero practice found faster start number partitions equal 2 theta lowerbound total overflow greater zero keep doubling number partitions partition value found total overflow zero conduct binary search value upper bound previous value lower bound 42 rectilinear partitioning come second contribution work alternative rectilinear partitioning algorithm like li et al optimizes cuts one dimension given fixed set cuts discussion follow take c 1 fixed step algorithm seek define column buckets whose width wide possible without bucket column assigned b tuples define first column seek largest index j ov 1 1 nondecreasing j may identify binary search using precalculated r k j candidate j requires op time compute ov 1 1 j hence op log u 2 time required define first column second column computed exactly first taking index starting point ie identify largest j 2 ov 1 j 1 process continues either p fewer adjacent overflowfree columns discovered placed last column suffers overflow former case partitioning session terminates latter case may freeze newly discovered cuts choose new cuts dimension complexity one partitioning session several components first ot log cost sorting tuples dimension time optimize one dimension first compute new r k 1 j values takes ot logp time followed op 2 log u 2 cost allocating cuts since partitioning session iterates bounded number times asymptotic complexity original rectilinear application 4 shown converge unchanging cut sets given sufficiently many iterations algorithm would converge found prudent back away larger number partitions small number iterations fails find suitable partition original rectilinear partitioning problem shown nphard three dimensions proof suffices show intractability finding minimal p square overflowfree partition exists tractability rectilinear partitioning problem two dimensions still unknown informative consider essential difference partitioning algorithm li et al uninterested partition overflow expend computational energy minimizing nonzero overflows given c 1 possible find c 2 yielding overflowfree partition algorithm find none exists algorithm determines quickly contrast previous algorithm seeks find c 2 minimizes overflow uninterested whether minimal overflow two three whether zero nonzero distinction permits us find overflowfree partitions substantially less work previous algorithm seen empirical results 43 aggregation third contribution algorithm aggregating adjacent buckets low utilization partitioning phase buckets may low utilization two adjacent buckets 50 utilization smaller may combine single bucket even though gridfile directory contain two pointersthey identical following partitioning apply aggregation scheme based observation let b equal bucket capacity first assume grid directory size 2 theta 2 view four equal quadrants labeled nwnesesw define procedure canmergeab returns logical true neither b already merged group level j sum utilization less 100 define procedure mergeab j merge b one bucket level j using canmerge merge define recursive function function aggregatea j follows g1a g1c g1b figure 2 aggregation examples 1 consists 1 theta 1 gridfile already merged group level return 2 partition four quadrants nwnesesw 3 sum utilizations four quadrants less 100 aggregate one bucket return 4 canmergenwnej canmergeswsej call mergenwnej mergeswsej 5 canmergenwswj canmergenesej call mergenwswj mergenesej 6 canmergenwnej call mergenwnej 7 canmergeswsej call mergeswsej 8 canmergenwswj call mergenwswj 9 canmergenesej call mergenesej 10 call aggregatenwj1 aggregatenej1 aggregateswj1 aggregatesej1 assuming grid file directory initially 2 theta 2 aggregation accomplished call aggregated example consider grid directory left hand side figure 2 bucket capacity 10 entries directory number tuples bucket merge whole one bucket merge two halves merge nw sw quadrants call aggregation strategy two remaining quadrants practice restriction powers two although current partitioning algorithm assumes grid equal number partitions dimension present aggregation algorithm general case without loss generality assume shape grid directory n rows columns find largest 2 n let g1 subdirectory grid directory composed first 2 rows let g2 subdirectory composed complement original directory first aggregate g1 let div n number square 2 theta 2 subdirectories fit g1 one square subdirectories apply square region aggregation algorithm left apply algorithm recursively two regions right hand side figure 2 show example 13 theta 20 grid directory subdirectory g1 composed g1a g1b g1c square power two region aggregation policy applied g1a g1b entire aggregation policy called recursively g1c g2 algorithm could improved yield slightly better bucket utilizations fast proved sufficient needs far depending use gridfile different aggregation strategies used gridfile read cfd database buddysystem pairing approach needed facilitate splits future insertion tuples necessary case regions aggregated buckets need rectangular hence could allow aggregation resulting improved bucket utilization yet developed algorithms calculate aggregation since algorithm sufficient needs date hand gridfile used transaction processing environment tuples might later inserted buddy pairing must preserved 5 experimental comparison section present experimental results two partitioning algorithms present run times bucket utilization results experiments make attempt get smooth curves collect confidence intervals figures result one experimental run thus often noise presumably use workstation jobs experiments run sparc 10 workstation sanity checks code made running algorithms profiler make sure time spent sections code expected run time rp algorithm dominated startup costs creating precalculated r k 1 j sorting records data sets paper 40 run time spent creating r k 1 j 20 time sorting data points note even high cost creating r k 1 j overall algorithm significantly faster r k 1 j precalculated contrast run time dp algorithm dominated actually partitioning since op 2 u 2 section 51 present results single partitioning given fixed partitioning dimension following sections present results assuming number partions initial partitioning known section 52 present results uniformly distributed synthetic data sets section 53 present results highly skewed cfd data sets section 54 present bucket utilization results experiments demonstrate utility aggregation phase 51 fixed partitioning given first compare dp dp2 rp algorithms assuming fixed partitioning exists one dimension conduct experiments since exact scenario li et al proposed algorithm note fixed partitioning obtained specified li et al 2 consider data set 5000 tuples x coordinates tuple chosen uniform distribution 1 2000 obtain initial horizontal partitioning equally spacing cuts within domain table 1 present results number partitions dimension varied 12 5 assuming bucket capacity 50 tuples columns headed seconds record amount cpu time used partitioning columns headed overflow total number tuples fit within bucket capacity columns headed blocksover number blocks overflowed overflow blocksover numbers identical dp dp2 algorithms since algorithms find exact partitioning differ run time first note rp algorithm one two orders magnitude faster dp dp2 algorithms values p conversely dynamic programming algorithms minimize total overflow better large number partitions thus specific problem objective function formulated li et al dynamic programming algorithm proposed satisfies objective function better rectilinear partitioning algorithm expense significantly computation premise work better partition sufficiently large number partitions ensure overflows note although dp algorithm smaller number tuples overflowed results larger number buckets overflow number partitions less 11 blocks overflow rp algorithm used last column partitioning whereas dp algorithm used overflow blocks spread partitioning space consider case number partitions 10 rp algorithm used 10 overflow blocks 10 blocks 106 106 101 111 94 94 108 112 113 106 tuples allocated since 50 tuples fit per block new blocks need created one hand dp algorithm used 40 overflow blocks 68 tuples requiring 40 new blocks created hence total overflow good indicator optimality partitioning propose better metric would number new blocks needed hold overflows continue use total tuple overflow paper since algorithms dynamically find number partitions needed make overflow zero 52 number partitions given uniformly distributed data assume number partitions known initial fixed partitioning given first consider run time algorithm uniformly distributed data x coordinates tuple chosen uniform distribution 1 n n depends experiment reported experiments allow duplicate data set points since cfd data duplicate points verified inclusion duplicates results similar relative performance first consider relative performance algorithms number tuples varied rp algorithm dp dp2 seconds overflow blocksover seconds seconds overflow blocksover 9 620e01 1672 9 159e02 113e02 950 76 7 630e01 2958 7 122e02 894e01 2550 43 table 1 cpu times overflow fixed partitioning given figures 3 4 plot computation time seconds versus number tuples relation assuming coordinate values uniformly distributed 1 2000 note yaxis logarithmic top bottom plot computation time dp dp2 rp algorithms remember dp2 algorithm dp algorithm except precomputes stores ov 1 j8i 8j plot figure 3 assumes 50 tuples fit per page plot figure 4 assumes 300 tuples per page page size 8192 bytes tuples size would 164 27 bytes respectively tuple size 164 bytes may typical size transaction processing systems tuples data sets usually around 2432 bytes number tuples increases run time dp algorithm becomes long practical use relation 40000 164 byte tuples 64 megabytes byte tuples 12 megabytes hence reasonable expect sufficient memory partition data sets least 40000 tuples 40000 164 byte tuples figure 3 dp algorithm requires 26600 seconds 74 hours 100000 tuples require 77200 seconds 214 hours times clearly prohibitive dp2 algorithm requires 3000 seconds 50 minutes 6070 seconds 101 minutes 40000 100000 tuples respectively requires 15 megabytes space hold precomputed ov 1 j rp algorithm requires 12 40 seconds 40000 100000 tuples respectively thus rp algorithm practical algorithm rp algorithm 2000 250 times faster dp dp2 algorithm 40000 tuples difference solution times unexpected given complexities dp dp2 rp algorithms omaxfp 2 u 2 log tg log tg respectively consider number unique attribute values data set impacts relative performance policies figure 5 plot computation time seconds versus maximum attribute domain data set 40000 tuples assuming 300 tuples fit per page note yaxis logarithmic curves top bottom dp dp2 rp algorithms run dp2 algorithm storage space precalculated ov megabytes thus points plotted maximum domain values 5000 higher increasing maximum domain value increases number unique attribute values data set dp dp2 algorithms highly sensitive number unique values data set conversely rp algorithm relatively insensitive number unique values maximum domain value 2000 rp algorithm 450 110 times faster dp dp2 algorithm maximum domain value 10000 rp algorithm 17000 times faster dp algorithm experiments section assume maximum domain value 2000 many cfd data sets number unique values almost equal number tuples thus even 10000 small value consider tuple size effects relative performance two algorithms figure 6 plot computation time seconds versus number tuples per page assuming 40000 tuples attribute domain maximum 2000 yaxis logarithmic number tuples per page decreases hence tuple size increases dp algorithms requires significantly computation conversely rp algorithm relatively insensitive size tuples thus rp algorithm remains viable algorithm wide range tuple sizes degradation dp algorithm tuple size increases easy predict complexity algorithm tuple size increases number tuples per bucket decreases hence number partitions p increases would expect runtime rp algorithm increase also since complexity rp algorithm op 2 logu max majority run time rp algorithm spent sorting tuples creating r k 1 j thus obscuring sensitivity tuple size figure 7 plot ratios computation time dp dp2 algorithms relative rp algorithm tuple size increases ratio increases 53 number partitions given unstructured cfd data consider run time algorithm highly skewed data use actual data sets unstructured grid cfd simulations term grid used describe way coordinates data set connected data set composed xy realvalued coordinates data sets computational models cross sections airflows around aircraft wings 3 figure 8 plot data set set 1034 points x restrict range plotted since majority data central region plotting whole range would make difficult distinguish points areas high concentration 94 1034 points plotted vertical horizontal lines partitioning lines resulting running rp algorithm data set note one vertical line included plot seen partitioning fixed equal space partitioning would bad choice figure 9 plot partitioning computation time versus number tuples three different data sets smallest data set 1034 tuples dp dp2 algorithm required 2370 650 times computation rp algorithm partitioning data set 3959 tuples dp dp2 algorithm required 38817 5629 times computation rp algorithm thus dp algorithm especially impractical highly skewed data since dp algorithm required 42 hours 3959 tuples data set run 15895 tuple data set rp algorithm required 66 seconds partition 15895 tuple data set four orders magnitude difference computation time surprising light results experiment plotted figure 5 unstructure grid data sets number unique attribute values almost equal number tuples hence number tuples set increases rp algorithm dp algorithm bucket utilization bucket utilization partitions preaggregation postaggregation partitions preaggregation postaggregation 1000 5 800e01 870e01 5 800e01 800e01 5000 12 694e01 794e01 12 694e01 781e01 10000 20000 80000 48 694e01 731e01 47 724e01 737e01 100000 53 712e01 727e01 52 740e01 743e01 table 2 average bucket utilizations number tuples varied number partitions needed increase number unique attribute values rp algorithm experience much increase computation time data sets get larger since majority time spent precalculation r k 1 j initial sort data 54 bucket utilizations aggregation effectiveness present average bucket utilizations previous experiments aggregation phase completed table 2 present utilizations uniformly distributed data experiment figure 3 column label partitions number partitions direction smallest number algorithm returned total overflow zero overall average bucket utilization quite good would result inserting tuples one time little difference utilization dp rp algorithms addition aggregation phase significantly improve bucket utilization bucket utilization already good experiments run time aggregation phase minimal less 2 rp runtime hence worth aggregating even modest improvement table 3 present utilizations uniformly distributed data experiment figure 6 little difference bucket utilization two algorithms average bucket utilization tends decrease number tuples per page decreases 5 tuples fit per page bucket utilization 28 aggregation better 70 thus aggregation phase considerably improve utilization cases utilization poor runtime dp algorithm 5 10 tuples per page excessive hence present aggregation results parameters skewed data aggregation phase results substantial savings disk space table 4 present utilizations unstructured grid cfd data set three different grids average bucket utilization without aggregation poor improves significantly aggregation thus highly skewed data aggregation essential achieving good bucket utilizations note tuple data dp algorithm since computation time 3959 tuple data set required hours rp algorithm dp algorithm tuples bucket utilization bucket utilization perpage partitions preaggregation postaggregation partitions preaggregation postaggregation 200 15 889e01 889e01 15 889e01 889e01 100 22 826e01 826e01 22 826e01 826e01 table 3 average bucket utilizations tuples per page varied rp algorithm dp algorithm bucket utilization bucket utilization partitions preaggregation postaggregation partitions preaggregation postaggregation table 4 average bucket utilizations unstructured grid cfd data 6 twophase bulk loading algorithm description section describe two phase algorithm bulk loading data sets significantly larger available buffer space suppose data set contains tuples suppose maximum tuples contained memory time applying rp algorithm approach two steps first partition set groups size fewer set contain points within rectangle xy plane however collection sets need rectilinear second step apply rp individual set merge individual grid files created steps elaborated upon given find smallest perfect square integer r r partition data set r groups follows sorting data set xcoordinate value may easily divide set r groups r successive elements sorted order serves partition data set along xaxis strips tuples strip may sorted along yaxis points may separated groups successive points effectual divides strip rectangles rectangle containing permitted number points remains apply rp group write buckets data disk one possibility partition group separately define final grid file union separately defined gridfiles recognizing cut defined group one side data domain must propagate r1 groups cause splitting grid directories consider different approach groups partitioned build global grid file initially empty upon reading group identify set cuts global grid file affect group treat immutable seek find minimum number additional cuts needed avoid overflow requires simple modification rp algorithm another optimization first strip attributes indexed data set two phase algorithm applied coordinates without requiring io whole tuple partitioning set coordinates creating overall grid directory buckets could filled making second pass data set may result faster load time tuple size large data set hence grid directory extremely large another optimization uses two level directory scheme suggested 5 top level directory one entry r subdirectories note would mean point access could require three disk accesses instead two 7 conclusions future work proposed implemented new rectilinear partitioning rp algorithm physical partitioning gridfiles proposed rp algorithm significantly faster recently proposed dynamic partitioning dp algorithm li et al 2 number overflows rp permits necessarily larger dp algorithm minimizes however argue minimizing number additional blocks created due overflow actually better measure one rp algorithm finds better solutions dp algorithm considered use greedy algorithm dp algorithm kernels loop seeks minimize size grid file needed achieve overflows synthetic data sets uniformly distributed integers rp algorithm two three orders magnitude faster dp algorithm actual cfd data sets whose indexed attributes highly skewed reals rpbased algorithm three four orders magnitude faster dpbased algorithm also developed efficient aggregation algorithm improving bucket utilizations grid files resulting bulk loading using rp dp partitioning algorithms algorithm minimal overhead yield substantial improvements bucket utilization bucket utilization partitioning poor aggregation phase necessary achieve reasonable bucket utilizations indexed data highly skewed also proposed two phase bulk load algorithm several optimizations loading data sets significantly larger available buffer space algorithm guarantees bucket overflows proposed possible alternative sampling based methods yet investigated performance algorithm future plan experimentally compare two phase algorithm inserting one tuple time sampling based methods also intend consider sophisticated aggregation techniques partitioning differing numbers partitions attribute r fundamentals computer algorithms algorithms loading parallel grid files algebraic turbulence modeling unstructured adaptive meshes rectilinear partitioning irregular data parallel computations grid file adaptable symetric multikey file structure time space optimality btrees probalistic method query processing sampling issues parallel database systems tr ctr dora cai ruth aydt robert j brunner optimized data loading multiterabyte sky survey repository proceedings 2005 acmieee conference supercomputing p42 november 1218 2005 apostolos papadopoulos yannis manolopoulos parallel bulkloading spatial data parallel computing v29 n10 p14191444 october rundensteiner merging rtrees efficient strategies local bulk insertion geoinformatica v6 n1 p734 march 2002 gisli r hjaltason hanan samet speeding construction pmr quadtreebased spatial indexes vldb journal international journal large data bases v11 n2 p109137 october 2002