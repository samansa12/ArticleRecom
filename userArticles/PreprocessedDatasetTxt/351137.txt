performance evaluation conservative algorithms parallel simulation languages abstractparallel discrete event simulation conservative synchronization algorithms used high performance alternative sequential simulation paper examine performance set parallel conservative algorithms implemented maisie parallel simulation language algorithms include asynchronous null message algorithm synchronous conditional event algorithm new hybrid algorithm called accelerated null message combines features preceding algorithms performance algorithms compared using ideal simulation protocol protocol provides tight lower bound execution time simulation model given architecture serves useful base compare synchronization overheads different algorithms performance algorithms compared function various model characteristics include model connectivity computation granularity load balance lookahead b introduction parallel discrete event simulation pdes refers execution discrete event simulation program parallel distributed computers several algorithms developed synchronize execution pdes models number studies attempted evaluate performance algorithms variety benchmarks survey many existing simulation protocols performance studies various benchmarks appears 9 11 number parallel simulation environments also developed provide modeler set constructs facilitate design pdes models4 one maisie3 parallel simulation language implemented shared distributed memory parallel computers maisie designed separate model underlying synchronization protocol sequential parallel used execution efficient sequential parallel optimistic execution maisie models described previously2 paper evaluate performance set conservative algorithms implemented maisie set algorithms include null message algorithm6 conditional event7 algorithm new conservative algorithm called accelerated null message anm algorithm combines preceding two approaches unlike previous performance studies use speedup throughput metric comparison use efficiency primary metric define efficiency protocol using notion ideal simulation protocol isp introduced paper performance parallel simulation model depends variety factors include partitioning model among processors communication overheads parallel platform including hardware software overheads overheads parallel synchronization algorithm parallel model fails yield expected performance benefits analyst tools ascertain underlying cause instance difficult determine whether problem due inherent lack parallelism model due large overheads implementation synchronization protocol ideal simulation protocol offers partial solution problem isp allows analyst experimentally identify maximum parallelism exists parallel implementation simulation model assuming synchronization overhead zero words specific decomposition model given parallel ar chitecture possible compute percentage degradation performance due simulation algorithm directly translates measure relative efficiency synchronization scheme thus isp may used compute efficiency given synchronization algorithm provide suitable reference point compare performance different algorithms including conservative optimistic adaptive techniques previous work relied theoretical critical path analyses compute lower bounds model execution times bounds approximate ignore overheads including architectural system overheads parallel simulation algorithm control remainder paper organized follows next section describes conservative algorithms used performance study reported paper section 3 describes ideal simulation protocol use separating protocoldependent independent heads section 4 describes implementation issues synchronization algorithms including language level constructs support conservative algorithms section 5 presents performance comparisons three conservative algorithms lower bound prediction isp related work area described section 6 section 7 conclusion conservative algorithms parallel discrete event simulation physical system typically viewed collection physical processes pps simulation model consists collection logical processes lps simulates one pps lps share state variables state lp changed via messages correspond events physical system section assume lp knows identity lps communicate lp p use terms destset p sourceset p respectively refer set lps lp p sends messages receives messages causality constraint simulation model normally enforced teh simulation algorithm ensuring messages logical process lp processed increasing timestamp order distributed simulation algorithms broadly classified conservative optimistic based enforce conservative algorithms achieve allowing lp process message timestamp ensure lp receive message timestamp lower optimistic algorithms hand allow events potentially processed timestamp order causality errors corrected rollbacks recomputations paper focus conservative algorithms order simplify description algorithms define following terms term defined lp p physical time r assume communication channels fifo earliest input time eit p r lower bound logical timestamp message lp p may receive interval r 1 earliest output time eot p r lower bound timestamp message lp p may send interval r 1 earliest conditional output time ecot p r lower bound timestamp message lp p may send interval r 1 assuming lp p receive messages interval ffl lookahead la p r lower bound duration lp send message another lp value eot ecot given lp depends eit unprocessed messages input queue lookahead figure 1 illustrates computation eot ecot lp models fifo server server assumed minimum service time one time unit also lookahead three scenarios figure respectively represent contents input message queue lp three different points execution messages simulation time simulation time b simulation time c figure 1 computation eot ecot lp modeling server minimum service time one time unit shaded messages processed lp already processed lp shown shaded boxes let next refer earliest timestamp message input queue since next eit ecot equal next plus minimum service time b eot equal plus minimum service time lp may still receive messages timestamp less next 40 smaller eit however ecot equal next plus minimum service time lp receive messages earliest next output response processing message timestamp next c next 1 unprocessed messages therefore ecot equal 1 various conservative algorithms differ compute value eit lp system definition conservative algorithm physical time r lp p process messages timestamp eit p r therefore performance conservative algorithm depends efficiently accurately lp compute value eit following sections discuss three different algorithms compute eit 21 null message algorithm common method used advance eit via use null messages sufficient condition lp send null message every lp dest set whenever change eot lp computes eit minimum recent eot received every lp sourceset note change eit lp typically implies eot also advance number techniques proposed reduce frequency null messages transmitted instance null messages may piggybacked regular messages may sent lp blocked rather whenever change eot null message algorithm requires simulation model contain zerodelay cycles model contains cycle cycle must include least one lp positive lookahead ie lp accepts message timestamp message generated lp must timestamp strictly greater t13 22 conditional event algorithm conditional event algorithm 7 lps alternate eit computation phase event processing phase sake simplicity first consider synchronous version ensures messages transit lps reach eit computation phase state value eit lp p equal minimum ecot lps transitive closure 1 sourceset p algorithm made asynchronous defining eit minimum ecot values lps transitive closure sourceset timestamps messages transit lps note definition eit definition global virtual time gvt optimistic algorithms hence gvt computation algorithms 5 used details one algorithm described section 44 23 accelerated null message algorithm superimpose null message protocol asynchronous conditional event protocol allows null message protocol perform unhindered eit lp computed maximum values computed two algorithms method potential combining efficiency null message algorithm presence good lookahead ability conditional event algorithm execute even without lookahead scenario null message algorithm alone deadlock models poor lookahead may take many transitive closure sourceset many applications almost set lps system rounds null messages sufficiently advance eit lp anm could directly compute earliest global event considerably faster message piggybacking used extensively reduce number synchronization messages global ecot computation node initiated node otherwise blocked experimental performance studies parallel simulations used speedup throughput ie number events executed per unit time performance metric metrics appropriate evaluating benefits parallel simulation shed light efficiency simulation protocol number factors affect execution time parallel simulation model classify factors two categories protocolindependent factors protocolspecific factors former refer hardware software characteristics simulation engine like computation speed processor communication latency cost context switch together model characteristics like partitioning lp processor mapping determine inherent parallelism model specific simulation protocol used execute model relatively little control teh overhead contributed factors contrast overhead due protocolspecific factors depend specific simulation protocol used execution model conservative protocols may include overhead processing propagating null messages6 conditional event messages7 idle time lp blocked eit yet advanced sufficiently allow process message available input queue case optimistic protocols protocolspecific overheads may include state saving rollback global virtual time gvt computation costs separation cost protocolspecific factors total execution time parallel simulation model lend considerable insight performance instance allow analyst isolate model performance may poor due lack inherent parallelism model something control protocol one performance may poor due plethora null messages may addressed using appropriate optimizations reduce count past critical path analyses used prove theoretical lower bounds related properties12 1 parallel simulation model however analyses include cost many protocolindependent factors computation critical path time excluding overheads contributed simulation protocol means computed bound typically loose lower bound execution time model relatively little practical utility simulationist either improving performance given model measuringthe efficiency given protocol introduce notion ideal simulation protocol isp used experimentally compute tight lower bound execution time simulation model given architecture although isp based notion critical path computes parallel execution time actually executing model parallel architecture resulting lower bound predicted isp realistic includes overheads due protocolindependent factors must incurred simulation protocol used execution assumes synchronization overheads zero primary idea behind isp simple model executed trace messages accepted lp collected locally lp subsequent execution lp may simply use trace locally deduce safe process incoming message synchronization protocol necessary synchronization protocol used execute model using isp measured execution time include protocolspecific overheads however unlike critical path analyses isppredicted bound include cost protocolindependent factors required parallel execution model given lower bound easy measure efficiency protocol described next section besides serving reference point computing efficiency given protocol representative presimulation isp yield realistic prediction available parallelism simulation model speedup potential found low user modify model may include changing partitioning system changing assignment lps processors even moving different parallel platform order improve parallelism model implementation issues performance experiments executed using maisie simulation language algorithm including isp implemented maisie runtime system programmer develops maisie model selects among available simulation algorithms command line option separation algorithm simulation model permits consistent comparison protocols one algorithms implemented directly applictaion section briefly describe maisie language specific constructs provided support design parallel conservative simulations section also describes primary implementation issues algorithm 41 maisie simulation environment maisie 3 cbased parallel simulation language program collection entity definitions c functions entity definition entity type describes class objects instance henceforth referred simply entity represents specific lp model entities may created dynamically recursively events physical system modeled message communications among corresponding entities entities communicate using buffered message passing every entity unique message buffer asynchronous send receive primitives provided deposit remove messages buffer respectively message carries timestamp corresponds simulation time corresponding event specific simulation constructs provided maisie similar provided processoriented simulation languages addition maisie provides constructs specify dynamic communication topology model lookahead properties entity constructs used investigate impact different communictaion topologies lookahead patterns performance conservative algorithms described earlier figure 2 maisie model fcfs server piece code constructs tandem queue system described section 5 used minor changes experiments described entity server defines message type job used simulate requests service server body entity consists unbounded number executions wait statement line 12 execution statement causes entity block receives message specified type case job receiving message type entity suspends jobservicetime simulation time units simulate servicing job executing hold statement line 13 subsequently forwards job adjacent server identified variable nextserver using invoke statement line 14 performance many conservative algorithms depends connectivity model absence information algorithm must assume every entity belongs source set destset every entity however maisie provides set constructs may used entity dynamically add remove elements sets add source del source add dest del dest figure 2 server entity specifies connectivity entities using add source add dest functions line 89 lookahead another important determinant performance conservative algorithms maisie provides predefined function setlookahead allows user specify current lookahead runtime system runtime system uses information compute better estimate eot ecot may feasible otherwise instance server idle possible clocktype meantime 4 ename nextserver 6 message jobfg 8 add sourceprevserver 9 add destnextserver 14 invoke nextserver jobfg figure 2 maisie entity code first come first served fcfs server user defined lookahead server precompute service time next job line 15 becomes lookahead transmitted runtime system using function setlookahead line 11 suspends 42 entity scheduling multiple entities mapped single processor scheduling strategy must implemented choose one among number entities may eligible execution given time entity eligible executed input queue contains message timestamp lower current eit entity maisie runtime entity scheduled allowed execute long remains eligible helps reduce overall context switching overhead since messages executed time entity scheduled may result starvation entities mapped processor turn may cause blocking processors might waiting messages entities resulting suboptimal performance note however without prior knowledge exact event dependencies scheduling scheme optimal alternative scheduling strategy used global event list algorithm schedule events across entities mapped processor order timestamps examine discuss overheads caused two scheduling strategies section 5 43 null message algorithm one tunable parameters null message scheme frequency null messages transmitted different alternatives include eager null messages lp sends null messages successors soon eot changes lazy null messages lp sends null messages successors idle demand driven lp sends null message destination destination demands know value eot performance different null message transmission schemes including eager lazy demand driven schemes discussed 17 experiments found demand driven schemes performed poorly whereas lazy null message scheme combined eager event send ing ie regular messages sent soon generated case runtime found marginally outperform schemes use lazy null message scheme experi ments advantage reducing overall number null messages several null messages may replaced latest message however delay sending null messages may delay processing real messages receiver 44 conditional event computation conditional event anm protocol necessary periodically compute earliest conditional event model discussed section 23 asynchronous algorithm allows earliest event time computed without need freeze computation node runtime system computation takes place phases start new phase jth processor computes ecot value phase ij smallest timestamp sent processor phase accounts messages transit worst case none messages sent processor phase may received accounted e processors thus global ecot phase calculated following min n number processors messages sent phases need considered new phase starts messages previous phase received along fifo communication assumption implies e ij takes account messages sent processor processor phase 2 phase every processor sends ecot message contains minimum compute global ecot minimum ecot messages processors note ecot message needs carry phase identifier since new phase start previous one finished boolean flag sufficient store phase identifier 45 isp ideal simulation protocol isp implemented one available simulation protocols maisie environment implementation uses data structures entity scheduling strategy message sending receiving schemes conservative algorithms discussed earlier primary overhead execution model isp time reading matching event trace implementation minimizes overhead follows entire trace read array beginning simulation order exclude time reading trace file execution reduce matching time trace stored simply sequence unique numeric identifiers assigned message runtime system ensure fifo operation input queue thus synchronization overhead executing simulation model isp time required execute bounded number numeric comparison operations incoming message cost clearly negligible compared overheads parallel simulation resulting time excellent lower bound exection time parallel simulation 5 experiments results programs used experiments written maisie contain additional directives parallel simulation ie explicit assignment maisie entities processors b code create source destination sets entity c specification lookaheads experimental measurements taken sparcserver 1000 8 supersparc processors 512m shared main memory selected closed queuing networks cqn widely used benchmark evaluate parallel simulation algorithms benchmark used easily reproducible allows communication topology lookahead two primary determinants performance conservative protocols modified controlled manner cqn model characterized following parameters ffl type servers classes jobs two separate versions model used cqnf server fifo cqnp server results cqnp experiments switch server queue figure 3 closed queuing networkn ffl number switches tandem queues n number servers tandem queue q ffl number jobs initially assigned switch jn ffl service time service time job sampled shiftedexponential distribution mean value unit time indicating mean value ffl topology job arrives switch switch routes job one n tandem queues equal probability 1 time unit servicing job server forwards job next server queue last server queue must send job back unique associated switch ffl total simulation time h switch server programmed separate entity thus cqn model total entities entities corresponding switch associated tandem queue servers always mapped processor shiftedexponential distribution chosen service time experiments minimum lookahead every entity nonzero thus preventing potential deadlock situation null message algorithm topology network 4 shown figure 3 performance parallel algorithms typically presented computing speedup parallel execution time pprocessors however describe next section sequential execution time model using standard global event list gel algorithm13 provide lower bound single processor execution fact slower parallel conservative algorithm reason speedup metric defined might show superlinear behavior models become saturated model enough parallelism paper suggest computing efficiency using isp provide tight lower bound compare conservative protocols respect efficiency relative execution time isp efficiency protocol architecture defined follows using isp execution time using protocol efficiency protocol identifies fraction execution time devoted synchronizationrelated factors protocolspecific operations execution model begin experiments section 51 comparing execution time five protocols gelglobal event list nullnull message condconditional event anm isp single processor configuration instructive identifies unique set sequen tial overheads incurred protocol one processor subsequent sections investigate impact modifications various model characteristics like model connectivity section 52 lookahead properties section 53 computation granularity section 54 51 simulation cqnf model one processor figure 4 shows execution times cqnf model 100 000 one processor sparcserver 1000 seen figure execution times protocols differ significantly even one processor computation granularity associated event model small makes protocolspecific overheads associated event relatively large allowing us clearly compare overheads various protocols primary purpose study figure 4 isp best execution time regarded close approximation pure computation cost model first compare isp gel protocols major difference two protocols entity scheduling strategy described section 45 isp employs entity scheduling scheme conservative protocols entity removes processes many safe messages input queue possible swapped isp means entity scheduled execution swapped next message local trace available input queue entity contrast gel algorithm schedules entities strict order message timestamps cause numerous context switches table 1 shows total number context switches protocol configuration number context switches isp approximately 15 times isp gel null cond anm execution time protocols figure 4 execution times cqnf model one processor table 1 number context switches null messages global ecot computations one processor executions theta1 000 isp gel null cond anm context switches 85 1257 393 1149 914 global computation number regular messages processed simulation 1193 theta1 000 less required gel algorithm considering total messages processed execution 1200000 messages gel protocol almost one context switch per message 2 isp conservative protocols also use efficient data structure order entities gel algorithm whereas gel must use ordered data structure like splay tree sort entities order earliest timestamps messages input queues protocols use simple unordered list entities scheduled basis safe messages thus performance difference isp gel protocols primarily due differences costs context switching entity queue management next compare performance isp three conservative protocols first isp fewer context switches protocols number messages processed entity using conservative protocols bounded eit whereas isp upper bound differences number context switches among three conservative protocols due differences computation eit well due additional context switches may required process synchronization messages instance cond protocol 2 since maisie runtime system main thread correspond entity number context switches larger number messages three times number context switches null protocol cond protocol switch entities every global ecot computation globally updates eit value entity null protocol require context switch process every null message cqnf model used experiment consists 128 entities switch entity lookahead 1 time unit thus window size two global ecot computations small shown table 1 cond protocol approximately 49000 global computations averages one global computation every advance 2 units simulation time even though null protocol uses context switches execution time significantly larger isp large number null messages 1732000 table 1 must processed resulting updates eit although anm protocol incurs overhead due null messages global ecot computations number null messages global ecot computations significantly less null cond protocols result performance lies somewhere null cond protocols 52 communication topology section 41 introduced maisie constructs alter default connectivity entity next experiment examine impact communication topology performance parallel conservative simulations protocol cqnf model executed different values total number serevrs kept constant among three configurations keeping n q 128 parameters model set 000 total number entities n q 1 kept constant among different configurations also keep size model constant n increases connectivity model increases dramatically n switch entities n outgoing channels q server entities tandem queue one outgoing channel instance total number links 368 1120 4160 respectively first measured speedup isp protocol speedup calculated respect one processor isp execution seen figure 5 speedup isp relatively independent n implies inherent parallelism available three configurations affected significantly number links 3 figure 6 8 show efficiency three conservative protocols 64g 3 small reduction speedup n64 due dramatic increase number context switches configuration seen table 2 number processors figure 5 cqnf speedup achieved isp02061 efficiency number processors null cond figure cqnf efficiency protocol efficiency number processors null cond figure 7 cqnf efficiency protocol efficiency number processors null cond figure 8 cqnf efficiency protocol null message number processors figure 9 cqnf nmr null protocol135 window size number processors figure 10 cqnf window size cond protocol seen three graphs null anm protocols similar efficiencies except sequential case cond protocol performs quite differently examine performance protocol following subsections 521 null message protocol null protocol eit value entity calculated using eot values incoming channels ie entities sourceset number incoming channels entity small eit value advanced null messages thus efficiency null protocol relatively high case low connectivity shown figure 6 however high connectivity protocol requires large number null messages performance degrades significantly null message ratio nmr commonlyused performance metric protocol defined ratio number null messages number regular messages processed model seen figure 9 nmr low increases substantially connectivity model becomes dense entity must send null messages even entities processor nmr configuration change number processors however efficiency decreases number processors increased null messages remote processors expensive processorlocal null messages 522 conditional event protocol unlike consrvative protocols performance cond protocol affected communictaion topology model cost global ecot computation independent topology thus figures 6 8 efficiency cond protocol degrade rather improves n goes 32 64 reason relative cond protocol performance isp degrades causing relative efficiency cond protocol improve effect explained looking table 2 presents number context switches incurred one processor execution three model configurations protocol seen table measure increases dramatically isp n increases 32 64 cond protocol already one context switch per message change significantly n increases average window size another commonly used metric protocol defined number synchronizations figure shows average window size three experiments cond protocol table 2 number context switches one processor executions theta1 000 regular messages isp gel null cond anm seen figure average window size parallel implementations close 1 implies protocol requires one global computation every simulation clock tick one processor execution window size 2 smaller window size parallel implementation caused need flush messages may transit computing global ecot described section 44 however value window size w appear strong correlation performance cond protocol first although w drops 50 go 1 2 processors efficiency drop dramatically second although efficiency protocol continues decrease number processors p increases figures 6 figure shows w change dramatically p 2 performance degradation protocol number processors may explained follows first processor broadcasts ecot messages global ecot computation requires messages p processor execution p 1 second idle time spent lp waiting completion global ecot computation also grows significantly increases 523 anm protocol efficiency anm protocol shown figure 6 8 close null protocol except one processor execution figure 11 12 show nmr average window size respectively anm protocol almost nmr values null protocol average window sizes vary widely models although window size becomes narrower n increases occurs following reasons ffl ecot computation initiated entity processor messages process n increases since every processor must send one ecot message one global ecot computation eit updates ecot messages easily defer unless every processor entities schedule ffl even global ecot calculation unhindered may effect null messages already advanced eit values cases number null messages decreased global ecot computations anm protocol higher overheads null protocol therefore efficiencies anm protocol figure 6 8 close ones null protocol except one processor executions models rarely sent since null messages efficiently advance eit value entity situation processors entity schedule unlikely however 64 performance anm protocol expected closer cond protocol since eit updates ecot messages efficient updates null messages seen figure 12 ecot messages fact sent frequently average window size approximately 7 64 inefficiency case arises large number null messages sent entity hence duration processor would idle cond protocol filled processing time null messages seen comparing figure 9 11 protocols almost nmr considering anm protocol overhead caused ecot computation reason efficiency null protocol ecot messages actually improve advancement eit little improvement makes overhead ecot computations experiments section global ecot computations anm protocol sufficient impact improve performance however models experiments good lookahead values thus null messages efficiently update eit values entities next section examine cases simulation models poor lookahead compare performance anm null protocols case 53 lookahead 531 precomputation service times well known performance conservative protocols depends largely lookahead value model lookahead stochastic server improved precomputing service times14 section examine effects lookahead cqnf models precomputing service times instead lookahead set one time unit lower bound service time generated shifted exponential distribution change entities lookahead value one time unit worst lookahead value experiments figures 13 15 show effect change plot p performance degradation results change function number processors note performance isp cannot affected lookahead value use lookahead simulation run thus isp performance identical result shown figure 5 fractional performance degradation calculated follows precomputation service times execution time precomputation service times gamma 1 interestingly figures show performance degradation negative cases indicates executions actually become faster lookahead reduced null anm protocols attributed choice scheduling strategy discussed section 42 although strategy reduces context switching overheads may also cause starvation entities entity scheduled long period blocks progress entities processor may also block entities remote processors thus increase overall idle time note performance improvement poorer lookahead occurs primarily configuration communication topology dense number jobs available server typically greater 1 may lead long scheduling cycles cond protocol duration window size determines long entity scheduled context switch longer window implies fewer ecot computations may also lead increased blocking entities thus cases poorer lookahead may force frequent ecot messages thus improve performance effect related communication topology relative performance cond protocol without lookahead almost three values n figures 13 15 performance null anm protocols degrade connectivity model becomes dense performance cond protocol change significantly discussed particular performance cond protocol degrade although already outperforms two protocols experiment better lookahead figure 8 indicates cond protocol significant advantage null message based protocols case simulation model high connectivity poor lookahead another interesting observation performance anm protocol degrade much null protocol figure 15 behavior may understood figure 16 shows relative increase number null messages global ecot computations poor lookahead experiment considered section good lookahead scenario section 52 seen figure 16 model poor lookahead anm protocol suppresses increase null messages increasing number global ecot computations result shows capability anm protocol implicitly switch eit computation base ecot messages eit values cannot calculated efficiently null messages null message number processors figure 11 cqnf nmr anm protocol501502503504501 2 3 4 5 6 7 8 window size number processors figure 12 cqnf window size anm protocol02061 performance degradation number processors null cond figure 13 cqnf performance low lookahead performance degradation number processors null cond figure 14 cqnf performance low lookahead performance degradation number processors null cond figure 15 cqnf performance low lookahead cqnf good lookahead number processors number global computations cond number global computations anm number null messages null number null messages anm figure increase null messages global computations low lookahead 532 cqn priority servers cqnp section 531 examined impact lookahead explicitly reducing lookahead value server entity section vary lookahead using priority servers rather fifo servers tandem queues assume job one two priority classes low high low priority job preempted high priority job case precomputation service time cannot always imrove lookahead low priority job service may interrupted time lookahead remaining service time low priority job precomputed service times useful server idle experiments described section investigate impact variability lookahead priority server performance three protocols figure 17 shows speedup achieved isp cqn models priority servers cqnp 25 jobs 256 assumed high priority comparison figure 5 isp achieves slightly better performance events priority servers slightly higher computation granularity fcfs servers impact computation granularity protocol performance explored next section since isp performance depend lookahead model performance degradation expected observed protocol figures 20 show efficiency protocol 64g performance cond protocol priority servers similar fcfs servers figures 6 8 performance two protocols considerably worse priority servers even though connectivity cond protocol outperforms two protocols shows cond protocol connectivity insensitive also less lookahead dependent null message based protocols 54 computation granularity one good characteristics cqn models evaluation parallel simulation protocols fine computation granularity computation granularity protocolindependent factor changes breakdown costs required different operations model high computation granularity percentage contribution protocoldependent factors execution time sufficiently small produce relatively high efficiency simulation protocols examine inserting synthetic computation fragment containing 1000000 operations executed every incoming message server figure 21 shows impact computation granularity speedup using isp cqnf model 32 number processors figure 17 cqnp speedup achieved isp02061 efficiency number processors null cond figure cqnp efficiency protocol efficiency number processors null cond figure 19 cqnp efficiency protocol efficiency number processors null cond figure 20 cqnp efficiency protocol number processors original computation fragment figure 21 cqnf speedup synthetic computation fragment efficiency number processors null cond figure 22 cqnf efficiency protocol synthetic computation fragment simulation horizon h reduced 1000 sequential execution time model dummy computation fragment 1200 times longer original model figure performance improvement isp close linear performance degrades little number processors 5 6 7 decomposition model among processors leads unbalanced workload one protocolindependent factors parallel simulation improvement speedup larger computation granularity attributed improvement ratio event processing time protocolindependent factors communication latency context switch times figure 22 shows impact increasing computation granularity efficiency three conservative protocols clearly additional computation diminishes protocoldependent overheads null anm protocols performance two protocols close isp performance cond protocol however gets worse number processors increases efficiency 54 8 processors described 522 degradation due idle time spent processor waiting completion global computation implies even cond protocol employs efficient method global ecot computation overhead becomes close zero protocol achieve half speedup isp execution 8 processors idle time must spent waiting global ecot computation complete result shows inherent synchronousness cond protocol although implementation algorithm asynchronous 6 related work prior work evaluating performance discreteevent models conservative protocols used analytical simulation models well experimental studies performance null message deadlock avoidance algorithm 6 using queuing networks synthetic benchmarks studied fujimoto 10 reed et al 16 studied performance deadlock avoidance algorithm deadlock detection recovery algorithm shared memory architecture chandy sherman 7 describe conditional event algorithm study performance using queuing networks implementation conditional event algorithm synchronous ie lps carry local computations followed global computation performance studies carried paper assume network high number jobs paper compare performance conditional event protocol others nicol15 describes overheads synchronous algorithm similar conditional event algorithm studied paper mathematical model constructed qualify overhead due various protocolspecific factors however analytical tractability paper ignores costs protocolindependent operations simplification communication topology physical system thus results useful qualitative comparisons provide tight upper bound potential performance derived using isp effect lookahead performance conservative protocols studied fujimoto 10 nicol 14 introduced idea precomputing service time improve lookahead cota sargent 8 described use graphical representation process automatically computing lookahead performance studies carried simulation models specific experiments performance study presented paper differs two important respects first developed used new metric efficiency respect ideal simulation protocol allows protocolspecific overheads separated cleanly overheads directly contributed simulation protocol second implementation algorithms separated model allows performance comparison consistent algorithm implemented directly simulation model conclusions important goal parallel simulation research facilitate use discreteevent simulation community maisie simulation language separates simulation model specific algorithm sequential parallel used execute model transparent sequential optimistic implementations maisie developed described previously 2 paper studied performance variety conservative algorithms implemented maisie three algorithms studied include null message algorithm conditional event algorithm new algorithm called accelerated null message algorithm combines preceding approaches maisie models developed standard queuing network benchmarks various configurations model executed using three different algorithms results performance study may summarized follows ffl ideal simulation protocol isp provides suitable basis compare performance conservative protocols clearly separates protocol dependent independent factors affect performance given synchronization protocol gives realistic lower bound execution time simulation model given partitioning architecture existing metrics like speedup throughput indicate performance provide additional insight could improved metrics like nmr null message ratio window size useful characterization protocol dependent overheads null message conditional event protocols respectively cannot used among diverse set simulation protocols isp hand used analyst compare protocoldependent overheads even conservative optimistic protocols ffl null message algorithm exploited good parallelism models dense connectivity however performance algorithm sensitive communication topology lookahead characteristics model thus appropriate models high connectivity low lookahead values ffl insensitivity communication topology model conditional event protocol outperforms null message based protocols lps highly coupled also performs well models poor lookahead although algorithmic syn chronousness degrades performance parallel executions high number processors performance protocol stable throughout experiments faster global ecot computations may achieve better performance since conditional event algorithm also good characteristic requiring positive lookahead values algorithm may also used simulate models zero lookahead cycles ffl performance anm protocol null message conditional event protocols one processor execution expected performance parallel executions however close null message protocol since small eit advancements null messages defer global ecot computation thus performs worse conditional event protocol simulation model high connectivity poor lookahead however compared null message protocol cases anm protocol prevents explosion number null messages frequent global ecot computa tions performs better null message protocol shows protocol capability adaptively implicitly switching execution mode null message based synchronization conditional event based one better performance since algorithm also inherits characteristic conditional event algorithm simulate models zero lookahead cycles best suited models whose properties unknown future work includes use isp performance evaluation various algorithms optimistic algorithms synchronous algorithms together algorithms examined paper using additional applications different disciplines acknowledgments authors wish thank professor iyer three reviewers valuable comments suggestions resulted significnat improvements presentation also acknowledge assistance past present team members parallel computing laboratory role developing maisie software maisie may obtained annonymous ftp httpmaycsuclaeduprojectsmaisie r stability event synchronisation distributed discrete event sim ulation unifying framework distributed simulations maisie language design efficient discreteevent simulations language support parallel discreteevent simulations global virtual time algorithms asynchronous distributed simulation via sequence parallel computations conditional event approach distributed simulation framework automatic lookahead computation conservative distributed simulation parallel discrete event simulation performance measurements distributed simulation strategies state art parallel simulation understanding limits optimistic conservative parallel simulation distributed discreteevent simulation parallel discrete event simulation fcfs stochastic queueing networks cost conservative synchronization parallel discrete event simulations parallel discrete event simulation shared memory approach variants chandymisrabryant distributed simulation al gorithm tr ctr alfred park richard fujimoto kalyan perumalla conservative synchronization largescale network simulations proceedings eighteenth workshop parallel distributed simulation may 1619 2004 kufstein austria jinsheng xu moon jung chung predicting performance synchronous discrete event simulation ieee transactions parallel distributed systems v15 n12 p11301137 december 2004 mookyoung chung chongmin kyung improving lookahead parallel multiprocessor simulation using dynamic execution path prediction proceedings 20th workshop principles advanced distributed simulation p1118 may 2426 2006