parallel dynamic programming solving string editing problem cgmbsp paper present coarsegrained parallel algorithm solving string edit distance problem string substrings string c method based novel cgmbsp parallel dynamic programming technique computing highest scoring paths weighted grid graph algorithm requires log p roundssupersteps ofracn2plog local computation p number processors p2 leq leq n knowledge first efficient cgmbsp algorithm alignment substrings c furthermore cgmbsp parallel dynamic programming technique presented interest right expect lead parallel dynamic programming methods cgmbsp b introduction molecular biology important field application parallel computing sequence comparison among fundamental tools computational molecular biology used solve complex problems 14 including computation similarities biosequences 11 13 15 beside molecular biology applications sequence comparison also used several applications 8 9 17 notions similarity distance cases interchangeable used infer functionality aspects related evolutive history evolved sequences either case looking numeric value measures degree sequences alike dierent give formal definition string editing prob lem let string symbols fixed size alphabet string following edit op erations deletion insertion substitution edit operation assigned non negative real number representing cost operation dx deletion symbol x ix insertion symbol x x exchange symbol x symbol edit sequence sequence editing operations cost sum costs operations let c two strings respectively n string editing problem input strings c consists finding edit sequence minimum cost transforms c figure 1 grid dag g cost edit distance c let ei j minimum cost transforming prefix r ij figure 2 processor p ij stores submatrix g ij length prefix c length j follows ei easy see string editing problem modeled grid graph 1 12 figure 1 n grid graph e directed acyclic weighted graph whose vertices points grid rows columns 0 n vertex j directed edge endpoints within boundaries grid 12 14 authors describe obtain similarity alignment two strings using string editing assuming similarity score satisfies triangle equality similarity problem solved computing largest sourcesink path weighted directed acyclic graph g grid dag corresponds edit sequence transforms c standard sequential algorithms string editing problem based dynamic programming complexity algorithms omn time given similarity matrix construction optimal alignment done omn sequential time 14 parallel dynamic programming well studied topic ecient parallel pram algorithms dynamic programming presented galil park 5 6 pram algorithms string editing problem proposed apostolico et al 1 general study parallel algorithms dynamic programming found 7 paper study parallel dynamic programming string editing problem using bsp 16 coarse grained multicomputer cgm 3 4 model cgm consists set p processors p1 pp onp local memory per processor n space needed sequential algorithm processor connected router send messages pointtopoint fash ion cgm algorithm consists alternating local computation global communication rounds separated barrier synchronization round equivalent superstep bsp model communication round consists routing single hrelation onp require information sent given processor another processor one communication round packed one long message thereby minimizing message overhead cgm model communication cost modeled number communication rounds main advantage bspcgm algorithms map well standard parallel hardware particular beowulf type processor clusters 4 main concern communication requirements goal minimize number communication rounds present cgmbsp algorithm solving string edit distance problem string substrings string c via parallel dynamic programming 2 log sequential algorithm presented 12 solve approximate repeats strings problem problem also arises common substring alignment problem 10 method requires log p roundssupersteps n 2 log local computation knowledge first e cient cgmbsp algorithm problem furthermore cgmbsp parallel dynamic programming technique presented interest right expect result lead parallel dynamic programming methods cgmbsp 2 cgm algorithm computing highest scoring paths section present parallel algorithm computing highest scoring paths ahsp weighted n grid graphs using cgm p processors mn local memory per processor using method find optimal alignment c divide grid graph g p subgrids g ij 1 processor p ij stores subgrid g ij figure 2 let left boundary l g set points leftmost column right top bottom boundaries r b respectively defined analogously boundary g union left right top bottom boundaries l r b let distg ij mn1 containing lengths shortest paths begin left boundary g ij end right r ij bottom b ij boundary g ij matrix consists four submatrices l ij r ij stor ing shortest paths begin left boundary end right boundary g ij l ij b ij storing shortest paths begin left boundary end bottom boundary g ij ij r ij storing shortest paths begin top boundary end right boundary g ij storing shortest paths begin left boundary end bottom boundary g ij using algorithm schmidt 12 processor compute distances paths left top boundaries right bottom boundaries g ij time mn log general strategy cgmbsp algorithm fol lows general step algorithm several processors collaborate join previously calculated subgrids beginning step subgrid distance matrix distributed among group processors two neighbor grids joined processors hold two distance trices resulting new distance matrix distributed among processors step algorithm reduces factor 12 number subgrids remaining merged 21 joining grids show sequential algorithm join two adjacent grids common horizontal boundary case common vertical boundary analogous next subsection show distance matrices two grids size l k stored q processors used 2q processors build distance matrix 2l 1k size merged grid procedure takes time ol provided q small compared l k constant number communication rounds round transfers ol data fromto processor local memory required processor ol simplicity refer upper grid gu boundaries lu tu bu ru lower grid g l boundaries l l l b l r l refer distance matrices upper lower final grids distu dist l dist ul respectively important note size resulting distance matrix dierent total size two original distance matrices however four grids joined 2 2 configuration sizes add precisely initial distance matrix stored matrix evenly distributed among q processors 1 definition accounts top left bottom right corners q processors store distu consecutive columns distu q processors store dist l p l1 p l2 p lq store consecutive rows dist l note distance matrices actually banded matrices great portion matrices involved joining operation figure 3 illustrates parts old matrices copied parts used build new matrix copied parts require redistribution end step concentrate calculating submatrix dist ul shaded areas illustrate regions paths exist submatrices eectively involved calculations thicker border b b l r l r u dist u dist l dist ul figure 3 matrices distu dist l dist ul existence unused shaded parts distance matrices impact constants paper important results therefore ignore simplicity define indices interesting part dist ul let us concentrate paths lu tu b l r l paths cross common boundary sources sequence points lu tu beginning lower left corner lu ending top right corner let destinations sequence points b l r l starting lower left corner g l ending top right corner let middle sequence points taken left right figure 4 denote mi j index k leftmost point mk belongs optimum path j path mi value used sentinel meaning determination single mi j involves search entire sequence find x minimizes use previously calculated results restrict search using following r l g l r u g u figure 4 merging gu g l monge properties 1 12 property 1 valid j property 2 j1 j2 mi j1 valid basically properties imply two optimum leftmost paths share common extremity cannot cross proof based fact take two crossing paths exchange parts build even better paths build path left hence know mi1 j 1 2 search mi mi1 j mi2 j furthermore certain j mi j sequence 1 one value interval sequence using one sweep doubling number known paths operation call sweep use several rows distu jth column dist l similar procedure used calculate mi several values j properties lead following sequential algorithm obtain new distance matrix algorithm base parallel algorithm based recursive version presented 1 calculate use mi j calculating distance j process step begin marked points sequences j marked mi j already known intervals marked points contain points yet used computations step pick middle point interval mark calculating required paths crossing points begin extremities marked algorithm 1 sequential merge distu dist l input two distance matrices distu dist l output dist ul 31 take middle point remaining intervals calculate paths marked points 32 take middle point remaining intervals calculate paths marked points 33 take already used middle points calculate paths mark points unmarked points end algorithm theorem 1 algorithm 1 requires ktt 2 sequential time proof step 31 makes one sweep marked point requires time kr number marked points step 32 also requires time kr 33 done time kr marked point hard see loop executed log iterations value r approximately doubles iteration 2 hence follows total time algorithm 22 parallelizing join operation show algorithm 1 modified compute dist ul cgm natural way parallelize algorithm make processor determine dier ent part dist ul division distu dist l accomplish data dependent solution based dynamic scheduling blocks dist ul processors cgm version algorithm 1 three main phases determination subproblems used parts distu dist l determination scheduling subproblems solution subproblems adapt algorithm 1 calculate distances points interval 1 points interval j1 j2 intervals size assume already calculated j j1 j j2 mi j1 mi j2 already calculated words already know solution borders subproblem important dierence subproblem entire problem part matrix distu dist l used shapes parts irregular shown figure 5 hence order make sweep one point segment one row distu segment one column dist l running time sweep determined size segment therefore variable total running time subproblem sizes necessary segments calculated time ot know many times algorithm sweep segment thus total running time subproblem estimated complete problem divided several subproblems solved parallel 2q processors let us divide 2q equal segments size suppose simplicity integer overlap extremities lead 4q 2 subproblems grid u grid l dist u figure 5 data required compute block dist ul distributed among 2q processors fact subproblems involving tu b l empty omit significant asymptotic performance work 4q 2 subproblems instead natural quantity q 2 order distribute workload evenly beginning cgmbsp algorithm problem calculates mi j belong subproblem boundary implies calculating equally spaced rows 2q1 equally spaced columns dist ul associated mi j lemma 1 values dist ul multiple 1 corresponding values mi calculated parallel 2q processors store distu dist l time ok log qt space 2 two communication rounds oqt data sentre ceived processor proof processors store dist l distributed rows calculate 2q rows one knows lengths paths interval points points hence need receive pu1 pu2 puq length paths chosen points sample interval also send information allow pu1 pu2 puq calculate 2q 1 required columns dist ul communication processor sendsreceives ok data data processor p l1 p l2 p lq calculates paths sample using variation algorithm 1 since 2q 1 running time step dominated last log iterations loop points sample marked several iteration make 2q sweeps segment size k q total running time ok logtq processor among p l1 p l2 p lq versions paths lengths crossing points sample one considering crossings certain interval calculate better paths partitioned q equal intervals processor receives q versions paths points certain interval tq points processor sendsreceives oqt data spends oqt time nave search ot time using monge properties avoid searching versions path omit details latter due lack space concludes procedure processor among p l1 p l2 p lq stores information 4q 4q 2 subproblems mkx mk frontiers subproblem previously de scribed define part dist l used subproblem pu1 pu2 puq contain information mxk mxk borders subproblems define usage distu processors contain actual data necessary process sub problems information borders information sent proper processors one identify data used subproblem besides information used estimate timespace requirement subproblem 23 scheduling subproblems processors commented earlier solve subproblem algorithm sometimes sweeps segment row dist l sometimes sweeps segment column distu estimated running time subproblem divided estimation based used parts dist l based used parts distu running time thus estimated eorts two processors apply total memory necessary store needed parts distu dist l processor takes ot time work estimations one sub work 4q subproblems processors send timespace estimation single pro cessor say pu1 receives processes oq 2 data need distribute 4q 2 subproblems 2q processors objective distribution minimize completion time balancing load processors special case well known nphard multiprocessor scheduling problem case additional restriction space required subproblems assigned single processor perform entire distribution single communication round following present solution ensures claimed time space bounds met lemma 2 4q 2 subproblems scheduled among 2q processors time oq 2 log q resulting 2 time requirements processor proof since subproblems overlap bor ders total space required worst case one subproblem require entire columns rows space2q total running time subproblems dicult calculate sweeps along segments rows columns take dierent times let us consider case dist l get 2q subproblems vertically aligned dist l use sweeping pattern segments columns dist l segments add size total running time sweeps basically running time sweeps sequential algorithm final conclusion time sum running times subproblems approximately equal running time sequential algorithm ot 2 worst case one subproblem run time2q guarantee processor spend ot 2 q time need ot 2 q space calculate cost pro cessor equal sum time space requirements sum costs cost ot 2 problem distribute subproblems among processors local cost processor sum costs subproblems assigned try minimize maximum among processors local cost since maximum cost subproblem cost2q maximum local cost cannot greater minimum local cost plus cost2q would possible reassign subproblems better way hence optimum solution cost less twice cost best possible solution using list scheduling heuristic allocating greedy way costly subproblems first obtain solution cost 43 optimum solution 2 hence maximum local cost less equal since cost sum space time require ments processors require ot 2 q time ot 2 q space solve subproblems scheduling calculated pu1 time oq 2 log q time dominated required sorting subproblems assignment established processor pu1 broadcasts information processors oq 3 data sent processor sends data proper processors receive data subproblems assigned complicated communication step require considerable bookkeeping total data sentre ceived oktq per processor finally processor solves subproblems generating submatrix dist ul subproblem space required data dist l distu discarded subproblems solved subproblems solved last communication step redistributes submatrices dist ul way adequate join new grid neighbor left right theorem 2 2l1k l 2k1 grid two lk halves distance matrix half distributed local memories dierent set q processors possible calculate distance matrix full grid parallel 2q processors given time ol constant number communication steps local memories total data sentreceived step one processor ol theorem follows algorithm described total communication required consists following steps 1 distribution samples allow processors start calculating boundaries subproblems 2 distribution tentative lengths crossing points paths determined previous step processor concentrates candidates certain paths 3 distribution results searches best paths defining boundaries subproblems estimated size time requirements subproblems sent one processor 4 one processor sends assignment subproblems processors 5 data subproblems distributed among processors following predetermined assignment 6 results redistributed among processors 24 overall analysis given nm grid p processors grid initially divided p smaller grids simplify exposition assume number processors even power two subgrid processed one processor obtain distance matrix division grid must aim best overall performance algorithm knowledge best sequential algorithm problem requires onm logminn time 12 algorithm proposed build complex structure would support several kinds queries take onm logminn space however easily adapted use 2 space case interested boundary boundary distances results make tempting divide grid strips minimize logarithmic factor small gain local memory required would prohibitive previously stated divide grid p p configuration ensure local memory required distance matrix 2 p leads following conclusion theorem 3 distance matrix nm grid calculated parallel cgm p processors time n 2 log olog p communication rounds nm local memory proof based previous discussion algorithm requires mn log time calculate distance matrices p subgrids build final distance matrix requires log p merging steps merging step requires constant number communication rounds p bound sucient ensure communication rounds involve nm data per processor processing time merging steps nm 2 resulting total n 2 log p thus whole algorithm runs n 2 log time final distance matrix find scores alignments substrings c lengths paths top bottom grid among results kind 3 conclusion paper present ecient algorithm compute edit distance string substrings string c cgm model algorithm requires log p roundssupersteps n 2 log local computation thus presents linear speedup number communication rounds independent problem size 4 acknowledgments authors wish thank referees helpful comments 5 additional authors w song universidade de sao paulo sao paulo sp brazil email song ime usp br partially supported fapesp grant 98061382 cnpq grant 52377896 1 461230003 cnpqnsf collaborative research program grant 680037993 6 r bounds multiprocessing timing anomalies scalable parallel geometric algorithms coarse grained multicomputers parallel dynamic programming dynamic programming convexity introduction parallel dynamic programming approximate string matching algorithm di common substring alignment problem general method applicable search similarities amino acid sequence two proteins highest scoring paths weighted graphs application finding approximate repeats strings theory computation evolutionary distances pattern recognition introduction computational molecular biology common molecular subsequences bridging model parallel computation fast text searching allowing errors tr bridging model parallel computation efficient parallel algorithms string editing related problems fast text searching dynamic programming convexity concavity sparsity scalable parallel geometric algorithms coarse grained multicomputers highest scoring paths weighted grid graphs application finding approximate repeats strings approximate string matching fast algorithm computing longest common subsequences common substring alignment problem introduction parallel dynamic programming ctr stjepan rajko srinivas aluru space time optimal parallel sequence alignments ieee transactions parallel distributed systems v15 n12 p10701081 december 2004