syntactic versus computational views approximability attempt reconcile two distinct views approximation classes syntactic computational syntactic classes max snp permit structural results natural complete problems computational classes apx allow us work classes problems whose approximability well understood results provide syntactic characterization computational classes give computational framework syntactic classeswe compare syntactically defined class max snp computationally defined class apx show every problem apx placed ie approximationpreserving reduction problem max snp methods introduce simple yet general technique creating approximationpreserving reductions shows wellapproximable problem reduced approximationpreserving manner problem hard approximate corresponding factors reduction follows easily recent nonapproximability results max snphard problems demonstrate generality technique applying classes max snprmax2 min fpi21 clique problem set cover problem respectively complete problemsthe syntactic nature max snp used papadimitriou yannakakis j comput system sci 43 1991 pp 425440 provide approximation algorithms every problem class provide alternate approach demonstrating result using syntactic nature max snp develop general paradigm nonoblivious local search useful developing simple yet efficient approximation algorithms show algorithms find good approximations max snp problems yielding approximation ratios comparable best known variety specific max snphard problems nonoblivious local search provably outperforms standard local search degree approximation achieved efficiency resulting algorithms b introduction approximability np optimization npo problems investigated past via definition two different types problem classes syntacticallydefined classes max snp computationallydefined classes apx class optimization problems constant factor approximation found polynomial time former useful obtaining structural results natural complete problems latter allows us work classes problems whose approximability completely determined attempt develop linkages two views approximation problems thereby obtain new insights types classes show natural generalization max snp renders identical class apx unexpected validation papadimitriou yannakakiss definition max snp attempt providing structural basis study approximability sideeffect resolve open problem identifying complete problems max np techniques extend generic theorem used create approximation hierarchy also develop generic algorithmic paradigm guaranteed provide good approximations max snp problems may also applications 11 background motivation wide variety classes defined based directly polynomialtime approximability problems contained within eg apx constantfactor approximable problems ptas problems polynomialtime approximation schemes fptas problems fullypolynomialtime approximation schemes advantage working classes defined using approximability criterion allows us work problems whose approximability wellunderstood crescenzi panconesi 9 recently also able exhibit complete problems classes particularly apx unfortunately complete problems seem rare artificial seem provide insight natural problems class research direction find approximationpreserving reductions known complete artificial problems classes natural problems therein view understanding approximability latter second family classes npo problems studied defined via syntactic considerations based syntactic characterization np due fagin 10 research direction initiated papadimitriou yannakakis 22 followed panconesi ranjan 21 kolaitis thakur 19 led identification approximation classes max snp rmax2 1 syntactic prescription definition classes proved useful establishment complete problems moreover recent results arora lund motwani sudan szegedy 3 established hardness approximating complete problems max snp within specific constant factors unless natural wonder hardest problems syntactic subclass apx bear relation np though computational view allows us precisely classify problems based approxima bility yield structural insights natural questions certain problems easier approximate others canonical structure hardest representative problems given approximation class furthermore intuitively speaking view abstract identification reductions establish natural complete problems class syntactic view hand essentially structural view syntactic prescription gives natural way identifying canonical hard problems class performing approximationpreserving reductions establish complete problems attempts trying find class mentioned properties ie natural complete problems capturing problems specified approximability successful typically focus relax syntactic criteria allow wider class problems included class however cases seems inevitable classes cannot expressive enough encompass problems given approximability syntactically defined approximation classes strictly contained class npo strict containment shown syntactic considerations alone result could show classes contains p would separated p np would expect every class nature would missing problems p indeed case current definitions explore different direction studying structure syntactically defined classes look closure approximationpreserving reductions advantage closure maintains complete problems set managing include p closure problems p reduction simply use polynomial time algorithm compute exact solution becomes interesting example compare closure 1 max snp denoted max snp apx positive resolution ie max would immediately imply nonexistence ptas max snphard problems since known ptas strict subset apx p 6 np hand unconditional negative result would difficult obtain since would imply p 6 np resolve question affirmative exact nature result obtained depends upon precise notion approximation preserving reduction used define closure class max snp strictest notion reductions available literature lreductions due papadimitriou yannakakis 22 introduce new notion reductions called ereductions slight extension lreductions using reductions define class max snp show equals apxpb class polynomially bounded np optimization problems approximable within constant factors using slightly looser definitions approximation preserving reductions particular ptasreductions crescenzi et al 8 extended include apx max snp build upon result identify interesting hierarchy approximability classes interesting sideeffect results positive answer question papadimitriou yannakakis 22 whether max np complete problems syntactic view seems useful obtaining structural complexity results also developing paradigms designing efficient approximation algorithms exploiting syntactic nature max snp develop general paradigm designing good approximation algorithms problems class thereby provide computational view refer paradigm nonoblivious local search modification standard local search technique 24 show every max snp problem approximated within constant factors algorithms turns performance nonoblivious local search comparable bestknown approximation algorithms several interesting representative problems max snp intriguing possibility coincidence rather hint universality paradigm variant thereof results related extent ausiello protasi 4 define class glo guaranteed local optima npo problems property locally optimum solutions ratio value global local optimum bounded constant follows glo subset apx shown fact strict subset show max snp problem contained glo thereby establishing max snp contained glo contrasts notion nonoblivious local search guaranteed provide constant factor approximations problems max snp fact results indicate nonoblivious local search significantly powerful standard local search delivers strictly better constant ratios also provide constant factor approximations problems glo independently work alimonti 1 used similar local search technique approximation specific problem contained glo max snp 1 papadimitriou yannakakis 22 hinted definition max snp stating minimization problems placed classes lreductions maximization problems 12 summary results section 2 present definitions required state results particular definitions e reduction apx apxpb max snp max snp section 3 show max generic theorem allows equate closure syntactic classes appropriate computational classes outlined section 4 also develop approximation hierarchy based result notion nonoblivious local search nonoblivious glo developed section 5 section 6 illustrate power nonobliviousness first showing oblivious local search achieve performance ratio 32 max 2sat even allowed search exponentially large neighborhoods contrast simple nonoblivious local search algorithm achieves performance ratio 43 establish paradigm yields 2 k approximation max ksat section 7 provide alternate characterization max snp via class problems called max kcsp shown simple nonoblivious algorithm achieves bestknown approximation problem thereby providing uniform approximation max snp section 8 illustrate power class algorithms showing achieve bestknown ratio specific max snp problem vertex cover contained glo implies max snp contained glo glo strict subset nonoblivious glo section 9 apply approximating traveling salesman problem finally section 10 apply technique improving longstanding approximation bound maximum independent sets boundeddegree graphs preliminary version paper appeared 18 preliminaries definitions given npo problem p instance p use jij denote length opt denote optimum value instance solution value solution denoted v assumed polynomial time computable function takes positive integer values see 7 precise definition npo solution instance npo problem p error ei notice definition error applies uniformly minimization maximization problems levels approximability performance ratio approximation algorithm optimization problem p performance ratio rn given instance p oe solution value within multiplicative factor r optimal value referred rapproximation performance ratio r always computes solution error r gamma 1 21 ereductions describe precise approximation preserving reduction use paper various notions approximation preserving reductions exist literature cf 2 16 reduction use referred ereduction errorpreserving reduction seems strictest see ereduction essentially lreduction papadimitriou yannakakis 22 differs one relatively minor aspect problem p ereduces problem p 0 denoted exist polynomial time computable functions f g constant fi maps instance p instance 0 p 0 opt opt related polynomial factor maps solutions 0 0 solutions ei remark 1 ereduction essentially strictest possible notion reduction requires error p linearly related error p 0 notions reductions literature example f reductions p reductions crescenzi panconesi 9 enforce condition one important consequence constraint ereductions sensitive ie 2 p mapped ereduction good solution 0 provide structural information good solution thus reductions real optimization problems decision problems artificially encoded optimization problems implausible p e p 0 implies p well approximable p 0 fact ereduction fptaspreserving reduction important benefit reduction applied uniformly levels approximability case existing definitions fptaspreserving reduction literature example fptaspreserving reduction crescenzi panconesi 9 much unrestricted scope share important property ereduction note crescenzi panconesi 9 showed exists problem p 0 2 ptas problem thus undesirable situation problem p ptas fptaspreserving reduction problem p 0 ptas remark 3 lreduction papadimitriou yannakakis 22 enforces condition optima instance p linearly related optima instance 0 p 0 mapped appears unnatural restriction considering reduction allowed arbitrary polynomial time computation real difference lreduction ereduction ereduction linearity relation optimas satisfied lreduction intuitively however study approximability desirable attribute simply errors corresponding solutions closely linearly related somewhat artificial requirement linear relation optimum values precludes reductions problems related scaling factor instance seems desirable two problems whose objective functions simply related fixed polynomial factor interreducible reasonable definition approximationpreserving reduction relaxation lreduction constraint motivated precisely consideration let c class npo problems using notion ereduction define hardness completeness problems respect c well closure polynomiallybounded subclass definition 4 hard complete problems problem p 0 said chard problems p e p 0 chard problem p said ccomplete addition p 2 c definition 5 closure closure c denoted c set npo problems p p e p 0 p 0 2 c remark 4 closure operation maintains set complete problems class definition 6 polynomially bounded subset polynomially bounded subset c denoted cpb set problems p 2 c exists polynomial pn instances 2 p 22 computational syntactic classes first define basic computational class apx definition 7 apx npo problem p class apx exists polynomial time computable function mapping instances p solutions constant c 1 instances p class apxpb consists polynomially bounded npo problems approximated within constant factors polynomial time let fapx denote class npo problems approximable within factor f obtain hierarchy approximation classes instance polyapx logapx classes npo problems polynomial time algorithms performance ratio bounded polynomially logarithmically respectively input length precise form definitions provided section 4 let us briefly review definition syntactic classes definition 8 max snp max np 22 max snp class npo problems expressible finding structure maximizes objective function denotes input consisting finite universe u finite set bounded arity predicates p finite structure f quantifierfree firstorder formula class max np defined analogously except objective function natural extension associate weight every tuple range universal quantifier modified objective find maximizes v x wxfi weight associated tuple x example 1 max ksat max ksat problem given collection clauses n boolean variables possibly weighted clause disjunction precisely k literals find truth assignment satisfying maximum weight collection clauses fixed integer k max ksat belongs class max snp results papadimitriou yannakakis 22 adapted show k 2 max ksat complete ereductions class max snp definition 9 rmaxk 21 rmaxk class npo problems expressible finding structure maximizes objective function single predicate fi quantifierfree cnf formula occurs k times clause occurrences negative results panconesi ranjan 21 adapted show max clique complete ereductions class rmax2 class npo problems expressible finding structure minimizes objective function single predicate fi quantifierfree cnf formula occurs k times clause occurrences positive results kolaitis thakur 19 adapted show set cover complete ereductions class min f 3 max snp closure apxpb section establish following theorem examine implications proof based results arora et al 3 efficient proof verifications theorem 1 max remark 5 seeming weakness max snp captures polynomially bounded apx problems removed using looser forms approximationpreserving reduction defining closure particular crescenzi trevisan 8 define notion ptaspreserving reduction apxpb using result conjunction theorem easily seen max weaker reduction necessary allow reductions finegrained optimization problems coarser polynomiallybounded optimization problems cf 8 following surprising consequence theorem 1 theorem 2 max papadimitriou yannakakis 22 implicitly introduced closure classes conjecture would interesting see equality shown independent result arora et al 3 also obtain following resolution problem posed papadimitriou yannakakis 22 finding complete problems max np theorem 3 max sat complete max np following subsections establish max snp apxpb idea first ereduce minimization problem apxpb maximization problem therein ereduce maximization problem apxpb specific complete problem max snp viz max 3sat since ereduction forces optimas two problems involved related polynomial factors easy see max snp apxpb combining establish theorem 1 31 reducing minimization maximization observe fact p belongs apx implies existence approximation algorithm constant c c henceforth use ai denote v ai first reduce minimization problem p 2 apxpb maximization problem p 0 2 apxpb latter obtained merely modifying objective function p follows let p 0 objective function v 0 instances solutions p verified optimum value instance p 0 always lies ai c 1ai thus 1approximation algorithm p 0 ffi error solution optimum p 0 ie opt 0 optimal value v 0 obtain c c c thus solution p 0 error ffi solution p error c implying ereduction 32 np languages max 3sat following theorem adapted result arora lund motwani sudan vazirani 3 critical ereduction maximization problems max 3sat theorem 4 given language l 2 np instance x 2 n one compute polynomial time instance f x max 3sat following properties 1 formula f x clauses depends n 2 exists constant ffl 0 1 gamma fflm clauses f x satisfied truth assignment 3 x 2 l f x completely satisfiable 4 x 62 l truth assignment satisfies clauses f x 5 given truth assignment satisfies clauses f x truth assignment satisfies f x completely constructed polynomial time properties may immediately obvious construction given arora lund motwani sudan szegedy 3 easy verify provide reduction properties 1 3 4 property 5 obtained fact assignments satisfy clauses actually close terms hamming distance valid codewords linear code uniquely errorcorrected codeword obtained corrupted codeword satisfy clauses f x property 2 requires bit care provide brief sketch may ensured idea revert back pcp model redefine proof verification game suppose original game properties x 2 l exists proof verifier accepts probability 1 otherwise x 62 l verifier accepts probability 12 augment game adding proof 0th bit prover uses follows bit set 1 prover chooses play old game else effectively giving game verifier turn first looks 0th bit proof set performs usual verification else tosses unbiased coin accepts turns heads clear x 2 l exists proof verifier always accepts also x 62 l proof cause verifier accept probability greater 12 finally setting 0th bit 0 prover create proof verifier accepts probability exactly 12 proof system transformed 3cnf formula desired form 33 reducing maximization max 3sat already established without loss generality need worry maximization problems consider problem p let polynomialtime algorithm delivers capproximation p c constant given instance p let bound optimum value obtained running input note may stronger bound priori polynomial bound optimum value instance length jij important consequence p c opt generate sequence np decision problems l given instance create p formulas f using reduction theorem 4 ith formula obtained np language l consider formula following features ffl number satisfiable clauses f exactly ffl guaranteed theorem 4 ffl given assignment satisfies 1 clauses f construct polynomial time solution value least j see observe following assignment many clauses must satisfy clauses least j formulas f let largest index happens clearly j furthermore property 5 theorem 4 construct truth assignment satisfies f completely truth assignment used obtain solution v order complete proof remains shown given truth assignment error ffi ie satisfies max 1 clauses f find solution error ei constant fi show possible cfflffl main idea behind finding solution use second property find good solution using good truth assignment f suppose given solution satisfies max 1 clauses since max 1 use second feature construct solution 1 fflm c readily seen assuming obtain hand error solution 2 obtained running capproximation algorithm p given therefore choosing immediately obtain solution larger value among 1 error fi ffi thus reduction indeed ereduction 4 generic reductions approximation hierarchy section describe generic technique turning hardness result approximation preserving reduction start listing kind constraints imposed hardness reduction approximation class optimization problem observe end restrictions obeyed known hardness results corresponding approximation classes definition 11 additive problems npo problem p said additive exists operator maps pair instances 1 2 instance 1 2 opt definition 12 downward closed family family functions said downward closed g 2 f constants c g 0 n 2 ogn c implies g 0 2 f function g said hard family f g 0 2 f exists constant c g 0 n 2 ogn c function g said complete f g hard f g 2 f downward closed family f class f apx consists problems approximable within ratio gjij function g 2 f definition 14 canonical hardness np maximization problem p said canonically hard class f apx exists transformation constants n 0 c gap function g hard family f given instance x 3sat n n 0 variables n n c x n instance p following properties ffl x 2 3sat opt ffl x 62 3sat opt ffl given solution v ngn truth assignment satisfying x found polynomial time canonical hardness np minimization problems analogously defined opt formula satisfiable opt given solution value less ngn one construct satisfying assignment polynomial time 41 reduction theorem 5 f downward closed family functions additive npo problem w canonically hard class f apx problems f apx ereduce p proof let p problem fapx approximable within c let w problem shown hard within factor g g complete f start special case p w maximization problems describe functions f g constant fi required ereduction let 2 p instance size n pick n cn ogn describe reduction need specify functions f g function f defined follows let denote nplanguage fij opt ig create instance oe 2 w size n 2 l opt oe n ngn otherwise define construct function g given instance 2 p solution 0 fi compute solution following manner first use find solution 1 also compute second solution 2 follows let j largest index solution 0 projects solution instance oe j v 0 turn implies find solution 2 witness solution one among 1 2 yields larger objective function value show reduction holds cn consider following two cases case 1 j case v thus ff gamma 1 approximate solution argue 0 best ff gamma 1fi approximate solution oe start following upper bound cn gn gammagn thus approximation factor achieved 0 given nm case 1 hence approximates within factor fi ffl 0 approximates oe within factor ffl case 2 j let flm note fl 1 ff gamma flfl approximate solution bound value solution 0 oe cn quality thus case also find virtue 2 solution quality fi ffl 0 solution quality consider general cases p w maximization problems case minimization problems transformation works one minor change creating oe np language consists instances exists case p minimization problem w maximization problem first ereduce p maximization problem p 0 proceed reduction proceeds follows objective function p 0 defined v 0 begin easy verify p 2 fapx implies let fi approximate solution instance p show best fi2 approximate solution instance p 0 assume without loss generality fi 6 0 multiplying 2m 2 opt iv get 2 implies upon rearranging thus reduction p p 0 ereduction finally last remaining case ie p maximization problem w minimization problem dealt similarly transform p minimization problem p 0 remark 6 theorem appears merge two different notions relative ease approximation optimization problems one notion would consider problem p 1 easier p 2 exists approximation preserving reduction p 1 p 2 different notion would regard p 1 easier one seems better factor approximation statement essentially states two comparisons indeed instance max clique problem chromatic number problem polyapx interreducible observation motivates search interesting function classes f class f apx may contain interesting optimization problems 42 applications following consequence oftheorem 5 theorem 6 b set cover canonically hard approximate within factor wlog n briefly sketch proof theorem hardness reduction max sat clique canonical 3 11 classes apxpb polyapx logapx expressible classes fapx downward closed function families problems max sat max clique set cover additive thus apply theorem 5 remark 7 would like point almost known instances hardness results seem shown problems additive particular true max snp problems max clique chromatic number set cover one case hardness result seem directly apply additive problem longest path 17 however case closely related longest st path problem easily seen additive hardness result essentially stems problem lastly interesting optimization problems seem additive problems related graph bisection partition also happen notable instances hardness approximation results achieved 5 local search max snp section present formal definition paradigm nonoblivious local search describe applies generic max snp problem given max snp problem p recall goal find structure maximizes objective function v x fi x subsequent discussion view kdimensional boolean vector 51 classical local search start reviewing standard mechanism constructing local search algorithm ffilocal algorithm p based distance function ds 1 hamming distance two kdimensional vectors ffineighborhood structure given ns u universe structure called ffioptimal 8s algorithm computes ffioptimum performing series greedy improvements initial structure 0 iteration moves current structure constant ffi ffilocal search algorithm polynomiallybounded npo problem runs polynomial time ffl local change polynomially computable ffl number iterations polynomially bounded since value objective function improves monotonically integral amount iteration optimum polynomiallybounded 52 nonoblivious local search nonoblivious local search algorithm based 3tuple hs initial solution structure must independent input fi realvalued function referred weight function realvalued distance function returns distance two structures appropriately chosen metric distance function computable time polynomial ju j thus constant ffi nonoblivious ffi local algorithm terminates time polynomial input size classical local search paradigm call oblivious local search makes natural choice function fi distance function ie chooses v hamming distance however show later choice always yield good approximation ratio formalize notion general type local search definition 15 nonoblivious local search algorithm nonoblivious local search algorithm local search algorithm whose weight function defined x r r constant f quantifierfree firstorder formulas profits p real constants distance function arbitrary polynomialtime computable function nonoblivious local search implemented polynomial time much way oblivious local search note considering polynomiallybounded weight functions profits fixed independent input size general nonoblivious weight functions direct search direction actual objective function fact see exactly reason powerful allow better approximations definition nonoblivious glo class problems nonoblivious glo consists problems approximated within constant factors nonoblivious ffi local search algorithm constant ffi remark 8 make observations definition would perfectly reasonable allow weight functions nonlinear stay definition purposes paper allowing constant number predicates weight functions enables us prevent encoding arbitrarily complicated approximation algorithms structure kdimensional vector convenient metric distance function hamming distance assumed underlying metric unless otherwise specified however found sometimes useful modify example modifying hamming distance complement vector considered distance 1 finally sometimes convenient assume local search makes best possible move bounded neighborhood rather arbitrary move improves weight function believe increase power nonoblivious local search 6 power nonoblivious local search show exists choice nonoblivious weight function max ksat assignment 1optimal respect weight function yields performance ratio 2 k respect optimal first obtain tight bounds performance oblivious local search max 2sat establishing performance significantly weaker bestknown result even allowed search exponentially large neighborhoods use following notation fixed truth assignment set clauses exactly literals true set clauses w denotes total weight clauses 61 oblivious local search max 2sat show strong separation performance oblivious nonoblivious local search max 2sat suppose use ffilocal strategy weight function f total weight clauses satisfied assignment ie following theorem shows oblivious ffi local strategy cannot deliver performance ratio better 32 rather surprising given willing allow nearexponential time oblivious algorithm theorem 7 asymptotic performance ratio oblivious ffi local search algorithm max 2sat 32 positive ratio still bounded 54 ffi may take value less n2 proof show existence input instance max 2sat may elicit relatively poor performance ratio ffi local algorithm provided construction input instance assume n 2ffi 1 input instance comprises disjoint union four sets clauses say defined 1ijn 1ijn 2ffi2in ijn clearly 1 without loss generality assume current input assignment 1 satisfies clauses g 1 g 2 none clauses g 3 g 4 satisfied flip assignment values k ffi variables would unsatisfy precisely kn gamma clauses g 1 number clauses g 1 flipped variable occurs unflipped variable hand flipping assigned values k ffi variables satisfy kn gamma clauses g 3 next show denote set clauses n variables given claim following assignment values n variables k ffi variables assigned value false satisfy kn gamma clauses pn ffi proof prove simultaneous induction n ffi statement true instance pn ffi n ffi nonnegative integers n base case includes trivially verified true allowable value ffi namely assume statement true instance pn consider instance pn ffi statement trivially true g choice k ffi variables q assertion trivially true assume k 2 delete clauses containing variables z 1 z 2 pn ffi get instance pn gamma 2 1 consider three cases case 1 case reduced problem finding upper bound maximum number clauses satisfied setting k variables false pn gamma 2 use inductive hypothesis conclude n clauses satisfied thus assertion holds case however may directly use inductive hypothesis case observe since inductive hypothesis setting k gamma 1 variables pn gamma 2 false satisfies n clauses assigning value false set k variables satisfy clauses hence assertion holds case also case case z j 1 satisfies one clause remaining variables satisfy clauses inductive hypothesis adding two terms see assertion holds case 3 analyze case based whether precisely clauses remaining variables satisfy n clauses using inductive hypothesis thus assertion still holds otherwise z 1 satisfies precisely clauses remaining n clauses using inductive hypothesis summing two terms get n gamma kk upper bound total number clauses satisfied thus assertion holds case also see bound tight simply consider situation k variables set false ffi total number clauses satisfied given assuming clause weight lemma 1 allows us conclude ffilocal algorithm cannot increase total weight satisfied clauses starting assignment optimal assignment hand satisfy clauses choosing vector 0 thus performance ratio ffilocal algorithm say r ffi bounded asymptotically converges 32 next show bound tight since 1local algorithm achieves however make another intriguing observation namely ffi n2 ratio r ffi bounded 54 see 1local algorithm ensures performance ratio 32 consider 1optimal assignment z let ff denote set clauses containing variable z literal clause ff satisfied z similarly let fi denote set clauses containing variable z precisely one literal satisfied clause fi furthermore precisely literal containing variable z complement value assigned variable z exactly set clauses ff becomes satisfied set clauses fi longer satisfied since z 1optimal must case w ff w fi sum inequality variables get inequality observe clause 0 gets counted twice clause 1 gets counted exactly thus fractional weight number clauses satisfied 1local assignment bounded hence performance ratio achieved 1local algorithm bounded 32 combining upper bound derived earlier conclude r may summarize results follows lemma 2 performance ratio r ffi ffi local algorithm max 2sat using weight function positive integer furthermore ratio still bounded 54 ffi may take value less n2 62 oblivious local search max 2sat illustrate power nonoblivious local search showing achieves performance ratio 43 max 2sat using 1local search simple nonoblivious weight function theorem 8 nonoblivious 1local search achieves performance ratio 43 max 2sat proof use nonoblivious weight function consider assignment z 1optimal respect weight function without loss generality assume variables renamed unnegated literal gets assigned value true let p ij n ij respectively denote total weight clauses containing literals z j z j respectively since z 1optimal assignment variable z j must satisfy following equation gamma2 p 2j gamma2 p 1j 2 n 1j 2 n 0j 0 summing inequality variables using obtain following inequality immediately implies total weight unsatisfied clauses local optimum 14 times total weight clauses thus algorithm ensures performance ratio 43 remark 9 result achieved using oblivious weight function instead modifying distance function corresponds distances hypercube augmented edges nodes whose addresses complement 63 generalization max ksat also design nonoblivious weight function max ksat 1local strategy ensures performance ratio 2 k 1 weight function f form coefficients c specified later theorem 9 nonoblivious 1local search achieves performance ratio 2 k proof without loss generality assume variables renamed unnegated literal assigned true current truth assignment thus set set clauses unnegated literals denote change current weight flip value z j set 0 easy verify following equation thus algorithm terminates know f summing values j using fact get following inequality determine values coefficient term left hand side unity verified achieves goal thus coefficient w 0 right hand side equation 2 weight clauses satisfied bounded 12 k times total weight clauses worthwhile note regardless value chosen coefficient c 0 7 local search csp max snp introduce class constraint satisfaction problems problems max snp exactly equivalent problems class furthermore every problem class approximated within constant factor nonoblivious local search algorithm 71 constraint satisfaction problems connection syntactic description optimization problems approximability nonoblivious local search made via problem called max kcsp captures problems max snp special case definition 17 kary constraint let set boolean variables kary constraint z size k subset z kary boolean predicate definition given collection c weighted kary constraints variables g max kcsp problem find truth assignment satisfying maximum weight subcollection constraints following theorem shows max kcsp problem universal max snp problem contains special cases problems max snp theorem fixed k max kcsp 2 max snp moreover kcsp instance corresponding instance problem computed polynomial time 72 nonoblivious local search max kcsp suitable generalization nonoblivious local search algorithm max ksat yields following result theorem 11 nonoblivious 1local search algorithm performance ratio 2 k max kcsp proof use approach similar one used previous section design nonoblivious weight function f weighted version max kcsp problem 1local algorithm yields performance ratio problem consider constraints least one satisfying assignment constraint replaced monomial conjunction k literals monomial evaluates true corresponding literal assignment represents satisfying assignment constraint furthermore monomial precisely one satisfying assignment assign monomial weight constraint represents thus assignment variables satisfies monomials total weight w 0 also satisfies constraints original problem total weight w 0 denote monomials true literals assume weight function f form assuming variables renamed current assignment gives value true variable know variable z j f given equation 1 using fact 1optimal assignment f summing values j write following inequality determine values coefficient term left hand side unity verified achieves goal thus coefficient w k right hand side equation 1 total weight clauses satisfied least 12 k times total weight clauses least one satisfiable assignment conclude following theorem theorem 12 every optimization problem p 2 max snp approximated within constant factor uniform nonoblivious 1local search algorithm ie problem expressible kcsp performance ratio 2 k 8 nonoblivious versus oblivious glo section show exist problems constant factor approximation obtained ffi local search algorithm oblivious weight function even allow ffi grow input size however simple 1local search algorithm using appropriate nonoblivious weight function ensure constant performance ratio 81 max 2csp first problem instance max 2csp given collection monomials monomial precisely two literals objective find assignment maximize number monomials satisfied show instance problem every exists instance one whose local optima value vanishingly small fraction global optimum input instance consists disjoint union two sets monomials say g 1 g 2 defined 1ijn ijn clearly consider truth assignment 1 satisfies monomials g 2 none monomials g 1 claim assignment ffi optimal respect oblivious weight function see observe complementing value p ffi variables unsatisfy least ffip2 monomials g 2 hand satisfy precisely p ffi ffip2 z ffi local optimum optimal assignment hand namely monomials g 1 thus n2 performance ratio achieved ffi local algorithm asymptotically diverges infinity already seen section 7 1 local nonoblivious algorithm ensures performance ratio 4 problem since problem max snp obtain following theorem theorem 13 exist problems max snp oblivious algorithm approximate within constant performance ratio ie max snp 6 glo 82 vertex cover ausiello protasi 4 shown vertex cover belong class glo hence exist constant ffi oblivious ffilocal search algorithm compute constant factor approximation fact example used show performance ratio ensured ffilocal search asymptotically diverges infinity however show exists rather simple nonoblivious weight function ensures factor 2 approximation via 1local search fact algorithm simply enforces behavior standard approximation algorithm iteratively builds vertex cover simply including endpoints currently uncovered edge assume input graph g given structure v feg v set vertices encodes edges graph solution represented 2ary predicate iteratively constructed represent maximal matching clearly endpoints maximal matching constitute valid vertex cover vertex cover twice large vertex cover graph thus encoding vertex cover computed algorithm algorithm starts initialized empty relation iteration one new pair included nonoblivious weight function used let encode valid matching graph g 2 make following observations obtained either deleting edge including edge incident edge property fi 0 fi thus 1local search never move relation 0 encode valid matching g ffl hand relation 0 corresponds encoding matching g larger matching encoded fi encode maximal matching g always exist relation 1neighborhood larger weight two observations combined fact start valid initial matching empty matching immediately allow us conclude 1optimal relation always encodes maximal matching g established following theorem 14 1local search algorithm using nonoblivious weight function achieves performance ratio 2 vertex cover problem theorem 15 glo strict subset nonoblivious glo 2 implicit formulation correspond lower triangular matrix representation matching edges 9 traveling salesman problem tsp12 problem traveling salesman problem restricted complete graphs edge weights either 1 2 clearly satisfies triangle inequality papadimitriou yannakakis 23 showed problem hard max snp natural weight function tsp12 weight tour used show 4local algorithm yields 32 performance ratio algorithm starts arbitrary tour iteration checks exist two disjoint edges b c tour deleting replacing edges c b yields tour lesser cost theorem 4local search algorithm using oblivious weight function achieves 32 performance ratio tsp12 proof let c 4optimal solution let let permutation vertices c occur order v consider optimal solution unit cost edge e associate unit cost edge e 0 c follows let consider edges e c claim either e 1 e 2 must unit cost suppose tour c 0 obtained simply deleting e 1 e 2 inserting edges e cost least one less c c 4optimal thus contradiction let uo denotes set unit cost edges let uc set unit cost edges c form image uo mapping since edge e uc image unit cost edges incident v since tour two edges uo map e 0 thus ju c j ju j2 hence costo bound shown tight theorem 17 exists tsp12 instance optimal solution cost n o1 exists certain 4optimal solution cost 3n2 o1 maximum independent sets bounded degree graphs input instance maximum independent set problem bounded degree graphs denoted misb graph g degree vertex g bounded constant present algorithm performance ratio 12 problem 10 algorithm uses two local search algorithms larger two independent sets computed algorithms gives us claimed performance ratio refer two algorithms 1 2 framework algorithm 1 characterized 3local algorithm weight function simply ji thus start initialized empty set easy see iteration correspond independent set g convenient way looking algorithm follows define swap process deleting vertices including j vertices set v gamma set iteration algorithm 1 performs either 0 however interpreted j applications 0 swaps thus algorithm may viewed executing 0 swap iteration algorithm terminates neither two operations applicable let denote 3optimal independent set produced algorithm 1 furthermore let optimal independent set let make following useful observations ffl since vertex 0 performed implies vertex v gamma must least one incoming edge ffl similarly since 1 swaps performed implies ji gamma x j vertices gamma precisely one edge coming thus vertices gamma x must least two edges entering set rather straightforward consequence two observations following lemma lemma 3 algorithm 1 performance ratio 12 misb proof two observations imply minimum number edges entering vertices gamma x hand maximum number edges coming vertices vertices gamma x bounded ji gamma x jd thus must rearranging get yields desired result nearly matches approximation ratio d2 due hochbaum 15 noted result holds broader class graphs viz kclaw free graphs graph called exist independent set size k larger vertices independent set adjacent vertex lemma 3 applies next objective improve ratio using algorithm 1 combination algorithm 2 following lemma uses slightly different counting argument give alternative bound approximation ratio algorithm 1 constraint size optimal solution lemma 4 real number c algorithm 1 performance ratio gamma c2 misb optimal value proof noted earlier vertex v gamma must least one edge coming set least vertices must least two edges coming therefore following inequality must satisfied thus finally observe lemma shows algorithm 1 yields better approximation ratio size optimal independent set relatively small algorithm 2 simply classical greedy algorithm algorithm conveniently included framework use directed local search let ni denote set neighbors vertices weight function simply ji jd 1 difficult see starting empty independent set 1local algorithm directed search weight function simply simulates greedy algorithm greedy algorithm exploits situation optimal independent set relatively large size using fact existence large independent set g ensures large subset vertices g relatively small average degree following two lemmas characterize performance greedy algorithm lemma 5 suppose exists independent set x v average degree vertices x bounded ff ff 1 greedy algorithm produces independent set size least proof greedy algorithm iteratively chooses vertex smallest degree remaining graph deletes vertex neighbors graph examine behavior greedy considering two types iterations first consider iterations picks vertex outside x suppose ith iteration picks vertex exactly k neighbors set x remaining graph since one k vertices must also least k edges incident loose least k 2 edges incident x suppose p iterations occur let observe secondly consider iterations greedy selects vertex x loose vertices x x independent set thus total size independent set constructed greedy algorithm least p cauchyschwartz inequality therefore 1 rearranging obtain thus result follows lemma 6 nonnegative real number c 3d gamma performance ratio gamma c2 misb optimal value least gamma cjv jdc4 proof observe average degree vertices bounded jv gamma ojdjoj thus using fact joj gamma cjv know algorithm 2 computes independent set size least joj1 hence sufficient determine range values c take following inequality satisfied substituting bound value ff rearranging terms equation yields following since c must strictly bounded quadratic equation satisfied choice combining results lemmas 4 6 choosing largest allowable value c get following result theorem approximation algorithm simply outputs larger two independent sets computed algorithms 1 2 performance ratio performance ratio claimed essentially d2414 improves upon longstanding approximation ratio d2 due hochbaum 15 10 however recently flurry new results problem berman furer 6 given algorithm performance even fixed constant halldorsson radhakrishnan 14 shown algorithm 1 run kclique free graphs yields independent set size least 2nd combine algorithm cliqueremoval based scheme achieve performance ratio d61 acknowledgements many thanks phokion kolaitis helpful comments suggestions thanks also giorgio ausiello pierluigi crescenzi guiding us intricacies approximation preserving reductions available literature r new local search approximation techniques maximum generalized satisfiability problems approximate solution np optimization problems proof verification hardness approximation problems optimization problems local optima efficient probabilistically checkable proofs approximating maximum independent set bounded degree graphs introduction theory complexity completeness approximation classes generalized firstorder spectra polynomialtime recognizable sets computers intractability guide theory np completeness improved approximations independent sets boundeddegree graphs efficient bounds stable set approximability npcomplete optimization problems approximating longest path graph syntactic versus computational views approx imability approximation properties np minimization classes hardness approximating minimization problems quantifiers approximation traveling salesman problem distances one two analysis local search problems heuristics tr ctr bruno escoffier vangelis th paschos completeness approximation classes beyond apx theoretical computer science v359 n1 p369377 14 august 2006 angel evripidis bampis laurent gourvs approximating pareto curve local search bicriteria tsp12 problem theoretical computer science v310 n13 p135146 01 january 2004 james b orlin abraham p punnen andreas schulz approximate local search combinatorial optimization proceedings fifteenth annual acmsiam symposium discrete algorithms january 1114 2004 new orleans louisiana jukka suomela approximability identifying codes locatingdominating codes information processing letters v103 n1 p2833 june 2007 cristina bazgan bruno escoffier vangelis th paschos completeness standard differential approximation classes polydapx dptascompleteness theoretical computer science v339 n2 p272292 12 june 2005 friedrich eisenbrand fabrizio grandoni complexity fixed parameter clique dominating set theoretical computer science v326 n13 p5767 20 october 2004 alex characterization np optimal amortized query complexity proceedings thirtysecond annual acm symposium theory computing p191199 may 2123 2000 portland oregon united states jianer chen xiuzhen huang iyad kanj ge xia polynomial time approximation schemes parameterized complexity discrete applied mathematics v155 n2 p180193 january 2007 moni naor kobbi nissim communication preserving protocols secure function evaluation proceedings thirtythird annual acm symposium theory computing p590599 july 2001 hersonissos greece harry b hunt iii madhav v marathe venkatesh radhakrishnan ravi daniel j rosenkrantz richard e stearns parallel approximation schemes class planar near planar combinatorial optimization problems information computation v173 n1 p4063 february 25 2002