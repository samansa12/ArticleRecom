design implementation efficient message scheduling controller area network abstractthe controller area network widely used realtime control applications automobiles aircraft automated factories paper present mixed traffic scheduler mts provides higher schedulability fixedpriority schemes like deadlinemonotonic dm incurring less overhead dynamic earliestdeadline ed scheduling also describe mts implemented existing network adapters motorolas toucan previous work 1 2 shown mts far superior dm schedulability performance paper present implementation overhead measurements showing processing needed support mts consumes 5 6 percent cpu time considering schedulability advantage makes mts ideal use control applications b introduction distributed realtime systems used increasingly control applications automobiles aircraft robotics process control systems consist multiple computational nodes sensors actuators interconnected lan 3 multiple lan protocols available use including map 4 ttp 5 etc controller area network 6 gained widespread acceptance industry 7 control networks must carry periodic sporadic realtime messages well nonrealtime messages messages must properly scheduled network realtime messages meet deadlines coexisting nonrealtime messages limit scope paper scheduling messages whose characteristics like deadline period known priori previous work regarding scheduling messages includes 8 9 focused fixedpriority scheduling shin 10 work reported paper supported part nsf grants mip9203895 ddm9313222 onr grant n000149410229 opinions findings conclusions recommendations authors necessarily reflect views funding agencies sof data crc ack eof sof start frame crc cyclic redundancy code eof end frame figure 1 various fields data frame considered earliestdeadline ed scheduling consider high overhead makes ed impractical paper present scheduling scheme called mixed traffic scheduler mts increases schedulable utilization performs better fixedpriority schemes incurring less overhead ed paper goes beyond work presented 1 2 removing ideal assumptions made previous work also describe mts implemented existing network adapters address problem control priority inversion lowpriority message transmitted ahead higherpriority one within network adapters evaluate different solutions problem measure various execution overheads associated mts implementing motorola 68040 processor emeralds realtime operating system 11 emeralds os designed use distributed embedded control applications mtss implementation use emeralds provide basic os functionality interrupt handling context switching using emulated network device another 68040 acting network adapter connected main node vme bus present detailed measurements execution interrupt handling task scheduling context switching overheads associated mts show feasibility using mts control applications next section give overview protocol section 3 describes various types messages target application workload include realtime nonrealtime messages section 4 gives mts algorithm section 5 discusses issues related implementation mts focusing priority inversion problem section 6 presents implementation overhead measurements paper concludes section 7 controller area network specification defines physical data link layers layers 1 2 isoosi reference model frame seven fields shown figure 1 concerned data length dl identifier id fields dl field 4 bits wide specifies number data bytes data field 0 8 id field two lengths standard format 11bits whereas extended format 29bits controls bus arbitration message addressing interested former described next makes use wiredor wiredand bus connect nodes rest paper assume wiredor bus processor send message first calculates message id may based priority message id message must unique processors pass messages associated ids bus interface chips chips wait till bus idle write id bus one bit time starting significant bit writing bit chip waits long enough signals propagate along bus reads bus chip written 0 reads 1 means another node message higher priority node drops contention end one winner use bus thought distributed comparison ids messages different nodes message highest id selected transmission 3 workload characteristics control applications devices exchange periodic messages motors drives used industrial applications others eventdriven smart sensors moreover operators may need status information various devices thus generating messages timing con straints classify messages three broad categories 1 harddeadline periodic messages 2 harddeadline sporadic messages 3 nonrealtime besteffort aperiodic messages periodic message multiple invocations one period apart note whenever use term message stream refer periodic referring invocations periodic sporadic messages minimum interarrival time mit invocations nonrealtime messages completely aperiodic deadline constraints lowspeed vs highspeed realtime messages messages realtime control system wide range deadlines example messages controller highspeed drive may deadlines hundreds microseconds hand messages devices temperature sensors deadlines seconds physical property measured temperature changes slowly thus classify realtime messages two classes highspeed lowspeed depending tightness deadlines clear section 4 reason classification number bits required represent deadlines messages note highspeed relative term relative tightest deadline 0 workload messages order magnitude deadlines 0 within one order magnitude difference 0 considered highspeed messages others lowspeed 4 mixed traffic scheduler fixedpriority deadline monotonic dm scheduling 12 used setting messages id unique priority 8 9 however general fixedpriority schemes give lower utilization schemes nonpreemptive earliestdeadline 1 ed several reaserchers used ed network scheduling 1517 motivates us use ed schedule messages meaning message id must contain message deadline actually logical inverse deadline bus time progresses absolute deadline values get larger larger eventually overflow id problem solved using type wraparound scheme present section 41 even puting deadline id forces one use extended format 29bit ids compared standard format 11bit ids wastes 2030 bandwidth negating benefit obtained going fixedpriority dynamicpriority scheduling makes ed impractical section present mts scheduler combines ed fixedpriority scheduling overcome problems ed 41 time epochs already mentioned using deadlines id necessitates type wraparound scheme use simple scheme expresses message deadlines relative periodically increasing reference called start epoch soe time two consecutive soes called length epoch deadline field message logical inverse absolute deadline message current time assumed nodes synchronized clocks 18 42 mts idea behind mts use ed highspeed messages dm lowspeed ones first give highspeed messages priority lowspeed nonrealtime ones setting significant bit 1 id highspeed messages figure 2a protects highspeed messages types traffic uniqueness field 5 bits 2 allowing highspeed messages priority field 1 bit remaining 5 bits still enough encode deadlines relative latest soe solution quantize time regions encode deadlines according region fall distinguish messages whose deadlines fall region use dmpriority message uniqueness code makes mts hierarchical scheduler top level ed deadlines two messages distinguished quantization one earlier deadline higher priority nonpreemptive scheduling release time constraints nphard strong sense 13 however zhao ramamritham 14 showed ed performs better simple heuristics deadline dm prioritydm priority fixed priority b c figure 2 structure id mts parts c show ids highspeed lowspeed nonrealtime messages respectively soel end epoch figure 3 quantization deadlines relative start epoch lower level dm messages deadlines region scheduled dm priority calculate length region l r l longest relative deadline highspeed message width deadline field 5 bits case clear figure 3 shown 3 worstcase situation occurs message deadline max released end epoch absolute deadline lies max beyond current soe deadline field must encode time span using bits leading expression l r use dm scheduling lowspeed messages fixedpriority scheduling nonrealtime ones latter assigned priorities arbitrarily ids messages shown figures 2 b c respectively secondmost significant bit gives lowspeed messages higher priority non realtime ones scheme allows 32 different highspeed messages periodic sporadic 512 lowspeed messages periodic sporadic 480 nonrealtime messages 2 sufficient applications 43 id update protocol ids highspeed messages updated every soe note id updates different nodes coincide almost exactly priority inversion occur id lowpriority message updated highpriority one small window time lowpriority message consecutive zeros six significant bits id means 32 codes nonrealtime messages illegal leaves 512 gamma codes higher priority id highpriority message avoid problem must use agreement protocol trigger id update nodes clock synchronization algorithm 18 synchronizes clocks within 20s simple agreement protocol one node designated broadcast message bus message received nodes time nature bus upon receiving special message nodes update ids local messages protocol two disadvantages first much bandwidth wasted transmitting extra message every seconds moreover separate protocol must run elect new leader case old leader fails instead use following protocol robust also consumes less bandwidth node periodic timer fires every seconds time node takes following actions 1 set flag inform device driver id update protocol begun 2 configure network adapter receive messages ie enter promiscuous mode adjusting receive filter 3 increment data length dl field highestpriority ready message node first incrementeddl message sent bus serve signal nodes update ids messages original dl message less 8 incrementing dl result transmission one extra data byte device drivers receiving nodes strip extra byte forwarding message application described later dl already 8 adapters allow 4bit dl field set 9 higher 8 data bytes transmitted node starts receiving messages transmitted bus device driver node table listing ids message streams system along data lengths messages arrive device driver compares dl field values table finds message incremented dl field nodes receive message time take following actions 1 restore receive filter reenable message filtering na 2 local message whose dl field incremented periodic timer transmitted yet decrement dl field back original value 3 update message ids reflect new soe node receives incrementeddl message time id update node starts time first incrementeddl message completes nexthighestpriority message begins transmission long nodes complete id updates message completes window least 55s since message contains least one data byte messages updated ids time next bus arbitration round begins priority inversion occur case one nodes slow cannot complete id update within window time nodes configured update n th message first incrementeddl message transmission n small number large enough allow slowest node calculate new ids write na n th message transmission protocol incurs network overhead 16 bits every seconds compared 47 bits per epoch simple leaderbased agreement protocol reception first incrementeddl message causes device drivers set dl fields local messages back original values complete next transmission also incremented dl field already started two messages 8 extra data bits worstcase leads 16bit overhead cpu side periodic process incurs overhead moreover network adapters filter disabled device drivers must process two messages may may meant node device drivers must perform filtering software discard messages meant node measurements various cpu overheads section 6 5 implementation section present schemes implement mts motorolas toucan module 19 features message buffers internal arbitration transmission buffers based message id toucan representative modern nas following present brief description toucan problems faced implementing realtime scheduling solution problems mts 51 motorola toucan toucan module developed motorola onchip inclusion various microcontrollers toucan lies chip cpu interconnected cpu onchip modules motorolas intermodule bus motorola currently marketing mc68376 19 microcontroller incorporates toucan cpu32 core toucan 16 message buffers buffer configured either transmit receive messages one buffers valid messages waiting transmission toucan picks buffer highestpriority id contends bus id respect toucan differs older network adapters intel 82527 20 arbitrate buffers using fixedpriority daisychain scheme forces host cpu sort messages according priority placing network adapter buffers one main reason picked toucan implementing mts time toucan available mc68376 microcontroller implement mts within emeralds toucan would first port emeralds mc68376 microcontroller avoid instead used device emulation 21 generalpurpose microcontroller made emulate network adapter emulator interfaces host cpu io bus emulator presents host cpu interface actual network adapter would emulator receives commands host cpu performs corresponding actions produces results actual network adapter would thus providing accurate measurements various overheads interrupt handling message queuing host cpu use 68040 board emulate toucan module connect host cpu another 68040 vme bus 52 mts implementing mts goal minimize average overhead suffered host node transmitting message overhead following components 1 queuingbuffering messages software network adapter buffers unavailable 2 transferring messages network adapter 3 handling interrupts related message transmission priority inversion unbounded adapter buffers contain lowpriority messages messages sent long higherpriority messages anywhere else network con sequently highpriority message stay blocked software indeterminate period time causing miss deadline priority inversion problem network scheduling implementation regardless scheduling policy dm mts implemented ensure adapter buffers always contain highestpriority messages lowerpriority messages queued software suppose b buffers allocated message transmission usually b twothirds total number buffers see section 6 total number outgoing message streams b less mtss implementation straightforward assign one buffer stream whenever device driver receives message transmission simply copies message buffer reserved stream case buffering needed within device driver also means need adapter generate interrupts upon completion message transmission 3 leads lowestpossible host cpu overhead number message streams exceeds b messages buffered software reduce host cpu overhead want buffer fewest possible messages avoiding priority inversion mts treats lowspeed highspeed messages differently scheduling purposes treat messages differently implementation purposes well goal keep overhead frequent messages belonging highspeed periodic streams low possible get low average permessage overhead implementation number periodic highspeed message streams nhp 3 adapter must programmed generate interrupts messages queued software waiting adapter buffers become available case less b reserve nhp buffers highspeed periodic streams treat buffering software remaining buffers used highspeed sporadic lowspeed nonrealtime messages messages arrive device driver transmission inserted priority sorted queue avoid priority inversion device driver must ensure l buffers always contain l messages head queue newlyarrived message priority higher lowestpriority message buffer preempts message overwriting preemption increases cpu overhead necessary avoid priority inversion preempted message stays device driver queue eventually transmitted according priority among l buffers buffer containing 1 th lowest priority message configured trigger interrupt upon message transmission defined later interrupt used refill buffers queued messages must large enough ensure bus become idle interrupt handled buffers refilled usually 1 2 enough keep bus busy 4794 minimum note puts restriction l must greater making l less equal lead bus becoming idle isr executes makes buffers available highspeed periodic messages useful lowspeed messages make small portion workload highspeed sporadic messages either nonexistent nhp b must queue even highspeed periodic messages software single prioritysorted queue outgoing messages b buffers filled queue streams dedicated buffers cpu overhead calculation message id transferring message data id network adapter note message data copied directly user space network adapter keep overhead minimum messages queued software extra overhead inserting message queue including copying 8 fewer bytes message data user space device driver space inserting queue plus overhead handling interrupts generated upon message transmission interrupt overhead incurred every message transmissions q number buffers filled queue q b l depending whether highspeed periodic messages buffered also message potentially preempt one message preempted message already copied network adapter copied preemption overhead equivalent overhead transferring message network adapter table 1 summarizes overheads various types messages measurements overheads section 6 note dm scheduling also incurs similar overheads difference id message streams dm fixed new id calculated time implementing dm toucan different implementing mts message type overhead queued calculate id copy na queued calculate id insert priority queue copy na table 1 summary overheads mtss implementation toucan 6 results schedulability mts compared dm ed evaluated published 1 2 present measurement various mts implementation overheads impact mts schedulability overhead measurements implementation mts 25mhz motorola 68040 cache emeralds rtos table 2 data see highspeed messages dedicated network adapter buffers incur overhead transfer na operation overhead calculate id highspeed messages 30 insert priority queue including copying device driver memory 63 transfer message na 8 data bytes 78 preempt message 78 handling dequeuing transmitted messages 424 miscellaneous parameter passing etc 60 table 2 cpu overheads various operations involved implementing mts highspeed periodic messages queued average permessage overhead depends number buffers used transmission q toucan buffers 56 usually used message reception ids configured receive various message streams needed node leaves 10 buffers message transmission worstcase scenario message transmission incurs average overhead assuming 2 calculation queuing worstcase l q total number message streams using queue lowspeed non realtime messages fixed ids incur overhead 332 lowspeed highspeed messages share queue highspeed messages using dedicated buffers smaller lowspeed messages assuming 3 buffers available 2 lowspeed nonrealtime messages incur overheads 703155l q smsg highspeed sporadic messages overheads 733155l q smsg numbers see certain node 7 highspeed periodic streams 1 highspeed streams lowspeed nonrealtime messages highspeed periodic messages make 90 outgoing traffic highspeed sporadiclowspeednonrealtime messages average permessage overhead comes overhead significantly higher number highspeed periodic streams large enough highspeed messages queued case permessage overhead twice much overhead highspeed periodic streams dedicated buffers fortunately realtime control applications 1015 tasks per node wellknown avionics task workload 22 23 accepted typifying realtime control applications example tasks send internode messages typically send 12 messages per task indicates applications dedicated buffers available highspeed message streams resulting low permessage overhead 2025s range used simple linked list sort messages priority queue works well small number messages 510 typically need queue larger number messages sorted heap give lower overhead note overheads applicable dm well difference dm id calculated permessage overhead 3s less mts id readjustment end epoch table 3 lists cpu overheads incurred id update protocol overhead periodic task includes context switching cpu scheduling overheads one context switch occurs task wakes another task blocks included overhead measurements operation overhead periodic task 680 device driver interrupt message arrival 404 read message na 8 data bytes 78 software filtering dl lookup 30 id update 28 per message table 3 cpu overheads various operations involved updating message ids id update device driver receives two messages incurring overhead 404 including context switching overheads receiving first message ids highspeed messages updated assuming ids 5 messages need updated total overhead per epoch becomes 1844s 2ms id update takes 9 cpu time motivates us increase increasing increases level quantization deadlines results reduced schedulability highspeed messages hand network overhead associated id updates 16 bits per epoch decreases leading increased schedulability bits per epoch consume 08 network bandwidth 1mbs bus impact network schedulability due blocking effect much higher measurements showed extra overhead 23 percentage points fewer workloads feasible mts workload utilization without overhead increasing result sizeable improvement schedulability due reduced id update overhead offset loss schedulability due coarser quantization figure 4 shows effect increasing schedulability data point generate 1000 workloads measure percentage found feasible mts using schedulability conditions 2 workload 815 highspeed periodic streams 2 6 highspeed sporadic streams 25 lowspeed periodic streams 4 lowspeed sporadic streams deadlines highspeed messages set randomly 052ms range lowspeed messages set randomly 2100ms periods periodic messages calculated adding small random value deadline mit sporadic streams set 2s lowspeed highspeed sporadic streams different data points obtained varying number highspeed periodic streams 8 15 leads variation workload utilization roughly 50100 range results include overhead resulting 16 extra bits per epoch id updates figure shows doubled 2ms 4ms network schedulability actually improved slightly two highspeed sporadic streams workload six sporadic streams used loss schedulability coarser quantization gain reduced id update overhead 12 percentage points fewer workloads feasible results show lighttomoderate highspeed sporadic loads increasing 4ms continues give good performance even heavy highspeed sporadic loads 4ms results slight degradation performance increased 3ms id update cpu overhead reduces 6 cpu time whereas becomes 46 cpu time 7 conclusion standard message frame format 11bit id field fixedpriority scheduling dm used bits go unused idea behind mts use extra bits enhance network schedulability mts places quantized form message deadline extra bits using dmpriority messages remaining bits enhances schedulability frequent messages system highspeed messages mts able feasibly schedule workloads dm utilization 2006001000 percent feasible workloads l2ms l4ms l2ms l4ms figure 4 impact changing mts schedulability since message ids based deadlines must periodically updated presented protocol perform update without priority inversion protocol consumes 56 cpu time considering large improvements network schedulability mts displays dm extra overhead justified also presented scheme implement mts toucan network adapter representative modern network adapters biggest challenge implementing scheduling mts dm controlling priority inversion within network adapter showed cans characteristics short message size preemption message adapter newlyarrived higherpriority outgoing message effective method avoiding priority inversion future avenue research study message reception issues try reduce average permessage reception overhead unlike message transmission message reception depend network scheduling policy dm mts used message reception overheads reduced optimizing interrupt handling using polling instead interrupts detect message arrival using combination interrupts polling r nonpreemptive scheduling messages controller area network realtime control applications scheduling messages controller area network realtime cim applications smart networks control ttp protocol faulttolerant realtime systems road vehicles interchange digital information controller area network highspeed communication inside look fundamentals analyzing realtime communications controller area network calculating controller area network message response times realtime communications computercontrolled workcell emeralds microkernel embedded realtime systems complexity fixedpriority scheduling periodic realtime tasks nonpreemptive scheduling periodic sporadic tasks simple integrated heuristic algorithms scheduling tasks time resource constraints scheme realtime channel establishment widearea networks realtime communication multihop networks ability establishing realtime channels pointtopoint packetswitched networks implementing distributed highresolution realtime clock using canbus mc68336376 users manual communications controller architectural overview end emulated network device evaluating adapter design building predictable avionics plarform ada case study generic avionics software specification tr