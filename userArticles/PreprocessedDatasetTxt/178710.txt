using genetic algorithms concept learning article explore use genetic algorithms gas key element design implementation robust concept learning systems describe evaluate gabased system called gabil continually learns refines concept classification rules interaction environment use gas motivated recent studies showing effects various forms bias built different concept learning systems resulting systems perform well certain concept classes generally well matched biases poorly others incorporating ga underlying adaptive search mechanism able construct concept learning system simple unified architecture several important features first system surprisingly robust even minimal bias second system easily extended incorporate traditional forms bias found concept learning systems finally architecture system encourages explicit representation biases result provides important additional feature ability dynamically adjust system bias viability approach illustrated comparing performance gabil four traditional concept learners aq14 c45 id5r iacl variety target concepts conclude observations merits approach possible extensions b introduction important requirement natural artificial organisms ability acquire concept classification rules interactions environment paper explore use adaptive search technique namely genetic algorithms gas central mechanism designing systems motivation approach comes accumulating body evidence suggests although concept learners require fairly strong biases induce classification rules efficiently priori set biases appropriate concept learning tasks exploring design implementation robust concept learning systems capable adaptively shifting biases appropriate find particularly intriguing natural way gabased concept learners provide capability proof concept implemented system called gabil features compared performance four traditional concept learning systems aq14 c45 id5r iacl set target concepts varying complexity present results following manner begin showing concept learning tasks represented solved traditional gas minimal implicit bias illustrate explaining gabil system architecture detail compare performance minimalist gabil system aq14 c45 id5r iacl set target concepts varying complexity expected single system best presented concepts however posteriori one identify biases largely responsible systems superiority certain classes target concepts show gabil easily extended include biases improves system performance various classes concepts however introduction additional biases raises problem apply achieve bias adjustment necessary robust performance finally show gabased system extended dynamically adjust bias natural way support claims empirical studies showing improvement robustness gabil adaptive bias conclude discussion merits approach directions research 2 gas concept learning supervised concept learning involves inducing descriptions ie inductive hypotheses concepts learned set positive negative examples target concepts examples instances represented points ndimensional feature space defined priori legal values features known concepts therefore represented subsets points given ndimensional space concept learning program presented description feature space set correctly classified examples concepts expected generate reasonably accurate description unknown concepts choice concept description language important several respects introduces language bias make classes concepts easy describe class descriptions become awkward difficult approaches involved use classification rules decision trees recently neural net works choice also defines space possible concept descriptions correct concept description must selected using given set positive negative examples constraints case size complexity search space requires fairly strong additional heuristic pruning form biases towards concepts simpler general effects adding biases addition language bias produce systems work well concepts wellmatched biases perform poorly classes concepts needed means improving overall robustness adaptability concept learners order successfully apply situations little known priori concepts learned since genetic algorithms gas shown powerful adaptive search technique large complex spaces contexts motivation work explore usefulness building flexible effective concept learners 1 order apply gas concept learning problem need select internal representation space searched must done carefully preserve properties make gas effective adaptive search procedures see dejong 1987 detailed discussion traditional internal representation gas involves using fixedlength generally binary strings represent points space searched however representations appear wellsuited representing space concept descriptions generally symbolic nature syntactic semantic constraints widely varying length complexity two general approaches one might take resolve issue first involves changing fundamental ga operators crossover mutation work effectively complex nonstring objects alternatively one attempt construct string representation minimizes changes ga approach certain advantages disadvantages developing new ga operators sensitive syntax semantics symbolic concept descriptions appealing quite effective also introduces new set issues relating precise form operators take frequency applied alternative approach using string representation puts burden system designer find mapping complex concept descriptions linear strings property traditional ga operators manipulate strings preserve syntax semantics underlying concept descriptions advantage approach effective mapping defined standard shelf ga used changes paper illustrate latter approach develop system uses traditional ga minimal changes examples approach see rendell 1985 grefenstette 1989 koza 1991 janikow 1991 decision adopt minimalist approach immediate implications choice concept description languages need identify language excellent introductions gas found holland 1975 goldberg 1989 effectively mapped string representations yet retains necessary expressive power represent complex concept descriptions efficiently consequence chosen simple yet general rule language describing concepts details presented following sections 21 representing search space natural way express complex concepts disjunctive set possibly overlapping classification rules ie disjunctive normal form dnf lefthand side rule ie disjunct term consists conjunction one tests involving feature values righthand side rule indicates concept classification assigned examples matched covered lefthand side rule collectively set rules thought representing unknown concept rules correctly classify elements feature space allow arbitrarily complex terms conjunctive lefthand side rules powerful description language difficult represent strings however restricting complexity elements conjunctions able use string representation standard gas negative side effect rules may required express concept achieved restricting element conjunction test form value feature example given value set return true else return false example rule might take following symbolic form sphere cube widget since lefthand sides conjunctive forms internal disjunction eg disjunction within feature f2 loss generality requiring one test feature left hand side rule result modified dnf allows internal disjunction see michalski 1983 discussion internal disjunction restrictions construct fixedlength internal representation classification rules fixedlength rule n feature tests one feature feature test represented fixedlength binary string length depend type feature nominal ordered etc currently gabil uses features nominal values system uses k bits k values nominal feature example set legal values feature f1 small medium large pattern 011 would represent test f1 medium large suppose feature f2 values sphere cube brick tube two classes widgets gadgets rule 2 feature problem would represented internally rule equivalent small medium large widget notice feature test involving 1s matches value feature equivalent dropping conjunctive term ie feature irrelevant rule example values f2 relevant rule succinctly interpreted widget completeness allow patterns 0s match nothing means rule containing pattern match points feature space rules form use final concept description quite useful storage areas gas evolving testing sets rules righthand side rule simply class concept example belongs means rule language defines stimulusresponse system message passing form internal memory found holland 1986 many traditional concept learning contexts single concept learned situations need rules explicit righthand side since class implied clearly string representation chosen handles cases easily assigning bits righthand side rule 211 sets classification rules since concept description consist one classification rules still need specify gas used evolve sets rules currently two basic strategies michigan approach exemplified hollands classifier system hol land 1986 pittsburgh approach exemplified smiths ls1 system smith 1983 systems using michigan approach maintain population individual rules compete space priority population contrast systems using pittsburgh approach maintain population variablelength rule sets compete respect performance domain task still much learned relative merits two approaches paper report results obtained using pittsburgh approach 2 individual population variablelength string representing unordered set fixedlength used pittsburgh approach see wilson 1987 booker 1989 examples michigan approach rules number rules particular individual unrestricted limited userdefined upper bound illustrate representation concretely consider following example rule set 2 rules rule set equivalent widget large widget 212 rule set execution semantics choosing rule set representation use gas also important define simple execution semantics encourage development rule subsets subsequent recombination subsets form new better rule sets one important feature property orderdependency among rules rule set rule set used predict class example lefthand sides rules rule set checked see match cover particular exam ple parallel execution semantics means rules perform locationindependent manner possible example might covered one rule number existing approaches resolving conflicts basis dynamically calculated rule strengths measuring complexity lefthand sides rules various voting schemes also possible rules cover particular example unmatched examples could handled partial matching andor covering operators best handle two situations general context learning multiple concepts classes simultaneously difficult issue yet resolved satisfaction however issues considerably simpler learning single concepts case quite natural view rules rule set union possibly overlap ping covers concept learned hence example matches one rules classified positive example concept example fails match rule classified negative example paper focus simpler case singleconcept learning problems also dominated conceptlearning literature left extension multiconcept problems future work 213 crossover mutation genetic operators modify individuals within population produce new individuals testing evaluation historically crossover mutation important best understood genetic operators crossover takes two individuals produces two new individuals swapping portions genetic material eg bits mutation simply flips random bits within population small probability eg 1 bit per 1000 one goals achieve concept learning representation could exploit fundamental operators feel achieved goal variablelength string representation involving fixedlength rules described previous sections mutation operator identical standard one performs usual bitlevel mutations currently using fairly standard extension traditional 2 point crossover operator order handle variablelength rule sets 3 standard 2 point crossover fixedlength strings two degrees freedom selecting crossover points since crossover points always match parents eg exchanging segments positions 1225 parent however variable length strings four degrees freedom since guarantee picked two crossover points first parent points exist second parent hence second set crossover points must selected standard crossover restrictions crossover points may occur ie rule boundaries within rules requirement corresponding crossover points two parents match semantically one parent cut rule boundary parent must cut rule boundary similarly one parent cut point 5 bits right rule boun dary parent must cut similar spot ie 5 bits right rule boundary example consider following two rule sets use denote crossover cut point note left cut point offset 2 bits rule boundary right cut point offset 1 bit rule boundary bits within cut points swapped resulting rule set 3 rules rule set 1 rule 3 also investigating use uniform crossover operator recently shown effective certain contexts 2point crossover f1 f2 class f1 f2 class f1 f2 class 22 choosing fitness function addition selecting good representation important define good fitness function rewards right kinds individuals keeping minimalist phi losophy selected fitness function involving classification performance ignor ing example length complexity biases fitness individual rule set computed testing rule set current set training examples typically subset examples see section 26 letting fitness individual provides bias toward correctly classifying examples providing nonlinear differential reward imperfect rule sets bias equivalent one encourages consistency completeness rule sets respect training examples rule set consistent covers negative examples complete covers positive examples 23 gabil gabased concept learner position describe gabil gabased concept learner heart system ga searching space rule sets ones perform well given set positive negative examples figure 1 provides pseudocode description ga used insert figure 1 pt represents population rule sets random initialization population rule set evaluated fitness function described section 22 rule sets probabilistically selected survival proportion fitness ie consistent complete crossover mutation applied probabilistically surviving rule sets produce new population cycle continues consistent complete rule set possible found within timespace constraints given traditional concept learners differ ways examples presented many systems presume batch mode instances presented system others work incremental mode one instances presented system time designing gabased concept learner simplest approach involves using batch mode fixed set training examples presented ga must search space variablelength strings described set rules high fitness 100 implies completeness consistency training set however many situations learning neverending process new examples arrive incrementally learner explores environment examples general contain noise carefully chosen outside agent kinds problems interested imply concept learner must evolve concept descriptions incrementally nonoptimal noisy instances simplest way produce incremental ga concept learner follows concept learner initially accepts single example pool examples searches perfect rule set possible example within timespace constraints given rule set used predict classification next example prediction incorrect ga invoked batch mode evolve new rule set using two examples prediction correct example simply stored previous example rule set remains unchanged new additional instance accepted prediction made ga rerun batch mode prediction incorrect refer mode operation batchincremental refer ga batchincremental concept learner gabil although batchincremental mode costly run batch provides much finelygrained measure performance appropriate situations learning never stops rather measure algorithms performance using small training subset instances learning batchincremental mode measures performance algorithm available instances therefore every instance acts testing instance training instance ultimate goal achieve pure incremental system capable responding even complex situations environment changing learning process paper however report performance gabil batchincremental concept learner 3 empirical system comparisons experiments described section designed compare predictive performance gabil four concept learners function incremental increases size complexity target concept 31 domains experiments involve two domains one artificial one natural domain 1 artificial domain designed reveal trends relate system biases incremental increases target concept complexity domain invented 4 feature world feature 4 possible distinct values ie 256 instances world within domain 1 constructed set 12 target concepts varied complexity 12 target concepts increasing number rules disjuncts number relevant features conjuncts per rule required correctly describe concepts number disjuncts ranged 1 4 number conjuncts ranged 1 3 target concept labeled ndmc n number disjuncts number conjuncts see appendix 2 definition target concepts target concepts complete set 256 instances labeled positive negative examples target concept 256 examples randomly shuffled presented sequentially batchincremental mode procedure repeated times trials concept learning algorithm pair domain 2 selected natural domain test conjectures system biases domain 2 wellknown natural database diagnosing breast cancer michalski et al 1986 database descriptions cases 286 patients case instance described terms 9 features small amount noise unknown origin database manifested cases identical features different classifications target concept considerably complex concepts ndmc world example seeing 286 instances aq14 system also known newgem described develops inductive hypothesis disjuncts average 4 conjuncts per disjunct since gabil id5r handle nominals breast cancer instances features form numeric intervals converted breast cancer bc database use nominal features conversion necessarily loses inherent ordering information associated numeric intervals example feature age defined numeric interval values 1019 2029 9099 original database represented set a1 a2 a9 nominals converted database using bc database randomly shuffled instances averaged 10 runs noted problems two test domains singleclass problems discussed earlier evaluating approach multiclass problems part future plans 32 systems performance gabil system described section 23 evaluated domains standard ga settings 06 2pt crossover 0001 mutation used choice population size difficult large complex search spaces larger population sizes preferable generally require computation time unoptimized batchincremental version gabil able use population size 1000 arti ficial domain however bc domain population size 100 used order keep experimental computation time reason able 4 4 unoptimized batchincremental version gabil somewhat slower c45 aq iacl substantially slower id5r one conclude however ga concept learners inherently slower see janikow 1991 details better assess gabil system four concept learners also evaluated target concept domains selected four systems represent four combinations batch incremental modes two popular hypothesis forms dnf decision trees chosen systems aq14 mozetic 1985 based aq algorithm described michalski 1983 c45 quinlan unpublished id5r utgoff 1988 ibas algorithm concept learner iacl gordon 1990 based ibas algorithm described iba 1979 aq14 iacl form modified dnf hypotheses c45 id5r systems based id algorithm described quinlan 1986 form decision tree hypotheses aq14 c45 run batch incremental mode since batch systems id5r iacl incremental aq14 like aq generates classification rules instances using beam search system maintains two sets classification rules concept one set call positive hypothesis learning target concept set call negative hypothesis learning negation target concept note gabil currently uses positive hypothesis aq14 like gabil generates classification rules modified dnf allows internal disjunction feature values internal disjunction allows fewer external disjuncts hypotheses aq14s learning method guarantees inductive hypotheses consistent complete respect training examples learning method called star algorithm generates hypothesis class c potential rules hypothesis formed randomlychosen example called seed maximally generalizing description seed without covering examples wrong class one rule chosen set potential rules using userspecified set criteria rule added hypothesis c procedure repeats generate rules hypothesis examples class c covered hypothesis aq14s criteria hypothesis preferences biases influences learning behavior systems performance depends criteria well parameter set tings particular parameter settings chose aq14 implement preference simpler inductive hypotheses eg inductive hypotheses shorter rules 5 c45 uses decision tree representation rather rule representation inductive hypotheses decision tree node associated instance feature node represents test value feature arcs emanating feature node correspond values feature leaf node associated classification eg positive negative one concept learned view decision tree positive dnf hypothesis one would consider hypothesis disjunction paths conjunction feature values root positive leaf negative hypothesis simply disjunction paths root negative leaf 5 precise criteria used positive negative inductive hypotheses allowed intersect provided intersection covers instances noisy examples considered positive maximum beam width set 20 minimum number features values preferred rule settings less impact system performance left default values information theoretic measure biases search space decision trees trees constructed first selecting root node next level nodes tree nodes features minimize entropy therefore maximize information gain selected first result preference simpler ie shorter decision trees c45 require completeness consistency two configurations c45 available pruned unpruned pruning process simplifying decision trees process occurs decision tree generated consists testing tree previously seen instances replacing subtrees leaves branches whenever replacement improves classification accuracy 6 pruning designed tree simplification increases simplicity preference improved prediction accuracy since obvious us either configuration preferable used versions experiments id5r learns basic algorithm c45 however system learns incrementally incremental learning id5rs biases nearly identical c45 unpruned one minor difference unlike c45 id5r predict class new instance cannot make prediction eg instance covered decision tree modified id5r make random prediction case 7 fourth system compared gabil iacl gordon 1990 system similar aq14 iacl wellknown systems described therefore describe slightly detail iacl maintains two dnf hypotheses one learning target concept one learning negation concept internal disjunction permitted consistency completeness required unlike aq14 though iacl learns incrementally prefers hypotheses specific ie less general rather simpler merging process maintains completeness merging process incorporates new instance already covered hypothesis hypothesis class instance performing small amount gen eralization done forming new hypothesis rules using specific generalization operator every rule hypotheses iacl forms new rule feature values equal specific generalization feature values new instance original rule new rule kept consistent previous instances otherwise original rule kept instead instance cannot merge existing rule hypothesis description added new rule features nominals case experiments specific generalization internal disjunction feature values rule new instance example suppose system receives first instance positive small sphere initial positive hypothesis 6 type pruning c45 variant pessimistic pruning described quinlan 1987 prunes tree either subtree leaf node quinlan personal communication 7 id5r like gabil research tool therefore handle realistic data characteristics eg missing feature values handled sophisticated systems c45 widget second instance medium cube positive positive hypothesis becomes small medium sphere cube widget note new hypothesis matches medium spheres small cubes though seen yet iacls splitting process maintains consistency system incorrectly predicts class new instance system uses previously saved instances relearn hypotheses correctly let us continue example illustrate splitting process suppose system receives new negative example medium sphere current positive hypothesis matches example thereby violating consistency requirement splitting process positive hypothesis becomes widget widget negative hypothesis widget new instances merged rules generalize hypotheses whenever merging preserves consistency respect previous instances 33 performance criteria feel learning curves effective means assessing performance context incremental concept learning experiments reported curve represents average performance 10 independent trials learning single target concept trial keep track small window recent outcomes counting correct predictions within window value curve time step represents percent correct achieved recent window instances window size 10 used arti ficial domain one size 50 bc domain sizes chosen experimentally balance need capturing recent behavior desire smooth short term variations learning curves generating learning curves target concept collapsed information curves two performance criteria first called prediction accuracy pa criterion average values learning curve beginning end learning target concept distilled learning curves single average value simplify presentation results second performance criterion called convergence c number instances seen 95 prediction accuracy maintained 95 prediction accuracy achieved eg bc database c defined finelygrained measure obtainable batchincremental incremental modes facilitates performance criterion well criteria described local sense apply single target concept local criterion corresponding global criterion considers target concepts domain global prediction accuracy criterion average pa criteria values every target concept within domain likewise global convergence criterion average c criteria values target concepts domain since global criteria based far data local criteria base conclusions experiments former 34 results table 1 shows results pa global pa denoted average tables criteria measuring performance systems ndmc bc target concepts table 2 shows results applying c global c denoted average tables criteria measure performance ndmc concepts since system achieves 95 prediction accuracy bc database although differences tables 1 2 general trend similar tables see aq14 best performer overall particular aq14 top close top performer ndmc concepts system however perform well systems bc target concept except iacl results due fact aq14 using chosen parameter settings system well tuned simpler dnf target concepts 8 insert table 1 insert table 2 iacl perform well systems bc target concept consider result iacls sensitivity conversion numeric intervals nominals discussed earlier iacls msg operator wellsuited learning 8 aq14 use flexible partial matching hypotheses instances flexible matching tends improve performance aq systems michalski 1990 newest version aq aqtt15 uses flexible matching unavailable time study future plan run aqtt15 suite target concepts instance features structured nominals ie generalization trees structure values numeric wellsuited learning features nomi nals according gordon 1990 iacl performs well numeric form database 9 experiments reported indicate conversion data nominal form adversely affect performance aq14 c45 pruned abbreviated c45p tables performs well target concepts many short disjuncts 4d1c short disjuncts target concept artificial domain idbased systems c45 pruned unpruned well id5r perform poorly 10 based global performance criteria unpruned abbreviated c45u tables performs best idbased systems artificial domain whereas c45 pruned performs best bc domain gabil appears good overall performer superbly particular concept also distinct region space concepts clearly degrades furthermore gabil quite competitive difficult bc target concept statistical significance results presented appendix 1 clear results none systems evaluation superior others target concepts dominance one technique certain class concepts appears due large part builtin forms bias embodies negative impact classes concepts 4 robust concept learner gabil system evaluated incorporates pure ga search mechanism sense specific changes made internal representation genetic operators relating task concept learning application tasks generally results good overall gabased problem solver one outperformed taskspeci fic approaches particularly simpler problems see exam ple de jong spears 1989 however one nice properties gabased system difficult augment gas taskspecific features improve performance task obtaining performance comparisons described previous section felt extending gabil small set features appropriate concept learning would significantly enhance overall performance robustness approach follows traditional concept learners evaluated appeared contain one biases considered largely responsible systems success particular class target concepts selected subset biases implemented additional genetic operators used gabils ga search procedure see figure 2 virtue approach simple unified way gabils 9 run batch mode numeric bc database 70 instances training set 30 test set 72 predictions made test set correct predictions see gordon 1990 explanation difficulty systems based id3 target concepts type de jong spears 1991 underlying search process extended include various traditional forms concept learning bias insert figure 2 since aq14 seemed best overall performer selected initial source additional operators gabil described aq14 system used experiments preferences simpler general rules studying results initial evaluation hypothesized one biases largely responsible aq14s superior performance ndmc concepts analysis led addition two new gabil operators add biases simpler general descriptions 41 adding alternative operator one mechanisms aq uses increase generality inductive hypotheses adding alternative generalization operator michalski 1983 operator generalizes adding disjunct ie alternative current classification rule useful form operator according michalski 1983 addition internal disjunct example disjunct adding alternative operator might create new disjunct sphere cube operator call aa adding alternative operator easily implemented gabil including additional mutation unlike normal mutation operator asymmetric mutation rate particular studies reported operator incorporates 75 probability mutating bit 1 25 probability mutating 0 therefore aa operator gabil strong preference adding internal disjuncts illustrate adding alternative operator might change disjunct 100 100 note feature f2 generalized disjunct genetic operators adding alternative operator applied probabilistically subset population generation studies reported applied rate 001 1 11 clarity reporting experimental results call version gabil adding alternative operator gabila 42 dropping condition operator second complementary generalization mechanism leading simpler hypotheses involves removing appear nearly irrelevant conditions dis junct operator call dc dropping condition operator based generalization operator name described michalski 1983 exam ple disjunct small medium dc operator might create new disjunct dc operator easily added gabil following manner operator applied particular member population ie particular rule set disjunct deterministically checked possible condition dropping decision drop condition based criterion gordon 1990 involves examining bits feature disjunct half bits feature disjunct 1s remaining 0 bits changed 1s changing feature 1 values operator forces feature become irrelevant within disjunct thereby simulates effect shortened disjunct illustrate suppose operator applied following disjunct dropping condition operator result new disjunct follows note feature f1 irrelevant within disjunct 11 note addition standard mutation operator continues fire probability 001 genetic operators new operator applied probabilistically subset population generation experiments reported rate used make claim rates used either new operators sense optimal studies selected rate seemed reasonable basis informal experiments preference see section 5 things selfadaptive call gabil dc operator gabild taskspeci fic operators added gabil resulting system called gabilad see figure 3 note interesting complementary relationship two operators adding alternatives set stage dropping condition altogether insert figure 3 augmented forms gabil change way overall structure gabased system described earlier compare figures 1 3 difference set genetic operators expanded result traditional crossover mutation operators used normal manner produce new offspring rule sets parents two new operators probabilistically applied offspring producing additional taskspecific changes 43 results study effects adding bias operators gabil gabila gabild gabilad run concept domains used earlier table 3 shows results system performance measured using pa global pa criteria table 4 shows results system performance measured using c global criteria gabil abbreviated g tables insert table 3 insert table 4 according global criteria tables 3 4 gabila perform well gabild gabilad bc target concept combination operators gabilad best interesting note however ndmc domain gabilad perform well gabild results indicate one improve gabils performance certain classes concepts addition appropriate set bias operators hand possible general know beforehand set biases best results also point danger indiscriminately including multiple biases strategy overcoming lack priori knowledge since multiple simultaneous biases fact interfere one another leading degradation performance results confirm similar bias problems exhibited contexts motivated us focus sophisticated way improving gabils overall robustness namely dynamically adjust taskspeci fic biases 5 adaptive ga concept learner although genetic algorithms represent robust adaptive search mechan ism ga implementations involve static settings things population size kind representation operators used operator probabilities number attempts make aspects gas adaptive provide brief overview work next section 51 adaptive gas two approaches building adaptive gas refer withinproblem approach acrossproblem approach withinproblem approach adapts ga dynamically solves one problem contrast across problem approach adapts gas course many problems one good example acrossproblem approach provided grefenstette 1986 paper separate metaga used adapt ga solves suite problems advantage approach resulting system performs robustly suite problems unfortunately approach also time consuming since problem must solved large number times furthermore adaptation coarse sense system necessarily optimal given problem withinproblem adaptation provides finergrained approach since ga adapted one problem solved since problem solved approach require much less time concentrate withinproblem approach since wish adapt ga solves concept learning problem withinproblem approaches divided two categories coupled uncoupled based observation adaptive ga effect searching two spaces original problem space space adaptations underlying ga relationship two search processes important design consideration adaptive gas coupled approach searches handled simultanously single ga search procedure accomplished using underlying population store information relevant adaptive mechanism well standard information regarding original problem space searched approach elegant straightforward since new adaptive mechanism required see schaffer 1987 examples approach unfortunately coupling also means additional search hindered issues hinder search problem space example one possible concern mechanism may work well large population sizes statistical sampling algorithm small populations samples may misleading lead wrong conclusions issue raised later paper uncoupled approach rely upon ga adaptive mechanism rather behavior underlying ga adjusted separate control mechanism see davis 1989 janikow 1991 examples may alleviate problems associated coupling mechanisms appear difficult construct involve complicated bookkeeping although may explore route future work concentrate conceptually simpler coupled approach paper next consider implement coupled withinproblem approach within gabil 52 adaptive gabil recall taskspeci fic operators added gabil dc aa added static way either present present entire experiment present applied via fixed probabilities new individuals simplest coupled way make selection application operators adaptive individual specify operators applied intuition individuals enable correct operators fit survival point view result system capable performing search best set operators biases search best hypotheses parallel see baeck et al 1991 related work approach easily implemented adding individual additional control bits one adaptive operator bit determines whether corresponding operator used individual control bit 0 associated operator permissible fired thus ignoring operator probabil ity control bit 1 associated operator permissible fires according relevant operator probability control bits act added boolean preconditions operators values control bits evolved normal way selection crossover mutation 12 initial test approach gabil modified include two extra control bits one taskspeci fic operators introduced earlier example consider following rule set f1 f2 class f1 f2 class two added control bits indicated letters dropping condition adding alternative respectively rule set dropping condition operator permissible adding alternative operator example dc operator would change rule set 12 dropping condition adding alternative operators alter control bits f1 f2 class f1 f2 class call modified system adaptive gabil begun explore potential effective dynamic bias adjustment get immediate direct comparison earlier results adaptive gabil run ndmc bc target concepts results presented tables 5 6 insert table 5 insert table 6 results global criteria shown bottom tables 5 6 highlight couple important points first ndmc domain adaptive gabil outperforms original gabil gabila gabilad furthermore adaptive gabil performs almost well gabild prediction accuracy criterion better convergence criterion adaptive gabil outperforms gabilad particularly standpoint global c criterion shows danger indiscriminately including multiple fixed biases interfere producing lower performance results demonstrate virtues adaptive gabil selecting appropriate biases bc target concept adaptive gabil performs better gabil gabila worse gabild gabilad suggests adaptive gabils advantage diminished smaller population sizes eg population sizes 100 involved address issue future versions gabil adapt population size well operator selection comparison systems new adaptive gabil much better c45 ndmc domain close bc target concept also adaptive gabil competitive aq14 ndmc domain much better bc target con cept tested statistical significance results see appendix 1 found adaptive gabil outperforms systems results generally significant 90 level furthermore systems outperform adaptive gabil results generally significant ie significance 80 lower two notable exceptions bc database c45 gabilad outperform adaptive gabil 95 level significance believe latter exception due small population size 100 former exception addressed incorporate c45s information theoretic biases gabil bias quite easily implemented genetic operator making features higher entropy values likely 1s since higher entropy values imply less relevance interesting question point whether improved performance adaptive gabil result significant bias adjustment run easily monitored displayed figures 4 5 illustrate frequency dropping condition dc adding alternative aa operators used adaptive gabil two target concepts 3d3c 4d1c since control bits operator randomly initialized roughly half initial population contain positive control bits resulting operators starting rate approximately 05 search progresses towards consistent complete hypothesis however frequencies adaptively modified target concepts dc operator found useful consequently fired higher frequency consistent table 5 indicates gabild outperforms gabila furthermore note difference predictive accuracy gabil gabild two target con cepts difference greater 4d1c target concept indicating greater importance dc operator reflected figures 4 5 dc operator evolves higher firing frequency 4d1c concept comparison 3d3c concept similar comparisons made aa operator insert figures 4 5 considering gabil clearly performing additional task selecting appropriate biases results encouraging process extending refining gabil result experiments described also extending experimental analysis include systems attempt dynamically adjust bias 6 related work bias adjustment adaptive bias context similar dynamic preference bias adjustment concept learning see gordon 1990 related literature vast majority concept learning systems adjust bias focus changing representational bias notable exceptions adjust algorithmic bias include competitive relation learner induce select optimizer combination crliso tcheng et al 1989 climbing bias space climbs provost 1991 peak holder 1990 variable bias management system vbms rendell et al 1987 geneticbased inductive learner gil janikow 1991 classify systems according type bias select adaptive gabil shifts bias dynamically selecting generalization operators set biases considered crliso includes strategy predicting class new instances method criteria hypothesis selection set biases considered climbs includes beam width heuristic search percentage positive examples satisfactory rule must cover maximum percentage negative examples satisfactory rule may cover rule complexity peaks changeable algorithmic biases learning algorithms rote learning empirical learning decision tree explanationbased generalization ebg gil similar gabil since also selects generalization operators however use ga selection uses ga concept learning task also classify systems according whether searches space hypotheses space biases coupled gabil unique along dimension system couples searches advantages disadvantages coupled approach presented section 5 summarize comparisons table 7 insert table 7 vbms system different others mentioned primary task system identify concept learner implements particular set algorithmic biases best suited problem along set problem characteristic dimensions problem characteristic dimensions system considers number training instances number features per instance three concept learners tested suitability along problem characteristic dimensions vbms would ideal companion abovementioned systems system could map suitability biases problems knowledge could passed systems use initialization procedure constraining bias space search 7 discussion future work presented method using genetic algorithms key element designing robust concept learning systems used approach implement system compares favorably concept learning systems variety target con cepts shown addition providing minimally biased yet powerful search strategy gabil architecture allows adding taskspecific biases natural way form additional genetic operators resulting performance improvements certain classes concepts however experiments paper highlight one fixed set biases appropriate target concepts response observations shown approach extended produce concept learner capable dynamically adjusting bias response characteristics particular problem hand results indicate promising approach building concept learners require human loop adapt adjust system requirements particular class concepts current version gabil adaptively selects two forms bias taken single system aq14 future plan extend set biases include additional biases aq14 systems example would like implement gabil information theoretic bias believe primarily responsible c45s successes results presented involved singleclass learning problems important next step extend method multiclass problems also focusing adjusting lower level biases learning systems believe techniques also applied selection higher level mechanisms induction analogy final goal produce robust learner dynamically adapts changing concepts noisy learning conditions frequently encountered realistic environments acknowledgements would like thank machine learning group nrl useful comments gabil j r quinlan c45 zianping zhang ryszard michalski aq14 r survey evolution strategies triggered rule discovery classifier systems automated synthesis constrained generators adapting operator probabilities genetic algorithms using genetic algorithms search program spaces using genetic algorithms solve npcomplete prob lems learning concept classification rules using genetic algorithms genetic algorithms search active bias adjustment incremental computer science department genetic system learning models consumer choice optimization control parameters genetic algorithms ieee transactions systems system learning control strategies genetic algo rithms general utility problem machine learning adaptation natural artificial systems escaping brittleness possibilities generalpurpose learning algorithms applied parallel rulebased systems learning disjunctive concepts examples inductive learning decision rules attributebased examples knowledgeintensive genetic algorithm approach concept formation decision tree induction using genetic programming paradigm theory methodology inductive learning learning flexible concepts fundamental ideas method based twotiered representation newgem program learning examples navigation extended bias space inductive learning thesis proposal induction decision trees documentation users guide c4 genetic plans probabilistic learning system synthesis results robust concept learning using dynamicallyvariable bias adaptive crossover distribution mechanism genetic algorithms flexible learning problem solving heuristics adaptive search building robust learning systems combining induction optimization id5r incremental id3 tr ctr b ravichandran avinash gandhe r e smith xcs robust automatic target recognition proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa j l lvarez j mata j c riquelme mining interesting regions using evolutionary algorithm proceedings 2002 acm symposium applied computing march 1114 2002 madrid spain ral girldez jess aguilarruiz jos c riquelme efficient data structure decision rules discovery proceedings acm symposium applied computing march 0912 2003 melbourne florida leila shila shafti eduardo prez prez constructive induction genetic algorithms learning concepts complex interaction proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa jiyuan yiping phoebe chen concept learning text documents proceedings 2004 ieeewicacm international conference web intelligence p698701 september 2024 2004 jungwon kim peter bentley immune memory gene library evolution dynamic clonal selection algorithm genetic programming evolvable machines v5 n4 p361391 december 2004 rafael ramirez amaury hazan esteban maestre xavier serra genetic rulebased model expressive performance jazz saxophone computer music journal v32 n1 p3850 spring 2008 jaume bacardit natalio krasnogor smart crossover operator multiple parents pittsburgh learning classifier system proceedings 8th annual conference genetic evolutionary computation july 0812 2006 seattle washington usa man leung wong kwong sak leung inducing logic programs genetic algorithms genetic logic programming system ieee expert intelligent systems applications v10 n5 p6876 october 1995 philip g k reiser patricia j riddle scaling inductive logic programming evolutionary wrapper approach applied intelligence v15 n3 p181197 novemberdecember 2001 siddhartha bhattacharyya evolutionary algorithms data mining multiobjective performance modeling direct marketing proceedings sixth acm sigkdd international conference knowledge discovery data mining p465473 august 2023 2000 boston massachusetts united states ignasi belda ivan traus susana gordo teresa tarrag sergio madurga xavier llor ernest giralt peptide data mining virtual design knowledge extraction proceedings 8th annual conference genetic evolutionary computation july 0812 2006 seattle washington usa jos c riquelme jess aguilarruiz carmelo del valle supervised learning means accuracyaware evolutionary algorithms information sciences international journal v156 n34 p173188 15 november ral girldez jess aguilarruiz feature influence evolutionary learning proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa filippo neri relational concept learning cooperative evolution journal experimental algorithmics jea 7 p12 2002 spears diana f gordonspears evolution strategies resource protection problems advances evolutionary computing theory applications springerverlag new york inc new york ny rafael ramirez amaury hazan inducing generative expressive performance model using sequentialcovering genetic algorithm proceedings 9th annual conference genetic evolutionary computation july 0711 2007 london england wrappers feature selection decision tree induction variable ordering bayesian network structure learning information sciences international journal v163 n13 p103122 14 june 2004 yifeng zhang siddhartha bhattacharyya genetic programming classifying largescale data ensemble method information sciences international journal v163 n13 p85101 14 june 2004 redman david clutter highperformance commercial data mining multistrategy machine learning application data mining knowledge discovery v6 n4 p361391 october 2002 krzysztof krawiec genetic programmingbased construction features machine learning knowledge discovery tasks genetic programming evolvable machines v3 n4 p329343 december 2002 shaul markovitch dan rosenstein feature generation using general constructor functions machine learning v49 n1 p5998 october 2002 jaume bacardit michael stout natalio krasnogor jonathan hirst jacek blazewicz coordination number prediction using learning classifier systems performance interpretability proceedings 8th annual conference genetic evolutionary computation july 0812 2006 seattle washington usa david quintana cristbal luque pedro isasi evolutionary rulebased system ipo underpricing prediction proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa inductive bias supervised learning using evolutionary computation wrapperbased approach data mining opportunities challenges idea group publishing hershey pa jaume bacardit analysis initialization stage pittsburgh approach learning classifier system proceedings 2005 conference genetic evolutionary computation june 2529 2005 washington dc usa alex alves freitas evolutionary computation handbook data mining knowledge discovery oxford university press inc new york ny 2002 alex freitas survey evolutionary algorithms data mining knowledge discovery advances evolutionary computing theory applications springerverlag new york inc new york ny b ravichandran avinash gandhe robert smith raman mehra robust automatic target recognition using learning classifier systems information fusion v8 n3 p252265 july 2007 alayn j estvez j sigut j l snchez p toledo evolutionary michigan recurrent fuzzy system nuclei classification cytological images using nuclear chromatin distribution journal biomedical informatics v39 n6 p573588 december 2006 ryszard michalski learnable evolution model evolutionary processes guided machine learning machine learning v38 n12 p940 janslashfeb 2000 filippo neri lorenza saitta exploring power genetic search learning symbolic classifiers ieee transactions pattern analysis machine intelligence v18 n11 p11351141 november 1996 krzysztof j cios lukasz kurgan clip4 hybrid inductive machine learning algorithm generates inequality rules information sciences international journal v163 n13 p3783 14 june 2004 giordana f neri l saitta botta integrating multiple learning strategies first order logics machine learning v27 n3 p209240 june 1997 michelle galea qiang shen john levine evolutionary approaches fuzzy modelling classification knowledge engineering review v19 n1 p2759 march 2004 b park h kargupta e johnson e sanseverino hershberger l silvestre distributed collaborative data analysis heterogeneous sites using scalable evolutionary technique applied intelligence v16 n1 p1942 januaryfebruary 2002