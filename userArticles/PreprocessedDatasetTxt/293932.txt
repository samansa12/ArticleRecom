rational filters passive depth defocus fundamental problem depth defocus measurement relative defocus images performance previously proposed focus operators inevitably sensitive frequency spectra local scene textures result focus operators laplacian gaussian result poor depth estimates alternative use large filter banks densely sample frequency space though approach result better depth accuracy sacrifices computational efficiency depth defocus offers stereo structure motion propose class broadband operators used together provide invariance scene texture produce accurate dense depth maps since operators broadband small number sufficient depth estimation scenes complex textural properties addition depth confidence measure derived computed outputs operators confidence measure permits refinement computed depth maps experiments conducted synthetic real scenes evaluate performance proposed operators depth detection gain error less irrespective texture frequency depth accuracy found 0512 distance object imaging optics b introduction pertinent problem computational vision recovery threedimensional scene structure twodimensional images problems studied vision far attracted attention resulted variety sensors algorithms jarvis1983 besl1988 broadly classified two categories active passive active techniques produce relatively reliable depth maps applied many industrial applications however environment cannot controlled case distant objects outdoor scenes active methods prove impractical consequence passive techniques always desirable passive sensing methods stereo structure motion rely algorithms establish local correspondences two images resulting disparity estimates motion vectors depths points scene computed process determining correspondence widely acknowledged computationally expensive addition techniques suffer occlusion missing part problems possible compute depths scene points visible one images alternative passive techniques based focus anal ysis depth focus uses sequence images taken changing focus setting imaging optics small steps pixel focus setting maximizes image contrast determined turn used compute depth corresponding scene point horn1968 jarvis1983 krotkov1987 darrell wohn1988 nayar nakagawa1994 contrast depth defocus uses two images different optical settings pentland1987 subbarao1988 ens lawrence1991 bove jr1993 subbarao surya1994 nayar et al1995 xiong shafer1995 relative defocus two images principle used determine threedimensional structure focus level two images varied changing focus setting lens moving image sensor respect lens changing aperture size depth defocus confronted abovementioned missing part correspondence problems makes attractive prospect structure estimation despite merits point time fast accurate dense depth defocus demonstrated using active illumination constrains dominant frequencies scene texture nayar et al1995 watanabe et al1995 past investigations passive depth defocus indicate prove computationally expensive obtain reliable depth map frequency characteristics scene textures large extent unpredictable furthermore texture vary dramatically image since response defocus blur function varies texture frequency single broadband filter produces aggregate estimate defocus unknown texture cannot lead accurate depth estimates obvious solution use enormous bank narrowband filters compute depth leastsquares sense using dominant frequencies texture xiong shafer1995 gokstorp1994 requires one forego computational efficiency worsen mat ters depth map high spatial resolution obtained filters bank small kernel sizes uncertainty relation bracewell1965 tells us frequency resolution filter bank reduces proportional inverse kernel size used short one cannot design filter narrow enough response support area filter kernel small xiong shafer xiong shafer1995 proposed attractive way cope problem used moment filters compensate frequency spectrum texture within passband narrowband filters approach results accurate depth estimates requires use four additional filters tuned filters filter bank translates five times many convolutions needed typical filter bank method xiong shafer xiong shafer1995 use convolutions total makes approach computationally expensive ens lawrence ens lawrence1991 proposed method based spatialdomain analysis two blurred images estimate convolution matrix convolved one two images produce image matrix corresponds relative blur two images matrix computed mapped depth estimates method produces accurate depth maps ever iterative nature convolution matrix estimation makes computationally expensive subbarao surya subbarao surya1994 proposed stransform applied depth defocus modeled image thirdorder polynomial spatial domain arrived simple elegant expression subbarao surya 1994 far near focused images respectively blur circle diameters images 1 2 expressed second central moments oe 2 2 oe 1 respectively since additional relation oe 2 oe 1 obtained focus settings used two images oe 2 oe 1 solved mapped depth estimate see terms depend scene frequency equation 1 considered sort texturefrequency invariant depth defocus method produces reasonable depth estimates large planar surfaces scene however yield depth maps high spatial resolution needed depth variations scene significant argue requires detailed analysis image formation well design novel filters based frequency analysis paper propose small set filters operators passive depth defocus operators used conjunction yield invariance texture frequency computing depth underlying idea precisely model relative image blur frequency domain express model rational function two linear combinations basis functions rational expression leads us texture invariant set operators outputs operators used coefficients depth recovery equation solved get depth estimate attractive feature approach uses small number broadband linear operators small kernel supports consequently depth maps computed high efficiency accuracy also high spatial resolution since operators derived using rational expression model relative image blur referred rational operators rational operators general derived blur model paper structured follows first concept texture invariant operator set described next operations needed depth defocus discussed including use prefiltering coefficient smoothing efficient algorithm obtaining confidence measure operator outputs outlined confidence measures effectively used refinement computed depth maps specific implementation rational operators used three basis functions model relative blurring function resulted set three rational operators kernel sizes 7theta7 operator set used compute depth maps synthetic scenes real scenes experimental results analyzed quantify performance proposed depth defocus approach depth defocus 21 principle fundamental depth defocus relationship focused defocused imagesborn wolf1965 figure 1 shows basic image formation geometry light rays radiated object point p pass aperture refracted lens converge point q image plane relationship object distance focal length lens f image distance given lens lawd f point object plane projected onto single point image plane causing clear focused image f formed however sensor plane coincide image plane displaced energy received p lens distributed patch sensor plane result blurred image clear single image include sufficient information depth estimation two different scenes defocused different degrees could produce identical images solution depth estimation problem achieved using two images separated known physical distance 2e ens lawrence1991 subbarao surya1994 distance fl image 1 lens also known given described setting problem reduced analyzing relative blurring scene point two images computing position focused image restriction images scene points must lie far focused sensor plane 1 nearfocused sensor plane 2 ease description introduce normalized depth ff equals gamma1 1 1 2 using ffe lens law 2 obtain depth scene point r f figure 1 image formation depth defocus two images 1 2 include information required recover scene structure focused planes scene corresponding two images 22 defocus function precise modeling defocus function critical accurate depth estimation defocus function described detail previous works born wolf1965 horn 1986 figure ffe distance focused image scene point defocused image formed sensor plane light energy radiated scene point collected imaging optics uniformly distributed sensor plane circular patch radius 1 sigma ffe ad 1 distribution also called pillbox defocus function used image used image 2 pir rectangular function takes value 1 jrj 1and 0 otherwise f e effective fnumber optics optical system shown figure 1 f e equals 2a order eliminate magnification differences near far focused images used telecentric optics described appendix 711 detailed watanabe nayar1995b telecentric case f e equals f2a 0 fourier domain defocus function 3 j 1 firstorder bessel function first kind u v denote spatial frequency parameters x directions respectively 2 evident expression defocus serves lowpass filter bandwidth filter decreases radius blur circle increases ie plane focus gets farther sensor plane figure 2 illustrates effect figure 2a shows image f x formed focused plane fourier spectrum f u v sensor plane displaced distance 1 gamma ffe defocused image 2 convolution focused image pillbox h 2 x shown figure 2b effect defocus spatial geometric model valid far image exactly focused case wave optics model needed describe point spread function assumed lens induced aberrations small compared radius blur circle born wolf1965 2 past investigators used gaussian model instead pillbox model blur function mainly facilitate mathematical manipulations fourier transform gaussian function also gaussian converted quadratic function using logarithm see approach depth defocus form blur function used frequency domains written 2 u since ff vary point point image strictly speaking spacevariant system cannot expressed convolution therefore equation 5 hold rigorous sense however assume ff constant small patch around pixel equation 5 remains valid within small patch hereon use terms fourier transform spectrum assumed small image patch assumption ff variation patch small valid patch must small practice realize requirement one forced use broadband filters kernel size linear filter inversely proportional bandwidth filter figure 2c similar b except sensor lies distance 1 focused plane produce defocused image 1 1 u note spectrum plots used polar coordinates f r f spatial frequencies rather cartesian coordinates u v defocus function usually rotationally symmetric symmetry allows us express defocus spectrum using single parameter namely radial frequency f see figure 2 since image c defocused one b lowpass response h 1 u v greater h 2 u v 23 depth two images introduce normalized ratio p u equivalently spatial domain spectrum f u v focused image appears equations 5 6 gets cancelled normalized ratio simply 1 e 2fe x 122fe 1 ae 4fe p 1 e 1 e 2fe x 4fe p 1 e ft ft ft 122fe 1 ae b c2 figure 2 effect blurring near far focused images focused image f fourier spectrum b pillbox defocus model h 2 fourier spectrum 2 blurred image c pillbox defocus model h 1 fourier spectrum 1 image larger blurring f radial frequency figure 3 shows relationship normalized image ratio mp normalized depth ff several spatial frequencies seen mp monotonic function ff large rule thumb frequency range equals width main lobe defocus function h maximally defocused ie distance focused image f sensor plane 2e zerocrossing defocus function figure 2 highest frequency normalized image ratio mp monotonic found given frequency within bound since mp monotonic function ff mp unambiguously mapped depth estimate fi shown figure 3 figure 3 relation normalized image ratio mp defocus parameter ff upper frequency bound determined mp monotonic function defocus parameter ff given frequency within bound mp unambiguously mapped depth estimate fi besides serving critical role development figure 3 also gives us new way viewing previous approaches depth defocus one method determine amplitudes 1 2 spectra two defocused images predefined radial frequency f 2 unique depth estimate obtained basic idea previous work based pentland1987 gokstorp1994 xiong shafer1995 although ratio used past simply 1 2 rather normalized ratio mp introduced magnitudes two image spectra predefined frequency determined using linear operators convolution however trivial problem image texture unknown include unpredictable dominant frequencies hence possible fix priori frequency interest problem may resolved using large bank narrowband filters densely samples frequency space estimate powers large number individual frequencies however important tradeoffs emerge implementing narrowband linear operators gokstorp1994 xiong shafer1995 first approach clearly inefficient computational perspective furthermore uncertainty relation bracewell1965 tells us apply frequency analysis small image area frequency resolution reduces proportional inverse area used obtain dense depth map one must estimate h 1 h 2 using small area around pixel narrow filter spatial domain corresponds broadband filter frequency domain result operator output inevitably average local image spectrum band frequencies since response defocus function h depends local depth ff uniform within passband operator output operator best approximate focus measure result large errors depth given linear operators however carefully designed end pass band would desirable set broadband operators together provide focus measures invariant texture operators broadband small number could cover entire frequency space avoid use extensive filter bank result would efficient robust highresolution depth estimation next section describe method accomplish 3 rational operator set 31 modeling relative defocus using rational expression established monotonic response normalized image ratio mp normalized depth defocus ff frequencies see equation 7 figure 3 objective model relation closed form would like model precise yet lead us small number linear operators depth recovery end model function mp rational expression two linear combinations basis functions basis functions g p u v coefficients functions frequency u v u v ff residual error fit model function mp model accurate residual error negligible becomes possible use model map normalized image ratio mp normalized depth ff expression rewritten ff left hand side represents actual depth scene point fi right estimated depth difference two arise residual error nonzero normalized ratio left side given us frequency u v obtain depth estimate fi solving equation 10 model normalized image ratio general principle basis captures monotonicity structure normalized ratio used specific discussion use basis chosen implementation since response mp ff oddsymmetric almost linear small radial frequencies f r see figure 3 could model response using three basis functions powers fi equation 10 becomes 3 term including fi 3 seen small correction compensates discrepancy mp linear model previous section know blurring model completely determines mp given depth ff frequency u v 3 found replacing b p2 ff tanh aff gives us slightly better fit defocus model pillbox function yet reduce computational cost solving equation 10 depth fi chosen simple polynomial model polynomial model rfi u v therefore fit theoretical mp equation 7 assuming fi ff gives us unknown ratios g p1 gm1 g p2 gm1 functions frequency u v case rotationally symmetric blurring model pillbox function ratios reduce functions radial frequency f r fix one coefficient functions say g p1 u v coefficients determined ratios 4 therefore possible determine coefficient functions ensure polynomial model accurately fits normalized image ratio mp given equation 7 figure 4 shows example set based arbitrary selection g p1 u v coefficient functions g p1 g p2 gm1 case pillbox blur model general form rational expression equation 9 coefficients rational expression determined multiplicative constant frequency therefore u v unknown scaling function coefficient functions g p u v gm u v represent structures ratios obtained fitting rfi u v ff frequency response unknown scaling function u v needed determine coefficient functions without ambiguity accomplished general rational expression described section 41 examine well polynomial model fits plots figure 3 normalized ratio precisely interested knowing well model used estimate depth end frequency select true depth value ff find corresponding ratio mp using analytical expression 7 ratio plugged polynomial model 12 calculate depth estimate fi using newtonraphson method process repeated frequencies let us rewrite equation 12 thirdorder term considered small correction following initial practice gp1 u v cannot selected arbitrarily restrictions need considered exact selection procedure discussed later section 41 gp1fr fq gp2fr fq gm1fr fq figure 4 example set coefficient functions obtained fitting polynomial model normalized image ratio mp g p1 u v chosen remaining two functions determined fit invariance fr figure 5 depth fi estimated using polynomial model equation 12 plotted function spatial frequency different values actual depth ff see estimated depth equals actual depth invariant frequencies within upper bound f r max given equation 17 value provided newtonraphson method solution one iteration figure 5 shows estimated depth fi practical purposes equal actual depth indicating polynomial model indeed accurate estimated depth invariant insensitive texture frequency far radial frequency f r f r max frequency limit f r max response ff shown figure 3 becomes nonmonotonic within region accurate depth estimate obtainable practice image convolved using passband filter ensure frequencies f r max removed rule thumb used determine f r max given equation 8 however pillbox blur model found via numerical simulation f r max fact 12 times larger 5 limit given equation 8 e valuable sideeffect introducing normalized image ratio mp utilize 20 frequency spectrum information conventional methods use ratio 1 2 32 rational operator set introduced rational expression model normalized ratio mp shown solution equation 10 gives us robust depth estimates frequencies within permissible range thus far robustness demonstrated individual frequencies section show rational model used design small set broadband operators handle arbitrary textures 5 number increased 12 13 larger number newtonraphson iterations used however depth results additional range numerically stable presence noise since response curves mp tend flatten hence use one iteration taking crossproducts equation 10 get integrating entire frequency space get invoke power theorem bracewell1965 f u v gu v fourier transforms functions fx gx respectively since conducting spatialfrequency analysis analyzing frequency content small area centered around pixel right hand side equation 20 nothing convolution implies cm ff c p ff actually functions x determined convolutions inverse fourier transforms gm u v short coefficients needed compute depth using polynomial equation 19 determined convolving difference image mx summed image px linear operators spatial domain equivalents coefficient functions refer rational operators outputs operators pixel x plugged equation 19 determine depth fix example use model equation 12 depth recovery equation becomes substituting equation 22 rational operators nothing inverse fourier transforms coefficient functions shown figure 4 see though operators broadband see figure 4 recovery equation independent scene texture provides efficient means computing precise depth estimates 4 implementation rational operators previous section described theory underlying rational operators section discuss various design implementation issues must addressed ensure rational operators produce accurate depth defocus particular describe design procedure used optimize rational operator kernels estimation depth confidence measure prefiltering images prior application rational operators postprocessing outputs operators since rational expression model equation 9 general focus simpler model equation 12 used experiments however procedures described applied forms rational model 41 design rational operators kernels since rational operators broadband linear filters implement small convolution kernels beneficial two reasons low computational cost b high spatial resolution however shall see design problem trivial note deriving operators functions g equation must ratio equals one obtained fitting polynomial model normalized image ratio discrepancy ratio would naturally cause depth estimation errors fortunately base form function u v equation 13 remains discretion adjusted minimize discrepancies imply u v selected arbitrarily rather given convenient initial form optimized clearly effect discrepancies ratio would vary frequency hence depend textural properties scene design operator kernels therefore done minimizing objective function represents ratio errors frequencies relation depth estimation error ratio error derived appendix 72 argue appendix depth error kept minimum ratio errors must satisfy following oe gm1 u oe g p2 u oe gm1 u v oe g p2 u v determine weighting functions used minimization errors gm1 u v g p2 u v constant derivation expressions set u v equal g p1 u v ie g p1 u therefore equation 13 u g p2 u position formulate objective function operator design follows oe gm1 oe gm1 p2 u v actual ratios designed discrete kernels gm1 u v g p2 u v ratios obtained previous section fitting polynomial model normalized image ratio oe gm1 constant used ensure minimization 2 produce trivial result zerovalued operators m1 0 0 actural dc response designed discrete kernel g m1 gm1 0 initial value summation discrete frequency samples sufficiently dense kernel size n theta n frequency samples least 2n theta 2n order avoid gibbs phenomenon oppenheim schafer1989 optimization use 32 theta 32 sample points 7 theta 7 kernels since 2 nonlinear minimization done using levenbergmarquardt algorithm press et al1992 still need define p u v ff equation 25 dependent unknown texture image however since p u v ff used fix weighting functions equation 25 rough approximation suffices end assume distribution image spectrum optimization used corresponds brownian motion 6 though p u v ff changes ff use approximation p u v 6 denote fractal dimension peitgen saupe1988 h two dimensional case last issue concerns base form function u equation 25 initial selection made function refined optimization 2 gm1 u must 0 order realize gm1 u using finite kernel also g p1 u v must smooth without rapid fluctuations obtain rational operators small kernels implementation imposed rotational symmetry added constraint used laplacian gaussian initialize g p1 u v g p1 f r f peak f peak f peak radial frequency g p1 maximum frequency set 04f nyquist optimization function used initialization refined optimization 2 example set discrete rational operators obtained optimization 2 presented shortly 42 prefiltering discuss prefiltering needs applied input images 1 x purpose remove dc component high frequencies applying rational filters dc component harmful small change illumination two images cause unanticipated bias image mx bias would propagate errors coefficient image cm1 x since gm1 operator applied mx essentially lowpass filter turn would cause depth errors end spectrum radial frequencies greater f r max see equation 17 also harmful violate monotonicity property mp needed rational operators work therefore high frequencies must also removed although possible embed desired prefilter within rational filters given prefiltering done using linear operators chosen use separate prefilter following reason since prefilter attempts cut low high frequencies tends large kernel embedding prefilter rational operators would require operators also large kernels thus resulting low spatial resolution well unnecessary additional computations holds true corresponds case extreme fractal 15 corresponds brownian motion corresponds smooth image finally corresponds white noise completely random image 7 equation 12 mp zero ju vj 0 since ff nonzero 1gm1 u must zero equation 12 valid rational operators design prefilter posed optimization objective function let us define desirable frequency response prefilter fu v reasons stated earlier frequency response must cut dc component high frequencies addition frequency response smooth rotationally symmetric ensure small kernel size function desired properties laplacian gaussian given right hand side equation 28 using f define objective function oe pass oe stop frequency response designed prefilter kernel oe pass oe stop represent weights assigned passband stopband regions prefilter respectively stopband levenbergmarquardt algorithm press et al1992 used determine prefilter kernel 43 example set discrete rational filters figures 6 7 show kernels frequency responses rational operators prefilter derived kernel size set 7theta7 ef pixels order make operators uniformly sensitive textures directions imposed constraint kernels must symmetric respect x axes well lines constraints reduce number degrees freedom dof kernel design problem case 7theta7 kernel dof reduced 10 reduces 6 6theta6 5theta5 kernel dof 6 small design operators desired frequency responses therefore smallest kernel size chosen k 7 note passband response prefilter figure 7 refined kernel size increased final design issue pertains maximum frequency f r max since discrete fourier transform kernel size k minimum discrete frequency period 1k difficult obtain precisely response frequency region 1k spectrum region going suppressed prefilter close dc component therefore maximum frequency f r max must well 1k express condition f r ks using equation 17 obtain 2e condition interpreted follows maximum blur circle diameter 2ef e must smaller 73 kernel size k also intuitively reasonable kernel larger blur circle seeks measure blur 8 44 coefficient image smoothing applying prefilter rational operators figure 6 images mx px obtain coefficients plugged equation 23 compute depth fi however problem arise solving depth c p1 x equation 24 close zero depth estimate becomes unstable evident solution step equation 15 since frequency response g p1 x cuts dc component figure 5 zerocrossings usually common coefficient image c p1 x ff also obvious image areas weak texture 9 c p1 x approaches zero solve problem apply smoothing operator coefficient image enables us avoid unstable depth estimates zerocrossings coefficient image otherwise must removed ad hoc postfiltering optimize smoothing operation minimize depth errors need analytic model depth error using depth recovery equation 23 get dropped parameter x brevity solving dfi get c p2 small correction factor following approximation made c p1 denote standard deviations errors cm1 c p1 c p2 oe cm1 oe cm1 oe cm1 respectively simplify matters assumed errors independent get hoel1971 oe fi 8 since conditions related kernel size rough suggest linearity depth estimation checked using synthetic images find best kernel size k evaluation reported experimental section 9 weak texture equivalent low spectrum power high frequency region gamma000133 00453 01799 0297 01799 00453 gamma000133 00453 04009 08685 1093 08685 04009 00453 01799 08685 2957 4077 2957 08685 01799 0297 1093 4077 6005 4077 1093 0297 01799 08685 2957 4077 2957 08685 01799 00453 04009 08685 1093 08685 04009 00453 gamma000133 00453 01799 0297 01799 00453 gamma000133c c c c c c c c c c c c gamma003983 gamma009189 gamma0198 gamma0259 gamma0198 gamma009189 gamma003983 gamma009189 gamma03276 gamma04702 gamma04256 gamma04702 gamma03276 gamma009189 gamma0259 gamma04256 1393 3385 1393 gamma04256 gamma0259 gamma009189 gamma03276 gamma04702 gamma04256 gamma04702 gamma03276 gamma009189 005685 gamma002031 gamma006835 gamma006135 gamma006835 gamma002031 005685 gamma002031 gamma006831 005922 01454 005922 gamma006831 gamma002031 gamma006835 005922 01762 gamma001998 01762 005922 gamma006835 gamma006135 01454 gamma001998 gamma0698 gamma001998 01454 gamma006135 gamma006835 005922 01762 gamma001998 01762 005922 gamma006835 gamma002031 gamma006831 005922 01454 005922 gamma006831 gamma002031 005685 gamma002031 gamma006835 gamma006135 gamma006835 gamma002031 005685c c c c c c c c c c c c pref ilter gamma0143 gamma01986 gamma01056 gamma007133 gamma01056 gamma01986 gamma0143 gamma01986 gamma01927 001795 007296 001795 gamma01927 gamma01986 gamma01056 001795 02843 04601 02843 001795 gamma01056 gamma007133 007296 04601 06449 04601 007296 gamma007133 gamma01056 001795 02843 04601 02843 001795 gamma01056 gamma01986 gamma01927 001795 007296 001795 gamma01927 gamma01986 gamma0143 gamma01986 gamma01056 gamma007133 gamma01056 gamma01986 gamma0143c c c c c c c c c c c c figure rational operator kernels derived using kernel size 7theta7 ef pixels regardless scene texture passive depth defocus accomplished using small operator set u001003a g m1 b g p1 u00050015c g p2 prefilter figure 7 frequency responses rational operators shown figure 6 expression useful gives us estimate depth error inverse estimate 1oe fi 2 viewed depth confidence measure used combine adjacent depth estimates maximum likelihood sense obtain accurate depth estimates also one wishes apply depth defocus different scales using pyramid framework jolion rosenfeld1994 burt adelson1983 darrell wohn1988 gokstorp1994 confidence measure used combine depth values different levels pyramid equation 34 oe c m1 oe c p1 oe c p2 constants defined readout noise image sensor used frequency responses rational operators hand fi assumed locally constant since depth expected vary smoothly points image facts lead us error model place develop method coefficient image smoothing multiply equation 23 c p1 x ff sum depth values neighborhood r pixel get c p1 x c p1 x fi depth estimate coefficient smoothing since last terms equations 36 23 small corrections fi approximated fi c p1 c p1 x c p1 c p1 equation 35 see fi weighted average raw depth estimates fi neighborhood r weights 1oe fi 2 x statistics hoel1971 know optimal weighted average independent variables whose variances oe 2 obtained weighting x 1oe 2 therefore weighted average depth estimates viewed optimal variance oe 2 resulting depth estimate fi given byoe 2 hence coefficient smoothing equation 36 optimal minimizes 10 error estimated depth fi addition resulting smoothed coefficient c p1 x proportional inverse variance fi ie 1oe fi 2 clear equations 35 37 38 therefore smoothed coefficient c p1 x ff used confidence measure postprocess computed depth maps another method cope zerocrossings cp1 coefficient image based hilbert approach detailed watanabe nayar1995a prefilter prefilter far focused image near focused image rational operator coefficient smoothing depth computation figure 8 flow depth defocus algorithm using datacubes mv200 pipeline processor entire algorithm executed little 016 msec obtain 512theta480 depth map 45 algorithm figure 8 illustrates flow depth defocus algorithm implemented far near focused images first added subtracted produce px mx respectively convolved prefilter subsequently three rational operators resulting coefficient images smoothed local averaging final step computation depth coefficients using single iteration newtonraphson method using equations 15 16 alternatively depth computation achieved using precomputed twodimensional lookup table lookup table configured take c 0 inputs provides depth fix output summary depth map generated 5 twodimensional convolutions simple smoothing coefficient images straightforward depth computation step operations executed efficiently using pipelined image processor one uses datacubes mv200 pipeline processor computations realized using 10 pipelines entire depth defocus algorithm executed 016 msec image size 512theta480 efficiency algorithm comes use rational operator set far superior existing depth defocus algorithm attempts compute accurate depth estimates xiong shafer1993 gokstorp1994 5 experiments 51 experiments synthetic images first illustrate linearity depth estimation invariance texture frequency using synthetic images synthetic images shown figure 9 correspond planar surface inclined away sensor normalized depth value 0 top 255 bottom plane includes 10 vertical strips different textural properties left 7 strips textures narrow power spectra whose central frequencies 0015 003 008 013 018 025 035 left right th strip white noise next two strips fractals dimensions 3 25 respectively peitgen saupe1988 near far focused images generated using pillbox blur model defocus condition used ef pixels experiments digital images used size 640theta480 depth map estimated using 7theta7 rational operators 5theta5 coefficient smoothing shown gray coded image figure 9c wireframe figure 9d evident proposed algorithm produces high accuracy despite significant texture variations vertical strips figure summarizes quantitative results obtained experiment figure includes plots gradient estimated depth map b rms root mean square error oe computed depth c averaged confidence value point square plots corresponds one strips image numbered left right see numbers next squares note gradient estimated depth map nothing depth detection gain figure 10a shows gain invariant except left three strips slight gain error left three strips ratio gm1 u vg p1 u v high low frequencies result farfocused image b nearfocused image c graycoded depth map wireframe depth map figure 9 depth defocus applied synthetic images inclined plane accurately recovered despite significant texture variations g p1 u v small low frequency region small error g p1 u v causes large error ratio low values g p1 u v lowfrequency textures reflected extremely low confidence values corresponding strips however low frequencies cut prefilter depth errors suppressed exist frequency components one wants utilize low frequencies pyramid jolion rosenfeld1994 darrell wohn1988 constructed rational filters applied level pyramid depth maps computed different levels pyramid combined maximumlikelihood sense using confidence measures easily computed along coefficient image using equation 34 figure 10b c show rough agreement confidence measure plot function 1oe 2 02center freq101103105gain 1f 1f 1f a02center freq c 1f 1f 1f b0408confidence 1f 1f 1f 15freq distribution confidence4080120246 figure 10 analysis depth errors textured inclined plane shown figure 9 point square plots corresponds single texture strip inclined plane numbered 110 gradient computed depth map corresponds depth detection gain invariance depth estimation image texture evident b rms error oe computed depth c depth confidence value seen rough agreement 1oe 2 figure 11 synthetic images generated assuming staircase like threedimensional structure steps staircase textures used figure 9 computed depth map accurate depth discontinuities sensed sharpness preserved demonstrating high spatial resolution proposed algorithm spikes two left strips due extremely low depth confidence values areas case natural textures enough texture contrast low confidence values unlikely frequencies texture provide sufficient information robust depth estimation graycoded depth map wire frame plot depth map figure 11 depth defocus applied synthetic images staircase textures stairs strips figure 9 depth discontinuities estimated high accuracy reflecting high spatial resolution produced proposed algorithm 52 experiments real images images real scenes taken using sony xc77 monochrome camera lens used cosmicar b1214d2 f25mm lens converted telecentric lens using additional aperture make magnification invariant defocus see appendix watanabe nayar1995b result telecentricity image shifts far near focused images lower 110 pixel lens aperture set f83 farfocused image 1 taken lens focused 869mm camera nearfocused image 2 lens focused 529mm two distances chosen scene points lie focus settings result maximum blur circle radius ef pixels two focus settings 256 images averaged 85 sec get images high signaltonoise ratio figure 12 shows results obtained scene includes variety textures figure 12a b farfocused nearfocused images respectively figure 12c computed depth map wireframe plot depth maps curved planar surfaces detected high fidelity high resolution without postfiltering 9theta9 median filtering get even better depth map shown figure 12e farfocused image b nearfocused image c graycoded depth map without postfiltering wireframe plot c wireframe plot 9theta9 median filtering figure 12 depth defocus algorithm applied real scene complex textures figure 13 shows results scene includes areas extremely weak textures white background clay cup figure 13a b farfocused nearfocused images respectively figure 13c computed depth map wireframe plot image areas except white background area produce accurate depth estimates depth confidence value oe textured background 05 object distance 11 error table surface 10 relative object distance even white background area reasonable depth map despite fact texture weak see confidence map figure 13e reflects lack texture motivated us develop modified algorithm called adaptive coefficient smoothing repeatedly averages coefficients computed rational operators confidence value reaches certain acceptable level figure 13f shows depth map computed using algorithm last experiment seeks quantify accuracy depth estimation target used plane paper similar textured background scene figure 12 plane moved steps 25mm depth map plane computed position since estimated depth fi measured image side mapped object side using lens law equation 2 optical settings processing conditions used previous experiments plot figure 14 illustrates algorithm excellent depth estimation linearity rms error line fit measured depths 42 mm slight curvature plot probably due errors optical settings focal length aperture depth values 50theta50 area used estimate rms depth error position planar surface figure 14 rms errors plotted sigmaoe error bars rms error relative object distance seen vary object distance 04 08 close objects 08 12 objects farther 880 mm partly mapping depth measured image side depth object side reason error estimated depth oe fi larger scene point larger fi seen equation 34 note rms error depends coefficient smoothing postfiltering stages found empirically error gaussianlike distribution using distribution one show error reduces factor 18 depth map convolved 8theta8 averaging filter definition error often used quantify performance range sensors farfocused image b nearfocused image c graycoded depth map wireframe depth map confidence value 12 map f wireframe adaptive coefficient smoothing figure 13 depth defocus applied scene includes weak texture white background larger errors region weak texture reflected confidence map adaptive coefficient smoothing algorithm uses confidence map refine depth estimates regions weak texture actual depth mm estimated depth fitting error figure 14 depth estimation linearity textured plane plane moved increments 25mm away lens plotted distances measured lens rms error relative object distance 04 12 6 conclusions proposed class rational operators passive depth defocus though operators broadband used together provide invariance scene texture since broadband small number operators sufficient cover entire frequency spectrum hence rational operators replace large filter banks expensive computational perspective advantage comes without need sacrifice depth estimation accuracy resolution detailed procedure used design rational operators example constructed 7theta7 operators using polynomial model normalized image ratio however notion rational operators general represents complete class filters design procedure described used construct operators based rational models normalized image ratio rational operators derived desired blur function addition rational operators discussed wide range issues pertinent depth defocus particular detailed analyses techniques provided prefiltering near far focused images well postprocessing outputs rational operators operator outputs also used derive depth confidence measure measure used enhance computed depth maps proposed depth defocus algorithm requires total 5 convolutions tested algorithm using synthetic scenes real scenes evaluate performance found depth detection gain error less 1 regardless texture frequency depth accuracy found 05 12 object distance sensor results several natural extensions since scene areas expect low texture frequency would meaningful embed proposed scheme pyramidbased processing framework image areas dominant low frequencies higher frequencies higher levels pyramid proposed algorithm applied levels pyramid resulting depth maps combined using depth confidence measures b given efficiency al gorithm worth implementing realtime version using pipeline image processing architecture datacube mv200 estimate algorithm would result least 6 depth maps per second 512theta480 resolution c present im plementation varied position image sensor change focus setting alternatively aperture size varied rational operators derived optical setup using basis functions b p1 see watanabe nayar1995a finally would worthwhile applying algorithm outdoor scenes large structures appendix 71 problem image registration rational operators give accurate results farfocused image 1 near focused image 2 need precisely registered within 01 pixel respect one another however conventional lenses magnification varies focus setting hence misregistration introduced experiments mechanically changed focus setting process introduced translation two images lens aberrations small misregistration decomposed two factors global magnification change global translation two factors magnification change proves much harmful change corrected using image warping techniques darrell wohn1988 wolberg1990 however generally introduces undesirable effects smoothing aliasing since warping based spatial interpolation resampling techniques used optical solution problem described following section detailed watanabe nayar1995b 711 telecentric optics imaging system shown figure 1 effective image location point p moves along principal ray r sensor plane displaced causes shift image coordinates image p variation image magnification defocus manifests correspondence like problem depth defocus corresponding points images needed estimate blurring approach problem optical perspective rather computational one consider image formation model shown figure 15 modification made respect model figure 1 use external aperture 0 aperture placed frontfocal plane ie focal length front principal point lens simple addition solves problem magnification variation distance ff sensor plane lens simple geometrical analysis reveals ray light r 0 scene point passes center 0 aperture 0 emerges parallel optical axis image side lens kingslake1983 result despite blurring effective image coordinates point p images 1 coordinate focused image q f given offthe shelf lens aperture easily appended casing lens resulting optical system called telecentric lens nominal effective fnumbers classical optics figure 1 fa respectively equal fa 0 telecentric case magnification change reduced order less 003 ie 01 pixel 640theta480 image detailed discussion telecentricity implementation found watanabe nayar1995b recently used idea develop realtime active depth defocus sensor nayar et al1995 watanabe et al1995 712 translation correction seen previous section magnification changes farfocused nearfocused images avoided focus setting changed translations may also introduced translation correction done using image processing without introducing harmful image artifacts however processing must carefully r f f figure 15 constantmagnification imaging system depth defocus achieved simply placing aperture frontfocal plane optics resulting telecentric optics avoids need registering farfocused nearfocused images watanabe nayar1995b implemented since seek 01 pixel registration two images procedure use briefly described detailed watanabe nayar1995b use fftphase based local shift detection estimate shift vectors subpixel accuracy divide fourier spectra corresponding local areas two images fit plane phases ratio spectra gradient fitted plane nothing relative shift two images get shift vectors several positions image similarity transform used model shift vector field fitting vectors similarity model estimate global translation residual magnification changes separately watanabe nayar1995b residual magnification corrected tuning aperture position telecentric optics translation corrected shifting images opposite directions need subpixel accuracy interpolate image resample generate registered images interpolating function lanczos4 windowed sinc function wolberg 1990 since translation correction remains constant entire image single shift invariant convolution achieves desired shift though convolution distorts image spectrum since images undergo amount shift distortion images common distortion eliminated normalized image ratio mp computed application rational filters translation correction found maximum registration error experiments small 002 pixels 72 operator response depth error deviation ratio functions g p u v gm u v filter design obtained fitting polynomial model normalized image ratio varies frequency u v hence depends texture scene filter design described section 41 need relation ratio error depth estimation error starting equation 12 get g p1 u v g p2 u v fi f u v depth estimated single frequency u v since u v ratio condition 13 fixed define g p1 u becomes differentiation get mu v ff p u v ff treated constants since wish find error fi f u v caused errors gm1 u v g p2 u v solving dfi f u v get since g p2 u v small correction factor approximated equations 23 20 since c p2 c p1 c p2 represents small correction depth estimate fi approximated integrating frequencies du dv hence error fi caused error fi f u v combining expression equation 43 du dv optimal values dgm1 u v dg p2 u v would minimize depth error dfi question trivial dgm1 u v dg p2 u v influence complex way avoid either two terms integrand numerator taking disproportionately large value decided assume terms constant value gives us following bounds dgm1 u v dg p2 u v oe gm1 u oe g p2 u jfi f u vj set 1 represents worst case ie largest normalized depth error acknowledgements research conducted center research intelligent systems department computer science columbia university supported part production engineering research laboratory hitachi part david lucile packard fellowship authors thank yasuo nakagawa hitachi ltd support encouragement work r range imaging sensors principles optics fourier transform applications laplacian pyramid compact image code pyramid based depth focus matrix based method determining depth focus computing depth outoffocus blur using local frequency representation introduction mathematical statistics focusing memo 160 robot vision perspective range finding techniques computer vision pyramid framework early vision optical system design journal computer vision shape focus effective approach rough surfaces science fractal images new sense depth field numerical recipes c depth defocus spatial domain approach parallel depth recovery changing camera parameters minimal operator set texture invariant depth defocus telecentric optics constantmagnification imaging digital image warping depth focusing defocusing moment filters high precision computation focus stereo tr ctr boissenin j wedekind n selvan b p amavasai f caparrelli j r travis computer vision methods optical microscopes image vision computing v25 n7 p11071116 july 2007 n rajagopalan chaudhuri uma mudenagudi depth estimation image restoration using defocused stereo pairs ieee transactions pattern analysis machine intelligence v26 n11 p15211525 november 2004 liming chen georgy kukharev tomasz ponikowski pca reconstruction based approach extending facial image databases face recognition systems enhanced methods computer security biometric artificial intelligence systems springerverlag london 2005 boissenin j wedekind n selvan b p amavasai f caparrelli j r travis computer vision methods optical microscopes image vision computing v25 n7 p11071116 july 2007 vinay p namboodiri subhasis chaudhuri defocus diffusion depth estimation pattern recognition letters v28 n3 p311319 february 2007 paolo favaro stefano soatto geometric approach shape defocus ieee transactions pattern analysis machine intelligence v27 n3 p406417 march 2005 reinhard erum arif khan depthoffieldbased alphamatte extraction proceedings 2nd symposium applied perception graphics visualization august 2628 2005 coroa spain lyubomir zagorchev ardeshir goshtasby paintbrush laser range scanner computer vision image understanding v101 n2 p6586 february 2006