mainmemory index structures fixedsize partial keys performance mainmemory index structures increasingly determined number cpu cache misses incurred traversing index keys stored indirectly standard mainmemory databases cost key retrieval terms cache misses dominate cost index traversal yet inefficient time space store even moderate sized keys directly index nodes paper investigate performance tree structures suitable oltp workloads face expensive cache misses nontrivial key sizes propose two index structures pkttrees pkbtrees significantly reduce cache misses storing partialkey information index show small fixed amount key information allows cache misses avoided allowing simple node structure efficient implementation finally study performance cache behavior partialkey trees comparing mainmemory tree structures wide variety key sizes key value distributions b introduction following recent dramatic reductions random access memory ram competitive price disk storage years ago multigigabyte main memories easily affordable expandable 64bit architectures applications much 1 2 gb data main memory built relatively inexpensive systems moderate growth space requirements need concern reasons spurred stringent performance demands advanced business networking internet applications number mainmemory database mainmemory database cache products appeared market 2 22 29 products essentially fulfill expectations research mainmemory databases last fifteen years see permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copy otherwise republish post servers redistribute lists requires prior specific permission andor fee acm sigmod 2001 may 2124 santa barbara california usa example 9 12 15 16 providing approximate orderof magnitude performance improvement simple database applica tions compared disk databases data fully resident main memory 2 29 adapting mainmemory database algorithms become cache conscious perform well multilevel mainmemory storage hierarchies recently received attention database literature 5 24 25 mentioned papers related work see example 6 commonly used processors execute dozens instructions time taken read main memory cache miss instance memory access time 450 mhz sun ultra 60 50 times slower time access data resident onchip cache fur ther disparity processor speed memory latency expected grow since cpu speeds increasing much faster rate 60 per year memory speeds 10 per consequently mainmemory index structures designed minimize cache misses index traversal keeping cpu costs space overhead low intuitively cachemiss costs minimized small node sizes high branching fac tors example 6 found optimal node sizes btree implementation slightly larger 1 cache block average number keys present node would fill cache block low cpu costs index traversal important since cache misses cost fewdozen instructions setting key comparison costs important component cpu cost especially multipart variablelength keys addition ally space overhead important since cost ram approximately 1mb 50 times expensive disk storage result amount main memory available index may limited cost factors leading constraints index size space usage depends space used represent keys index nodes space used pointers average occupancy nodes tree mainmemory oltp environments include mix read update operations ttree 1 b tree two index structures studied previously literature 17 24 mainmemory database products aware 2 29 implement ttree index structure proposed lehman carey 17 however 24 authors found due higher cost cache misses modern hardware trees performed better experiments conducted integer keys assumption integer keys may valid olap environment assuming suitable preprocessing general purpose database must handle complex keys multiple parts null values 1 ttree similar binary tree multiple keys instead one stored node variablelength fields countryspecific sort values etc key size key storage strategy directly affect branching factor trees since branching factors small already node sizes based cache blocks height tree vary substantially key size changes thus initial motivation research examination ttree btree performance mainmemory oltp environment order consider variety key storage schemes key sizes 9 17 authors suggest avoiding key size problem replacing key value index pointer data reconstructing key needed index traversal indirect keystorage approach advantage optimizing storage eliminating duplication key values index improving branching factor nodes simplifying search avoiding complexity storing long variablelength keys index nodes however approach must reexamined due additional cache misses caused retrieval indirect keys second approach dealing large complex keys use key compression allow keys fit cache blocks keycompression approach benefit entire key value constructed without accessing data records dereferencing pointers however typical compression schemes employed prefix btrees 4 disadvantage compressed keys variablesized leading undesirable space management overheads small mainmemory index node depending distribution key values prefixcompressed keys may still fairly long resulting low branching factors deeper trees paper propose partialkey approach uses fixedsize parts keys information key differences minimize number cache misses cost performing compares tree traversal keeping simple node structure incurring minimal space overhead key represented partialkey tree pointer data record containing key value key partial key given key index refer index key purposes discussion partial key consists 1 offset first bit index key differs base key 2 l bits index key value following offset l input parameter intuitively base key given index key recent key encountered search prior comparing index key partialkey approach relies able resolve comparisons search key index key using partialkey information index key comparison cannot resolved pointer data record dereferenced obtain full index key value using idea partial keys develop pkttree pkbtree variants ttree btree respectively describe search algorithms partialkey trees well strategies maintaining partialkey information presence updates finally conduct extensive performance study pkttree pkbtree structures comparing standard trees btrees direct indirect key storage schemes experiments consider wide range parameter settings key size key value distribution entropy also study sensitivity partialkey algorithms l number key value bits stored partial key performance results given detail section 53 indicate ffl indexing schemes studied partialkey trees minimize cache misses key sizes ffl due lower cpu costs btrees direct key storage faster partialkey trees small key sizes slower larger key sizes ffl partialkey schemes good space utilization slightly worse ttrees indirect key storage much better direct key storage schemes ffl small fixed value l amount partial key informa avoids indirect key accesses wide variety lengths entropies summary partialkey trees incur cache misses impose minimal space overheads reduce cost key comparisons without introducing variablelength structures node thus enabling larger keys handled much efficiency smaller keys expect relative performance partialkey trees improve time increasing cost cache misses remainder paper organized follows section 2 discuss related work sections 3 4 introduce partial comparisons apply search pkt pkbtrees section 5 present results performance study fi nally section 6 present conclusions issues addressed future work 2 related work early study index structures mainmemory databases undertaken 17 authors proposed ttree index order optimize storage space advocated storing pointers data records instead key values index however design choice result large number cache misses since pointer dereference access key value key comparison could potentially lead cache miss since time early work mainmemory databases little difference cost cachehit cachemiss much attention paid minimizing cache block misses work cacheconscious data structures outside database community focused optimizing scientific workloads cacheconscious behavior studied 6 pointerbased structures including search trees however work focused actions taken without programmer cooperation rather explicitly designed data structures recently rao ross propose two new mainmemory indexing techniques cachesensitive search trees csstree 24 cachesensitive b trees 25 designed readintensive olap environment csstree essentially compact spaceefficient tree csstree nodes fully packed keys laid contiguously level level main memory thus children node easily located performing simple arith metic explicit pointers child nodes longer needed absence updates key values mapped integers mapping preserves ordering key values thus key value csstree compact inte ger stored node eliminating pointer deref erences summary csstree incurs little storage space overhead exhibits extremely good cache behavior csb tree adapts ideas index structure supports efficient update csstree authors recommend rebuilding scratch batch updates structure stores groups sibling nodes adjacent memory reducing number pointers stored parent node without incurring additional cache misses however work continues assume integer keys ex tent performance improvements csb trees csstrees partialkey trees likely orthogonal since former focuses reducing pointer overhead improving space utilization latter focuses reducing keysize comparison cost partialkey techniques borrow earlier work key compression 4 11 however differences discuss partialkey trees similar bit trees introduced 11 bit trees extend trees storing partial keys instead full key values keys contained leaf nodes partial key bit tree consists offset difference bit relative previous key node authors describes several properties searches using offset difference bits particular show somewhat surprising result precise position search key leaf node determined performing exactly one pointer dereference retrieve indirect key focus mainmemory rather disk partialkey trees differ bit trees following respects 1 partial keys stored internal nodes leaf nodes 2 partial keys contain l bits key value following difference bit addition difference bit offset 3 searching key node partialkey tree requires one pointer dereferenced frequently requires pointer dereferences due l bits additional information novel search algorithms trees proposed 4 employ key compression improve storage space characteristics branching factor trees suppose p common prefix keys subtree rooted node n node n common prefix p computed tree traversal suffix key value stored n keys move leaf node due split separator shortest portion key needed distinguish values splitting nodes moved partialkey trees differ prefix b trees following respects 1 prefix trees factor portion common keys node partialkey trees factor information common pairs adjacent keys within node typically longer prefix common whole node 2 prefix trees entire suffix separator stored partialkey trees first l bits suffix stored thus partialkey trees may lose key value information prefix 3 prefix b needed contrast partialkey tree pointer dereferences must performed comparison cannot resolved using partialkey information 4 partial keys stored prefix tree variable sized complicates implementation cases separator may even fit 64byte cache line causing index nodes span multiple cache blocks reducing branching factor thus partial key trees trade guarantee indirect key references partialkey trees low probability indirect key dereferences exchange simple node structures strongly bounded tree heights reasonable since cost cachemiss orders magnitude lower cost random disk access ronstrom thesis 28 describes httptree variation prefix trees compression performed within node storing keys relative previous key factoring common suffixes etc nodes also clustered pages facilitate distribution however searches full key reconstructed order perform comparisons compressed key sizes variable lossless compression schemes primarily numeric attributes recently proposed database literature 13 23 goldstein ramakrishnan shaft 13 propose page level algorithm compressing tables numeric attribute minimum value occurring tuples page stored separately entire page instead storing original value attribute tuple difference original value minimum stored tuple00101111101010 rec 2 1 data record partial l bits figure 1 partial key thus since storing difference consumes fewer bits storage space overhead table reduced tuple differential coding tdc 23 compression method also achieves space savings storing differences instead actual values attributes however attribute value tuple stored difference relative attribute value preceding tuple 3 partial key search section describe partial key approach algorithms performing compares searches presence partial keys assume keys represented fixedlength bit strings though required general bits numbered order decreasing significance beginning bit 0 significant bit 31 partial keys overview consider order index keys visited compared search key traversal ttree btree index observe structures key visited far closest value search key either recent key compare less search key recent key compare greater easy see recent key compare less search key shares initial bits compared less search key search similarly recent key compared greater thus observation follows fact initial bits may shared recent search key example keys either side large power two event rare following discussion refer current key visited index key opposed search key previous visited base key partialkey schemes key represented index three items 1 pointer record containing key 2 offset first bit index key differs base key 3 first l bits index key following offset illustrate construction partial key figure 1 figure others index key search key generally referred k k j base key one approach using partial key information would mirror use prefixes prefix btree approach search code would maintain known prefix index key traversed tree concatenating appropriate portions partial keys encountered known portion sufficient resolve comparison search key cache miss avoided however turns constructing prefix necessary fact comparisons often resolved noting offset search key differed base key comparing offset stored partial key index key observation ensures comparisons performed small fixedlength portions key precisely comparisons performed topic next section 32 partialkey comparisons section discuss properties difference bits formally present theorem bears directly comparisons partialkey trees offset significant thus lowest bit difference keys k k j also let ck result lt gt eq comparison keys k depending whether k k j partialkey approach based observation index key k j base key k b noting partial key key k j frequently allow full comparisons k j search key k avoided index retrieval particular two k j compare way lt example base key known possible determine k compares k j well additional reference keys unless theorem 31 given k ae proof assume without loss generality k suppose dk first bit difference must 0 k b bit must 1 follows dk bits k agree bits k b bits including dk corresponding bit k also 1 thus hand suppose dk thus since k bit position dk must 0 k 1 k b since dk must k j k b 1 bit sequences preceding bit k k j must identical thus follows k cases follow symmetry key ideas theorem 31 illustrated figure 2a less base key k b dk 9 greater dk 5 thus shown figure first 5 bits k k j k b match 6 th bit k k b 1 k j 0 theorem 31 used compute cases result comparison search key k index key k j partial key index key k j stores difference bit offset respect base key k b encountered previously search since attempt made search algorithm compare k k j must case ck available due previous comparison search key base key thus case dk theorem 31 used infer dk turn propagated next index key comparison k j base key case handled theorem 31 occurs dk case inference one make identical first dk one cannot determine keys k k j compare example illustrated figure 2b cases shown figure k one k difference bits equal l bits key value stored index key compared corresponding bits search key bits equal retrieval indirectly stored key required note shown figure 1 difference bit included l bits stored partial key since k k j differ k b value bit corresponding bits k k j must identical procedure comparepartkeysearchkey indkey comp offset begin 1 indkeypkoffset offset 2 3 comp gt 4 else 5 comp lt 6 offset indkeypkoffset 7 else indkeypkoffset offset 8 9 partkey searchkey0indkeypkoffset1 10 else 11 partkey searchkey0indkeypkoffset1 12 comp offset comparesearchkey 13 14 offset indkeypkoffset 15 comp eq 16 return comp offset figure 3 comparepartkey comparison using partial keys procedure comparepartkey figure 3 utilizes theorem 31 compute result comparison search key index key containing partialkey information partialkey information consists three fields pkoffset pklength partkey described table 1 input parameters comp offset comparepartkey result comparison difference bit location search key respect base key steps 16 procedure straightforward application theorem 31 case difference bit locations search key index key equal keys must identical difference bit difference bit keys must either 0 1 depending whether keys less greater base key step 12 function compare invoked compute comparison l bits following difference bit keys function comparek1 k2 returns pair values comp offset following semantics value comp one eq lt gt depending whether bit sequence k1 equal less greater bit sequence k2 two sequences compared bit bit return value offset location significant bit two keys differ thus steps 1314 since partkey may represent entire index key bits partkey agree corresponding bits searchkey comparison search key index key cannot resolved procedure returns eq case semantics returned offset simply two keys agree first offsetgamma1 bits note step 12 function compare needs consider bits starting bit offset indkeyoffset two keys since corresponding bits preceding point identical 2 therefore b figure 2 examples comparisons keys k k j cannot resolved table 1 partialkey notation symbol description l maximum number bits key value stored partial key offset difference bit key k base key bits following location k pkoffset key k pklength number partialkey bits stored key k sequence consisting bits offsets l key k k1 delta k2 concatenation bit sequences k1 k2 n numkeys number keys node n th key node n th pointer node n keys cases procedure comparepartkey performs one integer comparison involving difference bit offsets however additional expense may incurred since bit offset must computed anticipation next comparison greater cost simple integer compares compares well comparisons larger keys shown section 5 partialkey scheme adapted multisegment keys even segments arbitrary length idea treat pkoffset two digit number first digit indicates key segment second indicates offset within seg ment partkey field may limited bits single seg ment cost complexity span segments 33 partialkey nodes comparepartkey procedure described previous section basic building block performing retrievals pkt trees pkbtrees present complete algorithm searching tree present linear encoding scheme computing partial keys array keys index node n also present linear search algorithm finding search key node present pair adjacent keys node search key lies linear encoding partial keys base key key n simply key immediately preceding n first key nkey0 base key key ancestor n tree compared search key tree traversal node n visited thus base key first key depends tree structure different pkttree pkbtree discuss following section simple linear search algorithm searching key index node n visited search key compared base key nkey0 let comp offset denote result comparison offset difference bit search key base key order locate position search key n procedure comparepartkey see figure used compute comparison difference bit offset search key nkey0 case comparison cannot resolved using partialkey information nkey0 comparepartkey returns eq nkey0 dereferenced search key compared full key corresponding nkey0 result comparison difference bit offset used compare search key nkey1 steps comparing search repeated successive keys n comparison difference bit offset previous key key greater equal search key found however naive linear search strategy may perform unnecessary dereferences following example illustrates 32 consider node n figure 4 difference bit key respect previous key marked arrow bits following difference bit stored partial key key let base key first key n search key figure 4 linear searching key node 00101 let search key 10111 search key compared base key comparison difference bit offset gt 0 respectively invoking comparepartkey search key nkey0 gt returns eq 2 since nkey0pkoffset 0 search matches nkey0 first two bits thus nkey0 would dereferenced comp pkoffset comparison nkey0 gt 2 respectively next search key compared nkey1 invoking comparepartkey since greater 2 difference bit offset search key nkey0 comparepartkey returns gt 2 nkey1 dereferenced next invocation comparepartkey nkey2 returns gt 3 since bit sequence 1010 constructed nkey2 smaller 1011 corresponding bits search key returning gt 3 nkey3 parepartkey moves key 4 returns lt 1 nkey4 since finds nkey4pkoffset 1 less 3 offset returned nkey3 thus simple linear search algorithm stops nkey4 position search key n determined using one key dereference nkey0 however position search key also determined without dereferencing keys including nkey0 reason comparepartkey returns eq 2 invoked nkey0 thus point know first two bits nkey0 10 since first two bits nkey0 agree search key since nkey1pkoffset 3 also conclude first two bits nkey1 agree nkey0 thus 10 since must case third bit nkey2 1 third bit nkey1 must 0 fourth bit nkey2 obtained partial key thus conclude first four bits nkey2 1010 since search key 10111 comparison search key nkey2 resolved gt 3 subsequent comparisons carried described earlier conclude search key lies nkey3 nkey4 thus position search key determined without dereferencing single key linear search algorithm requiring one key deref erence procedure findnode shown figure 5 avoids unnecessary dereferences made simple linear search algorithm comparing search key index key node n case procedure comparepartkey returns eq comparison search key index key cannot resolved findnode immediately dereference index key stead exploits semantics eq offset returned com procedure findnoden searchkey offset begin 1 high n numkeys 2 low 1 3 cur offset 4 cur cmp gt 5 cur low 1 6 cur highf 7 cur cmp cur 8 comparepartkeysearchkey n keycur cur cmp cur 9 cur 10 high cur 11 break 12 else cur 13 low cur 14 offset cur 15 cur 17 high low 1 18 low high offset findbittreen searchkey low high 19 cache miss 20 return low high offset figure 5 findnode linear searching key node using partial keys parepartkey search key index key agree first offset1 bits try resolve comparisons subsequent keys illustrated earlier example 32 eq 2 result comparison nkey0 useful resolving comparison operation key nkey2 fact procedure comparepartkey already stated correctly handles value eq input parameter called findnode informal proof fact found appendix procedure findnode accepts input parameters node n perform linear search difference bit offset search key base key nkey0 assumes search key nkey0 greater base key respect nkey0s partial key computed similar simple linear search algorithm described earlier compares search key successive index keys node index key larger search key found procedure comparepartkey used perform every comparison results previous comparison stored variables cur cmp cur passed input parameters unlike simple linear search scheme index key immediately dereferenced precise result comparison key search key cannot computed instead variables low high used keep track positions index keys n search key definitely known greater less respectively end sweep keys node n high low greater 1 implies precise position search key n ambiguous case procedure findbittree used locate exact position search key low high returns consecutive keys search key lies difference bit offset search key respect lower key procedure findbittree employs search algorithm bit trees described 11 requires exactly one key dereferenced nutshell algorithm performs sequential scan keys n offsets low high maintains variable pos initially set low key examined difference bit offset partial key bit value search key 1 variable pos set position key n hand bit value search key 0 keys difference bit offset greater current skipped next key examined key whose difference bit offset less current key examined nkeypos dereferenced compared search key comp offset pair returned comparesearchkey nkeypos findbittree takes one following actions 1 2 suppose high position first key rightleft pos difference bit offset less nkeypos return high1 high offset correctness findbittree case 2 due following property pos pos key whose difference bit offset equal pos key whose difference bit offset less poss refer reader 11 details variable offset returned findnode difference bit offset search key n keylow 1 case low 1 search key less nkey0 offset difference bit offset search key base key nkey0 finally search key contained n procedure returns position index key equals search key revisiting example 32 findnode determines position search key node n without requiring keys deref erenced successive invocations procedure comparepartkey sequence keys n return eq 2 eq 2 gt 3 gt 3 lt 1 maintaining partialkey information presence dates linear encoding strategy maintaining partial key information quite straightforward insertion new key node requires partial keys inserted key key following recomputed deletion requires partial key key following deleted key recomputed 4 partialkey trees building partialkey comparison singlenode partial search algorithms presented previous section discuss partial keys improve performance mainmemory index structures reducing l2 cache miss rate particular present partialkey variants ttree 17 btree 3 index structures suitable use mainmemory pktttree pkbtree refer extend mainmemory counterparts representing keys partialkey information described section 3 linear encoding scheme described previous section used compute partial keys index keys node linear encoding node level thus need specify base key respect first key node encoded since base key every key node simply key preceding 41 pkttree ttree balanced binary tree multiple keys stored node leftmost rightmost key value node define range key values contained node balancing handled avl trees 1 refer reader 17 26 additional information ttrees including details update strategies concurrency control pkttree similar ttree except addition pointer data record containing full key value index key entry also contains partialkey formation following nptr0 nptr1 denote pointers left right children node n storing partialkey information first key node n base key respect partial key computed first key parent node described leftmost key parent node key search key compared node n visited figure 6a depicts example pkttree figure solid arrows denote base index keys dashed arrows represent pointers child nodes procedure findttreesearchkey begin 1 n root tree 2 lan nil 3 offset 0 4 comp gt 5 n nil f 6 comp offset comparepartkeysearchkey 7 8 dereference nkey0 cache miss 9 comp offset comparesearchkeynkey0 10 11 return n 0 0 offset 12 else 13 n nptr0 14 else 15 lan n 16 lanoffset offset 17 n n ptr1 19 return lan findnodelan lan0 searchkey lanoffset figure 7 findttree searching key ttree using partial keys searching key searching key value pkttree relatively straightforward performed described procedure findttree see figure 7 procedure findttree includes optimization 17 requires node search key compared leftmost key value node step 6 variables comp offset keep track results recent comparison search key leftmost key parent node passed parameters com parepartkey case comparepartkey cannot resolve comparison leftmost key current node dereferenced step 8 search key found less key search proceeds left subtree found greater search proceeds right subtree current node noted variable lan step 15 significance lan search reaches bottom tree search key present tree node stored lan greater lan0 procedure findnode thus employed order determine position search key node lan since find node requires leftmost key greater base key lan0 deleted lan passing input parameter findnode maintaining partialkey information presence dates inserts deletes keys pkttree cause ro tations movement keys nodes insertionsdeletions pkttree b pkbtree pointers pointers figure pkttrees pkbtrees keys nodes partialkey information cases updated follows ffl case rotation parent node involved rotation may change thus partialkey information leftmost key node recomputed respect new parent ffl leftmost key node changes partialkey information recomputed leftmost keys node two children ffl case key left key node changes due key inserted deleted partialkey information key recomputed relative new preceding key 42 pkbtree pkbtree identical btree except structure index keys index key consists pointer data record key partialkey information leaf nodes contain index internal nodes also contain nnumkey1 pointers index nodes subtree pointed nptri contains keys storing partialkey information base key leftmost key n largest key contained ancestor n less leftmost key thus n 0 node n 0 ptri points n one parents n 00 path n 0 n n 00 ptr0 points n one parents base key relative nkey0 encoded n illustrated figure 6b solid arrows denote base keys index keys pkbtree dashed arrows represent pointers child nodes searching key procedure findbtree figure 8 contains code searching key pkbtree beginning root node node procedure findnode invoked determine child node visited next search variable offset stores offset difference bit search key base key nkey0 largest key ancestor n also less nkey0 findnode simply returns offset input search key less nkey0 maintaining partialkey information presence dates insert operation causes key inserted leaf node pkbtree key inserted leftmost position leaf partial key needs computed relative largest key less ancestor hand keys left node partial key procedure findbtreesearchkey begin 1 n root tree 2 pn nil 3 offset 0 4 n nil f 5 pn n 6 low high offset findnoden searchkey offset 7 low high 8 return n low high 9 n nptrhigh 11 return pn low high figure 8 findbtree searching key btree using partial keys computed easily relative preceding key partial key next key computed respect case node n split splitting key n inserted parent splits thus handled simply updating partialkey information parent similar key insertion case key deletion pkbtree somewhat complicated case leftmost key leaf deleted partialkey information needs recomputed base key ancestor deletion nonleftmost key leaf simply requires partial key key following recomputed finally deletion key nkeyi internal node n pkbtree causes replaced smallest key subtree pointed node containing key every node n 00 n n 00 n 00 0s partial key recomputed smallest key replaces deleted key nkeyi base key 5 performance goal performance study compare lookup performance ttrees btrees pkttrees pkbtrees mainmemory setting particular goals follows 1 study performance wide range key sizes key value distri butions 2 evaluate impact changing amount partial information used pkt pkbtrees 3 evaluate space usage spacetime tradeoff subsequent sections describe hardware platforms design experiments present selected results 51 memory hierarchy latencies observed memory references depend primarily whether data present cache whether vir system cpu l1 data l2 data dram cycle time size block latency size block latency l2 miss latency sun ultra 37ns 16k 64 6ns 2m 64 33ns 266ns sun ultra 22ns 16k 64 4ns 4m 64 22ns 208ns pentium iii 17ns 16k 5ns 512k 40ns 142ns pentium iiie 14ns 16k 4ns 256k 10ns 113ns table 2 latency cache vs memory tual address translation lookaside buffer tlb 2 modern mainmemory architecture typically includes two levels cache small fast oncpu l1 cache larger offcpu 3 therefore slower l2 cache typical parameters cache memory speed shown table 2 see 19 20 7 latency information generated version 19 lmbench 18 locally available processors intended give reader feel current cache parameters comparison systems another component memory hierarchy tlb caches translations virtual physical addresses shown 5 significant effect perfor mance focus tlb issues paper one justification approach fact almost modern tlbs capable using superpages 14 essentially allowing single tlb entries point much larger regions posing difficulties operating system implementors 27 facility may effectively remove tlb miss issue mainmemory databases allowing entire database effectively share one two tlb entries focus tlb effects apparent experimentation form better performance index nodes span multiple cache lines results shown due limited space determining effect superpages tlb costs mainmemory data structures remains future work 52 experimental design implemented ttrees btrees direct indirect storage keys also implemented pkttrees pkbtrees varied size partial keys stored node ttree algorithms essentially lehman carey optimization performing single keycomparison given level direct key partialkey variants stored en tirepartial key values leftmost key node used initial traversal ttree code adapted system additional support concurrency control 26 next locking 21 iteratorbased scans features exercised tests partialkey trees implemented two schemes storing offsets bitwise bytewise bitwise scheme used description section 3 since scheme concepts clearly articulated however may convenient implementation store difference information larger granularity particular consider byte granularity clearly results sections 3 4 hold byte offsets differ since bit offset also differ manner ever byte offsets equal may still case bit offsets would differ case one simply stores bits difference could occur words entire byte thus offsets compare equal keys disambiguated 2 physical characteristics memory module especially repeated access page may also factor considered paper 3 pentium iiie l2 cache though relatively small onchip first byte storing offsets larger granularity trades distinguishing power coding simplicity bit offsets one always stores precise l bits capable distinguishing otherwise bits stored keys model keys unique fixedlength sequences unsigned bytes key comparisons performed bytewise context separate function call indirect keys stored separate l2 cache lines since typically retrieved data records intuitive partial keys would sensitive distribution keys particular entropy keys since tests generate bytes key independently entropy byte depends number symbols byte selected specifically byte selected uniformly alphabet n symbols byte contains lg n bits shannon entropy 8 intuitively keys higher entropies distinguished earlier compare leading lower comparison costs terms partial keys lower entropy leads larger common prefixes lower chance two keys differ within l bytes common prefix mentioned section 3 partialkey trees may used multipart variablelength keys implement options tests note degree implementing wider variety keys thus expensive key com parisons works partialkey schemes since schemes reduce impact key comparison costs cases partial key sufficient however bytewise comparisons may somewhat less efficient example singleinstruction integer comparisons selected bytewise comparison reasonable model key comparison expense attempt vary cost additional parameter current study performance metrics evaluated various indices based following three performance metrics walltime number l2 cache misses storage space requirements number l2 measured using special registers available ultrasparc via perfmon software 10 parameter settings unless otherwise stated index node spanned three l2cache blocks total 192 bytes index stored 1m keys keys chosen uniformly random rejected unique three cache blocks chosen size could handle larger innode key sizes experiments shown performed comparably better smaller larger node sizes studied algorithms 1m records represented largest size machine could easily hold memory relatively large number records required see effect l2 cache misses timing numbers tests present results two choices byte entropy generated keys 36 bits 78 bits corresponding alphabet sizes 12 220 respectively though actual experiments considered wide variety entropies inbetween experiments key size independent parameter fixed time per lookup usec l2 misses per lookup time vs cache misses pkbtree pkttree time per lookup usec l2 misses per lookup time vs cache misses pkbtree pkttree b figure 9 time l2 cache performance various key strategies high low entropy size l partial keys stored 2 bytes stored offsets byte granularity since found partialkey trees perform optimally nearoptimally choices hardware environment experiments conducted sun ultra workstation 296mhz ultrasparc ii processor 256 megabytes ram shown table 2 machine 16k l1 data cache size 2m l2 directmapped cache 64 byte block size latencies shown lmbench 18 6ns 2 cycles l1 cache 33ns 11 cycles l2 266 ns 88 cycles main memory implemented index structures using suns c compiler version 42 optimization level o3 experiments ensured virtual memory accessed runs resident ram experimental runs cases run consisted 100000 lookups pregenerated list randomly selected keys tree searches successful run repeated 10 times averaged ensured overall standard deviation time low less 1 figures shown document tree 15 million elements maximum fit main memory platform 53 selected results index performance mainmemory environment dominated cpu costs performing key comparisons cache miss costs thus reasonable btrees direct key storage perform better partialkey trees small keys since space usage comparable space required partial key partialkey comparison code somewhat expensive simple bytewise key compares however keys become longer btree performance expected become worse partial trees due lower branching factor higher key comparison costs low byteentropies cases expect indirect indexes perform poorly comparison direct indexes data structure indirect indexes require extra cache misses perform comparison expectations confirmed experiments figure 9 summarizes experimental results indexing schemes data sets 15 million elements yaxis shows number l2 cache misses xaxis shows average time lookup microseconds plots parametric key size key sizes 8 12 20 28 36 bytes high entropy case additional point size 4 figure 9a shows behavior low entropy entropy per byte 36 figure 9b shows experiment run entropy 78 given key size entropy left defines improved performance performance thus partial ordering one algorithm outperforms another values key size entropy value algorithm faster fewer cache misses using metrics cache misses lookup time make following observations ffl pkbtrees consistently outperform algorithms l2 cache misses ffl direct btrees outperform algorithms time small key sizes would hold integer keys ffl direct ttrees outperform algorithms time large key sizes slightly outperforming pkbtrees ffl direct ttrees indirect btrees essentially cache performance occurs ttrees suffer due tree levels btrees suffer due key dereferencing ffl indirect ttrees perform poorly compared strate gies primarily due cache misses tree levels dereferencing ffl key sizes cachemiss behavior partialkey trees good corresponding tree structure direct storage 4 byte keys one reasons superior cachemiss characteristics partialkey trees always translate better timing numbers especially smaller key sizes factors like cpu costs performing key comparisons etc significant component overall performance however based cachemiss statistics expect performance partialkey trees improve relative trees direct key storage long processor speeds improve quickly mainmemory latency choice l larger values l necessary entropy low sufficient entropy must present partial key high probability differ corresponding bytes search key general random keys length l 2 lg 2 nh ensure two keys collide keys disambiguous length lg 2 nh 8 one see key wise difference information adapts low entropy keys keys time per lookup usec partial key length bytes pkb bit pkb byte pkt bit pkt byte time per lookup usec overhead per key bytes pkbtree pkttree b figure 10 varying partialkey size timespace tradeoffs low entropy adjacent keys likely larger common prefixes increasing l adversely affects branching factor nodes thus tradeoff reducing cache misses avoiding references indirect keys reducing cache misses bushier thus shallower trees investigated issues running experiments wide variety key entropies values l experiment keys relatively low entropy 36 bits per byte results similar wide range entropy values expect partial keys perform well wide variety key distributions fact performance almost always optimal small values l 2 4 bytes due efficacy storing difference offsets storing zero bytes key information special case reduces algorithm similar bit tree 11 generalized handle internal levels tree incur fewer cache misses option perform well l 0 experiments confirm following intuition storing differences bit level important order increase distinguishing power space usage space overhead critical attribute mainmemory index figure 10b show spacetime tradeoff different algorithms variety key sizes graph xaxis space axis lookup time lower lefthand corner optimal key size parameter varies 0 8 bytes space numbers obtained tree built random insertions 1m keys see graph indirect storage poor time performer excels space ever schemes direct key storage trade space time storage overheads increase significantly key size pkt pkbtrees provide nice tradeoff taking approximately twice space indirect storage key sizes less space directstorage btrees key sizes greater 4 6 conclusions future work paper introduced two new index structures pkt pkbtrees designed optimize space time cachemiss performance indices mainmemory oltp databases index structures based partial keys small fixedsize representations keys allow index nodes retain simple struc ture improve branching factor speed key comparisons yet resolve key comparisons without reference indirectly stored keys performance study found partialkey trees perform better btrees keys stored directly node keys larger 1220 bytes depending key distribution partialkey trees incur fewer cache misses btrees smallest key sizes leading expectation performance pkbtrees relative btrees improve time gap processor main memory speeds widen causing penalty cache miss severe fi nally pkbtrees take much less space standard btrees smallest trees pkttrees direct ttrees perform well pkbtrees perform better slightly larger however expect time ttrees replaced variations btree mainmemory databases dramatically better l2 cache coherence optimal performance key sizes performance results lead one consider hybrid approach direct storage used small fixedlength keys partialkey representations used larger variablelength keys future work intend explore ways architectural trends affect performancecritical mainmemory dbms code one trend increasing availability instructionlevel parallelism related trend increasing cost branch misprediction pipeline bubbles second trend availability superpages tlbs may significantly reduce tlb cost inmemory algorithms 7 r design analysis computer algorithms storage manager main memory database performance critical applications organization maintenance large ordered indexes prefix btrees database architecture optimized new bottleneck memory access imporving pointerbased codes cacheconscious data placement pentium iii processor sc242 450 mhz 800 mhz datasheet elements information theory implementation techniques main memory database systems perfmon users guide main memory database systems overview compressing relations indexes virtual memory contemporary microprocessors dali high performance mainmemory storage manager evaluation starbursts memory resident storage component study index structures main memory database management systems portable tools performance analysis ultra ultra workstation datasheet arieskvl keyvalue locking method concurrency control multiaction transactions operating btree indexes microsoft com cache conscious indexing decisionsupport main memory making b logical physical versioning mainmemory databases reducing tlb memory overhead using online superpage promotion design modelling parallel data server telecom applications timesten team tr elements information theory bittree data structure fast file processing reducing tlb memory overhead using online superpage promotion storage manager inmemory data management consumer transactions timesten approach prefix italicbitalictrees making b trees cache conscious main memory design analysis computer algorithms implementation techniques main memory database systems virtual memory contemporary microprocessors main memory database systems evaluation starbursts memory resident storage component blockoriented compression techniques large statistical databases compressing relations indexes logical physical versioning main memory databases study index structures main memory database management systems cache conscious indexing decisionsupport main memory database architecture optimized new bottleneck ctr peter bumbulis ivan bowman compact btree proceedings 2002 acm sigmod international conference management data june 0306 2002 madison wisconsin bin cui beng chin ooi jianwen su kianlee tan contorting high dimensional data efficient main memory knn processing proceedings acm sigmod international conference management data june 0912 2003 san diego california phil garcia multithreaded architectures sort benchmark proceedings 1st international workshop data management new hardware june 1212 2005 baltimore maryland b barla cambazoglu cevdet aykanat performance query processing implementations rankingbased text retrieval systems using inverted indices information processing management international journal v42 n4 p875898 july 2006 inga sitzmann peter j stuckey compacting discriminator information spatial trees australian computer science communications v24 n2 p167176 januaryfebruary 2002 main memory indexing case bdtree ieee transactions knowledge data engineering v16 n7 p870874 july 2004 jingren zhou john cieslewicz kenneth ross mihir shah improving database performance simultaneous multithreading processors proceedings 31st international conference large data bases august 30september 02 2005 trondheim norway ke wang yabo xu jeffrey xu yu scalable sequential pattern mining biological sequences proceedings thirteenth acm international conference information knowledge management november 0813 2004 washington dc usa bin cui beng chin ooi jianwen su kianlee tan indexing highdimensional data efficient inmemory similarity search ieee transactions knowledge data engineering v17 n3 p339353 march 2005 shimin chen phillip b gibbons todd c mowry gary valentin fractal prefetching btrees optimizing cache disk performance proceedings 2002 acm sigmod international conference management data june 0306 2002 madison wisconsin richard hankins jignesh patel effect node size performance cacheconscious btrees acm sigmetrics performance evaluation review v31 n1 june shimin chen phillip b gibbons todd c mowry improving index performance prefetching acm sigmod record v30 n2 p235246 june 2001 bingsheng qiong luo cacheoblivious nestedloop joins proceedings 15th acm international conference information knowledge management november 0611 2006 arlington virginia usa jeong min shim seok il song jae soo yoo young soo min efficient cache conscious multidimensional index structure information processing letters v92 n3 p133142 15 november 2004