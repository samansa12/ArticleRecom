sparse approximate inverse smoothers geometric algebraic multigrid sparse approximate inverses considered smoothers geometric algebraic multigrid methods based spaialgorithm mj grote huckle siam j sci comput constructs sparse approximate inverse matrix minimizing frobenius norm leads new hierarchy inherently parallel smoothers spai0 spai1 spai geometric multigrid performance spai1 usually comparable gaussseidel smoothing difficult situations neither gaussseidel simpler spai0 spai1 smoothers adequate reduction automatically improves spai smoother needed combined algebraic coarsening strategy jw ruge k stben sf mccormick ed multigrid methods siam 1987 pp 73130 resulting method yields robust parallel algebraic multigrid iteration easily adjusted even nonexpert numerical examples demonstrate usefulness spai smoothers sequential parallel environmentessential advantages spaismoothers improved robustness inherent parallelism ordering independence possible local adaptivity b introduction multigrid methods rely subtle interplay smoothing coarse grid correction careful combination yields ecient multigrid solver large linear systems resulting discretization partial dierential equations 7141527 standard smoothers multigrid usually consist steps basic iterative method shall consider smoothers based sparse approximate inverses hence starting linear system let denote sparse approximation 1 corresponding basic iterative method since approximate inverse known explicitly iteration step requires one additional v matrixvector multiply therefore easy parallelize cheap evaluate sparse recently various algorithms proposed attempt compute directly sparse approximate inverse 5917 comparative study various approximate inverse preconditioners refer benzi tuma 6 approximate inverse techniques also gaining importance smoothers multigrid methods first introduced benson frederickson 34 shown eective various dicult elliptic problems unstructured grids tang wan 25 advantages sparse approximate inverse smoothers classical smoothers damped jacobi gaussseidel ilu inherent parallelism possible local adaptivity improved robustness shall consider sparse approximate inverse spai smoothers based spaialgorithm grote huckle 13 spaialgorithm computes approximate inverse explicitly minimizing frobenius norm computation application smoother inherently parallel since eective sparsity pattern general unknown priori spaialgorithm attempts determine promising entries dynamically strategy proved eective generating preconditioners many dicult illconditioned problems 11324 moreover provides means adjusting smoother locally automatically necessary nevertheless choosing priori sparsity pattern computational cost greatly reduced possible choices include powers suggested huckle 16 chow 10 hence shall investigate following hierarchy sparse approximate inverse smoothers spai0 spai1 spai spai0 spai1 sparsity pattern xed diagonal spai0 whereas spai1 sparsity pattern spai sparsity pattern determined automatically spaialgorithm 13 parameter controls accuracy amount llin structured geometric grids dicult use complex geometries application code designers often turn large unstructured grids yet lack natural grid hierarchy prevents use standard geometric multi grid context algebraic multigrid amg often seen promising method solving largescale problems original amg algo rithm rst introduced 1980s ruge stuben 22 uses simple gaussseidel iteration smoother determines coarse grid space sophisticated way improve robustness method iteration fails converge automatic way improve smoother alternative investigate usefulness smoothers based sparse approximate inverses spai inherently parallel performance also easily adjusted even nonexpert thus aim general inherently parallel algebraic multigrid method section 2 brie review spaialgorithm show sparse approximate inverses used smoothers within multigrid iteration heuristic greens function interpretation underpins eectiveness smoo thers rigorous results smoothing property approximate inverses proved 8 summarized section 24 next present section 3 detailed description algebraic coarsening strategy used 22 together key components algorithm ecient implementation finally section 4 compare performance spai smoothing gaussseidel smoothing various test problems either within geometric algebraic multigrid setting smoothing 21 classical smoothers consider sequence nested grids nest mesh wish solve n n linear system multigrid method details multigrid see hackbusch 14 15 section 10 wesseling 27 multigrid iteration results recursive application twogrid method twogrid method consists 1 presmoothing steps level coarse grid correction level 1 2 postsmoothing steps level leads iteration error e r prolongation restriction operators respectively 1 denotes smoother nested nite element spaces galerkin discretization used galerkin product representation holds otherwise one still use 4 dene coarsegrid problem given r p shall always use x 0 initial guess multigrid vcycle iteration proceeds relative residual drops prescribed tolerance kb x kbk tol 5 calculate average rate convergence 1m expected multigrid convergence behavior achieved number multigrid iterations necessary achieve xed tolerance essentially independent number grid levels typically smoother form w approximates cheap invert course w 1 never computed explicitly let diagonal l lower triangular part u upper triangular part damped jacobi smoothing corresponds whereas gaussseidel smoothing corresponds 8 parameter chosen maximize reduction high frequency components error optimal value problem dependent usually unknown priori although gaussseidel typically leads faster convergence dicult implement parallel smoothing step 9 requires solution lower triangular system neither jacobi gaussseidel smoothing lead satisfactory convergence one either resort sophisticated matrix dependent prolongation restriction operators 29 robust smoothers based incomplete lu ilu factorizations 28 unfortunately ilusmoothing inherently sequential therefore dicult implement parallel also dicult improve locally say near boundary singularity without aecting llin everywhere lu factors 22 spaismoothers alternative inverting w 7 propose compute explicitly sparse approximate inverse use smoothing drop grid index simplify notation yields spaismoother computed minimizing ki mak frobenius norm given sparsity pattern contrast w 1 7 matrix 10 computed explicitly therefore application spai requires matrixvector multiplications easy parallelize require solution upper lower triangular systems moreover frobenius norm naturally leads inherent parallelism rows computed independently one another indeed since solution 11 separates n independent leastsquares problems e k denotes kth unit vector sparse leastsquares problems small since eective sparsity pattern unknown priori original spai algorithm 13 begins diagonal pattern augments progressively sparsity pattern reduce residual r additional reduction 2norm r k involves two steps first algorithm identies set potential new candidates based sparsity current sparse residual r k second algorithm selects protable entries usually less entries computing candidate cheap upper bound reduction kr k k 2 new entries selected added k small leastsquares problem 12 solved augmented set indices algorithm proceeds row satises tolerance set user controls llin quality preconditioner larger value leads sparser less expensive approximate inverse also less eective smoother higher number multigrid cycles lower value usually reduces number cycles cost computing may become prohibitive moreover denser results higher cost per smoothing step optimal value minimizes total time depends problem discretization desired accuracy computer architecture details original spaialgorithm found 13 addition spai shall also consider following two greatly sim plied spaismoothers xed sparsity patterns spai0 di agonal spai1 sparsity pattern solve leastsquares problem 12 thus minimize ki mak frobenius norm sparsity pattern chosen priori eliminates search eective sparsity pattern thus greatly reduces cost computing approximate inverse spai1 smoother coincides smoother tang wan 25 diagonal calculated directly simply given kk k kth row note always welldened nonsingular contrast damped jacobi spai0 parameterfree summarize shall consider following hierarchy spaismoothers minimize ki mak frobenius norm certain sparsity pattern diagonal given 14 spai1 sparsity pattern spai sparsity pattern determined automatically via spai algorithm 13 row satises 13 given approximate inverses leads smoothing step found many situations spai0 spai1 yield ample smoothing however added exibility providing automatic criterion improving smoother via spaialgorithm remains useful indeed spai0 spai1 used initial guess spai thus locally improved upon needed reducing matrices inherent small block structure typical discretization systems partial dierential equations blockspaialgorithm 2 greatly reduces cost computing 23 greens function interpretation approximate inverses yield eective smoothers problems come partial dierential equations mesh parameter h tends zero solution linear system h u tends solution underlying dierential equation appropriate boundary conditions matrix h corresponds discrete version dierential operator l let h k denote kth row solves linear system e h k kth unit vector h 0 h k tends greens function l denotes adjoint dierential operator x x k delta centered x k exhibit correspondence h k recall l formally dened identity u v appropriate function spaces equation 20 continuous counterpart relation 17 19 20 conclude similarly combination 16 18 21 leads discrete counterpart 22 comparison 22 23 shows h k corresponds gx x k kth row h approximate inverse h solves 12 equiva lently min hence h k approximates kth column h k 18 discrete 2norm xed sparsity pattern h k nonzero entries usually lie neighborhood x k correspond mesh points x j close x k therefore appropriate scaling inverse powers h see h approximates gx x k locally continuous l 1268 3 partial dierential operators gx x k typically singular x k decays smoothly necessarily rapidly increasing distance jx x k j clearly slower decay denser h must approximate well 1 deciency sparse approximate inverse preconditioners also pointed tang 24 time however suggests sparse approximate inverses obtained minimization ki mak frobenius norm naturally yield smoothers multigrid indeed eective preconditioner must approximate uniformly entire spectrum l contrast eective smoother needs capture highfrequency behavior yet highfrequency behavior corresponds singular local behavior gx x k precisely approximated h k illustrate fact consider standard vepoint stencil discrete laplacian 15 15 grid figure 1 following page compare 1 gaussseidel approximate inverse l two explicit approximate inverses spai1 spai02 recall gaussseidel poor preconditioner problem remains excellent smoother captures highfrequency behavior 1 similarly spai1 spai yield local operators shall see good smoothing property despite resemblance gaussseidel spai approximate inverses note onesidedness former contrast symmetry latter gaussseidel spai 02 fig 1 row 112 following operators 1 top left gaussseidel inverse computed spai1 bottom left computed spai02 bottom right 24 theoretical properties contrast heuristic interpretation previous section shall summarize rigorous results 8 smoothing property simplest smoother spai0 multigrid convergence theory rests two fundamental conditions smoothing property 15 denition 1063 function lim approximation property 15 section 1063 general smoothing approximation properties together imply convergence twogrid method multigrid wcycle contraction number independent level number moreover symmetric positive denite prob lems conditions also imply multigrid vcycle convergence independent see hackbusch 15 sect 106 details approximation property independent smoother depends discretization prolongation operator p restriction operator r 15 approximation property shown hold large class discrete elliptic boundary value problems symmetric positive denite problems smoothing property usually holds classical smoothers damped jacobi symmetric gaussseidel incomplete cholesky 8 smoothing property 25 shown hold spai0 smoother reasonable assumptions matrix precisely symmetric positive denite spai0 smoother satises smoothing property either weakly diagonally dominant seven nonzero odiagonal entries per row furthermore two diagonal smoothers spai0 damped jacobi optimal relaxation parameter lead identical smoothers discrete laplacian periodic boundary conditions space dimension 8 special situation parameterfree spai0 smoother automatically yields scaling diaga minimizes smoothing factor sense optimal general situations however smoothers dier boundary conditions even constant coecients equispaced mesh comparison two diagonal smoothers via numerical experiments showed spai0 attractive alternative damped jacobi 8 indeed spai0 parameterfree typically leads slightly better convergence rates damped jacobi 3 algebraic multigrid multigrid mg methods sensitive subtle interplay smoothing coarsegrid correction standard geometric multigrid method applied dicult problems say strong anisotropy interplay disturbed error longer smoothed equally well direc tions although manual intervention selection coarse grids sometimes overcome diculty remains cumbersome apply practice unstructured grids complex geometry contrast algebraic multigrid approach compensates decient smoothing sophisticated choice coarser grids interpolation operators based matrix many amg variants exist dier coarsening strategy interpolation used introduction various amg methods found 26 following ruge stuben 22 describe algebraic coarsening strategy interpolation operators shall combine spai smoothers section 22 use numerical experiments 31 coarsening strategy1020301020300206 x anisotropic stencilh 26 6 6 6 6 4 fig 2 error gaussseidel smoothing steps problem described section 42 001 smooth error component aligned anisotropy read stencils fundamental principle underlying coarsening strategy based observation interpolation performed along smooth error components symmetric mmatrices error smoothed well along large negative odiagonal entries matrix 23 therefore grid point p may identify among neighboring points q good candidates interpolation comparing magnitude corresponding entries pq leads following relations point p neighbors q connectivity graph matrix condition notation interpretation pq max apr 0 ja pr j p q p strongly depends q pq 6 0 q strongly uences p pq weakly depends q pq 6 0 q weakly uences p parameter controls threshold discriminates strong weak connections typically 025 denition positive odiagonal entries necessarily weak relations p q p q symmetric symmetric next dene set dependencies point p set uences point p set weak dependencies point p every level coarsening strategy must divide p set points level two disjoint sets c coarse points also present coarser level f ne points absent coarser level choice c f induces cfsplitting coarse grid correction heavily depends accurate interpolation accurate interpolation guaranteed every f point surrounded suciently many strongly dependent c points typical conguration shown figure 3 q3 strong dependency dependency c point f point strong dependencies indicated solid arrows weak dependencies represented dashed arrows c points represented solid circles whereas f points represented dashed circles hence strong dependencies point c points therefore q 2 q 4 good candidates interpolating p fig 3 ideal coarsening conguration interpolation coarsening algorithm attempts determine cfsplitting maximizes f toc dependency f points coarsening goal 1 minimal set c coarsening goal 2 important strike good balance two con icting goals overall computational eort depends convergence rate also amount work per multigrid cycle clearly optimal cf splitting minimizes total execution time however since convergence rate generally unpredictable coarsening algorithm merely attempts meet coarsening goals 1 2 heuristic fashion complexity must exceed log n retain overall complexity multigrid iteration 32 coarse grid selection greedy heuristic split p c f every step greedy heuristic moves promising candidate p c forcing neighboring points f procedure repeated points distributed every step requires olog n operations complexity computations exceed log n desired overall complexity log n reached greedy heuristic described 23 based following two principles correspond coarsening goals 1 2 1 promising candidate p becoming c point highest number uences ji p j uences p added f choice supports coarsening goal 1 f points eventually least one strong c dependency 2 keep number c points low coarsening goal 2 algorithm prefer c points near recently chosen f points hence u ences given higher priority starting points undecided points algorithm proceeds selecting u promising c point highest priority priority point p dened equation ects preference choosing next c point point uences many previously selected f points key advantage 26 possibility update priority locally o1 time results desired overall complexity log n summarize coarse grid selection algorithm algorithm 1 coarse grid selection procedure set priorityp ji p j end u u 1 select p 2 u maximal p riorityp q 2 p dependencies p end q 2 p uences p r 2 q dependencies q end end procedure implement steps 1 2 3 eciently o1 time maintain list q points sorted priority together list point indices q moreover list boundaries b priorities occurring q enables immediate update sorted list q figure 4 shows possible segment lists q b 5 611 15index q position q priorityp position q3141312 index b fig 4 three lists q b enable ecient implementation coarsening algorithm setup phase coarsening algorithm b computed sorted priority step 1 simply chooses last element q steps 2 3 implemented exchanging point whose priority must either incremented decremented left rightmost neighbor q priority priority adjusted q remains sorted b updated accordingly following suggestion k stuben shall skip second pass original coarsening algorithm 22 enforces even stronger f toc dependency high computational cost involved 33 interpolation grid function u h dened ner grid interpolated grid function uh dened coarser grid c follows hence values c points simply transfered coarser level whereas values f points interpolated c neighbors four dierent dependencies possible f point neighbors shown figure 5 standard interpolation see 23 choice weights w pq interpolating p based equation pp e pq e indeed ae 0 smoothing eect minimal error e declared algebraically smooth see 23 details clearly cannot interpolate p surrounding f points whereas weakly dependent c points included either rough nature error direction thus connections q 1 q 2 figure 5 always ignored interpolation corresponding interpolation weights set zero w pq 1 cancellation weak dependencies neglected entries weakly dependent neighbors added diagonal hence equation 28 becomes pp e pq e strong c dependencies q 3 figure 5 cause diculty value uh available coarse grid location division 29 pp yields weight pq pp however strong f dependencies q 4 figure 5 available interpolation must rst interpolated c points strongly depend replace qq qq every q 2 q f every point r 2 q yields weight pq pp qr qq point q direct indirect neighbor p 30 32 apply two weights calculated separately added q4 strong dependency dependency c point f point q3 indirect interpolation direct interpolation ignored ignored fig 5 four dierent dependencies possible p neighbors algorithm described determines coarse grid levels basis approximate inverse fact information contained used determine coarse grid levels interpolation weights suggested meurant 1920 34 measuring computational costs memory requirements comparing performance various smoothers cannot limit comparing number multigrid iterations also need estimate additional amount work due smoother calculate total density ratio nonzero entries grid levels 1 smoothing applied additional amount work due smoother proportional rapidly reducing number points one level next matrices must also remain reasonably sparse measured instance galerkin coarse grid approximation enlarges standard point stencil nest grid ninepoint stencils subsequent levels resulting value geometric multigrid 16 semicoarsening together onedimensional interpolation used increases two results presented following section computed matlab implementation shall evaluate eciency various approaches comparing respective values 4 numerical results illustrate usefulness versatility spai smoothing shall consider various standard test problems cases dierential equation considered discretized nest level standard nite dierences equispaced mesh geometric multigrid use regularly rened sequence equispaced grids single unknown remaining center domain algebraic multigrid coarser levels obtained coarse grid selection algorithm described section 32 denition strong dependency section 31 algorithm proceeds number grid points drops twenty coarse grid operators obtained via galerkin product formula 4 geometric multigrid p correspond standard linear interpolation whereas amg p obtained described section 33 use multigrid vcycle iteration two pre two postsmoothing steps 2 multigrid iteration proceeds relative residual satises prescribed tolerance 5 41 rotating ow problem rst consider convectiondiusion problem 0 10 1 ux boundary u represents scalar quantity advected rotating ow eld convection dominated h linear systems cease symmetric positive denite problems lie outside classical multigrid theory use centered secondorder nite dierences diusion discretize convection rstorder upwinding ensure numerical stability table geometric mg convergence rates rotating ow problem 128128 grid dierent values symbol indicates multigrid iteration diverges smoother gaussseidel spai0 spai1 spai03 spai02 table convergence rates q obtained standard mg smoothers yield acceptable convergence rates diusion dominated case however multigrid iteration diverges gaussseidel spai0 smoothing contrast spai1 smoother still yields convergent method use spai03 smoothing accelerates convergence even increases 14 reduce diusion even spai02 smoother yields convergent iteration although resulting value quite high construction spai02 remains parallel fully auto matic remark symmetric gaussseidel smoothing 27 leads convergent multigrid iteration yet approach generalize easily unstructured grids parallel results since spai1 smoother inherently parallel straightforward apply within parallel version geometric mg data distributed among processors via domain decomposition wellknown work eciently number multigrid applications 18 platform shall use ethbeowulf cluster consists 192 dual cpu pentium iii 500 processors nodes connected via 100 mbits 1 gbs switched network communication done mpi apply parallel multigrid implementation rotating flow problem 35 128 nodes total executiontime 156 seconds 40964096 grid time includes setup construction spai1 smoother requires solution sixteen million small 259 independent leastsquares problems shown table 1 use coarsest level consists single mesh point leads divergent multigrid iteration increasing resolution coarsest level 3232 mesh points one obtains convergent multigrid iteration table scalability parallel mg using spai1 problem size number processors increased factor 4 total time increases 30 gridsize 512512 4 10231023 number processors total time sec 20 26 obtain good speedup parallel mg code important perform coarse grid agglomeration see 21 loss eciency coarser grid levels although implemented agglomeration strategy computations scale reasonably well long problem size matches size parallel architecture see table 2 rotating ow problem algebraic coarsening clearly aligned ow direction larger dots correspond c points coarser levels b locally anisotropic diusion semicoarsening apparent center domain fig 6 examples algebraic coarsening two model problems considered amg results none approaches however entirely satisfactory vanishing vis cosity overcome lack robustness small apply algebraic coarsening strategy described section 3 figure 6a displays coarse levels selected algorithm table 3 spai0 spai1 yield convergence without particular tuning 05 spai table amg convergence results rotating ow problem varying 128128 grid 28 34 42 smoother q q q gaussseidel 014 038 081 table amg convergence rates rotating ow problem smoother gaussseidel spai0 spai1 spai05 gridsize q q q q 128128 42 081 036 01 021 10 027 04 43 096 038 01 024 10 034 04 smoother yields compromise spai0 spai1 smoothers storage requirement convergence rate lie obtained xed sparsity patterns spai0 spai1 lower values reduce convergence rate even poor convergence rates obtained gaussseidel could probably improved either smoothing c points f points 23 using symmetric gaussseidel results table 4 demonstrate robustness spai smoothing deed 0 convergence rates obtained combined spaiamg approach remain bounded 42 locally anisotropic diusion section consider locally anisotropic problem ux boundary diusion coecient x except inside square 14 34 14 34 x constant table 5 observe geometric multigrid diculties small values unidirectional smoothing error aligned strong anisotropy standard isotropic interpolation fails table locally anisotropic diusion geometric mg convergence rates q varying 128 128 grid smoother q q q gaussseidel amg results amg overcomes diculties performing automatic semicoarsening operator dependent interpolation direction strong couplings correspond smooth error components wellknown eg 23 amg solves problems little diculty results table 6 verify fact acceptable densities densities could lowered even dropping smallest entries interpolation operators 23 consider truncated grid transfer operators table amg convergence results locally anisotropic diusion 128 128 grid note q remain bounded 0 284 294 294 smoother q q q gaussseidel 014 018 018 convergence rates obtained gaussseidel spai1 comparable 02 spai0 results slightly slower convergence overall spai1 smoother ecient smoother problem although reduction results even faster convergence approximate inverses become dense thus expensive results tables 6 7 demonstrate robust multigrid behavior either h 0 table amg convergence rates q locally anisotropic diusion note q remain bounded gridsize 6464 128128 256256 289 294 295 gaussseidel 012 018 022 concluding remarks results show sparse approximate inverses based minimization frobenius norm provide attractive alternative classical jacobi gaussseidel smoothing simpler smoothers spai0 spai1 often provide ample smoothing comparable damped jacobi gaussseidel nev ertheless situations convection dominated rotating ow spai1 leads convergent multigrid iteration unlike gaussseidel demonstrate improved robustness implementation geometric multigrid combined spai1 smoothing enables fast solution large convection diusion problems massively parallel architectures incorporating spai smoothers amg 22 obtain exible parallel algebraic multigrid method easily adjusted underlying problem computer architecture even nonexpert interesting incorporate information available approximate inverses coarsening strategy grid transfer operators suggested 1920 expected benet would include improved robustness local adaptivity multigrid components well authors currently pursuing issues report elsewhere near future acknowledgment thank klaus stuben useful comments suggestions r mpi implementation spai preconditioner t3e block version spai preconditioner iterative solution large sparse linear systems arising certain multidimensional approximation problems frequency domain behavior set parallel multigrid smoothing operators sparse approximate inverse preconditioner conjugate gradient method comparative study sparse approximate inverse preconditioners approximate inverse preconditioners via sparsesparse iterations priori sparsity patterns parallel sparse approximate inverse preconditioners robustness scalability algebraic multigrid parallel preconditioning sparse approximate inverses iterative solution large sparse systems equations approximate sparsity patterns inverse matrix preconditioning factorized sparse approximate inverse preconditionings numerical experiments algebraic multilevel preconditioners multilevel ainv preconditioner parallel adaptive multigrid toward e sparse approximate inverse smoother multi grid introduction algebraic multigrid introduction multigrid methods robustness ilusmoothing matrix prolongations restrictions blackbox multigrid solver tr robustness ilu smoothing matrixdependent prolongations restrictions blackbox multigrid solver multigrid methods parallel computersmyampersandmdasha survey recent developments factorized sparse approximate inverse preconditionings sparse approximate inverse preconditioner conjugate gradient method parallel preconditioning sparse approximate inverses approximate inverse preconditioners via sparsesparse iterations approximate sparsity patterns inverse matrix preconditioning comparative study sparse approximate inverse preconditioners toward effective sparse approximate inverse preconditioner priori sparsity patterns parallel sparse approximate inverse preconditioners robustness scalability algebraic multigrid sparse approximate inverse smoother multigrid robust parallel smoothing multigrid via sparse approximate inverses coarsegrid selection parallel algebraic multigrid ctr michele benzi preconditioning techniques large linear systems survey journal computational physics v182 n2 p418477 november 2002