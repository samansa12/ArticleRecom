using generalized cayley transformations within inexact rational krylov sequence method rational krylov sequence rks method generalization arnoldis method constructs orthogonal reduction matrix pencil upper hessenberg pencil rks method useful matrix pencil may efficiently factored paper considers approximately solving resulting linear systems iterative methods show cayley transformation leads efficient robust eigensolver usual shiftinvert transformation linear systems solved inexactly within rks method relationship recently introduced jacobidavidson method also established b introduction suppose eigenvalues near complex number possibly corresponding eigenvectors generalized matrix eigenvalue problem needed assume b large complex matrices order n also suppose least one b nonsingular equation 11 eigenvalues without loss generality assume b invertible following standard convention refer b matrix pencil us n considered large prohibitive compute eigenvalues dense algorithm would attempt standard approach perform inverse iteration 17 p386 matrix b sequence iterates produced mild assumptions sequence converges toward desired eigenvector eigenvalue closest rayleigh quotient calculation gives estimate eigenvalue another approach extract approximate eigenpair using information subspace defined joining together iterates sequence 12 leads straightforward extension 22 ideas introduced ericsson ruhe 13 spectral shiftinvert transformation lanczos method starting vector v arnoldis method 2 builds step step orthogonal basis krylov subspace km one improvement inverse iteration scheme given possibly vary every step example j may set rayleigh quotient z h azz h bz z unit vector direction si elegantly shows build orthogonal basis rational krylov subspace work r b lehoucq supported mathematical information computational sciences division subprogram office computational technology research us department energy contract w31109eng38 work karl meerbergen supported project iterative methods scientific computing contract number hcm network chrcct930420 coordinated cerfacs toulouse france mathematics computer science division argonne national laboratory argonne il 60439 usa current address sandia national laboratories ms 1110 pobox 5800 albuquerque nm 871851110 rlehoucqcssandiagov z lms numerical technologies interleuvenlaan 70 3001 heverlee belgium kmlmsnitbe r b lehoucq k meerbergen resulting algorithm called rational krylov sequence rks method generalization shiftinvert arnoldi method shift possibly varied step methods considered require solution x typically accomplished factoring gamma b example gamma b sparse direct method 7 8 9 10 12 11 may employed shifts j varied use one direct methods conjunction arpack 21 powerful combination computing solutions generalized eigenvalue problem 11 however large eigenvalue problems n 10 000 direct methods using rks method may provide efficient solution potentially prohibitive storage requirements motivation current study investigate use iterative methods linear systems equations arising rks method one benefit many eigenvalue problems arising discretization partial differential equations intelligent preconditioner may often constructed shall call methods inexact rks ones longer rational krylov space particular shall demonstrate cayley transformation performs robustly shiftinvert transformation si using iterative methods linear solves continue remarks order although combining eigensolver using one methods discussed previously iterative method linear solves new even novel idea generally appreciated residuals linear systems must small precise matrix vector product must applied kbu gamma v approximate solution linear system ffl machine precision necessary requirement correct representation underlying krylov subspace linear systems solved accuracy guarantee krylov space si j generated example arnoldis method used reason expect hessenberg matrix generated represents orthogonal projection si onto arnoldi vectors generated assumption accuracy violated often case results produced eigensolver taken caution fittingly literature approaches finding solutions generalized eigenvalue problem 11 approximate solutions linear systems available sparse bramble et al 4 knyazev 18 knyazev et al 19 morgan 25 szyld 42 consider situation matrix pencil symmetric positive definite papers 18 19 4 also contain numerous citations russian literature algorithms based jacobidavidson method 38 introduced sleijpen van der vorst discussed 14 39 recent report sorensen 41 discusses methods based truncating qz iteration recent paper meerbergen roose 23 provided motivation current article demonstrate superior numerical performance cayley transformation shiftinvert transformation within arnoldi method using iterative linear solver article organized follows introduce rks method x2 inexact rks method introduced x3 along connection inverse iteration examples illustrating ideas presented x4 illustrate method generalized eigenvalue problem x5 show appropriate approximate shiftinvert transformation could used compare inexact rks jacobidavidson methods x6 conclude paper x7 summary inexact rational krylov sequence method 3 ffl choose starting vector v1 ffl 1 select pole j zero j 2 continuation vector 3 form w 4 orthogonalize w 5 theta k 7 8 compute approximate eigenpairs interest 9 check whether approximate eigenpairs satisfy convergence criterion fig 21 computing rational krylov sequence rks matrix pencil ab main ideas remaining questions article matrices denoted uppercase roman characters vectors denoted lowercase roman characters range matrix v denoted rv hermitian transpose vector x denoted x introduced employed next sections norm k delta k used euclidean one 2 rational krylov sequence method method outlined algorithm listed figure 21 practical rks algorithm given 32 ruhe considers shiftinvert transformation si exact arithmetic transformations lead rational krylov space however finiteprecision arithmetic andor conjunction iterative methods linear systems substantial differences may exist see 23 examples call j poles j zeros continuation vectors discussion possible choices postponed x32 section discuss relationships among quantities steps 17 form gramschmidt orthogonalization employ finally computation approximate eigenpairs convergence eliminating w steps 25 obtain relationship theta h 1j h 2j theta rearranging equation 22 results putting together relations 4 r b lehoucq k meerbergen h j j associated jth columns hm tm respectively final simplification rewrite equation 23 tm remark long subdiagonal elements h j1j nonzero hm lm unreduced upper hessenberg rectangular matrices hence full rank 21 orthogonalization orthogonalization step 3 algorithm figure 21 performed using iterative classical gramschmidt algorithm approach used sorensen 40 based analysis 5 reorthogonaliza tion gramschmidt algorithm 22 computing eigenvalue estimates consider calculation approximate eigenpairs rks method first discuss compute ritz pairs main purpose article study use iterative linear system solvers rks various ways extract eigenvalues therefore use standard ritz values throughout though theory easily extended harmonic 32 39 ritz values consider matrix c subspace rx x 2 c nthetak full rank pair jxz called ritz pair c respect subspace rx referred galerkin projection two important properties galerkin projection following first rx j c n ritz pairs exact eigenpairs c second c normal ritz values lie convex hull eigenvalues c example c hermitian ritz values lie smallest largest eigenvalue c following theorem shows ritz pairs may computed rks method outlined algorithm listed figure 21 theorem 21 j vm1 lm z ritz pair b gamma1 respect lm z proof following definition 26 equation 24 ritz pair lm thus vm1 desired equivalence 27 follows denote ith ritz value available steps rks algorithm figure 21 unless otherwise stated assume ritz values increasing distance j j associated ritz vector denoted sub superscripts omitted whenever meaning context clear inexact rational krylov sequence method 5 221 computing ritz pairs generalized eigenvalue problem 27 may solved standard one since lm unreduced upper hessenberg matrix lm full rank hence lm invertible thus standard eigenvalue problem solved giving 1 remark moorepenrose generalized inverse explicit formation inverse lm required instead km may computed least squares methods example lapack 1 software ritz vector lm z 1 sub superscripts omitted context clear 23 stopping criterion accuracy ritz pair typically estimated residual norm kay gamma byk equation 24 follows lm z g km z lm z simple check convergence ritz pair algorithm figure 21 userdefined error tolerance tol ritz pair follows aey hence small relative kb gamma1 ak eigenpair nearby problem poorly conditioned eigenvalue matrix pencil kb gamma1 k large size kgk indicates accuracy computed ritz value conclusion motivates us say sequence ritz pairs fixed converges toward eigenpair equation 11 kg zero increases toward n although convergence rigorously defined necessarily kg n allow us track progress ritz pair step algorithm figure 21 3 inexact rks method steps 35 rks algorithm figure 21 cayley transformation computed two step process first linear system solved w next w orthogonalized v j solution v j1 h j results two steps account largest source errors arising computing floatingpoint arithmetic since interest using preconditioned iterative method solution equation 31 neglect errors gramschmidt orthogonalization phase assume columns v j1 orthogonal machine precision 6 r b lehoucq k meerbergen let us formally analyze errors arising solution equation 31 let denote computed solution associated residual thus ks j x h ks ks modest multiple machine precision say direct method computes backward stable solution robust implementation direct method gives backward stable solution linear system note even backward stable solution x j hand may share digits accuracy w moreover achieving backward stable solution iterative method may prohibitively expensive therefore shall study situation large backward error allowed solution linear system order give indication mean large words iterative linear system solvers needed linear system said solved relative residual tolerance solution x satisfies kb gamma cxk kbk b krylov methods 15 34 typically used gmres 35 bicgstab 37 qmr 16 among widely used see 3 templates solvers performance solvers substantially improves suitable preconditioner employed hence mean large error 10 gamma8 putting j together sm j call inexact rational krylov sequence irks relation relation may rewritten km generalized moorepenrose inverse words computed exact rks pencil caution reader confuse em unsubscripted es x 23 denote oe lm reciprocal minimum singular value fore large ritz pairs x221 may pencil near b situation implies even use direct method linear systems nearly rank deficient lm might lead inaccurate ritz pairs matrix em incorporates backward error linear solution distance matrix pencil call ritz pairs define discuss quantities prove helpful discussion follows ffl cayley residual c residual linear system 31 step j rational krylov method ffl rks residual f j rks method computes ritz pair j rks residual satisfies inexact rational krylov sequence method 7 ffl choose starting vector v1 ffl 1 select pole j j 1 set zero otherwise set 2 compute continuation vector r j 3 form solving ae oe x j set 4 see steps 46 icrks method listed figure 32 fig 31 inverse iteration via inexact rks method ffl true residual r j residual defined r j sub superscript true residual dropped f j three residuals may linked via relationships follow equation 32 definition 33 present numerical evidence demonstrates although kf j k decreases size increasing j r j decrease inexact shiftinvert transformation employed however inexact cayley transformation used instead ks j z j k kf j k decrease size true residual also decreases continuation section follows x31 present relationship inverse iteration includes theorem shows convergence inexact inverse iteration x32 fix various parameters rks method ie poles zeros continuation vectors selection makes link generalized davidson method 6 25 26 x33 informal argument given convergence inexact cayley rational krylov sequence icrks method described x32 using theoretical result x31 also illustrate numerical example 31 inverse iteration first exploit direct relationship inverse iteration occurs special choice continuation vector cayley transformation used example presented compares choice shiftinvert transformation subsection concluded theorem shows numerical behavior observed fortuitous event although choice continuation vector exploit entire space vectors icrks theorem justifies superior properties combining approximate linear solve via cayley transformation equation 22 matrix identity 21 follows using 25 l 8 r b lehoucq k meerbergen hence v j1 l j linear combination columns v j1 obtained performing one step inverse iteration vector v j j inductive argument easily establishes following property lemma 31 scalar v 1 starting vector rks lemma 31 indicates compute approximate eigenvalue denote equation 24 gives rayleigh quotient estimate eigenvalue without need explicitly apply b algorithm inverse iteration given figure 31 approximate eigenpair iteration j use relationships 34 z recall used j gamma1 entries 0 v 1 determine initial estimates eigenpair compare inexact inverse iteration computed via rks method using shiftinvert cayley transformations example example 31 olmstead model 28 represents flow layer viscoelastic fluid heated equations boundary conditions speed fluid v related viscoelastic forces equation discretized central differences gridsize 1n2 discretization equation may written size jacobian matrix consider jacobian parameter values trivial steady state thus interest eigenvalue largest real part ran algorithm figure 31 linear systems solved 20 iterations gaussseidel starting zero initial vector since solver stationary relative residual norm almost constant initial guess eigenvalue 0 initial vector rks n poles j set equal 5 j residuals r j f j j z j shown table 31 three sequences decrease cayley transform used redid experiments using shiftinvert transformation results also shown table 31 ks j z j k kr j k stagnate near value note however kf j k tends zero table 31 shows true residual decreases cayley transformation used stagnates shiftinvert transformation following result indicates occurs mild conditions performing inexact inverse iteration either shiftinvert cayley transformation inexact rational krylov sequence method 9 table numerical results inverse iteration example 31 using inexact cayley shiftinvert transformations table shows norms true residual r j j z j rks residual norm l j also displayed cayley transformation cayley shiftinvert theorem 32 assume integer k value fl 0 relative residual tolerance used linear solves see equations 312 313 cayley transformation used kf shiftinvert transformation used proof z follows ks j kk l j k ks cayley transform prove 37 induction j clearly satisfies 37 k suppose 37 holds integer hypothesis theorem combining equations 39 312 results ks j gamma1 k using inductive hypothesis kr j gamma1 k gives 37 follows shiftinvert 38 follows 39 313 completes proof theorem shows ae iteration computed via cayley transformation produce ritz pair small direct residual since inexact inverse iteration better exact inverse iteration although term kf j k decrease using shiftinvert transformation size direct residual kr j k may stagnate occurs contribution solving linear systems inexactly si j true residual constant direct method used linear system equations multiple machine precision hence whether shiftinvert cayley transformation used true residual kr j k decreases rate proportional ae exact cayley transformation l 1 hence thus converges zero 1 sigma tends one increasing j computation reveals quite often k l j k 1 small number steps also holds inexact inverse iteration seen exact inverse iteration applied b table 31 demonstrates hence large enough k convergence rate inverse iteration using cayley transform approximately ae method progresses ae easily estimated thus largest relative residual tolerance may used also easily estimated 32 choosing pole zero continuation vector robust efficient strategy selecting poles rks method subject research present situation complicated employ approximate methods linear solves since concerned showing use k k computation ritz pairs fixed pole used numerical experiments choice zero cayley transformation crucial computing ritz pair small direct residual demonstrated numerical examples 23 first formally analyze choice zero continuation vector give example suppose j gamma1 j gamma1 inexact ritz pair computed j1st step inexact rks method select zero j gamma1 contination vector interest cayley transformation leads shiftinvert transformation gives 3 inexact rational krylov sequence method 11 ffl choose starting vector v 1 kv 1 ffl 1 select pole j j 1 set zero j gamma1 otherwise set 2 compute continuation vector r j residual 3 form w 4 see steps 47 rks method listed figure 21 5 solve eigenvalue problem 6 check whether approximate eigenpairs satisfy convergence criterion fig 32 computing eigenvalues pencil b inexact cayley rational krylov sequence icrks method linear systems solved although transformations use continuation vector cayley transformation also uses ritz value zero difference two linear systems 310 311 righthand side preconditioner used solve linear system 310 generalization davidsons method 6 26 computing eigenvalues matrix pencil denote computed solutions 310 311 x c j x si iterative method relative residual tolerance used two linear systems residuals linear systems satisfy ks c ks si cayley shiftinvert transformation respectively drop superscripts denote whether cayley shiftinvert transformation context clear view two bounds 312 313 computed solutions cayley transformation preferred shiftinvert transformation appears use cayley transformation leads better results inexact linear solvers zero continuation vector chosen 310 experimental results also support conclusion algorithm figure 32 lists inexact cayley rks method icrks illustrate properties algorithm means example demonstrates 1 inexact rational krylov method galerkin projection method 2 method compute one eigenvalue time davidson methods example 32 consider matrices eigenpairs j e j 5 goal compute smallest eigenvalue 1 corresponding eigenvector e 1 icrks method using fixed pole 07 starting vector set equal v 5 cayley system 12 r b lehoucq k meerbergen solved x note simulates stationary iterative solver residual tolerance implies f 5 5 thus computed eigenpairs exact eigenpairs ae 5 found 10000 00120 gamma00697 03708 gamma04728 gamma00000 19987 gamma05981 44591 gamma56013 gamma00001 01003 04666 171897 gamma211757 gamma00002 00340 gamma44220 368172 gamma407251 eigenpairs 10000 00000 00000 00000 00000 09812 gamma01801 gamma00177 gamma01340 09229 03188 01681 00045 sigma 00068i gamma00826 sigma 07214i true residual form r 5 example shows e 5 nearly rank deficient desired eigenvector nearly nullvector therefore desired eigenvalue case computed small true residual noted perturbation e 5 small direction one eigenspace hence icrks able compute several eigenvalues simultaneously situation linear systems solved accurately instance direct method example icrks computes exact eigenpairs steps general however r 5 inexact ritz pair computed galerkin projection also remark 5 4 5 5 nonreal would case galerkin projection real symmetric matrix contrast iterative eigenvalue solvers arnoldi jacobidavidson methods galerkin projections employed 33 inexact rational krylov informally discuss algorithm listed figure 32 including comparison inexact inverse iteration previous section 35 ritz vector igamma1 computed x 221 follows inexact rational krylov sequence method 13 table numerical results olmstead model example 33 table shows order accuracy residual norm rightmost ritz pair norm j z j first four components z j numerical experiments reveal jth component z j large relative components see table 32 best approximation desired eigenvector among columns v j1 l j given v j1 l j improvement previous ritz vector one step inverse iteration thus using continuation vector v give better results information subspace rv i1 used inexact inverse iteration uses information space spanned last column v i1 inexact ritz pairs lead true residuals r cayley transform used cayley residual iteration satisfies ks k kr igamma1 k true residual jth iteration decomposed r ks gives upper bound ks j z j k righthand side ks k independent j quite large small however je typically forms decreasing sequence increasing j decreasing sequence ks j z j k example 33 discuss example e z j j z j tend zero icrks method matrix arises problem example 31 ran algorithm icrks figure 32 fixed starting vector n linear systems solved gmres preconditioned ilu number iterations gmres determined relative error tolerance selected shows residual norm norm error term j z j ks j z j k tend zero large j ks j z j k kr j k case f j converges rapidly zero j z j table 32 also illustrates fact decreases fixed increasing j 4 numerical example example illustrates use inexact rational krylov methods solution generalized eigenvalue problem also make comparison inexact inverse iteration cayley transform icrks simulation flow viscous fluid free surface tilted plane leads finite element approach eigenvalue problem singular matrix computation eigenvalue nearest gamma10 interest since theory valid nonsingular 14 r b lehoucq k meerbergen table numerical results tilted plane problem x 4 methods used inexact rational krylov icrks inverse iteration cayley transform iteration j j inexact ritz value j cayley residual g icrks fig 32 inverse iteration fig 31 ks ks 9 b interchange role b computing eigenvalue nearest fact b singular implies eigenvalue shown presence eigenvalue disturb calculation nonzero eigenvalue shiftinvert arnoldi method 29 24 rational krylov method 36 used one way reduce impact start icrks method initial vector v 1 poor eigenspace corresponding achieved selecting arbitrary eigenvalue fl nearest gamma01 computed use icrks fig 32 fixed pole gamma01 linear systems solved gmres preconditioned initial vector v 1 computed system using gmresilut solver algorithm stopped kr j numerical results shown table 41 inexact rational krylov ic rks inexact inverse iteration using cayley transform first note kf j k kakkg j k kg j k measure rks residual see also 28 also note icrks inverse iteration sequences kr j k ks j k decrease methods converge finally note icrks faster inverse iteration 5 relation inexact shiftinvert cayley transforms previous section showed inexact rational krylov method used computation eigenvalues matrix pencil example shows substantial difference convergence behavior shiftinvert cayley transforma tions section show appropriate shiftinvert transformation may also employed step icrks following relationship results j residual linear system approximately solved rearranging 51 adding j j sides gives equivalent shiftinvert system inexact rational krylov sequence method 15 hence zero vector used initial guess iterative method linear systems approximately solved via cayley transform gammay j used shiftinvert transformation formulation assume constant icrks converges eigenpair 313 follows shiftinvert used convergence eigenpair attained decreasing j increases context inexact inverse iteration lai lin lin 20 also observe approximate linear system solver requires increasingly tighter tolerance residual linear system number inverse iterations increases contrast cayley transformation allows us use fixed tolerance linear system residual 6 connection jacobidavidson method show connection jacobidavidson 14 39 38 rks 32 methods consider linear system j gamma1 ritz vector interest amounts selecting jth continuation vector j gamma1 algorithm icrks figure 32 associated ritz value righthand side 61 residual eigenpair j j orthogonal j since interested expanding search space span columns v j multiply sides equation 61 projector gamma using fact results component w direction j play role w added subspace rv j thus interested finding component w orthogonal j linear system solved instead jacobidavidson method calls equation 62 correction equation suppose x j computed solution equation 62 residual j given j orthogonal j rewrite 63 j orthogonality j j leads 6 r b lehoucq k meerbergen choosing zero jacobidavidson rks methods cayley transformations used j computed solution jacobidavidson correction equation x inserted rks method note although ritz vector j orthogonal righthand side jacobidavidson correction equation 62 j orthogonal righthand side 64 advantage inexact rational krylov method matrices k j require explicit application andor b needed jacobidavidson method efficient implementation jacobidavidson method requires dot products first elements last row v h caution reader conclude jacobidavidson method expensive variant icrks fits icrks framework detailed numerical comparison two methods requires examining respective rates convergence ability obtain relative residual reductions linear solves subject future work 7 conclusions paper studied use approximate linear solves within ruhes rational krylov sequence method analysis convergence inexact inverse iteration showed importance using cayley transformation instead usual shiftinvert transformation linear systems solved given relative residual tolerance theoretical link inexact rational krylov method uses generalized cayley transformations jacobidavidson methods drawn resulting connection correction equation cayley transformation called eigenpairs computed icrks inexact ritz pairs ritz pairs perturbed rks method classical properties galerkin projection lost due inexactness since icrks solves perturbed problem application techniques developed rks method using approximate linear solves may employed techniques include use complex poles zeros real b 31 harmonic ritz pairs deflation purging 32 36 implicit application rational filter 36 acknowledgments authors thank dirk roose financial support allowed first author visit second author visit initiated collaboration lead article authors also thank gorrik de sambanx gerard sleijpen referees helpful comments suggestions improved quality article particular one referees provided numerous contructive criticisms improved quality presentation r principle minimized iterations solution matrix eigenvalue problem templates solution linear systems building blocks iterative methods subspace preconditioning algorithm eigenvectoreigenvalue computation reorthogonalization stable iterative calculation lowest eigenvalues corresponding eigenvectors large real symmetric matrices unsymmetricpattern multifrontal method sparse lu factor ization combined unifrontalmultifrontal method unsymmetric sparse matrices supernodal approach sparse partial pivoting me28 sparse unsymmetric linear equation solver complex equations design ma48 design new frontal code solving sparse unsymmetric systems spectral transformation lanczos method numerical solution large sparse generalized symmetric eigenvalue problems iterative solution linear systems qmrpack package qmr algorithms matrix computations convergence rate estimates iterative methods mesh symmetric eigenvalue problem preconditioned gradienttype iterative methods subspace partial generalized symmetric eigenvalue problem inexact inverse iteration large sparse eigenvalue problems arpack users guide solution large scale eigenvalue problems implicitly restarted arnoldi methods matrix transformations computing rightmost eigenvalues real nonsymmetric matrices restarted arnoldi method applied iterative linear system solvers computation rightmost eigenvalues implicitly restarted arnoldi purification shiftinvert transformation davidsons method preconditioning generalized eigenvalue problems generalizations davidsons method computing eigenvalues large nonsymmetric matrices implement spectral transformation bifurcation memory improving spectral transformation block arnoldi method rational krylov sequence methods eigenvalue computation rational krylov algorithm nonsymmetric eigenvalue problems rational krylov tool kit sparse matrix computations iterative methods sparse linear systems gmres generalized minimal residual algorithm solving nonsymmetric linear systems implicit application rational filter rks method jacobidavidson iteration method linear eigenvalue problems implicit application polynomial filters kstep arnoldi method truncated qz methods large scale generalized eigenvalue problems criteria combining inverse rayleigh quotient iteration tr ctr tsungmin hwang wenwei lin weicheng wang weichung wang numerical simulation three dimensional pyramid quantum dot journal computational physics v196 n1 p208232 1 may 2004