complexity analysis static analyses paper argues many algorithms static analysis algorithms particular bottomup logic program presentations clearer simpler analyze correctness complexity classical pseudocode presentations main technical contribution consists two theorems allow many cases asymptotic running time bottomup logic program determined inspection well known datalog program runs onk time k largest number free variables single rule theorems given significantly refined variety algorithms presented analyzed examples b introduction paper argues many algorithms static analysis algorithms particular bottomup logic program presentations clearer simpler alyze correctness complexity classical pseudocode presenta tions static analysis algorithms natural representations bottomup logic programs ie inference rules forwardchaining procedural inter pretation technical content paper consists two metacomplexity theorems allow many cases running time bottomup logic logic program determined inspection paper presents analyzes variety static analysis algorithms natural presentations bottomup logic programs examples running time bottomup presentation determined metacomplexity theorems given either best known within polylog factor best known use term inference rule mean first order horn clause ie first order formula form 1 c c first order atom ie predicate applied first order terms first order horn clauses form turing complete model computation used practice general purpose programming language atoms 1 called antecedents rule atom c called conclusion using inference rules programming language one represents arbitrary data structures first order terms example one represent terms lambda calculus arbitrary formulas first order logic first order terms underlying programming language restriction first order terms way rules construction rules defining static analyses higher order languages two basic ways view set inference rules algorithm backward chaining approach taken traditional prolog interpreters 13 4 forward chaining bottomup approach common deductive databases 23 22 18 metacomplexity analysis derives bottomup approach simple example consider rule p x p states binary predicate p transitive let set assertions form c constant symbols generally use term assertion mean ground atom ie atom containing variable use term database mean set assertions set r inference rules database let rd denote set assertions proved obvious way assertions using rules r r consists rule transitivity consists assertions form p c rd simply transitive closure bottomup view rule set r taken algorithm computing output rd input interested methods quickly determining running time rule set r ie time required compute rd exam ple consider following algorithm computing transitive closure predicate edge defined bottomup rules edgex pathx z input graph contains e edges algorithm runs oen time significantly better 3 sparse graphs note oen running time derived simply counting number variables single rule section 4 gives metacomplexity theorem applies arbitrary rule sets allows oen running time algorithm determined inspection simple rule set oen running time may seem obvious examples given throughout paper metacomplexity theorem used cases completely rigorous treatment running time rule set would otherwise tedious metatheorem proved section 4 states rd computed time proportional number prefix firings rules r number derivable ground instances prefixes rule antecedents theorem holds arbitrary rule sets matter complex antecedents many antecedents rules provided every variable conclusion rule appears antecedent rule presenting first significant metacomplexity theorem section 4 section 3 reviews known metacomplexity theorem based counting number variables single rule used syntactically local rule sets ones every term conclusion rule appears antecedent basic properties syntactically local rule sets also mentioned briefly section 3 fact syntactically local rule sets express polynomial time decidable term languages sections 4 gives first significant metacomplexity theorem basic examples including cky algorithm contextfree parsing although paper focuses static analysis algorithms variety parsing algorithms eisner sattas recent algorithm bilexical grammars 6 simple complexity analyses based metacomplexity theorem given section 4 section 5 gives series examples program analysis algorithms expressed bottomup logic programs first example basic data flow algorithm computes dynamic transitive closure transitive closure operation new edges continually added underlying graph computation proceeds many dynamic transitive closure algorithms shown 2npdacomplete 11 17 2npda class languages recognized twoway nondeterministic pushdown automaton problem 2npdacomplete class 2npda furthermore property solved subcubic time problem 2npda also solved subcubic time 2npdacomplete problem known solvable subcubic time section 5 also presents linear time subtransitive data flow algorithm applied programs typable nonrecursive data types bounded size combined control data flow analysis algorithm calculus examples metacomplexity theorem section 4 allows running time algorithm determined inspection rule set section 6 presents second main result paper metacomplexity theorem extended bottomup programming language incorporating unionfind algorithm three basic applications metacomplexity theorem unionfind rules presented section 7 unification algorithm congruence closure algorithm type inference algorithm simply typed calculus section 8 presents hengleins quadratic time algorithm typability version abadicardelli object calculus 12 example interesting two reasons first algorithm obvious first published algorithm problem used 3 dynamic transitive closure algorithm 19 second hengleins presentation quadratic algorithm uses classical pseudocode fairly complex show algorithm presented naturally small set inference rules whose 2 running time easily derived unionfind metacomplexity theorem assumptions mentioned introduction use term assertion mean ground atom ie atom containing variables use term database mean set assertions also mentioned introduction rule set r database let rd set ground assertions derivable using rules r write r phi alternative notation phi 2 rd use jdj number assertions jjdjj number distinct ground terms appearing either arguments predicates assertions subterms arguments ground substitution mapping finite set variables ground terms paper consider ground substitutions oe ground substitution defined variables occurring term oet defined standard way result replacing variable image oe also assume expressions terms atoms represented interned dag data structures means term always represented pointer memory equality testing unit time operation furthermore assume hash table operations take unit time substitution oe defined x compute pointer representing oefx unit time note interned expressions support indexing example given binary predicate p index assertions form p w data structure representing points list terms w p w asserted conversely terms w point list terms p w asserted concerned rules written intention defining bottomup algorithms intuitively bottomup logic program variable conclusion appear antecedent unbound assigned value rule runs although unbound variables conclusions well defined semantics writing rules used bottomup way always possible avoid variables rule variables conclusion appear antecedent called bottomup bound paper consider bottomup bound inference rules datalog rule one contain terms variables syntactically local rule one every term conclusion appears antecedent either argument predicate subterm argument every syntactically local rule bottomup bound every bottomup bound datalog rule syntactically local however rule bottomup bound syntactically local note converse syntactically local giving main results paper apply arbitrary rule sets give first naive metacomplexity theorem theorem applies syntactically local rule sets every term conclusion syntactically local rule appears antecedent follows syntactically local rule never introduce new term implies r syntactically local database rd finite precisely following theorem 1 r syntactically local rd computed ojdj largest number variables occurring single rule prove theorem one simply notes suffices consider set ground horn clauses consisting assertions unit clauses plus instances rules r terms appear ojjdjj k instances computing inferential closure set ground clauses done linear time 5 oen transitive closure example introduction shows theorem 1 provides crude upper bound running time inference rules presenting second metacomplexity theorem however briefly mention addition properties local rule sets used remainder paper included sake completeness first property syntactically local rule sets capture complexity class p say rule set r accepts term inputt r acceptt theorem implies language accepted syntactically local rule set polynomial time decidable following less trivial theorem proved 8 states converse polynomial time property firstorder terms encoded syntactically local rule set theorem 2 givan mcallester l polynomial time decidable term language exists syntactically local rule set accepts exactly terms l second subject mention briefly call semantic locality rule set r called semantically local whenever r phi exists derivation phi assertions using rules r every term derivation appears every syntactically local rule set semantically local reasoning used prove theorem 1 r semantically local rd computed ojdj largest number variables single rule many cases possible mechanically show given rule set semantically local even though syntactically local 15 2 however semantic locality general undecidable property rule sets 8 4 second metacomplexity theorem prove second metacomplexity theorem say database e closed rule set r would seem determining closedness would easier computing closure cases yet closed metacomplexity theorem states essence closure computed quickly computed time needed merely check closedness final result consider rule 1 c check database e closed rule one compute ground substitutions oe e check oec also e find substitutions first match pattern 1 assertions database get substitutions oe 1 oe 1 given oe oe e match oe assertions database get extensions oe i1 oe i1 e substitution oe determines prefix firing rule defined definition 1 define prefix firing rule rule set r database e ground instance initial sequence contained let pr e set prefix firings rules r database e note rule p x might large number firings first two antecedents firings three antecedents simple algorithm outlined checking e closed r requires least jp r ej steps computation outlined closure check algorithm would actually require time step extending oe oe i1 involves iterating entire database following theorem states compute rd time proportional jdj plus rdj theorem 3 set r bottomup bound inference rules exists algorithm mapping rd runs ojdj jp r rdj time proving theorem 3 consider simple applications consider transitive closure algorithm defined inference rules edgex pathx edgex pathy z pathx z r consists two rules consists e assertions form edgec involving n constants immediately jp r rdj oen theorem 3 immediately implies algorithm runs oen time parsesu consa j parsesb parsesc j fig 1 cockekasimiyounger cky parsing algorithm parsesu means substring j parses nonterminal u second example consider algorithm context free parsing shown figure 1 grammar given chomsky normal form consists set assertions form x x z input sting represented lisp list form consa input string specified assertion form inputs let g number productions grammar let n length input string theorem 3 immediately implies algorithm runs ogn 3 time note rule six variables three string index variables three nonterminal variables give proof theorem 3 proof based source source transformation given program note following source source transformations inference rules preserve quantity jdjjpr rdj function multiplicative constant second transformation note must least one element p r rd assertion rd hence adding rule single antecedent fresh predicate conclusion doubles value jdj jp r rdj second transformation done two steps first add new rule replace antecedent existing rule similar analysis holds third transformation free variables 1 2 least one nonvariable x free variables variables among x among variables occur x variables among among x transformations allow us assume without loss generality multiple antecedent rules form p x multiple antecedent rule create index enumerate values x p x asserted also enumerate values z qy z asserted new assertion form p x qy z derived iterate possible values missing variable time proportional number values 5 basic examples figure 2 gives simple firstorder data flow analysis algorithm algorithm takes input set assignment statements form assignx e x program variable e either constant expression form constantn tuple expression form hy zi z program variables projection expression form pi 1 pi 2 program variable consider database containing e assignment assertions involving n program variables pair expressions clearly first rule upper left corner e firings transitivity rule n 3 firings two rules en firings since e 2 theorem 3 implies algorithm given figure 2 runs 3 time possible show determining whether given value reach given variable defined rules figure 2 2npda complete 11 17 2npda class languages recognizable twoway nondeterministic pushdown automaton language l called 2npdahard problem 2npda reduced l n polylog n time say problem solved subcubic time solved k 3 2npda hard problem solved subcubic time problems 2npda solved subcubic time data flow problem 2npdacomplete sense class 2npda 2npdahard cubic time impractical many applications problem changed slightly require assignment statements well typed using types bounded size problem determining given value reach given variable solved linear time done sub transitive data flow analysis 10 firstorder setting rules figure 2 use types defined following grammar h note grammar allow recursive types linear time analysis extended handle list types recursive types giving analysis weaker figure 2 simplicity avoid recursive types consider database containing assignment statements described subject constraint must possible assign every variable type every assignment well typed example database contains assignx hy zi x must type h oei oe types z respectively similarly database contains must type form h oei type assumptions use inference rules given figure 3 note rules figure 3 syntactically local inference rule lower right contains term conclusion namely pi j e 2 contained antecedent rules introduce new terms however difficult see rules maintain invariant every derived assertion form e 1 e 2 e 1 e 2 fig 2 data flow analysis algorithm rule involving pi j abbreviation two rules one pi 1 one pi 2 fig 3 subtransitive data flow analysis rule multiple conclusions represents multiple rules one conclusion z fig 4 determining existence path given source fig 5 flow analysis algorithm calculus pairing rules intended applied initial database containing single assertion form inpute e closed calculus term ffrenamed distinct bound variables distinct names note rules rules syntactically local every term conclusion appears antecedent hence terms derived assertions subterms input term rules compute directed graph subterms input type implies every newly introduced term must well typed example rules construct expression pi 1 pi 2 x x must type form h hoe jii since type expressions finite finitely many well typed terms inference process must terminate fact variable type involving b syntax nodes inference process terminates linear time see suffices observe rules maintain invariant every derived assertion involving form pij assertion e 1 derived directly assignment using one rules left hand side figure type x b syntax nodes input assignment form assignx e lead b derived assertion n assignments input database bn derived assertions involving easy check inference rule bn firings theorem 3 algorithm runs obn time possible show rules construct directed graph whose transitive closure includes graph constructed rules figure 2 determine given source value flows given variable need simply determine path source variable well known one determine linear time whether path exists given source node node directed graph however also note computation done algorithm shown figure 4 fact algorithm figure 4 runs linear time guaranteed theorem 3 another example figure 5 gives algorithm control data flow calculus extended pairing projection operations rules implement form set based analysis 1 9 rules also used determine given term typable recursive types function pair ing union types 16 using arguments similar relating control flow analysis partial types 14 20 detailed discussion precise relationship rules figure 5 set based analysis recursive types beyond scope paper primarily concerned complexity analysis algorithm rules transitivity rule prefix firings transitivity rule n 3 firings hence theorem 3 implies algorithm runs 3 time possible give subtransitive flow algorithm analogous rules figures 5 runs linear time assumption input expression well typed every type expression bounded size 10 however subtransitive version figure 5 beyond scope paper 6 algorithms based unionfind variety program analysis algorithms exploit equality perhaps fundamental use equality program analysis use unification type inference simple types examples include nearly linear time flow analysis algorithm bondorf jorgensen 3 quadratic type inference algorithm abadicardelli object calculus given henglein 12 dramatically improvement empirical performance due equality reported fahndrich et al 7 formulate general approach incorporation unionfind methods algorithms defined bottomup inference rules section give general metacomplexity theorem union find rule sets let union find merge three distinguished binary predicate sym bols predicate union appear rule conclusions rule tecedents predicates find merge appear rule antecedents rule conclusions bottomup bound rule set satisfying conventions called unionfind rule set intuitively assertion form unionu w conclusion rule means u w made equivalent assertion form mergeu w means point union operation applied u w time union operation u w equivalent assertion findu f means point find u value f given database define merge graph undirected graph containing edge w either merges w mergew database path w merge graph say w equivalent say database unionfind consistent every term whose equivalence class contains least two members exists unique term f every term w equivalence class database contains findw f unique term called find note database containing merge find assertions unionfind consistent define result performing union operation terms unionfind consistent database already equivalent union operation effect equivalent union operation adds assertion merges plus assertions form findw f w equivalent either f find larger equivalence class either equivalence class contains one member otherwise f term fact find value second argument equivalence classes singleton significant complexity analysis unification congruenceclosure algorithms note either class contains one member w larger class assertion findw f need added appropriate indexing union operation run time proportional number new assertions added ie size smaller equivalence class also note whenever find value term changes size equivalence class term least doubles implies given term number terms f e contains finds f log base 2 size equivalence class course practice one erase obsolete find assertions term one assertion form finds f however find assertions generate conclusions erased erasure process improve bound given theorem 4 fact erasure makes theorem difficult state order allow relatively simply metacomplexity theorem erase obsolete find assertions define clean database one containing merge find sertions given unionfind rule set r clean database say database e rclosure e derived repeatedly applying rules r including rules result union operations application rules r changes e unlike case traditional inference rules unionfind rule set many possible closures set derived assertions depends order rules used example derive three union operations unionu w unions w unionu merge graph contain two arcs graph depends order union operations done rules used derived assertions merge assertions arbitrary relations depend order inference algorithms however correctness analysis running time analysis done independently order rules run present general metacomplexity theorem unionfind rule sets theorem 4 unionfind rule set r exists algorithm mapping rclosure denoted rd runs time ojdj jp r rdj jf rdj f rd set find assertions rd proof essentially identical proof theorem 3 source tosource transformation applied r show without loss generality need consider single antecedent rules plus rules form z variables p q r predicates union find merge rules union assertion conclusion argument rules union operations conclusion handled using union operation unit cost prefix firing leading redundant union operation cost nonredundant operation proportional number new find assertions added 7 basic unionfind examples figure 6 gives unification algorithm essence unification problem pair hs ti unified hu wi one must recursively unify u w rules guarantee hs ti equivalent hu wi u equivalent term pi 1 f f common find two pairs similarly w must also equivalent rules compute appropriate equivalence relation unification however rules detect clashes occurscheck failures done performing appropriate lineartime computations final find map analyze running time rules figure 6 first note rules maintain invariant find values terms appearing input prob lem implies every union operation either form unions w unionpi w w appear input problem let n number distinct terms appearing input fig 6 unification algorithm algorithm operates simple terms defined either constant variable pair simple terms input database assumed set assertions form equates w w simple terms rules generate appropriate equivalence relation unification generate clashes occurscheck failures see text unionx selects find value arguments singleton equivalence classes rules maintain invariant find values terms original input fig 7 congruence closure algorithm input database assumed consist set assertions form equates w inputs w simple terms defined caption figure 6 figure 6 find values terms original input fig 8 type inference simple types input database assumed consist single assertion form inpute e closed term pure calculus distinct bound variables ffrenamed distinct names case unification algorithm rules construct appropriate equivalence relation types occurscheck resulting equivalence relation must done elsewhere terms involved equivalence relation defined merge graph given term number assertions form finds f log base 2 size equivalence class log n find assertions closure implies log n prefix firings theorem 4 implies closure computed log n time best known unification algorithm runs time 21 best online unification algorithm runs onffn time ff inverse ackermanns function application theorem 4 rules figure 6 yields slightly worse running time perhaps simpler presentation consider congruence closure algorithm given figure 7 first consider correctness fundamental property congruence closure equivalent 0 equivalent 0 pairs hs ti appear input hs ti equivalent hs fundamental property guaranteed lower right hand rule figure 7 rule guarantees hs ti hs occur input equivalent 0 0 hs ti hs equivalent hf common find 0 f 2 common find 0 algorithm computes congruence closure equivalence relation analyze complexity rules figure 7 first note case unification rules maintain invariant every find value input term given one see terms involved equivalence relation either input terms pairs input terms implies 2 terms involved equivalence relation n number distinct terms input given term number assertions form finds f ologn number firings congruence rule log 2 n implies number terms involved equivalence relation actually log 2 n since term appear left hand side olog n find assertions log 3 n find assertions theorem 4 implies closure computed log 3 n time possible show erasing obsolete find assertions algorithm made run log n time best known running time congruence closure leave reader verify inference rules figure 8 define appropriate equivalence relation types program expressions types constructed linear time find relation output procedure clear inference rules generate union operations hence closure computed log n time 8 hengleins quadratic algorithm consider hengleins quadratic time algorithm determining typability variant abadicardelli object calculus 12 algorithm interesting first algorithm published problem classical dynamic transitive closure algorithm requiring 3 gleins presentation quadratic algorithm given classical pseudocode fairly complex fig 9 hengleins type inference algorithm simple unionfind rule set hengleins algorithm given figure 9 first define type expressions grammar oe ff j ff represents type variable intuitively object type provides slot field slot name slot name slot value type oe algorithm takes input set assertions type constraints form oe 1 oe 2 oe 1 oe 2 type expressions take type object slots note given null type base type infinitely many closed type expressions ie type expressions containing variables algorithm decide whether exists interpretation fl mapping type variable closed type expression constraint oe 1 oe 2 floe 1 subtype floe 2 subtype relation taken invariant ie closed type subtype closed type equal j rules figure 9 assume input preprocessed type expression appearing input either top level subexpression top level type expression database also includes assertions form accepts note preprocessing done linear time invariance property subtype relation justifies final rule lower right figure 9 system constraints rejected equivalence relation forces type subexpression ie occurscheck type expressions fails final database contains oe accepts analyze complexity algorithm figure 9 note terms involved equivalence relation type expressions appearing processed input expression either type expression original unprocessed input form oe oe original input slot name appearing top level oe let n number assertions processed input note preprocessing guarantees least one input assertion type expression number type expressions appearing input also since terms involved equivalence relation rules generate merge assertions implies rules generate assertions form oe implies number prefix firings 2 since terms involved equivalence relation log n find assertions closure theorem 4 implies running time 2 n log 9 conclusions paper argued many algorithms natural presentations bottomup logic programs presentations clearer simpler analyze correctness complexity classical pseudocode pre sentations variety examples given analyzed examples suggest variety directions work case unification hengleins algorithm final checks performed postprocessing pass possible extend logic programming language ways allow algorithms fully expressed rules stratified negation failure would allow natural way inferring notacceptsoe hengleins algorithm preserving truth theorems 3 4 would allow acceptability check done rules simple extension unionfind formalism would allow detection equivalence distinct constants hence allow rules unification detect clashes might also possible extend language improve running time cycle detection strongly connected component analysis directed graphs another direction work involves aggregation would nice language features metacomplexity theorems allowing natural efficient renderings dijkstras shortest path algorithm inside algorithm computing probability given string probabilistic context free grammar r typing conditional types automated complexity analysis based ordered resolution efficient analysis realistic offline partial evalu ation logic programming schemes implementations time algorithms testing satisfiability propositional horn formulae efficient parsing bilexical contextfree grammars head automaton grammars partial online cycle elimination inclusion constraint graphs new results local inference relations based analysis ml programs linear time subtransitive control flow anal ysis cubic bottleneck subtyping flow analysis breaking n 3 barrier faster object type inference predicate logic programming language efficient inference partial types automatic recognition tractability inference relations inferring recursive types intercovertability set constraints context free language reachability efficient inference object types type system equivalent flow analysis linear unification complexity relational query languages tr compilers principles techniques tools old resolution tabulation magic sets strange ways implement logic programs extended abstract alexander methoda technique processing recursive axioms deductive databases bottomup beats topdown datalog finite presentation theorem approximating logic programs typing conditional types setbased analysis ml programs xsb efficient deductive database engine efficient inference partial types type system equivalent flow analysis efficient inference object types tabled evaluation delaying general logic programs modern compiler implementation java lineartime subtransitive control flow analysis interconvertbility set constraints contextfree language reachability partial online cycle elimination inclusion constraint graphs breaking italicnitalicsubscrpt3subscrptbarrier efficient unification algorithm algorithm reasoning equality abstract interpretation theory objects cubic bottleneck subtyping flow analysis complexity relational query languages extended abstract ctr dan melamed multitext grammars synchronous parsers proceedings conference north american chapter association computational linguistics human language technology p7986 may 27june 01 2003 edmonton canada jens palsberg tian zhao trevor jim automatic discovery covariant readonly fields acm transactions programming languages systems toplas v27 n1 p126162 january 2005 pablo lpez frank pfenning jeff polakow kevin watkins monadic concurrent linear logic programming proceedings 7th acm sigplan international conference principles practice declarative programming p3546 july 1113 2005 lisbon portugal markjan nederhof giorgio satta language intersection problem nonrecursive contextfree grammars information computation v192 n2 p172184 august 1 2004