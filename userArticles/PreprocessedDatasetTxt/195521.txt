trapdriven simulation tapeworm ii tapeworm ii softwarebased simulation tool evaluates cache tlb performance multipletask operating system intensive workloads tapeworm resides os kernel causes host machines hardware drive simulations kernel traps instead address traces conventionally done allows tapeworm quickly accurately capture complete memory referencing behavior limited degradation overall system performance paper compares trapdriven simulation implemented tapeworm common technique tracedriven memory simulation respect speed accuracy portability flexibility b introduction tracedriven simulation probably popular method evaluating memory system architectures consisting caches tlbs smith82 holliday91 technique worked well design memory systems supporting singletask user intensive applications found spec benchmark suite gee93 spec91 however growing body work showing memory systems tuned type work trapdriven simulation tapeworm ii richard uhlig david nagle trevor mudge stuart sechrest department electrical engineering computer science university michigan email uhligeecsumichedu bassooneecsumichedu work supported defense advanced research projects agency darpaaro contract number daal0390c0028 national science foundation cise research instrumentation grant cda 9121887 digital equipment corporation grant national science foundation graduate fellowship load perform well interactive digitalmedia appli cations distributed file systems databases require frequent interaction operating system tasks agarwal88 anderson91 chen93a cvetanovic94 mogul91 nagle93 nagle94 uhlig94b ousterhout89 unfortunately tracedriven simulation tools limited single usermode tasks thus cannot capture significant portion memory system activity applications tracedriven simulators oscapable tend rely expensive hardware monitoring equipment generally portable developed softwarebased tool called tapeworm ii attempts overcome limitations tapeworm simulations driven traces traps operating system kernel tapeworm resides kernel trap corresponds simulated tlb cache miss approach three principal advantages 1 completeness 2 speed 3 portabil ity tapeworm simulations complete traps originate user task even os kernel tapeworm fast simulator invoked uncommon case tlb cache misses finally tapeworm software based ported system provides support certain primitives despite advantages method suffer certain drawbacks although capable simulating tlbs caches different sizes associativities trapdriven simulation generally less flexible tracedriven approaches respect simulation architectural structures write buffers instruction pipelines tapeworms presence system also introduces new forms measurement bias though strictly disadvantage trapdriven simulations also sensitive inherent variations memory system performance issue generally ignored tracedriven simulation studies paper presents detailed description tapeworm design section 3 uses prototype compare strengths weaknesses trapdriven simulation tracedriven simulation section 4 begin discussion related work next section related work capture multitask os activity memory architecture studies traditionally relied hardware instrumentation tech appear 6th international conference architectural support programming languages operating systems asplosvi october 57 1994 san jose california niques either attach extra hardware running system modify existing hardware microcode designed architecture agarwal86 alexander85 clark83 cvetanovic94 flanagan92 nagle92 torrellas92 unfortunately hardware approaches costly implement usually tied single machine overcome limitations recent research extended softwareonly instrumentation techniques include multiprocess os activity mogul borg describe system task multitask workload instrumented make entries systemwide trace buffer mogul91 amodified operating system kernel interleaves execution different userlevel workload tasks according usual scheduling policies invokes memory simulator whenever trace buffer becomes full chen extended technique include annotation os kernel thus enabling complete accounting system activity chen93b simulators avoid traces entirely driven instead kernel traps tools use privileged machine operations cause underlying host hardware filter hits simulated memory structure trap simulator miss one example approach first generation tapeworm performs tlb simulation nagle93 uhlig94a system intercepts kernel traps softwaremanaged tlb miss handlers r2000based decstation drive tlb simulator user kernel misses intercepted tapeworm able fully consider multitask os effects different tlb configurations talluri describes similar trapdriven tlb simulator runs sparcbased workstations talluri94 another example wisconsin wind tunnel wwt simulator also based kernel traps set cleared modifying errorcorrecting code ecc check bits sparcbased cm5 reinhardt93 unlike tapeworm performs uniprocessor simulations includes multitask kernel references wwt designed investigate multiprocessor cache coherence algorithms capture os activity work shares properties tracedriven trapdriven simulation cmelik94 lebeck94 martonosi92 hybrid approaches annotate program invoke simulation handlers every memory reference systems simulations optimized calling null handler memory locations known simulated cache tlb paper advances previous work two significant ways first describes design secondgeneration tapeworm combines oscapable features original tapeworm tlb simulator wwtlike mechanism setting finegrained memory traps resulting simulator capable cache tlb simulation captures multitask os kernel activity second using tapeworm prototype investigate positive negative aspects trapdriven simulation general paper primarily study pros cons trap driven simulation examples actual studies operating system architecture interactions used tapeworm see nagle93 nagle94 uhlig94b 3 tapeworm design 31 tapeworm algorithm tapeworm simulation algorithm best explained contrasting essential features traditional tracedriven simulator shall use term cache following dis cussion although methods apply equally well tlb simulation core tracedriven simulation executes loop similar shown left side figure 1 processing steps include obtaining next address trace searching address simulated cache invoking replacement policy event miss trace addresses come file created traceextraction tool might generated fly annotated workload agarwal86 borg90 chen93b cmelik94 eggers90 holliday91 hsu89 larus90 larus93 magnusson93 mips88 mogul91 sites88 smith91 search procedure involves indexing data structure represents cache depending associativity cache performing one comparisons test hit though simple operation search test must performed every address trace tapeworm operates different principle driven address traces traps operating system kernel tapeworm resides tapeworm begins simulation setting traps memory locations workloads address space locations traps set represent memory locations currently resident simulated cache structure workload executes first reference location causes trap kernel directed tapeworm simulator traps represent simulated cache misses need search data structure representing simulated cache tapeworm simply counts miss clears trap required memory location clearing trap effectively caches memory location figure 1 tracedriven versus trapdriven simulation algorithms core execution loops tracedriven trapdriven simulators code abstracts away many details actual simulation treatment writes assigning penalties different types misses eg criticalwordfirst cache singlepass simulators usi ng stack algorithms also complex structure mattson70 sugumar93 thompson89 trapdriven kernel traps invoke twmissaddress twmissaddress tracedriven address nextaddresstrace searchaddress else simulated cache structure subsequent references location trap proceed full hardware speed tapeworm sets new trap different memory location accordance replacement policy emulate displacement simulated cache structure tapeworm design offers number advantages tracedriven simulation first annotation rewriting workload required traps dynamically set cleared workload runs second tapeworms kernel privileges allow easily set traps userlevel task well kernel enables study multitask os interactions third tapeworm uses underlying hardware filter hits simulated cache structure provide speed advantages conventional tracedriven simulation see section 41 32 tapeworm primitives although outlined core tapeworm algorithm number important details mechanisms setting memory traps policies registering workload pages tapeworm need clarified table 1 describes key tapeworm primitives tapeworm operations setting clearing traps performed twsettrap twcleartrap implemented many machines using various privileged operations intended diagnostics debugging see table 2 example trap set using diagnostic mode alter parity bits given memory location rein hardt93 subsequent use memory location result memory parity error trap trap cleared restoring correct parity memory location mechanisms table 1 tapeworm primitives detail routine description set memory trap starting pa physical address extending size bytes subsequent use memory locations region trap kernel pass control tapeworm previously set memory traps starting pa extending size bytes subsequent use memory region workload may proceed uninterrupted twregisterpagetid p v register page tapeworm page added setting traps physical memory locations starting page address p task id tid virtual physical page mapping defined pv recorded tapeworm enable virtuallyindexed physicallyindexed cache simulations twremovepagetid p v remove page define tid p v tapeworm domain page removed flushing simulated cache clearing traps memory locations twattributestid simulate inherit set tapeworm attributes task identified tid tid zero signifies kernel nonzero value simulate registers task tapeworm nonzero value inherit indicates initial value simulate attribute children task twreplacetid pa va insert missing memory location defined pa physicallyindexed cache va virtuallyindexed cache data structure simulated cache needed tid used form part cache tlb tag displaced entry selected basis various simulation parameters cache size line size associativity returned call instruction data breakpoints page valid bits work equally well supported host hardware twsettrap twcleartrap accept size parameter support range simulation parameters various page sizes tlb simulation various line sizes cache table 2 privileged operations useful trapdriven simulation table summarizes privileged operations useful building blocks trapdriven memory simulator common operations many existing architectures see table 12 privileged operation description memory parity ecc traps trap os kernel detecting memorypar ity error read write operations enable software change parity bits associated memory location instruction break point trap os kernel breakpoint instruction encountered data breakpoint trap os kernel specific data memory location read written size support different sized pages typical page sizes range 128 byte 1mbyte ns r uc counters count total number instructions executed processor simulation actual trapping mechanism selected underlying implementation routines depends size trap required tlb simulation granularity large page valid bits effective particularly machine supports variable page sizes memory parity traps breakpoints perhaps set clusters one best choice cache sim ulation required granularity order cache line using memory parity ecc check bits cause kernel traps interfere intended purpose detecting true memory errors practice problem memory errors frequent possible distinguish true ecc errors caused tapeworm experience neither condition true tapeworm inactive system runs logged one true singlebit ecc error nearly year operation even tapeworm active correctly detects true memory errors high probability 1 noted previously workloads require previous modification tapeworm simulation traps set cleared dynamically tasks run work tapeworm requires assistance os virtual memory vm system task faults first access page vm system registers page tapeworm using twregisterpage call page marked valid vm system sets traps memory locations page future references parts page invoke tapeworm cache miss handler 2 parallel routine called twremovepage used vm system remove pages tapeworm domain unmapped due task termination paging secondary storage twremovepage clears traps page flushes simulated cache mimics action performed vm system host machines real cache vm system maps one virtual page given physical page must still register mapping tapeworm using twregisterpage situation tapeworm increments reference count physical page set new memory traps enables new task benefit shared entries brought cache another task would happen real system similarly twremovepage decrements reference count flushes page simulated cache reference count reaches zero minor modification twregisterpage twremovepage primitives enables tapeworm support form cache set sampling enhance speed implemented tracedriven simulator set sampling uses filtered trace containing exactly addresses map certain subset cache sets kessler91 puzak85 misses locations used form estimators total number cache misses less trace used set sampling reduce tracedriven simulation times preprocessing overhead construct trace sample rather filter addresses software obtain sample tapeworm exploits trapping framework make host hardware perform function much lower cost accomplished modifying twregisterpage set traps memory locations map specific cache sets given sample memory loca 1 implementation tapeworm decstation 5000200 makes use singleerror correcting doubleerror detecting ecc code trap set flipping specific ecc check bit among 7 total check bits assigned 32 bits data tapeworm detects singlebit error 38 check data bit positions detects doublebit error knows true error occurred 2 case tlb simulation page valid bits may used tapeworm set traps extra bit maintained software indicate true state page resident physical memory tions part sample never cause miss traps effectively filtered simulation overhead result tapeworm slowdowns decrease direct proportion degree sampling additional benefit method different samples obtained simply changing pattern traps registered tapeworm pages tracedriven simulation full trace must reprocessed obtain new set sample tapeworm supports cache simulation workloads consisting multiple tasks control tasks included given simulation assigned twotapeworm attributes simulate inherit stored extended version os task data structure attributes set calling twattributes task identifier specifying task assign new attributes zero task identifier used indicate os kernel simulate zero default value task runs system without intervention tapeworm nonzero simulate indicates current future pages touched task must registered tapeworm via twregisterpage call second attribute inherit defines initial value simulate children task words task fork child task inherits tapeworm attributes parent follows childsimulate parentinherit childinherit parentinherit different settings simulate inherit pair useful common simulation situations example attribute set shell task workload started shell workloads children registered tapeworm shell task however excluded simulation inheritance mechanism greatly simplifies simulation workloads complex task fork trees sdet kenbus multistage optimizing compiler see table 4 another common attribute used task children simulated combination useful registering kernel pages tapeworm final primitive table 1 twreplace direct analogue replacement routine tracedriven simulator maintains data structure representing simulated cache inserting new entries selecting others displaced according predefined simulation parameters implemented entirely software simulation configurations restricted way tlb cache structure underlying host hardware example simulated caches may either smaller larger size caches underlying host machine larger simulated cache simply sets fewer traps workloads memory locations similar adjustments used twreplace simulate different line sizes associa tivities well complex cache structures including split unified multilevel caches additionally twreplace access actual virtualtophysical page mappings established vm system simulate either virtual physical cache indexing 33 design summary tapeworm kernel privileges works close cooperation vm system include pages task well kernel inheritance tapeworm attributes task fork greatly simplifies problem capturing activity complex multitask workload allowing different combinations tasks cache effects simulated tapeworm attributes enable experiments measure isolate task interference effects finally fully optimizing common case cache hits use set sampling tapeworm fast 4 tapeworm implementation experiences implemented tapeworm tlb instruction cache simulation mach 30 operating system kernel running mips r3000based decstation 5000200 hardware mechanisms selected set clear traps page valid bits ecc check bits section use implementation study effectiveness tapeworm design meeting three main goals simulation completeness speed portabil ity also discuss difficulties encountered implemen tation suggest inexpensive hardware support could increase tapeworms flexibility enhance speed validate accuracy tapeworm results assist computation metrics miss ratios use hardware monitoring system called monster based das 9200 logic analyzer nagle92 system allows us unobtrusively count total instructions stall cycles comparison tracedriven simulation use cache2000 memory simulator mips88 driven pixiegenerated traces smith91 note pixie generates userlevel address traces single task widespread use pixie makes representative tracedriven simulation environments table 3 table 4 summarize workloads used study exception spec92 benchmarks xlisp espresso eqntott common characteristic workloads consist multiple tasks andor spend significant fraction time executing os services 41 speed original implementation tapeworm miss handler written entirely c required 2000 cycles exe cute similar cycle counts 2500 similar operation wisconsin wind tunnel simulator lebeck94 optimized handler rewriting entirely assembly code bypassing usual kernel entry exit code new code requires execution stack saves minimal number registers careful coding final optimized handler requires 250 cycles handle simulated misses directmapped caches 4word line sizes see table 5 components time higher degrees associativity slightly increase time twreplace longer cache lines increase cost twsettrap twcleartrap simulating different cache sizes little effect times although 250 cycle cost kernel trap greater average cost gen table 3 workload summary benchmarks compiled ultrix mips c compiler version 21 level 2 optimization workload description xlisp lisp interpreter written c configured solve 8queens problem spec92 benchmark espresso boo l ean funct benchmark eqntott translates logical representation boolean equation truth table spec92 benchmark mpegplay mpegplay v20 berkeley plateau research group displays 610 frames compressed video file patel92 jpegplay xloadimage program written jim frost displays four jpeg images ousterhout john ousterhouts benchmark suite oust erhout89 sdet multiprocess system performance benchmark includes programs test cpu performance os performance io perfor mance spec sdm benchmark suite kenbus simulates user activity researchoriented software development environment spec sdm benchmark suite table 4 workload operating system summary monster monitoring system used obtain instruction counts fraction time spent different tasks experiments performed mach 30 kernel version mk77 userlevel bsd unix server version uk38 decstation x display server version 7 release 5 run time total elapsed time seconds user task count total number tasks created including x bsd server execution workload workload instr run time secs kernel bsd server server user tasks user task count espresso 534 2680 29 19 00 951 1 mpegplay 1423 9553 241 273 40 446 1 jpegplay 1793 8970 91 94 26 788 1 ousterhout 567 3789 480 314 00 206 15 sdet 823 4370 437 355 00 208 281 kenbus 176 2313 489 291 00 220 238 erate process trace address 40 60 cycles per address cache2000 pixie tapeworm traps occur misses tracedriven simulator must consider addresses whether hit miss suggests rough breakeven ratio 4 hits 1 miss 1 tapeworm becomes slower 1 breakeven point approximation amount processing differs hits misses average number cycles per address cache2000 varies depending ratio hits misses table 5 tapeworm miss handling time table shows total number cycles required handle tapeworm cache miss along components handler numbers instructions times simulation directmapped caches 4word line sizes comparison also show average number cycles per address hit miss cache2000 simu lation note average includes time generate addresses onthefly pixieannotated workload routine name instructions kernel trap return 53 cycles per miss tapeworm 246 cycles per address cache2000 53 cache2000 see bottom table 5 poorly performing caches exhibit miss ratios 020 higher tapeworm typically outperforms tracedriven simulation cache2000 moreover contrast tracedriven simulation tapeworm works better larger cache thus smaller miss ratio best measure overall simulation speed actual time required perform simulation interested comparisons onthefly simulation techniques able measure lengthy computations therefore define slowdown ratio simulation trap trace generation overhead run time uninstrumented workload overhead time added workload run either tapeworm pixie cache2000 normal workload run time unmodified run host machine decstation 5000200 figure shows tapeworm slowdowns vary cache size mpegplay workload comparison cache2000 simulators slowdowns decrease cache size increases different reasons tapeworm slowdowns decrease nearly zero larger caches number traps tapeworm miss handler approaches zero cache2000 slowdowns decrease slightly less manipulation data structures required hits search misses search replace however cache2000 slowdowns never fall 20 even largest caches smallest size cache figure 2 comparison tracedriven tapeworm slowdowns tapeworm slowdowns compared cache2000 simulation driven pixiegenerated instruction address traces simulation mpegplay different sizes directmapped instruction caches 4word lines 4 bytesword pixiecache2000 combination measure singletask workload tapeworm attributes set measure activity mpegplay task exclude x display server bsd unix server kernel references however slowdowns cases computed using total wallclock run time workload includes time x bsd servers cache size miss cache 2000 slowdowns tapeworm slowdowns slow cache size kbytes slowdown tapewormoverhead normal workload runtime slowdown pixie cache2000overhead normal workload runtime 1 kbyte miss ratio 0118 tapeworm still outperforms cache2000 factor 3 although simulations caches higher associativities larger cache lines increase tapeworm miss handling time slightly structures typically experience fewer misses overall thus actually lead faster simulation figure 3 shows tapeworm slowdowns broader range cache configurations slowdowns reported thus far simulations without sampling figure 3 illustrates speed benefits set sam pling give results smallest cache sizes noting tapeworm slowdowns larger caches sufficiently small avoid need sampling altogether notice slowdowns decrease direct proportion fraction sets sampled ever sampling increase measurement variance examine effect addition sources variation performance measurements next section 42 completeness accuracy section examine issues simulation accuracy begin illustrating importance including multitask kernel references comparing relative contributions different workload components user server kernel 1 overall icache miss counts isolating components way also able partially validate results comparing user component singleusertask workloads pixiedriven figure 3 tapeworm slowdowns different simulation configurations figures left show tapeworm slowdowns caches varying degrees associativity line sizes figure top shows benefits set sampling terms reduced slowdowns increasing degrees sampling notation 12 means half cache sets sampled figure 2 workload mpegplay g g g g g slowdown cache size kbytes g 4 word g g g g g slowdown cache size kbytes g 1way 4way 8way g g g g g slowdown cache size kbytes g 11 116 sampling cache2000 simulations next study problems measurement variation due os effects set sampling using various tapeworm features isolate measure effectively remove individual contributions effects overall measurement variance finally conclude comments measurement bias due tapeworms presence running system miss contributions workload components table 6 shows typical icache miss counts miss ratios workloads 4 kbyte cache table shows number misses kernel bsd x servers user tasks allowed run dedicated cache 2 activity column gives results workload components share single cache due cache interfer 1 user task mean several tasks children shell workload initiated lump tasks together simulations using tapeworm inheritance attribute server task x display server bsd server exist prior initiation workload refer server tasks kernel system components workload 2 cache shared multiple user tasks case kenbus sdet ousterhout ence among individual workload components sum individual miss columns less activity column note first spec92 benchmarks eqntott espresso exhibit low miss counts overall consistent previous observations many spec92 benchmarks require small icaches run well gee93 servers kernel contribute majority total misses even contribution total number misses negligible workloads mpegplay jpegplay sdet ousterhoutexhibit predominance server kernel misses much higher overall miss ratios ousterhout example total miss ratio 10 mostly due system components interference effects simulator considers usertask component ousterhout would incorrectly estimate icache miss ratio less 1 workload suite greater fraction misses coming user task xlisp incidentally performs much better cache slightly larger table miss count miss ratio contributions different workload components table gives number misses millions miss ratios parentheses different workload components data collected running separate trials workload run dedicated directmapped cache 4 kbytes 4word line whenever possible eg singletask workloads traces gives miss ratios predicted tracedriven simulation using pixiecache2000 activity gives total miss counts workload components share cache note cache interference effects values column greater sum individual components difference shown last column entitled interference miss ratios relative total number instructions workload instructions given workload component hence miss ratios individual component plus interference sum total miss ratio given activity workload traces user tasks servers kernel activity interference espresso 160 0003 180 0003 228 0004 196 0004 953 0018 349 0007 jpegplay 298 0002 314 0002 1458 0008 921 0005 3628 0020 935 0005 kenbus 750 0043 1189 0068 1278 0073 4570 0260 1353 0077 mpegplay 3763 0027 3791 0027 3392 0024 1927 0014 1125 0079 2139 0015 ousterhout 193 0003 1862 0033 2172 0038 6139 0108 1912 0034 sdet 2014 0024 2518 0031 1809 0022 1046 0127 4125 0050 xlisp 8577 0061 9002 0064 631 0004 298 0002 1358 0096 3655 0026 noted compared tapeworm miss counts user task components workload pixiedriven cache2000 simulations purposes validation wherever comparison possible ie singleusertask work loads tapeworm miss counts user portion workload nearly identical reported cache2000 shall see next sections measurement variation bias makes validating tapeworm results workload components eg servers kernel inherently difficult problem sources measurement variation tracedriven simulations trace given workload typically used repeatedly obtain performance measurements different memory configurations result tracedriven simulations exhibit variance simulation given memory configuration repeated however precise sequence traps drive tapeworm simulation impossi table 7 variation measured memory system performance measurements include 16 trials apiece taken using 18 set sampling consider activity including kernel servers simulations line directmapped physicallyindexed caches x mean number misses standard deviation trial set numbers parenthesis percent mean value range percent difference mean value minimum maximum workload minimum maximum range espresso 491 293 60 345 30 1372 180 1028 209 jpegplay mpegplay 5848 701 12 4734 19 6895 18 2161 37 ousterhout 3150 261 8 2709 14 3503 11 794 25 sdet 4128 877 21 3258 21 6348 54 3090 75 table 8 variation due set sampling table isolates degree set sampling vary cache performance measurements tapeworm removed sources variation considering activity espresso process kernel servers simulating virtuallyindexed caches 4word line directmapped two sets data points measurements without sampling consist 16 trials error bars plot represent one standard deviation size kbytes sampling table 9 variation due page allocation table shows page allocation alone vary cache performance tapeworm removed sources variation considering activity mpegplay process kernel servers sampling two sets data points physically virtuallyindexed cache 4word line directmapped data point average 4 trials error bars plot represent one standard deviation size kbytes physically indexed 128 292 460 15 virtually indexed number cache size kbytes addressed cache virtually addressed cache average number cache size kbytes ble reproduce run run dynamic system effects example distributions physical page frames allocated task change run run affect sequence addresses seen physicallyindexed cache kessler92 sites88 turn causes variation cache miss ratios another source measured performance variance caused tapeworm employs set sampling results table 7 measure extent effects workload suite reporting statistics multiple experimental trials measurements simulations byte physicallyindexed cache using 18th sampling cache sets note standard deviations different measurement trials rather large ranging 10 high 70 mean values cases minimum maximum values differ mean much factor two isolate measurement variation caused set sampling removed pageallocation effects simulating virtually indexed rather physicallyindexed cache new trials performed without sampling results shown table 8 example espresso expected results without sampling show zero variance multiple trials experiment notice results without sampling consistently predict slightly higher miss counts sampling measurement bias discussed completely next section due increased time dilation effect increased slowdown nonsampled experiments table 9 shows degree page allocation vary cache performance removed sampling variation simulated workload mpegplay example physi callyindexed virtuallyindexed cache virtually indexed cache simulation exhibits zero variation sequence references cache independent distribution physical page frames assigned os run run essentially assumption made tracedriven cache simulators notice 4 kbyte physicallyindexed cache simulation results vary page size machine 4 kbytes page allocation appear pages overlap caches 4 kbytes smaller physicallyindexed cache greatest degree variation percent mean appears cache size 32 k bytes roughly size program text used mpegplay variation decreases larger smaller caches observation consistent probabilistic model cache page conflicts published kessler91 kesslers model predicts random page allocation probability cache conflicts peaks size cache roughly equals address space size workload decreases larger smaller caches finally notice variation due page allocation comparable larger set sampling suggests error introduced sampling reasonable trade increased speed simulating physicallyindexed caches course combined effect sources variance greater either isolation forcing larger number trials performed increase level confidence mean value addition page allocation observed sources memory system performance variation due os effects example observed gradual substantial increases tlb misses due kernel server memory fragmentation longrunning system important note tapeworms sensitivity sources performance variation necessitate multiple experimental trials liability performance variations due page allocation memory fragmentation real system effects considered necessary however tapeworm simulations configured remove effects produce measurements less variation like traditional tracedriven simulators example shown table 10 sources measurement bias tapeworms presence kernel workloads operation raises questions measurement bias although tapeworm carefully avoids setting traps code data never directly changes miss counts indirect ways tapeworm alter results first 256 kbytes physical memory allocated tapeworm boot time removes 64 pages free memory pool resulting possible increase paging activity minimize problem adding enough additional physical memory paging avoided altogether second source error cause tapeworm slowdowns resulting system time dilation effect causes clock interrupts run workload leading increased cache conflict misses figure 4 plots magnitude error induced time dilation notice error grows steeply slowdowns 0 2 levels larger slowdowns tapeworm slowdowns 4 bias tends 10 amount slowdown varies workload table 10 measurement variation removed measurement made table 7 variation due sampling page allocation removed accomplished configuring tapeworm simulation virtuallyindexed caches without set sampling workload minimum maximum range espresso 426 006 1 421 1 430 1 009 2 jpegplay 2060 006 0 2056 0 2064 0 008 0 mpegplay 5316 006 0 5312 0 5320 0 008 0 ousterhout 3469 122 4 3383 2 3555 2 172 5 sdet 4123 000 0 4122 0 4123 0 000 0 workload time dilation cannot removed simple adjustment clock interrupt frequency done borg90 chen93b collecting time dilation curves larger set workloads determine shape magnitude figure 4 possible adjust simulation results factor away form systematic error final source bias related masking certain tapeworm memory traps decstation 5000200 singlebit ecc errors raise hardware interrupt line cause kernel trap interrupts disabled kernel trap cannot occur resulting reduction cache misses seen tapeworm kernel runs interrupts masked limitation affects kernel references small fraction kernel code affected special code around regions helps tapeworm take cache effects account 43 portability ease portability tapeworm carefully partitioned hardwaredependent hardwareindependent sections minimal amount code actually runs ker nel controlled system call interface userlevel x figure 4 error due time dilation increases cache misses due time dilation measured mpegplay workload including system activity kernel servers running physicallyaddressed 4 kbyte directmapped icache 4word lines time dilation varied changing degree sampling dilation increase 208 9570 57 442 9966 101 increase dilation slowdown application see table 11 hardwaredependent code consists primarily modified kernel entry code two routines twsettrapandtwcleartrap principle implemented many machines see table 12 practice unexpected interactions components memory system hinder attempts implement primitives archi tectures example port tapeworm decstation 5000200 decstation 5000240 hindered due differences way dma implemented two machines intentional hardware support primitives could help avoid problems also reduce time set clear traps implementation operations performed issuing convoluted sequence control instructions mem orycontroller asic implements ecc logic piecing together memory address ecc error ie address tapeworm cache miss also requires dozen load shift add mask instructions could supported single load believe cleaner interface diagnostic functions memory asic could reduce total misshandling time 50 cycles increasing tapeworms speed another factor 5 1 although expensive direct support form trap bit memory location could decrease cost setting clearing traps support would useful applications debuggers distributed shared memory appel91 despite problems ports tapeworm run osf1 mach 30 operating systems decstation 3100s decstation 5000200s 486based gateway pcs 44 flexibility respect flexibility tapeworm trouble simulating memory structures fit cache model example write buffers queues hold contents short time cannot simulated tapeworm algo rithm limitation restricts simulations writeback write policy furthermore unlike tracedriven simulation easily efficiently extended simulation architectural structures instruction pipelines trapdriven approach seems limited simulation memory system hierarchies components problems flexibility inherent trapdriven simulation related specific limitations host hardware example decstation 5000200 ecc bits checked 4word cache line refills effectively limits simulation tapeworm cache line sizes multiples 4 words machine attempts implement data cache simulation particular machine hindered allocateonwrite policy causes ecc traps cleared without invoking tapeworm miss handlers machines use allocateonwrite policy data cache simulations possible reinhardt93 finally although miss counts provided 1 similar operation performed miss handler r3000 softwaremanaged tlb requires 20 cycles table 11 tapeworm code distribution code lines machinedependent kernel code 343 5 machineindependent kernel code 889 13 machineindependent user code 5652 82 tapeworm useful metrics right studies require measures miss ratios misses per instruction mpi obtain instruction counts using logic analyzer much convenient method would onchip instruction counter cases intentional hardware support trapdriven simulation primitives could overcome problems 5 summary future work development tapeworm demonstrates onthefly cache tlb simulation driven kernel traps greatly simplify problem evaluating memory structures workloads including multiple tasks operating system loads moreover measurements tapeworms performance show simulations performed rather small degradation overall system performance opens important new areas consideration fast simulation creates possibility examining wider range alternative configurations investigating variability results repeated runs workload simulations driven memory references generated actual users session tapeworm slowdowns made imperceptible user makes possible watch interesting cases cannot identified traditional batch simulations use continuous monitoring simulation opens possibility using results perform realtime hardware software tuning future generations simulators monitors driven kernel traps would benefit better hardware support generating traps reads writes particular memory locations better support result even faster flexible simulations continuing develop add features tapeworm simulator currently adding datacache simulation capabilities porting tapeworm architectures including dec alphabased workstations sparcbased machines 6 acknowledgments thank joel emer bill grundmann essential information decstation 5000200 memorycontroller asic thanks also go alessandro forin help mach table 12 privileged operations modern microprocessors entries table taken variety sources including data books text books microprocessor report mreport92 mreport93 given entry may true every implementation given processor features memoryparityerror traps actually systemimplementation dependent features affirmative entry means found least one system given microprocessor implements feature blank entry means insufficient data available privileged operation mips r3000 mips r4000 sparc dec alpha tera intel intel pentium power memory parity ecc traps yes yes yes yes yes yes instruction breakpoint invalid page traps variable page size instruction counters 30 trap handlers chihchieh lee implemented 486 tapeworm port r cache performance operating system multiprogramming workloads atum new technique capturing address traces using micro code translation buffer performance unix environment interaction architecture operating system design virtual memory primitives user programs generation analysis long address traces software methods system address trac ing impact operating system structure memory system performance cache performance vax11780 fast instructionset simulator execution profiling characterization alpha axp performance using tp spec work loads techniques efficient inline tracing sharedmemory multiprocessor bach byu address collection hardware cache performance spec92 benchmark suite techniques cache memory simulation using address reference traces introduction shade analysis multimegabyte secondary cpu cache memories page placement algorithms large realindexed caches abstract execution technique efficiently tracing programs efficient program tracing new abstraction memory system simulation design efficient simulation multiprocessor effectiveness trace sampling performance debugging tools evaluation techniques storage hierarchies effect context switches cache performance monster tool analyzing interaction operating systems computer architectures design tradeoffs softwaremanaged tlbs optimal allocation onchip memory multipleapi operating systems arent operating systems getting faster fast hardware performance software mpeg video decoder wisconsin wind tunnel virtual prototyping parallel comput ers multiprocessor cache analysis atum cache memories tracing pixie surpassing tlb performance superpages less operating system support characterizing caching synchronization performance multiprocessor operating system design tradeoffs softwaremanaged tlbs tr atum new technique capturing address traces using microcode cache performance operating system multiprogramming workloads multiprocessor cache analysis using atum efficient stack algorithms analysis writeback sector memories techniques efficient inline tracing sharedmemory multiprocessor effect context switches cache performance virtual memory primitives user programs interaction architecture operating system design memspy analyzing memory system bottlenecks programs page placement algorithms large realindexed caches characterizing caching synchronization performance multiprocessor operating system design tradeoffs softwaremanaged tlbs wisconsin wind tunnel effectiveness trace sampling performance debugging tools impact operating system structure memory system performance shade fast instructionset simulator execution profiling kernelbased memory simulation extended abstract design tradeoffs softwaremanaged tlbs characterization alpha axp performance using tp spec workloads optimal allocation onchip memory multipleapi operating systems surpassing tlb performance superpages less operating system support cache memories cache performance vax11780 translation buffer performance unix enviroment efficient program tracing cache performance spec92 benchmark suite design efficient simulation multiprocessor ctr shubhendu mukherjee steven k reinhardt babak falsafi mike litzkow mark hill david wood steven husslederman james r larus wisconsin wind tunnel ii fast portable parallel architecture simulator ieee concurrency v8 n4 p1220 october 2000 emmett witchel mendel rosenblum embra fast flexible machine simulation acm sigmetrics performance evaluation review v24 n1 p6879 may 1996 herv jamrozik michael j feeley geoffrey voelker james evans ii anna r karlin henry levy mary k vernon reducing network latency using subpages global memory environment acm sigplan notices v31 n9 p258267 sept 1996 alvin r lebeck david wood active memory new abstraction memorysystem simulation acm sigmetrics performance evaluation review v23 n1 p220230 may 1995 fast datalocality profiling native execution acm sigmetrics performance evaluation review v33 n1 june 2005 alvin r lebeck david wood active memory new abstraction memory system simulation acm transactions modeling computer simulation tomacs v7 n1 p4277 jan 1997 madhusudhan talluri mark hill surpassing tlb performance superpages less operating system support acm sigplan notices v29 n11 p171182 nov 1994 babak falsafi david wood modeling costperformance parallel computer simulator acm transactions modeling computer simulation tomacs v7 n1 p104130 jan 1997 richard uhlig david nagle trevor mudge stuart sechrest joel emer instruction fetching coping code bloat acm sigarch computer architecture news v23 n2 p345356 may 1995 richard uhlig trevor n mudge tracedriven memory simulation survey acm computing surveys csur v29 n2 p128170 june 1997