dynamically negotiated resource management data intensive application suites abstractin contemporary computers networks computers various application domains making increasing demands system move data one place another particularly form soft realtime constraint brute force technique implementing applications type domain demands excessive system resources even though actual requirements different parts application vary according way used moment sophisticated approach provide applications ability dynamically adjust resource requirements according precise needs well availability system resources paper describes set principles designing systems provide support soft realtime applications using dynamic negotiation next execution level abstraction introduced specific mechanism implementing principles utility principles execution level abstraction shown design three resource managers facilitate dynamic application adaptation gryphon epartpcip dqm architectures b introduction emerging class application programs stimulated rapid evolution computer hardware networks distributed applications data intensive requiring diverse data types beyond traditional numerical character types audio video streams moved one computer another timesensitive nature moving stream data similarity target applications traditional hard realtime applications applications often referred soft realtime applications contrast hard realtime sys tems every deadline must met applications considered success although deadlines met distributed virtual environment dve one example soft realtime applications dve supports logical world containing various shared entities users interact entities world using multimedia workstation dves dataintensive since shared information must disseminated throughout network user machines many classes applications exhibit similar data movement characteristics including multimedia systems imagebased information systems image processing systems video conferencing virtual reality purpose operating system manage resources facilities used processes distribute data among objects traditionally general purpose operating systems designed builtin policies resource managers provide best effort satisfy resource requests according relatively inflexible generally fair policy besteffort resource management policies typically include support deadline management particularly precise nature deadline management depends application semantics soft realtime applications importance specific data movement task depends importance two entities involved transfer one moment may important systems user move data location location b user directing computer perform task depending b whereas minutes later interactions b may far less important since user shifted focus another set computational entities example suppose object containing video clip shared two users joe betty two different workstations interconnected network joe betty discussing video clip might important workstations high fidelity moving image screens video continues run suppose joe betty shift attention different set objects longer necessary support data transfer rate required high fidelity video particularly maintaining data transfer video clip uses resources needed joe bettys new activity resource management policies support applications sometimes called usercentric 13 types policies stress system cannot satisfy resource requests running processes resources allocated best satisfy desires user past years focused resource management techniques supporting soft realtime data movement early experimentation indicated operating system performance inadequate support type data movement however observed effect resource bottlenecks could minimized os employed allocation policy resources directed applications parts application needed moment yet could changed users activities changed resource management policy needed sensitive dynamic needs users context applications therefore effort focused defining experimenting ways system provide effective support applications originally reported conference paper paper derived 21 two primary contributions paper first identification set three principles guide development soft realtime applications along explanation mechanism execution levels implement three principles principles based requirements dataintensive soft realtime applications may collectively require resources available principles define guidelines programmers develop soft realtime applica tions serve requirements system provide accompanying support informally execution level abstraction maps resource usage goodness defines unique mechanism design applications manage realtime performance execution level abstraction one concrete mechanism implementing software embraces principles second contribution paper presentation evaluation three specific aspects soft realtime support illustrate utility principles execution levels many contemporary applications target domain written objectoriented programs requiring support distributed objects object management policies crucial overall data movement performance gryphon distributed object system provides means applications influence systems object placement caching consistency policies 10 gryphon uses execution levels tradeoff shared object consistency versus network bandwidth analysis experiments show managing policies match application strategy remote object reference performance improved several orders magnitude applications frequently need move large amounts stream data one device another eg network display data moves devices sometimes needs filtered eg compressdecompress data extrapolate missing sections realtime parametricallycontrolled inkernel pipe rtpcip mechanism provides means sertremove kernellevel filters used moving data devices execution performance agent epa employs another form execution levels level determined confidence reliability applications pipeline service request estimates epa selected level execution based application service estimates configures pipeline controls rtpcip operation adjusting filter priorities epartpcip facility provides form soft realtime control previously available using inkernel pipe mechanisms generic soft realtime applications need certain resource levels order meet deadlines applications written dynamically modify processing according availability resources cpu network bandwidth etc dynamic quality service resource manager dqm uses execution levels allow applications dynamically negotiate cpu allocation result applications implement broad range soft realtime strategies possible systems section 2 explains system design principles shows execution levels provide mechanism implementing section 3 introduces gryphon distributed object system explains uses execution levels discusses performance approach section 4 presents epartpcip mechanism shows allows applications provide one approach soft realtime control inkernel filter mechanisms section 5 explains dqm mechanism uses execution levels discusses several aspects behavior section 6 summary conclusion various researchers addressed different aspects soft realtime support eg see 6 7 8 9 12 14 17 19 23 25 one problem many studies inherent definition term soft realtime mean applications almost always meet deadlines computation priorities elevated deadline missrate high applications period lengthened misses many deadlines etc one conclusion draw diversity perspectives characteristics important one context another unfortunately would difficult design os behave properly casebycase basis follows one might consider meta approach framework way applications make requirements known os responsibility casting specific soft realtime requirements framework responsibility application designer study based meta approach best explained considering set underlying principles derived studying various soft realtime applications particularly dve carefully considering types os support applications require section explains rationale principles principles execution level realization principles remainder paper shows principles applied three different aspects system support 21 motivation principles target applications substantial data movement units unit application object compound object one intended represent person dve thread etc applications unit needs able change importance interactions units according information known runtime eg focus users attention based information relative importance units changed dynamically reflect best interests users representative target class applications built prototype virtual planning room 22 vpr multiperson dve supporting freeform communication manner similar electronic meeting rooms distributed virtual environments vpr world collection objects vrml representations behaviors varying complexity compound object representing human participant avatar becomes part world user enters vpr basic role vpr provide realtime audio video support across network render objects users screen according users avatar orientation provide environment one add domainspecific extensions vpr clientserver system person uses workstation implement humancomputer interface hence client machine must render visible artifact vrml description appropriate objects world cause behaviors modifications objects reflected appropriate clients vpr developed used begin exploring system software design organization might wellsuited soft realtime applications programmers environment quickly learn design objects use different strategies performing work according perceived importance work user graphic object video stream focus users attention ie user oriented avatars eye directly video stream object considerable system resources used render images user really care three people using vpr two engaged high frequency manipulation complex shared object third person probably want use inordinate workstation resources tracking minor changes shared object user engaged video stream system unable deliver full 24 frames per second user often choose run video playback 12 frames per second rather fluctuate 16 24 frames per second network bandwidth workstation relatively underutilized local resources oversubscribed local resources momentarily important network bandwidth processing changed accordingly example application throughput therefore end user satisfaction would improved workstation received uncompressed data stream remote site rather decompressing stream locally received 22 system design principles based experience vpr various underlying systems developed relatively straightforward set principles direct ongoing system research though principles sim ple highlight characteristics soft realtime application domain current operating systems address realtime many aspects target application domain involve periodic computation processing must done repeatedly according regularly occurring deadline example display frame update must occur least 24 times per second many systems designed support per second however users often able tolerate certain failures meet deadline especially means another aspect users work receive higher quality service failure mode softening deadline requirement vary according exact nature application mix occasional missed deadlines acceptable provided regular consistently missing deadline small amount time may acceptable application may able scale back service time requirement make possible system make dead line application may able scale back resource usage units meet deadlines etc principle 1 resource managers support diverse definitions application failure provide sufficient mechanisms react missed deadlines application knowledge oversubscribed multithreaded system resource managers must block threads allocate resources others best effort resource manager builtin policy guide way allocates resources environment dve relative importance thread changes according nature relevant objects attention user resource manager needs additional information perceive situation information available runtime via application principle 2 applications provide information single number eg priority represent resource utilization needs resource managers designed use knowledge influence allocation strategy dynamic negotiation conventional environment application makes request sources assumes resources available application turn provide best service flexible environment application might request amount resource k 0 resource manager unable satisfy resource manager could respond application saying offer k 1 units resource based periodic usage form admission hard realtime quality service qos technologies application could respond saying would willing change say period would need k 2 units resource etc application resource manager potentially enter negotiation whenever application asks resources assurance resource availability case periodic computing nature soft realtime computing makes difficult application provide optimized request since know state systems resources hard realtime system many soft realtime systems request made using worst case estimate unfortunately worst case requests tend tie resources times really needed aggravating oversubscription problem realtime systems determine behavior admission time requiring application unequivocally determine maximum amount resource ever need hard realtime system supports dynamic admission must analyze new request context extant resource commitments target domain applications may enter leave system time threadsobjects may frequently change resource needs suggests resource requests change nature individual negotiation might change whenever unit makes resource request principle 3 resource management interface designed level allocation negotiated two parties negotiation initiated either party time 23 execution levels mechanism dynamic negotiation principles discuss responsibilities soft realtime applications resource managers communication interface first principle focuses application behavior application address different forms soft realtime deal missed deadlines second principle addresses interface application resource manager interact one another third principle concerned resource managers obligation negotiated policy principles suggest resource management philosophy needed application assume part responsibility resource allocation strategy principles 1 2 yet fits within general framework multiprogrammed operating system requires nature applicationsystem programming interface enhanced address principles others also recognized kind shift interface could substantially improve overall system performance singleapplication multiprogrammed domains eg see 20 23 25 principle 3 suggests framework applications resource managers pose resource allocation scenarios one another accomplished providing language interaction ensuring two parties prepared interact one another principles realized using software abstraction called execution levels applications execution levels defined design implementation software application execution levels provide mechanism designing selecting soft realtime strategy still responsibility application developer however strategy selected execution levels allow application specify resource requirements consistent strategy implements set execution levels represents varying strata resource allocation application able operate simplest case execution levels application different levels different resource types application unit provide highest quality service able acquire r j1 units j resource types application writer also design first alternative strategy uses r j2 units j resource types providing degraded service eg graphics figures may rendered well period may need longer frame update rate may lower applications written run oversubscribed environments commonly use form execution levels matter course without system support example graphics programs frequently use wireframes represent geometric solids certain phases graphic editing table 1 shows set execution levels related kind graphic programming technique used vpr table represents amount cpu time used various rendering options vpr simple moving object changes processing time 41 range 12 execution levels varying 3 rendering lights polygons frames per second max smooth 1 2x 319 1000 wireframe 1 2x 445 717 smooth 0 2x 476 670 smooth 1 1x 587 543 wireframe 0 2x 770 414 smooth 0 1x 797 400 wireframe 1 1x 894 357 wireframe 0 1x 1274 250 table 1 varying resource usage vpr parameters rendering mode wireframe flat shading smooth shading number specific light sources 0 1 number polygons marked 2x used twice many polygons marked 1x table shows frames per second generated cpu time used percentage highest level opengl performance characterization organization 24 similar performance measurements showing applications exhibit 10 different execution levels cpu requirements varying much factor 10 see 11 justification using execution levels applications execution levels define total order resource vector system resource types underlying theory approach none projects described paper currently address one resource type thus relatively easy define total order level increases ie quality solution decreases resource requirements also decrease fundamental constraint approach makes application defining notion soft realtime even though resource requirement versus level monotonic practical applications would normally linear level increases quality applications service decreases usually point application provides service example video frame rate streaming video application falls 5 frames per second quality effectively zero execution levels mechanism enables applications resource managers implement soft realtime consistent principles described figure 1a represents conventional thread thread thread application resources resource manager conventional thread thread thread application negotiation resources resource manager mechanism execution levels b execution levels figure 1 execution level api resource manager relationship among threads application resources use undirected solid lines dashed lines figure represent control flow among resource resource manager application best effort approaches resource management policy built resource manager time designed interaction policy module set applications figure 1b shows new framework logical component called negotiation mechanism interacts application using execution levels conceptually negotiation mechanism appears conventional application resource managers negotiation mechanism appears resource manager capable dynamic negotiation applications framework applications able create tactics defining managing soft realtime expressing resource needs resource manager negotiation mechanism using execution levels supports principles 1 2 negotiation mechanism extension work done conventional thread thread thread application negotiation mechanism execution levels object store gryphon orb figure 2 orb gryphon resource managers provides module dynamic negotiation supports principles 2 3 execution levels sufficient language supporting dynamic negotiation though problem shifts application negotiation modules designed distributed object manager study realtime pipe control study dynamic qos manager study employ different approaches designing implementing modules remainder paper consider studies detail 3 gryphon distributed object manager network bandwidth limited resource managed shared aspect work object oriented systems natural study distributed object managers means addressing network bandwidth performance eg see 15 16 18 26 gryphon enhancement conventional distributed object manager corba orb purpose gryphon support dynamic negotiation object placement policies according needs application state system resources figure 2 describes general architecture gryphon approach context figure 1 application uses corba idl interface normal object refer ences supplementary language describing object placement caching policy preferred application supplementary parts language called policy hints set hints constitutes one execution level eg distributed view object may use strong consistency model one level weaker form consistency lower level negotiation mechanism defines execution level order application uses definition directing gryphon according observed performance system negotiation mechanism detects shortage network bandwidth lowers execution level applications free bandwidth gryphon designed analyze hint information receives applications set policies orb gryphon system supports fundamental principles described section 2 follows principle 1 soft realtime using execution levels application variable object coherence object placement various timeliness updates policies principle 2 application knowledge application supplies information regarding location caching level form per user per object update granularity consistency requirements principle 3 dynamic negotiation application dynamically modifies object coherence place ment timeliness policies example users change focus one set objects another 31 representing execution levels realtime applications wide variety object reference patterns example following scenarios represent one recurring class vpr applications also types though three illustrate approach scenarios generates radically different set requirements object manager scenario learning laboratory dve used laboratory student small group students conduct various experiments student may browse different experiments without communicating students join group work people laboratory number static objects complex vrml specifications eg lab apparatus documentation avatars move infrequently objects move scenario b collaboratively flying unoccupied air vehicle siewert built unoccupied air vehi cle floaters test various parts epartpcip work see section 4 vpr used fly floaters ie one navigate floaters manipulating virtualization vpr scenario group people navigate floaters collaborative work within vpr avatars virtual space together see objects room scenario c weather modeling application weather modeling highly data computation tensive end result weather information displayed dve weather data partitioned small regional subsets intense processing performed partition first phase processing complete data fringes subsets distributed processes computation continues scenarios implemented system like vpr objects shared across many workstations causing substantial network traffic conventional distributed object managers provide location transparency though experience vpr shows distributed components needed substantial influence object location policies without flexibility applications could make performance tradeoffs based access demands several techniques reduce network traffic due remote object reference placement object stored host x frequently referenced host traffic delay application could reduced storing object host caching object stored host x frequently read hosts z keeping copies object hosts z reduce network traffic consistency object stored host x rapidly changed arbitrary hosts read host traffic processing overhead host reduced allowing keep outofdate copy object opposed updating ys copy time xs copy changes gryphon approach based idea applications component capable choosing among techniques since application behavior critical factor benefit technique table 2 represents relationship application hints levels scenarios level hints semantics centralized location strong consistency distributed location caching 3 location best location caching 4 location best location cache strong strong consistency 5 location best location cache sequential sequential consistency 6 location best location app directed caching app directed caching 7n location best location caching updates propagated update frequency table 2 execution levels scenarios b b differ primarily number objects movement application implementing scenario b would use decreasing amounts network bandwidth decreasing level higher level number scenarios application would inspired run lower higher level components missing soft deadlines levels 16 produce behavior though application provide information level level i1 overall system benefits due reduced network traffic distinction levels 1 2 related using single object storage location versus distributing objects multiple storage servers would unusual application option included emphasize centralized servers cause higher network traffic levels 7 n applications fidelity erodes since level 7 host machine allows changing objects become inconsistent due lack update propa gation differences among levels number updates host willing miss scenario c table 3 different set data reference patterns two scenarios consequently operate different set resource allocation criteria scenarios b data distributed host machines perform localized computation best location strong consistency case lower highernumbered levels represent situations use less network bandwidth meaning application must work achieve result bandwidth available system level hints semantics location strong consistency distributed location strong consistency 3 location best location sequential consistency 4 location best location caching 5 location best location app directed caching app directed caching 6n location best location caching app directed caching different algorithms table 3 execution levels scenario c 32 performance analysis analyze performance gryphon system implementation models based scenarios others discussed 10 used characterize traffic patterns resulting different object managers vpr object state changes object moves may also change due behaviors though simplification sufficient analysis assuming single message used move object messages small fit one network data packet table 4 shows parameters characterize message traffic table 5 shows values represent three scenarios scenario notable large number objects many moving also many processes using objects finally video fidelity required good scenario many characteristics scenario except number objects greatly reduced represents different kind application many moving objects objects updated time relatively high update rates however frame update rate zero parameters used derive equations three metrics vpr amount network traffic vpr processes messages per second tapp amount network traffic nonvpr processes messages per second n number moving objects number objects modified process u update rate moving objects l number processes using object v number vpr processes number static moving objects f update rate display frames r ratio updates get propagated table 4 parameters used model network traffic c weather modeling 10000 1000 1000 table 5 characteristics scenarios used evaluate gryphon system total total traffic network messages per second using model scenarios gryphon system performance compared centralized distributed corba object managers system 1 orb centralized corba object manager centralized orb single server stores objects reference object requires remote reference addition since orb special knowledge application send receive message required determine state object orb centralized amount traffic server likely bottleneck system 2 orb distributed corba object manager distributed configuration orb objects randomly equally distributed among processes orb centralized local objects result message traffic accesses would gone central orb go process object located distribution addresses implicit bottleneck due centralized configurations vpr first part expression represents read operations local client second part represents reads external clients data stored local server note expression includes references due frame updates dve needs render objects would implicitly read object frame update rate system 3 gryphon location policy object manager includes gryphon capable acting location hints like system 2 objects evenly distributed across processes case assumed located client making modifications system 4 gryphon location caching policies object manager includes gryphon capable acting location caching hints model reflects fact data pushed clients instead pulled via request messages ie remove 2x multiplier reflect absence send message system 5 gryphon location caching consistency policies configuration full gryphon system models scenario scenario b scenario c system 1 528004 5764 2000000 system 2 1054950 10952 3600000 system 3 1054940 10944 0 system 4 1998 38 9000000 system 5 20 19 900 system scenario scenario b scenario c system 2 528008 5768 3600000 system 3 528000 5760 0 system 4 1998 38 9000000 system 5 20 19 900 tapp comparison system scenario scenario b scenario c system 1 528004000 115280 20000000 system 2 527476000 109516 18000000 system 3 527472000 109440 0 system 4 1998000 760 90000000 system 5 19980 380 9000 total comparison table gryphon system performance comparison table 6 summarizes network message traffic using load generated three scenarios supported five different object management configurations highlights results system 1 centralized corba system 2 distributed corba subject substantially traffic others almost every scenario due requirement support location transparency supporting caching applicationfavored object placement substantial impact scenario c consequently gryphon performs much better systems location transparency caching system results large performance gains scenario b results unnecessary cache consistency updating scenarios c network traffic scenario 3 system 3 zero since analysis show infrequent reads small portions data case load negligible general table shows gryphon approach significantly reduces message traffic rate compared approaches total message traffic total gryphon system fraction percent centralized distributed corba systems three scenarios work illustrates object policies cast execution levels support principles also shows relative performance different levels experiments results reported 10 4 inkernel pipeline module thread control aspect work focuses support continuous media flow devices several studies shown embed applicationspecific code kernel perform operations specific data stream eg see 6 7 9 however approaches allow application influence way resources allocated components address applicationspecific tradeoffs realtime parametrically controlled inkernel pipe rtpcip facility provides means insert ingdeleting filter programs intofrom logical stream two devices filter parametrically controlled negotiation mechanism see figure 3 execution performance agent epa negotiation mechanism interacts userspace part application dynamically adjust scheduling priorities achieve soft realtime control pipeline epartpcip supports principles soft realtime follows principle 1 soft realtime diverse forms computation expressed terms deadline confidence execution time reliability analogous execution levels principle 2 application knowledge application provides desired deadline confidence reliability expected execution time rather simple priority epa principle 3 dynamic negotation epa supports negotiated management pipelines admission policy based relative execution time reliabilities requested deadline con fidences requested confidence deadlines may renegotiated online epa policy admission confidence negotiation derived extension deadline monotonic scheduling admission policy relaxes hard realtime require cpu scheduler application filter device device epa kernel user filter filter execution levels parametric control figure 3 epartpcip architecture ment worstcase deterministic execution time provided epa provides confidence reliability semantics online monitoring actual reliability admission testing order describe epa able provide execution control terms deadline confidence execution time reliability review deadline monotonic hard realtime scheduling show extended implement epa aspect work goal dynamically negotiate policy allocating resources used move data one node another within one node one device disk another device sound card rtpcip architecture uses existing techniques creating modules embedded kernel space extensions device drivers cf 3 7 device interface module connected arbitrary pipestage filter pipeline dynamically configured inserting filters source sink device interface application userspace monitors summary information kernel order control movement data source sink devices purpose epa interact userspace application modules pipeline specifically provides status information userspace program accepts parameters control behavior filter modules ensures data flows pipeline according realtime constraints estimated module execution times 41 soft realtime pipeline control threadbased operating system environment pipe module execution controlled kernel thread schedulertypically besteffort scheduler long system become overloaded pipe facility provide satisfactory service overload conditions epa dynamically computes new priorities threads executing modules provides scheduler allocate cpu threads imminent deadlines since hard realtime systems guarantees task admitted system completed prior prespecified deadline necessity conservative processing time estimates expressed terms worst case execution time wcet admission based assumption every task uses maximum amount resources schedule ensures admitted tasks execute deadline continuous media applications softened deadline requirements threads continuous media pipe must usually meet deadlines acceptable occasionally miss one system overloadedthe frequency missed deadlines highthe epa reduces loading conditions reconfiguring pipeline eg removing compression filter trading network bandwidth cpu bandwidth epa design driven experience practicality rather using wcet computing schedule uses range values associated confidence level specify execution time additional requirement application provide execution time estimates range confidence slightly complex approach described use rialto 14 application loads pipeline stages must specify following parameters service type common modules single pipeline guaranteed reliable besteffort computation time wcet guaranteed service expected execution time specification distribution normal distribution mean specified number samples reliable service none besteffort service input source device interface designation input output block sizes desired termination soft deadlines confidence reliable service term soft confidence term confidence soft minimum r min optimal r opt time output response release period expected minimum interarrival time aperiodics io periods 42 epadm approach thread scheduling approach scheduling rtpcip thread execution based branch hard realtime scheduling theory called deadline monotonic dm 1 dm consists fixedpriority scheduling threads periodic nature assigned priorities inverse relation deadlines example thread smallest deadline assigned highest priority dm proven optimal scheduling policy set periodic threads deadline every thread less equal period thread addition concept epadm thread scheduling pipeline stages based definition soft termination deadlines terms utility potential damage system controlled application see figure 4 5 figure 4 shows response time utility damage relation soft termination deadlines well early responses epa signals controlling application either deadline missed specifically abort thread completed termination deadline likewise epa buffer early responses later release r opt r min worst case signaled controlling applications handle deadline misses according specific performance goals using epa interface renegotiation service applications missed termination deadline damage catastrophic ie termination deadline hard deadline pipeline must configured guaranteed service rather reliable service dm theories apply directly inkernel pipeline mechanism dm appropriate hard realtime systems epadm schedulability test eases restriction dm admission requirements allow threads admitted expected execution times terms execution confidence interval rather requiring deterministic wcet expected time determined using offline estimates execution time based confidence intervals knowledge expected time refined online epa time thread run relaxing wcet admission requirement complex processing incorporated pessimistic wcet conservative assumptions eg cache misses pipeline stalls need reduce utility performanceoriented pipelines tolerate occasional missed deadlines especially probability deadline miss quantified beforehand earliest computation time distribution c high term signal abort r min buffered bestcase execution hold early response time release start time latest desired response termination c low soft signal response failure dropout degradation desired optimal response desired response earliest possible response utility curve wcet expected r opt buffered desired response interval context switch overhead response utility response damage figure 4 execution events showing utility desired response evaluation epadm schedulability test based execution duration described confidence intervals results probabilistic performance predictions perthread basis terms expected number missed soft termination deadlines simplification formulas threads assumed contribute maximum amount interference loosely defined amount time spent executing threads one question confidence number missed soft termination deadlines largely function confidence epa user execution time example thread execution time confidence 999 passes admission test expected miss associated deadline 01 time less sufficient necessary schedulability tests dm used part determine schedulability epadm scheduling policy shown figure 5 assumed computation time expressed normal distribution normal distribution assumption required greatly reduces number offline samples needed compared assuming distribution max interference time higher priority threads preempt execute number times period thread runs number times thread k executes period thread based period execution time thread k c low shortest execution duration thread c high longest execution duration thread j period eq 1 probability theory normal distribution c low high low high eq 2 epadm admission test low high soft term soft term 10 term figure 5 schedulability formulas epadm policy thread j z p low z p high unit normal distribution quantiles execution time thread example illustrates use epadm scheduling theory assuming two threads normal distribution execution times worstcase execution time wceti known comparison attributes threads shown table 7 threads scheduled based epadm scheduling admission test thread 1 probability completing execution soft least 999 expressed p c low soft 0999 simi larly probability p c high term 09998 likewise thread 2 respective deadline confidences low soft thread c exp n trials z p low conf soft z p high conf term wcet soft term table 7 parameters example threads equations figure 5 used determine schedulability two threads using execution time confidence desired soft term confidence thread 1 using eq 1 c high c low thread 1 shorter deadline two threads assigned highest prior ity therefore interference term max zero simplifies schedulability test thread 1 case equation 2 applied thread 1 becomes c low high soft term 10 use c high 1 formula shows 4872 use c low 1 formula shows 4986 50 10 thread schedulable thread 2 using eq 1 c high c low using eq 2 loworhigh 2 softorterm 2 max 2 softorterm 2 10 term 2 meaning max thread 2 interrupted twice period thread 1 case thread 1 might execute terminated epa term 2 evaluating c high yields400 evaluating c low yields420 formulas satisfied thread 2 schedulable example shows epadm scheduling approach supports soft realtime computation necessary guarantee every instance periodic computation complete execution deadline fact although shown use wcet basic dm formulas result lack schedulability thread 2 wcet statistical extreme cannot guaranteed general rtpcip mechanism conjunction epadm scheduling approach offers new flexible support devicetodevice processing needed dves threads created executed monitored order deliver predictable quantifiable performance according applications needs operating system overhead kept minimum amount dynamic interaction application code operating system low 5 dynamically negotiated scheduling also general cases need control soft realtime execution applications dve soft realtime applications must able modify resource consumption consequently quality output given time based relative importance data user amount physical resources available applications importance concurrently executing applications section discusses work applying dynamic negotiation cpu scheduling support soft realtime application execution middleware dynamic qos manager dqm allocates cpu individual applications according dynamic application need corresponding user satis faction applications able trade individual performance overall user satisfaction cooperating maximize user satisfaction selectively reducing increasing resource consumption available resources requirements change quality service qos 2 approach applied scheduling provide operating system support soft realtime application execution qos system allows application reserve certain amount resources initialization time subject resource availability guarantees resources available application duration execution applied scheduling means application reserve fixed percentage cpu sole use available cpu cycles committed new applications begin executing applications finished freeing enough cpu new applications requests met soft realtime environment application needs reasonable assurance rather absolute assurance resources available request qos hard realtime environ ments system makes strict guarantees service requires application make strict statement resource needs result applications environment must use worst case estimates resource need soft realtime systems applications make optimistic estimates resource needs expecting operating system generally able meet needs demand inform applications unable several operating systems designers created designs interfaces support form soft realtime operation new operating systems interfaces allow process either 1 negotiate operating system specific amount resources rt mach 17 rialto 14 2 specify range resource allocations mmoss 8 3 specify measure application importance used compute fair resource allocation smart 19 systems provide mechanism used reduce resource allotment granted running appli cations even though system able allocate resources aggressively hypothesis soft realtime applications still perform acceptably since average case resource requirements may significantly lower worstcase estimates resources allocated benefit amortized set executing applications creating resource management mechanisms operating systems developers assumed possible applications adjust behavior according availability resources without providing general model application development environment extreme applications may forced dynamically adapt strategy resource allocation less required averagecase execution mercer et al suggest dynamic resource manager could created deal situation processor overload 17 rialto researchers used mechanism develop application repertoire though apparently attempt define general model use dqm framework see figure 6 applications constructed take advantage mechanisms without participate directly detailed negotiation protocol framework based execution levels application program constructed using set strategies achieving goals strategies ordered relative resource usage relative quality output dqm interprets resource usage information operating system execution level information community applications balance system load overall user satis faction available resources across collection applications section 53 describes experiments conducted evaluate approach dqm framework supports fundamental principles asserted paper soft realtime thread thread thread application execution levels cpu scheduler figure dqm architecture processes follows principle 1 soft realtime dqm supports generic softening realtime processes execution levels applications may modify period algorithms implement arbitrary soft realtime policy principle 2 application knowledge application provides three pieces information per execution level resources needed benefit provided period principle 3 dynamic negotation dqm dynamically adjusts application levels runtime based application deadline misses current system state 51 execution levels dqm aspect work application execution characterized set quadruples level runtime application specifies maximum cpu requirements maximum benefit set quadruples level resource usage benefit period dqm level 1 represents maximum benefit 6 maximum cpu usage 075 number execution levels 6 level cpu benefit periodms table 8 quadruples example application highest level provides maximum benefit using maximum amount resources lower execution levels represented larger numbers example application might provide information shown table 8 indicates maximum amount cpu application require 75 cpu running maximum level level provide userspecified benefit 6 table shows application run relatively high benefit 80 65 maximum resource allocation level allocation reduced 40 quality result substantially less 25 52 dynamic qos manager dqm dqm dynamically determines specific allocation profile best suits needs applications user conforming requirements imposed resource availability delivered operating system runtime applications monitor determine deadlines missed notify dqm event response dqm informs application level execute modification execution level causes application internally change algorithm used execute allows dqm leverage mechanisms provided systems rt mach rialto smart order provide cpu availability applications dqm dynamically determines level running applications based available resources benefit resource availability determined different ways cpu overload determined incidence deadline misses running applications cpu underutilization determined cpu idle time current dqm done reading cpu usage low priority application situations cpu overload consequently missed deadlines levels selected reduce overall cpu usage maintaining adequate performance set running applications similarly situations cpu underutilization levels selected increase overall cpu usage four resource allocation policies examined use dqm distributed application misses deadline application autonomously selects next lower level variation policy allows applications raise level successfully met n consecutive deadlines n applicationspecific policy could used conjunction rt mach reserves mmoss smart fair policy even proportional option event deadline miss even option reduces level application currently using cpu assumes applications equally important therefore attempts distribute cpu resource fairly among running applications event underutilization policy raises level application currently using least cpu time proportional option uses benefit parameter raises lowers level application highest lowest benefitcpu ratio policy approximates scheduling used smart system optimal policy uses applications userspecified benefit ie importance utility priority applicationspecified maximum cpu usage well relative cpu usage benefit information specified level determine qos allocation cpu resources maximizes overall user benefit policy performs well initial qos allocations experiments shown execution level choice fluctuate wildly result second option implemented restricts change level 1 policy similar valuebased approach proposed alpha kernel 12 hybrid policy uses optimal specify initial qos allocations uses different algorithms decide levels modify dynamically resource availability changes two options implemented use absolute benefit benefit density benefitincremental cpu usage determine execution level changes application 1 maximum benefit 8 max cpu usage 042 levels 9 level cpu benefit 9 application 2 maximum benefit 4 max cpu usage 077 levels 6 level cpu benefit application 3 maximum benefit 5 max cpu usage 022 levels 8 level cpu benefit application 4 maximum benefit 2 max cpu usage 062 levels 4 level cpu benefit table 9 synthetic program characteristics 53 dqm experiments experiments presented section represented vpr applications synthetic appli cations synthetic applications consume cpu cycles attempt meet deadlines accordance specified execution levels without performing useful work synthetic applications generated random programs meet desired general criteriarandom total qos require ment absolute benefit number execution levels relative qos requirements benefit level synthetic applications periodic nature constant period 01 second applications must perform work every period reflect complete variability real applications simplifies analysis resulting data given set applications data generated running applications dqm recording 100 samples current level expected cpu usage actual cpu usage application well total cpu usage total benefit applications current system idle time applications ran total 10 seconds 100 periods results indicate adequate observing performance policies steady state experiments run 19 applications 2 9 levels simplifying comparison presented single representative set synthetic applications used execution level information application set shown table 9 4 applications 4 9 levels associated benefit cpu usage numbers figure 7a shows execution levels result given application set running dqm distributed policy skip value 0 skip value indicates number missed execution level application 1 application 2 application 3 application 4 execution levels051525 fraction cpu application 1 application 2 application 3 application 4 sum b cpu usage figure 7 performance distributed skip0 deadlines must occur succession application reduces execution level skip value 0 means application reacts instantly lowering level regardless transient nature overload situation execution levels seen change rapidly beginning system started state cpu overload ie combined qos requirement complete set applications running highest level level 1 approximately 200 cpu 10th sample applications stabilized levels operate within available cpu resources additional level adjustment application 3 38th sample due additional missed deadline probably resulting transient cpu load generated nonqos application lack changes beginning wild fluctuations end graph result startup termination applications beginning end experiment combined slightly longer 110 second data recording sample interval figure 7b shows cpu usage applications experiment total requested cpu usage designated sum starts approximately twice available cpu drops 1 applications adjusted stable levels note also adjustment sample 38 lowering total cpu usage approximately 80 figure 8a shows cpu usage distributed policy skip value 2 using larger skip value desensitizes algorithm deadline misses level adjustment made every 3rd deadline miss rather one result longer initial period stability reached result less overshoot gives applications time stabilize distributed skip2051525 fraction cpu application 1 application 2 application 3 application 4 sum b fair proportional figure 8 cpu usage level adjustments stability reached sample 16 two small adjustments samples 24 49 however overall cpu usage stays close 100 duration experiment essentially overshoot observed figure 7b results running applications fair policy using even option shown centralized policy makes decisions attempt give applications equal share cpu policy generally produces results nearly identical distributed policy set applications figure 8b shows results running applications fair policy using proportional option version policy attempts distribute shares available cpu cycles application proportional applications benefit previous policies cpu percentage used applications approximately policy cpu usagebenefit ratio approximately applications fact ratio close equal reached given execution levels defined applications figure 9 shows cpu usage applications running optimal policy policy reaches steady state operation immediately applications enter system level uses available cpu cycles policy optimizes cpu allocation maximize total benefit set applications producing overall benefit number 1488 compared 1302 policies note also policy optimizes benefit necessarily utilization policies shown result stable steady state yielding additional deadline misses requiring corrections however policy least stable given figure 9 cpu usage optimal02061 fraction cpu fairproportional optimal application 2051525 fraction cpu fairproportional optimal b sum figure 10 performance four policies changing cpu resources caused applications entering leaving system figure 10a shows plots application 2 four different policies figure 10b shows summed cpu usage four policies shown figure 10a graph gives indication time required applications reach steady state along cpu utilization resulting allocations figure 10a particular summarizes differences various policies optimal policy selects feasible value immediately level application unchanged duration experiment distributed fair even policies reach steady state value although take different amounts time reach state distributed policy taking slightly longer fair proportional policy reaches steady state time distributed fair policies although allocation slightly less case general experiments show given set levelbased applications possible create dqm dynamically adjusts application execution levels maximize user satisfaction within available resources even absence underlying qos soft realtime scheduling mech anisms four dqm decision policies demonstrate range possibilities inherent model 4 dqm extended support extensive use execution levels 6 summary conclusion nextgeneration multimedia applications require timely delivery complex data across within nodes dynamic computing environments user requirements change frequently writing executing applications deliver manage data according rapidlychanging requirements requires new support operating system development tools paper introduced set principles evolved work designing dve resource managers support principles address soft realtime communicating application knowledge support dynamic negotiation paper also presents framework execution levels implement principles execution levels used three different contexts gryphon distributed object manager epartpcip facility dqm support soft realtime applications gryphon project paper shown approach used adjust object storage strategies compensate scarce network bandwidth epartpcip study describes execution levels used provide realtime support kernel pipelines using confidence reliability parameters execution levels dqm study demonstrates execution levels used implement general dynamic negotiation top besteffort operating system including measurements reflect behavior system acknowledgment authors nutt brandt griff partially supportedby nsf grant iri9307619 jim mankovich designed almost singlehandedly built three different versions vpr several graduate students particularly chris gantz helped us participation group discussions virtual environments humancomputer interfaces realtime soft realtime performance prototype system r hard realtime schedul ing deadline monotonic approach survey qos architectures extensibility safety performance spin operating system realtime application execution dyanamic quality service assurance scheduling hard realtime systems review design qos controlled atm based communication system exploiting inkernel data paths improve io throughput cpu availability evalutions soft realtime handling methods soft realtime framework scheduling ipc mechanisms continuous dia tailorable location policies distributed object systems dynamic quality service resource management multimedia applications general purpose operating systems iii support usercentric modular realtime resource management rialto operating system cpu reservations time constraints efficient object caching corba compliant system constructing reliable distibuted communication systems corba processor capacity reserves operating system support multimedia applications highly available design agile applicationsaware adaptation mobility resource management virtual planning room software support virtual planning room resource centric approach multimedia operating systems www page httpwww resource allocation model qos management architectural design globe widearea distributed system tr ctr ingray chen shengtun li iling yen adaptive qos control based benefit optimization video servers providing differentiated services multimedia tools applications v25 n2 p167185 february 2005 scott brandt gary j nutt flexible soft realtime processing middleware realtime systems v22 n12 p77118 janmarch 2002 eyal de lara yogesh chopra rajnish kumar nilesh vaghela dan wallach willy zwaenepoel iterative adaptation mobile clients using existing apis ieee transactions parallel distributed systems v16 n10 p966981 october 2005