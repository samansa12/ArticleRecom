local convergence predictorcorrector method semidefinite programming study local convergence predictorcorrector algorithm semidefinite programming problems based monteirozhang unified direction whose polynomial convergence recently established monteiro strict complementarity nondegeneracy assumptions superlinear convergence qorder 15 proved scaling matrices corrector step bounded condition number version predictorcorrector algorithm enjoys quadratic convergence scaling matrices predictor corrector steps bounded condition numbers latter results apply particular algorithms using alizadehhaeberlyoverton aho direction since scaling matrix identity matrix b introduction study superlinear convergence interiorpoint methods linear programming lp initiated early 90s effort explain fact interior point methods tend perform significantly better practice indicated polynomial complexity bounds discrepancy due limitation worst case analysis used deriving polynomial complexity bounds reflects inherent conflict requirements global convergence fast local convergence superlinear convergence especially important semidefinite programming sdp since finite termination schemes exist problems predicted theory confirmed numerical experiments condition number linear systems defining search directions increases 1 normalized duality gap respective systems become ill conditioned approach solution therefore interior point method superlinearly convergent unlikely obtain high accuracy practice spite theoretical polyno mial complexity hand superlinearly convergent interior point method achieve good accuracy eg 10 gamma10 better substantially fewer iterations indicated worse case global linear convergence rate related polynomial complexity local convergence analysis interior point algorithms sdp much challenging lp shown relatively smaller number papers addressing subject first two papers investigating superlinear convergence interior point algorithms written independently kojima shida shindoh 4 potra sheng 13 algorithm investigated papers extension mizunotodd ye predictorcorrector algorithm lp uses kshhrvwm search direction see next section definition search direction kojima shida shindoh 4 established superlinear convergence following three assumptions sdp strictly complementary solution nondegenerate sense jacobian matrix kkt system c iterates converge tangentially central path sense size neighborhood containing iterates must approach zero namely lim kk f denotes frobenius norm matrix ffl denotes corresponding scalar product see next section precise definitions 13 used assumptions b c instead proposed sufficient condition superlinear convergence implied assumptions 14 improved result obtained superlinear convergence assumption following condition lim clearly weaker c course c enforced al gorithm practical efficiency approach questionable however theoretical point view proved 14 modified algorithm 4 uses several corrector steps order enforce c polynomial complexity superlinearly convergent assumption well known assumption necessary superlinear convergence standard interior point methods even qp case see 10 kojima shida shindoh 4 also gave example suggesting interior point algorithms sdp based kshhrvwm search direction unlikely superlinearly convergent without imposing condition like c 5 authors showed predictorcorrector algorithm using aho direction quadratically convergent assumptions b see next section definition aho search direction also proved algorithm globally convergent polynomial complexity bounds found algorithm shown condition c automatically satisfied iteration sequence generated algorithm appears use aho direction corrector step strong effect centering exploited property 15 showed direct extension mizunotoddye algorithm based kshhrvwm direction predictor step aho direction corrector step polynomial complexity superlinearly convergent qorder 15 assumptions b interesting superlinearly convergent predictorcorrector algorithm based nt search direction proposed luo sturm zhang 7 algorithm depends parameter ffl 0 produces points x defined 27 ffl4 algorithm starts feasible point x given ffl ffl4 finds feasible point x iterations however bound number iterations proved hold hence algorithm polynomial usual sense algorithm superlinearly convergent assumption turns c enforced algorithm since proved 7 sufficiently large k also proved one uses one predictor r correctors per iteration k converges zero qorder 21 paper investigate local behavior predictorcorrector algorithm considered monteiro 9 sdp using mzfamily search directions show sufficient condition potra sheng 13 superlinear convergence applies algorithm sufficient condition independent scaling matrices particular show algorithm superlinearly convergent satisfied specifically show assumptions b superlinear convergence qorder 15 obtained scaling matrices corrector step bounded condition num ber finally propose new version predictorcorrector algorithm enjoys quadratic convergence scaling matrices predictor corrector steps bounded condition numbers b satisfied following notation terminology used throughout paper pdimensional euclidean space nonnegative orthant ir positive orthant ir set p theta q matrices real entries set p theta p symmetric matrices set p theta p symmetric positive semidefinite matrices set p theta p symmetric positive matrices jth entry matrix trm trace p theta p matrix equals 0 positive semidefinite 0 positive definite n eigenvalues 2 largest smallest eigenvalue 2 euclidean norm vector corresponding norm matrix ie frobenius norm matrix kg g 2 predictorcorrector algorithm sdp consider semidefinite programming sdp problem associated dual problem given data primal dual variables respectively g ffl h denote trace g h also simplicity assume linearly independent throughout paper assume 21 22 finite solutions optimal values equal assumption x solutions 21 22 solutions following nonlinear system denote feasible set problem 23 solution set f ie consider symmetrization operator 17 since observed zhang 17 nonsingular matrix p matrix real spectrum 2 ir follows given nonsingular matrix p 23 equivalent perturbed newton method applied system 24 leads following linear system theta n unknown search direction 2 0 1 centering parameter normalized duality gap corresponding x search direction obtained 25 called monteirozhang mz unified direction 17 11 matrix p used 25 called scaling matrix search direction well known taking results alizadehhaeberlyoverton aho search direction 1 corresponds kojimashindohharahelmberg rendlvanderbeiwolkowiczmonteiro kshhrvwm search direction 6 3 8 case p coincides nesterovtodd nt search direction 12 monteiro zhang 11 established polynomiality longstep pathfollowing method based search directions defined scaling matrices belonging class following 11 sheng et al 16 proved polynomiality mizunotoddye type predictorcorrector algorithm sdp imposing scaling matrices chosen class nthetan nonsingular pxsp moreover superlinear convergence proved addtional simple condition primaldual algorithms considered monteiro 9 based centrality measure theta n 1 denote n fl following neighborhood central path monteiros generalized predictorcorrector algorithm semidefinite programming based mz family directions consists predictor step corrector step iteration starting strictly feasible pair x generates sequence iterates n ff iteration monteiros generalized predictorcorrector algorithm described follows algorithm given choose nonsingular n theta n matrices p k p k ffl predictor step solve system 25 x denote solution u theta n set compute step length ffl corrector step solve system 25 x solution set end iteration using elegant analysis monteiro 9 proved predictorcorrector algorithm defined properly chosen parameters ff fi 0 well defined needs iterations producing pair x initial gap precisely monteiro showed k 0 3 technical results analyzing local behavior predictorcorrector algorithm monteiro need following technical result proved 8 lemma 26 9 lemma 21b lemma 31 suppose 2 ir pthetap nonsingular matrix e 2 ir pthetap least one real eigenvalue following lemma part lemma 35 monteiro 9 lemma 32 let w 2 ir nthetan gwg gamma1 skewsymmetric nonsingular nthetan following technical result play important role analysis lemma 33 let x 1 suppose x deltay nthetan theta ir theta nthetan solution linear system deltay k 2 ir nthetan f proof denoting write easily seen using notation follows using 38 lemma 32 hand using 38 obtain gammakx gamma12 x x gamma12 x 12 sx implies ii follows 39 fact interesting note inequalities lemma independent scaling matrix p next lemma establish lower bound stepsize k together lemma 33 enables us analyze asymptotic behavior predictorcorrector algorithm generated predictorcorrector algorithm proof simplicity let us omit index k 28 together linearity h p delta fact rh p 25a imply using fact u ffl therefore hence x 0 0 2 0 otherwise exists 0 2 0 x 0 0 singular means hand 32 implies contradicts 310 using 34 therefore result follows definition 4 sufficient condition superlinear convergence section investigate asymptotic behavior predictorcorrector algorithm obtain sufficient condition superlinear convergence definition 41 triple x called strictly complementary solution throughout paper assume following condition holds assumption 1 sdp problem strictly complementary solution x orthogonal matrix q eigenvectors x define easily seen ib ng simplicity let us assume b n diagonal matrices sequel write matrix block form assume dimensions 11 22 jibj theta jibj jinj theta jinj respectively next lemma use following notation lemma 42 potrasheng 13 lemma 44 assumption 1 ks ks using lemma 43 write using techniques obtain similar result predicted pair x k lemma 43 let x assumption 1 satisfied 13 let us define linear manifold easily seen x lemma 44 potrasheng 13 lemma 45 assumption 1 f ae lemma 45 potrasheng 13 lemma 46 assumption 1 every accumulation point strictly complementary solution 23 let us define solution following minimization problem gamma constant kx k k k f gamma 8k note every accumulation point belongs feasible set minimization problem feasible set bounded therefore exists k theorem 46 assumption 1 predictorcorrector algorithm superlinearly convergent moreover exists constant oe 0 convergence qorder least 1oe sense proof simplicity let us omit index k easily seen u used relation clearly satisfies equation denoting applying lemma 33 obtain implies similarly lemma 43 fact similar manner obtain let us observe 46 47 48 49 410 get hence applying ii lemma 33 obtain noting deduce finally k constant oe 0 k lemma 34 follows therefore lemma 46 originally obtained potra sheng 14 based lemma 46 establish following generalization result potra sheng 14 theorem 61 theorem 47 assumption 1 x k 1 predictorcorrector algorithm superlinearly convergent moreover x k constant oe 0 convergence qorder least 1 05g 5 superlinear convergence strict complementarity nondegeneracy throughout section assume assumption 1 strict complementarity holds let x strictly complementary solution 21 22 also assume following nondegeneracy condition introduced kojima shida shindoh 4 5 first let us define affine space g 0 assumption 2 nondegeneracy x remarked section 5 kojima shida shindoh 5 strict complementarity assumption nondegeneracy condition equivalent combination primal dual nondegeneracy conditions given alizadeh haeberly overton 2 assumptions 1 2 solution x unique therefore iteration sequence converges x sequence predicted pairs lemma 51 kojimashidashindoh 5 lemma 53 assume h us x v let r nonsingular matrix r easily seen rscaled sdp also satisfies strict complementarity nondegeneracy conditions unique solution rx r r using lemma 51 considering new sdp 51 easily obtain following lemma lemma 52 assume nonsingular matrix r next lemma cond f denotes condition number matrix b lemma 53 cond f p k proof let r corrector step algorithm u easily seen suppose 52 true ie sequence unbounded choose subsequence r obviously u fact matrices linearly indepen dent together u implies u dividing sides 53 letting k 1 along subsequence obtain contradicts lemma 52 theorem 54 strict complementarity nondegeneracy assumptions cond f p k o1 algorithm superlinearly convergent qorder least 15 proof predictor step thus lemma 53 obtain note f f therefore ends proof invoking theorem 47 result says superlinear convergence predictorcorrector algorithm independent choice scaling matrix p k predictor step algorithm scaling matrices used corrector step need wellconditioned superlinear convergence clearly family scaling matrices admissible corrector step superlinear convergence includes identity matrix defining aho special case imposing assumption scaling matrices used predictor step new strategy step size improve order convergence stated theorem 54 order achieve quadratic convergence need slightly modify choice step size instead k given 29 use predictorcorrector algorithm new strategy called modified predictorcorrector algorithm easily seen modified predictorcorrector algorithm still polynomial complexity follows show also quadratically convergent theorem 55 hypothesis theorem 54 cond f p k modified predictorcorrector algorithm quadratically convergent proof proof theorem 54 cf 55 using 57 argument similar employed proof lemma 53 get write g 5455 prove using 59 argument lemma 53 get observing c 2 positive constant without loss generality may assume together 56 513 implies let evidently k means therefore 6 remarks paper consider feasible version predictorcorrector method keep presentation simple however analysis used easily extended infeasible predictorcorrector algorithms based unified direction proposed monteiro zhang strict complementarity nondegeneracy assumptions established superlinear convergence qorder 15 pure predictorcorrector algorithm scaling matrices corrector step satisfy cond f p k superlinear convergence obtained weaker condition interesting topic future research finally mention quadratic convergence established predictorcorrector algorithm slight modification step size selection would interesting find whether quadratic convergence proved original predictorcorrector algorithm r complementarity nondegeneracy semidefinite programming interiorpoint method semidefinite programming local convergence predictorcorrector infeasibleeinteriorpoint algorithms semidefinite programs predictorcorrector interiorpoint algorithm semidefinite linear complementarity problem using alizadehhaeberlyoverton search direction superlinear convergence symmetric primaldual path following algorithm semidefinite programming polynomial convergence primaldual algorithms semidefinite programming based monteiro zhang family directions local convergence interiorpoint algorithms degenerate monotone lcp unified analysis class pathfollowing primaldual interiorpoint algorithms semidefinite programming superlinearly convergent primaldual infeasibleinterior point algorithm semidefinite programming superlinear convergence interiorpoint algorithms semidefinite programming superlinear convergence predictorcorrector method semidefinite programming without shrinking central path neighborhood general class interiorpoint algorithms semidefinite programming polynomial complexity superlinear convergence extending primaldual interiorpoint algorithms linear programming semidefinite programming tr ctr b zhao enlarging neighborhoods interiorpoint algorithms linear programming via least values proximity measure functions applied numerical mathematics v57 n9 p10331049 september 2007