trace processors traces dynamic instruction sequences constructed cached hardware microarchitecture organized around traces presented means efficiently executing many instructions per cycle trace processors exploit control flow data flow hierarchy overcome complexity architectural limitations conventional superscalar processors 1 distributing execution resources based trace boundaries 2 applying control data prediction trace level rather individual branches instructions three sets experiments using specint95 benchmarks presented detailed evaluation trace processor configurations results affirm significant instructionlevel parallelism exploited integer programs 2 6 instructions per cycle also isolate impact distributed resources quantify value successively doubling number distributed elements ii trace processor data prediction applied intertrace dependences potential performance improvement perfect prediction around 45 benchmarks realistic prediction gcc achieves actual improvement 10 iii evaluation aggressive control flow benchmarks benefit control independence much 10 b introduction improvements processor performance come two ways advances semiconductor technology advances processor microarchitecture sustain historic rate increase computing power important kinds advances continue almost certain clock frequencies continue increase microarchitectural challenge issue many instructions per cycle efficiently argue conventional superscalar microarchitecture cannot meet challenge due complexity inefficient approach multiple instruction issue due architectural limitations ilp inability extract sufficient parallelism sequential programs going todays modest issue rates 12 16 way issue superscalar processors face complexity phases instruction processing instruction fetch bandwidth limited frequent branches instruction dis patch register renaming particular requires increasingly complex dependence checking among instructions dispatched clear wide instruction issue large pool instruction buffers full result bypassing among functional units feasible fast clock even wide superscalar processor could efficiently exploit ilp still fundamental limitations finding parallelism architectural limitations due handling control data memory dependences purpose paper advocate next generation microarchitecture addresses complexity architectural limitations development microarchitecture brings together concepts significant body research targeting issues fills gaps give complete cohesive picture primary contribution evaluating performance potential microarchitecture offers 11 trace processor microarchitecture proposed microarchitecture figure 1 organized around traces context trace dynamic sequence instructions captured stored hard ware primary constraint trace hardware determined maximum length may number implementationdependent constraints traces built program executes stored trace cache 12 using traces leads interesting possibilities revealed following trace properties trace contain number type control transfer instructions number implicit control predictions property suggests unit control prediction trace individual control transfer instructions nexttrace predictor 3 make predictions trace level effectively ignoring embedded control flow trace trace uses produces register values either liveonentry entirely local liveonexit 45 referred liveins locals liveouts respectively property suggests hierarchical register file implementation local register file per trace holding values produced consumed solely within trace global register file holding values live traces distinction local dependences within trace global dependences traces also suggests implementing distributed instruction window based trace boundaries result processor composed processing elements pe organization smallscale superscalar processor pe 1 enough instruction buffer space hold entire trace 2 multiple dedicated functional units 3 dedicated local register file holding local values 4 copy global register file figure 1 trace processor 111 hierarchy overcoming complexity organization based traces reduces complexity taking advantage hierarchy control flow hierarchy processor sequences program level traces contained within traces finer granularity control flow also value hierarchy global local values enables processor efficiently distribute execution resources hierarchy overcome complexity phases processing instruction predicting traces multiple branches implicitly predicted simpler alternative bruteforce extensions singlebranch predictors together trace cache trace predictor offer solution instruction fetch complexity instruction dispatch trace given local register file affected traces local registers prerenamed trace cache 45 prerenaming definition eliminates need dependence checking among instructions dis patched locals represent dependences entirely contained within trace liveins liveouts go global renaming trace dispatch thereby reducing bandwidth pressure register maps freelist instruction issue distributing instruction window among smaller tracesized windows instruction issue logic longer centralized furthermore pe fewer internal result buses thus given instruction monitors fewer result tag buses result bypassing full bypassing local values among functional units within pe feasible despite possibly longer latency bypassing global values pes register file size bandwidth requirements global register file reduced hold local values sufficient read port bandwidth achieved copies pe write ports cannot handled way liveouts must broadcast copies global file however write bandwidth reduced eliminating local value traffic instruction retirement retirement dual dispatch physical registers returned free list freelist update bandwidth reduced liveouts mapped physical registers 112 speculation exposing ilp alleviate limitations imposed control data memory dependences processor employs aggressive speculation control flow prediction granularity traces yield good better overall branch prediction accuracy many aggressive singlebranch predictors 3 value prediction 67 used relax data dependence constraints among instructions rather predict source destination values instructions limit value predictions liveins traces limiting predictions critical subset values imposes structure value prediction predicting liveins particularly appealing enables traces execute independently memory speculation performed two ways first load store addresses predicted dispatch time second employ memory dependence speculation loads issue prior stores disambiguation occurs fact via distributed mechanism 113 handling misspeculation selective reissuing pervasiveness speculation handling misspeculation must fundamentally change misspeculation traditionally viewed uncommon event treated accordingly misprediction represents barrier subsequent computation however data misspeculation particular viewed normal aspect computation data misspeculation may caused mispredicted source register value mispredicted address memory preprocess trace construct trace instruction branch predict cache global registers livein value predict trace cache reorder buffer segment per trace next trace predict maps rename global registers predicted issue buffers registers units processing element 1 processing element 2 processing element 3 processing element 0 speculative state data cache dependence violation instruction detects mispre diction reissue new values operands new value produced propagated dependent instructions turn reissue instructions along dependence chain reissue mechanism selective reissuing simple fact existing issue mechanism selective reissuing due control misprediction involved also discussed performance improvement evaluated trace processors 12 prior work paper draws significant bodies work either efficiently exploit ilp via distribution hierarchy expose ilp via aggressive speculation part body research focuses hardware intensive approaches ilp work area multiscalar processors 89 first recognized complexity implementing wide instruction issue context centralized resources result interesting combination compiler hard ware compiler divides sequential program tasks task containing arbitrary control flow tasks like traces imply hierarchy control flow val ues execution resources distributed among multiple processing elements allocated task granularity runtime tasks predicted scheduled onto pes control data dependences enforced hardware aid compiler case register dependences multiscalar processors several characteristics common trace processors distributing instruction window register file solves instruction issue register file complexity mechanisms multiple flows control avoid instruction fetch dispatch com plexity also exploit control independence tasks neither scheduled compiler guaranteed parallel processors demonstrate aggressive control speculation 10 memory dependence speculation 811 recently microarchitectures proposed address complexity superscalar pro cessors trace window organization proposed 4 basis microarchitecture presented con ceivably register file memory organizations could superimposed organization eg original multiscalar distributed register file 12 distributed speculativeversioning cache 13 far discussed microarchitectures distribute instruction window based task trace boundaries dependencebased clustering interesting alternative 1415 similar trace processors window execution resources distributed among multiple smaller clusters however instructions dispatched clusters based dependences based proximity dynamic instruction stream case traces instructions steered clusters localize dependences within cluster minimize dependences clusters early work 16 proposed fillunit constructing reusing larger units execution individual instructions concept relevant next generation processors subsequent research 1718 emphasize atomicity allows unconstrained instruction preprocessing code scheduling recent work value prediction instruction collapsing 67 address limits true data dependences ilp works propose exposing ilp predicting addresses register values well collapsing instructions execution combined functional units 13 paper overview section 2 describe microarchitecture detail including frontend value predictor processing element mechanisms handling mis speculation section 3 describes performance evaluation method primary performance results including comparison superscalar presented section 4 followed results value prediction section 5 study control flow section 6 2 microarchitecture trace processor 21 instruction supply trace uniquely identified addresses instructions course sequence addresses encoded compact form example starting addresses basic blocks trace starting address plus branch directions regardless trace identified trace ids derivatives trace ids used sequence program shaded region figure 2 shows fastpath instruction fetch nexttrace predictor 3 trace cache sequencing logic coordinate datapath trace predictor outputs primary trace id one alternate trace id prediction case primary one turns incorrect one could use alternates diminishing returns sequencer applies hash function bits predicted trace id form index trace cache trace cache supplies trace id equivalent cache tag trace cached location compared full predicted trace id determine hit best case predicted trace cached correct predicted trace misses cache trace constructed slowpath sequencer nonshaded path figure 2 predicted trace id encodes instructions fetched instruction cache sequencer uses trace id directly instead conventional branch predictor execution engine returns actual branch outcomes predicted trace partially completely incorrect alternate trace id consistent known branch outcomes used try different trace trace cache hit build trace remainder trace cache miss alternate ids prove insufficient slowpath sequencer forms trace using conventional branch predictor actual branch outcomes figure 2 frontend trace processor 211 trace selection interesting aspect trace construction algorithm used delineate traces trace selection obvious trace selection decisions involve either stopping embedding various types control instructions call directs call indirects jump indirects returns heuristics may stop loop branches ensure traces end basic block boundaries embed leaf functions embed unique call sites enhance control independence trace selection decisions affect instruction fetch band width pe utilization load balance pes trace cache hit rate trace prediction accuracy strongly influence overall performance often targeting trace selection one factor negatively impacts another factor studied issue extensively unless otherwise stated trace selection use 1 stop maximum 16 instructions 2 stop call indi rect jump indirect return instruction 212 trace preprocessing traces preprocessed prior stored trace cache processor model requires prerenaming information trace cache register operands marked local global locals prerenamed local register file 4 although done preprocessing might also include instruction scheduling 17 storing information along trace set reorder buffer quickly dispatch time collapsing dependent instructions across basic block boundaries 7 213 trace cache performance section present miss rates different trace cache configurations miss rates measured running dynamic instruction stream dividing traces based trace selection algorithm looking successive trace ids cache include graphs go gcc compress fits entirely within 16k direct mapped trace cache jpeg xlisp show 4 miss rates 32k direct mapped cache two sets curves two different trace selection algorithms set shows miss rates 1way 8way associativity total size kilobytes instruction storage along xaxis top four curves default trace selection section 211 bottom four curves labeled key add two stopping constraints stop call directs stop loop branches default trace selection gives average trace lengths 148 go 139 gcc constraining trace selection gives smaller average trace lengths 118 go 109 gcc advantage much lower miss rates benchmarks go particular miss rate 14 constrained selection 128kb trace cache 34 figure 3 trace cache miss rates 214 trace predictor core trace predictor correlated predictor uses history previous traces previous trace ids hashed fewer bits placed shift register forming path history path history used form index prediction table 2 entries table entry consists predicted trace id hit logic fastpath sequencer trace next sequencer slowpath cached trace id alternate primary function hash predicted trace id trace preds branch pred control targets branch construct trace trace new trace trace id preprocess outcomes execution instr block optional path miss rate gcc dm 2way 4way 8way dm 2way 4way 8way s1030507048 miss rate size kbytes go dm 2way 4way 8way dm 2way 4way 8way alternate trace id 2bit saturating counter guiding replacement accuracy correlated predictor aided return history stack call within trace path history register copied pushed onto hardware stack trace ends return path history value popped stack used replace newest trace path history register reduce impact coldstarts aliasing correlated predictor augmented second smaller predictor uses previous trace id whole path history table entry correlated predictor tagged last trace use entry tag matches correlated predictor used otherwise simpler predictor used counter simpler predictor saturated prediction automatically used regardless tag detailed treatment trace predictor found 3 215 trace characteristics important trace characteristics shown table 1 average trace length affects instruction supply bandwidth instruction buffer utilization larger better want significant fraction values locals reduce global communication note ratio locals liveouts tends higher longer traces observed 4 22 value predictor value predictor contextbased organized twolevel table contextbased predictors learn values follow particular sequence previous values 19 firstlevel table indexed unique prediction id derived trace id given trace multiple prediction ids one per livein address trace entry firstlevel table contains pattern hashed version previous 4 data values item predicted pattern firstlevel table used look 32bit data prediction secondlevel table replacement guided 3bit saturating counter associated entry secondlevel table predictor also assigns confidence level predictions 206 instructions issue predicted values predictions high level confidence confidence mechanism 2bit saturating counter stored pattern firstlevel table table sizes used study large order explore potential entries firstlevel 2 20 entries secondlevel accuracy contextbased value prediction affected timing updates accurately model detailed treatment value predictor found 19 23 distributed instruction window 231 trace dispatch dispatch stage performs decode renaming value predictions livein registers trace renamed looking physical registers global register rename map independently liveout registers receive new names freelist physical registers global register rename map updated reflect new names dispatch stage looks value predictions livein registers loadstore addresses trace dispatch stage also performs functions related precise exceptions similar mechanisms used conventional processors first segment reorder buffer rob reserved trace enough information placed segment allow backing rename map state instruction instruction second snapshot register rename map saved trace boundaries allow backing state point exception quickly processor first backs snapshot corresponding excepting trace information traces rob segment used back excepting instruc tion rob also used free physical registers 232 freeing allocating pes precise interrupts traces must retired inorder requiring rob maintain state outstanding traces number outstanding traces therefore limited number rob segments assuming enough physical registers match rob state handles trace retirement pe freed soon trace completed execution unfortunately knowing trace completed simple due misspeculation model mechanism needed determine instruction issued last time consequently pe freed trace retired retirement guarantees instructions done lower performance solution effectively arranges pes circular queue like segments rob pes therefore allocated freed fifo fashion even though might fact complete outoforder table 1 trace characteristics statistic comp gcc go jpeg xlisp trace length inst 145 139 148 158 124 liveins 52 43 50 68 41 liveouts 62 56 58 64 51 locals 56 38 59 71 26 loads 26 36 31 29 37 stores 09 19 10 12 22 cond branches 21 21 18 10 19 control inst 29 28 22 13 29 trace misp rate 171 81 157 66 69 233 processing element detail datapath processing element shown figure 4 enough instruction buffers hold largest trace loads stores address generation part treated instruction buffers memory access part loads stores along address pre dictions placed loadstore buffers included loadstore buffers validation hardware validating predicted addresses result address computa tions set registers provided hold livein predic tions along hardware validating predictions values received traces figure 4 processing element detail instructions ready issue operands become available livein values may already available global register file liveins may predicted values buffered instruction case instructions continually monitor result buses arrival new values operands memory access operations continually monitor arrival new computed addresses associated functional unit queue holding completed results instruction issue blocked results held waiting result bus result may local value liveout value case local global result buses arbitrated separately global result buses correspond directly write ports global register file characterized two numbers total number buses number buses pe arbitrate cycle memory buses correspond directly cache ports characterized similarly 24 misspeculation section 113 introduced model handling misspeculation instructions reissue detect mispredictions selectively reissuing dependent instructions follows naturally receipt new values section describes mechanisms detecting various kinds mispredictions 241 mispredicted liveins livein predictions validated computed values seen global result buses instruction buffers store buffers monitor comparator outputs corresponding livein predictions used predicted computed values match instructions used predicted livein reissued otherwise reissue case validation latency appears misprediction penalty absence speculation instructions may issued sooner 6 242 memory dependence address misspeculation memory system figure 5 composed data cache structure buffering speculative store data distributed loadstore buffers pes memory buses connecting trace dispatched loads stores assigned sequence numbers sequence numbers indicate program order memory operations window store buffer may organized like cache 21 integrated part data cache 13 important thing mechanism must exist buffering speculative memory state maintaining multiple versions memory locations 13 figure 5 abstraction memory system handling stores store first issues memory supplies address sequence number data one memory buses store buffer creates new version memory address buffers data multiple versions ordered via store sequence numbers store must reissue received new computed address must first undo state old address perform store new address transactions initiated store sending old address new address sequence number data one memory buses loadstore buf fu fu tags values tags values global buffers issue issue file reg file reg local result buses agen results store data fu fu global result buses ports buses addrdata livein value preds pes global memory buses datan data2 address multiple versions store must reissue received new data simply performs address handling loads load sends address sequence number memory system multiple versions location exist memory system knows version return comparing sequence numbers load supplied data sequence number store created version thus loads maintain two sequence numbers data load must reissue received new computed address simply reissues memory system new address loads snoop store traffic store address sequence number load must reissue 1 store address matches load address 2 store sequence number less load 3 store sequence number greater load data true memory dependence violation load must also reissue store sequence number simply matches sequence number load data takes care store changing address false dependence existed store load sending new data 243 concerning control misprediction conventional processor branch misprediction causes subsequent instructions squashed ever instructions controldependent misprediction need squashed 22 least three things must done exploit control independence trace processor first instructions fetched wrong path must replaced second although instructions necessarily replaced remain may still reissue changes register dependences third stores wrong path must undo speculative state memory system trace repredict sequences used selective control squashes detecting control misprediction within trace traces subsequent pes automatically squashed instead frontend repredicts dispatches traces resident trace id checked repredicted trace id partial ie common prefix total match instructions beyond match need replaced replaced register dependences may changed global register names instruction resident trace checked new trace instructions differ pick new names reissuing follow existing issue mechanism approach treats instructions like data values individually validated store removed window already performed must first issue memory undo transaction performed described previous section loads falsedependent store snoop store thus reissue removing adding loadsstores window cause sequence number problems sequence numbering based pe buffer 3 simulation environment detailed simulation used evaluate performance trace processors comparison superscalar processors also simulated simulator developed using simplescalar simulation platform 23 platform uses mipslike instruction set delayed branches comes gccbased compiler create binaries table 2 fixed parameters benchmarks primary simulator uses hybrid tracedriven executiondriven approach control flow simulator tracedriven functional simulator generates true dynamic instruction stream stream feeds processor simulator processor explicitly fetch instructions wrong path due control mis speculation data flow simulator completely latency 2 cycles fetch trace predictor see section 214 value predictor see section 22 trace cache total traces 2048 trace line size 16 instructions branch pred predictor 64k 2bit sat counters tags 1bit hyst instr cache line instructions 2way interleaved miss global phys regs unlimited functional units n symmetric fullypipelined fus nway issue memory unlimited speculative store buffering line size 64 bytes unlimited outstanding misses exec latencies address generation memory integer alu operations latencies validation latency compress modified make single pass benchmark input dataset instr count compress 400000 e 2231 104 million gcc o3 genrecogi 117 million go 9 9 133 million ijpeg vigoppm 166 million queens 7 202 million executiondriven essential accurately portraying data misspeculation model example instructions reissue due receiving new values loads may pollute data cache prefetch wrong addresses extra bandwidth demand observed result buses etc stated default control sequencing model control mispredictions cause new traces brought processor resolved aggressive control flow model investigated section 6 accurately measure selective control squashing fully executiondriven simulator developed considerably slower hybrid approach applied section 6 simulator faithfully models frontend pe memory system depicted figures 2 4 5 respec tively model parameters invariant simulations shown table 2 table also lists five spec95 integer benchmarks used along input datasets dynamic instruction counts full runs 4 primary performance results section performance trace processors conventional superscalar processors presented without data prediction difference superscalar simulator trace processor simulator superscalar centralized execution engine hardware frontend memory system identical thus superscalar benefit trace predictor trace cache reduced rename complexity selective reissuing due memory dependence violations experiments table 3 focus three parameters window size issue width global result bypass latency trace processors 4 8 16 pes simulated pe hold trace 16 instructions conventional superscalar processors window sizes ranging 16 256 instructions simulated curves labeled model name trace ss superscalar followed total window size points curve represent varying issue widths case trace proces sors aggregate issue width trace processor curves come pairs one assumes extra latency 0 bypassing values processing elements assumes one extra cycle 1 superscalar penalized results bypassed locals fetch bandwidth local global result buses cache buses chosen commensurate configura tions issue width window size note window size refers inflight instructions including completed yet retired retire width equals issue width superscalar entire trace retired trace processor graphs figure 6 first encouraging result benchmarks show ilp increases nicely window size issue bandwidth processor models except compress go exhibit poor control prediction accuracy absolute ipc also encouraging example large trace processors average 30 37 instructions per cycle gcc extra cycle transferring global values noticeable performance impact order 5 10 also notice crossover points trace processor curves example t64 2way per pe performs better t128 1way per pe low issue widths better augment issue capability add pes superscalar versus trace processors one way compare two processors fix total window size total issue width centralized instruction window happens divide window equal partitions dedicate equal slice issue bandwidth partition question focuses effect load balance load balance ipc trace processor approach superscalar processor example consider two points gcc jpeg xlisp graphs t128 0 2way per pe ss128 16way ipc performance differs 16 19 effect load balance also trace processor instruction buffers underutilized due small traces instruction buffers freed discrete chunks comparison rather arbitrary suggests equivalence based total issue width reality total issue width lacks meaning context trace processors really need comparison method based equivalent complexity ie equal clock cycle one measure complexity issue complexity goes product window size issue width 15 equivalence measure comparing two previous datapoints invalid superscalar processor much complex 128x16 versus 16x2 unfortunately one measure processor complexity instead take approach demonstrates philosophy next generation processors 1 take smallscale superscalar processor maximize performance 2 use highlyoptimized processor replicate taking advantage hierarchical organization words goal increase ipc keeping clock cycle optimal constant last graph figure 6 interprets data gcc philosophy suppose start superscalar processor instruction window 1 2 4way issue basic building block successively add copies form trace processor assume penalty one pe extra cycle bypass values pes might account global result bus figure 6 trace processor superscalar processor ipc note bottomright graph derived adjacent graph indicated arrow interprets data different way table 3 experiments pe window size fetchdispatch bw number pes 4 8 issue bw per pe total issue bw 4 8 local result buses global result buses 4 4 global buses used cache buses used ipc total issue width t128 1 ipc total issue width t128 1 ipc total issue width t128 1 ipc total issue width t128 1 ipc total issue width t128 1 ipc number pes gcc 1way issue 2way issue 4way issue arbitration global bypass latency extra wakeup logic snooping global result tag buses one might roughly argue complexity ie cycle time remains relatively constant successively pes gcc 4 way issue per pe ipc progressively improves 58 1 4 pes 19 4 8 pes 12 8 16 pes 5 adding structured value prediction section presents actual potential performance results trace processor configuration using data prediction chose configuration 8 pes 4way issue 1 extra cycle bypassing values global result buses experiments explore real perfect value pre diction confidence timing value predictor updates 7 bars benchmark figure 7 first four bars real value prediction labeled r first r denoting real prediction second qualifier denotes confidence model r real confidence says use predictions marked confident predictor oracle confidence says use value correctly predicted third qualifier denotes slow immediate updates predictor last three bars graph perfect valueno address prediction pv perfect addressno value prediction pa perfect value address prediction p figure 7 performance data prediction rightmost bar perfect prediction potential performance improvement data prediction signif icant around 45 benchmarks three benchmarks benefit twice much address prediction value prediction shown papv bars despite data predictions potential two benchmarks gcc xlisp show noticeable actual improvement 10 however keep mind data value prediction stage significant engineering remains done still much explored predictor design space although gcc xlisp show good improvement less quarter potential improvement gcc confidence mechanism fault oracle confidence makes 7 difference xlisp hand shows oracle confidence half potential improvement achievable unfortu nately xlisp performs poorly terms letting incorrect predictions pass confident first graph figure 8 shows number instruction squashes fraction dynamic instruction count first two bars without value prediction last two bars value prediction denoted v first two bars show number loads squashed stores dependence misspeculation total number squashes result due cascade reissued instruc tions livein address misspeculation add totals last two bars xlisps 30 reissue rate explains shows less performance improvement gcc despite higher accuracy second graph shows distribution number times instruction issues window figure 8 statistics selective reissuing 6 aggressive control flow section evaluates performance trace processor capable exploiting control independence instructions control dependent branch misprediction squashed instructions whose register dependences change selectively reissued described section 243 accurate measurement control flow model requires fetching instructions wrong paths primarily capture data dependences may exist paths reason use fully executiondriven simulator section trace processor 16 pes 4way issue per pe two benchmarks show significant improvement ipc compress 13 jpeg 9 benchmarks frequently traverse small loops containing simple reconvergent control flow also important small loops fixed number iterations allowing processor capture traces beyond loop value prediction performance results 50 100 150 200 300 400 450 500 compress gcc go jpeg xlisp benchmark improvement base ipc rrs rri ros roi pa 100 200 300 400 500 700 800 900 1000 number times issued fraction dynamic instr jpeg compress go gcc xlisp 0 5 10 15 20 30 comp gcc go jpeg xlisp instruction squash rate load squash total load squash v total v 7 conclusion trace processors exploit characteristics traces efficiently issue many instructions per cycle trace data characteristics local versus global values suggest distributing execution resources trace level way overcome complexity limitations also suggest interesting application value prediction namely prediction intertrace dependences treating traces unit control prediction results efficient high accuracy control prediction model initial evaluation trace processors without value prediction shows encouraging absolute ipc values eg gcc 3 4 reaffirming ilp exploited large programs complex control flow isolated performance impact distributing execution resources based trace boundaries demonstrated overall performance value replicating fast smallscale ilp processors hierarchy trace processors structured value prediction show promise although two benchmarks show noticeable performance improvement potential improvement substantial benchmarks feel good engineering value prediction confidence mechanisms increase gains pervasiveness speculation next generation processors misspeculation handling becomes important issue rather treating mispredictions afterthought speculation discussed data misspeculation incorporated existing issue mechanism also discussed mechanisms exploiting control independence showed sequential programs may benefit acknowledgments work supported part nsf grant mip 9505853 us army intelligence center fort huachuca contract dabt6395c0127 arpa order d346 views conclusions contained herein authors interpreted necessarily representing official policies endorsements either express implied us army intelligence center fort huachuca us government work also supported graduate fellowship ibm r trace cache low latency approach high bandwidth instruction fetching critical issues regarding trace cache fetch mechanism improving superscalar instruction dispatch issue exploiting dynamic code sequenc es facilitating superscalar processing via combined staticdynamic register renaming scheme value locality speculative execution performance potential data dependence speculation collapsing multiscalar architecture multiscalar pro cessors control flow speculation multiscalar processors dynamic speculation synchronization data dependences anatomy register file multiscalar processor data memory alternatives multiscalar processors 21264 superscalar alpha processor oforder execution hardware support large atomic units dynamically scheduled machines exploiting instruction level parallelism processors caching scheduled groups increasing instruction fetch rate via blockstructured instruction set ar chitectures predictability data values assigning confidence conditional branch predictions arba hardware mechanism dynamic reordering memory references limits control flow paral lelism evaluating future mi croprocessors simplescalar toolset tr hardware support large atomic units dynamically scheduled machines limits control flow parallelism anatomy register file multiscalar processor multiscalar architecture facilitating superscalar processing via combined staticdynamic register renaming scheme multiscalar processors trace cache assigning confidence conditional branch predictions increasing instruction fetch rate via blockstructured instruction set architectures performance potential data dependence speculation myampersandamp collapsing improving superscalar instruction dispatch issue exploiting dynamic code sequences exploiting instruction level parallelism processors caching scheduled groups dynamic speculation synchronization data dependences complexityeffective superscalar processors pathbased next trace prediction predictability data values value locality speculative execution control flow speculation multiscalar processors ctr lieven eeckhout tom vander aa bart goeman hans vandierendonck rudy lauwereins koen de bosschere application domains fixedlength block structured architectures australian computer science communications v23 n4 p3544 january 2001 peter g sassone scott wills scaling atlas chipmultiprocessor ieee transactions computers v54 n1 p8287 january 2005 bing luo chris jesshope performance microthreaded pipeline australian computer science communications v24 n3 p8390 januaryfebruary 2002 independence trace processors proceedings 32nd annual acmieee international symposium microarchitecture p415 november 1618 1999 haifa israel yiannakis sazeides james e smith limits data value predictability international journal parallel programming v27 n4 p229256 aug 1999 haitham akkary michael driscoll dynamic multithreading processor proceedings 31st annual acmieee international symposium microarchitecture p226236 november 1998 dallas texas united states avinash sodani gurindar sohi understanding differences value prediction instruction reuse proceedings 31st annual acmieee international symposium microarchitecture p205215 november 1998 dallas texas united states venkata krishnan josep torrellas need fast communication hardwarebased speculative chip multiprocessors international journal parallel programming v29 n1 p333 february 2001 amirali baniasadi balancing clusteringinduced stalls improve performance clustered processors proceedings 2nd conference computing frontiers may 0406 2005 ischia italy sriram vajapeyam p j joseph tulika mitra dynamic vectorization mechanism exploiting farflung ilp ordinary programs acm sigarch computer architecture news v27 n2 p1627 may 1999 subramanya sastry subbarao palacharla james e smith exploiting idle floatingpoint resources integer execution acm sigplan notices v33 n5 p118129 may 1998 venkata krishnan josep torrellas hardware software support speculative execution sequential binaries chipmultiprocessor proceedings 12th international conference supercomputing p8592 july 1998 melbourne australia steven k reinhardt shubhendu mukherjee transient fault detection via simultaneous multithreading acm sigarch computer architecture news v28 n2 p2536 may 2000 quinn jacobson james e smith trace preconstruction acm sigarch computer architecture news v28 n2 p3746 may 2000 pedro marcuello jordi tubella antonio gonzlez value prediction speculative multithreaded architectures proceedings 32nd annual acmieee international symposium microarchitecture p230236 november 1618 1999 haifa israel yiannakis sazeides james e smith modeling program predictability acm sigarch computer architecture news v26 n3 p7384 june 1998 sanjay jeram patel marius evers yale n patt improving trace cache effectiveness branch promotion trace packing acm sigarch computer architecture news v26 n3 p262271 june 1998 brian fields shai rubin rastislav bodk focusing processor policies via criticalpath prediction acm sigarch computer architecture news v29 n2 p7485 may 2001 amirali baniasadi andreas moshovos instruction distribution heuristics quadcluster dynamicallyscheduled superscalar processors proceedings 33rd annual acmieee international symposium microarchitecture p337347 december 2000 monterey california united states narayan ranganathan manoj franklin empirical study decentralized ilp execution models acm sigplan notices v33 n11 p272281 nov 1998 ramon canal antonio gonzlez lowcomplexity issue logic proceedings 14th international conference supercomputing p327335 may 0811 2000 santa fe new mexico united states n vijaykumar sridhar gopal james e smith gurindar sohi speculative versioning cache ieee transactions parallel distributed systems v12 n12 p13051317 december 2001 dana henry bradley c kuszmaul gabriel h loh rahul sami circuits widewindow superscalar processors acm sigarch computer architecture news v28 n2 p236247 may 2000 artur klauser abhijit paithankar dirk grunwald selective eager execution polypath architecture acm sigarch computer architecture news v26 n3 p250259 june 1998 ryan rakvic bryan black john paul shen completion time multiple branch prediction enhancing trace cache performance acm sigarch computer architecture news v28 n2 p4758 may 2000 amir roth gurindar sohi register integration simple efficient implementation squash reuse proceedings 33rd annual acmieee international symposium microarchitecture p223234 december 2000 monterey california united states bryan black bohuslav rychlik john paul shen blockbased trace cache acm sigarch computer architecture news v27 n2 p196207 may 1999 ivn martel daniel ortega eduard ayguad mateo valero increasing effective ipc exploiting distant parallelism proceedings 13th international conference supercomputing p348355 june 2025 1999 rhodes greece young michael smith better global scheduling using path profiles proceedings 31st annual acmieee international symposium microarchitecture p115123 november 1998 dallas texas united states ramon canal joanmanuel parcerisa antonio gonzlez dynamic code partitioning clustered architectures international journal parallel programming v29 n1 p5979 february 2001 efe yardimci michael franz dynamic parallelization mapping binary executables hierarchical platforms proceedings 3rd conference computing frontiers may 0305 2006 ischia italy pedro marcuello antonio gonzlez jordi tubella speculative multithreaded processors proceedings 12th international conference supercomputing p7784 july 1998 melbourne australia joanmanuel parcerisa antonio gonzlez reducing wire delay penalty value prediction proceedings 33rd annual acmieee international symposium microarchitecture p317326 december 2000 monterey california united states craig zilles gurindar sohi masterslave speculative parallelization proceedings 35th annual acmieee international symposium microarchitecture november 1822 2002 istanbul turkey ramon canal antonio gonzlez reducing complexity issue logic proceedings 15th international conference supercomputing p312320 june 2001 sorrento italy aneesh aggarwal manoj franklin scalability aspects instruction distribution algorithms clustered processors ieee transactions parallel distributed systems v16 n10 p944955 october 2005 steven e raasch nathan l binkert steven k reinhardt scalable instruction queue design using dependence chains acm sigarch computer architecture news v30 n2 may 2002 gabriel loh timestamping algorithm efficient performance estimation superscalar processors acm sigmetrics performance evaluation review v29 n1 p7281 june 2001 yuan chou jason fung john paul shen reducing branch misprediction penalties via dynamic control independence detection proceedings 13th international conference supercomputing p109118 june 2025 1999 rhodes greece freddy gabbay avi mendelson effect instruction fetch bandwidth value prediction acm sigarch computer architecture news v26 n3 p272281 june 1998 pedro marcuello antonio gonzlez jordi tubella thread partitioning value prediction exploiting speculative threadlevel parallelism ieee transactions computers v53 n2 p114125 february 2004 aneesh aggarwal manoj franklin instruction replication reducing delays due interpe communication latency ieee transactions computers v54 n12 p14961507 december 2005 vikas agarwal hrishikesh stephen w keckler doug burger clock rate versus ipc end road conventional microarchitectures acm sigarch computer architecture news v28 n2 p248259 may 2000 ramadass nagarajan karthikeyan sankaralingam doug burger stephen w keckler design space evaluation grid processor architectures proceedings 34th annual acmieee international symposium microarchitecture december 0105 2001 austin texas antonia zhai christopher b colohan j gregory steffan todd c mowry compiler optimization memoryresident value communication speculative threads proceedings international symposium code generation optimization feedbackdirected runtime optimization p39 march 2024 2004 palo alto california jeffrey oplinger monica lam enhancing software reliability speculative threads acm sigplan notices v37 n10 october 2002 sangyeun cho penchung yew gyungho lee access region locality highbandwidth processor memory system design proceedings 32nd annual acmieee international symposium microarchitecture p136146 november 1618 1999 haifa israel pedro marcuello antonio gonzlez clustered speculative multithreaded processors proceedings 13th international conference supercomputing p365372 june 2025 1999 rhodes greece sanjay jeram patel daniel holmes friendly yale n patt evaluation design options trace cache fetch mechanism ieee transactions computers v48 n2 p193204 february 1999 brian fahs satarupa bose matthew crum brian slechta francesco spadini tony tung sanjay j patel steven lumetta performance characterization hardware mechanism dynamic optimization proceedings 34th annual acmieee international symposium microarchitecture december 0105 2001 austin texas sangyeun cho penchung yew gyungho lee decoupling local variable accesses wideissue superscalar processor acm sigarch computer architecture news v27 n2 p100110 may 1999 alvin r lebeck jinson koppanalil tong li jaidev patwardhan eric rotenberg large fast instruction window tolerating cache misses acm sigarch computer architecture news v30 n2 may 2002 hoseop kim james e smith instruction set microarchitecture instruction level distributed processing acm sigarch computer architecture news v30 n2 may 2002 mladen berekovic tim niggemeier distributed simultaneously multithreaded smt processor clustered scheduling windows scalable dsp performance journal signal processing systems v50 n2 p201229 february 2008 venkata krishnan josep torrellas chipmultiprocessor architecture speculative multithreading ieee transactions computers v48 n9 p866880 september 1999 joanmanuel parcerisa antonio gonzalez improving latency tolerance multithreading decoupling ieee transactions computers v50 n10 p10841094 october 2001 michael gschwind kemal ebciolu erik altman sumedh sathaye binary translation architecture convergence issues ibm system390 proceedings 14th international conference supercomputing p336347 may 0811 2000 santa fe new mexico united states balasubramonian sandhya dwarkadas david h albonesi dynamically allocating processor resources nearby distant ilp acm sigarch computer architecture news v29 n2 p2637 may 2001 rajagopalan desikan simha sethumadhavan doug burger stephen w keckler scalable selective reexecution edge architectures acm sigplan notices v39 n11 november 2004 sangjeong lee penchung yew augmenting trace cache highbandwidth value prediction ieee transactions computers v51 n9 p10741088 september 2002 trace cache microarchitecture evaluation ieee transactions computers v48 n2 p111120 february 1999 andreas moshovos gurindar sohi reducing memory latency via readafterread memory dependence prediction ieee transactions computers v51 n3 p313326 march 2002 lucian codrescu steve nugent james meindl scott wills modeling technology impact cluster microprocessor performance ieee transactions large scale integration vlsi systems v11 n5 p909920 october james r larus whole program paths acm sigplan notices v34 n5 p259269 may 1999 smruti r sarangi wei liu josep torrellas yuanyuan zhou reslice selective reexecution longretired misspeculated instructions using forward slicing proceedings 38th annual ieeeacm international symposium microarchitecture p257270 november 1216 2005 barcelona spain r gonzlez cristal pericas valero veidenbaum asymmetric clustered processor based value content proceedings 19th annual international conference supercomputing june 2022 2005 cambridge massachusetts sangyeun cho penchung yew gyungho lee highbandwidth memory pipeline wide issue processors ieee transactions computers v50 n7 p709723 july 2001 troy johnson rudolf eigenmann n vijaykumar speculative thread decomposition empirical optimization proceedings 12th acm sigplan symposium principles practice parallel programming march 1417 2007 san jose california usa lucian codrescu scott wills james meindl architecture atlas chipmultiprocessor dynamically parallelizing irregular applications ieee transactions computers v50 n1 p6782 january 2001 joanmanuel parcerisa julio sahuquillo antonio gonzalez jose duato onchip interconnects instruction steering schemes clustered microarchitectures ieee transactions parallel distributed systems v16 n2 p130144 february 2005 michele co dee b weikle kevin skadron evaluating trace cache energy efficiency acm transactions architecture code optimization taco v3 n4 p450476 december 2006 jung ho ahn mattan erez william j dally tradeoff data instruction threadlevel parallelism stream processors proceedings 21st annual international conference supercomputing june 1721 2007 seattle washington roni rosner micha moffie yiannakis sazeides ronny ronen selecting long atomic traces high coverage proceedings 17th annual international conference supercomputing june 2326 2003 san francisco ca usa balasubramonian sandhya dwarkadas david h albonesi dynamically managing communicationparallelism tradeoff future clustered processors acm sigarch computer architecture news v31 n2 may j gregory steffan christopher colohan antonia zhai todd c mowry stampede approach threadlevel speculation acm transactions computer systems tocs v23 n3 p253300 august 2005 mahjur h jahangir h gholamipour performance trace locality reference performance evaluation v60 n14 p5172 may 2005 engin ipek meyrem kirman nevin kirman jose f martinez core fusion accommodating software diversity chip multiprocessors acm sigarch computer architecture news v35 n2 may 2007 jun yan wei zhang hybrid multicore architecture boosting singlethreaded performance acm sigarch computer architecture news v35 n1 p141148 march 2007 michael smith overcoming challenges feedbackdirected optimization keynote talk acm sigplan notices v35 n7 p111 july 2000 mladen berekovic sren moch peter pirsch scalable clustered smt processor digital signal processing acm sigarch computer architecture news v32 n3 p6269 june 2004 kevin skadron pritpal ahuja margaret martonosi douglas w clark branch prediction instructionwindow size cache size performance tradeoffs simulation techniques ieee transactions computers v48 n11 p12601281 november 1999 theo ungerer borut robi jurij ilc survey processors explicit multithreading acm computing surveys csur v35 n1 p2963 march