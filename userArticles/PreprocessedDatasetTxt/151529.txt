fast algorithms generating discrete random variates changing distributions one fundamental operations simulating stochastic discreteevent dynamic system generation nonuniform discrete random variate simplest form operation stated follows generate random variable x distributed integers 12n fixed nonnegative numbers wellknown alias algorithm available accomplish task o1 time difficult problem generate variates x ais changing time present three rejectionbased algorithms task algorithm characterize performance terms acceptance probability expected effort generate variate show fairly unrestrictive conditions longrun expected effort o1 applications markovian queuing networks discussed also compare three algorithms competing schemes appearing literature b introduction problem generating nonuniform discrete random variate fundamental simulation discrete event stochastic system simplest version problem generate variate random variable x p given p change time wellknown alias algorithm eg see 2 pp 158160 takes preprocessing time generate variate o1 time paper interested developing efficient algorithms case changing time procedure desirable simulation multidimensional markov processes used model queueing telephone networks definition problem follows suppose given n nonnegative numbers 1 sequence independent random variables problem generate variate xs realization fxsg refer integers ng outcomes x call rate outcome time static version problem rates change time dynamic version zero ss change time incremented discrete event simulation number ss change time incremented typically small algorithms developed paper attempt exploit special property section 2 first show rejection algorithm employed generate variates changing distributions performance algorithm characterized acceptance probability develop two additional algorithms expense additional memory improve significantly acceptance probability section 3 suppose rates random determined discrete state space markov process typically case applications explicitly characterize longrun acceptance probability longrun expected effort three algorithms terms steady state rates underlying markov process section 4 several classes queueing networks considered class characterize longrun performance algorithms terms defining parameters network section 5 compare algorithms paper eventlist approach assuming event list organized heap algorithm transit proposed fox 8 section 6 discuss several methods improving performance three algorithms discussed paper three algorithms following assumptions force throughout paper a1 exists finite exists finite b 0 refer 1 majorizing nvector three algorithms presented paper rejection based rejection algorithm operates respect majorizing nvector runs o1 average time provided acceptance probabilities bounded away zero n increases traditionally correctly however major theme literature rejection algorithms making implicit constant depending reciprocal acceptance probability small quantify constant terms particular quantify constant product form instances queueing network models terms traffic conditions clearly though heavier traffic nodes smaller constant essentially network call three algorithms generate1 generate2 generate3 generate1 implementation discrete version standard rejection using dynamic rate vector respect uniform majorizing nvector erate3 implementation discrete version standard rejection using dynamic rate vector respect nonuniform majorizing nvector erate1 generate3 based assigning single bucket event generate2 combines principle generate1 assignment possibly one bucket outcome bucket schemes considered literature apparently linked directly rejection algorithms 21 algorithm generate1 present first algorithm generating variates changing distribution algorithm makes use n buckets ie array b size n bucket capacity 1 bucket initially set bi 0a completes preprocessing clearly processing completed time notice initial contents bucket exceed unity algorithm generate variate x0 hereafter let u stand uniform random variable interval 0 1 algorithm generate1 step 1 generate u compute dnue step 2 let step 3 r bi accept output quit else go step 1 observe generate1 picks bucket random uniformly bucket chosen output probability bi notice r uniform variable interval 0 1 independent algorithm generate1 rejection algorithm eg see 2 pp 151152 generating discrete random variates fixed distributions rejection algorithm typically discussed context continuous random variables follows output algorithm generate1 distribution x0 key observation make generate1 also used generate variates changing distributions indeed suppose generate1 used generate variate xs thus sa time simply reset 1a procedure valid since assumption a1 contents bucket never exceeds unity order characterize performance generate1 let acceptance time event r bi first time step 3 invoked generating variate xs refer p acceptance time acceptance probability time note expected number uniform random variates u needed generate variate xs algorithm generate1 equal reciprocal acceptance probability theorem 21 acceptance probability time generate1 given p acceptance time na proof p acceptance time r bi r bi establishing result 2 theorem 21 know performance generate1 poor time average ss significantly less uniform upper bound particular generate1 exploit fact may many outcomes often case applications algorithms discussed generate2 generate3 take advantage special structure 22 algorithm generate2 generate1 one bucket assigned outcome n idea behind generate2 assign one buckets outcome number buckets assigned proportional upper bound ith rate specifically let fixed positive number let number buckets assigned outcome denoted l given also let total number buckets note following bounds total number buckets thus generate2 number buckets assigned held fixed even ss change chosen random one l buckets bucket assigned output certain probability probability however change ss change precise make use two arrays c b size l n respectively b set set cj equal outcome assigned bucket j 1 preprocessing step 1 outcome compute l step 2 compute prefix sums l sums step 3 initialize c follows fill cells 1 1 1 cells step 4 set next present procedure generating variate x0 algorithm generate2 step 1 generate u compute step 2 let step 3 let cj r bi output quit else go step 1 generate1 algorithm also used generate variate xs generated variate xs time simply reset note since never exceeds unity also note always set case generate2 reduces generate1 manner entirely analogous generate1 define event acceptance time algorithm generate2 theorem 22 time output generate2 distribution xs moreover generate2 p acceptance time proof p acceptance time l l 2 follows also note acceptance time l bi combining two expressions gives p ijacceptance time completes proof 2 theorem 22 directly gives following result corollary 21 following bounds acceptance probability generate2 p acceptance time furthermore divisor acceptance time since significantly less na algorithm generate2 give much higher acceptance probability compared generate1 23 algorithm generate3 last algorithm similar spirit generate2 advantage always achieving upper bound corollary 21 acceptance probability disadvantage effort required pass one iteration algorithm somewhat greater required generate2 generate3 makes use alias algorithm data structures also makes use array b size n initially set preprocessing including required alias algorithm equivalent version algorithm independently discovered fishman 5 algorithm generate3 step 1 use alias algorithm generate variate distribution step 2 generate uniform variate u step 3 u bi accept output quit else go step 1 leave reader establish following analog theorem 22 theorem 23 time output generate3 distribution xs moreover generate3 p acceptance time give brief comparison three algorithms throughout comparison suppose generate2 hence corollary 21 know acceptance probability generate2 greater 12 acceptance probability generate3 chart gives comparison memory requirements operation counts three algorithms assumed worst case memory count generate2 operation counts assumed following operations count 1 multiplication subtraction upper floor operation table look comparison uniform variate generation define operation count maximum number operations performed one pass steps algorithm memory operation count 2n integers generate3 integers particular acceptance probability generate2 close generate3 may conclude chart generate2 preferable generate3 also mention divisor rate rates change time generate2 streamlined streamlined version generate2 run faster alias algorithm streamlined algorithm similar identical algorithm developed fox see 2 pp 157158 foxs algorithm flexibility due choice parameter 24 performance measure randomized algorithms theorem 23 know expected number u needed generate variate xs greater b however theorem 23 exclude possibility number u needed generate xs exceeds probability analogous statements made theorem 21 theorem 22 order study question let independent identically distributed geometric random variables parameter p v thought number times coin flipped head appears mth time p probability head appears single flip chernoff bounds see eg 11 pp 388393 used obtain tight bounds probabilities tail ends v particular show following fixed 0 ffl 1 see 15 make use bounds analysis like function used specify asymptotic resource bounds deterministic algorithms e used specify resource like time space etc bounds randomized algorithms e defined follows definition 15 say function f e og exist constants c n 0 input size n n 0 ff 0 say function f g lim n1 theorem 24 let h lower bound acceptance probability three algorithms algorithm called times total number us generated algorithm 1 probability fixed proof follows chernoff bound observation number u generated three algorithms obtain variate x upper bounded geometric random variable parameter h 2 corollary 22 n number us generated 1 probability constant 0 ffl 1 fixed ff 1 thus number us generated e 3 random rates discrete event simulation rates typically evolve random manner context shall write ith rate time order emphasize fact rates random also write context random rates longer require variables xs independent require however independent given easily seen generate1 generate2 generate3 satisfy requirement assumptions a1 a2 translate directly current context replaced acceptance probabilities theorems 21 22 23 analogs context random rates replace ea applications see section 4 underlying discrete state space markov process defines rates 1 case total jump rate markov process sth jump convenient make following assumption a3 underlying markov process irreducible aperiodic positive recurrent assumption a3 force converge distribution random variable total rate process jump steady state let z total rate process arbitrary time instant steady state also well defined due assumption a3 random variables z take discrete values typically different distributions fact follows theorem 2106 walrand 16 following theorems enable us characterize longrun performance algorithms terms steadystate behavior underlying markov process course simulations steady state three algorithms let v number random variables u called order generate variate xs shall refer v effort required generate variate xs theorem 31 assumptions a1a3 generate1 following longrun acceptance probability longrun expected effort lim p acceptance time lim proof theorem 21 p acceptance time na taking expectations applying assumption a3 equalities gives lim p acceptance time na lim na 4 ey combined 5 6 give desired result 2 proofs following two theorems entirely analogous proof theorem 31 theorem 32 assumptions a1a3 generate2 following longrun acceptance probability longrun expected effort lim p acceptance time ezd lim theorem 33 assumptions a1a3 generate3 following longrun acceptance probability longrun expected effort lim p acceptance time lim 4 application queueing networks section give examples possible explicitly calculate moments appearing theorems section 3 although examples better studied analytical methods simulation results give insight run times generate algorithms queueing networks used extensively modeling analysis computer systems networks eg see 12 illustrate ideas variate generation consider open jackson network eg see 16 one fundamental queueing networks n singleserver queues customers arrive outside according poisson process rate routed queue probability r 0i service times queue exponentially distributed parameter customer completes service queue routed queue j probability r ij leaves network probability r i0 service times assumed independent arrival process assume exists nonnegative solution traffic equa ae assumption assures underlying markov process irreducible aperiodic positive recurrent consider simulating markov process associated queueing network note rate associated queue either 0 depending whether queue occupied empty note rate associated external arrivals 0 given current rates 0 elapsed time interevent time next arrival servicecompletion event exponentially distributed parameter event service completion queue probability sy arrival probability 0 sy determined elapsed time event type alias algorithm used determine o1 time queue customer routed including possibility routed outside new iteration begins ie incremented determine next interevent time next eventtype next queue customer routed note two rates change iteration iteration consider central component simulation procedure determining event type according probabilities sy one three algorithms applied characterize performance generate3 simple exercise reader generate1 generate2 note application theorem 41 longrun acceptance probability generate3 jackson network given lim p acceptance time longrun expected effort generate3 jackson network given lim proof let l denote random variable number customers present queue steady state well known since follows 7 combining last two expressions ez varz theorem 33 completes proof 2 see theorem 41 time average utilization ae queue least 12 case applications practical interest longrun acceptance probability greater 12 theorem 41 also tells us particularly desirable high values ae queues high service rates let us attempt characterize performance queueing networks first consider jackson network described servers queue suppose ae conditions associated markov process irreducible positive recurrent aperiodic case 0 values 0 following proof theorem 41 shown longrun expected effort generate3 given lim leave reader derive corresponding expression longrun acceptance probability easily shown 8 lim generate3 consider sequence queueing networks nth network sequence n stations network sequence satisfies 9 ffl 0 longrun average expected effort o1 second consider case multiple classes class c exogenous arrival rate c routing probabilities r c suppose one server queue service rate given depend class also suppose service discipline queue firstcomefirstserve fcfs c sets traffic equations suppose equation nonnegative solution c suppose modified definitions assumptions well known 7 continues hold true multiclass network hence theorem 41 holds unchanged third consider multiclass network single server node discussed suppose network closed ie customers neither enter leave network population size fixed class finite state markov process associated network irreducible aperiodic lim l number customers present node steady state quantity expressed terms defining parameters normalization constants networks discussed productform queueing networks let us consider nonproductform network particular consider closed multiclass singleserver network discussed paragraph suppose service rate class c customers queue c ie service rates depend class well queue thus takes values 0 1 n maximum service rate queue given cg let classc customer served queue steady state lim unfortunately current tools queueing theory offer means expressing fl c terms defining parameters nonproductform network numerous techniques available approximate quantities eg see 12 competing methods compare algorithm several competing schemes carry comparison two contexts multiserver queueing networks systems similarity 51 multiserver queueing networks consider network n queues series queue equipped servers server operates rate arrivals outside arrive rate customer traverses n queues sequence assume large say greater 100 shall assume traffic moderate heavy ie 5 9 must stress complexity bounds given section derived specific example necessarily extrapolate examples first competing method discuss makes use list future events assume reader familiar standard approach simulating discrete event system method data structure contains time next external arrival times service completions customers currently network thus data structure contains least 1 nm events assuming data structure organized heap method requires onm memory olog n log worstcase effort generate event assumed traffic conditions effort close worst case second competing method also employs list future events instead implemented across servers future event list implemented across queues case data structure contains time next arrival nonempty queue time next service completion assuming heap employed method requires memory olog n worstcase effort note complexity bounds heaps hold traffic conditions case moderate heavy traffic third competing scheme algorithm transit proposed fox 8 employing foxs notation fi vector takes form fi number busy servers queue time memory required approach shown longrun expected effort transit indeed employing notation fox choice fi 0 js j typically close n w typically close zero follows average complexity typical situations however transit modified run time olog n shown 9 though high implicit constant papers 8 9 discuss transit context implemented across queues discussed paragraph however analogous first competing method transit also implemented across servers 10 fourth competing scheme therefore transit implemented servers refer tran sittailored case fi vector takes form fi depending whether jth server time busy assume nm servers numbered also suppose fi 0 set maximum rates ie fi 0 transit simplifies algorithm transittailored step 1 use alias algorithm generate variate j distribution step 2 fi j 0 accept output j quit else go step 1 algorithm transittailored independently discovered fox 10 7 note transittailored transit respect majorizing vector clearly transittailored implementation standard rejection respect nonuniform nvector remarks t10 t11 9 case transit mentioned however implementation across servers except networks singleserver queues noted independently paper noted 7 note case transittailored generate3 identical analogous fashion define tailored algorithms generate2 generate3 easily seen generate3tailored equivalent transittailored whereas generate2tailored different mimicking analysis section 4 see transittailored longrun expected effort given lim n v interpreted number times step 1 invoked tran sittailored generating event time follows 10 longrun expected effort transittailored o1 sequence models however memory requirements omn therefore arrive following table memory longrun expected effort future olog n transit olog n transit omn o1 generate2 o1 generate3 therefore clear traffic conditions large n future event list transit competitive must stress complexities chart implicit constant factor depending reciprocal acceptance probability constants algorithms chart comparable except effort transit whose constant substantially larger let us compare constants transittailored generate3 first observe acceptance probabilities two algorithms identical ever transittailored requires one less operation generate3 pass steps algorithm therefore run times two algorithms going close transittailored slightly faster acceptance probability generate3 transittailored greater generate2 never twice much based observations discussion end section 2 make following conclusions first suppose memory issue transittailored gives slightly better performance generate3 compared generate2 tran sittailored requires operations per pass steps higher acceptance probability however acceptance probability generate2 made arbitrarily close acceptance probability transittailored decreasing hence sufficiently small generate2 slightly faster transittailored let us suppose memory issue generate2 suppose memory requirements generate2 generate3 roughly transittailored requires approximately times memory required generate2 generate3 100 eliminate competition mentioned end section 2 tradeoff operations per pass acceptance probability comparing generate2 generate3 although acceptance probability generate2 greater one half generate3 recommend user perform pilot runs choosing two algorithms example assumed servers customers homogeneous case eg various servers various phases phdistribution keeping track individual servers needed inhomogeneous case either heap implemented across servers ie first competing scheme one tailored algorithms would implemented 52 systems similarity definition similarity please refer 8 9 similarity general version transit o1 complexity even implemented across queues queueing network settings andor similarity respect nvector majorize dynamic rate vector however similarity transittailored generate1 generate2 generate3 perform badly queueing networks nodes light traffic common reliability model mentioned 8 later arguably acceptance probabilities generate1 generate2 generate3 bounded away zero n increases unless growth repair rates decrease failure rates unnaturally restricted point general version transit similarity imply reference vector globally majorizes 6 improving performance although algorithms generate2 generate3 useful many applications situations performance less satisfactory particular unsatisfactory performance occur expected rates typically far respective upper bounds ie section discuss three modifications generate2 designed alleviate even overcome prob lem paper 14 discuss modifications employed efficient simulation largescale telephone networks throughout section shall simplify notation suppressing references time variable discussing modifications beneficial introduce yet another algorithm generating variates changing distributions algorithm also independently discovered fishman yarberry 6 equivalent version found devroye 4 similar algorithm also given 13 ex 427 page 422 different context informal description algorithm follows sake convenience suppose log 2 n integer discussion algorithm based binary tree 1 levels n leaf nodes bottom level value associated ith leaf node value associated node sum values associated two sons node thus value node root binary tree 1 note preprocessing time needed set binary tree generate variate x first generate uniform number call z 0 compare number value associated left child root less know variate f1 proceed algorithm left side binary tree proceed right side tree value z minus value stored left child note number comparisons needed generate variate x log 2 n changes generating variate x update binary tree olog n operations follows first reset value associated leaf node 0 move path node root reset sums accordingly summary binarytree algorithm requires preprocessing time olog n time per variate generate variates x changing distributions advantage algorithm compared generate2 performance depend close upper bounds disadvantage take significantly time generate variate x n large acceptance probability generate2 small 61 method partitioning subset suppose exists partition 1 ng following properties vicinity larger conditions following scheme makes sense first draw uniform random variate u u declare variate x belongs 1 use generate2 across 1 determine u 1 1 declare variate x belongs 2 use binarytree method across 2 find course order utilize method need get handle ea n perhaps done analytical analysis pilot runs context queueing networks method may suitable fraction queues heavy traffic remaining queues light traffic mention another partitioning scheme noted 7 62 method ii pseudo upper bounds indices ea replace smaller value perhaps ea longrun standard deviation course assumes one get handle well ea may indices occurs algorithm generate2 longer correct since may bi 1 order rectify algorithm keep track set counter ffi maxfa phig phi empty set step 3 generate2 replace test r bi test r biffi leave reader verify correctness procedure necessary update phi ffi much effort required update suppose changes 0 necessary perform update following circumstances order minimize effort update phi ffi phi implemented priority queue data structure one four events occurs olog jphij operations sufficient update pseudo upper bounds chosen large enough jphij ffi typically small however chosen small acceptance probability becomes undesirably low 63 method iii global updates method ii may possible determine priori good pseudo upper bounds may case appropriate choice pseudo upper bounds changes evolution underlying process simulating cases may want consider occasional global updates pseudo upper bounds reinitializations arrays c b reinitialization make sure entries b close 1 course process global update costly requiring time done rarely may advantageous compared n may worthwhile perform global update detect given time low small many entries array b much less 1 make use following sampling process pick say 10 log n random outcomes major fraction outcomes entry much less say 12 b array perform global update using chernoff bounds show major fraction sample low b value major fraction b values low high probability also perform checking every 20 log n samples thus making sure total additional cost per sample due checking fraction similar reinitialization mentioned 8 conclusions paper presented three simple algorithms generating nonuniform discrete random variate changing distributions fairly unrestrictive assumptions algorithms expected o1 run time simulation results 14 confirm competitiveness algorithms relation future event schedule algorithms widely use though algorithms useful many applications important open problem follows exist constant time algorithm discrete random variate generation make assumptions way rates xs change algorithms positive step direction acknowledgements grateful professor george fishman professor bennet fox professor kurt mehlhorn dr marty reimann valuable comments r fast probabilistic algorithms hamiltonian circuits matchings journal computer systems science 182 guide simulation measure asymptotic efficiency tests hypothesis based sum observations annals mathematical statistics 23 nonuniform random variate generation springer exploiting special structure improve future event set management simulation technical report shortening future event lists appear orsa j generating markovchain transitions quickly operations research society america journal computing generating markovchain transitions quickly ii operations research society america journal computing queueing systems computer performance evaluation methodol ogy ieee transactions computers 33 introduction algorithms creative approach efficient simulation largescale loss networks technical report mscis9162 derivation randomized sorting selection algo rithms technical report introduction queueing networks tr guide simulation 2nd ed introduction algorithms ctr paul b callahan outputsensitive generation random events proceedings ninth annual acmsiam symposium discrete algorithms p374383 january 2527 1998 san francisco california united states keith w ross danny h k tsang jie wang monte carlo summation integration applied multiclass queuing networks journal acm jacm v41 n6 p11101135 nov 1994