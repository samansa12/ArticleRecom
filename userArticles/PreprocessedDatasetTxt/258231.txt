stability augmented system factorizations interiorpoint methods implementations interiorpoint algorithms obtain search directions solving symmetric indefinite systems linear equations conditioning coefficient matrices socalled augmented systems deteriorates later iterations diagonal elements grow without bound despite apparent difficulty steps produced standard factorization procedures often accurate enough allow interiorpoint method converge high accuracy underlying linear program nondegenerate show convergence arbitrarily high accuracy occurs rate closely approximates theory also explain demonstrate happens linear program degenerate convergence acceptable accuracy arbitrarily high accuracy usually obtained b introduction focus core linear algebra operation primaldual interiorpoint methods linear programming solution system linear equations whose coefficient matrix large sparse symmetric existing codes linear system formulated two different ways one formulation usually called augmented system formulation symmetric indefinite coefficient matrix involves compact generally denser symmetric positivedefinite matrix diagonal matrix involved formulations disconcerting property elements grow 1 iterates approach solution set blowup produce ill conditioning coefficient matrix linear system paper examine augmented system look various factorization algorithms system behave ill conditioning develops restrict study three standard factorization algorithms bunch parlett bunchkaufman sparse bunchparlett algorithms last used least one practical interiorpoint code linear programming see fourer mehrotra 5 assume attempt made improve conditioning underlying linear systems guessing whether component solution bound preprocessing kind detracts intuitive appeal interiorpoint algorithms namely avoid explicit guessing contents basis numerical experiments feasible linear programs find two distinct scenarios arise 1 even iterates close solution set computed search directions good enough produce rapid convergence algorithm nearly rates predicted theory performance little sur prising since matrix poorly conditioned might expected computed directions inaccurate allow algorithm make much progress scenario usually occurs underlying linear program unique primaldual solution 2 near solution calculation search direction fails breakdown matrix factorization else computed search direction inaccurate interiorpoint method move tiny distance along mathematics computer science division argonne national laboratory 9700 south cass avenue argonne il 60439 work supported mathematical information computational sciences division subprogram office computational technology research us department energy contract w31109eng38 violating bound scenario usually occurs underlying linear program degenerate analysis paper explains observations close examination behavior factorization algorithms highly structured matrices arise application effects roundoff error tracked using fairly standard techniques backward error analysis successful interiorpoint methods practical linear programming problems primaldual methods bestknown potentialreduction algorithm class devised kojima mizuno yoshise 9 review paper todd 17 contains wealth historical information potentialreduction methods early developments pathfollowing methods surveyed gonzaga 7 mizuno todd ye 15 describe important variant methods require iterates stay within cramped neighborhood central path zhang 25 extended pathfollowing approach allowing iterates infeasible retaining global convergence polynomial complexity see also wright 21 developments took place context linear complementarity class problems includes linear programming special case computational side ob1 code described lustig marsten shanno 10 generated search directions type described paper compute maximum step ff could taken along direction without violating positivity bounds set actual step length 995 ff mehrotras 14 predictorcorrector search direction differs one analyzed paper assumptions difference vanishes solution approached newer codes described mehrotra 14 fourer mehrotra 5 lustig marsten shanno 12 vanderbei 18 xu hung ye 23 implement mehrotras predictorcorrector strategy newer codes continue use step lengths based ff hence pay particular attention effect roundoff error quantity previous analysis illconditioned linear systems arise interiorpoint barrier methods carried ponceleon 16 wright 22 pon celeon 16 showed systems sensitive structured perturbations certain class provided underlying optimization problem well con ditioned wright 22 analyzed gaussian elimination context interiorpoint algorithms linear complementarity problems simultaneously original version paper independently fors gren gill shinnerl 4 performed analysis augmented system barrier algorithms analysis tends detailed results overlap however assume factorization algorithms select large diagonal elements pivots others pattern generally occur practice vavasis 19 gives illuminating discussion augmented system contexts optimization presents solution method provably stable certain sense guaranteed produce useful steps sense paper duff 3 also discusses augmented systems general context describes sparse factorization procedure 2 interiorpoint methods consider linear program standard form dual 1 2 solution x feasible 1 feasible 2 x complementary denote set primaldual solutions iterate x primaldual interiorpoint method satisfies strict inequality directions found applying modification newtons method following system nonlinear equations specifically search direction delta deltax deltas satisfies linear equations4 deltax delta deltas5 4 oe 2 0 1 known centering parameter important quantity defined step length ff along search direction determined various factors mini mally updated x components required stay strictly positive least half components x critical components become close lower bound zero later stages algorithm despite property step length ff quite close one without violating property 6 search direction delta deltax deltas exact solution 5 perturbations caused roundoff present critical components delta deltax deltas requirement 6 severely curtail allowable step length slow con vergence hence important critical components delta deltax deltas computed high relative accuracy point provides focus much error analysis throughout paper use u denote unit roundoff define implicitly statement x two floatingpoint numbers op denotes gamma theta flz denotes floatingpoint approximation real number z since concern internal workings single interiorpoint iterate omit iteration counters quantities reason use order notation odelta slightly unconventional way j two nonnegative numbers positive constant c large cj say matrix vector oj norm oj say purposes paper mainly interested factorizations behave relative u dimensions n ignored use notation odelta g matrix g deltaj denotes jth column g idelta denotes ith row matrix whose elements jg ij j denoted jgj use k delta k denote one equivalent matrix norms k k delta k1 g rectangular 2norm condition number defined follows definition 1 let g rectangular matrix full rank suppose svmax g svmin g denote largest smallest singular values g respectively 2norm condition number g g square nonsingular definition coincides usual definition 3 definitions assumptions assume throughout problems 1 2 feasible exists least one triple x satisfying constraints implies existence solutions 1 2 following theorem gives another consequence feasibility theorem 31 suppose 1 2 feasible x point exists solution delta deltax deltas 5 proof proof follows section 6 wright 21 see particular lemma 62 theorem 63 remarks last two paragraphs 21 note need full rank theorem 31 hold set basic indices ng defined nonbasic set n well known b n form partition f1 ng least one solution x strictly complementary x goldman tucker 6 cardinality b denoted jbj partitioning columns according b n define b theta jbj n theta jn j say linear program nondegenerate primaldual solution unique assume also b reasonably well conditioned nondegenerate problems confine analysis one specific primaldual algorithm rather rely set assumptions satisfied variety algorithms first assumptions concerns iterates search directions relationship current infeasibility assumption 1 sequence iterates x generated interiorpoint algorithm satisfies following properties becomes sufficiently small 11a addition infeasibility assumption 1 strong guler ye 8 study algorithms iterates strictly feasible fact require x slightly separated boundary positive orthant sense constant fl 2 0 1 show limit points algorithms strictly complementary solutions 1 2 pathfollowing potentialreduction algorithms fact satisfy 14 easy infer results 11 holds subsequences approach limit points moreover 12 trivially satisfied feasible algorithms infeasibleinteriorpoint algorithm described wright 20 satisfies assumption 1 algorithm 21 provided sequence iterates x bounded implemented algorithms vanderbei 18 lustig marsten shanno 10 11 xu hung ye 23 usually step fixed multiple distance boundary rather enforce potential reduction condition condition like 14 nevertheless iteration sequence usually satisfies properties assumption 1 practical problems finally state without proof technical lemma use later sections lemma 32 let h square matrix partitioned h 11 h 22 also square suppose h 11 h 22 gamma h nonsingular h nonsingular 4 exact approximate search directions defining r 5 obtain4 delta deltax deltas5 4 eliminating deltas system obtain augmented system formulation delta deltax 16a wright 22 performed error analysis system like 16a context specific pathfollowing algorithm monotone linear complementarity problem results 22 relevant present case 16 discuss later potential difficulties formulation 16 arise two sources possible rankdeficiency certain submatrices fact diagonal elements x approach zero others approach 1 despite effects ill conditioning finite precision find approximate search directions obtained 16 using standard factorization procedures often remarkably good allow interiorpoint algorithm take nearunit steps make substantial improvements duality measure following theorem specify set conditions happy situation holds later sections identify situations conditions hold remainder paper use ff denote largest number 0 1 17a decreasing ff 2 0 ff theorem 41 suppose assumption 1 holds let delta deltax deltas exact solution 5 equivalently 16 let c delta c deltax c deltas approximation step suppose centering parameter oe 5 lies range 0 12 following conditions hold 18a deltas 18c 17 suppose ff obtained replacing deltax deltas c deltax c deltas 17 sufficiently small ff c deltax proof 11a 18a components restrict value ff since u much smaller 1 use 18b well deduce deltas deltas similarly show xb decrease condition 17b show duality gap actually decreases entire interval 0 1 exact approximate search directions condition play role determining ff ff exact direction 5 18a oe 2 0 12 ff 2 0 1 hence sufficiently small duality gap decreasing 0 1 approximate direction c deltax c deltas bound modified slightly account inexactness omit details straightforward messy state conclusion dff deltax find duality gap decreasing whole interval ff 2 0 1 hence condition bound ff ff away 1 17a ncomponents x bcomponents fact ff satisfiesff 5 x deltas 11a 18a jdeltax x identical argument used term 22 haveff proving 19 maximum step length ff along approximate direction c deltax c deltas 18c 11b c deltas c hence 22 c deltas c sufficiently small estimates 20 follow immediately last expression finally estimate potential decrease 21 5 deltax deltas used assumption 1 18 estimate remainder terms finally obtain 21 substituting ff 5 augmented system remainder paper focus procedure based 16 finding search directions section define generalized form matrix 16a call canonical matrix show backward error analysis solution procedure satisfies certain condition condition 1 approximate step c delta c deltax c deltas obtained 16 finiteprecision environment useful sense theorem 41 later sections define conditions standard algorithms solving symmetric indefinite systems satisfy condition 1 hence yield useful search directions sharpened specialized error analysis yields much stronger results naive application standard results also gain insight algorithms work even nondegeneracy assumptions sections 6 7 8 fail hold continue generate useful search directions even degenerate problems quite small given symmetric matrix order n factorization procedures yield p permutation matrix l unit lower triangular blockdiagonal matrix 1 theta 1 2 theta 2 diagonal blocks denote counterparts matrices actually computed finiteprecision environment l respectively given system z data p l factorization find computed solution z performing two vector permutations p triangular substitutions l l blockwise inversion operations except permutations may introduce additional roundoff error must accounted error analysis methods focus single step factorization procedure applied matrix properties like given system 16a define definition 2 matrix canonical matrix symmetric permutation small diagonal diagonal elements omegagamma16 call degenerate canonical matrix form zero blocks nonvacuous keeping particular application 16a use n denote number rows columns composite matrix b j n respectively denote total dimension corresponding canonical matrix define canonical error matrix prove factorizations error matrix form definition 3 let canonical matrix corresponding canonical error matrix delta matrix dimension ffi u elements delta u ou important role pivot selection process played quantities denote magnitude largest offdiagonal element column sufficient condition useful steps following condition states common goal backward error analysis three factorization procedures condition satisfied along nondegeneracy linear program result theorem 41 holds condition 1 given system z canonical matrix symmetric factorization solution process yields computed solution z satisfies delta canonical error matrix associated ou allow perturbed righthand side nature particular system 16a residuals r b r c computed difference o1 quantities ou perturbations appear evaluated obvious way addition terms n x gamma1 may give rise errors similar magnitude theorem 51 suppose assumption 1 holds problem nonde generate moderate suppose procedure solving condition 1 denote approximate solution 16a c delta c deltax sufficiently small proof prove 31 appealing 5 partitioning b n according 10 partitioning diagonal matrices x accordingly see matrix 5 permutation of6 6 6 6 4 11 diagonal elements xb sn areomegagammae3 matrices sb xn addition b square well conditioned matrix 33 perturbation uniformly nonsingular matrix 5 result 31 follows 11 12 derive relative error estimate 32 consider system 16a permuting matrix accord b n partition rewrite 16a follows4 delta deltax n5 4 11 sufficiently small diagonals x gamma1 diagonals x gamma1 coefficient matrix canonical defining delta restate system mb mn z n db dn assumption b condition 1 computed solution z 35 satisfies mb mn z n db dn ou canonical error matrix delta satisfies combining estimate 35 36 obtain mb mn z n 31 z n ou ou ou add effect find righthand side 37 ou coefficient matrix 37 use lemma 32 lemma 32 yields following estimates combining observations 38 obtain ou ou giving 32 next examine accuracy c deltas calculated substituting c delta c deltax 16b theorem 52 suppose assumptions theorem 51 satisfied c deltas evaluated floatingpoint arithmetic formula 16b c deltax replacing deltax 39a deltas deltas proof standard roundoff error analysis applied 16b shows c deltaxj differencing 16b 40 obtain deltaxj 11 combining estimates 32 41 obtain desired result 39a 11 31 32 substituting 41 obtain 39b last two results show requirements theorem 41 satisfied algorithm make significant progress along search directions summarize combination theorems 41 51 52 corollary corollary 53 suppose assumption 1 holds problem non degenerate moderate suppose procedure solving condition 1 approximate step computed oe 2 0 12 sufficiently small formulae 19 20 21 satisfied 6 bunchkaufman factorization show section procedure solving 16a based bunchkaufman factorization satisfies condition 1 conclusion corollary 53 applies since much analysis section reused analysis bunchparlett sparse bunchparlett algorithms give details refer later sections sufficient describe first stage procedure later stages apply technique recursively remaining submatrix pivot selection procedure bunchkaufman 2 follows choose find r else 1 theta 1 pivot choose p 1 p 1 tp else 2 theta 2 pivot choose p 1 p 1 tp end denote 1 theta 1 2 theta 2 pivot block e write first step factorization yields c algorithm continues applying procedure note generally changed stage factorization contains subdiagonals first one two columns l factor bunch kaufman 2 show particular choice 178 modest bound element growth stage factorization applied canonical matrices bunchkaufman procedure selects pivots specific types produces reduced submatrix also canonical state results following two theorems whose proofs tedious relegated appendix theorem 61 let one step bunchkaufman factorization applied canonical matrix degenerate pivot block e either 1 theta 1 block chosen among diagonal elements ii 2 theta 2 block offdiagonal element e 12 one elements b b matrix remaining elimination canonical absolute change elements o1 c using notation 42 pivot theorem 62 let one step bunchkaufman factorization applied degenerate canonical matrix pivot block e either 1 theta 1 block chosen diagonals large small ii 2 theta 2 block elements b matrix remaining elimination canonical necessarily de generate absolute change remaining matrix assumption 1 initial matrix 16a canonical barring pathological growth remaining submatrices one theorems 61 62 applies every stage bunchkaufman factorization b square original matrix corresponding nondegenerate linear program remaining matrices encountered every stage factorization degenerate 1 theta 1 pivot dimensions b unchanged 2 theta 2 pivot shrinks b exactly one row column remains square pivot causes b disappear altogether reduced matrix form u follows case square b theorem 61 sufficient analyze entire factorization following result gives backward error analysis factorization case corollary 63 let bunchkaufman factorization applied canonical matrix b square sufficiently small obtain computed factors l delta canonical error matrix associated proof prove result induction argument dimension matrix induction made slightly complex usual form canonical matrix notably presence square matrix b dimension therefore 45 holds two cases two elements diagonal offdiagonals u hence 1 theta 1 pivot chosen pivoting first step elimination yields l unit diagonals obtain expanding factors delta delta canonical error matrix associated logic applies pivoting occurs remaining case pivot 2 theta 2 holds trivially examine canonical matrix dimension n 2 b square examine first stage factorization matrix canonical nondegenerate theorem 61 applies permutation matrix p 1 42 43 first stage yields partial factors 0 note delta canonical error matrix corresponding proof theorem 61 2 2 submatrix 1 canonical use inductive hypothesis deduce l factors submatrix satisfy permutation matrix p 2 canonical error matrix corresponding compose overall factors follows 0 0 substituting 47 46 48 obtain theta canonical error matrices corresponding hence delta canonical error matrix corresponding complete proof noting theorem 61 applied remaining also canonical nondegenerate given system z data p l factorization computed solution z found performing two vector permutations p triangular substitutions l l blockwise inversion 2 theta 2 diagonal blocks handled gaussian elimination procedure outlined following technical lemma proved appendix a3 easy show elements pivot block e satisfy condition 49 lemma 64 consider 2 theta 2 linear system e symmetric ffi 2 0 1 compute solution applying gaussian elimination permuted system computed solution satisfies additional error introduced recovery solution computed factors l l quantified next result lemma 65 suppose assumptions notation corollary 63 hold computed solution z system deltap delta canonical error matrix associated proof standard results triangular substitution computed solution similar result holds triangular substitution transpose solution z note blockdiagonal 1 theta 1 2 theta 2 blocks 2 theta 2 pivot blocks arise bunchkaufman procedure assumptions lemma 64 hold computed solution 2 theta 2 subsystem e 1 theta 1 block estimate 53 holds trivially hence computed solution z b z combining error expressions three component systems find computed solution z satisfies multiplying matrix products find 52 satisfied earlier discussions composition l easy see absolute matrix product j lj contains o1 elements except large diagonals occur positions ptp hence p deltap canonical error matrix corresponding ptp proof complete summarize effects roundoff error entire solution process 16 following theorem theorem 66 suppose canonical matrix b square sufficiently small bunchkaufman factorization followed solution process outlined satisfies condition 1 proof noted immediately following condition 1 actual righthand side may differ terms ou theoretical value 52 computed solution z z satisfies deltap substituting 45 obtain deltap condition 1 follows set delta shown case nondegenerate linear program procedure based applying bunchkaufman 16a leads approximate steps c delta c deltax c deltas satisfy conditions theorem 41 estimate 20 implies final iterations primaldual algorithm nearunit steps taken along directions without leaving nonnegative orthant moreover centering parameter oe small zero large reduction duality gap expected extreme case linear convergence rate constant ou attained actual step length close ff practical algorithms choose step length fixed multiple typically 95 9995 ff indeed methods often converge rapidly final stages algorithms use theoretically justifiable definition step length story unfortunately simple 22 section 4 instance extra restrictions applied ff ensure 12 14 continue hold next iterate restrictions may result ff much smaller one case analyzed 22 section 4 repeat finally note lower triangle l produced bunchkaufman factorization may contain elements much larger original matrix phenomenon closely scrutinized recent report ashcraft grimes lewis 1 observe leads convergence difficulties nonlinear programming code context canonical matrix theorem 61 blowup problem occur show part c theorem contribution ce gamma1 made one step bunchkaufman either o1 blowup problem may occur however degenerate canonical matrix theorem 62 deal matrices like linear program degenerate case serious difficulties face discuss section 9 7 bunchparlett factorization bunchparlett searches entire remaining matrix pivot one two columns pivot selection procedure follows choose rs choose p 1 p 1 tp else choose p 1 p 1 tp rs end elimination step identical bunchkaufman process using ldl factorization solve system z preceding section bunchkaufman value 178 leads modest bound 257 element growth stage applied canonical matrices bunchparlett factorization proceeds three stages 1 diagonal elements selected 1 theta 1 pivots 2 2 theta 2 pivots type described theorem 61a chosen 3 2 theta 2 pivots like available remaining matrix contains elements size u combination small 1 theta 1 pivots used complete factorization process prove assertion following lemma theorem 71 suppose bunchparlett procedure applied canonical matrix factorization proceeds according threestage outline canonical matrix b square nonvacuous factorization completed stages 1 2 stage 3 vacuous proof assuming vacuous pivot selection step pivot element therefore one large diagonals corresponding remaining matrix updated subtracting hence remaining matrix retains canonical form apply argument inductively diagonals exhausted end stage 1 remaining matrix form stage 2 begins b vacuous fact assumption b omegagamma245 omegagamma338 element rs achieves maximum comes b 2 theta 2 block offdiagonal element rs selected pivot elimination step size b reduced one row column proof theorem 61b applied show remaining matrix also canonical 2 theta 2 pivots type continue selected b vanishes number steps stage 2 minrowsb columnsb end stage remaining matrix square dimension elements size u stage 3 1 theta 1 2 theta 2 pivots may used factor matrix b square factorization complete stage 2 major results section 6 continue hold bunchparlett algorithm used instead bunchkaufman trivial adjustments analysis section 6 appendix a1 necessary summarize conclusions following theorem theorem 72 suppose canonical matrix b square sufficiently small bunchparlett factorization followed solution process outlined section 6 satisfies condition 1 8 sparse bunchparlett factorization several authors notably fourer mehrotra 5 proposed sparse variant bunchparlett factorization compromises maintaining sparsity limiting element growth remaining matrix outline pivot selection procedure described 5 slight modification noted index define degree n number offdiagonal nonzeros row also define estimate joint nonzero content rows j termed oxo ii jj zero tile one ii jj zero full ii jj nonzero define cost associated using 55 pivot block three cases tile n cost estimate fillin associated using 55 pivot block prospective pivots define stability criteria terms usual constant offdiagonal norms defined 29 1 theta 1 pivot must satisfy ii 2 theta 2 pivot 55 must pivot selection procedure follows consider ii degree elements accept 1 theta 1 pivot exit else label unstable unstable pivots ii previous loop consider 2 theta 2 pivots involving ii costs oxo tile full pivots respectively blocks satisfy 57 accept 2 theta 2 pivot exit end pivot selection pattern sparse bunchparlett algorithm essentially bunchkaufman algorithm described theorems 61 62 prove result appendix since analysis differs little bunchkaufman case theorem 81 results theorems 61 62 hold sparse bunch parlett factorization used place bunchkaufman procedure obtain result modified acceptance condition 56 1 theta 1 pivots description 5 righthand side 1ffi rather 2ffi original choice sparse bunchparlett algorithm applied degenerate canonical matrix could allow another type pivot 2 theta 2 pivot one diagonal size u pivot type poorly conditioned generally lead instability blockwise inversion major results section 6 also continue hold sparse bunch parlett algorithm used place bunchkaufman summarize conclusions following theorem theorem 82 suppose canonical matrix b square sufficiently small sparse bunchparlett factorization followed solution process outlined section 6 satisfies condition 1 9 degenerate case linear program 1 2 degenerate three factorization procedures longer run completion two kinds pivots described theorem 61 nonsquare shape b matrix 34 means pivots size u either 1 theta 1 2 theta 2 used point factorization process factorizations fail pivots exactly zero happens often small problems otherwise common outcome interiorpoint algorithm makes slow erratic progress achieved certain small value section sketch reasons outcome factorizations large diagonal elements x gamma1 n sn used 1 theta 1 pivots even though pivots necessarily used others except bunchparlett algorithm factorizations behave solving system 16 equivalent partitioned form delta theta coefficient matrix 58 perturbation matrix since b well conditioned definition 2 matrix 60 2 minjbj nonzero singular values magnitudeomegagammagni nondegenerate case 60 well conditioned otherwise jm gamma jbjj zero singular values jbj null space 60 spanned z z theta gamma jbj matrix full rank b null space 60 spanned matrix z z spans null space b small null spaces altered much perturbation size present matrix 58 nonzero singular values 60 well separated zero perturbations solution 58 due roundoff occur mainly space small singular values hence jbj perturbations occur mostly range space matrix 61 components delta similarly jbj perturbations occur range space matrix 61 components deltax b main source difficulty inaccuracy computed residual vectors r b r c mentioned contain errors ou case jbj perturbations magnified inverses small singular values usually leading errors size ou components deltax b large relative errors deltax b induce large relative errors deltas b formula 16b step length boundary ff may therefore sharply curtailed nonnegativity requirements 17a case jbj large relative errors delta induce errors deltax n formula 59 turn induce large relative errors deltas n 16b step length may curtailed result errors sources vector r less significant strictly feasible starting point see 13 simply set throughout algorithm case fix r zero computations avoid problem usually easy find starting point however thought given ways dealing problem one option simply terminate algorithm stalls declaring success r small option works well purposes since stalling usually occurs reduced ou time problem usually converged acceptable accuracy fourer mehrotra 5 report convergence criteria usually satisfied ill effects roundoff seen testing section 10 allows similar conclusion second option switch termination procedure interiorpoint algorithm stalls finite termination procedure see example ye 24 crossover simplex method meggido 13 could activated third option simply fix r zero computations reached ou level stage current point feasible within limits floatingpoint arithmetic effectively introducing perturbation problem freeze infeasibility current level perturbation interesting effect moves solution particular vertex previously optimal face changing b n partition appropriately continue run interiorpoint algorithm higher accuracy eventually converges vertex going many iterates taking sharp turns process result process similar would achieve crossover simplex computational cost would generally much higher 10 computational experiments report computational experiments demonstrate effects described testbed algorithm pathfollowing algorithm described wright 21 exact arithmetic algorithm achieves superlinear convergence eventually always takes affinescaling steps 5 step length ff approaching 1 algorithm performs well practical problems fast codes use mehrotra predictorcorrector heuristic solid convergence theory exists except nondegenerate case asymptotic behavior finite precision quite similar two algorithms show finite precision effects confined nice problems generate problems fairly wide variations components x n matrix dense random elements defined every instance selected uniform distribution interval 0 1 choose elements first row positive ensure feasible region bounded control size index sets b n control amount degeneracy set choose particular solution setting vectors b c determined choices lapack bunchkaufman factorization routines dsytrf dsytrs used solve 16a routines rest code use doubleprecision arith metic giving sparc5 results obtained report problems problems smaller exactly zero pivots often occur degenerate cases leading breakdown termination occurs artificially stringent criterion chosen give us clear look asymptotic effects first result nondegenerate problem 1 shows sizes krk iterate reasons outlined immediately following condition 1 krk stabilizes magnitude ou duality gap converge subquadratically would exact arithmetic rather exhibits extremely fast linear convergence rate constant 10 gamma10 exactly effect predicted formula 21 affinescaling steps taken last four iterations see pivots properties predicted theorem 61 examine matrix bunchkaufman factorization table 2 shows iteration expected six 1 theta 1 pivots pivots diagonals tiny offdiagonals areomegagammae4 structure present every iteration iteration 15 second example dual degenerate problem seen table 3 algorithm achieves fairly high accuracy 20 iterations improvement made point behavior consistent discussion section 9 suggests results section 6 tight cannot prove useful search directions obtained arbitrarily small examination factor second example table 4 shows pivot pattern line predictions theorems 61 62 together results imply exactly minm jbj stable 2 theta 2 pivots 3 43 16 5 31 120 19 221 138 20 333 142 termination table factor iteration 17 nondegenerate test problem rowcolumn pivot block table dual degenerate problem 19 60 138 22 148 138 factor iteration 17 degenerate test problem magnitude less rowcolumn pivot block 9 offdiagonal b jn large 1 theta 1 pivots together stable pivots account stages factorization unstable pivots used remaining submatrix whose dimension jm gamma jbjj table 4 see last two 1 theta 1 pivots unstable expected described first part section 9 errors c deltax b c deltas b preventing progress iteration 100 computed affine step k c exact counterpart would kdeltax b k1 comparing components c deltas b b find step boundary sharply curtailed restriction deltas 23 remaining components step contain deleterious errors deltas finally consider primal degenerate problem iteration schedule table 5 shows similar behavior dual degenerate problem factor iteration 100 shown table 6 pivots stable except last two 1 theta 1 blocks matches prediction 63 discussed section 9 deleterious errors occur subvector c delta errors induced c deltas n c deltax n formulas 59 16b iteration 100 k c deltas affine scaling step components c deltax b c deltas b affected 1norms 17gamma18 51gamma12 respectively primal degenerate problem 100 176 140 table factor iteration 17 degenerate test problem rowcolumn pivot block 14 proofs theorems sections 6 8 a1 proof theorem 61 prove systematically excluding possible choices pivots iii pivot 1 theta 1 diagonal element either 1 1 2 2 blocks canonical matrix inspection bunchkaufman algorithm shows 11 chosen pivot either r since r maximum offdiagonal column 26 o1 since 11 comes either 1 1 2 2 block 26 jt fixed 64 magnitude largest offdiagonal rowcolumn 26 1 1norm row column b 65 incompatible hence jt 11 j 1 1 2 2 blocks cannot used pivot similar argument holds rr chosen pivot rr one small diagonals iv pivot 2 theta 2 involves least one element since offdiagonals 26 o1 quantities o1 pivot diagonal elements 11 rr must implies 11 rr o1 since diagonals cannot candidates 11 rr v pivot 2 theta 2 pivot block drawn either entirely 1 1 block 26 entirely 2 2 block case 1r element jt 1r 1r largest magnitude column 26 since column includes either row column b one rows columns b u iii contradiction since estimate incompatible b omegagamma43 completes proof part turn b examining effects one step elimination performed pivot selection corresponding two cases ii suppose element chosen pivot symmetric permutation canonical matrix place pivot 1 1 position obtain p permutation matrix n deltai denotes ith column n n obtained n removing n deltai obtained removing ith row column since j ou gamma1 submatrix remains elimination ii theta easy see 66 canonical result proved case case ii proof little messier suppose diagonals 2 theta 2 pivot element e 1 j j element e 2 symmetric rearrangement put pivot upper left corner 26 becomes deltaj p permutation matrix ith row n n n n idelta removed ith row b jth element removed jth column b ith element removed ith jth column removed choice b ij either largest element row largest element column b assumptions b deduce jb ij j denoting pivot block e therefore elimination step yields remaining matrix deltaj obvious 68 satisfies definition 2 except possibly conditioning remaining matrix b matrix obtained pivoting j element b 1 1 position one step gaussian elimination fact partial pivoting since noted b ij largest element either row column hence conditioning reduced submatrix b unlikely differ much b reasonable assert shown stated result holds cases ii proof part b complete part c note whether pivot block 1 theta 1 2 theta 2 pivots pivots omegagamma17 a2 proof theorem 62 prove excluding possible choice pivot iii pivot 2 theta 2 contains least one element degenerate canonical matrix pivot diagonal elements 11 rr must implies diagonals ou neither element come case either 1 theta 1 2 theta 2 pivot made elements size ou use standard argument element growth bunchkaufman argument leads 44 deduce result b remaining case pivot single diagonal element notation 42 hence update remaining submatrix bounded certainly size u a3 proof lemma 64 proof floatingpoint arithmetic lu factorization 50 yields following approximate lu factors well known triangular substitution applied triangular system h computed solution z satisfies u h jeu applying observation matrices 69 find computed solution 50 satisfies multiplying coefficient matrix 70 obtain last equality follows 49 hence 71 written satisfies bound 51 a4 proof theorem 81 proof start proving analog theorem 61a earlier proof systematically exclude three possible choices pivots iii pivot 1 theta 1 diagonal element either 1 1 2 2 blocks 26 pivot ii say u according stability criterion 56 implies one rows columns b ou however estimate incompatible o1 kind pivot cannot occur iv pivot 2 theta 2 involves least one diagonal element first show cannot diagonals case least one diagonals ii say would considered 1 theta 1 pivot earlier point algorithm considered would accepted since ii sufficiently small hence one diagonals without loss generality suppose 57 ii remaining diagonal jj u fact fi fi fi fi fi hence 57 second row inequality 1norm one rows columns b estimate contradicts assumptions b hence type pivot cannot occur v pivot 2 theta 2 pivot block e drawn either entirely 26 entirely 2 2 block case elements e u 57 taking second row relation obtain definition j nonnegative consider two cases 72 reasons outlined earlier assumptions b inconsistent bound case cannot hold case jt ij also disallowed assumptions hence pivots type cannot occur proof remaining parts b c theorem 61 identical case turning case degenerate canonical matrix analog theorem 62 start showing 2 theta 2 pivots may contain diagonal elements note degenerate matrix offdiagonals hence quantities size u pivot 2 theta 2 block diagonals one ii say must considered previously 1 theta 1 pivot considered would accepted since ii hence type pivot cannot occur one diagonals diagonal element jj say must considered earlier 1 theta 1 pivot since would accepted reason described hence pivot ii size u must considered 1 theta 1 pivot rejected 56 ii must hand since 2 theta 2 pivot accepted must consider first case 2 j first block row 74 inequality implies contradicts assumption jj remaining case 74 73 contradiction hence kind pivot exactly one diagonals comes cannot occur either done analog part b theorem 62 56 57 definition c e 42 hence update matrix ce gamma1 c bounded follows giving result acknowledgments thank editor linda kaufman care took paper two anonymous referees meticulous reports improved presentation content also thank john lewis interesting discussions bunchkaufman factorization visit argonne april 1995 r accurate symmetric indefinite linear equation solvers stable methods calculating inertia solving symmetric linear systems solution augmented systems stability symmetric illconditioned systems arising interior methods constrained optimization solving symmetric indefinite systems interiorpoint method linear programming theory linear programming p nl iteration potential reduction algorithm linear complementarity problems computational experience primaldual interior point method linear programming finding primal dualoptimal bases implementation primaldual interior point method adaptive step primaldual interiorpoint algorithms linear programming potential reduction methods mathematical programming technical report sor 925 stable numerical algorithms equilibrium systems simplified homogeneous selfdual linear programming algorithm implementation finite convergence interiorpoint algorithms linear programming convergence class infeasibleinteriorpoint methods horizontal linear complementarity problem tr ctr stephen j wright superlinear convergence stabilized sqp method degenerate solution computational optimization applications v11 n3 p253275 dec 1998 csaba mszros detecting dense columns interior point methods linear programs computational optimization applications v36 n23 p309320 april 2007 cafieri dapuzzo v simone serafino iterative solution kkt systems potential reduction software largescale quadratic problems computational optimization applications v38 n1 p2745 september 2007