selfcalibration 1d projective camera application selfcalibration 2d projective camera abstractwe introduce concept selfcalibration 1d projective camera point correspondences describe method uniquely determining two internal parameters 1d camera based trifocal tensor three 1d images method requires estimation trifocal tensor achieved linearly approximation unlike trifocal tensor 2d images solving roots cubic polynomial one variable interestingly enough prove 2d camera undergoing planar motion reduces 1d camera observation deduce new method selfcalibrating 2d camera using planar motions selfcalibration method 1d camera applications 2d camera calibration demonstrated real image sequences b introduction ccd camera commonly modeled 2d projective device projects point p 3 projective space dimension 3 point p 2 analogy consider call 1d projective camera projects point p 2 point p 1 1d projective camera may seem abstract many imaging systems using laser beams infrared ultrasound acting source plane modeled way less obvious interesting purpose situations usual 2d camera model also closely related 1d camera model one first example might case 2d affine camera model operating line segments direction vectors lines 3d space image correspond via 1d projective camera model 21 cases discussed later paper first introduce concept selfcalibration 1d projective camera analogy 2d projective camera active topic 17 12 7 13 1 29 20 since pioneering work 18 turns theory selfcalibration 1d camera considerably simpler corresponding one 2d essentially determined unique way linear algorithm using trifocal tensor 1d cameras establishing result investigate relationship usual 2d camera 1d camera turns 2d camera undergoing planar motion reduced 1d camera trifocal line 2d cameras remarkable relationship allows us calibrate real 2d projective camera using theory selfcalibration 1d camera advantage evident instead solving complicated kruppa equations 2d camera selfcalibration exact linear algorithm used 1d camera selfcalibration constraint motion 2d camera restricted planar motions applications including 2d affine camera calibration also briefly discussed part work also presented 10 paper organised follows section 2 review 1d projective camera trifocal tensor efficient estimation trifocal tensor discussed section 3 theory selfcalibration 1d camera introduced developed section 4 pointing direct applications theory section 5 develop section 6 new method 2d camera selfcalibration converting 2d camera undergoing planar motions 1d camera experimental results simulated real image sequences presented section 7 finally concluding remarks future directions given section 8 throughout paper vectors denoted lower case boldface matrices tensors upper case boldface basic tensor notation used covariant indices subscripts contravariant indices superscripts implicit summation convention projective camera trifocal tensor first review onedimensional camera abstracted study geometry lines affine cameras 21 also introduce directly analogy 2d projective camera 1d projective camera projects point projective plane point projective line projection may described 2 theta 3 homogeneous matrix x examine geometric constraints available points seen multiple views similar 2d camera case 23 24 13 28 9 constraint case 3 views constraint 2 views two projective lines always intersect point projective plane let three views point x given 1 rewritten matrix form 0 vector cannot zero 0 2 expansion determinant produces trifocal constraint three views ijk 2 theta 2 theta 2 homogeneous tensor whose components ijk 3 theta 3 minors involving three views following 6 theta 3 joint projection matrix components tensor made explicit bracket denotes 3 theta 3 minor ithj 0 th k 00 th row vector joint projection matrix bar j k denotes mapping 1 2 7 2 gamma1 easily seen constraint obtained adding views reduces trilinearity proves uniqueness trilinear constraint moreover 2 theta 2 theta 2 homogeneous tensor minimal parametrization three views uncalibrated setting since three views exactly 3 theta 2 theta 3 gamma projective transformation p 2 result onedimensional projective camera interesting trifocal tensor encapsulates exactly information needed projective reconstruction p 2 namely unique matching constraint minimally parametrizes three views estimated linearly contrast 2d image case multilinear constraints algebraically redundant linear estimation approximation based overparametrization 3 estimation trifocal tensor 1d camera point correspondence 3 views u yields one homogeneous linear equation 8 tensor components ijk 2 least 7 point correspondences solve tensor components linearly careful normalisation measurement matrix nevertheless necessary like stressed 11 linear estimation fundamental matrix points image first translated centroid points origin image coordinates scaled average distance points origin 1 achieved affine transformation image coordinates image normalised image coordinates normalised tensor components ijk linearly estimated svd original tensor components ijk recovered descaling normalised tensor ijk c 4 selfcalibration 1d camera 3 views concept camera selfcalibration using point correspondences became popular computer vision community following maybank faugeras 18 solving socalled kruppa equations basic assumption internal parameters camera remain invariant case 2d projective camera internal calibration determination 5 internal parameters equivalent determination image absolute conic p 3 41 internal parameters 1d camera circular points 1d camera represented 2 theta 3 projection matrix 2theta3 projection matrix always decomposed r 2theta2 k ff represents two internal parameters ff focal length pixels u 0 position principal point external parameters represented 2 theta 2 rotation matrix r 2theta2 cos sin sin cos translation vector 2theta1 object space 1d camera projective plane rigid motion plane leaves two circular points j invariant pair complex conjugate points line infinity plane similar 2d camera case knowledge internal parameters equivalent image absolute conic knowledge internal parameters 1d camera equivalent image points j circular points p 2 relationship image circular points internal parameters 1d camera follows directly projecting one circular points gamma1 camera 2theta3 ff r 2theta2 clearly appears real part ratio projective coordinates image circular point position principal point u imaginary part focal length ff 42 determination images circular points next task locate circular points images let us consider one circular points say circular point projected onto 0 00 three views invariant assumption internal parameters camera constant triplet corresponding points satisfies trilinear constraint 3 corresponding points therefore ijk 0 yields following cubic equation unknown cubic polynomial one unknown real coefficients general either three real roots one real root pair complex conjugate roots latter case one real pair complex conjugates obviously case interest fact equation 4 characterizes points projective plane coordinates three views reminiscent 3d case one interested locus points space project onto point two views see section 6 result obtained case internal parameters camera constant general three points two circular points complex conjugate real point following geometric interpretation consider first case two views let us ask question set points images two views set points called 2d horopter h set two 1d views since two cameras internal parameters ignore assume work calibrated pixel coordinates case camera identified orthonormal system coordinates centered optical center one axis parallel retina one optical axis two views correspond via rotation followed translation always described general pure rotation around point whose coordinates easily computed cameras projection matrices simple computation shows horopter h circle going two optical centers illustrated figure 1a fact circle minus two optical centers note since circles go circular points hence name also belong horopter curve expected case three views real point exists must intersection horopter first two views horopter h 23 last two views first one circle going optical centers c 1 c 2 second one circle going optical centers c 2 c 3 two circles intersect general second point c real point discussing third circle h 13 corresponding first third views must also go real point c see figure 1b first camera second camera center rotation bc second camera c2first camera third camera figure 1 two dimensional horopter set points coordinates 2 views see text b geometric interpretation real point c images three views see text therefore established interesting result internal parameters 1d camera uniquely determined least 7 point correspondences 3 views seven points yield trifocal tensor equation 4 yields internal parameters applications theory selfcalibration 1d camera considerably simpler corresponding one 2d 18 directly used whenever 1d projective camera model occurs instance selfcalibration active systems using laser beams infrared 3 ultrasound whose imaging system basically reduced 1d camera source plane partialfull selfcalibration 2d projective camera using planar motions first type applications straightforward interesting observation 1d calibration procedure also used selfcalibrating real 2d projective camera camera motion restricted planar motions discussed detail remaining paper 6 calibrating 2d projective camera using planar motions planar motion consists translation plane rotation axis perpendicular plane planar motion often performed vehicle moving ground used camera selfcalibration beardsley zisserman 4 armstrong et al 1 recall selfcalibration 2d projective camera 8 18 consists determining 5 unchanging internal parameters 2d camera represented 3 theta 3 upper triangular matrix mathematically equivalent determination image absolute conic plane conic described x given image absolute conic x calibration matrix k found c using choleski decomposition converting 2d images 1d images given planar motion trifocal planethe plane camera centersof camera coincident motion plane camera moving therefore image location motion plane trifocal line could determined fundamental matrices determination image location motion plane reported 1 4 obviously restricting working space trifocal plane perfect 1d projective camera model projects points trifocal plane onto trifocal line 2d image plane trifocal line image trifocal plane practice points really lie trifocal plane however may virtually project 3d points onto trifocal plane therefore comes central idea method 2d images camera undergoing planar motion reduce 1d images projecting 2d image points onto trifocal line achieved least two ways first vanishing point v rotation axis welldefined vanishing point rotation axis direction perpendicular common plane motion determined fundamental matrices noticing image horopter planar motion degenerates two lines 1 one goes vanishing point rotation axis may refer 1 details given 3d point image mentally project plane motion projection parallel direction rotation image virtual point obtained image intersection line v theta trifocal line ie v theta since vanishing point v rotation axis trifocal line well defined construction illustrated figure 2 welldefined geometric operation note also projective projection p 2 image plane p 1 trifocal line 7 illustrated figure 3 alternatively vanishing point available nonetheless create virtual points trifocal plane given two points 0 images 0 line 0 intersects plane motion image virtual point obtained image intersection line 0 trifocal line see figure 4 another important consequence construction 2d image line segments also converted 1d image points construction even simpler resulting 1d image point intersection line segment trifocal line direction axis rotation figure 2 creating 1d image 2d image vanishing point rotation axis trifocal line see text trifocal line vanishing point rotation axis 2d image point 1d image point figure 3 converting 2d image points 1d image points image plane equivalent projective projection image plane trifocal line vanishing point rotation axis projection center figure 4 creating 1d image pairs points line segments see text 1d selfcalibration point obtained interesting result 1d projective camera model obtained considering reprojected points trifocal line planar motion 1d selfcalibration method described section 4 allow us locate image circular points common planes parallel motion plane estimation image absolute conic 2d camera planar motion generally gives us two points absolute conic together vanishing point rotation axes pole trifocal line wrt absolute conic polepolar relation vanishing point rotation axes trifocal line introduced 1 whole provides 4 constraints absolute conic since conic 5 dof least different planar motions yielding 8 linear constraints absolute conic sufficient determine full set 5 internal parameters general 2d camera fitting general conic assume 4parameter model camera calibration image skew ie planar motion yielding 4 constraints generally sufficient determine 4 internal parameters 2d camera however true common planar motions purely horizontal vertical motions image plane perpendicular motion plane easily proven 3 instead 4 independent constraints absolute conic configurations need least 2 different planar motions determining 4 internal parameters also suggests even planar motion purely horizontal vertical close vanishing point rotation axes constrains loosely absolute conic using circular points located absolute conic preferable numerically stable may need least 3 planar motions determine 5 internal parameters 2d camera note numerical instability vanishing point nearly horizontal trifocal line already reported armstrong 2 obviously work 3parameter model known aspect ratio without skew one planar motion sufficient 1 mentioned beginning section method described section related work armstrong et al 1 important differences explain ffl first approach gives elegant insight intricate relationship 2d 1d cameras special kind motion called planar motion ffl second allows us use fundamental matrices 2d images trifocal tensor 1d images selfcalibrate camera instead trifocal tensor 2d images well known fundamental matrices efficiently robustly estimated 31 27 true estimation 1d trifocal tensor 21 linear process armstrong et al hand use trifocal tensor 2d images far hard estimate due complicated algebraic constraints knowledge also trifocal tensor 2d images takes special form planar motion case 1 new constraints included estimation process may worth mentioning case interest planar motion cameras kruppa equations become degenerate 30 recover internal parameters impossible kruppa equations since known trifocal tensor 2d images algebraically equivalent three fundamental matrices plus restriction trifocal tensor trifocal plane 14 15 9 method seen inexpensive way estimating full trifocal tensor 2d images first estimate three fundamental matrices nonlinear simple well understood estimate trifocal tensor trifocal plane linear although looks superficially 1d 2d trifocal tensors estimated linearly least 7 image correspondences misleading since estimation 1d trifocal tensor exactly linear 7 dof whereas linear estimation 2d trifocal tensor rough approximation based set 26 auxiliary parameters dof obtained neglecting 8 complicated algebraic constraints ffl third minor point method may require estimation vanishing point rotation axes 7 experimental results theoretical results 1d camera selfcalibration applications 2d camera calibration implemented experimented synthetic real images due space limitation present results synthetic data algorithms generally perform well show real examples consider scenario real camera mounted robots arm two sequences images acquired camera moving two different planes first sequence contains 7 indexed 16 22 images cf figure 5 second contains 8 indexed 8 15 calibration grid used ground truth internal camera parameters measured ff using standard calibration method 6 figure 5 three images first planar motion take triplets images first sequence triplet estimate trifocal line vanishing point rotation axes 3 fundamental matrices triplet 1d selfcalibration applied estimating images circular points along trifocal lines evaluate accuracy estimation images circular points trifocal plane recomputed image plane known internal parameters intersecting image absolute conic trifocal line table 1 shows results different triplets images first sequence image triplet fixed point circular points selfcalibration circular points calibration table 1 table estimated positions images circular points selfcalibration different triplets images first sequence quantities expressed first image pixel coordinate system location circular points calibration vary trifocal line location varies since 3 images planar motion camera could also estimate trifocal line vanishing point rotation axes using available fundamental matrices 7 images sequence results using redundant images presented different triplets table 2 note slight improvement results compared presented table 1 image triplet circular points fixed point known position calibration 2621 sigma i25906 table 2 table estimated positions image circular points different triplets images quantities vary 1d trifocal tensor varies trifocal line vanishing point rotation axes estimated using 7 images sequence instead minimum 3 images experiment carried sequence images camera underwent different planar motion similar results first image sequence obtained give result one triplet images table 3 sequence image triplet fixed point circular points selfcalibration circular points calibration table 3 table estimated position image circular points one triplet second image sequence two sequences images corresponding different planar motion yield four distinct imaginary points image plane must image absolute conic assuming camera skew could fit four points imaginary ellipse using standard techniques compute resulting internal parameters note use polepolar constraint vanishing point ratation axes absolute conic discussed section 6 constraint numerically reliable intuitive idea planar motions two trifocal lines together one image shown figure 6 1000 500 500 1000 150050015002500 figure image motion planes two planar motions ultimate goal selfcalibration get 3d metric reconstruction 3d reconstruction two images sequence performed using estimated internal parameters illustrated figure 7 evaluate reconstruction quality reconstruction using known internal parameters two reconstructions differ merely 3d similarity transformation could easily estimated resulting relative error normalised 3d coordinates similarity reconstruction selfcalibration offline calibration 34 percent 04 03 02 010103 02343844 figure 7 two views resulting 3d reconstruction selfcalibration 8 conclusions applications first established 2 internal parameters 1d camera uniquely determined trifocal tensor three 1d images since trifocal tensor estimated linearly least 7 points three 1d images method 1d selfcalibration real linear method modulo fact find roots third degree polynomial 1 variable parameterisation introduced secondly proven 2d camera undergoes planar motion 2d camera reduces 1d camera plane motion reduction 2d image 1d image efficiently performed using fundamental matrices 2d images based relation 2d 1d images selfcalibration 1d camera applied selfcalibrating 2d camera experimental results based real image sequences show large stability solutions yielded 1d selfcalibration method accurate 3d metric reconstruction obtained internal parameters 2d camera estimated 1d selfcalibration method camera motions may defeat selfcalibration method developed section 4 described 26 r invariancy methods points affine calibration mobile vehicles twisted cubic camera calibration camera calibration 3d computer vision stratification threedimensional vision projective motion point matches multiplicity solutions correspondences points n images defence 8point algorithm euclidean reconstruction uncalibrated views linear method reconstruction lines points geometry algebra multiple projective transformations algebraic properties multilinear constraints common framework multipleview tensors theory self calibration moving camera affine structure line correspondences uncalibrated affine cameras algebraic projective geometry algebraic functions recognition unified theory structure motion critical motion sequences monocular selfcalibration uncalibrated euclidean recon struction vision 3d non calibree contributions la reconstruction projective et etude des mouvements critiques pour lautocalibrage performance characterization fundamental matrix estimation image degradation matching constraints joint image autocalibration absolute quadric camera selfcalibration video sequences kruppa equations revisited robust technique matching two uncalibrated images recovery unknown epipolar geometry tr ctr mandun zhang jian yao bin ding yangsheng wang fast individual face modeling animation proceedings second australasian conference interactive entertainment p235239 november 2325 2005 sydney australia c murillo c sags j j guerrero goedem tuytelaars l van gool omnidirectional images hierarchical localization robotics autonomous systems v55 n5 p372382 may 2007