runtime spatial locality detection optimization disparity processor main memory performance grows number execution cycles spent waiting memory accesses complete also increases result latency hiding techniques critical improved application performance future processors present microarchitecture scheme detects adapts varying spatial locality dynamically adjusting amount data fetched cache miss spatial locality detection table introduced paper facilitates detection spatial locality across adjacent cached blocks results detailed simulations several integer programs show significant speedups improvements due reduction conflict capacity misses utilizing small blocks small fetch sizes spatial locality absent prefetching effect large fetch sizes spatial locality exists b introduction paper introduces approach solving growing memory latency problem 2 intelligently exploiting spatial locality spatial locality refers tendency neighboring memory locations referenced close together time traditionally two main approaches used exploit spatial locality first approach use larger cache blocks natural prefetching effect however large cache blocks result wasted bus bandwidth poor cache utilization due fragmentation underutilized cache blocks negative effects occur data little spatial locality cached second common approach prefech multiple blocks cache however prefetching beneficial prefetched data accessed cache otherwise prefetched data may displace useful data cache addition wasting bus bandwidth similar issues exist allocate caches effect prefetch data cache block containing written address particu technical report longer version 1 larly using large block sizes write allocation amount prefetching fixed however spatial locality hence optimal prefetch amount varies across often within programs available chip area increases meaningful spend resources allow intelligent control latencyhiding techniques adapting variations spatial locality numeric programs several known compiler techniques optimizing data cache performance contrast integer nonnumeric programs often irregular access patterns compiler cannot detect optimize example temporal spatial locality linked list elements hash table data often difficult determine compile time paper focuses cache performance optimization integer programs focus attention data caches techniques presented applicable instruction caches order increase data cache effectiveness integer programs investigating methods adaptive cache hierarchy management intelligently control caching decisions based usage characteristics accessed data paper examine problem detecting spatial locality accessed data automatically control fetch multiple smaller cache blocks data caches buffers able reduce conflict capacity misses smaller cache lines fetch sizes spatial locality absent also reduce cold start misses prefetch useful data larger fetch sizes spatial locality present introduce new hardware mechanism called spatial locality detection table sldt sldt entry tracks accesses multiple adjacent cache blocks facilitating detection spatial locality across blocks cached resulting information later recorded memory address table 3 longterm tracking larger regions called macroblocks show extensions cache microarchitecture significantly improve performance integer applications achieving 17 26 improvements 100 200cycle memory latencies respectively scheme fully compatible existing instruction set architectures isa remainder paper organized follows section related work section 3 discusses general spatial locality issues code example common application used illustrate role spatial locality cache line sizes determining application cache perfor mance well motivate spatial locality optimization techniques section 4 discusses hardware techniques section 5 presents simulation results section 6 performs cost analysis added hardware section 7 concludes future directions related work several studies examined performance effects cache block sizes 45 one studies allowed multiple consecutive blocks fetched one request 4 found data caches optimal staticallydetermined fetch size generally twice block size work also examine fetch sizes larger block size however allow fetch size vary based detected spatial locality another method allows number blocks fetched miss vary across program execution across different data 6 hardware 7891011 software 121314 prefetching methods uniprocessor machines proposed however many methods focus prefetching regular array accesses within wellstructured loops access patterns primarily found numeric codes methods geared towards integer codes 1516 focus compilerinserted prefetching pointer targets could used conjunction techniques dual data cache 17 attempts intelligently exploit spatial temporal locality however temporal spatial data must placed separate structures therefore relative amounts type data must determined priori also spatial locality detection method tuned numeric codes constant stride vectors integer codes spatial locality patterns may regular split temporalspatial cache 18 similar structure dual data cache however runtime locality detection mechanism quite different dual data cache paper 3 spatial locality caches seek exploit principle locality storing referenced item caches exploit temporal locality tendency item rereferenced soon additionally storing multiple items adjacent referenced item exploit spatial locality tendency neighboring items referenced soon exploitation temporal locality result cache hits future accesses particular item exploitation spatial locality result cache hits future accesses multiple nearby items thus avoiding long memory latency shortterm accesses items well traditionally exploitation spatial locality achieved either larger block sizes prefetching additional blocks define following terms used throughout paper element data item maximum size allowed isa system 8 bytes spatial reuse reference cached element element caused referenced element fetched cache spatial locality applications data set predict effectiveness spatial locality optimizations unfortu nately quantitative measure spatial locality exists forced adopt indirect measures one indirect measure amount spatial locality via inverse rela tioship distance references space time view measured spatial reuses 64kbyte fullyassociative cache 32byte lines gives us approximate time bound time taken block displaced space bound within 32byte block boundaries chose block size past studies found 16 32byte block sizes maximize data cache performance 4 measurement techniques differ 19 explicitely measure reuse distance time goal measure reused unused portions cache blocks different cache organizations figure 1a shows spatial locality estimates fullyassociative cache number dynamic cache blocks broken number 8byte elements accessed blocks cache lifetime blocks one element accessed spatial locality within measured context graph show relative locations accessed elements within 32byte cache block figure 1a shows 1383 cached blocks spatial reuse figure 1b shows distribution changes 16kbyte directmapped cache case 3093 blocks spatial reuse 32byte cache block half time extra data fetched cache simply wastes bus bandwidth cache space similar observations made numeric codes 19 therefore would beneficial tune amount data fetched cached miss spatial locality available data optimization investigated work discuss several issues involved varying fetch sizes including cost efficient accurate spatial locality detection fetch size choice cache support varying fetch sizes 31 code example section use code example spec92 gcc illustrate difficulties involved static analysis annotation spatial locality information motivating dynamic approach one main data structures used gcc rtl ex pression rtx whose definition shown figure 2 rtx structure contains twobyte code field onebyte mode field seven onebit flags array operand fields operand array defined contain one fourbyte ele ment however rtx dynamically allocated contain many array elements operands depending rtx code rtl expression type therefore rtx instance contains eight bytes frequently executed rtx renumbered equal tine used jump optimization two rtx 026compress 072sc 099go 147vortex pcode lmdes2customizer 085cc1 130li 134perl 124m88ksim benchmark total blocks blocks accesses four elements blocks accesses three elements blocks accesses two elements blocks accesses one elements 64kbyte fullyassociative 0 20 40 80 100 026compress 072sc 099go 147vortex pcode lmdes2customizer 085cc1 130li 134perl 124m88ksim benchmark total blocks blocks accesses four elements blocks accesses three elements blocks accesses two elements blocks accesses one elements b 16kbyte directmapped figure 1 breakdown blocks cached l1 data cache many 8byte elements accessed block cached results two cache configurations shown 32byte blocks struct rtxdef kind expression enum kind value expression enum machinemode mode 8 various bit flags unsigned int unsigned int call unsigned int unchanging unsigned int volatil unsigned int instruct unsigned int used unsigned integrated first element operands rtx number operands types controlled code field according rtldef rtunion fld1 common union element rtx int rtint char struct struct enum machinemode rttype figure 2 gcc rtx definition structures compared determine equivalent figure 3 shows slightly abbreviated version renumbered equal routine checking code mode fields two rtx structures identical routine compares operands determine also identical four branch targets figure 3 annotated execution weights derived execution profiles using spec reference input roughly 1 time code fields two rtx structures compared exiting case first two bytes rtx structure accessed 46 time x const int rtx first operand accessed therefore first eight bytes rtx structure accessed spatial locality within eight bytes many types rtl expressions routine use loop iterate operands last first comparing mismatch found case spatial locality slightly larger distance space previous case instruction types contain one operand common operand type loop rtl expression results recursive call rtx renumbered equal p routine illustrates amount spatial locality vary particular load references depending function arguments therefore original access rtx structure routine miss optimal amount data fetch cache vary correspond ingly example access getcodey line 10 figure 3 performs access ycode misses l1 cache spatial locality data depends whether program later fall case body switch statement line 11 body loop line 24 rtx type x determines initial value loop however time cache miss line 10 information available highly datadependent neither static analysis even possible profiling result definitive accurate spatial locality information load instructions dynamic analysis spatial locality data offers greater promise routine dynamic analysis instance accessed routine would obtain accurate spatial locality detection also dynamic schemes require profiling many users unwilling perform isa changes case labelref return nextrealinsn xfld0rtx nextrealinsn yfld0rtx case symbolref 19 return xfld0rtstr yfld0rtstr 22 compare elements pair corresponding elements fail match return 0 whole thing register int j 26 switch fmti case 28 xfldirtint yfldirtint return 0 29 break case return 0 36 break 37 case e 38 accesses xyfldirtvec return 43 3 register int 4 register rtxcode 5 register char fmt 9 rarely entered case e switch code case pc case cc0 case addrvec case addrdiffvec return 0 34 rtxrenumberedequalp xfldirtx yfldirtx 14 case constint return xfld0rtint yfld0rtint exits 448 times exits times case matches times exits 30014 times figure 3 gcc rtx renumbered equal routine executed 63173 times 32 applications aside varying data cache load fetch sizes spatial locality optimizations could used control instruction cache fetch sizes write allocate versus noallocate poli cies bypass fetch sizes bypassing employed latter case discussed briefly 3 greatly expanded paper paper examine application techniques control fetch sizes l1 l2 data caches also study optimizations conjunction cache bypassing complementary optimization also aims improve cache performance 41 overview prior work section briefly overview concept mac roblock well memory address table mat introduced earlier paper 3 utilized work showed cache bypassing decisions could effectively made runtime based previous usage memory address accessed bypassing schemes include 20211722 particular scheme dynamically kept track accessing frequencies memory regions called macroblocks macroblocks statically defined blocks memory uniform size larger cache block size macroblock size large enough total number accessed macroblocks excessively large small enough access patterns cache blocks contained within macroblock relatively uniform determined 1kbyte macroblocks provide good costperformance tradeoff order keep track macroblocks run time use mat ideally contains entry macroblock accessed macroblock address support dynamic bypassing decisions entry table contains saturating counter counter value represents frequency accesses corresponding mac roblock details mat bypassing scheme see 3 also introduced paper optimization geared towards improving efficiency l1 bypasses tracking spatial locality bypassed data using mat using information determine much data fetch l1 bypass paper introduce robust spatial locality detection optimization scheme using sldt enables much efficient detection spatial locality new scheme also supports fetching varying amounts data levels data cache without bypassing practice spatial locality optimization performed combination passing order achieve best possible performance well amortize cost mat hardware cost combined hardware addressed section 6 set 31 set 00 set 01 set set tag data 8 bytes 0x000000 0x000000 tag data 8 bytes 0x000000 0x000000 figure 4 layout 8byte subblocks 32byte block starting address 0x00000000 512byte 2way setassociative cache 8byte lines shaded blocks correspond locations four 8byte subblocks following presentation experimental results 42 support varying fetch sizes varying fetch size optimization could supported using subblocks case block size largest fetch size subblock size gcdfetch n number fetch sizes supported currently support two poweroftwo fetch sizes level cache subblock size simply smaller fetch size however cache lines underutilized smaller size fetched instead use cache small lines equal smaller fetch size optionally fill multiple consecutive blocks larger fetch size chosen approach similar used prefetching strategies 23 result cache fully utilized even smaller sizes fetched also eliminates conflict misses resulting accesses different subblocks however approach makes detection spatial reuses much difficult described section 43 also smaller block sizes increase tag array cost addressed section 6 scheme max fetch size data always aligned boundaries result techniques fetch data either side accessed element depending location element within max fetch size block experience spatial locality data cache either direction spatially referenced element 43 spatial locality detection table facilitate spatial locality tracking spatial counter sctr included mat entry role sctr track medium longterm spatial locality corresponding macroblock make fetch size decisions explained section 44 counter incremented whenever spatial miss detected occurs portions larger fetch size block data reside cache element currently ac cessed therefore hit might occurred larger fetch size fetched rather smaller fetch size implementation multiple cache blocks filled larger fetch size chosen spatial miss trivial detect cache fullyassociative tags different blocks residing larger fetch size block lie consecutive sets shown figure 4 data one 32byte block highlighted searching cache blocks larger fetch size block data require access tags consecutive sets thus either additional cycles access additional hardware support one possibility restructured tag array design allowing efficient access multiple consecutive sets tags alternatively separate structure used detect information approach investigated work structure called spatial locality detection table sldt designed efficient detection spatial reuses low hardware overhead role sldt detect spatial locality data cache recording mat data displaced sldt basically tag array blocks larger fetch size allowing singlecycle access necessary information figure 5 shows overview sldt interacts mat l1 data cache doublearrow line shows correspondence four l1 data cache entries single sldt entry order track cache blocks sldt would need n entries n number blocks cache represents worst case fetched smaller line size blocks cache different larger size blocks however order reduce hardware overhead sldt use much smaller number entries allow us capture shorterterm spatial reuses sldt could used track spatial locality aspects structures level memory hierarchy data cache instruction cache perform bypassing bypass buffer sldt tags correspond maximum fetch size blocks sz field one bit indicating either larger size block fetched cache smaller blocks fetched vc valid count field logmax fetch sizemin fetch size bits length indicates many smaller blocks larger size block currently valid data cache actual number valid smaller blocks vc1 sldt entry valid larger size block constituent blocks currently valid data cache bit mask could used implement vc rather counter design reduce operational complexity however large maximum minimum fetch size ratios bit mask result larger entries finally sr spatial reuse bit set spatial reuse detected discussed later larger size block data fetched cache sldt entry allocated possibly causing replacement existing entry values sz vc set 1 max fetch sizemin fetch size gamma 1 respectively smaller size block fetched sldt entry currently exists corresponding larger size block entry allocated sz vc initialized 0 entry already exists vc incremented indicate additional valid constituent block data cache fetch sizes sr bit initialized 0 cache block replaced data cache corresponding sldt entry accessed vc value decremented greater 0 vc already 0 valid block sldt entry invalidated spatial reuse hit mat sctr fetch update sctr hit spatial reuse results l1 data cache addr tag sz vc sr figure 5 sldt mat hardware sldt entry invalidated sr bit checked see spatial reuse data cached corresponding entry mat accessed sctr decremented effectively depositing information mat longerterm tracking sldt managed cache entries replaced case actions taken fi fetch initiator bit added data cache tag help detect spatial hits fi bit set 1 cache refill cache block containing referenced element ie cache block causing fetch otherwise reset 0 therefore hit block 0 fi bit spatial hit data fetched cache miss element table 1 summarizes actions taken sldt memory accesses sr bit initialized zero set types spatial misses spatial hits two types spatial misses detected first type spatial miss occurs portions larger fetch size block fetched independently indicated valid sldt entry sz 0 therefore might cache hit larger size block fetched corresponding entry mat accessed sctr incremented second type occur larger size block fetched one constituent blocks displaced cache indicated cache miss valid sldt entry sz 1 trivial detect miss element caused original fetch element larger fetch size block sr bit conservatively set sctr corresponding mat entry incremented spatial hit occur two situations larger size block fetched fi bit set one loaded cache blocks hit loaded cache blocks without fi bit set spatial hit described earlier increment sctr spatial hits fetch size correct update sctr fetch size changed future multiple smaller blocks fetched hit one also characterized spatial hit case detected checking vc larger 0 sz 0 however increment sctr case either spatial miss would detected earlier second element larger fetch size block first accessed missed cache sldt access access fi sz vc action miss hit 0 cache entry vc 0 replaced vc 0 invalidate sldt entry sldt entry replaced sr 0 invalidated sr 1 action table 1 sldt actions dash indicates corresponding value blank indicates value matter 44 fetch size decisions memory access lookup mat corresponding macroblock entry performed parallel data cache access entry found sctr value compared threshold value larger size fetched sctr larger threshold otherwise smaller size fetched entry found new entry allocated sctr value initialized threshold value larger fetch size chosen paper threshold 50 maximum sctr value 5 experimental evaluation 51 experimental environment simulate ten benchmarks including 026compress 072sc 085cc1 spec92 benchmark suite using reference inputs 099go 147vortex 130li 134perl 124m88ksim spec95 benchmark suite using training inputs last two benchmarks consist modules impact compiler 24 felt representative many realworld integer applica tions pcode front end impact run performing dependence analysis internal representation combinec file gnu cc input lmdes2 customizer machine description optimizer run optimizing supersparc machine description optimizations operate linked list complex data structures utilize hash tables efficient access information order provide realistic evaluation technique future highperformance highissue rate systems first optimized code using impact compiler 24 classical optimizations applied optimizations performed increase instruction level parallelism code scheduled register allocated optimized eightissue scoreboarded superscalar processor register renaming isa extension hp parisc instruction set support compiletime speculation perform cyclebycycle emulationdriven simulation hewlettpackard parisc 7100 workstation modelling processor memory hierarchy including related busses instruction latencies used hewlettpackard parisc 7100 given table 2 base machine configuration described table 3 since simulating entire applications level detail would impractical uniform sampling used reduce simulation time 25 however emulation still performed function latency function latency memory load 2 fp multiply 2 memory store 1 fp divide single prec 8 branch table 2 instruction latencies simulation experiments l1 icache 32kbyte splitblock direct mapped 64byte block l1 dcache 16kbyte nonblocking 50 max direct mapped 32byte block multiported writeback write alloc l1l2 bus 8byte bandwidth splittransaction 4cycle latency returns critical word first l2 dcache l1 dcache except 256kbyte 64byte block system bus l1l2 bus except 100cycle latency issue 8issue uniform except 4 memory opscycle max registers 64 integer 64 double precision floatingpoint table 3 base configuration samples simulated samples 200000 instructions length spaced evenly every 20000000 instructions yielding 1 sampling ratio smaller ap plications time samples reduced maintain least 50 samples 10000000 instructions evaluate accuracy technique simulated several configurations without sampling found improvements reported paper close obtained simulating entire application 52 macroblock spatial locality variations presenting performance improvements achieved optimizations first examine accuracy macroblock granularity tracking spatial locality important accurate spatial locality information mat scheme successful means data elements macroblock similar amounts spatial locality phase program execution dividing main memory macroblocks described section 41 macroblocks subdivided smaller sections size 32byte cache block simply call smaller sections blocks order determine dynamic cache block spatial locality behavior examined accesses blocks gathering information twice per simulation sample every 100000 instructions end 100000instruction phase determined fraction times block memory least one spatial reuse time cached phase call spatial reuse fraction block figure 6 shows graphical representation resulting information three programs row graph represents 1kbyte macroblock accessed particular phase every phase particular macroblock accessed corresponding row row contains one data point every 32byte block accessed corresponding phase lies macroblock purposes clarity rows sorted average block spatial reuse fractions per macroblock averages increase bottom top graphs cache blocks macroblock also sorted spatial reuse fractions increase left right rows full meaning blocks accessed corresponding phase finally cache blocks spatial reuse fractions falling within range plotted marker figure 6a shows spatial locality distribution 026compress blocks corresponding lighter gray points spatial reuse fractions 0 025 meaning spatial reuse blocks less 25 time cached blocks corresponding black points spatial reuse 75 time cached represents fairly optimal scenario macroblocks contain blocks approximately amount reuse figure 6b shows distribution 134perl around 34 macroblocks ids 0 6500 contain blocks little spatial reuse spatial reuse fractions less 025 29 macroblocks ids 13500 18900 contain blocks large fractions spatial reuse spatial reuse fractions 075 37 macroblocks contain cache blocks differing amounts spatial reuse medium gray points rows correspond blocks spatial reuse fractions 025 075 however information reveal time intervals spatial reuse blocks varies possible certain small phases program execution spatial locality behavior uniform changes drastically one small phase execution another type behavior possible due dynamicallyallocated data particular section memory may allocated one type data one part program freed reallocated another type later finally figure 6c shows distribution 085gcc similar characteristics 134perl macroblocks nonuniform spatial reuse fractions 53 performance improvements section examine performance improvement execution cycles eliminated base 8issue configuration described section 51 support varying fetch sizes use sldt mat level cache hierarchy l1 l2 sldts directmapped entries large number simulations showed directmapped sldts perform well fullyassociative design 32 entries perform almost well larger poweroftwo number entries 1024 entries maximum size examined l1 l2 mats utilize 1kbyte macroblocks examine one fourbit sctrs first present results infinite entry mats study effects limiting number mat entries 531 static versus varying fetch sizes left bar benchmark figure 7a shows performance improvement achieved using 8byte l1 data cache blocks static 8byte fetch size base 32 byte block fetch sizes bars show better choice block size highly applicationdependent right bars show improvement achieved spatial locality optimization l1 level using 8byte data cache block size fetching either 8 32bytes l1 data cache miss depending value 026compress b 134perl b 085gcc figure reuse fractions srf cacheblocksizeddata accessed macroblocks three applications corresponding sctr results show scheme able obtain either almost performance able outperform best static fetch size scheme cases 1 4bit sctrs perform similarly one case 4bit sctr achieves almost 2 greater performance improvement four leftmost bars benchmark figure 7b show performance improvement using different l2 data cache block static fetch sizes l1 spatial locality optimization 4bit sctr base configuration configuration described section 51 64byte l2 data cache block fetch sizes bars show better static blockfetch size highly applicationdependent example 134perl achieves much better performance 256byte fetch size 026compress achieves best performance 32 byte fetch size obtaining 14 performance degradation 256byte fetches rightmost two bars figure 7b show performance improvement achieved l2 spatial locality optimization uses 32byte l2 data cache block size fetches either 32 256 bytes l2 data cache miss depending value corresponding l2 mat sctr spatial locality optimizations able obtain almost better performance best static fetch size scheme benchmarks figure 8 shows breakdown processor stall cycles attributed different types data cache misses percentage total base configuration execution cycles left right bars benchmark stall cycle breakdown base configuration spatial locality optimization respectively spatial locality optimizations performed cache levels using configuration figure 7b 4bit sctr benchmarks large amounts spatial locality indicated results figure 7 obtain large reductions l2 cold start stall cycles fetching 256 bytes l2 cache misses benchmarks little spatial locality l1 data cache 026compress pcode obtained reductions l1 capacity miss stall cycles fetching fewer small cache blocks l1 misses cases l1 cold start stall cycles increase indicating l1 optimizations less aggressive terms fetching data however increases generally compensated reductions types l1 stall cycles conflict miss stall cycles increase lmdes2 customizer tends fetch fewer blocks l1 miss exposing conflicts interpreted capacity misses base configuration revisiting example section 31 found access ycode line 10 figure 3 missed 11223 times fetching bytes 47 misses 8 bytes remaining 53 also found average 099 spatial hits 002 spatial misses resulting data occurred per miss illustrating techniques successfully choosing appropriate amount data fetch miss 532 setassociative data caches increasing setassociativity data caches reduce number conflict misses may turn reduce advantage offered optimizations however 800 1000 026compress 072sc 099go 147vortex pcode lmdes2customizer 085cc1 130li 134perl 124m88ksim benchmark improvement base l1 static 8byte blockfetch size varying fetch 1bit sctr varying fetch 4bit sctr l1 trends 1500 1000 500 500 1000 1500 2000 026compress 072sc 099go 147vortex pcode lmdes2customizer 085cc1 130li 134perl 124m88ksim benchmark improvement base l2 static 32byte blockfetch size l2 static 64byte blockfetch size l2 static 128byte blockfetch size l2 static 256byte blockfetch size varying fetch 1bit sctr varying fetch 4bit sctr b l2 trends l1 varying fetches figure 7 performance various staticallydetermined blockfetch sizes spatial locality optimizations using 1 4bit sctrs 1000 2000 3000 4000 5000 7000 8000 9000 026compress base opti base opti base opti 147vortex base opti pcode base opti lmdes2customizer base opti base opti base opti 134perl base opti base opti benchmark total base execution cycles cold start stall cycles l2 capacity miss stall cycles conflict miss stall cycles cold start stall cycles l1 capacity miss stall cycles conflict miss stall cycles figure 8 stall cycle breakdown base spatial locality optimizations reductions capacity cold start stall cycles optimizations achieve remain investigate effects data cache configuration discussed section 51 modified 2way setassociative l1 data cache 4way setassociative l2 data cache figure 9 shows new performance improvements optimizations left bars show result applying optimizations l1 data cache right bars show result applying techniques l1 l2 data caches using fourbit sctrs improvements reduced significantly benchmarks shown figure 7 however large improvements still achieved benchmarks particularly applying optimizations l2 data cache level due reductions achieve l2 cold start stall cycles data spatial locality 200 200 400 600 800 1000 1200 1400 1600 2000 026compress 072sc 099go 147vortex pcode lmdes2custom izer benchmark improvement base varying fetch 4bit sctr varying fetch 4bit sctrs figure 9 performance spatial locality optimizations 2way 4way setassociative l1 l2 data caches respectively 533 growing memory latency effects discussed section 1 memory latencies increasing trend expected continue figure 10 shows improvements achieved optimizations applied directmapped caches 100 200cycle la tencies relative base configuration memory latency benchmarks see much larger improvements optimizations exception 026compress 026compress little spatial locality exploit longer latency cannot hidden effectively although raw number cycles eliminate grows percentage associated base execution cycle count becomes smaller 534 comparison integrated techniques doubled data caches memory latencies increase intelligent cache management techniques become increasingly important examined performance improvement achieved integrat 026compress 072sc 099go 147vortex pcode lmdes2custom izer benchmark improvement base 100cycle latency 200cycle latency figure 10 performance spatial locality optimizations growing memory latencies 500 1000 1500 2000 3000 026compress 072sc 099go 147vortex pcode lmdes2custom izer benchmark improvement base doubled 32k512k l1l2 varying fetch 4bit sctr bypass infinite mat varying fetch 4bit sctr bypass 1kentry mat varying fetch 4bit sctr bypass 512entry mat figure 11 comparison doubled caches integrated spatial locality bypassing optimizations infinite 1024 entry 512entry directmapped mats examined ing spatial locality optimizations intelligent bypass ing using 8bit access counters mat entry 3 4way setassociative buffers used hold bypassed data l1 l2 caches contain 128 8byte entries 512 32byte entries respectively sldt mat cache level used detect spatial locality control fetch sizes data cache bypass buffer level figure 11 shows improvements achieved combining techniques cache levels 100cycle memory latency show results three directmapped mat sizes infinite 1kentry 512entry also shown performance improvements achieved doubling l1 l2 data caches doubling caches bruteforce technique used improve cache performance figure 11 shows performing integrated optimizations cache levels outperform simply doubling levels cache case doubled caches perform significantly better optimizations 026compress improvement mostly comes doubling l2 data cache results hash tables fit data block tag tag cache cost size size cost level bytes bytes sets bits bytes table 4 hardware cost doubled data caches 512kbyte cache pcode benchmark performance degrades significantly reducing mat size however 1kentry mats still outperform doubled caches comparing figure 11 bypassing improvements 3 shows often significant improvements achieved intelligently controlling fetch sizes data caches bypass buffers 6 design considerations section examine hardware cost spatial locality optimization scheme described section 4 compare cost doubling data caches level discussed section 41 cost mat hardware amortized performing spatial locality bypassing optimizations reason compute hardware cost hardware support opti mizations combined performance compared performance doubling caches section 534 additional hardware cost incurred spatial locality optimization scheme small compared doubling cache sizes level particularly l2 cache 16kbyte directmapped l1 cache used generate results section 53 bits tag used per entry assuming 32bit addresses doubling cache result 17bit tags line size 32 bytes total additional cost increased tag array 17lambda2 1k bytes 1 addition extra 16k data needed similar computations show cost doubling 256kbyte l2 cache extra 6144 bytes tag 256k bytes data total tag data costs doubled l1 l2 caches shown table 4 directmapped mat 8bit access counters 4bit spatial counters table 12 gives hardware cost data tags mat sizes discussed section 534 since addresses within macroblock map mat counter number lower address bits discarded accessing mat size resulting mat address 1kbyte macroblocks shown column 3 table 12a table 12b shows data tag array costs directmapped data caches spatial locality optimization scheme data cost remains base configuration cost tag array cost increased due decreased line sizes additional support scheme requires 1bit fetch initiator bit per tag entry cost l1 buffer 4way setassociative cache 8byte lines shown table 12c optimized data caches bypass buffers require 1bit fetch initiator bit addition address tag cost l2 bypass buffer computed similarly table 12c 1 ignoring valid bit state mat data cost size mat tag size tag cost entries bytes address bits bits bytes hardware cost 512 1k entry mats cost l1 l2 cache levels data fetch block tag tag cache cost size size size cost level bytes bytes bytes sets bits bytes b hardware cost optimized data caches block data tag tag cache fetch size cost size cost level entries size bytes bytes bytes bits bytes c hardware cost bypass buffers cache sldt tag size tag cost level entries bits bytes hardware cost sldts figure 12 hardware cost breakdown spatial locality optimizations final component spatial locality optimization scheme 32entry sldt organized directmapped tag array vc 1bit sz 1bit sr fields included tag entry l1 sldt requires 2 bit vc 4 8byte lines per 32byte maximum fetch l2 sldt requires 3bit vc due 8 32 byte lines per 256byte maximum fetch bit mask could used implement vc rather counter design reduce operational complexity however large maximum minimum fetch size ratios 8to1 ratio l2 cache bit mask result larger entries table 12d shows total tag array costs l1 l2 sldts finally combining costs mat optimized data cache bypass buffer sldt results total l1 cost 24376 bytes 512entry mat 25848 bytes 1kentry mat therefore savings doubling l1 data cache 10k 8k bytes 512 1kentry mats respectively similar calculations show l2 optimizations save 247k bytes 245k bytes 512 1kentry mats spectively doubling l2 data cache translates 26 44 less tags data doubling data caches l1 l2 levels respectively larger 1kentry mat comparing performance spatial locality bypassing optimizations performance obtained doubling data caches levels shown figure 11 illustrates much smaller hardware costs optimizations usually outperform simply doubling caches reduce hardware cost could potentially integrate l1 mat tlb page tables macroblock size larger equal page size tlb entry need hold one 8bit counter value macroblock size less page size tlb entry needs hold several counters one macroblocks within corresponding page case small amount additional hardware necessary select counter values however study needed determine full effects tlb integration 7 conclusion paper examined spatial locality characteristics integer applications showed spatial locality varied programs also varied vastly data accessed application result varying spatial locality within across applica tions spatial locality optimizations must able detect adapt varying amount spatial locality within across applications order effective presented scheme meets objectives detecting amount spatial locality different portions memory making dynamic decisions appropriate number blocks fetch memory access spatial locality detection table sldt introduced paper facilitates spatial locality detection data cached information later recorded memory address table mat longterm tracking used tune fetch sizes missing access detailed simulations several applications showed significant speedups achieved techniques improvements due reduction conflict capacity misses utilizing small blocks small fetch sizes spatial locality absent utilizing prefetching effect large fetch sizes spatial locality exists ad dition showed speedups achieved scheme increase memory latency increases memory latencies increase importance cache performance improvements level memory hierarchy continue grow also available chip area grows makes sense spend resources allow intelligent control cache management order adapt caching decisions dynamic accessing behav ior believe schemes extended general framework intelligent runtime management cache hierarchy acknowledgements authors would like thank mark hill santosh abraham wenhann wang well members impact research group comments suggestions helped improve quality research research supported national science foundation nsf grant ccr9629948 intel corpo ration advanced micro devices hewlettpackard sun mi crosystems ncr national aeronautics space administration nasa contract nasa nag 1613 cooperation illinois computer laboratory aerospace systems software iclass r runtime spatial locality detection optimization predicting precluding problems memory latency runtime adaptive cache hierarchy management via reference analysis performance impact block sizes fetch strategies line block size choice cpu cache memo ries fixed adaptive sequential prefetching shared memory multipro cessors cache memories improving directmapped cache performance addition small fullyassociative cache prefetch buffers effective onchip preloading scheme reduce data access penalty quantifying performance potential data prefetch mechanism pointerintensive numeric programs stride directed prefetching scalar processors software methods improvement cache performance supercomputer applications design evaluation compiler algorithm prefetching data access microarchitectures superscalar processors compilerassisted data prefetching compilerbased prefetching recursive data structures spaid software prefetching pointer call intensive environments data cache multiple caching strategies tuned different types local ity split temporalspatial cache initial performance analysis quantitative analysis loop nest locality efficient simulation caches optimal replacement applications miss characterization modified approach data cache management reducing conflicts directmapped caches temporalitybased design data prefetching multiprocessor vector cache memories impact architectural framework multipleinstructionissue processors simulate 100 billion references cheaply tr line block size choice cpu cache memories data prefetching multiprocessor vector cache memories impact data access microarchitectures superscalar processors compilerassisted data prefetching effective onchip preloading scheme reduce data access penalty design evaluation compiler algorithm prefetching directed prefetching scalar processors data cache multiple caching strategies tuned different types locality modified approach data cache management compilerbased prefetching recursive data structures runtime adaptive cache hierarchy management via reference analysis cache memories predicting precluding problems memory latency software methods improvement cache performance supercomputer applications ctr guest editors introductioncache memory related problems enhancing exploiting locality ieee transactions computers v48 n2 p9799 february 1999 afrin naz mehran rezaei krishna kavi philip sweany improving data cache performance integrated use split caches victim cache stream buffers acm sigarch computer architecture news v33 n3 june 2005 jike cui mansur h samadzadeh new hybrid approach exploit localities lrfu adaptive prefetching acm sigmetrics performance evaluation review v31 n3 p3743 december sanjeev kumar christopher wilkerson exploiting spatial locality data caches using spatial footprints acm sigarch computer architecture news v26 n3 p357368 june 1998 jie tao wolfgang karl detailed cache simulation detecting bottleneck miss reason optimization potentialities proceedings 1st international conference performance evaluation methodolgies tools october 1113 2006 pisa italy srikanth srinivasan roy dzching ju alvin r lebeck chris wilkerson locality vs criticality acm sigarch computer architecture news v29 n2 p132143 may 2001 gokhan memik mahmut kandemir alok choudhary ismail kadayif integrated approach improving cache behavior proceedings conference design automation test europe p10796 march 0307 mccorkle programmable busmemory controllers modern computer architecture proceedings 43rd annual southeast regional conference march 1820 2005 kennesaw georgia neungsoo park bo hong viktor k prasanna tiling block data layout memory hierarchy performance ieee transactions parallel distributed systems v14 n7 p640654 july jaeheon jeong per stenstrm michel dubois simple penaltysensitive replacement policies caches proceedings 3rd conference computing frontiers may 0305 2006 ischia italy hur calvin lin memory prefetching using adaptive stream detection proceedings 39th annual ieeeacm international symposium microarchitecture p397408 december 0913 2006 prateek pujara aneesh aggarwal increasing cache capacity word filtering proceedings 21st annual international conference supercomputing june 1721 2007 seattle washington hantak kwak ben lee ali r hurson sukhan yoon woojong hahn effects multithreading cache performance ieee transactions computers v48 n2 p176184 february 1999 ben juurlink pepijn de langen dynamic techniques reduce memory traffic embedded systems proceedings 1st conference computing frontiers april 1416 2004 ischia italy tony givargis improved indexing cache miss reduction embedded systems proceedings 40th conference design automation june 0206 2003 anaheim ca usa mirko loghi paolo azzoni massimo poncino tag overflow buffering energyefficient cache architecture proceedings conference design automation test europe p520525 march 0711 2005 timothy sherwood brad calder joel emer reducing cache misses using hardware software page placement proceedings 13th international conference supercomputing p155164 june 2025 1999 rhodes greece soontae kim n vijaykrishnan mahmut kandemir anand sivasubramaniam mary jane irwin partitioned instruction cache architecture energy efficiency acm transactions embedded computing systems tecs v2 n2 p163185 may razvan cheveresan matt ramsay chris feucht ilya sharapov characteristics workloads used high performance technical computing proceedings 21st annual international conference supercomputing june 1721 2007 seattle washington jonathan weinberg michael mccracken erich strohmaier allan snavely quantifying locality memory access patterns hpc applications proceedings 2005 acmieee conference supercomputing p50 november 1218 2005