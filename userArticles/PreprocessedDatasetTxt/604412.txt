asynchronous transfer mode network technologies widearea highperformance cluster computing review fast networking technologies widearea high performance cluster computer systems describe experiences constructing asynchronous transfer mode atmbased local widearea clusters tools technologies experience led us develop discuss experiences using internet protocol systems well native atm protocols problems facing widearea integration cluster systems presently constructing beowulfclass computer clusters using mix fast ethernet gigabit ethernet technology anticipate systems integrate new localarea gigabit ethernet network technologies used connecting shared hpc resources across wideareas high latencies widearea cluster systems led us develop metacomputing problemsolving environment known distributed information systems control world discworld summarize main developments project well key features research directions software exploit computational services running fast networked cluster systems b introduction cluster computing become important part highend computing world many applications traditionally run highend supercomputers successfully run computer clusters paper describe experiences building high performance computer clusters linking together clusters clusters wide areas approach towards australian national computer room started 1996 led us two important conclusions widearea computing firstly technical standpoint limitations latency network reliability likely important bandwidth limitations future therefore successful widearea systems need constructed accordingly ondly political administrative issues behind supercomputer resource location ownership mean future attractive loosely cluster compute resources nationally even internationally institutions strong reasons wish retain ownership control computer resources clusters local sources may cluster sort therefore attractive architecture target software development article try divide cluster computing systems issues relevant achieving high performance typically local area compute clusters issues pertaining successful sharing resources institutions typically widearea issues size utilisation computer clusters varies enormously recent ieee workshop cluster computing 3 demonstrated well different uses term cluster computing use cluster broader sense describe collection networked compute resources may heterogeneous hardware operating systems software capable cooperating way distributed application may using parallel computing software models pvm8 mpi25 hpf17 higher granularity object service based system like globus7 legion10 corba27 discworld16 use term beowulfclass cluster sense widely adopted describe cluster dedicated sense random collection networked computers term constellation adopted describe compute cluster uses shared memory bus based technology focus clusters beowulfclass systems describing work paper time writing watershed sizes clusters limited number ports commercially available network switches example many groups report work modest clusters 8 16 processors continue operate prototype 8 node beowulf system student experiments modern switches typically capable interconnecting 16 24 even 48 compute nodes using fast ethernet 100mbits bandwidth nodes limits size single switch therefore might used delimiting size distinguishing large small computer clusters number present larger number processors economically linked using shared memory technology high end systems asci systems tera computer architecture achieve considerably higher number nodes interlinked shared memory hardly described commodity economical architectures switches 510 series intel allow switches stacked using high bandwidth links individual switches preserve full point point bandwidth compute nodes constructed 120 node beowulf class system using flat switch architecture dual processor nodes intel 510 series limited linking 7 24 port switches manner limit 168 networked nodes represents well limitations current network technology fast ethernet technology used link individual nodes gigabit ethernet uplinking used switch backplane file server node beowulf systems larger built must use sort hierarchical network architecture longer commodity nature likely network technology move forward economics technical improvements commodity switchgear soon allow bigger systems systems therefore continue encroach traditional supercomputing market area scalable software run systems available applications prob lems experience effort still needed ensure major contribution towards latency parallel applications running clusters remain operating system kernel communications software achieving low latency sending messages nodes beowulf system appears important limitation present achieving high bandwidth describe experiences constructing atmbased clusters section 2 attempt summarise metacomputing approach cluster management section 3 describe latency distributed computing problems important widearea clusters tackled review networking technologies actively used cluster computing systems section 4 discuss relative technical economic advantages section describe experiences experimental wide area system ran 1996 1998 employing local wide area atm technology connect high performance computing clusters around australia research data networks rdn cooperative research centre crc set joint venture involving university adelaide australian national university canberra monash university melbourne university queensland telecom australia tel stra map shown figure 1 shows initial broadband network able set use connected adelaide melbourne sydney canberra brisbane latency performance aspects discussed trialed links 34mbits 155mbits various branches network experimented various combinations cross mounted long distance filesystems video conferencing simple shared whiteboard style collaborative software cross connected computer clusters describe asynchronous transfer mode atm technology used experiments section 4 main features experiments analyse effects relatively high wide area bandwidths available cluster computing yet perceptibly high latencies arising long distances able construct wellconnected compute clusters peculiar bisection bandwidth latency properties arise part cluster geographically separate site although number wide area broadband networks built usa 4 26 unusual network fully integrated long distances rather local area use atm technology telstra built experimental broadband network ebn 21 provide foundation australian broadband application development major objectives provide core network service providers customers collaborate development trial new broadband applications allow telstra developers gain operational experience public atmbased broadband services ocean kilometres network ebn broadband telstras experimental kahgreat australian bight bass strait figure 1 telstras experimental broadband network ebn ebn 34mbits atm network connecting research commercial partner sites figure shows prototype storage processing hardware arranged adelaide canberra separated 1200km connected ebn adelaide canberra cells consisted number dec alphastations interconnected locally 155mbits atm cells two sites connected across ebn 34mbits experimented extensively cluster computing resources adelaide canberra assessing capabilities distributed high performance computing system operating across long distances worth considering fundamental limitations involved long distance networks although employ oc3c 155mbits multimode fibre local area networking restricted e3 34mbits interface card connect adelaide melbourne hence canberra practice severe limitation realistic applications unable fully utilise 155mbits link wide areas except contrived circumstances would case shared link however lineofsight distances involved parts network adelaidemelbourne asx1000 switch compute file servers xterminals dec alpha sgi power challenge workstation multimode fibre oc3c 155mbps farm storage works raid tape library dec alpha workstation farm storage works raid canberra network ebn broadband experimental telstras adelaide brisbane sydney melbourne adelaide canberra ebn project resources gigaswitch fileserver figure 2 dhpc project hardware resources adelaide canberra connected via telstras ebn traffic sent sites via ordinary internet bandwidthintensive experiments carried specifically routing traffic ebn 732 km consequently effective network distances adelaide cities shown table 1 lightspeedlimited latencies shown table 1 calculated basis vacuo lightspeed 2997810 5 kms 1 therefore noted fundamental physics limitation take consideration implementation details ebn city network distance adelaide km lightspeedlimited latency ms melbourne 660 22 table 1 intercity distances adelaide lightspeedlimited latencies experimental broadband network made simple networkperformance measurements using unix ping utility uses internet control message protocol icmp various packet sizes initiated adelaide bounced back process running networked sites shown table 2 varying packet sizes sent possible derive crude latency bandwidth measurements emphasized measurements approximations achievable comparison latency limits table 1 times table 2 averaged 30 pings represent roundtrip time measurements precision 1 ms except syracuse significant packet loss variations suggest accuracy 20 ms appropriate ping measured latency adelaide canberra appears approx ping mean time mean time mean time mean time packet canberra syracuse usa local machine local machine size via ebn via internet via ethernet via atm switch bytes ms ms ms ms 1008 2008 8008 22 441 table 2 approximate performance measurements using ping imately 15 ms compared theoretical limit roundtrip 76 ms switch technology transit delays approximately 10 per switch depending upon exact number switches whole system could approach measurable effect beyond precision ping resolve believe allowing nonvacuo lightspeeds actual limitation measured latency close within better factor two best achievable believe variations caused factors exact route ebn takes slower signal propagation speed terrestrial copper cables routers switch overheads small overheads initiating ping combined satisfactorily explain discrepancy latencies ebn appears provide close best reasonably achievable latency also interest bandwidth achieved actual bandwidth achieved given application vary depending upon protocols buffering layers traffic network ping measurements suggest approximate value 2 8kb22 227mbits represents approximately 84 27mbits bandwidth available us operational network unix utility ttcp useful determining bandwidth performance measurements outwith resolution possible ping typical achievable bandwidth local machines operational 155mbits fibre network 1103 mbits compared typical figure local 10mbits ethernet 6586mbits figures representative busy network user traffic 1998 1999 additional link connecting australia japan made available us dedicated 1mbits bandwidth available experimentation carried work collaboration real world computing partner shiprwcp 28 japan found effective latency around 200ms single trip adelaide tsukuba city japan atm network experiences suggest major limitations wide area cluster computing future likely latency limitations rather bandwidth limitations telstra experimental broadband network closed end 1998 alternative atm network supplied optus pty ltd made available us 1999 network similar latency characteristics advantage apply burst full 155mbits adelaide canberra practice found 8mbits entirely adequate day day widearea cluster computing operations interesting reflect experiences setting using net works staff telstras research laboratories instrumental setting initial circuits allocating bandwidth experiments trials proceeded became well automated process little human intervention required except needed split bandwidth allocations video cluster file system circuits example one problems experimental set permanent virtual circuits pvcs available us network configuration routing hosts needed changed manually time reconfiguration required one promises atm standard switched virtual circuits svcs could manipulated software reallocate bandwidth different applications although able experiment pseudo svcs using proprietary facilities atm switch gear possible enable proper switch virtual circuits across different vendors switch gear different sites collaboration knowledge still available wide area atm networks believe disappointing limitation technology practice expended considerable time effort carrying experiments particularly difficult reconfigure routers operating systems driver software every time needed carry different experiment atm technology matured since start experiments believe technology choice cluster computing level atm likely still find place network backbone technology certainly long distance networks perhaps even still local area networks driver support administration tools atm based cluster computing appear forthcoming consequently believe much likely internet protocols implemented top atm technologies perhaps much useful cluster computing 3 metacomputing cluster management vision start wide area network trials national computer room imagined network software management infrastructure would enable institutions share access scarce highperformance computing sources seemed important given scarcity supercomputing systems australia particular revised vision however still areas computer sharing mechanism important whole supercomputing industry continued shaken global reduction number supercomputer vendors still business attributed number factors least greater availability cluster computing resources need institutions control resources appears strong one relatively cheap cluster computing systems enables phenomena believe therefore although still need software enable compute resource sharing resources likely clusters affects characteristics software applications integrate software netsolve globus legion ninf discworld system aimed enabling use distributed computing resources applications favoured approach encapsulate applications including parallel ones services run metacomputing environment focussed efforts building java middleware allow approaches taken experiences parallel computing era allow wide area systems behave tightly coupled parallel system running multi processor applications across wide area net works choice matter granularity group parts application together wide area parallel approach attractive simplicity tools technologies parallel computing redeployed software reengineering efforts metacomputing approach recognizes networks espe cially widearea ones remain unreliable long distance latencies improve short new physics breakthrough fundamental distributed computing problems need considered building widearea cluster systems distributed information systems control world discworld 16 metacomputing model framework series prototype systems developed date basic unit execution discworld service services prewritten software components applications either written java legacy codes provided java wrapper users compose number services together form complex processing request jobs scheduled across participating nodes 19 example discworld application land planning system 5 client application requires access land titles information one site digital terrain map data another aerial photography satellite imagery stored another site discworld build parallel computing technology embed parallel programs services support module known jump provides integration messagepassing parallel programs might run conventional supercomputer cluster13 environment discworld ideal use across cluster distributed network clusters nodes within cluster used federated hosts connected via highspeed dedicated network nodes used parallel processor farm running services implemented parallel programs employed approaches multi cluster experiments across atm network ability make intelligent decisions schedule services discworld environment order minimize either execution time total resource cost relies ability characterise services nodes environment fast networking technologies section review major networking technologies describe roles wide area highperformance cluster computing discuss asynchronous transfer mode atm fast ethernet gigabit ethernet scalable coherent interconnect sci myrinet technologies technologies may differing roles play widearea cluster computing next years table 3 summarises networking technologies consider data table combined benchmarking experiments well reports literature 6 22 23 29 seen problems require gigabitorder bandwidth fast ethernet seems logical choice gigabitorder bandwidth required decision clearcut complex tradeoff bandwidth latency attainable approximate cost per node whether technology considered commodity use term commodity refer fact technology available mass market available specialist vendors technology theoretical measured tcpip latency approx cost bandwidth bandwidth per node us ethernet 10mbits 658mbits 12ms 80 fast ethernet 100mbits 68mbits 1ms 150 atm 155mbits 1103mbits 1ms 2500 gigabit ethernet 1000mbits 950mbits 12ms 1200 sci 1600mbits 106mbits 4s 1400 myrinet 1200mbits 1147mbits 117s 1700 table 3 interconnection network technologies characteristics measured also reported open literature able trial atm network clusters using sponsorship australian commonwealth government table 3 shows atm still especially economic choice belief gigabit ethernet technology widely adopted correspondingly driven price 41 atm asynchronous transfer mode atm 1 collection communications protocols supporting integrated data voice networks atm developed standard widearea broadband networking also finds use scalable local area networking technology atm best effort delivery system sometimes known bandwidth ondemand whereby users request receive bandwidth dynamically rather fixed predetermined paid rate atm guarantees cells transmitted sequence received order atm technology provides cellswitching multiplexing combines advantages packet switching flexibility efficiency intermittent traffic circuit switching constant transmission delay guaranteed capacity atm uses pointtopoint fullduplex transmission medium provides connectionoriented protocols addition supporting native atm protocols atm adaption layer aal 34 5 use lane allows atm network viewed part tcpip network allow multicast broadcast number studies consider use aals highspeed interconnections parallel computing 20 employ 155mbits localarea atm network 14 15 well 34mbits broadband network ebn atm allows guaranteed bandwidth reservation across circuit link number links defined endpoints three different types bandwidth reser vation constant bit rate cbr variable bit rate vbr available bit rate abr cbr used traffic sites constant rarely ever change bandwidth requirements vbr used characterise traffic mean bandwidth requirement change slightly traffic along vbr circuit operate cir cuits maximum bandwidth short amounts time intermediate switches may drop cells exceed vbr parameters finally abr exists bursty traffic cannot easily characterised abr traffic sent uses available link ca pacity enough link capacity traffic abr traffic queued buffers fill case cells dropped atm popular telecommunications industry 21 broadband networks cbr vbr traffic used dedicated statically dynamically allocated customer links voice constantrate data typical data characterised bursty make sense reserve bandwidth cbr even vbr capacity abr uses available bandwidth atm link must used avoid wasting capacity many sites adopted atm local area network major factor prohibiting widespread adoption cost atm switches atm interface cards individual nodes 42 notable networking technologies high performance parallel interface hippi pointtopoint link uses twistedpair copper cables connect hosts via crossbar switches hippi gets name data transmitted parallel connecting cables 50 cores used transmit data one bit per line standard allows transmission rates 800mbits 1600mbits maximum length copper cables 25 metres serial version hippi available using fibre optic media allows maximum distance 10km ends hippi successfully used networking supercomputer systems seems likely overtaken cheaper technologies fibre channel fc defined fibre channel standard circuitswitching also packetswitching technology allows transmission multiple rates data sent frames 2148 bytes 2048 bytes data fc successfully used interconnecting hosts also likely overtaken economics technologies 43 internet native technology protocols many networking technologies proprietary communications protocols atm adaptation layers aal proprietary protocols provide optimized communication usually tradeoff code portability using proprietary protocols also fraught pitfalls majority users wish make every optimisation code users working heterogeneous mixtures networking hardware custom protocols widely used example experiments atms aal5 uncovered bug implementation manufacturers engineers said could fixed purchasing much faster machine 20 experimented implementing message passing communications software raw atm adaptation layers conclude since approach widely supported atm vendors feasible approach long term conclude experiments using wellknown standard protocol ip easiest portable approach manufacturers provide encapsulation ip packets within proprietary protocols atms lan emulation ip promises around long time advent ipv6 features ip tunneling allowing standard ip traffic encapsulated within ipv6 packets18 summary found 10mbits desktop connections still common current machines capable effectively utilising 100mbits connection clusters workstations medium bandwidth requirements 100mbits fast ethernet viable affordable solution high bandwidth required tradeoff cost performance necessary sci provides best latency measured bandwidth nowhere near high myrinet myrinet largest bandwidth systems consider latency still millisecond larger latency tolerated bandwidth critical believe open standards gigabit ethernet may appropriate choice reiterate believe economics large markets ensure gigabit ethernet technology becomes widespread cluster computing 5 summary conclusions article reviewed number fast networking technologies cluster computing related experiences atm particular preliminary experiments experiences reported leads us believe combination fast ethernet gigabit ethernet chosen route general purpose beowulf class cluster computing systems believe technical criteria fairly finely balanced factor two advantages one technology economics mass market dictate technology becomes widespread course feedback phenomena cheaper switches network cards adopted even widely believe atm may still role play wide area cluster computing systems preferable transparent cluster users cluster system soft ware internet protocol surely implemented top atm users cluster software continue interface believe still many interesting developments made software manage wide area clusters well highperformance clusters seems important recognise message passing level technology play useful part high performance systems considerable research still done address latency reliability issues wide area cluster systems 6 acknowledgements thanks jamathew assistance carrying measurements reported work also pleasure thank helped conducting trials ebn kjmaciunas dkirkham staylor mrezny mwilson mbuchhorn r available httpwww casa project comparison high speed lans grid blueprint new computing frastructure pvm parallel virtual machine users guide tutorial networked parallel computing gigabit ethernet alliance ieee standards online ieee standards online geographic information systems applications atmbased distributed high performance computing system discworld environment servicebased metacomputing high performance fortran forum hpff internet engineering task force scheduling metacomputing systems using atm distributed applications telstras experimental broadband network comparison two gigabit sanlan technolo gies scalable coherent interface myrinet assessment gigabit ethernet cluster interconnect atm performance characteristics distributed high performance computers message passing interface forum applications enabling technology nynet upstate corridor object management group 3com corporation tr pvm parallel virtual machine grid discworld myrinet geographic information systems application atmbased distributed high performance computing system geostationarysatellite imagery applications distributed highperformance computing legiona view 50000 feet assessment gigabit ethernet cluster interconnect