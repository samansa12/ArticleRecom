robust temporal spectral modeling query melody query melody problem retrieving musical performances melodies retrieval real performances complicated due large number variations performing melody presence colored accompaniment noise describe simple yet effective probabilistic model task describe generative model rich enough capture spectral temporal variations musical performances allows tractable melody retrieval previous studies music retrieval melodies performed either symbolic eg midi data monophonic single instrument performances performed experiments retrieving live studio recordings operas contain leading vocalist rich instrumental accompaniment results show probabilistic approach propose effective scaled massive datasets b introduction natural way searching musical audio database song look short audio segment containing melody song existing systems based textual information title song name composer however people often remember name composer songs title easily recall fragments soloists melody task query melody attempts automate music retrieval task rst discussed context query humming 11 13 14 works focus converting hummed melodies symbolic midi format midi acronym musical instrument digital inter face symbolic format representing music permission make digital hard copies part work personal classroom use granted without fee provided copies made distributed profit commercial advantage copies bear notice full citation first page copy otherwise republish post servers redistribute lists requires prior specific permission andor fee sigir02 august 1115 2002 tampere finland query converted symbolic format challenge search musical performances approximately match query research far conducted music stored midi format 12 monophonic ie single vocal instrument recordings see instance 9 7 references therein paper suggest method query melody query posed symbolic form monophonic melody database consists real polyphonic recordings dealing real polyphonic recordings need address several complicating factors ideally melodies represented sequences notes pair frequency temporal duration real recordings two major sources diculty arise rst high variability actual durations notes melody performed faster slower one dictated musical score type variation often referred tempo vari ability furthermore tempo vary within single performance instance performance start slow tempo gradually increases second complicating factor high variability spectrum due many factors dierences tone colors timbre dierent singersinstruments intentional variation leading vocalists eg vibrato dynamics spectral masking leading vocal accompanying vocals orchestra propose tackle diculties using generative probabilistic approach models temporal spectral variations associate note hidden tempo variable tempo variables capture temporal variations durations notes enable ecient com putation hidden tempo sequence modeled rst order markov process addition also describe simple probabilistic spectral distribution model robust masking noise accompanying instruments singers spectral distribution model variant harmonic likelihood model pitch detection 16 combining temporal spectral probabilistic components obtain joint model thought dynamic bayesian network 8 representation enables ecient alignment retrieval using dynamic programming probabilistic approach related several recent works employ hidden markov models hmm music processing raphael 15 uses melody information pitches durations notes building hmm score following application similar approach taken durey clements 9 use pitch information notes building hmms melody retrieval however approaches designed evaluated monophonic music databases work polyphonic music processing addressed tasks music segmentation textures 6 polyphonic pitch tracking 18 genre classication 17 10 believe approach describe paper step toward eective retrieval procedure massive musical datasets 2 problem setting setting given melody task retrieve musical performances containing requested melody nd location within retrieved perfor mances melody sequence notes note pair pitch value duration value goal retrieve melodies audio signals representing real performances formally let r denote positive real numbers let frequency values hz let f l fh diapason diapason singer instrument range pitch frequencies use singer instrument instance tenor singer typically employs diapason 110hz 530hz let denote set possible frequencies notes welltempered western music tuning system possible pitches notes diapason melody described formally sequence pitches p 2 k sequence durations 2 r k predened time units eg seconds samples performance melody discrete time sampled audio performance formally entirely dened given melody play sing using pitch p1 rst d1 seconds play sing pitch p2 next d2 seconds forth reality melody impose rigid framework actual frequency content given note varies type instrument played performer examples variations vibrato timbre eects accompaniment also greatly uences spectral distribution playing note using pitch p likely see local concentration energy close multiples frequency p power spectrum signal however may spectral regions high levels energy address problem later section another source variation local scaling durations notes instructed melody performer typically uses tempo scales duration moves one tempo another thus using dierent time scale play notes therefore also need model variation tempo describe tempo sequence sequence scaling factors 2 actual duration note denoted e scaled seemingly allowing dierent scaling factors dierent notes adds degree freedom makes melody duration values redundant however typical tempo sequence change rapidly thus ects information original durations scaling factor table 1 shows two examples sequences pitchdurationtempo triplet p generates actual pitchduration pair p e rallentando 12 12 125 13 13 table 1 examples scaling factor sequences rst sequence scaling factors gradually increasing thus tempo decreasing rallentando second example scaling factors decreasing tempo increasing accelerando order describe generation actual performance audio signal p e introduce one vari able 2 r k starting time sample number note performance dene e j consecutive blocks signal samples let block samples generated note power spectrum varies signicantly performance performance according various factors spectral envelope soloist pitches accompaniment instruments since goal locate retrieve melody dataset may contain thousands per formances resort simple spectral model explicitly model variables use approximation likelihood block spectrum given pitch 3 melody signal generative model pose problem probabilistic framework need describe likelihood performance given melody cast tempo sequence hidden random variable thus likelihood written simplicity assume tempo sequence depend melody assumption naturally always hold found empirically types correlations ingnored short pieces perfor mances assumption identity e equ 1 rewritten need specify prior distribution tempo posterior distribution signal given pitches actual durations notes p ojp e 31 modeling chose model tempo sequence rst order markov process see sequel choice one hand allows ecient alignment retrieval hand found empirically rich enough fore likelihood given use lognormal distribution model conditional probability scaling parameter variance prior distribution rst scaling factor p m1 also assumed lognormal around zero variance log 2 n 0 experiments parameter determined manually according musical knowledge parameter also learned midi les 32 spectral distribution model section describe spectral distribution model exist quite models spectral distribution singing voices harmonic instruments however models rather general models typically assume musical signal contaminated white noise whose energy statistically independent signal see instance 16 references therein contrast assume leading instrument soloist accompanied orchestra chorus energy accompaniment typically highly correlated energy soloist put another way dynamics accompaniment matches dynamics soloist instance soloist sings pianissimo chorus follows pianissimo voices therefore developed simple model whose parameters eciently estimated copes correlation energy leading soloist accompaniment fig 1 show spectrum one frame performance signal database harmonics designated dashed lines clear gure large concentration energy designated harmonics residual en ergy outside harmonics certainly nonnegligible clearly lower energy harmonics thus assumptions although simplistic seem capture large extent characteristics spectrum singing accompaniment using denition block sec 2 likelihood signal given sequences pitches durations decomposed product likelihood values individual blocks therefore core modeling approach probabilistic model spectral distribution whole block given underlying pitch frequency soloist starting point similar model presented 16 assume note pitch p attains high energy frequencies multiples p namely p h integer h frequencies often referred harmonics since signal band limited need consider nite set harmonics h h 2 f1 2 hg practical purposes set h 20 enables fast parameter estimation procedure let f denote observed energy block frequency let denote energy soloist frequency harmonic model assumes figure 1 spectrum single frame along impulse train designating harmonics soloist bursts energy centered harmonics pitch frequency p h model weighted sum ah volume gain harmonic whose index h residual spectrum frequency denoted n equal describe probabilistic model leads following loglikelihood score log denotes 2norm derive equation assume spectrum ith block f comprised two components rst component energy soloist dened equ 2 second component general masking noise encompasses signals energy due accompaniment aects entire spectrum denote noise energy frequency energy spectrum frequency therefore modeled impose another simplifying assumption setting noise multivariate normal random variable assuming noise values frequency statistically independent equal variance thus noise density function v variance l number spectral points computed discrete fourier transform chose get good spectral resolution taking log density function get log gain values ah free parameters need estimate spectrum assuming noise level relatively small compared bursts energy harmonics pitch frequency set value ah f p h also know noise variance v parameter use simple maximum likelihood ml estimate easily found follows maximum likelihood estimate v found taking derivative log fjv respect v log fjv rearranging equ 4 noise value frequency written using equation along values set ah maximum likelihood estimate v equ 6 get log log since stochastic ingredient spectral model accompanying noise noise likelihood also constitute likelihood spectrum summarize overview approach retrieval given melody p want nd audio signal represents performance melody using probabilistic framework cast problem problem nding signal portion whose likelihood given melody p ojp high search strategy follows nd best alignment signal melody describe next section score alignment procedure devise also means retrieval rank segments signals accordance likelihood scores return segments achieving high likelihoods scores 4 alignment retrieval alignment melody signal performed nd ing best assignment tempo sequence formally looking scaling factors attain highest likelihood score although number possible sequences scaling factors grows exponentially sequence length problem nding eciently solved using dynamic programming describe scaling factors rst notes melody let rst samples signal let discrete set possible scaling factor values 2 let set possible sequences scaling factors scaling factor note 1 initialization 2 recursion 3 termination figure 2 alignment algorithm actual ending time note let joint likelihood pseudo code computing recursively shown fig 2 likely sequence scaling factors obtained algorithm saving intermediate values maximize expression recursion step complexity algorithm okt jm j 2 k number notes number samples digital signal jm j number possible tempo values maximal duration note using precomputation likelihood values reduced time complexity factor thus run time algorithm reduces okt jm j 2 important clarify precomputation completely determine single pitch value frame calculates probability frame given possible pitch diapason mentioned primary goal retrieve segments signals representing melody given query theoretically need assign segment likelihood score however marginal probability rather expensive compute thus approximate probability joint probability signal likely sequence scaling factors use likelihood score alignment procedure retrieval score 5 experimental results evaluate algorithm collected 50 dierent melodies famous opera arias queried melodies database real recordings recordings consist 832 performances opera arias performed 40 dierent tenor singers full orchestral accompaniment performance one minute data extracted seven audio cds 2 3 5 1 4 saved wav mat performances 90 percent digital recordings dddadd yet performances digital remastering old analog recordings aad spectral distribution model hsn hin avgp cov oerr avgp cov oerr melody length table 2 retrieval results introduced additional complexity retrieval task due varying level noise melodies experiments extracted midi les half midi les downloaded internet 1 rest midi les performed midi keyboard saved midi les compared three dierent tempobased approaches retrieval rst method simply uses original durations given query without scaling refer simplistic approach fixed tempo ft model second approach uses single scaling factor durations given melody however scaling factor determined independently signal maximize signals likelihood refer model locally fixed tempo lft model third retrieval method variable tempo model introduced paper therefore refer method variable tempo model taking prex subset melody used query evaluated three dierent lengths melodies 5 seconds 15 seconds 25 seconds assess quality spectral distribution model described sec 32 implemented spectral distribution model described 16 model assumes harmonics signal contaminated noise whose mean energy independent energy harmonics refer model harmonics scaled noise hsn model model 16 harmonics independent noise hin model evaluate performances methods used three evaluation measures oneerror coverage average precision explain measures introduce following notation let n number performances database let number melodies search mentioned experiments 50 melody index denote set performances containing melody probabilistic modeling discussed paper induces natural ordering performances melody let r j denote ranking performance indexed j respect melody based denitions httpwwwmusicscorefreeservecouk httpwwwclassicalmidigothereukcom give formal denitions performance measures used evaluation oneerror oneerror measures many times topranked performance contain melody posed query thus goal system return single performance contains melody oneerror measures many times retrieved performance contain melody formally denition oneerror predicate holds 0 otherwise coverage oneerror evaluates performance system respect topranked performance goal coverage measure assess performance system possible performances melody informally coverage measures number excess non relevant performances need scan retrieve relevant performances formally coverage dened average precision measures suce evaluating performances retrieval systems one achieve good low coverage suer high oneerror rates vice versa order assess ranking performance whole use frequently used average precision mea sure formally average precision dened addition also use precision versus recall graphs illustrate overall performances dierent approaches discussed paper precisionrecall graph shows level precision dierent recall values graphs presented paper noninterpolated calculated based precision recall values achieved integer positions ranked lists table 2 report results respect performance measures described ft lft vt mod els tempo model conducted experiments two spectral distribution models hin hsn clear table variable tempo model harmonics scaled noise spectral distribution outperforms rest models achieves superior results moreover performance variable tempo model consistently improves duration queries increases contrast fixed tempo exhibit improvement duration queries increases locally fixed tempo shows moderate improvement using fteen second long queries instead second long queries improve duration grows twenty seconds reasonable explanation phenomena amount variability short query naturally limited thus leverage gained accurate tempo modeling takes account variability tempo rather small thus query recall precision precision recall precision figure 3 precisionrecall curves comparing performance three tempo models queries consisting seconds top fteen second middle twenty seconds bottom precision recall precision recall precision figure 4 precisionrecall curves comparing performance tempo models three different query lengths duration grows power variable tempo model better exploited locally fixed tempo capture average tempo performance clearly fails capture changes tempo since chance tempo change grows duration query average tempo stops good approximation see improvement retrieval quality fig 3 give precisionrecall graphs compare three tempo models graph compares ft lft vt dierent query durations vt model clearly outperforms ft lft models longer query wider gap performance fig 4 compare precisionrecall graphs model function query duration graph shows precisionrecall curves 5 15 25 seconds queries see vt model consistently improves increase query duration using globally xed tempo ft clearly inadequate results poor performance precision never higher 035 even low level call performance lft model reasonable precision 05 achieved recall value 05 however full power approach utilized use vt model achieve average precision 092 recall 075 seems vt model reach overall performance serve basis large scale music retrieval systems lastly nal sanity check conjecture robustness vt model used vt lft model three long melody queries one minute applied retrieval alignment process let professional musician listen segmentation browse segmented spectogram example spectogram segmentation vt model given fig 5 example performance energy accompaniment higher energy leading tenor nonetheless listening experiment veried system able properly segment align melody posed query although perceptual listening tests subjective experiments indicated vt model also provides accurate alignment segmentation 6 discussion paper presented robust probabilistic model query melody proposed approach simple implement found work well polyphony rich recordings various types accompaniments probabilistic model developed focuses two main sources variability rst variations actual durations notes real recordings tempo variability second variability spectrum mainly due spectral masking leading vocal accompanying vocals orchestra work assumed pitch information query accurate duration altered performance assumption reasonable queries posed using symbolic input mechanism midi keyboard however easier convenient mechanism hum whistle melody task often called query humming addition tempo variability spectral masking query humming system also needs take account imperfections pitch hummed melody indeed frequency time figure 5 illustration alignment segmentation vt model pitches notes melody overlayed solid lines much work query humming devoted music retrieval using noisy pitch information majority work query humming though focused search noisy queries symbolic databases since main thrust research searches real polyphonic recordings complements research query humming supplement numerous systems search databases plan extend algorithm combined front end hummed queries addition started conducting research supervised methods musical genre classication believe combining highly accurate genre classication robust retrieval alignment able provide eec tive tool searching browsing professionals amateurs acknowledgments would like thank moria koman help creating queries used experiments leo kon torovitch useful comments manuscript 7 r best opera les 40 tenors nessun dorma young domingo model reasoning persistent causation melody spotting using hidden markov models overview audio information retrieval query humming musical information retrieval audio database searching monophonic patterns within polyphonic sources new zealand digital library melody index automatic segmentation acoustic musical signals using hidden markov models speech enhancement harmonic modeling via map pitch track ing audio information retrieval air tools pitch tracking using joint bayesian estimation multiple frame parameters tr model reasoning persistence causation query humming overview audio information retrieval automatic segmentation acoustic musical signals using hidden markov models ctr keiichiro hoashi kazunori matsumoto naomi inoue personalization user profiles contentbased music retrieval based relevance feedback proceedings eleventh acm international conference multimedia november 0208 2003 berkeley ca usa fangfei kuo mankwan looking new known music music retrieval melody style proceedings 4th acmieeecs joint conference digital libraries june 0711 2004 tuscon az usa olivier gillet gal richard drum loops retrieval spoken queries journal intelligent information systems v24 n2 p159177 may 2005