ordering anisotropy factored sparse approximate inverses consider ordering techniques improve performance factored sparse approximate inverse preconditioners concentrating ainv technique benzi truma several practical existing unweighted orderings considered along new algorithm minimum inverse penalty mip propose show good orderings improve speed preconditioner computation dramatically also demonstrate fast fairly reliable way testing good ordering respect test results also show orderings generally improve convergence krylov subspace solvers may difficulties particularly anisotropic problems argue weighted orderings take account numerical values matrix necessary systems developing simple heuristic dealing anisotropy propose several practical algorithms implement show promise conclude better heuristic required robustness b introduction consider solving system linear equations sparse nn matrix depending size nature computing environment iterative method form preconditioning speed convergence popular choice approximate inverse preconditioners whose application requires easily parallelized matrixvector multiplication particular interest today several methods constructing approximate inverses proposed eg 2 3 9 20 22 24 falling two categories directly form approximation 1 form approximations inverses matrixs lu factors second category currently shows promise first three reasons first easy ensure factored preconditioner nonsingular simply making sure factors nonzero diagonals second factorization appears allow information per nonzero stored improving convergence 4 8 third setup costs creating preconditioners often much less 4 however unlike 1 inverse lu factors critically dependent ordering rows columnsindeed exist general orderings even case spd matrix direct methods shown important ordering thus factored approximate inverse scheme must handle received editors march 6 1998 accepted publication revised form march 18 1999 published electronically november 17 1999 research supported natural sciences engineering council canada communications information technology ontario cito funded province ontario httpwwwsiamorgjournalssisc21333584html stanford university sccm program room 284 gates building 2b stanford ca 94305 department computer science university waterloo waterloo n2l 3g1 canada wptangriacsedu 868 robert bridson weipai tang ordering thought particular eective preconditioner ordering minimizes size dropped entries neededdecreasing error approximate inverse factors true ones see 14 discussion context ilu paper focus attention ainv algorithm 3 via implicit gaussian elimination smallelement dropping constructs factored approximate z w unit upper triangular 1 diagonal however purely structural results presented section 2 apply equally factored approximate inverse schemes whether numerical results carry still determined example conflicting evidence presented 5 16 eect fsai 22 perhaps resolved issue sparsity pattern selection fsai settled preliminary work studying eect ordering performance ainv shown promising results 3 recent work authors 5 carry research forward sections 2 3 realizing significant improvements speed preconditioner computation observing beneficial eects convergence noting structural information alone always enough turn attention anisotropic problems ilu class preconditioners determined orderings take numerical values matrix account usefuleven necessary eg 10 11 12 14 sections 46 try answer question whether thing holds factored approximate inverses appendix contains details test results 2 unweighted orderings intuitively smaller size dropped portion true inverse factors better approximate inverse assume magnitudes inverse factors nonzeros distributed roughly way dierent orderings experience shows fairly good assumption typical isotropic problems shall see later breaks anisotropic matrices particular consider simpler problem reducing number dropped nonzeros instead size course sparsity also want retain nonzeros possible thus really want reduce number nonzeros exact inverse factorsa quantity call inverse factor fill f fill definition 21 let square matrix triangular factorization lu f fill defined total number nonzeros inverses l u assuming cancellation forming inverses simplicity restrict discussion spd case first examining f fill considering several existing ordering algorithms may helpful finish section proposing new ordering scheme call mip application unsymmetric case straightforward following discussion makes use concepts graph theory graph n n matrix directed graph n nodes labeled 1 n arc j ij 0 directed path dipath ordered set arcs existoften written u 1 u k see chapter 3 17 example explanation gilbert 19 liu 23 following graph theoretic characterization structure inverse cholesky factor ordering anisotropy approximate inverses 869 theorem 22 let spd matrix cholesky factor l assuming cancellation structure corresponds transitive closure 1 graph l j z ij 0 dipath j graph l furthermore structure given transitive closure elimination tree transitive reduction 2 l notice last structure characterization simply means j ancestor elimination tree allows us significantly speed computation preconditioner given bushy elimination tree well allowing parallelismfor calculation column j factors ancestor columns need considered coarsergrain version parallelism via graph partitioning successfully implemented 6 exam ple another product characterization simple way computing f fill spd matrix obtained summing number nonzeros column inverse factor multiplying two transposed factor theorem 23 f fill spd matrix simply twice sum depths nodes elimination tree particular number nonzeros column j true inverse factor z given number nodes subtree elimination tree rooted j results suggest orderings avoid long dipaths l ie paths l monotonically increasing node indices cause lots f fill quadratic length alternatively trying get short bushy elimination trees another useful characterization f fill using notions 17 18 allows us cheap inverse symbolic factorizationdetermining nonzero structure inverse factorswithout using elimination tree essential minimum inverse penalty mip ordering algorithm presented later theorem 24 z ij 0 reachable j strictly nodes eliminated previous ior terms quotient graph model contained supernode adjacent j moment j eliminated based heuristic results examine several existing orderings might well propose new scheme directly implement heuristic reducing f fill redblack simplest ordering consider generalized redblack maximal independent set red nodes ordered first remaining black nodes ordered next according original sequence initial red block nontrivial dipaths hence odiagonal entries z minimum degree benzi tuma observed minimum degree generally beneficial ainv 3 justified noting minimum degree typically substantially reduces height elimination tree hence reduce f fill aside notice directmethod fillreducing orderings necessarily reduce f fill example good envelope ordering likely give rise tall narrow elimination treetypically pathand thus give full inverse factors noted isnt necessarily bad thing inverse factors still small entries without using numerical information matrix experience envelope orderings manage may seem 1 transitive closure directed graph g graph g vertices arc vertices u v connected dipath u v g 2 transitive reduction directed graph g graph g minimum number arcs still possessing transitive closure g variance result 13 elaborated 5 factored inverses banded spd matrices rate decay entries inverse upper bound decreases bandwidth decreases however decay measured terms distance diagonal really suitable small bandwidth orderings results presented section 5 13 measuring decay terms unweighted graph distance make theoretical progress possible return issue sections 46 nested dissection nd hand ordering vertex separators last nd avoids long monotonic dipaths hence lot f fill alternatively trying balance elimination tree reduces sum depths minimum inverse penalty mip noted cheaply compute number nonzeros column z within symbolic factoriza tion allows propose new ordering mip analogue minimum degree minimum degree built around symbolic cholesky factorization matrix step selecting nodes minimum penalty eliminate penalty originally taken degree node partially eliminated graph later algorithms used related quantities including external degree approximate upper bounds mip follow greedy strategy compute penalty node v based zdeg v number nonzeros column z v ordered nextthe degree inverse cholesky factor instead well udeg v number uneliminated neighbors node v current stage factorization counting supernodes experiments found function penalty fairly eective research better penalty function needed also ideas minimum degree multiple elimination element absorption etc might suitable 3 testing unweighted orderings used symmetric part matrix orderings redblack implemented straightforward greedy algorithm select maximal independent set minimum degree algorithm amdbar topnotch variant due amestoy davis du 1 wrote nd algorithm constructs vertex separators edge separators given multilevel bisection algorithm algorithm coarsens graph degree1 node compression heavyedge matchings less 100 nodes bisects small graph spectrally according fiedler vector 15 uses greedy boundarylayer sweep smooth projecting back original see 21 example details point appendix provides details testing tables contain data unweighted orderings weighted counterparts presented belowignore lower numbers brief selected several matrices harwellboeing collection tested ordering scheme table 4 gives true f fill matrix symmetric part ordering tables 57 give preconditioner performance number nonzeros allowed preconditioner significant eect results standardized test runs box left number report preconditioner many nonzeros matrix right number preconditioner twice many nonzeros terms f fill reduction amdbar nd mip always best three considerable factor nd wins 15 times amdbar 5 times mip 3 times one tie redblack beats natural ordering dramatically clear ordering help immensely accelerating computation ordering anisotropy approximate inverses 871 inverse fill time compute preconditioner fig 1 correlation f fill preconditioner computing time normalized respect given original ordering table average decrease number iterations test set percentages iterations taken given ordering fill redblack amdbar nd mip preconditioner nd winner followed amdbar mip redblack quite bit behind preconditioner computing time closely correlated f fillsee figure 1 thus calculating f fill provides fast reasonably good test indicate ecient unweighted ordering preconditioner computation perhaps important point iteration time dominates setup time may useful applications reverse true eect ordering speed solution less obvious poor behavior pores2 3 sherman2 watson5 indicate ainv probably isnt appropriate although properly treated sherman2 block matrix instead might gone better notice particular sometimes lowering drop tolerance increasing size preconditioner hopefully making accurate actually degrades convergence indefinite problems remaining matrices compared average decrease number iterations given orderingsee table 1 particularly given problems saylr4 wat son4 watt1 watt2 redblack cannot viewed good ordering mip overall best although problem watt1 whereas close contender amdbar fairly well dicult three mentioned good f fill reducing orderings made worthwhile improvements convergence rates surprising nd least considering superior f fill reduction clearly intuition fewer nonzeros drop makes better preconditioner merit tell entire story 3 3 somewhat better convergence achieved pores2 presumably due implementation dierences preconditioner application 872 robert bridson weipai tang 4 anisotropy preceding test results find several exceptions general rule amdbar nd mip perform similarly even ignoring pores2 sherman2 watson5 example considerable variations ale3d bcsstk14 nasa1824 orsreg1 saylr4 watson4 importantly variations correlated f fill factor work noticing matrices quite anisotropic recalling problems anisotropy poses ilu led investigate weighted orderings first develop heuristic handling anisotropic matrices goal mind order using diering strengths connections reduce magnitude inverse factor entries even end f fill hence drop nonzeros magnitude discarded portion inverse factors may smaller give accurate preconditioner look spd let ldl modified cholesky fac torization l unit lower triangular diagonal since zero diagonal hence nilpotent nonzero entries sum correspond monotonically increasing di orderings therefore avoid many dipaths involve large entries l one could substantially increase magnitude zs entries thus want move large entries away diagonal cannot appear many monotonic dipaths words node ordered want order remaining neighbors strong lconnections come late possible purposes ordering heuristic want easy approximation l independent eventual ordering chosensomething capture order magnitude entries l doesnt require us decide ordering ahead time assuming adequately dominant diagonal without much variation take absolute value lower triangular part symmetrically rescaled unit diagonal thought scaled gaussseidel approxima tion general heuristic delay strong connections approximating matrix defined alternative justification heuristic simply context reducing magnitude entries l presented 10 consider simple demonstration problem determine whether heuristic could help matrix singleaniso comes 5point finitedierence discretization regular 31 31 grid following pde edges corresponding ydirection 1000 times heavier corresponding xdirection try comparing two f fill reducing orderings first ordering strongfirst blockorders grid columns ordering anisotropy approximate inverses 873 strongfirst ordering weakfirst ordering fig 2 two orderings singleaniso depicted domain lighter shaded boxes indicate nodes ordered later table performance strongfirst ordering versus weakfirst ordering singleaniso ordering time compute preconditioner number iterations time iterations strongfirst weakfirst 038 25 025 nested dissection internally orders block nested dissectionthis brings strong connections close diagonal second weakfirst block orders grid rows instead pushing strong connections away diagonal delaying last illustrated figure 2 square grid shaded according place ordering orderings produce reasonable f fill 103682 isomorphic elimination trees however give dierent performance first level fillsee table 2 respects weakfirst ordering significantly better strong first one figure 3 plot decay entries inverse factors resulting two orderings show parts factors much smaller entries weakfirst ordering confirm heuristic 5 weighted orderings experience appears f fill reduction typically helps also reduce magnitude entries inverse factors blind numerical values matrix make mistakes allowing strong connections close diagonal creating algorithms ordering general matrices thus tried simply modify unweighted algorithms consider numerical values weighted nested dissection wnd consider spectral bipartition al gorithm finding fiedler vector eigenvector laplacian graph second smallest eigenvalue see 15 equivalent minimizing space orthogonal constant vectors entries sorted magnitude magnitudes comparing decay factors strongfirst weakfirst closeup strongfirst closeup weakfirst fig 3 comparison magnitude entries inverse factors dierent orderings singleaniso closeup images actual factors shaded according magnitude nonzerosdarker means bigger ij edge make bipartition depending side median entry lies notice closer together two entries valueie smaller isthe likely nodes ordered side cut would like weakly connected nodes ij small part strong connections edge cut try minimizing following weighted quadratic sum ij edge scaled matrix mentioned corresponds finding eigenvector second smallest eigenvalue weighted laplacian matrix graph defined edge ij 0 weighti thus modify nd simply changing laplacian used bipartition step weighted laplacian fortunately multilevel approach heavy edge matchings typically eliminate largest odiagonal entries well substantially decreasing size eigenproblem making easy solve wnd reasonable compute outin weighted orderings based intuition finite dierence matrices expect nodes involved long heavy paths near weighted center graph minimum weighted eccen tricity nodes least involved paths intuitively ones weighted ordering anisotropy approximate inverses 875 periphery graph thus outin orders periphery first proceeds approximate weighted center outside inside eciently find approximate weighted center use iterative algorithm algorithm 1 approximate weighted center calculate mweighted shortest paths mweighted distances nodes v distance minimum sum weights given along connecting path select node e maximum distance v travel r way along shortest path v e saving resulting node v i1 end loop v approximate center outin ordering following algorithm 2 outin compute get approximate weighted center c calculate distances shortest paths nodes c return nodes sorted order distant first c last despite earlier remark envelope orderings might useful weight information actually lets outin perform significantly better natural ordering reducing size nonzeros factors number however combine outin f fill reducing ordering try get best worlds thus test outin preprocessing stage applying redblack minimum degree mip note use hash tables methods accelerate latter two means true precedence set outin always followed breaking ties minimum penalty aside also considered modifying minimum degree mip tiebreaking directly based weight candidate nodes connections previously selected nodes weighted tiebreaking rcm proved useful context ilu 11 however significant extra cost incurred tie breaking achieved little hereit appears global view weights required approximate inverses proceeding large test set verify orderings behaving expected another demonstration matrix aniso similar problem singleaniso four abutting regions anisotropy diering directions 12see figure 4 diagram showing directions domain shown table 3 results wnd nd outinmip mip didnt change significant improvement orderings 6 testing weighted results repeated tests weighted orderings results given tables 47 unsymmetric matrices used define wnd outin avoiding issue directed edges unweighted orderings box tables lower numbers correspond weighted orderings grouped corresponding unweighted orderings comparison 876 robert bridson weipai tang fig 4 schematic showing domain aniso arrows indicate direction strong connections table performance weighted orderings versus unweighted orderings aniso ordering f fill time compute preconditioner number iterations time iterations given 462 041 118 12 outin 266 031 77 076 redblack 239 028 107 113 outinrb 208 028 61 061 outinamd 69 015 48 05 wnd 84 015 nd suered preconditioner computing timeour spectral weighting appears severe creating much f fill however important note increase time much less suggested f fillindeed although wnd gave several times f fill add32 memplus saylr4 sherman4 wang1 actually allowed slightly faster preconditioner computation verifies merit heuristic natural ordering redblack benefited substantially outin terms preconditioner computation amdbar mip didnt seem aected muchthis could quite well result data structure algorithms necessarily preserve initial precedence set outin terms improving convergence didnt fix problems pores2 sherman2 watson5 matrices weak diagonals anyhow heuristics probably dont apply outin outinrb definite improvement natural ordering redblack apart bcsstk14 watson4 eect outin amdbar mip clear usually theres little eect matrices eg ale3d saylr4 opposite eect two wnd shows promise improving convergence nd considerably ale3d bcsstk14 orsirr1 orsreg1 saylr4 much poorer f fill reduction generally factor 4 gave problems matrices though ordering anisotropy approximate inverses 877 7 conclusions clear f fill reduction crucial speed preconditioner computation often making order magnitude dierence also saw f fill matrix computed cheaply gives good indication preconditioner computation time unweighted orderings least reducing f fill typically also gives eective preconditioner accelerating convergencenot number nonzeros true inverse factors de creased magnitude portion dropped ainv reduced however although nd gave best f fill reduction mip gave best acceleration care must taken would interesting determine probably several steps nd followed mip minimum degree variant subgraphs prove practical ordering anisotropy significant eect performance terms preconditioner computing time solution time wnd algorithm shows promise highperformance algorithm exploit anisotropy perhaps tuning weights laplacian matrix used robustness still issue believe sophisticated weighting heuristic necessary progress appendix testing data test platform 180mhz pentium pro running windowsnt used matlab 51 algorithm ainv written mex extension c ainv algorithm leftlooking columnbycolumn ver sion odiagonal entries dropped magnitude usersupplied tolerance entries shifted 10 3 max computed magnitude also make crucial use elimination tree making column conjugate previous columns consider descendants elimination tree columns could possibly contribute anything accelerates ainv considerably low f fill orderingseg sher man3 amdbar ordering drop tolerance 01 accelerated factor four upcoming paper 7 explore thoroughly compare orderings selected several matrices mostly harwellboeing collection first found amount true f fill caused ordering given table 4 determined droptolerances ainv produce preconditioners approximately n 2n nonzeros n number nonzeros given matrix matrix ordering fill level attempted solve using bicgstab cg spd matrices b chosen correct x vector 1s tables 5 6 7 give cpu time taken preconditioner computation iterations required reduce residual norm factor 10 9 cpu time taken iterations halted 1800 iterations daggers tables 6 7 indicate convergence point box tables upper line corresponds unweighted ordering lower line weighted counterpart tables 5 6 7 numbers left box correspond lowfill tests right highfill tests highlight winning ordering matrix put best numbers underlined boldface 878 robert bridson weipai tang table comparison f fill caused dierent orderings nonzero counts given thousands nonzeros box upper number corresponds unweighted ordering lower number corresponds weighted counterpart given redblack amdbar nd mip name n nnz outin outin outin wnd outin 1486 1506 419 1526 709 4468 4435 1615 113777 1736 28974 19841 6815 26054 12750 128 91 37 114 59 sherman5 3312 21 1340 1122 414 334 465 432 430 54 833 52 ordering anisotropy approximate inverses 879 table comparison cpu time preconditioner computation box upper numbers correspond unweighted ordering lower numbers correspond weighted counterpart numbers left refer lowfill test numbers right refer highfill test given redblack amdbar nd mip name outin outin outin wnd outin 17 16 20 18 13 15 25 32 13 15 add32 339 456 327 435 34 36 32 34 37 34 71 80 61 63 35 34 29 30 37 34 ale3d 143 266 130 241 94 161 64 110 159 283 bcsstk14 62 111 60 107 23 37 20 33 30 47 56 84 56 85 22 36 36 56 35 57 706 766 810 845 616 619 547 558 651 582 nasa1824 46 78 40 71 13 21 15 23 18 28 39 60 39 61 14 22 19 30 17 28 84 152 85 147 30 50 24 38 35 57 84 145 85 147 31 51 28 45 42 68 13 17 11 18 08 11 10 14 09 13 orsreg1 76 107 47 64 28 39 27 38 33 46 64 88 53 71 29 36 46 64 44 61 pores2 28 40 25 38 13 19 07 11 13 18 17 25 20 29 10 15 12 18 16 24 saylr4 85 121 59 71 28 38 23 28 41 50 46 61 41 48 29 35 23 26 33 39 sherman2 58 111 54 99 30 50 30 50 32 53 52 89 50 88 32 55 40 68 30 51 sherman5 121 212 95 164 41 66 36 57 41 63 76 117 73 116 43 67 48 73 41 63 swang1 187 294 182 280 42 58 32 44 64 92 182 298 148 233 41 42 34 46 59 85 wang1 196 313 108 164 62 88 62 89 92 132 162 242 121 180 64 92 62 88 92 133 21 29 20 28 07 08 10 12 08 09 72 113 38 60 20 30 18 25 27 40 48 77 38 58 22 32 18 25 24 36 74 120 42 66 21 30 18 26 28 39 51 75 37 55 27 39 19 26 25 3 table comparison iterations required reduce residual norm 10 9 box upper numbers correspond unweighted ordering lower numbers correspond weighted counterpart numbers left refer lowfill test numbers right refer highfill test given redblack amdbar nd mip name outin outin outin wnd outin 28 21 34 19 9 28 37 21 33 43 26 28 42 19 pores3 87 28 90 23 81 31 36 21 37 26 36 23 36 22 35 23 36 22 28 19 28 21 28 19 43 28 6 28 4 ordering anisotropy approximate inverses 881 table comparison time taken iterations box upper numbers correspond unweighted ordering lower numbers correspond weighted counterpart numbers left refer lowfill test numbers right refer highfill test given redblack amdbar nd mip name outin outin outin wnd outin ale3d 184 115 102 93 55 86 100 87 49 50 49 58 36 54 42 42 50 69 61 77 93 90 92 89 86 75 130 154 79 71 134 160 132 170 83 77 103 105 77 75 147 114 104 68 220 57 150 43 111 45 nasa1824 714 735 682 735 633 521 532 504 653 520 nasa2146 103 102 116 128 78 63 79 56 72 69 116 74 109 74 92 67 94 60 79 61 orsreg1 24 19 23 14 23 13 22 20 24 14 22 15 21 12 22 15 20 13 23 16 pores3 11 05 12 04 11 05 05 03 04 03 43 46 40 38 48 50 40 44 40 39 43 37 41 38 saylr4 718 46 39 64 47 46 89 43 83 43 656 48 68 46 62 44 48 43 49 43 sherman5 28 25 25 24 26 20 23 20 24 22 29 23 29 23 25 20 27 21 24 20 32 34 29 26 31 27 29 29 30 30 32 32 31 28 30 26 30 28 30 28 23 03 04 03 06 03 03 0 r approximate minimum degree ordering algorithm sparse approximate inverse preconditioner conjugate gradient method sparse approximate inverse preconditioner nonsymmetric linear systems numerical experiments two approximate inverse preconditioners orderings factorized sparse approximate inverse preconditioners refined algorithms factored approximate inverse approximate inverse techniques general sparse matrices approximate inverse preconditioners via sparsesparse iterations spectral ordering techniques incomplete lu preconditioners cg methods weighted graph based ordering techniques preconditioned conjugate gradient methods towards costeective ilu preconditioner high level fill decay rates inverses band matrices algebraic approach connectivity graphs improving performance parallel factorized sparse approximate inverse precon ditioners computer solution large sparse positive definite systems evolution minimum degree ordering algorithm predicting structure sparse matrix computations parallel preconditioning sparse approximate inverses fast high quality multilevel scheme partitioning irregular graphs factorized sparse approximate inverse preconditionings role elimination trees sparse factorization toward e tr ctr e flrez garca l gonzlez g montero effect orderings sparse approximate inverse preconditioners nonsymmetric problems advances engineering software v33 n710 p611619 29 november 2002 michele benzi preconditioning techniques large linear systems survey journal computational physics v182 n2 p418477 november 2002