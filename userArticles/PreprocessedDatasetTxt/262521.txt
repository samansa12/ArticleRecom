compiletime scheduling dynamic constructs dataflow program graphs abstractscheduling dataflow graphs onto processors consists assigning actors processors ordering execution within processors specifying firing time scheduling decisions made runtime overhead excessive real systems reduce overhead compiletime decisions made assigning andor ordering actors processors compiletime decisions based known profiles available actor compile time profile actor information necessary scheduling execution time communication patterns however dynamic construct within macro actor conditional datadependent iteration makes profile actor unpredictable compile time constructs propose assume profile compiletime define cost minimized deciding profile assumption runtime statistics available compiletime decisions profiles dynamic constructs shown optimal bold assumptions expected nearoptimal cases proposed scheduling technique implemented one rapid prototyping facilities ptolemy paper presents preliminary results performance synthetic examples b introduction ataflow graph representation either programming language intermediate representation compilation suitable programming multiprocessors parallelism extracted automatically representation 1 2 node actor dataflow graph represents either individual program instruction group thereof executed according precedence constraints represented arcs also represent flow data dataflow graph usually made hierarchical hierarchical graph actor may represent another dataflow graph called macro actor particularly define datadependent macro actor datadependent actor macro actor execution sequence internal dataflow graph data dependent cannot predicted compile time examples macro actors contain dynamic constructs datadependent iteration recursion actors said dataindependent datadependent scheduling task consists assigning actors pro cessors specifying order actors executed processor specifying time ha department computer engineering seoul national university seoul 151742 korea email shacompsnuackr e lee department electrical engineering computer science university california berkeley berkeley ca 94720 usa email ealohmeecsberkeleyedu executed tasks performed either compile time run time 3 fullydynamic scheduling scheduling decisions made run time flexibility balance computational load processors response changing conditions program case program large amount nondeterministic behav ior static assignment actors may result poor load balancing poor scheduling performance fully dynamic scheduling would desirable however runtime overhead may excessive example may necessary monitor computational loads processors ship program code processors via networks run time furthermore usually practical make globally optimal scheduling decision run time paper focus applications moderate amount nondeterministic behavior dsp applications graphics applications scheduling decisions made compile time better order reduce implementation costs make possible reliably meet timing constraints compiletime processor scheduling rich distinguished history 4 5 efforts focused deterministic models execution time actor processor p k fixed datadependent actors program graph even restricted domain applications algorithms accomplish optimal scheduling combinatorial complexity except certain trivial cases therefore good heuristic methods developed years 4 6 7 8 also scheduling techniques applied completely expanded dataflow graph assume actor assigned processor indivisible unit simpler however treat datadependent actor schedulable indivisible unit regarding macro actor schedulable unit greatly simplifies scheduling task prasanna et al 9 schedule macro dataflow graphs hierarchically treat macro actors matrix operations schedulable units macro actor may assigned one processor therefore new scheduling techniques treat macro actor schedulable unit devised compiletime scheduling assumes static information actor known define profile actor static information actor necessary given scheduling technique example use list scheduling technique profile actor simply computation time actor processor communication requirements actor actors included profile scheduling tech ha lee compiletime scheduling dynamic constructs dataflow program graphs 769 nique requires information profile macro actor would number assigned processors local schedule actor assigned processors dataindependent macro actor matrix op eration profile deterministic however profile datadependent actor dynamic construct cannot determined compile time since execution sequence internal dataflow subgraph varies run time constructs assume profiles somehow compiletime main purpose paper show define profiles dynamic constructs compiletime crucial assumption rely approximate runtime statistics dynamic behavior compile time simulation may proper method gather statistics program run embedded dsp system sometimes runtime statistics could given programmer graphics applications scientific applications optimally choosing profile dynamic con structs minimize expected schedule length program assuming quasistatic scheduling figure 1 actor datadependent actor scheduling result shown gantt chart horizontal axis indicates scheduling time vertical axis indicates processors compile time profile actor assumed run time schedule length program varies depending actual behavior actor note pattern processor availability actor b starts execution preserved run time inserting idle time actor executed remaining static schedule followed scheduling strategy called quasistatic scheduling first proposed lee 10 dsp applications strict application quasistatic scheduling requires synchronization actors guaranteed compile time runtime synchronization necessary long pattern processor availability consistent scheduled one generally impractical assume exact runtime behaviors actors known compile time therefore synchronization actors usually performed run time case necessary enforce pattern processor availability inserting idle time instead idle time inserted synchronization required execute actors execution order actors changed scheduled order actual schedule length obtained runtime synchronization proven much different quasistatic scheduling would produce 3 hence optimality criterion profile dynamic constructs based quasistatic scheduling strategy makes analysis simpler ii previous work deterministic scheduling heuristics assume static information actors known almost none addressed define static information datadependent actors pioneering work issue done martin estrin 11 calculated b c fig 1 dataflow graph consists five actors among actor datadependent actor b gantt chart compiletime scheduling assuming certain execution time actor c run time actor takes longer second processor padded noops actor takes less first processor idled make pattern processor availability scheduled one dark line quasistatic scheduling mean path length actor dummy terminal actor level actor list scheduling exam ple two possible paths divided conditional construct actor dummy terminal actor level actor sum path lengths weighted probability path taken thus levels actors based statistical distribution dynamic behavior datadependent actors since expensive compute mean execution times instead usually used static information datadependent actors 12 even though mean execution time seems reasonable choice means optimal addition approaches common drawback datadependent actor assigned single processor severe limitation multiprocessor system two groups researchers proposed quasistatic scheduling techniques independently lee 10 loeffler et al 13 developed methods schedule conditional datadependent iteration constructs respectively approaches allow one processor assigned dynamic constructs figure 2 shows conditional compares three scheduling methods figure 2 b local schedules branches shown two branches scheduled three processors total number processors 4 lees method overlap local schedules branches choose maximum termination processor hard realtime systems proper choice otherwise may inefficient either one branch likely taken size likely branch much smaller hand loeffler takes local schedule likely branch profile conditional strategy inefficient branches equally likely taken size assumed branch much larger finally conditional evaluation replaced conditional assignment make construct static graph modified illustrated figure c scheme true false branches sched 770 ieee transactions computers vol 46 7 july 1997 ifthenelse construct b local schedule two lees method e leofflers method c fullystatic schedule fig 2 three different schedules conditional construct example conditional construct forms datadependent actor whole b local deterministic schedules two branches c static schedule modifying graph use conditional assignment lees method overlap local schedules branches choose maximum processor e loefflers method take local schedule branch likely executed uled result one branch selected depending control boolean immediate drawback inefficiency becomes severe one two branches small actor another problem occurs unselected branch generates exception condition dividebyzero error methods conditionals adhoc appropriate general solution quasistatic scheduling effective datadependent iteration construct construct make effective use processors cycle iteration schedules one iteration pads noops make pattern processor availability termination pattern start figure equivalently processors occupied amount time iteration pattern processor availability iteration construct independent number iteration cycles scheme breaks construct cannot utilize processors effectively one iteration cycle fig 3 quasistatic scheduling datadependent iteration con struct pattern processor availability independent number iteration cycles recursion construct yet treated successfully statically scheduled data flow paradigm recently proper representation recursion construct proposed 14 explained schedule recursion construct onto multiproces sors finite resources careless exploitation parallelism recursion construct may cause system deadlock summary dynamic constructs conditionals datadependent iterations recursions treated properly past scheduling efforts either static scheduling dynamic scheduling adhoc methods introduced proven unsuitable general lutions earlier result datadependent iteration 3 demonstrated systematic approach determine profile datadependent iteration actor could minimize expected schedule length paper extend analysis general dynamic constructs next section show dynamic constructs assigned profiles compiletime also prove given profiles optimal unrealistic sumptions experiments enable us expect decisions nearoptimal cases section 45 6 contains example datadependent iteration recur sion conditionals respectively show profiles dynamic constructs determined known runtime statistics implement technique ptolemy framework 15 preliminary simulation results discussed section 7 finally discuss limits method mention future work iii compiletime profile dynamic constructs actor assigned compiletime profile static scheduling assuming quasistatic scheduling strategy proposed scheme decide profile construct average schedule length minimized assuming actors except dynamic construct dataindependent objective suitable hard realtime system bound worst case havior also assume dynamic constructs uncorrelated assumption may isolate effect dynamic construct schedule length sep arately case interdependent actors may group actors another macro actor decide optimal profile large actor even though decision profile new macro actor would complicated case approach still valid nested dynamic constructs apply proposed scheme inner dynamic construct first simplicity examples paper one dynamic construct dataflow graph runtime cost actor c sum total computation time devoted actor idle time due quasistatic scheduling strategy proces sors figure 1 runtime cost datadependent actor sum lightly computation time darkly shaded areas actor c immediate idle time dynamic construct schedule length certain iteration written schedule total number processors system r rest computation including idle time may result within schedule end therefore minimize expected schedule length minimizing expected cost datadependent acha lee compiletime scheduling dynamic constructs dataflow program graphs 771 tor dynamic construct assume r independent decisions profile actor assumption unreasonable precedence constraints make r dependent choice profile consider example situation dynamic construct always critical path processors effectively use decision profile construct directly affect idle time end schedule included r hand enough parallelism make effective use unassigned processors execution times actors small relative schedule length assumption valid realistic situations likely fall two extremes select optimal compiletime profile actor assume statistics runtime behavior known compiletime validity assumption varies large extent depending application digital signal processing applications given program repeatedly executed data stream simulation useful obtain necessary information general however may use wellknown distribution example uniform geometric distribution makes analysis simple using statistical information choose profile give least expected cost runtime compiletime profile profile datadependent actor local schedule determines number assigned processors computation times taken assigned processors overall algorithm profile decision follows assume dynamic behavior actor expressed parameter k distribution pk total number processors n number processors assigned actor ank actor cost parameter n k pk probability parameter k next section illustrate proposed scheme datadependent iteration recursion conditionals respectively show profiles decided runtime statistics iv data dependent iteration datadependent iteration number iteration cycles determined runtime cannot known compiletime two possible dataflow representations datadependent iteration shown figure 4 10 numbers adjacent arcs indicate number tokens produced consumed actor fires 2 figure 4 since upsample actor produces tokens time fires iteration body consumes one token fires iteration body must fire times firing upsample actor figure 4 b f iteration body source1 b fig 4 datadependent iteration represented using either dataflow graphs shown graph used number iterations known prior commencement iteration b used otherwise number iterations need known prior commencement iteration token coming routed select actor iteration body arc connected control input select actor indicates initial token arc value false ensures data coming f input consumed first time select actor fires first input token consumed control input select actor value true function indicates iteration finished producing token value false itera tion output iteration function f routed around switch actor test function produces token value false many variations two basic models datadependent iteration previous work 3 considered subset datadependent iterations simultaneous execution successive cycles prohibited figure 4 b figure 4 restriction unless iteration body contains recurrence therefore generalize previous method permit overlapped cycles successive iteration cycles invokable completion iteration cycle detection intercycle dependency sequential language main task parallel compiler maximize parallelism dataflow represen tation however reveals dependency rather easily presence delay feedback arc assume probability distribution number iteration cycles known approximated compile time let number iteration cycles random variable known probability mass function pi simplicity set minimum possible value 0 let number assigned processors n total number processors assume blocked schedule local schedule iteration body remove unnecessary complexity illustrations although proposed technique applicable overlap execution schedule 16 blocked schedule assigned processors assumed available synchronized beginning thus execution time one iteration cycle n assigned processors n displayed figure 5 denote n time must 772 ieee transactions computers vol 46 7 july 1997 elapse one iteration next iteration enabled time could zero data dependency iterations given local schedule one iteration cycle decide assumed number iteration cycles xn number overlapped cycles kn two parameters xn kn chosen profile datadependent iteration actor determined shown figure 5 b subscript n n n xn kn represents functions n number assigned processors brevity omit subscript n variables without confusion using profile datadependent macro actor global scheduling performed make hierarchical compilation note pattern processor availability execution construct different execution address schedule iteration body paper since standard problem static scheduling2 x2 x next iteration cycle executable fig 5 blocked schedule one iteration cycle datadependent iteration actor quasistatic schedule constructed using fixed assumed number x cycles iteration cost actor sum dotted area execution time dark area idle time due iteration displays 3 possible cases depending actual number cycles b according quasistatic scheduling policy three cases happen runtime actual number cycles coincides assumed number iteration cycles iteration actor causes idle time cost actor consists execution time actor oth erwise assigned processors idled iteration takes fewer x cycles figure 5 c else processors well idled figure 5 expected cost iteration actor cn k x sum individual costs weighted probability mass function number iteration cycles expected cost becomes x pintx x 2 combining first term first element second term reduces e 3 method choose three parameters n k x order minimize expected cost equation 3 first assume n fixed since cn k x decreasing function k fixed n select maximum possible number k number k bounded two ratios n latter constraint necessary avoid idle time iteration cycles processor result k set next step determine optimal x value x optimal expected cost decreased vary x gamma1 therefore obtain following inequalities since positive inequality 5x k equal 1 inequality becomes inequality 5 3 shows previous work special case general method decided optimal value x k given number n choose optimal n next question answer since simple function n closed form n minimizing cn k x exists unfortunately however may use exhaustive search possible values n select value minimizing cost polynomial time moreover experiments show search space n often reduced significantly using criteria experiments show method relatively insensitive approximated probability mass function using wellknown distributions nice mathematical properties approximation reduce summation terms 3 6 closed forms let us consider geometric probability mass function parameter q approximated distribution number iteration cycles models class asymmetric bellshaped distributions geometric probability mass function means nonnegative integer r use inequality 6 findx ha lee compiletime scheduling dynamic constructs dataflow program graphs 773 therefore inequality 6 optimal value x satisfies using floor notation obtain closed form optimal value follows furthermore equation 3 simplified using factx getting simplified formulas optimal profile iteration actor similar simplification possible also uniform distributions 17 k equals 1 results coincide previous result reported 3 v recursion recursion construct instantiates part computation termination condition sat isfied high level programming languages support construct since makes program compact easy understand however number selfinstantiations called depth recursion usually known compiletime since termination condition calculated runtime dataflow paradigm recursion represented macro actor contains self actor figure 6 self actor simply represents instance subgraph within sits recursion actor one self actor function actor identically represented datadependent iteration actor shown figure 4 b previous section includes special case tail recursive constructs accordingly scheduling decision recursion actor translated datadependent iteration actor generalized recursion construct may one self actor number self actors recursion construct called width recursion real applications width recursion two recursion construct width 2 depth 2 illustrated figure 6 b c assume nodes depth computation tree termination condition discuss limitation assumption later also assume runtime probability mass function depth recursion known approximated compiletime potential parallelism computation tree generalized recursion construct may huge since nodes depth executed concurrently maximum degree parallelism however usually known compiletime exploit parallelism construct consider resource limitations may restrict parallelism order deadlock system restricting parallelism case maximum degree parallelism large recognized difficult problem solved dynamic dataflow system approach proposes efficient solution taking degree parallelism additional component profile recursion construct suppose width recursion construct k let depth recursion random variable known probability mass function pi denote degree parallelism means descendents depth computation graph assigned different processor groups descendent recursion construct depth called ground construct figure 7 denote size processor group n total number processors devoted recursion becomes nk profile recursion construct defined three parameters assumed depth recursion x degree parallelism size processor group n approach optimizes parameters minimize expected cost recursion construct example profile recursion construct displayed figure 7 b let sum execution times actors ac h figure 6 let sum execution times actors b schedule length l x ground construct becomes l x run time processors idled actual depth recursion different assumed depth recursion illustrated figure 7 c actual depth recursion smaller assumed depth x assigned processors idled otherwise processors well idled let r sum execution times recursion besides ground constructs basic cost r equal nk gamma1 runtime cost c 1 becomes assuming x less x cost c 2 becomes therefore expected cost recursion construct sum runtime cost weighted probability mass function x 774 ieee transactions computers vol 46 7 july 1997 ac ac ac test f b c depth112 self actor function fx testx true else return return hfc1xfc2x c fig 6 example recursion construct b dataflow representation self actor represents recursive call c computation tree recursion construct two self actors depth recursion two ac ac ac24 b nk l x ac ac ac construct ground ac ac ac c ac ac ac fig 7 reduced computation graph recursion construct width 2 degree parallelism 2 b profile recursion construct schedule length ground construct function assumed depth recursion x degree parallelism quasistatic schedule constructed depending actual depth recursion c x x manipulations first assume n fixed since expected cost decreasing function select maximum possible number number bounded processor constraint nk since assume assumed depth recursion x greater degree parallelism optimal value next decide optimal value x observation x optimal expected cost decreased x varied 1 gamma1 therefore get ha lee compiletime scheduling dynamic constructs dataflow program graphs 775 rearranging inequalities get followingx nk note similarity inequality 20 datadependent iterations 6 particular k 1 two formulas equivalent expected optimal values x depend shown 18 20 may need use iterative computations obtain optimal values x starting let us consider example probability mass function depth recursion geometric parameter q execution depth recursion proceed depth depth inequality 20 optimal x satisfies nk result x becomes nk assume n fixed since transcendental function n dependency expected cost upon size processor group n clear stead examine possible values n calculate expected cost equation 3 choose optimal n giving minimum cost complexity procedure still polynomial usually reduced significantly since search space n reduced criteria case geometric distribution depth recursion expected cost simplified case number child functions one simplified formulas geometric distribution coincide datadependent iterations except overhead term detect loop termination recall analysis based assumption nodes depth computation tree termination condition assumption roughly approximates realistic assumption call independence assumption nodes depth equal probability terminating recursion independent equal probability considered probability nodes depth terminate recursion assumption expected number nodes certain depth assumptions even though describe different behaviors independence assumption shape profile would shown figure 7 degree parallelism maximized moreover recursion processors schedule length ground constructs however optimal schedule length l x ground construct would different length l x proportional number executions recursion constructs inside ground construct number integer independence assumptions belongs subset f0 assumption since probability mass function number likely complicated independence assumption sacrifice performance choosing suboptimal schedule length simpler assumption vi conditionals decision making capability indispensable requirement programming language general applications even signal processing applications dataflow representation ifthenelse local schedules branches shown figure 2 b assume probability p 1 true branch branch 1 selected known false branch branch 2 selected probability ij finishing time local schedule ith branch jth processor let j finishing time jth processor optimal profile conditional construct determine optimal values f j g minimize expected runtime cost construct ith branch selected cost becomes therefore expected cost cn feasible obtain closed form solutions j max function nonlinear discontinuous instead numerical algorithm developed 1 initially take maximum finish time branch schedules processor according lees method 10 2 define ff initially variable ff represents excessive cost per processor expected cost branch selected run time define bottleneck processors branch processors fjg satisfy branches fig repeat next step 3 choose set bottleneck processors theta branch decrease j ffi j 2 theta variation expected cost becomes deltac set theta needs updated update theta repeat step 3 consider example shown figure 2 suppose 07 initial profile algorithm lees profile shown figure 8 776 ieee transactions computers vol 46 7 july 1997 happens loefflers profile specific ex ample optimal profile determined algorithm displayed figure 8 b1 initial profile b optimal profile fig 8 generation optimal profile conditional construct figure 2 initial profile b optimal profile generalized proposed algorithm mway branch construct case construct realize mway branch prefer using case construct using nested ifthenelse constructs generalization proposed algorithm proof optimality beyond scope paper detailed discussion refer 17 given number assigned processors proposed algorithm determines optimal profile obtain optimal number assigned processors compute total expected cost number choose minimum vii example proposed technique schedule datadependent actors implemented ptolemy heterogeneous simulation prototyping environment developed ucberkeley usa 15 one key objectives ptolemy allow many different computational models coexist system domain set blocks obey common computational model example mixed domain system shown figure 9 synchronous dataflow sdf domain contains dataindependent actors performs compiletime scheduling two branches conditional constructs represented sdf subsystems local schedules generated static scheduler using local schedules branches dynamic dataflowddf domain executes proposed algorithm obtain optimal profile conditional construct topmost sdf domain system regards ddf domain macro actor assumed profile performs global static scheduling ddf fig 9 example mixed domain system topmost level system sdf domain dynamic constructifthenelse ddf domain turn contains two subsystems sdf domain branches apply proposed scheduling technique several synthetic examples preliminary experiments experiments serve full test proof generality technique however verify proposed technique make better scheduling decisions simple adhoc decisions dynamic constructs many applications target architecture assumed shared bus architecture 4 processors communication overlapped computation test effectiveness proposed technique compare following scheduling alternatives dynamic constructs method 1 assign processors dynamic con struct method 2 assign one processor dynamic construct method 3 apply fully dynamic scheduling ignoring overhead method 4 apply fully static scheduling method 1 corresponds previous research quasistatic scheduling technique made lee 10 loeffler et al 13 data dependent iterations method 2 approximately models situation implement dynamic construct single big atomic actor simulate third model list possible outcomes represented dataindependent macro actor possible outcome replace dynamic construct dataindependent macro actor perform fullystatic scheduling scheduling result method 3 nonrealistic since ignores overhead fully dynamic scheduling strategy nonetheless give yardstick measure relative performance scheduling decisions modifying dataflow graphs may use fully static scheduling method 4 conditional construct may evaluate branches select one multiplexor actor datadependent iteration construct always perform worst case number iterations comparison use average schedule length program performance measure example consider construct datadependent iteration shown figure 10 number inside actor represents execution length increase parallelism pipelined graph beginning construct scheduling decisions made construct many processors assigned iteration body many iteration cycles scheduled explicitly assume number iteration cycles uniformly distributed 1 7 determine optimal number assigned processors compare expected total cost shown table since iteration body utilize two processors effectively expected total cost first two columns close ever schedule determines assigning one processor slightly better rather parallelizing iteration body scheduler automatically parallelizes iteration cycles change parameters may want parallelize iteration body first iteration cycles next ha lee compiletime scheduling dynamic constructs dataflow program graphs 777 14 52176 body554 fig 10 example construct top level subsystems associated construct also displayed number inside actor represents execution length actor proposed technique considers tradeoffs parallelizing inner loops parallelizing outer loops nested loop construct main problem parallelizing compilers sequential programs resulting gantt chart example shown figure 11 9 fig 11 gantt chart disply scheduling result 4 processors proposed scheduling technique example figure 10 profile construct identified number iteration cycles run time less equal 3 schedule length example schedule period 66 greater 3 schedule length increase therefore average schedule length example becomes 799 average schedule length scheduling decisions compared table ii proposed technique outperforms realistic methods achieves 85 ideal schedule length method 3 example assigning 4 processors iteration body method 1 worsens performance since fails exploit intercycle parallelism confining dynamic construct single actor method 2 gives worst performance expected since fails exploit intercycle parallelism parallelism iteration body since range number iteration cycles big assuming worst case iteration method 4 bad example however reveals shortcoming proposed technique assign 2 processors iteration body exploit parallelism iteration body well intercycle parallelism average schedule length becomes 777 slightly better scheduling result proposed technique calculate expected total cost decide optimal number processors assign iteration body account global effect decision since difference expected total costs proposed technique best scheduling significant shown table nonoptimality proposed technique could anticipated improve performance proposed technique add heuristic expected total cost significantly greater optimal one perform scheduling assigned number compare performance proposed technique choose best scheduling result search assumed number iteration cycles optimal profile faultless either since proposed technique finds local optimum proposed technique selects 3 assumed number iteration cycles proved however best assumed number 2 example even though performance difference negligible although proposed technique always optimal certainly better scheduling methods demonstrated table ii experiments dynamic constructs well nested constructs performed obtain similar results proposed technique outperforms adhoc decisions resulting quasistatic schedule could least 10 faster scheduling decisions currently existent little 15 slower ideal highly unrealistic fullydynamic schedule nested dynamic construct compiletime profile inner dynamic construct affects outer dynamic construct general tradeoff exploiting parallelism inner dynamic construct first outer construct first proposed technique resolves conflict automatically refer 17 detailed discussion let us assess complexity proposed scheme number dynamic constructs including nested ones number processors n total number profile decision steps order nd ond determine optimal profile also consumes ond time units therefore overall complexity order nd memory requirements order od magnitude number profiles maintained also order nd viii conclusion long datadependent behavior dominating dataflow program scheduling decisions made compile time better since reduce hardware software overhead scheduling run time compiletime decision task assignment andor ordering need static information called profiles actors heuristics compiletime decisions assume static information tasks use adhoc approximations paper propose systematic method decide profiles dynamic construct define compiletime profile dynamic construct assumed local schedule body dynamic 778 ieee transactions computers vol 46 7 july 1997 expected total cost construct function number assigned processors number assigned processors 1 2 3 4 expected total cost 1299 1359 1779 na ii performance comparison among several scheduling decisions average schedule length 797 909 1043 681 90 ideal 085 075 065 10 076 construct define cost dynamic construct choose compiletime profile order minimize expected cost cost dynamic construct sum execution length construct idle time processors runtime due difference compiletime profile actual runtime profile discussed detail compute profile three kinds common dynamic constructs conditionals datadependent iterations recursion compute expected cost require statistical distribution dynamic behavior example distribution number iteration cycles datadependent iteration must known approximated compiletime particular examples used ex periments performance degrade rapidly stochastic model deviates actual program havior suggesting compiler use fairly simple techniques estimate model implemented technique ptolemy part rapid prototyping environment illustrated effectiveness proposed technique synthetic example paper many examples 17 results preliminary indication potential practical applications promising proposed technique makes locally optimal decisions dynamic construct shown proposed technique effective amount data dependency dynamic construct small admittedly cannot quantify level technique breaks acknowledgments authors would like gratefully thank anonymous reviewers helpful suggestions research part ptolemy project supported advanced research projects agency us air force rassp program contract f3361593c1317 state california micro program following companies bell northern research cadence dolby hi tachi luckygoldstar mentor graphics mitsubishi mo torola nec philips rockwell r data flow languages synchronous data flow compiletime scheduling assignment dataflow program graphs datadependent iteration deterministic processor scheduling multiprocessor scheduling account interprocessor communications general approach mapping parallel computations upon multiprocessor architecture task allocation scheduling models multiprocessor digital signal processing hierarchical compilation macro dataflow graphs multiprocessors local memory recurrences iteration conditionals statically scheduled block diagram languages path length computation graph models computations effect operation scheduling performance data flow computer hierar chical scheduling systems parallel architectures tdfl tasklevel dataflow language ptolemy framework simulating prototyping heterogeneous sys tems program partitioning reconfigurable multiprocessor system compiletime scheduling dataflow program graphs dynamic constructs tr ctr ziegenbein k richter r ernst j teich l thiele representation process mode correlation scheduling proceedings 1998 ieeeacm international conference computeraided design p5461 november 0812 1998 san jose california united states karsten strehl lothar thiele dirk ziegenbein rolf ernst jrgen teich scheduling hardwaresoftware systems using symbolic techniques proceedings seventh international workshop hardwaresoftware codesign p173177 march 1999 rome italy jack n jean karen tomko vikram yavagal jignesh shah robert cook dynamic reconfiguration support concurrent applications ieee transactions computers v48 n6 p591602 june 1999 yury markovskiy eylon caspi randy huang joseph yeh michael chu john wawrzynek andr dehon analysis quasistatic scheduling techniques virtualized reconfigurable machine proceedings 2002 acmsigda tenth international symposium fieldprogrammable gate arrays february 2426 2002 monterey california usa chanik park sungchan kim soonhoi ha dataflow specification system level synthesis 3d graphics applications proceedings 2001 conference asia south pacific design automation p7884 january 2001 yokohama japan thies michal karczmarek janis sermulins rodric rabbah saman amarasinghe teleport messaging distributed stream programs proceedings tenth acm sigplan symposium principles practice parallel programming june 1517 2005 chicago il usa jin hwan park h k dai reconfigurable hardware solution parallel prefix computation journal supercomputing v43 n1 p4358 january 2008 praveen k murthy etan g cohen steve rowland system canvas new design environment embedded dsp telecommunication systems proceedings ninth international symposium hardwaresoftware codesign p5459 april 2001 copenhagen denmark l thiele k strehl ziegenbein r ernst j teich funstate